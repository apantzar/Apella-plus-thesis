[{
    "name": "\u0392\u03b1\u03c3\u03af\u03bb\u03b5\u03b9\u03bf\u03c2 \u0392\u03b1\u03c3\u03c3\u03ac\u03bb\u03bf\u03c2",
    "romanize name": "Vasileios Vassalos",
    "School-Department": "\u03a0\u03bb\u03b7\u03c1\u03bf\u03c6\u03bf\u03c1\u03b9\u03ba\u03ae\u03c2",
    "University": "aueb",
    "Rank": "\u039a\u03b1\u03b8\u03b7\u03b3\u03b7\u03c4\u03ae\u03c2",
    "Apella_id": 19804,
    "Scholar name": "Vasilis Vassalos",
    "Scholar id": "oaM-d7QAAAAJ",
    "Affiliation": "Professor of Informatics, Athens University of Economics and Business",
    "Citedby": 3653,
    "Interests": [
        "Databases",
        "Data management",
        "Information Integration",
        "Query Processing and Optimization",
        "Big Data Processing"
    ],
    "Scholar url": "https://scholar.google.com/citations?user=oaM-d7QAAAAJ&hl=en",
    "Publications": [
        {
            "Title": "Double index nested-loop reactive join for result rate optimization",
            "Publication year": 2009,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/4812428/",
            "Abstract": "Adaptive join algorithms have recently attracted a lot of attention in emerging applications where data is provided by autonomous data sources through heterogeneous network environments. Their main advantage over traditional join techniques is that they can start producing join results as soon as the first input tuples are available, thus improving pipelining by smoothing join result production and by masking source or network delays. In this paper we propose double index nested loops reactive join (DINER), a new adaptive join algorithm for result rate maximization. DINER combines two key elements: an intuitive flushing policy that aims to increase the productivity of in-memory tuples in producing results during the online phase of the join, and a novel re-entrant join technique that allows the algorithm to rapidly switch between processing in-memory and disk-resident tuples, thus better exploiting temporary delays \u2026",
            "Abstract entirety": 0,
            "Author pub id": "oaM-d7QAAAAJ:ULOm3_A8WrAC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Scheduling mapreduce jobs under multi-round precedences",
            "Publication year": 2016,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-319-43659-3_16",
            "Abstract": "We consider non-preemptive scheduling of MapReduce jobs consisitng of multiple map-reduce rounds so as to minimize the average weighted completion time on identical and unrelated processors. For identical processors, we present LP-based O(1)-approximation algorithms, while for unrelated processors the approximation ratio naturally depends on the maximum number of rounds of any job (a small constant in practice). For the single-round case, we substantially improve on previously best known approximation ratios for both identical and unrelated processors. Moreover, we conduct an experimental analysis and compare the performance of our algorithms against a fast heuristic and a lower bound on the optimal solution, thus demonstrating their promising practical performance.",
            "Abstract entirety": 1,
            "Author pub id": "oaM-d7QAAAAJ:SeFeTyx0c_EC",
            "Publisher": "Springer, Cham"
        },
        {
            "Title": "XPath query containment and rewriting using views",
            "Publication year": 2010,
            "Publication url": "https://hal.inria.fr/inria-00543951/",
            "Abstract": "AD/IM/VV (UCSD/INRIA/AUEB) View-based XML rewriting BDA Toulouse, October 2010 2/49",
            "Abstract entirety": 1,
            "Author pub id": "oaM-d7QAAAAJ:TFP_iSt0sucC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Rewriting minimizations for efficient query answering over ontologies",
            "Publication year": 2017,
            "Publication url": "https://www.worldscientific.com/doi/abs/10.1142/S0218213017600247",
            "Abstract": "Computing a (Union of Conjunctive Queries \u2014 UCQ) rewriting \u211b for an input query and ontology and evaluating it over the given dataset is a prominent approach to query answering over ontologies. However, \u211b can be large and complex in structure hence additional techniques, like query subsumption and data constraints, need to be employed in order to minimize \u211b and lead to an efficient evaluation. Although sound in theory, how to efficiently and effectively implement many of these techniques in practice could be challenging. For example, many systems do not implement query subsumption. In the current paper we present several practical techniques for UCQ rewriting minimization. First, we present an optimized algorithm for eliminating redundant (w.r.t. subsumption) queries as well as a novel framework for rewriting minimization using data constraints. Second, we show how these techniques can also be used \u2026",
            "Abstract entirety": 0,
            "Author pub id": "oaM-d7QAAAAJ:EUQCXRtRnyEC",
            "Publisher": "World Scientific Publishing Company"
        },
        {
            "Title": "Querying XML data sources that export very large sets of views",
            "Publication year": 2011,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/1929934.1929939",
            "Abstract": "We study the problem of querying XML data sources that accept only a limited set of queries, such as sources accessible by Web services which can implement very large (potentially infinite) families of XPath queries. To compactly specify such families of queries we adopt the Query Set Specifications, a formalism close to context-free grammars.We say that query Q is expressible by the specification P if it is equivalent to some expansion of P. Q is supported by P if it has an equivalent rewriting using some finite set of P's expansions. We study the complexity of expressibility and support and identify large classes of XPath queries for which there are efficient (PTIME) algorithms. Our study considers both the case in which the XML nodes in the results of the queries lose their original identity and the one in which the source exposes persistent node ids.",
            "Abstract entirety": 1,
            "Author pub id": "oaM-d7QAAAAJ:4DMP91E08xMC",
            "Publisher": "ACM"
        },
        {
            "Title": "Working Group: Classification, Representation and Modeling",
            "Publication year": 2009,
            "Publication url": "https://www.narcis.nl/publication/RecordID/oai:ris.utwente.nl:publications%2F2f1d4169-8999-46df-a8f1-785e45728963",
            "Abstract": "This report briefly summarizes the discussions carried out in the working group on classication, representation and modeling of uncertain data. The discussion was divided into two subgroups: the first subgroup studied how different representation and modeling alternatives currently proposed can fit in a bigger picture of theory and technology interaction, while the second subgroup focused on contrasting current system implementations and the reasons behind such diverse class of available prototypes. We summarize the findings of these two groups and the future steps suggested by group members.",
            "Abstract entirety": 1,
            "Author pub id": "oaM-d7QAAAAJ:WbkHhVStYXYC",
            "Publisher": "Dagstuhl"
        },
        {
            "Title": "Modelling machine learning algorithms on relational data with datalog",
            "Publication year": 2018,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/3209889.3209893",
            "Abstract": "The standard process of data science tasks is to prepare features inside a database, export them as a denormalized data frame and then apply machine learning algorithms. This process is not optimal for two reasons. First, it requires denormalization of the database that can convert a small data problem into a big data problem. The second shortcoming is that it assumes that the machine learning algorithm is disentangled from the relational model of the problem. That seems to be a serious limitation since the relational model contains very valuable domain expertise. In this paper we explore the use of convex optimization and specifically linear programming, for modelling machine learning algorithms on relational data in an integrated way with data processing operators. We are using SolverBlox, a framework that accepts as an input Datalog code and feeds it into a linear programming solver. We demonstrate the \u2026",
            "Abstract entirety": 0,
            "Author pub id": "oaM-d7QAAAAJ:xtRiw3GOFMkC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Declarative data analytics: a survey",
            "Publication year": 2019,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/8931243/",
            "Abstract": "The area of declarative data analytics explores the application of the declarative paradigm on data science and machine learning. It proposes declarative languages for expressing data analysis tasks and develops systems which optimize programs written in those languages. The execution engine can be either centralized or distributed, as the declarative paradigm advocates independence from particular physical implementations. The survey explores a wide range of declarative data analysis frameworks by examining both the programming model and the optimization techniques used, in order to provide conclusions on the current state of the art in the area and identify open challenges.",
            "Abstract entirety": 1,
            "Author pub id": "oaM-d7QAAAAJ:KxtntwgDAa4C",
            "Publisher": "IEEE"
        },
        {
            "Title": "Cost based plan selection for XPath",
            "Publication year": 2009,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/1559845.1559909",
            "Abstract": "We present a complete XPath cost-based optimization and execution framework and demonstrate its effectiveness and efficiency for a variety of queries and datasets. The framework is based on a logical XPath algebra with novel features and operators and a comprehensive set of rewriting rules that together enable us to algebraically capture many existing and novel processing strategies for XPath queries. An important part of the framework is PSA, a very efficient cost-based plan selection algorithm for XPath queries. In the presented experimental evaluation, PSA picked the cheapest estimated query plan in 100% of the cases. Our cost-based query optimizer independent of the underlying physical data model and storage system and of the available logical operator implementations, depending on a set of well-defined APIs. We also present an implementation of those APIs, including primitive access methods, a \u2026",
            "Abstract entirety": 0,
            "Author pub id": "oaM-d7QAAAAJ:0EnyYjriUFMC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Integrating clinical data from hospital databases.",
            "Publication year": 2018,
            "Publication url": "ftp://ceur-ws.org/pub/publications/CEUR-WS/Vol-2164.zip",
            "Abstract": "We present the Data Harmonization module from the Data Factory pipeline of the Human Brain Project which makes all the data transformations that are necessary to conform the local hospital datasets into a global schema and import them in the Medical Informatics Platform. To that scope, we encountered several challenging problems mostly due to the syntactic and semantic heterogeneities of the hospitals data. We elaborate on these data integration issues and present our implemented solutions.",
            "Abstract entirety": 1,
            "Author pub id": "oaM-d7QAAAAJ:1sJd4Hv_s6UC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Taco: tunable approximate computation of outliers in wireless sensor networks",
            "Publication year": 2010,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/1807167.1807199",
            "Abstract": "Wireless sensor networks are becoming increasingly popular for a variety of applications. Users are frequently faced with the surprising discovery that readings produced by the sensing elements of their motes are often contaminated with outliers. Outlier readings can severely affect applications that rely on timely and reliable sensory data in order to provide the desired functionality. As a consequence, there is a recent trend to explore how techniques that identify outlier values can be applied to sensory data cleaning. Unfortunately, most of these approaches incur an overwhelming communication overhead, which limits their practicality. In this paper we introduce an in-network outlier detection framework, based on locality sensitive hashing, extended with a novel boosting process as well as efficient load balancing and comparison pruning mechanisms. Our method trades off bandwidth for accuracy in a \u2026",
            "Abstract entirety": 0,
            "Author pub id": "oaM-d7QAAAAJ:MXK_kJrjxJIC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Machine learning in SQL by translation to TensorFlow",
            "Publication year": 2021,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/3462462.3468879",
            "Abstract": "We present sql4ml, a framework for expressing machine learning (ML) algorithms in a relational database management system (RDBMS). The user writes the objective function of an ML model as a SQL query, then sql4ml translates the query into an equivalent TensorFlow (TF) graph, which can be automatically differentiated and optimized to learn the model weights. Sql4ml makes the database a unified programming environment for feature engineering, learning/inference, and evaluating models. The proposed approach is more expressive than using ready-made ML algorithms, but abstracts away the details of the training process. We present the architecture of sql4ml and describe the method for translating an objective function in SQL to a TensorFlow representation. We show how recent ideas from Factorized ML [7] can be leveraged to efficiently move data between a database and an ML framework. Finally \u2026",
            "Abstract entirety": 0,
            "Author pub id": "oaM-d7QAAAAJ:08ZZubdj9fEC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Yannis Papakonstantinou",
            "Publication year": 2002,
            "Publication url": "http://www.cse.buffalo.edu/~mpetropo/presentations/SIGMOD02.pdf",
            "Abstract": "Query Languages for Semistructured Data Page 1 QURSED: Querying and Reporting \nSemistructured Data Yannis Papakonstantinou Michalis Petropoulos UNIVERSITY OF \nCALIFORNIA, SAN DIEGO Vasilis Vassalos NEW YORK UNIVERSITY June 2002 Page 2 \nOverview \u2022 Query Forms and Reports \u2013 Challenges of Semistructured Data \u2022 The QURSED \nsystem \u2013 Architecture \u2022 Technical foundation \u2013 Tree Query Language (TQL) \u2013 Query Set \nSpecification (QSS) \u2022 QURSED Editor Page 3 Exporting DBMSs on the Web FOR $s IN \ndocument(\u201csensors.xml\"), $p IN $s/manufacturer/product WHERE $p/specs/sensing_distance > 4 \nAND $p/specs/body_type/cylindrical RETURN <big_cylindrical_sensors> {$p} </big_cylindrical_sensors> \nSource BROWSER / GUI End-User DATABASE SERVER Source XQuery XML XML XML View \nXML Schema XML View \u2022 XML views and schemas \u2022 XQuery behind the scenes \u2022 Need for web-4 \u2026",
            "Abstract entirety": 0,
            "Author pub id": "oaM-d7QAAAAJ:zA6iFVUQeVQC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Towards the identification of disease signatures",
            "Publication year": 2015,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-319-23344-4_15",
            "Abstract": "The identification of biological signatures of diseases will enable the development of new biologically grounded classifications of brain diseases, leading to a new systematic understanding of their causes, and new diagnostic tools. In this paper we present the challenges and steps taken towards the identification of disease signatures, through the Medical Informatics Platform of the Human Brain Project, that will expedite diagnosis and lead to more accurate prognosis and objective diagnosis.",
            "Abstract entirety": 1,
            "Author pub id": "oaM-d7QAAAAJ:g5m5HwL7SMYC",
            "Publisher": "Springer, Cham"
        },
        {
            "Title": "A Review in Efficient Mobile Object Tracking Techniques",
            "Publication year": 2007,
            "Publication url": "http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.101.8947&rep=rep1&type=pdf",
            "Abstract": "Nowadays, wireless communication systems are becoming increasingly popular, resulting in new computing paradigms. This phenomenon stimulates the development of new distributed systems and applications, over wireless infrastructures, which assimilate the notion of mobility. Mobility rises naturally in wireless environments for they facilitate convenient location changes. On the other hand, the population boom of mobile inexpensive devices with advanced computational capabilities, that we are witnessing, fuels the development of distributed information services over wireless/mobile infrastructures. Inside these ubiquitous computing environments, a mobile workforce needs to locate other mobile objects (eg, data or devices). In this work we present the most widely researched solutions to the general problem of managing location changes and we debate on the advantages and disadvantages of these techniques.",
            "Abstract entirety": 1,
            "Author pub id": "oaM-d7QAAAAJ:hC7cP41nSMkC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Keywords-to-SPARQL translation for RDF data search and exploration",
            "Publication year": 2015,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-319-24592-8_9",
            "Abstract": "Linked Data is the most common practice for publishing and sharing information in the Data Web. As new data become available, their exploration is a fundamental step towards integration and interoperability. However, typical search methods as SPARQL queries require knowing both the SPARQL syntax and the vocabulary used in the data. For this reason, keyword-based search has been proposed, allowing an intuitive way for searching an RDF dataset. In this paper, we present a novel approach for keyword search on graph-structured data, and in particular temporal RDF graph, i.e. RDF data that involve temporal properties. Our method, instead of providing answers directly from the RDF data graph, automatically generates a set of candidate SPARQL queries that try to capture users information need as expressed by the keywords used. To support temporal exploration, our method is enriched with \u2026",
            "Abstract entirety": 0,
            "Author pub id": "oaM-d7QAAAAJ:abG-DnoFyZgC",
            "Publisher": "Springer, Cham"
        },
        {
            "Title": "QURSED: querying and reporting semistructured data",
            "Publication year": 2002,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/564691.564714",
            "Abstract": "QURSED enables the development of web-based query forms and reports (QFRs) that query and report semistructured XML data, ie, data that are characterized by nesting, irregularities and structural variance. The query aspects of a QFR are captured by its query set specification, which formally encodes multiple parameterized condition fragments and can describe large numbers of queries. The run-time component of QURSED produces XQuery-compliant queries by synthesizing fragments from the query set specification that have been activated during the interaction of the end-user with the QFR. The design-time component of QURSED, called QURSED Editor, semi-automates the development of the query set specification and its association with the visual components of the QFR by translating visual actions into appropriate query set specifications. We describe QURSED and illustrate how it accommodates the \u2026",
            "Abstract entirety": 0,
            "Author pub id": "oaM-d7QAAAAJ:zYLM7Y9cAGgC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Efficient Tracking of Mobile Data Items: Enabling Access to Mobile Data",
            "Publication year": 2008,
            "Publication url": "https://scholar.google.com/scholar?cluster=4578652301849261318&hl=en&oi=scholarr",
            "Abstract": "Wireless local-area networks are becoming increasingly popular on university campuses, in corporate environments and urban areas. This, along with the widespread deployment of mobile devices with advanced computational capabilities and large storage capacities, creates more opportunities for collaborative work in campus-like environments. Working together often means being able to access data that reside on one or more mobile devices, such as latest sales figures, customer contact data, product designs and so on. While offline full synchronization is an available option, accessing the data items where they reside has significant advantages. In such an environment, each mobile device is a peer, both a data server and a client for other peers. Mobility of peers means location changes for the data held by each peer, which creates the need for an efficient data items\u2019 tracking mechanism. We present the \u2026",
            "Abstract entirety": 0,
            "Author pub id": "oaM-d7QAAAAJ:hFOr9nPyWt4C",
            "Publisher": "technical report"
        },
        {
            "Title": "Monitoring the evolution of interests in the blogosphere",
            "Publication year": 2008,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/4498371/",
            "Abstract": "We describe blogTrust, an innovative modular and extensible prototype application for monitoring changes in the interests of blogosphere participants. We also propose a new approach for the analysis of weblog contents that is supported by blogTrust and can yield new insights on the analysis of the blogosphere by monitoring the convergence or dispersion of blogosphere interests. The proposed process classifies weblog posts in predefined categories, generates a feature vector for each weblog from the post classification results, clusters together blogs with similar topics/interests, and, via visualization techniques, enables the detection of interest convergence or divergence among bloggers over different time periods. BlogTrust uses established, robust data mining techniques to support every step of the process. The motivation for the work is a hypothesized strong connection between important (global or \"local\" \u2026",
            "Abstract entirety": 0,
            "Author pub id": "oaM-d7QAAAAJ:5nxA0vEk-isC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Querying and Updating XML with XML Schema constraints in an RDBMS",
            "Publication year": 2005,
            "Publication url": "https://www.researchgate.net/profile/Iraklis-Varlamis/publication/228722276_Querying_and_Updating_XML_with_XML_Schema_constraints_in_an_RDBMS/links/09e415075429ad26a9000000/Querying-and-Updating-XML-with-XML-Schema-constraints-in-an-RDBMS.pdf",
            "Abstract": "The increasing need of a variety of applications to store and process XML data has led to the development of systems and techniques for XML storage and querying. XML updating hasn\u2019t received a corresponding amount of attention. We discuss XPURS, a system of processing XPath queries and updates on XML Schema-compliant XML data. XPURS updates respect XML ordering and XML Schema typing constraints, and especially type inheritance and polymorphism. XPURS employs an innovative shredding scheme for storing XML data into a relational database management system. We report on preliminary performance measurements using the XBench benchmark.",
            "Abstract entirety": 1,
            "Author pub id": "oaM-d7QAAAAJ:TQgYirikUcIC",
            "Publisher": "\u03c4\u03b5\u03c7\u03bd\u03b9\u03ba\u03ae \u03b1\u03bd\u03b1\u03c6\u03bf\u03c1\u03ac (technical report)"
        },
        {
            "Title": "Graphical query interfaces for semistructured data: the QURSED system",
            "Publication year": 2005,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/1064340.1064344",
            "Abstract": "We describe the QURSED system for the declarative specification and automatic generation of Web-based query forms and reports (QFRs) for semistructured XML data. In QURSED, a QFR is formally described by its query set specification (QSS) which captures the complex query and reporting capabilities of the QFR and the associations of the query set specification with visual elements that implement these capabilities on a Web page. The design-time component of QURSED, called QURSED Editor, semi-automates the development of the query set specification and its association with visual elements by translating intuitive visual actions taken by a developer into appropriate specification fragments. The run-time component of QURSED produces XQuery statements by synthesizing fragments from the query set specification that have been activated during the interaction of the end-user with the QFR and renders \u2026",
            "Abstract entirety": 0,
            "Author pub id": "oaM-d7QAAAAJ:_FxGoFyzp5QC",
            "Publisher": "ACM"
        },
        {
            "Title": "What's Next in XML and Databases?",
            "Publication year": 2004,
            "Publication url": "https://scholar.google.com/scholar?cluster=10973037492075175276&hl=en&oi=scholarr",
            "Abstract": "Since the time XML became a W3C standard for document representation and exchange over the Web, many efforts have been devoted to the development of standards, methodologies, and tools for handling, storing, retrieving, and protecting XML documents. The purpose of this panel, held during the international EDBT'2004 workshop on\" database technologies for handling XML information on the Web\"[3], is to discuss the current status of the research in XML data management and to foresee new trends towards the XML-ization of database research.",
            "Abstract entirety": 1,
            "Author pub id": "oaM-d7QAAAAJ:iH-uZ7U-co4C",
            "Publisher": "Springer-Verlag New York Inc"
        },
        {
            "Title": "Materialized view selection for XQuery workloads",
            "Publication year": 2012,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/2213836.2213900",
            "Abstract": "The efficient processing of XQuery still poses significant challenges. A particularly effective technique to improve XQuery processing performance consists of using materialized views to answer queries. In this work, we consider the problem of choosing the best views to materialize within a given space budget in order to improve the performance of a query workload. The paper is the first to address the view selection problem for queries and views with value joins and multiple return nodes. The challenges we face stem from the expressive power and features of both the query and view languages and from the size of the search space of candidate views to materialize. While the general problem has prohibitive complexity, we propose and study a heuristic algorithm and demonstrate its superior performance compared to the state of the art.",
            "Abstract entirety": 1,
            "Author pub id": "oaM-d7QAAAAJ:blknAaTinKkC",
            "Publisher": "Unknown"
        },
        {
            "Title": "XPath on steroids: exploiting relational engines for XPath performance",
            "Publication year": 2007,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/1247480.1247517",
            "Abstract": "A lot of research has been conducted by the database community on methods and techniques for efficient XPath processing, with great success. Despite the progress made, significant opportunities for optimization of XPath still exist. One key to further improvements is to utilize more effectively existing facilities of relational RDBSes for the processing of XPath queries. After taking a comprehensive look at such facilities, we present techniques for XPath processing that work by identifying the best relational join algorithms, indices and file organization strategies for XPath queries. Our techniques both reduce the latency of the resulting SQL translations and guarantee their pipelined execution. We also propose a new technique for XML reconstruction from relations-mapped XML that\" splits the difference\" between schema-aware and schema-oblivious XML-to-relational mapping for a significant performance improvement \u2026",
            "Abstract entirety": 0,
            "Author pub id": "oaM-d7QAAAAJ:YsMSGLbcyi4C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Efficient physical operators for cost-based XPath execution",
            "Publication year": 2010,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/1739041.1739064",
            "Abstract": "The creation of a generic and modular query optimization and processing infrastructure can provide significant benefits to XML data management. Key pieces of such an infrastructure are the physical operators that are available to the execution engine, to turn queries into execution plans. Such operators, to be efficient, need to implement sophisticated algorithms for logical XPath or XQuery operations. Moreover, to enable a cost-based optimizer to choose among them correctly, it is also necessary to provide cost models for such operator implementations. In this paper we present two novel families of algorithms for XPath physical operators, called LookUp (LU) and Sort-Merge-based (SM), along with detailed cost models. Our algorithms have significantly better performance compared to existing techniques over any one of a variety of different XML storage systems that provide a set of common primitive access \u2026",
            "Abstract entirety": 0,
            "Author pub id": "oaM-d7QAAAAJ:mVmsd5A6BfQC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Efficient rewriting of XPath queries using query set specifications",
            "Publication year": 2009,
            "Publication url": "https://dl.acm.org/doi/abs/10.14778/1687627.1687662",
            "Abstract": "We study the problem of querying XML data sources that accept only a limited set of queries, such as sources accessible by Web services which can implement very large (potentially infinite) families of XPath queries. To compactly specify such families of queries we adopt the Query Set Specifications [14], a formalism close to context-free grammars.We say that query Q is expressible by the specification P if it is equivalent to some expansion of P. Q is supported by P if it has an equivalent rewriting using some finite set of P's expansions. We study the complexity of expressibility and support and identify large classes of XPath queries for which there are efficient (PTIME) algorithms. Our study considers both the case in which the XML nodes in the results of the queries lose their original identity and the one in which the source exposes persistent node ids.",
            "Abstract entirety": 1,
            "Author pub id": "oaM-d7QAAAAJ:kNdYIx-mwKoC",
            "Publisher": "VLDB Endowment"
        },
        {
            "Title": "On equivalence and rewriting of XPath queries using views under DTD constraints",
            "Publication year": 2011,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-642-23091-2_1",
            "Abstract": "It has long been recognized that query rewriting techniques are important tools for query optimization and semantic caching and are at the heart of data integration systems. In particular, the problem of rewriting queries using view definitions has received a lot of attention in these contexts. At the same time, the XPath language has become very popular for processing XML data, and there is much recent progress in semantic XPath optimization problems, such as XPath containment, and, more recently, XPath rewriting using views. In this paper we address the open problems of finding equivalent query rewritings using views for XPath queries and views that include the child, predicate and wildcard features (i.e., they are in XP(/, [], *)) under DTD constraints. In the process, we also develop novel containment tests for queries in XP(/,[],*) under DTD constraints.",
            "Abstract entirety": 1,
            "Author pub id": "oaM-d7QAAAAJ:M3NEmzRMIkIC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "Data Science with Linear Programming",
            "Publication year": 2017,
            "Publication url": "http://delbp.github.io/DeLBP-2017/papers/DeLBP-2017_paper_2CR.pdf",
            "Abstract": "The standard process of data science tasks is to prepare features inside a database, export them as a denormalized data frame and then apply machine learning algorithms. This process is not optimal for two reasons. First, it requires denormalization of the database that can convert a small data problem into a big data problem. The second problem is that it assumes that the machine learning algorithm is disentangled from the relational model of the problem. That seems to be a serious limitation since the relational model contains very valuable domain expertise. In this paper we explore the use of convex optimization and specifically linear programming as a data science tool that can express most of the common machine learning algorithms and at the same time it can be natively integrated inside a declarative database. We are using SolverBlox, a framework that accepts as an input Datalog code and feeds it into a linear programming solver. We demonstrate the expression of three common machine learning algorithms, Linear Regression, Factorization Machines and Spectral Clustering, and present use case scenarios where data processing and modelling of optimization problems can be done step by step inside the database.",
            "Abstract entirety": 1,
            "Author pub id": "oaM-d7QAAAAJ:OU6Ihb5iCvQC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Data integration in the human brain project",
            "Publication year": 2015,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-319-21843-4_3",
            "Abstract": "The Medical Informatics Platform of the Human Brain Project has the challenging task of organizing and presenting to its users a variety of data originating from different hospitals and hospital systems in a unified way, while protecting patients privacy as imposed by national legislation and institutional ethics. In this paper we view these challenges under the scope of data integration and analyze preliminary steps taken towards realizing the Medical Informatics Platform.",
            "Abstract entirety": 1,
            "Author pub id": "oaM-d7QAAAAJ:ldfaerwXgEUC",
            "Publisher": "Springer, Cham"
        },
        {
            "Title": "An analysis of peer-to-peer networks with altruistic peers",
            "Publication year": 2009,
            "Publication url": "https://link.springer.com/article/10.1007/s12083-008-0024-4",
            "Abstract": "We develop a new model of the interaction of rational peers in a Peer-to-Peer (P2P) network that has at its heart altruism, an intrinsic parameter reflecting peers\u2019 inherent willingness to contribute. Two different approaches for modelling altruistic behavior and its attendant benefit are introduced. With either approach, we use Game Theoretic analysis to calculate Nash equilibria and predict peer behavior in terms of individual contribution. We consider the cases of P2P networks of peers that (i) have homogeneous altruism levels or (ii) have heterogeneous altruism levels, but with known probability distributions. We find that, under the effects of altruism, a substantial fraction of peers will contribute when altruism levels are within certain intervals, even though no incentive mechanism is used. Our results corroborate empirical evidence of large P2P networks surviving or even flourishing without or with barely \u2026",
            "Abstract entirety": 0,
            "Author pub id": "oaM-d7QAAAAJ:M3ejUd6NZC8C",
            "Publisher": "Springer US"
        },
        {
            "Title": "08421 Working Group: Classification, Representation and Modeling.",
            "Publication year": 2008,
            "Publication url": "https://drops.dagstuhl.de/opus/frontdoor.php?source_opus=1941",
            "Abstract": "This report briefly summarizes the discussions carried out in the working group on classification, representation and modeling of uncertain data. The discussion was divided into two subgroups: the first subgroup studied how different representation and modeling alternatives currently proposed can fit in a bigger picture of theory and technology interaction, while the second subgroup focused on contrasting current system implementations and the reasons behind such diverse class of available prototypes. We summarize the findings of these two groups and the future steps suggested by group members.",
            "Abstract entirety": 1,
            "Author pub id": "oaM-d7QAAAAJ:3s1wT3WcHBgC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Architecture and implementation of an XQuery-based information integration platform",
            "Publication year": 2002,
            "Publication url": "https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.117.9373&rep=rep1&type=pdf#page=20",
            "Abstract": "An increasing number of business users and software applications need to process information that is accessible via multiple diverse information systems, such as database systems, file systems, legacy applications or web services. We describe the Enosys XML Integration Platform (EXIP), a commercial XQuery-based data integration software platform that provides a queryable integrated view of such information. We describe the platform architecture and describe what the main principles and challenges are for the query engine. In particular, we discuss the query engine architecture and the underlying semistructured algebra, which is tuned for enabling query plan optimizations.",
            "Abstract entirety": 1,
            "Author pub id": "oaM-d7QAAAAJ:Tyk-4Ss8FVUC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Rewriting minimisations for efficient ontology-based query answering",
            "Publication year": 2016,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/7814728/",
            "Abstract": "Computing a (Union of Conjunctive Queries - UCQ) rewriting R for an input query and ontology and evaluating it over the given dataset is a prominent approach to query answering over ontologies. However, R can be large and complex in structure hence additional techniques, like query subsumption and data constraints, need to be employed in order to minimise Rew and lead to an efficient evaluation. Although sound in theory, how to efficiently and effectively implement many of these techniques in practice could be challenging. For example, many systems do not implement query subsumption. In the current paper we present several practical techniques for UCQ rewriting minimisation. First, we present an optimised algorithm for eliminating redundant (w.r.t. subsumption) queries as well as a novel framework for rewriting minimisation using data constraints. Second, we show how these techniques can also be \u2026",
            "Abstract entirety": 0,
            "Author pub id": "oaM-d7QAAAAJ:pyW8ca7W8N0C",
            "Publisher": "IEEE"
        },
        {
            "Title": "View-based rewriting of XML queries",
            "Publication year": 2010,
            "Publication url": "https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.220.5770&rep=rep1&type=pdf",
            "Abstract": "AD/IM/VV (UCSD/INRIA/AUEB) View-based XML rewriting BDA Toulouse, October 2010 2/49",
            "Abstract entirety": 1,
            "Author pub id": "oaM-d7QAAAAJ:RGFaLdJalmkC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Meta-data management and quality control for the medical informatics platform",
            "Publication year": 2019,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/3331076.3331088",
            "Abstract": "The Medical Informatics Platform (MIP) of the Human Brain Project (HBP) is tasked with providing its users diverse high quality clinical data and tools for medical analysis, while complying with the national legislation about privacy and security. Data, which is provided by a large number of hospitals, tends to be heterogeneous and also has a constantly changing schema, due to hospitals' need to capture more information. In this paper we provide a look in the MIP's data ingestion pipeline and focus on steps taken by our team to properly integrate clinical data from heterogeneous sources while ensuring its quality throughout the processing pipeline. We have developed tools both for meta-data management and quality control.",
            "Abstract entirety": 1,
            "Author pub id": "oaM-d7QAAAAJ:p2g8aNsByqUC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Working Group: Classification, Representation and Modeling",
            "Publication year": 2009,
            "Publication url": "https://research.utwente.nl/files/31496989/Sarma2009working.pdf",
            "Abstract": "This report briefly summarizes the discussions carried out in the working group on classification, representation and modeling of uncertain data. The discussion was divided into two subgroups: the first subgroup studied how different representation and modeling alternatives currently proposed can fit in a bigger picture of theory and technology interaction, while the second subgroup focused on contrasting current system implementations and the reasons behind such diverse class of available prototypes. We summarize the findings of these two groups and the future steps suggested by group members.",
            "Abstract entirety": 1,
            "Author pub id": "oaM-d7QAAAAJ:bFI3QPDXJZMC",
            "Publisher": "Dagstuhl"
        },
        {
            "Title": "PaloPro: a platform for knowledge extraction from big social data and the news",
            "Publication year": 2017,
            "Publication url": "https://www.inderscienceonline.com/doi/abs/10.1504/IJBDI.2017.081185",
            "Abstract": "PaloPro is a platform that aggregates textual content from social media and news sites in different languages, analyses them using a series of text mining algorithms and provides advanced analytics to journalists and social media marketers. The platform capitalises on the abundance of social media sources and the information they provide for persons, products and events. In order to handle huge amounts of multilingual data that are collected continuously, we have adopted language independent techniques at all levels and from an engineering point of view, we have designed a system that takes advantage of parallel distributed computing technologies and cloud infrastructure. Different systems handle data aggregation, data processing and knowledge extraction and others deal with the integration and visualisation of knowledge. In this paper, we focus on two important text mining tasks, named entity recognition \u2026",
            "Abstract entirety": 0,
            "Author pub id": "oaM-d7QAAAAJ:a0OBvERweLwC",
            "Publisher": "Inderscience Publishers (IEL)"
        },
        {
            "Title": "Scheduling MapReduce jobs on identical and unrelated processors",
            "Publication year": 2020,
            "Publication url": "https://link.springer.com/article/10.1007/s00224-019-09956-6",
            "Abstract": "We consider non-preemptive scheduling of MapReduce jobs consisting of multiple map-reduce rounds so as to minimize their average weighted completion time on identical or unrelated processor environments. For identical processors, we present LP-based O(1)-approximation algorithms, while for unrelated processors the approximation ratio naturally depends on the maximum number of rounds of any job (which is a small constant in practice). For the single-round case, we substantially improve on previously best known approximation ratios, while also we introduce into our model the crucial cost of the data shuffle phase, i.e., the cost for the transmission of intermediate data from Map to Reduce tasks. Finally, we evaluate our algorithms via simulations in the general case of unrelated processors, comparing them with a lower bound on the optimal cost of the problem as well as with a fast algorithm which \u2026",
            "Abstract entirety": 0,
            "Author pub id": "oaM-d7QAAAAJ:Tiz5es2fbqcC",
            "Publisher": "Springer US"
        },
        {
            "Title": "Outlier-aware data aggregation in sensor networks",
            "Publication year": 2008,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/4497585/",
            "Abstract": "In this paper we discuss a robust aggregation framework that can detect spurious measurements and refrain from incorporating them in the computed aggregate values. Our framework can consider different definitions of an outlier node, based on a specified minimum support. Our experimental evaluation demonstrates the benefits of our approach.",
            "Abstract entirety": 1,
            "Author pub id": "oaM-d7QAAAAJ:KlAtU1dfN6UC",
            "Publisher": "IEEE"
        },
        {
            "Title": "A framework and positive results for IAR-answering",
            "Publication year": 2018,
            "Publication url": "https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/viewPaper/16628",
            "Abstract": "Inconsistency-tolerant semantics, like the IAR semantics, have been proposed as means to compute meaningful query answers over inconsistent Description Logic (DL) ontologies. So far query answering under the IAR semantics (IAR-answering) is known to be tractable only for arguably weak DLs like DL-Lite and the quite restricted EL\u22a5 nr fragment of E L\u22a5. Towards providing a systematic study of IAR-answering, in the current paper we first present a general framework/algorithm for IAR-answering which applies to arbitrary DLs but need not terminate. Nevertheless, this framework allows us to develop a sufficient condition for tractability of IAR-answering and hence of termination of our algorithm. We then show that this condition is always satisfied by the arguably expressive DL DL-Lite bool, providing the first positive result for IAR-answering over a non-Horn-DL. In addition, recent results show that this condition usually holds for real-world ontologies and techniques and algorithms for checking it in practice have also been studied recently; thus, overall our results are highly relevant in practice. Finally, we have provided a prototype implementation and a preliminary evaluation obtaining encouraging results.",
            "Abstract entirety": 1,
            "Author pub id": "oaM-d7QAAAAJ:nb7KW1ujOQ8C",
            "Publisher": "Unknown"
        },
        {
            "Title": "XML query forms (XQForms) declarative specification of XML query interfaces",
            "Publication year": 2001,
            "Publication url": "https://dl.acm.org/doi/pdf/10.1145/371920.372170",
            "Abstract": "XQForms is the first generator of Web-based query forms and reports for XML data. XQForms takes as input (i) XML Schemas that model the data to be queried and presented,(ii) declarative specifications, called annotations, of the logic of the query forms and reports that will be generated, and (iii) a set of template presentation libraries. The output is a set of query forms and reports that provide automated query construction and report formatting in order for the end users to query and browse the underlying XML data. Thus XQForms separates content (given by the XML Schema of the data), query form logic (specified by the annotations) and presentation of the forms and reports. The system architecture is modular and consists of four main components:(a) a collection of query form controls that incorporate query capabilities and allow parameter passing from the end users via the form page. A set of query form controls \u2026",
            "Abstract entirety": 0,
            "Author pub id": "oaM-d7QAAAAJ:Y0pCki6q_DkC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Sentiment extraction from tweets: multilingual challenges",
            "Publication year": 2015,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-319-22729-0_11",
            "Abstract": "Every day users of social networks and microblogging services share their point of view about products, companies, movies and their emotions on a variety of topics. As social networks and microblogging services become more popular, the need to mine and analyze their content grows. We study the task of sentiment analysis in the well-known social network Twitter (                     https://twitter.com/                                        ). We present a case study on tweets written in Greek and propose an effective method that categorizes Greek tweets as positive, negative and neutral according to their sentiment. We validate our method\u2019s effectiveness on both Greek and English to check its robustness on multilingual challenges, and present the first multilingual comparative study with three pre-existing state of the art techniques for Twitter sentiment extraction on English tweets. Last but not least, we examine the importance \u2026",
            "Abstract entirety": 0,
            "Author pub id": "oaM-d7QAAAAJ:M05iB0D1s5AC",
            "Publisher": "Springer, Cham"
        },
        {
            "Title": "Adaptive join operators for result rate optimization on streaming inputs",
            "Publication year": 2010,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/5453375/",
            "Abstract": "Adaptive join algorithms have recently attracted a lot of attention in emerging applications where data are provided by autonomous data sources through heterogeneous network environments. Their main advantage over traditional join techniques is that they can start producing join results as soon as the first input tuples are available, thus, improving pipelining by smoothing join result production and by masking source or network delays. In this paper, we first propose Double Index NEsted-loops Reactive join (DINER), a new adaptive two-way join algorithm for result rate maximization. DINER combines two key elements: an intuitive flushing policy that aims to increase the productivity of in-memory tuples in producing results during the online phase of the join, and a novel reentrant join technique that allows the algorithm to rapidly switch between processing in-memory and disk-resident tuples, thus, better exploiting \u2026",
            "Abstract entirety": 0,
            "Author pub id": "oaM-d7QAAAAJ:dhFuZR0502QC",
            "Publisher": "IEEE"
        },
        {
            "Title": "System for querying markup language data stored in a relational database according to markup language schema",
            "Publication year": 2006,
            "Publication url": "https://patents.google.com/patent/US7028028B1/en",
            "Abstract": "A data processing system receives data in a first format utilizing a markup language such as eXtensible Markup Language (XML), and stores the data in a different, relational database format involving multiple tables and columns, etc. The system translates subsequent query input expressed in the first format to prepare representative query instructions in SQL or another query language compatible with relational data, and thereafter executes the prepared instructions upon data in the relational database. The system outputs results of the query in format dictated by the query input.",
            "Abstract entirety": 1,
            "Author pub id": "oaM-d7QAAAAJ:WF5omc3nYNoC",
            "Publisher": "Unknown"
        },
        {
            "Title": "XML queries and algebra in the Enosys integration platform",
            "Publication year": 2003,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S0169023X02001416",
            "Abstract": "We describe the Enosys XML integration platform, focusing on the query language, algebra, and architecture of its query processor. The platform enables the development of eBusiness applications in customer relationship management, e-commerce, supply chain management, and decision support. These applications often require that data be integrated dynamically from multiple information sources. The Enosys platform allows one to build (virtual and/or materialized) integrated XML views of multiple sources, using XML queries as view definitions. During run-time, the application issues XML queries against the views. Queries and views are translated into the XCQL algebra and are combined into a single algebra expression/plan. Query plan composition and query plan decomposition challenges are faced in this process. Finally, the query processor lazily evaluates the result, using an appropriate adaptation of \u2026",
            "Abstract entirety": 0,
            "Author pub id": "oaM-d7QAAAAJ:W7OEmFMy1HYC",
            "Publisher": "North-Holland"
        },
        {
            "Title": "Semi-streamed index join for near-real time execution of ETL transformations",
            "Publication year": 2011,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/5767906/",
            "Abstract": "Active data warehouses have emerged as a new business intelligence paradigm where data in the integrated repository is refreshed in near real-time. This shift of practices achieves higher consistency between the stored information and the latest updates, which in turn influences crucially the output of decision making processes. In this paper we focus on the changes required in the implementation of Extract Transform Load (ETL) operations which now need to be executed in an online fashion. In particular, the ETL transformations frequently include the join between an incoming stream of updates and a disk-resident table of historical data or metadata. In this context we propose a novel Semi-Streaming Index Join (SSIJ) algorithm that maximizes the throughput of the join by buffering stream tuples and then judiciously selecting how to best amortize expensive disk seeks for blocks of the stored relation among a \u2026",
            "Abstract entirety": 0,
            "Author pub id": "oaM-d7QAAAAJ:maZDTaKrznsC",
            "Publisher": "IEEE"
        },
        {
            "Title": "What\u2019s Next in XML and Databases?",
            "Publication year": 2004,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-540-30192-9_31",
            "Abstract": "Since the time XML became a W3C standard for document representation and exchange over the Web, many efforts have been devoted to the development of standards, methodologies, and tools for handling, storing, retrieving, and protecting XML documents. The purpose of this panel, held during the international EDBT\u20192004 workshop on \u201cdatabase technologies for handling XML information on the Web\u201d [3], is to discuss the current status of the research in XML data management and to foresee new trends towards the XML-ization of database research.",
            "Abstract entirety": 1,
            "Author pub id": "oaM-d7QAAAAJ:QIV2ME_5wuYC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "Modelling real p2p networks: The effect of altruism",
            "Publication year": 2007,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/4343460/",
            "Abstract": "We develop a model of the interaction of rational peers in an incentive-free peer-to-peer (P2P) network and use game theoretic analysis to derive results about peer and network behavior. We calculate and discuss Nash equilibria and predict peer behavior in terms of individual contribution. At the heart of our model is altruism, an intrinsic parameter reflecting peers inherent willingness to contribute. Two different approaches for modelling altruistic behavior and its attendant benefit are introduced and discussed. We consider the cases of P2P networks of peers that (i) have homogeneous altruism levels or (ii) have heterogeneous altruism levels, but with known probability distributions. We find that, under the effects of altruism, a substantial fraction of peers will contribute when altruism levels are within certain intervals, even though no incentive mechanism is used. Our results corroborate empirical evidence of large \u2026",
            "Abstract entirety": 0,
            "Author pub id": "oaM-d7QAAAAJ:roLk4NBRz8UC",
            "Publisher": "IEEE"
        },
        {
            "Title": "A query optimization assistant for XPath",
            "Publication year": 2011,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/1951365.1951438",
            "Abstract": "We demonstrate a generic and extensible cost-based optimization and execution system for XPath queries, named GeCOEX, using a comprehensive suite of query analyzing and administrative tools, named QuOAX. GeCOEX supports many different physical operator implementations and XML storage engines and is agnostic to the underlying physical data model. Its optimizer is the first generic cost-based optimizer for XPath queries that always picks the cheapest estimated plan, among a very large number of possible plans, for a wide range of XPath queries and different datasets in a very small fraction of the time required for efficient execution. The QuOAX suite provides administration tools that allow the user to add new--or deactivate already deployed--physical operator implementations, physical operator cost models and rewriting rules and also to make use of different XML storage and XML statistics \u2026",
            "Abstract entirety": 0,
            "Author pub id": "oaM-d7QAAAAJ:4JMBOYKVnBMC",
            "Publisher": "Unknown"
        },
        {
            "Title": "DAIMON: data integration for a mobile network",
            "Publication year": 2005,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/1065870.1065880",
            "Abstract": "We describe the DAIMON system for data integration of nomadic data. DAIMON is based on an extension of the mediator-wrapper architecture, where each node is a mediator of its own information and information from its neighbouring nodes. We describe the overall architecture, including our lightweight peer location and neighbourhood identification scheme, cache management strategy and query processing and execution architecture, and show how it addresses the challenges of the wireless environment. We introduce connectivity profiles for mobile peers to capture their different connectivity, availability and accessibility patterns, and we describe how they can be used to guide query processing and optimization decisions by the mediator module of the mobile peers. The implementation of the DAIMON system is also discussed.",
            "Abstract entirety": 1,
            "Author pub id": "oaM-d7QAAAAJ:Zph67rFs4hoC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Inconsistency resolution in online databases",
            "Publication year": 2010,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/5447743/",
            "Abstract": "Shared online databases allow community members to collaboratively maintain knowledge. Collaborative editing though inevitably leads to inconsistencies as different members enter erroneous data or conflicting opinions. Ideally community members should be able to see and resolve these inconsistencies in a collaborative fashion. However most current online databases do not support inconsistency resolution. Instead they try to by-pass the problem by either ignoring inconsistencies and treating data as if they were not conflicting or by requiring inconsistencies to be resolved outside the system. To address this limitation, we propose Ricolla; an online database system that, by treating inconsistencies as first-class citizens, supports a natural workflow for the management of conflicting data. The system captures inconsistencies (so that community members can easily inspect them) and remains fully functional in \u2026",
            "Abstract entirety": 0,
            "Author pub id": "oaM-d7QAAAAJ:-f6ydRqryjwC",
            "Publisher": "IEEE"
        },
        {
            "Title": "In-network approximate computation of outliers with quality guarantees",
            "Publication year": 2013,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S0306437911001116",
            "Abstract": "Wireless sensor networks are becoming increasingly popular for a variety of applications. Users are frequently faced with the surprising discovery that readings produced by the sensing elements of their motes are often contaminated with outliers. Outlier readings can severely affect applications that rely on timely and reliable sensory data in order to provide the desired functionality. As a consequence, there is a recent trend to explore how techniques that identify outlier values based on their similarity to other readings in the network can be applied to sensory data cleaning. Unfortunately, most of these approaches incur an overwhelming communication overhead, which limits their practicality. In this paper we introduce an in-network outlier detection framework, based on locality sensitive hashing, extended with a novel boosting process as well as efficient load balancing and comparison pruning mechanisms. Our \u2026",
            "Abstract entirety": 0,
            "Author pub id": "oaM-d7QAAAAJ:IWHjjKOFINEC",
            "Publisher": "Pergamon"
        },
        {
            "Title": "A framework for clustering and classification of big data using spark",
            "Publication year": 2016,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-319-48472-3_20",
            "Abstract": "Nowadays, massive data sets are generated in many modern applications ranging from economics to bioinformatics, and from social networks to scientific databases. Typically, such data need to be processed by machine learning algorithms, which entails high processing cost and usually requires the execution of iterative algorithms. Spark has been recently proposed as a framework that supports iterative algorithms over massive data efficiently. In this paper, we design a framework for clustering and classification of big data suitable for Spark. Our framework supports different restrictions on the data exchange model that are applicable in different settings. We integrate k-means and ID3 algorithms in our framework, leading to interesting variants of our algorithms that apply to the different restrictions on the data exchange model. We implemented our algorithms over the open-source computing framework \u2026",
            "Abstract entirety": 0,
            "Author pub id": "oaM-d7QAAAAJ:yD5IFk8b50cC",
            "Publisher": "Springer, Cham"
        },
        {
            "Title": "Reconfigurable query generation system for web browsers",
            "Publication year": 2007,
            "Publication url": "https://patents.google.com/patent/US7203678B1/en",
            "Abstract": "A reconfigurable web-browser compatible data query system. The invention provides an XML platform enabling web-based forms that query data modeled by data schemas. This platform comprises a collection of query form controls, an annotation scheme for attaching these controls to the data schema, a compiler for creating a web-browser-compatible representation of the query form, and a run-time engine for constructing queries against the data and rendering query results.",
            "Abstract entirety": 1,
            "Author pub id": "oaM-d7QAAAAJ:YOwf2qJgpHMC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Building XML query forms and reports with XQForms",
            "Publication year": 2002,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S1389128602002189",
            "Abstract": "XQForms is the first generator of Web-based query forms and reports for XML data. XQForms takes inputs (i) an XML Schema that models the source data to be queried and presented, (ii) a declarative specification, called XQForm annotation, of the query forms and reports that will be generated, and (iii) a set of template presentation libraries. The output is a set of query form and report pages that provide automated query construction and report formatting so that the end users can query and browse the underlying XML data. XQForms separates content (given by the XML Schema of the source data), query form semantics (specified by the annotations) and presentation of the pages (provided by the template library). The system architecture is modular and consists of four main components: (a) a collection of query controls that generate query fragments based on the values that the end user submits via the query form \u2026",
            "Abstract entirety": 0,
            "Author pub id": "oaM-d7QAAAAJ:8k81kl-MbHgC",
            "Publisher": "Elsevier"
        },
        {
            "Title": "sql4ml A declarative end-to-end workflow for machine learning",
            "Publication year": 2019,
            "Publication url": "https://arxiv.org/abs/1907.12415",
            "Abstract": "We present sql4ml, a system for expressing supervised machine learning (ML) models in SQL and automatically training them in TensorFlow. The primary motivation for this work stems from the observation that in many data science tasks there is a back-and-forth between a relational database that stores the data and a machine learning framework. Data preprocessing and feature engineering typically happen in a database, whereas learning is usually executed in separate ML libraries. This fragmented workflow requires from the users to juggle between different programming paradigms and software systems. With sql4ml the user can express both feature engineering and ML algorithms in SQL, while the system translates this code to an appropriate representation for training inside a machine learning framework. We describe our translation method, present experimental results from applying it on three well-known ML algorithms and discuss the usability benefits from concentrating the entire workflow on the database side.",
            "Abstract entirety": 1,
            "Author pub id": "oaM-d7QAAAAJ:u9iWguZQMMsC",
            "Publisher": "Unknown"
        },
        {
            "Title": "08421 Working Group: Classification, Representation and Modeling",
            "Publication year": 2009,
            "Publication url": "https://drops.dagstuhl.de/opus/volltexte/2009/1941/",
            "Abstract": "This report briefly summarizes the discussions carried out in the working group on classification, representation and modeling of uncertain data. The discussion was divided into two subgroups: the first subgroup studied how different representation and modeling alternatives currently proposed can fit in a bigger picture of theory and technology interaction, while the second subgroup focused on contrasting current system implementations and the reasons behind such diverse class of available prototypes. We summarize the findings of these two groups and the future steps suggested by group members.",
            "Abstract entirety": 1,
            "Author pub id": "oaM-d7QAAAAJ:rO6llkc54NcC",
            "Publisher": "Schloss Dagstuhl-Leibniz-Zentrum f\u00fcr Informatik"
        },
        {
            "Title": "Towards an Analytics Query Engine.",
            "Publication year": 2016,
            "Publication url": "http://ceur-ws.org/Vol-1558/paper44.pdf",
            "Abstract": "This vision paper presents new challenges and opportunities in the area of distributed data analytics, at the core of which are data mining and machine learning. At first, we provide an overview of the current state of the art in the area and then analyse two aspects of data analytics systems, semantics and optimization. We argue that these aspects will emerge as important issues for the data management community in the next years and propose promising research directions for solving them.",
            "Abstract entirety": 1,
            "Author pub id": "oaM-d7QAAAAJ:u_35RYKgDlwC",
            "Publisher": "Unknown"
        },
        {
            "Title": "XML tuple algebra",
            "Publication year": 2009,
            "Publication url": "https://hal.inria.fr/inria-00431395/",
            "Abstract": "XML data management requires an algebraic approach. In this work, we describe a unified algebraic approach for modeling computations described by XML queries expressed in an specific, expressive XQuery subset.",
            "Abstract entirety": 1,
            "Author pub id": "oaM-d7QAAAAJ:aqlVkmm33-oC",
            "Publisher": "Springer"
        },
        {
            "Title": "Query rewriting for DL ontologies under the ICAR semantics",
            "Publication year": 2019,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-030-31095-0_10",
            "Abstract": " In the current paper we propose a general framework for answering queries over inconsistent DL knowledge bases. The proposed framework considers the ICAR semantics and is based on a rewriting algorithm that can be applied over arbitrary DLs. Since the problem of ICAR-answering is known to be intractable for DLs other than DL-Lite, our algorithm may not terminate. However, we were able to describe sufficient termination conditions and to show that they are always satisfied for instance queries and TBoxes expressed in the semi-acyclic- as well as in DL-Lite. Interestingly, recent results on UCQ-rewritability and existing techniques can be used within the proposed framework, to check if the conditions are satisfied for a given query and ontology expressed in a DL for which the problem is in general intractable.",
            "Abstract entirety": 1,
            "Author pub id": "oaM-d7QAAAAJ:XiSMed-E-HIC",
            "Publisher": "Springer, Cham"
        },
        {
            "Title": "Another outlier bites the dust: Computing meaningful aggregates in sensor networks",
            "Publication year": 2009,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/4812471/",
            "Abstract": "Recent work has demonstrated that readings provided by commodity sensor nodes are often of poor quality. In order to provide a valuable sensory infrastructure for monitoring applications, we first need to devise techniques that can withstand \"dirty\" and unreliable data during query processing. In this paper we present a novel aggregation framework that detects suspicious measurements by outlier nodes and refrains from incorporating such measurements in the computed aggregate values. We consider different definitions of an outlier node, based on the notion of a user-specified minimum support, and discuss techniques for properly routing messages in the networkin order to reduce the bandwidth consumption and the energy drain during the query evaluation. In our experiments using real and synthetic traces we demonstrate that: (i) a straightforward evaluation of a user aggregate query leads to practically \u2026",
            "Abstract entirety": 0,
            "Author pub id": "oaM-d7QAAAAJ:LkGwnXOMwfcC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Answering Queries Using Views.",
            "Publication year": 2009,
            "Publication url": "https://scholar.google.com/scholar?cluster=8434797556430315570&hl=en&oi=scholarr",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "oaM-d7QAAAAJ:vV6vV6tmYwMC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Reconfigurable query generation system for web browsers",
            "Publication year": 2010,
            "Publication url": "https://patents.google.com/patent/US7860877B2/en",
            "Abstract": "A reconfigurable web-browser compatible data query system. The invention provides an XML platform enabling web-based forms that query data modeled by data schemas. This platform comprises a collection of query form controls, an annotation scheme for attaching these controls to the data schema, a compiler for creating a web-browser-compatible representation of the query form, and a run-time engine for constructing queries against the data and rendering query results.",
            "Abstract entirety": 1,
            "Author pub id": "oaM-d7QAAAAJ:HDshCWvjkbEC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Two-phase schema matching in real world relational databases",
            "Publication year": 2008,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/4498334/",
            "Abstract": "We propose a new approach to the problem of schema matching in relational databases that merges the hybrid and composite approach of combining multiple individual matching techniques. In particular, we propose assigning individual matchers to two categories, \"strong\" matchers that provide a priori higher quality matches, and \"weak\" matchers that may be more sensitive to the inputs and are less reliable but can still help generate some matches. Matching is correspondingly done in two phases, with strong \"matches\" being produced by strong matchers being combined using a simple voting combiner, and weak matchers providing additional evidence for attributes left unmatched (again using a voting combiner). We observe that, while many recent advances in schema matching (Madhavan et al., 2005) use composite schema matching and rely on the existence of training schemas to train combiners, in many \u2026",
            "Abstract entirety": 0,
            "Author pub id": "oaM-d7QAAAAJ:UebtZRa9Y70C",
            "Publisher": "IEEE"
        },
        {
            "Title": "The Enosys Markets data integration platform: lessons from the trenches",
            "Publication year": 2001,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/502585.502681",
            "Abstract": "Enosys Markets offers a state-of-the-art data integration software platform to support the development of the next generation of eBusiness applications that deliver value by providing new levels of function for customer relationship management, e-commerce, supply chain management, and decision support. These applications require that data be integrated from information sources that exist both within and across organizational boundaries. The Enosys Markets data integration architecture and product family provides a complete end-to-end XML-based solution for integrating and querying distributed information sources. It incorporates advanced research into XML and database technology. We present the product architecture and components, discuss the key technical challenges, and outline the technical concepts and innovations employed in the Enosys platform.",
            "Abstract entirety": 1,
            "Author pub id": "oaM-d7QAAAAJ:ufrVoPGSRksC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Enabling data integration using mipmap",
            "Publication year": 2017,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-319-69751-2_9",
            "Abstract": "In previous work we have analysed the infrastructure of the Human Brain Project Medical Informatics Platform focusing on the challenges related to dataintegration based on a visual data exchange tool, called MIPMap. In this paper we present new MIPMap features that enhance the integration process and data access.",
            "Abstract entirety": 1,
            "Author pub id": "oaM-d7QAAAAJ:b0M2c_1WBrUC",
            "Publisher": "Springer, Cham"
        },
        {
            "Title": "Generating Query Forms and Reports for Semistructured Data: The QURSED Editor",
            "Publication year": 2003,
            "Publication url": "https://www.academia.edu/download/1405365/l2804docg1m7305.pdf",
            "Abstract": "The wide adoption of semistructured XML databases requires the existence of systems for the generation and execution of web-based interactive database query forms and reports. Such systems are most effective when they allow the construction of the query forms and reports without programming, via the use of intuitive graphical tools. We describe the architecture of the QURSED system for the declarative specification and automatic generation of web-based query forms and reports (QFRs) for semistructured XML data. We then focus on the QURSED Editor, a powerful GUI tool for the generation of the declarative specifications of QFRs. We describe the Editor's architecture and present the techniques and heuristics the Editor employs for translating visual designer input into meaningful specifications of query forms and reports. An on-line demonstration of the system is available at http://www. db. ucsd. edu/qursed",
            "Abstract entirety": 1,
            "Author pub id": "oaM-d7QAAAAJ:9ZlFYXVOiuMC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Robust management of outliers in sensor network aggregate queries",
            "Publication year": 2007,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/1254850.1254854",
            "Abstract": "Sensor networks are increasingly applied for monitoring diverse environments and applications. Due to their unsupervised nature of operation and inexpensive hardware used, sensor nodes may furnish readings of rather poor quality. We thus need to devise techniques that can withstand\" dirty\" data during query processing. In this paper we introduce a robust aggregation framework that can detect and isolate spurious measurements from computed aggregate values. Such readings are not injected in the reported aggregate, in order not to obscure the outcome, but are still maintained and returned to the user/application, which may investigate them further and take appropriate decisions. In addition, our framework provides a form of positive feedback to the user by enhancing the result with a set of nodes that contain the most characteristic values out of those included in the aggregation process. We perform an \u2026",
            "Abstract entirety": 0,
            "Author pub id": "oaM-d7QAAAAJ:Se3iqnhoufwC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Querying Expressive DL Ontologies under the ICAR Semantics.",
            "Publication year": 2018,
            "Publication url": "http://ceur-ws.org/Vol-2211/paper-35.pdf",
            "Abstract": "Inconsistency-tolerant semantics, like the ICAR semantics, have been proposed to perform query answering over inconsistent DL knowledge bases. In the current paper we propose a general framework for ICAR-answering over arbitary Horn-DLs that is based on rewriting. We describe conditions for termination of our rewriting algorithm and show that existing techniques and results on UCQ-rewritability can be used to check if they are satisfied for a given input ontology and query.",
            "Abstract entirety": 1,
            "Author pub id": "oaM-d7QAAAAJ:P5F9QuxV20EC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Efficient Physical Operators for a cost-based XPath Execution Engine",
            "Publication year": 2010,
            "Publication url": "https://www.academia.edu/download/3243751/novOp.pdf",
            "Abstract": "The creation of a generic and modular query optimization and processing infrastructure can provide significant benefits to XML data management. Key pieces of such an infrastructure are the physical operators that are available to the execution engine, to turn queries into execution plans. Such operators, to be efficient, need to implement sophisticated algorithms for logical XPath or XQuery operations. Moreover, to enable a cost-based optimizer to choose among them correctly, it is also necessary to provide cost models for such operator implementations. In this paper we present two novel families of algorithms for XPath physical operators, called LookUp and Sort-Merge-based (SM), along with detailed cost models. Our algorithms have significantly better performance compared to existing techniques over any one of a variety of different XML storage systems that provide a set of common primitive access methods. To substantiate the robustness and efficiency of our physical operators, we evaluate their individual performance over four different XML storage engines against operators that implement existing XPath processing techniques. We also demonstrate the performance gains for twig processing of using plans consisting of our operators compared to a state of the art holistic technique, specifically Twig2Stack. Additionally, we evaluate the precision of our cost models, and we conduct an analysis of the sensitivity of our algorithms and cost models to a variety of parameters.",
            "Abstract entirety": 1,
            "Author pub id": "oaM-d7QAAAAJ:YFjsv_pBGBYC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Interesting Problems in Semantic Integration and Interoperability",
            "Publication year": 2005,
            "Publication url": "https://drops.dagstuhl.de/volltexte/2005/54/pdf/04391.VassalosVasilis2.ExtAbstract.54.pdf",
            "Abstract": "We report on the issues discussed at the breakout session held at the Dagstuhl Seminar on Semantic Interoperability and Integration on September 23, 2004.",
            "Abstract entirety": 1,
            "Author pub id": "oaM-d7QAAAAJ:7PzlFSSx8tAC",
            "Publisher": "Schloss Dagstuhl-Leibniz-Zentrum f\u00fcr Informatik"
        },
        {
            "Title": "Improving the efficiency of XPath execution on relational systems",
            "Publication year": 2006,
            "Publication url": "https://link.springer.com/chapter/10.1007/11687238_35",
            "Abstract": "This work describes a method for processing XPath on a relational back-end that significantly limits the number of SQL joins required, takes advantage of the strengths of modern SQL query processors, exploits XML schema information and has low implementation complexity. The method is based on the splitting of XPath expressions into Primary Path Fragments (PPFs) and their subsequent combination using an efficient structural join method, and is applicable to all XPath axes. A detailed description of the method is followed by an experimental study that shows our technique yields significant efficiency improvements over other XPath processing techniques and systems.",
            "Abstract entirety": 1,
            "Author pub id": "oaM-d7QAAAAJ:hqOjcs7Dif8C",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "of Proceedings: Current trends in database technology, EDBT 2004 Workshops: EDBT 2004 Workshops PhD, DataX, PIM, P2P&DB, and ClustWeb",
            "Publication year": 2004,
            "Publication url": "https://scholar.google.com/scholar?cluster=14361448818299207591&hl=en&oi=scholarr",
            "Abstract": "While there are many proposals for path indexes on XML documents, none of them is perfectly suited for indexing large-scale collections of interlinked XML documents. Existing strategies lack support for intra-or inter-document links, require large amounts of time to build or space to store the index, or cannot efficiently answer connection queries. This paper presents the {\\em FliX} framework for connection indexing that supports large, heterogeneous document collections with many links, using the existing path indexes as building blocks. We introduce some example configurations of the framework that are appropriate for many important application scenarios. Experiments show the feasibility of our approach.",
            "Abstract entirety": 1,
            "Author pub id": "oaM-d7QAAAAJ:vRqMK49ujn8C",
            "Publisher": "Springer"
        },
        {
            "Title": "Two phase user driven schema matching",
            "Publication year": 2015,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-319-23135-8_4",
            "Abstract": "In recent years it has become apparent that schema matching is a labor intensive process that is very costly in resources; this has led to the development of various automated tools to substitute the human experts involved in it. To this end we propose two new ideas. The first is the separation of matching techniques into strong and weak ones, in what we call two phase schema matching. The second is using information a human expert can provide to the system during the process of schema matching, that is used to determine how to combine the various matching techniques. A system encompassing both our ideas is easily tunable and allows the human expert to become part of the matching process and help the system choose the best techniques to use. In extensive experiments we demonstrate that this approach is better than contemporary state of the art systems in relational databases. We also \u2026",
            "Abstract entirety": 0,
            "Author pub id": "oaM-d7QAAAAJ:HoB7MX3m0LUC",
            "Publisher": "Springer, Cham"
        },
        {
            "Title": "Non-asymptotic performance bounds for downlink MU-MIMO scheduling",
            "Publication year": 2016,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/7429066/",
            "Abstract": "We consider the user selection downlink MU-MIMO scheduling problem in the practical case where there are more users than transmit antennas. First, we deduce a number of structural properties for the sum data rate maximization function under the reduced-complexity suboptimal approaches of zeroforcing dirty-paper (ZF-DP) and zero-forcing beamforming (ZFBF) precoding. Next, we take advantage of the algorithmic literature proposed in the context of combinatorial auctions when bidders have subadditive valuations and propose a novel, fast, greedy approach with very low computational complexity. Then, we establish that both the proposed greedy algorithm and a previously proposed algorithm, which iteratively augments the scheduled user set, attain a M-approximation factor for both ZF-BF and ZF-DP precodings, where M is the number of antennas. To the best of our knowledge, this is the first time that non \u2026",
            "Abstract entirety": 0,
            "Author pub id": "oaM-d7QAAAAJ:ZHo1McVdvXMC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Score-consistent algebraic optimization of full-text search queries with graft",
            "Publication year": 2011,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/1989323.1989404",
            "Abstract": "We address two open problems involving algebraic execution of full-text search queries. First, we show how to correctly apply traditional database rewrite optimizations to full-text algebra plans with integrated scoring, and explain why existing techniques fail. Second, we show how our techniques are applied in a generic scoring framework that supports a wide class of scoring algorithms, including algorithms seen in the literature and user-defined scoring.",
            "Abstract entirety": 1,
            "Author pub id": "oaM-d7QAAAAJ:_Qo2XoVZTnwC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Efficient XQuery rewriting using multiple views",
            "Publication year": 2011,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/5767915/",
            "Abstract": "We consider the problem of rewriting XQuery queries using multiple materialized XQuery views. The XQuery dialect we use to express views and queries corresponds to tree patterns (returning data from several nodes, at different granularities, ranging from node identifiers to full XML subtrees) with value joins. We provide correct and complete algorithms for finding minimal rewritings, in which no view is redundant. Our work extends the state of the art by considering more flexible views than the mostly XPath 1.0 dialects previously considered, and more powerful rewritings. We implemented our algorithms and assess their performance through a set of experiments.",
            "Abstract entirety": 1,
            "Author pub id": "oaM-d7QAAAAJ:qxL8FJ1GzNcC",
            "Publisher": "IEEE"
        },
        {
            "Title": "XML storage",
            "Publication year": 2009,
            "Publication url": "https://hal.inria.fr/inria-00433434/",
            "Abstract": "XML documents require new techniques for compact storage and efficient query processing. In this entry, we classify the main approaches taken to store XML documents by industrial systems and in research works.",
            "Abstract entirety": 1,
            "Author pub id": "oaM-d7QAAAAJ:RHpTSmoSYBkC",
            "Publisher": "Springer"
        },
        {
            "Title": "Expressive capabilities description languages and query rewriting algorithms",
            "Publication year": 2000,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S0743106699000266",
            "Abstract": "Information integration systems have to cope with a wide variety of different information sources, which support query interfaces with very varied capabilities. To deal with this problem, the integration systems need descriptions of the query capabilities of each source, i.e., the set of queries supported by each source. Moreover, the integration systems need algorithms for deciding how a query can be answered given the capabilities of the sources. Finally, they need to translate a query into the format that the source understands. We present two languages suitable for descriptions of query capabilities of sources and compare their expressive power. We also use one of the languages to automatically derive the capabilities description of the integration system itself, in terms of the capabilities of the sources it integrates. We describe algorithms for deciding whether a query \u201cmatches\u201d the description and show their \u2026",
            "Abstract entirety": 0,
            "Author pub id": "oaM-d7QAAAAJ:IjCSPb-OGe4C",
            "Publisher": "North-Holland"
        },
        {
            "Title": "MiniCount: Efficient rewriting of COUNT-queries using views",
            "Publication year": 2006,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/1617369/",
            "Abstract": "We present MiniCount, the first efficient sound and complete algorithm for finding maximally contained rewritings of conjunctive queries with count, using conjunctive views with count and conjunctive views without aggregation. An efficient and scalable solution to this problem yields significant benefits for data warehousing and decision support systems, as well as for powerful data integration systems.We first present a naive rewriting algorithm implicit in the recent theoretical results by Cohen et al. [5] and identify three independent sources of exponential complexity in the naive algorithm, including an expensive containment check. Then we present and discuss MiniCount and prove it sound and complete. We also present an experimental study that shows Mini- Count to be orders of magnitude faster than the naive algorithm, and to be able to scale to large numbers of views",
            "Abstract entirety": 1,
            "Author pub id": "oaM-d7QAAAAJ:4TOpqqG69KYC",
            "Publisher": "IEEE"
        }
    ]
}]