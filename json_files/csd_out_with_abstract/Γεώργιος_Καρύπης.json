[{
    "name": "\u0393\u03b5\u03ce\u03c1\u03b3\u03b9\u03bf\u03c2 \u039a\u03b1\u03c1\u03cd\u03c0\u03b7\u03c2",
    "romanize name": "Georgios Karypis",
    "School-Department": "Computer Science and Engineering",
    "University": "University of Minnesota",
    "Rank": "\u039a\u03b1\u03b8\u03b7\u03b3\u03b7\u03c4\u03ae\u03c2",
    "Apella_id": 7274,
    "Scholar name": "George Karypis",
    "Scholar id": "ElqwScwAAAAJ",
    "Affiliation": "Distinguished McKnight University Professor, CS&E, University of Minnesota",
    "Citedby": 82995,
    "Interests": [
        "Data mining",
        "Parallel computing",
        "Recommender systems",
        "Learning analytics",
        "Chemical informatics"
    ],
    "Scholar url": "https://scholar.google.com/citations?user=ElqwScwAAAAJ&hl=en",
    "Publications": [
        {
            "Title": "Parallel multilevel algorithms for multi-constraint graph partitioning",
            "Publication year": 2000,
            "Publication url": "https://link.springer.com/chapter/10.1007/3-540-44520-X_39",
            "Abstract": "Sequential multi-constraint graph partitioners have been developed to address the load balancing requirements of multi-phase simulations. The efficient execution of large multi-phase simulations on high performance parallel computers requires that the multi-constraint partitionings are computed in parallel. This paper presents a parallel formulation of a recently developed multi-constraint graph partitioning algorithm. We describe this algorithm and give experimental results conducted on a 128-processor Cray T3E. We show that our parallel algorithm is able to efficiently compute partitionings of similar edge-cuts as serial multi-constraint algorithms, and can scale to very large graphs. Our parallel multi-constraint graph partitioner is able to compute a three-constraint 128-way partitioning of a 7.5 million node graph in about 7 seconds on 128 processors of a Cray T3E.",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:bEWYMUwI8FkC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "Adaptive matrix completion for the users and the items in tail",
            "Publication year": 2019,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/3308558.3313736",
            "Abstract": "Recommender systems are widely used to recommend the most appealing items to users. These recommendations can be generated by applying collaborative filtering methods. The low-rank matrix completion method is the state-of-the-art collaborative filtering method. In this work, we show that the skewed distribution of ratings in the user-item rating matrix of real-world datasets affects the accuracy of matrix-completion-based approaches. Also, we show that the number of ratings that an item or a user has positively correlates with the ability of low-rank matrix-completion-based approaches to predict the ratings for the item or the user accurately. Furthermore, we use these insights to develop four matrix completion-based approaches, ie, Frequency Adaptive Rating Prediction (FARP), Truncated Matrix Factorization (TMF), Truncated Matrix Factorization with Dropout (TMF+ Dropout) and Inverse Frequency Weighted \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:_mQi-xiA4oYC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Sequence, assembly and analysis of the Chinese Hamster genome: A context for comparative genomics in CHO cells",
            "Publication year": 2011,
            "Publication url": "https://scholar.google.com/scholar?cluster=14937507336876799040&hl=en&oi=scholarr",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:g5Ck-dwhA_QC",
            "Publisher": "AMER CHEMICAL SOC"
        },
        {
            "Title": "Intelligent metasearch engine for knowledge management",
            "Publication year": 2003,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/956863.956955",
            "Abstract": "The explosive growth of available information sources and the resulting information overload pose several problems for users in many business organizations and educational institutions. First, searching through several information sources, one at a time, is a source of enormous frustration for users. Second, top-ranked documents in search results are frequently irrelevant to what users are interested in. To address these problems, we have developed ixmeta\u2122, a powerful metasearch engine that gathers, evaluates, ranks, and reports the most relevant results from multiple information sources, including library catalogs, proprietary databases, intranets, and Web search engines. In addition to basic metasearch capabilities, ixmetafind uses personalization and clustering techniques to find the most relevant results for users. In this paper, we briefly describe technologies used in ixmetafind and present pinpoint\u2122 from \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:dTyEYWd-f8wC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Exploring optimizations on shared-memory platforms for parallel triangle counting algorithms",
            "Publication year": 2017,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/8091054/",
            "Abstract": "The widespread use of graphs to model large scale real-world data brings with it the need for fast graph analytics. In this paper, we explore the problem of triangle counting, a fundamental graph-analytic operation, on shared-memory platforms. Existing triangle counting implementations do not effectively utilize the key characteristics of large sparse graphs for tuning their algorithms for performance. We explore such optimizations and develop faster serial and parallel variants of existing algorithms, which outperform the state-of-the-art on Intel manycore and multicore processors. Our algorithms achieve good strong scaling on many graphs with varying scale and degree distributions. Furthermore, we extend our optimizations to a well-known graph processing framework, GraphMat, and demonstrate their generality.",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:ukw-9cB-YDkC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Graph InfoClust: Maximizing Coarse-Grain Mutual Information in Graphs",
            "Publication year": 2021,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-030-75762-5_43",
            "Abstract": "This work proposes a new unsupervised (or self-supervised) node representation learning method that aims to leverage the coarse-grain information that is available in most graphs. This extends previous attempts that only leverage fine-grain information (similarities within local neighborhoods) or global graph information (similarities across all nodes). Intuitively, the proposed method identifies nodes that belong to the same clusters and maximizes their mutual information. Thus, coarse-grain (cluster-level) similarities that are shared between nodes are preserved in their representations. The core components of the proposed method are (i) a jointly optimized clustering of nodes during learning and (ii) an Infomax objective term that preserves the mutual information among nodes of the same clusters. Our method is able to outperform competing state-of-art methods in various downstream tasks, such as node \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:lRPiJ3GhvscC",
            "Publisher": "Springer, Cham"
        },
        {
            "Title": "Regions of High Confidence in Chinese Hamster and CHO-K1 Genome Assemblies",
            "Publication year": 2016,
            "Publication url": "https://conservancy.umn.edu/handle/11299/179004",
            "Abstract": "Chinese hamster Ovary (CHO) cell lines are the dominant industrial workhorses for therapeutic recombinant protein production. The availability of the genome sequence of Chinese hamster and CHO cells will spur further genome and RNA sequencing of producing cell lines. However, the mammalian genomes assembled using shot-gun sequencing data still contain regions of uncertain quality due to assembly errors. Identifying high confidence regions in the assembled genome will facilitate its use for cell engineering and genome engineering. This dataset includes two genome annotation files that identify the 'high confidence regions' shared by the genome assemblies in comparison. The potential use of these files are to find locations in the publically available genome which are likely to be assembled correctly. These regions can be used confidently for genome engineering.",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:GYcXSSpN504C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Multilevel algorithms for partitioning power-law graphs",
            "Publication year": 2006,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/1639360/",
            "Abstract": "Graph partitioning is an enabling technology for parallel processing as it allows for the effective decomposition of unstructured computations whose data dependencies correspond to a large sparse and irregular graph. Even though the problem of computing high-quality partitionings of graphs arising in scientific computations is to a large extent well-understood, this is far from being true for emerging HPC applications whose underlying computation involves graphs whose degree distribution follows a power-law curve. This paper presents new multilevel graph partitioning algorithms that are specifically designed for partitioning such graphs. It presents new clustering-based coarsening schemes that identify and collapse together groups of vertices that are highly connected. An experimental evaluation of these schemes on 10 different graphs show that the proposed algorithms consistently and significantly outperform \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:-f6ydRqryjwC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Fast and effective lossy compression algorithms for scientific datasets",
            "Publication year": 2012,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-642-32820-6_83",
            "Abstract": "This paper focuses on developing effective and efficient algorithms for compressing scientific simulation data computed on structured and unstructured grids. A paradigm for lossy compression of this data is proposed in which the data computed on the grid is modeled as a graph, which gets decomposed into sets of vertices which satisfy a user defined error constraint \u03b5. Each set of vertices is replaced by a constant value with reconstruction error bounded by \u03b5. A comprehensive set of experiments is conducted by comparing these algorithms and other state-of-the-art scientific data compression methods. Over our benchmark suite, our methods obtained compression of 1% of the original size with average PSNR of 43.00 and 3% of the original size with average PSNR of 63.30. In addition, our schemes outperform other state-of-the-art lossy compression approaches and require on the average 25% of the space \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:MLfJN-KU85MC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "Text segmentation on multilabel documents: A distant-supervised approach",
            "Publication year": 2018,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/8594963/",
            "Abstract": "Segmenting text into semantically coherent segments is an important task with applications in information retrieval and text summarization. Developing accurate topical segmentation requires the availability of training data with ground truth information at the segment level. However, generating such labeled datasets, especially for applications in which the meaning of the labels is user-defined, is expensive and time-consuming. In this paper, we develop an approach that instead of using segment-level ground truth information, it instead uses the set of labels that are associated with a document and are easier to obtain as the training data essentially corresponds to a multilabel dataset. Our method, which can be thought of as an instance of distant supervision, improves upon the previous approaches by exploiting the fact that consecutive sentences in a document tend to talk about the same topic, and hence, probably \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:Nufq_to8ts0C",
            "Publisher": "IEEE"
        },
        {
            "Title": "Empirical and theoretical comparisons of selected criterion functions for document clustering",
            "Publication year": 2004,
            "Publication url": "https://link.springer.com/article/10.1023/B:MACH.0000027785.44527.d6",
            "Abstract": "This paper evaluates the performance of different criterion functions in the context of partitional clustering algorithms for document datasets. Our study involves a total of seven different criterion functions, three of which are introduced in this paper and four that have been proposed in the past. We present a comprehensive experimental evaluation involving 15 different datasets, as well as an analysis of the characteristics of the various criterion functions and their effect on the clusters they produce. Our experimental results show that there are a set of criterion functions that consistently outperform the rest, and that some of the newly proposed criterion functions lead to the best overall results. Our theoretical analysis shows that the relative performance of the criterion functions depends on (i) the degree to which they can correctly operate when the clusters are of different tightness, and (ii) the degree to which \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:5nxA0vEk-isC",
            "Publisher": "Kluwer Academic Publishers-Plenum Publishers"
        },
        {
            "Title": "Incremental singular value decomposition algorithms for highly scalable recommender systems",
            "Publication year": 2002,
            "Publication url": "http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.3.7894&rep=rep1&type=pdf",
            "Abstract": "We investigate the use of dimensionality reduction to improve the performance for a new class of data analysis software called \u201crecommender systems\u201d. Recommender systems apply knowledge discovery techniques to the problem of making personalized product recommendations during a live customer interaction. The tremendous growth of customers and products in recent years poses some key challenges for recommender systems. These are: producing high quality recommendations and performing many recommendations per second for millions of customers and products. Singular Value Decomposition (SVD)-based recommendation algorithms can quickly produce high quality recommendations, but has to undergo very expensive matrix factorization steps. In this paper, we propose and experimentally validate a technique that has the potential to incrementally build SVD-based models and promises to make the recommender systems highly scalable.",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:hC7cP41nSMkC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Cawa: An attention-network for credit attribution",
            "Publication year": 2020,
            "Publication url": "https://ojs.aaai.org/index.php/AAAI/article/view/6367",
            "Abstract": "Credit attribution is the task of associating individual parts in a document with their most appropriate class labels. It is an important task with applications to information retrieval and text summarization. When labeled training data is available, traditional approaches for sequence tagging can be used for credit attribution. However, generating such labeled datasets is expensive and time-consuming. In this paper, we present Credit Attribution With Attention (CAWA), a neural-network-based approach, that instead of using sentence-level labeled data, uses the set of class labels that are associated with an entire document as a source of distant-supervision. CAWA combines an attention mechanism with a multilabel classifier into an end-to-end learning framework to perform credit attribution. CAWA labels the individual sentences from the input document using the resultant attention-weights. CAWA improves upon the state-of-the-art credit attribution approach by not constraining a sentence to belong to just one class, but modeling each sentence as a distribution over all classes, leading to better modeling of semantically-similar classes. Experiments on the credit attribution task on a variety of datasets show that the sentence class labels generated by CAWA outperform the competing approaches. Additionally, on the multilabel text classification task, CAWA performs better than the competing credit attribution approaches 1.",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:SWgZeABleR0C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Monster: Minnesota protein sequence annotation server",
            "Publication year": 2008,
            "Publication url": "https://conservancy.umn.edu/handle/11299/215753",
            "Abstract": "MONSTER is a server for predicting the local structure and function properties of protein sequences. MONSTER provides residue-wise annotation services, that include secondary structure, transmembrane-helix region, disorder region, protein-dna binding site, local structure alphabet, solvent accessibility surface area, and residue-wise contact order prediction. MONSTER uses sequence-derived information (in the form of PSI-BLAST profiles), a window-based encoding scheme with an accurate kernel function to perform the classification or estimation. The user provides an amino acid sequence and selects the desired predictions, and submits a job to the MONSTER server. The results are emailed to the user as a link directing the user to a well formatted HTML output page.  Availability: http://bio.dtc.umn.edu/monster",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:jL-93Qbq4QoC",
            "Publisher": "Unknown"
        },
        {
            "Title": "A segment-based approach to clustering multi-topic documents",
            "Publication year": 2013,
            "Publication url": "https://link.springer.com/article/10.1007/s10115-012-0556-z",
            "Abstract": "Document clustering has been recognized as a central problem in text data management. Such a problem becomes particularly challenging when document contents are characterized by subtopical discussions that are not necessarily relevant to each other. Existing methods for document clustering have traditionally assumed that a document is an indivisible unit for text representation and similarity computation, which may not be appropriate to handle documents with multiple topics. In this paper, we address the problem of multi-topic document clustering by leveraging the natural composition of documents in text segments that are coherent with respect to the underlying subtopics. We propose a novel document clustering framework that is designed to induce a document organization from the identification of cohesive groups of segment-based portions of the original documents. We empirically give \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:_B80troHkn4C",
            "Publisher": "Springer-Verlag"
        },
        {
            "Title": "TR O2-O25",
            "Publication year": 2002,
            "Publication url": "https://scholar.google.com/scholar?cluster=10299954842682840740&hl=en&oi=scholarr",
            "Abstract": "Hypergraph partitioning is an important problem With extensive application to many areas, including VLSI design [Alpert and Kahng, l995], ef\ufb01cient storage of large databases on disks [Shekhar and Liu, 1996], and data min-ing [Mobasher et al., 1996, Karypis et al., 1999b]. The problem is to partition the vertices of a hypergraph into k equal-size parts, such that the number of hyperedges connecting vertices in different parts is minimized. During the course of VLSI circuit design and synthesis, it is important to be able to divide the system speci\ufb01cation into clusters so that the inter-cluster connections are minimized. This step has many applications including design packaging, HDL-based synthesis, design optimization, rapid prototyping, simulation, and testing. Many rapid prototyping systems use partitioning to map a complex circuit onto hundreds of interconnected FPGAs. Such partitioning instances are challenging \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:Gpwnp1kGG20C",
            "Publisher": "Unknown"
        },
        {
            "Title": "MGridGen/ParmGridGen, Serial/Parallel library for generating coase meshes for multigrid methods",
            "Publication year": 2001,
            "Publication url": "https://scholar.google.com/scholar?cluster=14050985065567479017&hl=en&oi=scholarr",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:k8to_Y4Q4_EC",
            "Publisher": "Technical Report Version 1.0, University of Minnesota, Department of Computer Science/Army HPC Research Center"
        },
        {
            "Title": "BIOT 122-Transcriptome dynamics-based gene network analysis for secondary metabolism",
            "Publication year": 2006,
            "Publication url": "https://scholar.google.com/scholar?cluster=8538140068899191316&hl=en&oi=scholarr",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:QsaTk4IG4EwC",
            "Publisher": "AMER CHEMICAL SOC"
        },
        {
            "Title": "FaiREO: User Group Fairness for Equality of Opportunity in Course Recommendation",
            "Publication year": 2021,
            "Publication url": "https://arxiv.org/abs/2109.05931",
            "Abstract": "Course selection is challenging for students in higher educational institutions. Existing course recommendation systems make relevant suggestions to the students and help them in exploring the available courses. The recommended courses can influence students' choice of degree program, future employment, and even their socioeconomic status. This paper focuses on identifying and alleviating biases that might be present in a course recommender system. We strive to promote balanced opportunities with our suggestions to all groups of students. At the same time, we need to make recommendations of good quality to all protected groups. We formulate our approach as a multi-objective optimization problem and study the trade-offs between equal opportunity and quality. We evaluate our methods using both real-world and synthetic datasets. The results indicate that we can considerably improve fairness regarding equality of opportunity, but we will introduce some quality loss. Out of the four methods we tested, GHC-Inc and GHC-Tabu are the best performing ones with different advantageous characteristics.",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:RgznTc0nqo4C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Finding frequent patterns using length-decreasing support constraints",
            "Publication year": 2005,
            "Publication url": "https://link.springer.com/article/10.1007/s10618-005-0364-0",
            "Abstract": "Finding prevalent patterns in large amount of data has been one of the major problems in the area of data mining. Particularly, the problem of finding frequent itemset or sequential patterns in very large databases has been studied extensively over the years, and a variety of algorithms have been developed for each problem. The key feature in most of these algorithms is that they use a constant support constraint to control the inherently exponential complexity of these two problems. In general, patterns that contain only a few items will tend to be interesting if they have a high support, whereas long patterns can still be interesting even if their support is relatively small. Ideally, we want to find all the frequent patterns whose support decreases as a function of their length without having to find many uninteresting infrequent short patterns. Developing such algorithms is particularly challenging because the \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:b0M2c_1WBrUC",
            "Publisher": "Kluwer Academic Publishers"
        },
        {
            "Title": "Protein structure methods and algorithms, volume 14 of Wiley Series in Bioinformatics: Computational Techniques and Engineering",
            "Publication year": 2010,
            "Publication url": "https://scholar.google.com/scholar?cluster=14052831873536859087&hl=en&oi=scholarr",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:GHsHDPAyICYC",
            "Publisher": "John Wiley & Sons"
        },
        {
            "Title": "Clustering methodologies for identifying country core competencies",
            "Publication year": 2007,
            "Publication url": "https://journals.sagepub.com/doi/abs/10.1177/0165551506067124",
            "Abstract": "The technical structure of the Mexican science and technology literature was                 determined. A representative database of technical articles was extracted from the                 Science Citation Index for the year 2002, with each article containing at least one                 author with a Mexican address. Many different manual and statistical clustering                 methods were used to identify the structure of the technical literature (especially                 the science and technology core competencies), and to evaluate the strengths and                 weaknesses of each technique. Each method is summarized, and its results presented.",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:tOudhMTPpwUC",
            "Publisher": "Sage Publications"
        },
        {
            "Title": "TR O4-O40",
            "Publication year": 2004,
            "Publication url": "https://scholar.google.com/scholar?cluster=14365286618896449293&hl=en&oi=scholarr",
            "Abstract": "Partitioning driven placement approaches are often preferred for fast and scalable solutions to large placement problems. However, due to the inaccuracy of representing wirelength objective by cut objective the quality of such placements often trails the quality of placements produced by pure wirelength driven placements. In this paper we present TH ETO, a new partitioning driven placement algorithm that retains the speed associated with traditional partitioning driven placement algorithms but incorporates a number of novel ideas that allows it to produce solutions whose quality is better than those produced by more sophisticated and computationally expensive algorithms. The keys to TH ETO\u2019s success are a new terminal propagation method that allows the partitioner to exactly map the half-perimeter wirelength cost to min-cut cost, and an integral post-bisectioning re\ufb01nement step that enhances the effectiveness \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:JTqpx9DYBaYC",
            "Publisher": "Unknown"
        },
        {
            "Title": "A fixed-point method to compute similarities in sparse response data",
            "Publication year": 2009,
            "Publication url": "https://www.researchgate.net/profile/George-Karypis-2/publication/265099546_A_Fixed-Point_Method_to_Compute_Similarities_in_Sparse_Response_Data/links/549ee9bf0cf267bdb8fdb8c8/A-Fixed-Point-Method-to-Compute-Similarities-in-Sparse-Response-Data.pdf",
            "Abstract": "Several key applications like recommender systems deal with data in the form of responses by users for items. In such applications, one of the most crucial task is to find users that share common interests, or items with similar characteristics. Assessing the similarity between users or items has several valuable uses, among which are the recommendation of new items, the discovery of groups of like-minded individuals, and the automated categorization of items. It has been recognized that popular methods to compute similarities, based on correlation, are not suitable for this task when the response data is sparse. This paper presents a new framework to compute similarity values that extends such methods by simultaneously solving equations relating user similarities to item similarities. Unlike correlation-based methods, that only consider user responses for common items, this approach uses all the available responses, which allows it to compute meaningful similarities when only a few user responses are available. To evaluate the usefulness of this approach, we test it on the problem of predicting the ratings of users for movies and jokes.",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:XD-gHx7UXLsC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Efficient identification of tanimoto nearest neighbors",
            "Publication year": 2017,
            "Publication url": "https://link.springer.com/article/10.1007/s41060-017-0064-z",
            "Abstract": "Tanimoto, or extended Jaccard, is an important similarity measure which has seen prominent use in fields such as data mining and chemoinformatics. Many of the existing state-of-the-art methods for market basket analysis, plagiarism and anomaly detection, compound database search, and ligand-based virtual screening rely heavily on identifying Tanimoto nearest neighbors. Given the rapidly increasing size of data that must be analyzed, new algorithms are needed that can speed up nearest neighbor search, while at the same time providing reliable results. While many search algorithms address the complexity of the task by retrieving only some of the nearest neighbors, we propose a method that finds all of the exact nearest neighbors efficiently by leveraging recent advances in similarity search filtering. We provide tighter filtering bounds for the Tanimoto coefficient and show that our method, TAPNN \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:kUhpeDhEZMUC",
            "Publisher": "Springer International Publishing"
        },
        {
            "Title": "HPC formulations of optimization algorithms for tensor completion",
            "Publication year": 2018,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S0167819117301849",
            "Abstract": "Tensor completion is a powerful tool used to estimate or recover missing values in multi-way data. It has seen great success in domains such as product recommendation and healthcare. Tensor completion is most often accomplished via low-rank sparse tensor factorization, a computationally expensive non-convex optimization problem which has only recently been studied in the context of parallel computing. In this work, we study three optimization algorithms that have been successfully applied to tensor completion: alternating least squares (ALS), stochastic gradient descent (SGD), and coordinate descent (CCD++). We explore opportunities for parallelism on shared- and distributed-memory systems and address challenges such as memory- and operation-efficiency, load balance, cache locality, and communication. Among our advancements are a communication-efficient CCD++ algorithm, an ALS algorithm rich \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:0ngZmJvimKcC",
            "Publisher": "North-Holland"
        },
        {
            "Title": "An efficient algorithm for discovering frequent subgraphs",
            "Publication year": 2004,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/1316833/",
            "Abstract": "Over the years, frequent itemset discovery algorithms have been used to find interesting patterns in various application areas. However, as data mining techniques are being increasingly applied to nontraditional domains, existing frequent pattern discovery approaches cannot be used. This is because the transaction framework that is assumed by these algorithms cannot be used to effectively model the data sets in these domains. An alternate way of modeling the objects in these data sets is to represent them using graphs. Within that model, one way of formulating the frequent pattern discovery problem is that of discovering subgraphs that occur frequently over the entire set of graphs. We present a computationally efficient algorithm, called FSG, for finding all frequent subgraphs in large graph data sets. We experimentally evaluate the performance of FSG using a variety of real and synthetic data sets. Our results \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:MXK_kJrjxJIC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Anomaly Detection on Attributed Networks via Contrastive Self-Supervised Learning",
            "Publication year": 2021,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/9395172/",
            "Abstract": "Anomaly detection on attributed networks attracts considerable research interests due to wide applications of attributed networks in modeling a wide range of complex systems. Recently, the deep learning-based anomaly detection methods have shown promising results over shallow approaches, especially on networks with high-dimensional attributes and complex structures. However, existing approaches, which employ graph autoencoder as their backbone, do not fully exploit the rich information of the network, resulting in suboptimal performance. Furthermore, these methods do not directly target anomaly detection in their learning objective and fail to scale to large networks due to the full graph training mechanism. To overcome these limitations, in this article, we present a novel Contrastive self-supervised Learning framework for Anomaly detection on attributed networks (CoLA for abbreviation). Our framework \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:I-2NeQpV75MC",
            "Publisher": "IEEE"
        },
        {
            "Title": "L2AP: Fast Cosine Similarity Search With Prefix L-2 Norm Bounds",
            "Publication year": 2013,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/6816700/",
            "Abstract": "The All-Pairs similarity search, or self-similarity join problem, finds all pairs of vectors in a high dimensional sparse dataset with a similarity value higher than a given threshold. The problem has been classically solved using a dynamically built inverted index. The search time is reduced by early pruning of candidates using size and value-based bounds on the similarity. In the context of cosine similarity and weighted vectors, leveraging the Cauchy-Schwarz inequality, we propose new \u2113 2 -norm bounds for reducing the inverted index size, candidate pool size, and the number of full dot-product computations. We tighten previous candidate generation and verification bounds and introduce several new ones to further improve our algorithm's performance. Our new pruning strategies enable significant speedups over baseline approaches, most times outperforming even approximate solutions. We perform an extensive \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:c1e4I3QdEKYC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Context-aware non-linear and neural attentive knowledge-based models for grade prediction",
            "Publication year": 2020,
            "Publication url": "https://arxiv.org/abs/2003.05063",
            "Abstract": "Grade prediction for future courses not yet taken by students is important as it can help them and their advisers during the process of course selection as well as for designing personalized degree plans and modifying them based on their performance. One of the successful approaches for accurately predicting a student's grades in future courses is Cumulative Knowledge-based Regression Models (CKRM). CKRM learns shallow linear models that predict a student's grades as the similarity between his/her knowledge state and the target course. However, prior courses taken by a student can have \\black{different contributions when estimating a student's knowledge state and towards each target course, which} cannot be captured by linear models. Moreover, CKRM and other grade prediction methods ignore the effect of concurrently-taken courses on a student's performance in a target course. In this paper, we propose context-aware non-linear and neural attentive models that can potentially better estimate a student's knowledge state from his/her prior course information, as well as model the interactions between a target course and concurrent courses. Compared to the competing methods, our experiments on a large real-world dataset consisting of more than M grades show the effectiveness of the proposed models in accurately predicting students' grades. Moreover, the attention weights learned by the neural attentive model can be helpful in better designing their degree plans.",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:uoRD4RTSUPoC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Experiments in automating the morphological classification of galaxies",
            "Publication year": 2001,
            "Publication url": "https://ui.adsabs.harvard.edu/abs/2001AAS...199.1015H/abstract",
            "Abstract": "Image classification and pattern recognition is an important and challenging problem for the efficient analysis of large astronomical databases and will become even more important with the development of the National Virtual Observatory. Neural networks and decision trees have already been successfully applied to star-galaxy or stellar-nonstellar image separation. But for many astrophysical problems such as large-scale structure, galaxy formation, and evolution, we need the morphological type of the galaxy. We report the VERY promising results of our first experiments with different classification algorithms including decision trees, K-nearest neighbor and the new support vector machines. Our results will be applicable to other digitized and digital sky surveys that will be part of the NVO. The APS Project and this investigation are supported by NASA's Applied Information Systems Research Program.",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:dQ2og3OwTAUC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Graph-Based Pattern Classification and Dimensionality Reduction",
            "Publication year": 2016,
            "Publication url": "https://books.google.com/books?hl=en&lr=&id=BvYYCwAAQBAJ&oi=fnd&pg=PA163&dq=info:w4DzRrPBQJEJ:scholar.google.com&ots=AcV468PgQM&sig=LbfPICi27VdEcXeYgDt_xzwzJWY",
            "Abstract": "Digital media, like images, videos, etc., play an important role in social networks. For example, users in social networks are able to post images depicting themselves and/or some of their friends in a location, while other users may see some of these images and rate them. Such rates can be used to describe connections between users or between users and locations, etc. Thus, digital media content analysis is of particular interest in social networks. Digital media representations are usually high-dimensional. For example, a facial image of size 200\u00d7 150 pixels can be represented by a 30000-dimensional vector obtained by using each pixel coordinate as a different dimension. Therefore, significant efforts have been devoted to deriving low-dimensional data representations that retain properties of interest of the data,",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:RMgMIBzvq-4C",
            "Publisher": "CRC Press"
        },
        {
            "Title": "A unified algorithm for load-balancing adaptive scientific simulations",
            "Publication year": 2000,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/1592772/",
            "Abstract": "Adaptive scientific simulations require that periodic repartitioning occur dynamically throughout the course of the computation. The repartitionings should be computed so as to minimize both the inter-processor communications incurred during the iterative mesh-based computation and the data redistribution costs required to balance the load. Recently developed schemes for computing repartitionings provide the user with only a limited control of the tradeoffs among these objectives. This paper describes a new Unified Repartitioning Algorithm that can tradeoff one objective for the other dependent upon a user-defined parameter describing the relative costs of these objectives. We show that the Unified Repartitioning Algorithm is able to reduce the precise overheads associated with repartitioning as well as or better than other repartitioning schemes for a variety of problems, regardless of the relative costs of \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:hFOr9nPyWt4C",
            "Publisher": "IEEE"
        },
        {
            "Title": "Improved prediction of protein model quality",
            "Publication year": 2008,
            "Publication url": "https://conservancy.umn.edu/handle/11299/215745",
            "Abstract": "Methods that can automatically assess the quality of computationally predicted protein structures are important, as they enable the selection of the most accurate structure from an ensemble of predictions. Assessment methods that determine the quality of a protein's structure by comparing it against the various structures predicted by different servers have been shown to outperform approaches that rely on the intrinsic characteristics of the structure itself.  We developed an algorithm to estimate the quality of a predicted protein structure using a consensus approach. Our method uses LGA to align the structure in question to the structures for the same protein predicted by different servers and estimates the per-residue error by averaging the distances across these alignments. On a dataset containing 892,299 positions from 4,969 CASP7 submissions, our method achieved a root mean squared error (RMSE) of 6.69angstroms, which is significantly better than the 8.21angstroms achieved by the winning scheme in CASP7 for this problem (Pcons). We further improved these results to 6.51angstroms by developing a scheme that carefully selects which distances to average based on the predicted quality of the overall structure. We also examined the use of machine learning approaches to learn an appropriate aggregation scheme, which led to a simple weight learning approach achieving a 2.61angstroms RMSE on a reduced dataset.  Our results show that the use of LGA alignments and aggregation of raw distances is the primary reason for its performance advantage. In addition, our results show that beyond a binary inclusion/exclusion decision \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:edDO8Oi4QzsC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Multi-view learning via probabilistic latent semantic analysis",
            "Publication year": 2012,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S0020025512001788",
            "Abstract": "Multi-view learning arouses vast amount of interest in the past decades with numerous real-world applications in web page analysis, bioinformatics, image processing and so on. Unlike the most previous works following the idea of co-training, in this paper we propose a new generative model for Multi-view Learning via Probabilistic Latent Semantic Analysis, called MVPLSA. In this model, we jointly model the co-occurrences of features and documents from different views. Specifically, in the model there are two latent variables y for the latent topic and z for the document cluster, and three visible variables d for the document, f for the feature, and v for the view label. The conditional probability p(z\u2223d), which is independent of v, is used as the bridge to share knowledge among multiple views. Also, we have p(y\u2223z, v) and p(f\u2223y, v), which are dependent of v, to capture the specifical structures inside each view \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:ML0RJ9NH7IQC",
            "Publisher": "Elsevier"
        },
        {
            "Title": "Kernelized Multitask Learning Method for Personalized Signaling Adverse Drug Reactions",
            "Publication year": 2021,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/9527143/",
            "Abstract": "The signaling of the associations between drugs and adverse drug reactions (ADRs) is a challenging task in pharmacovigilance, especially when an association is infrequent or has never previously been reported. Most existing methods for ADR signaling are based on analyzing the frequency with which drugs tend to co-occur with ADRs. In this article, we propose a kernelized multitask learning model, KEMULA, in which information is learned and transferred from the clinical data of other patients as collaborative information to rank distinct lists of ADRs for different patients. We comprehensively compare the performance of KEMULA against three baseline methods, two state-of-the-art ADR signaling methods, and two KEMULA variants. The method is tested on adverse drug event reports retrieved from the FDA Adverse Event Reporting System (FAERS), which includes 4,106,633 unique adverse drug event reports \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:KsTgnNRry18C",
            "Publisher": "IEEE"
        },
        {
            "Title": "Discerning critical parameters influencing bioprocess performance through pattern recognition in manufacturing data",
            "Publication year": 2011,
            "Publication url": "https://scholar.google.com/scholar?cluster=1579377516433769044&hl=en&oi=scholarr",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:Xl6nMSl579sC",
            "Publisher": "AMER CHEMICAL SOC"
        },
        {
            "Title": "Parallel static and dynamic multi\u2010constraint graph partitioning",
            "Publication year": 2002,
            "Publication url": "https://onlinelibrary.wiley.com/doi/abs/10.1002/cpe.605",
            "Abstract": "Sequential multi\u2010constraint graph partitioners have been developed to address the static load balancing requirements of multi\u2010phase simulations. These work well when (i) the graph that models the computation fits into the memory of a single processor, and (ii) the simulation does not require dynamic load balancing. The efficient execution of very large or dynamically adapting multi\u2010phase simulations on high\u2010performance parallel computers requires that the multi\u2010constraint partitionings are computed in parallel. This paper presents a parallel formulation of a multi\u2010constraint graph\u2010partitioning algorithm, as well as a new partitioning algorithm for dynamic multi\u2010phase simulations. We describe these algorithms and give experimental results conducted on a 128\u2010processor Cray T3E. These results show that our parallel algorithms are able to efficiently compute partitionings of similar edge\u2010cuts as serial multi \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:maZDTaKrznsC",
            "Publisher": "John Wiley & Sons, Ltd."
        },
        {
            "Title": "Understanding computer usage evolution",
            "Publication year": 2015,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/7113424/",
            "Abstract": "The proliferation of computing devices in recent years has dramatically changed the way people work, play, communicate, and access information. The personal computer (PC) now has to compete with smartphones, tablets, and other devices for tasks it used to be the default device for. Understanding how PC usage evolves over time can help provide the best overall user experience for current customers, can help determine when they need brand new systems vs. upgraded components, and can inform future product design to better anticipate user needs.",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:ijdKiLOsEJMC",
            "Publisher": "IEEE"
        },
        {
            "Title": "TR O2-O25",
            "Publication year": 2002,
            "Publication url": "https://scholar.google.com/scholar?cluster=9017308955581077030&hl=en&oi=scholarr",
            "Abstract": "Hypergraph partitioning is an important problem With extensive application to many areas, including VLSI design [Alpert and Kahng, l995], ef\ufb01cient storage of large databases on disks [Shekhar and Liu, 1996], and data min-ing [Mobasher et al., 1996, Kaiypis et al., 1999b]. The problem is to partition the vertices of a hypergraph into k equal-size parts, such that the number of hyperedges connecting vertices in different parts is minimized. During the course of VLSI circuit design and synthesis, it is important to be able to divide the system speci\ufb01cation into clusters so that the inter-cluster connections are minimized. This step has many applications including design packaging, HDL-based synthesis, design optimization, rapid prototyping, simulation, and testing. Many rapid prototyping systems use partitioning to map a complex circuit onto hundreds of interconnected FPGAs. Such partitioning instances are challenging \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:F9fV5C73w3QC",
            "Publisher": "Unknown"
        },
        {
            "Title": "6th International Workshop on Data Mining in Bioinformatics (BIOKDD06)",
            "Publication year": 2006,
            "Publication url": "https://www.researchgate.net/profile/Mohammed_Zaki4/publication/242406766_6th_International_Workshop_on_Data_Mining_in_Bioinformatics_BIOKDD06/links/54296d310cf2e4ce940e686e.pdf",
            "Abstract": "Data Mining is the process of automatic discovery of novel and understandable models and patterns from large amounts of data. Bioinformatics is the science of storing, analyzing, and utilizing information from biological data such as sequences, molecules, gene expressions, and pathways. Development of novel data mining methods will play a fundamental role in understanding these rapidly expanding sources of biological data.The goal of this workshop is to encourage KDD researchers to take on the numerous challenges that Bioinformatics offers. The workshop will feature invited talks from noted experts in the field, and the latest data mining research in bioinformatics. We encourage papers that propose novel data mining techniques for tasks like:",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:tz746QTLzJkC",
            "Publisher": "Unknown"
        },
        {
            "Title": "The structure and infrastructure of Mexico's science and technology",
            "Publication year": 2005,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S0040162505000260",
            "Abstract": "The structure and infrastructure of the Mexican technical literature was determined. A representative database of technical articles was extracted from the Science Citation Index for the year 2002, with each article containing at least one author with a Mexican address. Many different manual and statistical clustering methods were used to identify the structure of the technical literature (especially the science and technology core competencies). One of the pervasive technical topics identified from the clustering, thin films research, was analyzed further using bibliometrics, in order to identify the infrastructure of this technology.",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:XiSMed-E-HIC",
            "Publisher": "North-Holland"
        },
        {
            "Title": "Predicting the performance of randomized parallel search: An application to robot motion planning",
            "Publication year": 2003,
            "Publication url": "https://link.springer.com/article/10.1023/A:1026283627113",
            "Abstract": "In this paper we discuss methods for predicting the performance of any formulation of randomized parallel search, and propose a new performance prediction method that is based on obtaining an accurate estimate of the k-processor run-time distribution. We show that the k-processor prediction method delivers accurate performance predictions and demonstrate the validity of our analysis on several robot motion planning problems.",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:VLnqNzywnoUC",
            "Publisher": "Kluwer Academic Publishers"
        },
        {
            "Title": "Intro. Protein Structure Prediction, Methods Algorithms",
            "Publication year": 2010,
            "Publication url": "https://scholar.google.com/scholar?cluster=15799120455735072776&hl=en&oi=scholarr",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:4tNoA7Af41QC",
            "Publisher": "John Wiley and Sons, Inc., Hoboken, New Jersey"
        },
        {
            "Title": "TheTo---A Fast, Scalable and High-Quality Partitioning Driven Placement Tool.",
            "Publication year": 2004,
            "Publication url": "Unknown",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:XiVPGOgt02cC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Discriminating subsequence discovery for sequence clustering",
            "Publication year": 2007,
            "Publication url": "https://epubs.siam.org/doi/abs/10.1137/1.9781611972771.69",
            "Abstract": "In this paper, we explore the discriminating subsequence-based clustering problem. First, several effective optimization techniques are proposed to accelerate the sequence mining process and a new algorithm, CONTOUR, is developed to efficiently and directly mine a subset of discriminating frequent subsequences which can be used to cluster the input sequences. Second, an accurate hierarchical clustering algorithm, SSC, is constructed based on the result of CONTOUR. The performance study evaluates the efficiency and scalability of CONTOUR, and the clustering quality of SSC.",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:AXPGKjj_ei8C",
            "Publisher": "Society for Industrial and Applied Mathematics"
        },
        {
            "Title": "Intent term weighting in e-commerce queries",
            "Publication year": 2019,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/3357384.3358151",
            "Abstract": "E-commerce search engines can fail to retrieve results that satisfy a query's product intent because:(i) conventional retrieval approaches, such as BM25, may ignore the important terms in queries owing to their low\" inverse document frequency\"\"(IDF), and (ii) for long queries, as is usually the case in rare queries (ie, tail queries), they may fail to determine the relevant terms that are representative of the query's product intent. In this paper, we leverage the historical query reformulation logs of a large e-retailer (walmart. com) to develop a distant-supervision-based approach to identify the relevant terms that characterize the query's product intent. The key idea underpinning our approach is that the terms retained in the reformulation of a query are more important in describing the query's product intent than the discarded terms. Additionally, we also use the fact that the significance of a term depends on its context (other \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:iKswqCX-FLkC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Scienti\ufb01c Data Analysis",
            "Publication year": 2009,
            "Publication url": "https://www.taylorfrancis.com/chapters/edit/10.1201/9781420069815-18/scienti%EF%AC%81c-data-analysis-chandrika-kamath-nikil-wale-george-karypis-gaurav-pandey-vipin-kumar-krishna-rajan-nagiza-samatova-paul-breimyer-guruprasad-kora-chongle-pan-srikanth-yoginath",
            "Abstract": "The analysis of data is a key part of any scienti\ufb01c endeavor, as it leads to a better understanding of the world around us. With scienti\ufb01c data now being measured in terabytes and petabytes, this analysis is becoming quite challenging. In addition, the complexity of the data is increasing as well due to several factors such as improved sensor technologies and increased computing power. This complexity can take various forms such as multisensor, multispectral, multiresolution data, spatio-temporal data, high-dimensional data, structured and unstructured mesh data from simulations, data contaminated with di\ufb00erent types of noise, three-dimensional data, and so on.",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:ynsZFq2pu0MC",
            "Publisher": "Chapman and Hall/CRC"
        },
        {
            "Title": "Enriching course-specific regression models with content features for grade prediction",
            "Publication year": 2017,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/8259812/",
            "Abstract": "An enduring issue in higher education is student retention and timely graduation. Early-warning and degree planning systems have been identified as a key approach to tackle this problem. Accurately predicting a student's performance can help recommend degree pathways for students and identify students at-risk of dropping from their program of study. Various approaches have been developed for predicting students' next-term grades. Recently, course-specific approaches based on linear regression and matrix factorization have been proposed. To predict a student's grade, course-specific approaches utilize the student's grades from courses taken prior to that course. However, there are a lot of factors other than student's historical grades that influence his/her performance, such as the difficulty of the courses, the quality and pedagogy of the instructor, the academic level of the students when taking the courses \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:oqD4_j7ulsYC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Detecting significant genotype\u2013phenotype association rules in bipolar disorder: market research meets complex genetics",
            "Publication year": 2018,
            "Publication url": "https://journalbipolardisorders.springeropen.com/articles/10.1186/s40345-018-0132-x",
            "Abstract": "Disentangling the etiology of common, complex diseases is a major challenge in genetic research. For bipolar disorder (BD), several genome-wide association studies (GWAS) have been performed. Similar to other complex disorders, major breakthroughs in explaining the high heritability of BD through GWAS have remained elusive. To overcome this dilemma, genetic research into BD, has embraced a variety of strategies such as the formation of large consortia to increase sample size and sequencing approaches. Here we advocate a complementary approach making use of already existing GWAS data: a novel data mining procedure to identify yet undetected genotype\u2013phenotype relationships. We adapted association rule mining, a data mining technique traditionally used in retail market research, to identify frequent and characteristic genotype patterns showing strong associations to phenotype clusters. We applied this strategy to three independent GWAS datasets from 2835 phenotypically characterized patients with BD. In a discovery step, 20,882 candidate association rules were extracted. Two of these rules\u2014one associated with eating disorder and the other with anxiety\u2014remained significant in an independent dataset after robust correction for multiple testing. Both showed considerable effect sizes (odds ratio\u2009~\u20093.4 and 3.0, respectively) and support previously reported molecular biological findings. Our approach detected novel specific genotype\u2013phenotype relationships in BD that were missed by standard analyses like GWAS. While we developed and applied our method within the context of BD gene discovery, it may facilitate \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:q0uBw5dMOAkC",
            "Publisher": "SpringerOpen"
        },
        {
            "Title": "Expression levels for many genes in human peripheral blood cells are highly sensitive to ex vivo incubation",
            "Publication year": 2004,
            "Publication url": "https://www.nature.com/articles/6364098",
            "Abstract": "Monitoring of gene and protein expression in peripheral blood cells has significant potential for improving the diagnosis and therapy of many human diseases. As genomic-scale microarray and proteomic technologies are applied to peripheral blood, it is important to consider the variables that may affect interpretation of data. Here we report experiments performed to identify genes that are particularly sensitive to ex vivo handling prior to RNA extraction for gene expression microarrays or quantitative real-time RT-PCR assays. We examined Affymetrix gene expression in samples from eight normal individuals where blood was processed for RNA either immediately after blood draw or the next day following overnight incubation. These studies identified hundreds of genes that are sensitive to ex vivo handling of blood, and suggest that this is an important variable to consider when designing and interpreting human \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:mB3voiENLucC",
            "Publisher": "Nature Publishing Group"
        },
        {
            "Title": "A versatile graph-based approach to package recommendation",
            "Publication year": 2013,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/6735341/",
            "Abstract": "An emerging trend in research on recommender systems is the design of methods capable of recommending packages instead of single items. The problem is challenging due to a variety of critical aspects, including context-based and user-provided constraints for the items constituting a package, but also the high sparsity and limited accessibility of the primary data used to solve the problem. Most existing works on the topic have focused on a specific application domain (e.g., travel package recommendation), thus often providing ad-hoc solutions that cannot be adapted to other domains. By contrast, in this paper we propose a versatile package recommendation approach that is substantially independent of the peculiarities of a particular application domain. A key aspect in our framework is the exploitation of prior knowledge on the content type models of the packages being generated that express what the users \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:__bU50VfleQC",
            "Publisher": "IEEE"
        },
        {
            "Title": "A feature weight adjustment algorithm for document categorization",
            "Publication year": 2000,
            "Publication url": "https://www.cs.cmu.edu/~dunja/KDDpapers/Shankar_TM_IR.pdf",
            "Abstract": "In recent years we have seen a tremendous growth in the volume of text documents available on the Internet, digital libraries, news sources, and company-wide intra-nets. Automatic text categorization, which is the task of assigning text documents to pre-specified classes (topics or themes) of documents, is an important task that can help both in organizing as well as in finding information on these huge resources. In this paper we present a fast iterative feature weight adjustment algorithm for the linear-complexity centroid based classification algorithm. Our algorithm uses a measure of the discriminating power of each term to gradually adjust the weights of all features concurrently. We experimentally evaluate our algorithm on the Reuters-21578 and OHSUMED document collection and compare it against a variety of other categorization algorithms. Our experiments show that feature weight adjustment improves the performance of the centroid-based classifier by 2%-5%, substantially outperforms Rocchio and Widrow-Hoff and is competitive with SVM.",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:M05iB0D1s5AC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Dgl-lifesci: An open-source toolkit for deep learning on graphs in life science",
            "Publication year": 2021,
            "Publication url": "https://pubs.acs.org/doi/abs/10.1021/acsomega.1c04017",
            "Abstract": "Graph neural networks (GNNs) constitute a class of deep learning methods for graph data. They have wide applications in chemistry and biology, such as molecular property prediction, reaction prediction, and drug\u2013target interaction prediction. Despite the interest, GNN-based modeling is challenging as it requires graph data preprocessing and modeling in addition to programming and deep learning. Here, we present Deep Graph Library (DGL)-LifeSci, an open-source package for deep learning on graphs in life science. Deep Graph Library (DGL)-LifeSci is a python toolkit based on RDKit, PyTorch, and Deep Graph Library (DGL). DGL-LifeSci allows GNN-based modeling on custom datasets for molecular property prediction, reaction prediction, and molecule generation. With its command-line interfaces, users can perform modeling without any background in programming and deep learning. We test the \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:h1pkognVyKwC",
            "Publisher": "American Chemical Society"
        },
        {
            "Title": "MGridGen/ParMGridGen\u2014Serial/Parallel Library for Generating Coarse Grids for Multigrid Methods",
            "Publication year": 2001,
            "Publication url": "https://scholar.google.com/scholar?cluster=18298353864661132724&hl=en&oi=scholarr",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:qbqt7gslDFUC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Mining Evolving Patterns in Dynamic Relational Networks",
            "Publication year": 2016,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-319-24211-8_17",
            "Abstract": "Dynamic networks have recently been recognized as a powerful abstraction to model and represent the temporal changes and dynamic aspects of the data underlying many complex systems. This recognition has resulted in a burst of research activity related to modeling, analyzing, and understanding the properties, characteristics, and evolution of such dynamic networks. The focus of this growing research has been on mainly defining important recurrent structural patterns and developing algorithms for their identification. Most of these tools are not designed to identify time-persistent relational patterns or do not focus on tracking the changes of these relational patterns over time. Analysis of temporal aspects of the entity relations in these networks can provide significant insight in determining the conserved relational patterns and the evolution of such patterns over time. In this chapter we present new data \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:3_LpOwP6eMYC",
            "Publisher": "Springer, Cham"
        },
        {
            "Title": "Functional genomics of nectar production in the Brassicaceae",
            "Publication year": 2012,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S0367253012000801",
            "Abstract": "Nectar is a reward commonly offered by plants to attract potential pollinators, thereby ensuring outcrossing and efficient pollination. Until recently, little research has focused on the molecular components of nectar synthesis, and only a handful of genes have been shown to have a direct effect on nectary function. Recent transcriptomic data have made it possible to identify nectary-related candidate genes and further investigate their potential roles in the synthesis and secretion of nectar. Here we review the current state of research and address how our work aims to close gaps in knowledge relating to the process of nectar production. Using Brassicaceae species as models, we discuss the utilization of molecular and genomic tools available (i.e., sequenced genomes, T-DNA and TILLING mutants, sugar concentration assays, and metabolomics) to gain insight on the complex mechanisms of nectar secretion \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:hsZV8lGYWTMC",
            "Publisher": "Urban & Fischer"
        },
        {
            "Title": "TR O8-O44",
            "Publication year": 2008,
            "Publication url": "https://scholar.google.com/scholar?cluster=13919738147502541497&hl=en&oi=scholarr",
            "Abstract": "Collaborative \ufb01ltering is an important technique of ir1for\u2014mation filtering, commonly used to predict the interest of a user for a new item. In collaborative filtering systems, this prediction is made based on user-item preference data involving similar users or items. VVhen the data is sparse, however, direct similarity measures between users or items provide little information that can be used for the prediction. In this paper, we present a new collaborative \ufb01ltering approach that computes global similarities between pairs of items and users, as the equilibrium point of a system relating user similarities to item similarities.\\Ve show how this approach extends the classical techniques based on direct similarity, and illustrate, by testing on various datasets, its advantages over such techniques.",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:lgwcVrK6X84C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Distant-Supervised Slot-Filling for E-Commerce Queries",
            "Publication year": 2020,
            "Publication url": "https://arxiv.org/abs/2012.08134",
            "Abstract": "Slot-filling refers to the task of annotating individual terms in a query with the corresponding intended product characteristics (product type, brand, gender, size, color, etc.). These characteristics can then be used by a search engine to return results that better match the query's product intent. Traditional methods for slot-filling require the availability of training data with ground truth slot-annotation information. However, generating such labeled data, especially in e-commerce is expensive and time-consuming because the number of slots increases as new products are added. In this paper, we present distant-supervised probabilistic generative models, that require no manual annotation. The proposed approaches leverage the readily available historical query logs and the purchases that these queries led to, and also exploit co-occurrence information among the slots in order to identify intended product characteristics. We evaluate our approaches by considering how they affect retrieval performance, as well as how well they classify the slots. In terms of retrieval, our approaches achieve better ranking performance (up to 156%) over Okapi BM25. Moreover, our approach that leverages co-occurrence information leads to better performance than the one that does not on both the retrieval and slot classification tasks.",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:Ei5r6KrKXVQC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Position-based Hash Embeddings For Scaling Graph Neural Networks",
            "Publication year": 2021,
            "Publication url": "https://arxiv.org/abs/2109.00101",
            "Abstract": "Graph Neural Networks (GNNs) bring the power of deep representation learning to graph and relational data and achieve state-of-the-art performance in many applications. GNNs compute node representations by taking into account the topology of the node's ego-network and the features of the ego-network's nodes. When the nodes do not have high-quality features, GNNs learn an embedding layer to compute node embeddings and use them as input features. However, the size of the embedding layer is linear to the product of the number of nodes in the graph and the dimensionality of the embedding and does not scale to big data and graphs with hundreds of millions of nodes. To reduce the memory associated with this embedding layer, hashing-based approaches, commonly used in applications like NLP and recommender systems, can potentially be used. However, a direct application of these ideas fails to exploit the fact that in many real-world graphs, nodes that are topologically close will tend to be related to each other (homophily) and as such their representations will be similar. In this work, we present approaches that take advantage of the nodes' position in the graph to dramatically reduce the memory required, with minimal if any degradation in the quality of the resulting GNN model. Our approaches decompose a node's embedding into two components: a position-specific component and a node-specific component. The position-specific component models homophily and the node-specific component models the node-to-node variation. Extensive experiments using different datasets and GNN models show that our methods are able \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:6Zm5LS9gQ5UC",
            "Publisher": "Unknown"
        },
        {
            "Title": "TR 11-O07",
            "Publication year": 2011,
            "Publication url": "https://scholar.google.com/scholar?cluster=5690540893795954187&hl=en&oi=scholarr",
            "Abstract": "Identifying medical conditions that are correlated with vaccine adverse reactions can not only provide better understanding of how adverse reactions are triggered but also have the potential of detecting new adverse reactions that are otherwise hidden.\\Ve formulate this problem as mining frequent patterns with constraints. The major constraint we use is called the minimum dual-lift constraint, where dualis novel measure we propose to evaluate correlations in a pattern. VVe also introduce the notation of minimum improvement constraint to remove redundancy in generated pattern set. We come up with a novel approach to upper bound the dual-lift measure which helps to prune the search space. Experimental results show that our algorithm works signi\ufb01cantly better than the baseline on dense datasets. Our algorithm is also tested on the real world VAERS database. Some interesting vaccine adverse reactions \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:9c2xU6iGI7YC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Comparison of agglomerative and partitional document clustering algorithms",
            "Publication year": 2002,
            "Publication url": "https://apps.dtic.mil/sti/citations/ADA439503",
            "Abstract": "Fast and high-quality document clustering algorithms play an important role in providing intuitive navigation and browsing mechanisms by organizing large amounts of information into a small number of meaningful clusters, and in greatly improving the retrieval performance either via cluster-driven dimensionality reduction, term-weighting, or query expansion. This ever-increasing importance of document clustering and the expanded range of its applications led to the development of a number of novel algorithms and new clustering criterion functions, especially in the context of partitional clustering. The focus of this paper is to experimentally evaluate the performance of seven different global criterion functions in the context of agglomerative clustering algorithms and compare the clustering results of agglomerative algorithms and partitional algorithms for each one of the criterion functions. Our experimental evaluation shows that for every criterion function, partitional algorithms always lead to better clustering results than agglomerative algorithms, which suggests that partitional clustering algorithms are well-suited for clustering large document datasets due to not only their relatively low computational requirements, but also comparable or even better clustering performance.Descriptors:",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:M3NEmzRMIkIC",
            "Publisher": "MINNESOTA UNIV MINNEAPOLIS DEPT OF COMPUTER SCIENCE"
        },
        {
            "Title": "TR O6-O08",
            "Publication year": 2006,
            "Publication url": "https://scholar.google.com/scholar?cluster=10958171180493840009&hl=en&oi=scholarr",
            "Abstract": "ln recent years the development of computational techniques that build models to correctly assign chemical compounds to various classes or to retrieve potential drug-like compounds has been an active area of research. These techniques are used extensively at various phases during the drug development process. Many of the best-performing techniques for these tasks, utilize a descriptor-based representation of the compound that captures various aspects of the underlying molecular graph\u2019s topology. In this paper we introduce and describe algorithms for ef\ufb01ciently generating a new set of descriptors that are derived from all connected acyclic fragments present in the molecular graphs. In addition, we introduce an extension to existing vector-based kernel functions to take into account the length of the fragments present in the descriptors. We experimentally evaluate the performance of the new \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:gKiMpY-AVTkC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Mining Scientific Datasets Using Graphs",
            "Publication year": 2003,
            "Publication url": "https://scholar.google.com/scholar?cluster=2856255459098682025&hl=en&oi=scholarr",
            "Abstract": "As data mining techniques are being increasingly applied to scientific and other non-traditional domains, it is becoming apparent that existing approaches for modeling the characteristics of the underlying physical phenomena and processes cannot be used as they cannot model the requirement of these domains. An alternate way is to use graphs to capture in a single and unified framework many of the spatial, topological, geometric, and other types of relational characteristics present in such datasets. The added power provided by graph-modeling can only be realized if computationally efficient and scalable algorithms for many of the classical data-mining tasks, such as frequent pattern discovery, clustering, and classification, become available. In this paper we present some of our research on developing algorithms for finding frequently occurring patterns and building predictive models for graph datasets.",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:j8SEvjWlNXcC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Web search based on ranking",
            "Publication year": 2015,
            "Publication url": "https://books.google.com/books?hl=en&lr=&id=BvYYCwAAQBAJ&oi=fnd&pg=PA67&dq=info:NyoWqIoJRqEJ:scholar.google.com&ots=AcV468PgSJ&sig=yDVivsJCxQyYKLnR9K9Z453D3hE",
            "Abstract": "Web search is the process of identifying and ranking the web pages that are the most relevant to a user\u2019s query. Though this is similar to the task performed by traditional Information Retrieval (IR) systems, the nature of the underlying document collection (ie, the Web) and the widely varying needs and characteristics of its users, have made web search a research field of its own.",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:cBPnxVikjH8C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Introduction to Protein Structure Prediction: Methods and Algorithms",
            "Publication year": 2010,
            "Publication url": "https://scholar.google.com/scholar?cluster=15777357296503866657&hl=en&oi=scholarr",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:5F1dSjz1ScoC",
            "Publisher": "Wiley"
        },
        {
            "Title": "Implicit Heuristics to Mitigate Interconnect Congestion in a Multilevel Placement Framework",
            "Publication year": 2004,
            "Publication url": "https://conservancy.umn.edu/handle/11299/215629",
            "Abstract": "The congestion minimization techniques have become more important due to the shrinking geometries and ``taller'' interconnects, causing numerous design convergence problems. Also, multilevel placement algorithms are becoming more prevalant due to their ability to natively incorporate mixed-mode placement, in addition to their ability to scale to very large design sizes. In this context, we have developed a number of implicit heuristics for minimizing congestion in the process of enhancing an existing industrial multilevel placment tool (Dolphin). In contrast to the explicit congestion heuristics that explicity measure congestion either by stochastic estimators or by approximate global routing, our techniques primarily rely on pre-emptively identifying congestion-prone clusters and making amends to them. Essentially, we intervene during the clustering phase of the multilevel placement to identify such congestion-prone clusters and try to increase the supply of routing resources to those clusters. Increasing the supply of routing resources can be done by whitespace injection. Cell/cluster inflation is however, not a new technique, but what is new in our techniques is that we inflate the clusters {em before} any placement information is obtained. In addition to the effective schemes of cluster inflation that reduce congestion substantially (upto 25% on average), we have also modified the clustering formulation to generate clusters that are less prone to congestion. These new clustering schemes do not use any additional area and as a result a more attractive option for designs with very high utilization. The non-use of addtional whitespace does not mean \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:NnTm98qLMbgC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Feature mining for prediction of degree of liver fibrosis",
            "Publication year": 2005,
            "Publication url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1560528/",
            "Abstract": "Liver cirrhosis is a common lethal disease that is most often caused by alcoholism and viral hepatitis. Life expectancy is greatly influenced by the degree of liver fibrosis, which usually ranges from F0 (no fibrosis) to F4 (liver cirrhosis). The most accurate way of measuring fibrosis is by liver biopsy. However, due to its invasive nature liver biopsy is not performed frequently, and for this reason physicians rely on less accurate laboratory tests, with their inherent deficiencies. The goal of our work is to develop advanced data mining techniques that combine information provided from individual laboratory tests thereby increasing their diagnostic accuracy. We believe that such techniques hold the promise of empowering physicians to improve diagnostic processes without the need for invasive procedures. In this abstract we report on our first efforts to build a decision support system to assist physicians in predicting the \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:JQOojiI6XY0C",
            "Publisher": "American Medical Informatics Association"
        },
        {
            "Title": "Multiobjective hypergraph-partitioning algorithms for cut and maximum subdomain-degree minimization",
            "Publication year": 2006,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/1597385/",
            "Abstract": "In this paper, we present a family of multiobjective hypergraph-partitioning algorithms based on the multilevel paradigm, which are capable of producing solutions in which both the cut and the maximum subdomain degree are simultaneously minimized. This type of partitionings are critical for existing and emerging applications in very large scale integration (VLSI) computer-aided design (CAD) as they allow to both minimize and evenly distribute the interconnects across the physical devices. Our experimental evaluation on the International Symposium on Physical Design (ISPD98) benchmark show that our algorithms produce solutions, which when compared against those produced by hM/sub E/T/sub I/S have a maximum subdomain degree that is reduced by up to 36% while achieving comparable quality in terms of cut.",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:TQgYirikUcIC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Item-based collaborative filtering recommendation algorithms. 2001",
            "Publication year": 2007,
            "Publication url": "https://scholar.google.com/scholar?cluster=13081011208376467122&hl=en&oi=scholarr",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:1paMEeroeoQC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Predicting Local Structure and Function of Proteins",
            "Publication year": 2009,
            "Publication url": "https://www.taylorfrancis.com/chapters/edit/10.1201/9781420086850-12/predicting-local-structure-function-proteins-huzefa-rangwala-george-karypis",
            "Abstract": "Proteins have a vast influence on the molecular machinery of life. Stunningly complex networks of proteins perform innumerable functions in every living cell. Knowing the function and structure of proteins is crucial for the development of improved drugs, better crops, and even synthetic biofuels. As such, knowledge of protein structure and function leads to crucial advances in life sciences and biology.With rapid strides made in large scale sequencing technologies, we have seen an exponential increase in the available protein sequence information. Protein structures are primarily determined using X-ray crystallography or NMR spectroscopy, but these methods are time consuming, expensive and not feasible for all proteins. The experimental approaches to determine protein function (eg, gene knockout, targeted mutation, and inhibitions of gene expression studies) are low throughput in nature [21]. As such, our \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:HIFyuExEbWQC",
            "Publisher": "Chapman and Hall/CRC"
        },
        {
            "Title": "Improving Higher Education: Learning Analytics & Recommender Systems Research",
            "Publication year": 2017,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/3109859.3109870",
            "Abstract": "An enduring issue in higher education is student retention to successful graduation. Studies in the US report that average six-year graduation rates across higher-education institutions is 59% and have remained relatively stable over the last 15 years. For those that do complete a college degree, less than half complete within four-years. Requiring additional terms or leaving college without receiving a bachelor's degree has high human and monetary costs and deprives students from the economic benefits of a college credential (over $1 million in a lifetime and even higher in STEM fields). Moreover, when students do not succeed in graduating, local and national communities struggle to create an educated workforce. Estimates indicate that by 2020 over 64% of the jobs in the US will require at least some post-secondary education. These challenges have been recognized by the US National Research Council \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:cNe27ouKFcQC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Pareto optimal pairwise sequence alignment",
            "Publication year": 2013,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/6407131/",
            "Abstract": "Sequence alignment using evolutionary profiles is a commonly employed tool when investigating a protein. Many profile-profile scoring functions have been developed for use in such alignments, but there has not yet been a comprehensive study of Pareto optimal pairwise alignments for combining multiple such functions. We show that the problem of generating Pareto optimal pairwise alignments has an optimal substructure property, and develop an efficient algorithm for generating Pareto optimal frontiers of pairwise alignments. All possible sets of two, three, and four profile scoring functions are used from a pool of 11 functions and applied to 588 pairs of proteins in the ce_ref data set. The performance of the best objective combinations on ce_ref is also evaluated on an independent set of 913 protein pairs extracted from the BAliBASE RV11 data set. Our dynamic-programming-based heuristic approach produces \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:F2UWTTQJPOcC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Grew: A scalable frequent subgraph discovery algorithm",
            "Publication year": 2004,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/1410330/",
            "Abstract": "Existing algorithms that mine graph datasets to discover patterns corresponding to frequently occurring subgraphs can operate efficiently on graphs that are sparse, contain a large number of relatively small connected components, have vertices with low and bounded degrees, and contain well-labeled vertices and edges. However, for graphs that do not share these characteristics, these algorithms become highly unscalable. In this paper we present a heuristic algorithm called GREW to overcome the limitations of existing complete or heuristic frequent subgraph discovery algorithms. GREW is designed to operate on a large graph and to find patterns corresponding to connected subgraphs that have a large number of vertex-disjoint embeddings. Our experimental evaluation shows that GREW is efficient, can scale to very large graphs, and find non-trivial patterns.",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:pqnbT2bcN3wC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Load balancing across near-homogeneous multi-resource servers",
            "Publication year": 2000,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/843733/",
            "Abstract": "An emerging model for computational grids interconnects similar multi-resource servers from distributed sites. A job submitted to the grid can be executed by any of the servers; however, resource size or balance may be different across servers. One approach to resource management for this grid is to layer a global load distribution system on top of the local job management systems at each site. Unfortunately, classical load distribution policies fail on two aspects when applied to a multi-resource server grid First, simple load indices may not recognize that a resource imbalance exists at a server. Second, classical job selection policies do not actively correct such a resource-imbalanced state. We show through simulation that new policies based on resource balancing perform consistently better than the classical load distribution strategies.",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:g5m5HwL7SMYC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Scalable Label Propagation for Multi-relational Learning on the Tensor Product of Graphs",
            "Publication year": 2021,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/9369895/",
            "Abstract": "Multi-relational learning on knowledge graphs infers high-order relations among the entities across the graphs. This learning task can be solved by label propagation on the tensor product of the knowledge graphs to learn the high-order relations as a tensor. In this paper, we generalize a widely used label propagation model to the normalized tensor product graph, and propose an optimization formulation and a scalable Low-rank Tensor-based Label Propagation algorithm (LowrankTLP) to infer multi-relations for two learning tasks, hyperlink prediction and multiple graph alignment. The optimization formulation minimizes the upper bound of the noisy tensor estimation error for multiple graph alignment, by learning with a subset of the eigen-pairs in the spectrum of the normalized tensor product graph. We also provide a data-dependent transductive Rademacher bound for binary hyperlink prediction. We accelerate \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:rqnDXT1GswoC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Improved machine learning models for predicting selective compounds",
            "Publication year": 2012,
            "Publication url": "https://pubs.acs.org/doi/abs/10.1021/ci200346b",
            "Abstract": "The identification of small potent compounds that selectively bind to the target under consideration with high affinities is a critical step toward successful drug discovery. However, there is still a lack of efficient and accurate computational methods to predict compound selectivity properties. In this paper, we propose a set of machine learning methods to do compound selectivity prediction. In particular, we propose a novel cascaded learning method and a multitask learning method. The cascaded method decomposes the selectivity prediction into two steps, one model for each step, so as to effectively filter out nonselective compounds. The multitask method incorporates both activity and selectivity models into one multitask model so as to better differentiate compound selectivity properties. We conducted a comprehensive set of experiments and compared the results with those of other conventional selectivity prediction \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:nVrZBo8bIpAC",
            "Publisher": "American Chemical Society"
        },
        {
            "Title": "MGRIDGEN PARMGRIDGEN",
            "Publication year": 2001,
            "Publication url": "https://www.researchgate.net/profile/George-Karypis-2/publication/242356130_MGRIDGEN_PARMGRIDGEN_SerialParallelLibraryforGeneratingCoarseGrids_forMultigridMethods/links/56a3a99a08aef91c8c12c7e6/MGRIDGEN-PARMGRIDGEN-Serial-ParallelLibraryforGeneratingCoarseGrids-forMultigridMethods.pdf",
            "Abstract": "MGRIDGEN and PARMGRIDGEN are serial and parallel software packages that implement various algorithms for generating a sequence of coarse grids. The generated coarse grids contain well-shaped elements and thus they are well-suited for geometric multigrid methods. PARMGRIDGEN is an MPI-based parallel library that is based on the serial package MGRIDGEN and it is suited for parallel numerical simulations involving large unstructured grids since the algorithms incur a very small communication overhead, achieve high degree of concurrency and maintain the high quality of the coarse grids obtained by the serial algorithms in the MGRIDGEN library. This manual is organized as follows. In Section 2 we briefly describe the serial algorithms of MGRIDGEN and the parallel approach to the problem of coarse grid construction. In Section 3 we describe the use of the standalone programs, provided with MGRIDGEN and PARMGRIDGEN, to compute coarse grids. Section 4 describes the format of the basic parameters that are supplied to the routines. Section 5 provides a detailed description of the calling sequence of the functions in both libraries. Finally, Section 6 describes what other libraries you need in order to run MGRIDGEN and PARMGRIDGEN and provides contact information.",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:Yw6v6SrDvuUC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Genome alignments using MPI-LAGAN",
            "Publication year": 2008,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/4684935/",
            "Abstract": "We develop a parallel algorithm for a widely used whole genome alignment method called LAGAN. We use the MPI-based protocol to develop parallel solutions for two phases of the algorithm which take up a significant portion of the total runtime, and also have a high memory requirement. The serial LAGAN program uses CHAOS to quickly determine initial anchor or seeds, which are extended using a sparse dynamic programming based longest-increasing subsequence method. Our work involves parallelizing the CHAOS and LIS phases of the algorithm using a one-dimensional block cyclic partitioning of the computation. This leads to development of an efficient algorithm that utilizes the processors in a balanced way. We also ensure minimum time spent in communication or transfer of information across processors.We also report experimental evaluation of our parallel implementation using pairs of human \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:umqufdRvDiIC",
            "Publisher": "IEEE"
        },
        {
            "Title": "SLPMiner: An algorithm for finding frequent sequential patterns using length-decreasing support constraint",
            "Publication year": 2002,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/1183937/",
            "Abstract": "Over the years, a variety of algorithms for finding frequent sequential patterns in very large sequential databases have been developed. The key feature in most of these algorithms is that they use a constant support constraint to control the inherently exponential complexity of the problem. In general, patterns that contain only a few items will tend to be interesting if they have good support, whereas long patterns can still be interesting even if their support is relatively small. Ideally, we need an algorithm that finds all the frequent patterns whose support decreases as a function of their length. In this paper we present an algorithm called SLPMiner that finds all sequential patterns that satisfy a length-decreasing support constraint. Our experimental evaluation shows that SLPMiner achieves up to two orders of magnitude of speedup by effectively exploiting the length-decreasing support constraint, and that its runtime \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:e5wmG9Sq2KIC",
            "Publisher": "IEEE"
        },
        {
            "Title": "TraverseNet: Unifying Space and Time in Message Passing",
            "Publication year": 2021,
            "Publication url": "https://arxiv.org/abs/2109.02474",
            "Abstract": "This paper aims to unify spatial dependency and temporal dependency in a non-Euclidean space while capturing the inner spatial-temporal dependencies for spatial-temporal graph data. For spatial-temporal attribute entities with topological structure, the space-time is consecutive and unified while each node's current status is influenced by its neighbors' past states over variant periods of each neighbor. Most spatial-temporal neural networks study spatial dependency and temporal correlation separately in processing, gravely impaired the space-time continuum, and ignore the fact that the neighbors' temporal dependency period for a node can be delayed and dynamic. To model this actual condition, we propose TraverseNet, a novel spatial-temporal graph neural network, viewing space and time as an inseparable whole, to mine spatial-temporal graphs while exploiting the evolving spatial-temporal dependencies for each node via message traverse mechanisms. Experiments with ablation and parameter studies have validated the effectiveness of the proposed TraverseNets, and the detailed implementation can be found from https://github.com/nnzhan/TraverseNet.",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:F9HO9s0W2bwC",
            "Publisher": "Unknown"
        },
        {
            "Title": "FERN: Fair Team Formation for Mutually Beneficial Collaborative Learning",
            "Publication year": 2020,
            "Publication url": "https://arxiv.org/abs/2011.11611",
            "Abstract": "Automated Team Formation is becoming increasingly important for a plethora of applications in open source community projects, remote working platforms, as well as online educational systems. The latter case, in particular, poses significant challenges that are specific to the educational domain. Indeed, teaming students aims to accomplish far more than the successful completion of a specific task. It needs to ensure that all members in the team benefit from the collaborative work, while also ensuring that the participants are not discriminated with respect to their protected attributes, such as race and gender. Towards achieving these goals, this work introduces FERN, a fair team formation approach that promotes mutually beneficial peer learning, dictated by protected group fairness as equality of opportunity in collaborative learning. We formulate the problem as a multi-objective discrete optimization problem. We show this problem to be NP-hard and propose a heuristic hill-climbing algorithm. Extensive experiments on both synthetic and real-world datasets against well-known team formation techniques show the effectiveness of the proposed method.",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:WM2K3OHRCGMC",
            "Publisher": "Unknown"
        },
        {
            "Title": "A comprehensive survey of neighborhood-based recommendation methods",
            "Publication year": 2015,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-1-4899-7637-6_2",
            "Abstract": "Among collaborative recommendation approaches, methods based on nearest-neighbors still enjoy a huge amount of popularity, due to their simplicity, their efficiency, and their ability to produce accurate and personalized recommendations. This chapter presents a comprehensive survey of neighborhood-based methods for the item recommendation problem. In particular, the main benefits of such methods, as well as their principal characteristics, are described. Furthermore, this document addresses the essential decisions that are required while implementing a neighborhood-based recommender system, and gives practical information on how to make such decisions. Finally, the problems of sparsity and limited coverage, often observed in large commercial recommender systems, are discussed, and some solutions to overcome these problems are presented.",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:qmtmRrLr0tkC",
            "Publisher": "Springer, Boston, MA"
        },
        {
            "Title": "Opening Remarks",
            "Publication year": 2006,
            "Publication url": "http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.92.9694",
            "Abstract": "Data Mining is the process of automatic discovery of novel and understandable models and patterns from large amounts of data. Bioinformatics is the science of storing, analyzing, and utilizing information from biological data such as sequences, molecules, gene expressions, and pathways. Development of novel data mining methods will play a fundamental role in understanding these rapidly expanding sources of biological data. The goal of this workshop is to encourage KDD researchers to take on the numerous challenges that Bioinformatics offers. The workshop will feature invited talks from noted experts in the field, and the latest data mining research in bioinformatics. We encourage papers that propose novel data mining techniques for tasks like: Gene expression analysis Protein/RNA structure prediction Phylogenetics Sequence and structural motifs",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:j7XjBeKFbTsC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Introduction to protein structure prediction: methods and algorithms",
            "Publication year": 2011,
            "Publication url": "Unknown",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:ILKRHgRFtOwC",
            "Publisher": "John Wiley & Sons"
        },
        {
            "Title": "TR O2-O24",
            "Publication year": 2002,
            "Publication url": "https://scholar.google.com/scholar?cluster=7747790480479155308&hl=en&oi=scholarr",
            "Abstract": "As data mining techniques are being increasingly applied to non-traditional domains, existing approaches for \ufb01nding frequent itemsets cannot be used as they cannot model the requirement of these domains. An alternate way of modeling the objects in these data sets, is to use a graph to model the database objects. V\\/ithin that model, the problem of \ufb01nding frequent patterns becomes that of discovering subgraphs that occur frequently over the entire set of graphs. In this paper we present a computationally ef\ufb01cient algorithm for \ufb01nding frequent geometric subgraphs in a large collection of geometric graphs. Our algorithm is able to discover geometric subgraphs that can be rotation, scaling and translation invariant, and it can accommodate inherent errors 011 the coordinates of the vertices. We evaluated the performance of the algorithm using a large database of over 20,000 real two dimensional chemical structures \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:KbBQZpvPDL4C",
            "Publisher": "Unknown"
        },
        {
            "Title": "A Memory Management System Optimized for BDMPI's Memory and Execution Model",
            "Publication year": 2015,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/2802658.2802666",
            "Abstract": "There is a growing need to perform large computations on small systems, as access to large systems is not widely available and cannot keep up with the scaling of data. BDMPI was recently introduced as a way of achieving this for applications written in MPI. BDMPI allows the efficient execution of standard MPI programs on systems whose aggregate amount of memory is smaller than that required by the computations and significantly outperforms other approaches. In this paper we present a virtual memory subsystem which we implemented as part of the BDMPI runtime. Our new virtual memory subsystem, which we call SBMA, bypasses the operating system virtual memory manager to take advantage of BDMPI's node-level cooperative multi-taking. Benchmarking using a synthetic application shows that for the use cases relevant to BDMPI, the overhead incurred by the BDMPI-SBMA system is amortized such that it \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:QoJ_w57xiyAC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Dynamic programming",
            "Publication year": 2003,
            "Publication url": "http://www.cs.purdue.edu/homes/ayg/book/Slides/chap12_slides.pdf",
            "Abstract": "Dynamic Programming Page 1 Dynamic Programming Ananth Grama, Anshul Gupta, George \nKarypis, and Vipin Kumar To accompany the text \u201cIntroduction to Parallel Computing\u201d, Addison \nWesley, 2003. Page 2 Topic Overview \u2022 Overview of Serial Dynamic Programming \u2022 Serial \nMonadic DP Formulations \u2022 Nonserial Monadic DP Formulations \u2022 Serial Polyadic DP \nFormulations \u2022 Nonserial Polyadic DP Formulations Page 3 Overview of Serial Dynamic \nProgramming \u2022 Dynamic programming (DP) is used to solve a wide variety of discrete optimization \nproblems such as scheduling, stringediting, packaging, and inventory management. \u2022 Break \nproblems into subproblems and combine their solutions into solutions to larger problems. \u2022 In \ncontrast to divide-and-conquer, there may be relationships across subproblems. Page 4 Dynamic \nProgramming: Example \u2022 Consider the problem of finding a shortest path between a pair . (\u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:h168fVGZblEC",
            "Publisher": "Unknown"
        },
        {
            "Title": "A 2D parallel triangle counting algorithm for distributed-memory architectures",
            "Publication year": 2019,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/3337821.3337853",
            "Abstract": "Triangle counting is a fundamental graph analytic operation that is used extensively in network science and graph mining. As the size of the graphs that needs to be analyzed continues to grow, there is a requirement in developing scalable algorithms for distributed-memory parallel systems. To this end, we present a distributed-memory triangle counting algorithm, which uses a 2D cyclic decomposition to balance the computations and reduce the communication overheads. The algorithm structures its communication and computational steps such that it reduces its memory overhead and includes key optimizations that leverage the sparsity of the graph and the way the computations are structured. Experiments on synthetic and real-world graphs show that our algorithm obtains an average relative speedup range between 3.24 to 7.22 out of 10.56 across the datasets using 169 MPI ranks over the performance \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:Nnq8S6OXqDYC",
            "Publisher": "Unknown"
        },
        {
            "Title": "9th IEEE International Workshop on High Performance Computational Biology HiCOMB 2010 April 19, 2010 Downtown Sheraton, Atlanta Georgia, USA",
            "Publication year": 2010,
            "Publication url": "http://hicomb.org/HiCOMB2007/papers/HICOMB2010-00.pdf",
            "Abstract": "Welcome to the 9th International Workshop on High Performance Computational Biology (HiCOMB). Computational Biology and related disciplines are fast emerging as an important area for academic research and industrial application. The large size of biological data sets, the inherent complexity of biological problems, and the ability to deal with error-prone data require the development of novel parallel algorithms in order to address the underlying computational and memory requirements. The goal of this workshop is to provide a forum for discussion of latest research in developing high-performance computing solutions to problems arising from molecular biology and related life sciences areas.The technical program was put together by Program Chair George Karypis and eighteen members of a distinguished program committee. This year we received a total of sixteen submissions. Each of the papers were \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:rbGdIwl2e6cC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Preface in bioinformatics",
            "Publication year": 2005,
            "Publication url": "https://experts.umn.edu/en/publications/preface-in-bioinformatics",
            "Abstract": "Preface in bioinformatics \u2014 Experts@Minnesota Skip to main navigation Skip to search Skip to \nmain content Experts@Minnesota Logo Home Profiles Research Units University Assets \nProjects and Grants Research output Press / Media Datasets Activities Fellowships, Honors, and \nPrizes Search by expertise, name or affiliation Preface in bioinformatics Nikolaos G. Bourbakis, \nGeorge Karypis Computer Science and Engineering Research output: Contribution to journal \u203a \nEditorial \u203a peer-review 1 Scopus citations Overview Fingerprint Original language English (US) \nPages (from-to) 559-560 Number of pages 2 Journal International Journal on Artificial \nIntelligence Tools Volume 14 Issue number 4 DOIs https://doi.org/10.1142/s0218213005002259 \nState Published - Aug 2005 Access 10.1142/s0218213005002259 Cite this APA Standard \nHarvard Vancouver Author BIBTEX RIS Bourbakis, NG, & Karypis, G. (2005). Preface \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:DQNrXyjhriIC",
            "Publisher": "World Scientific Publishing Co. Pte Ltd"
        },
        {
            "Title": "Implicit Heuristics to Mitigate Interconnect Congestion in a Multilevel Placement Framework",
            "Publication year": 2004,
            "Publication url": "https://scholar.google.com/scholar?cluster=7778895762988530631&hl=en&oi=scholarr",
            "Abstract": "The congestion minimization techniques have become more important due to the shrinking geometries and \u201ctaller\u201d interconnects, causing numerous design convergence problems. Also, multilevel placement algorithms are becoming more prevalant due to their ability to natively incorporate mixed-mode placement, in addition to their ability to scale to very large design sizes. In this context, we have developed a number of implicit heuristics for minimizing congestion in the process of fortifying an existing industrial multilevel placment tool (Dolphin). In contrast to the explicit congestion heuristics that explicity measure congestion either by stochastic estimators or by approximate global routing, our techniques primarily rely on pre-emptively identifying congestion prone clusters and making amends to them. Essentially, we intervene during the clustering phase of the multilevel placement to identify such congestion prone \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:6bLC7aUMtPcC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Coherent closed quasi-clique discovery from large dense graph databases",
            "Publication year": 2006,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/1150402.1150506",
            "Abstract": "Frequent coherent subgraphs can provide valuable knowledge about the underlying internal structure of a graph database, and mining frequently occurring coherent subgraphs from large dense graph databases has been witnessed several applications and received considerable attention in the graph mining community recently. In this paper, we study how to efficiently mine the complete set of coherent closed quasi-cliques from large dense graph databases, which is an especially challenging task due to the downward-closure property no longer holds. By fully exploring some properties of quasi-cliques, we propose several novel optimization techniques, which can prune the unpromising and redundant sub-search spaces effectively. Meanwhile, we devise an efficient closure checking scheme to facilitate the discovery of only closed quasi-cliques. We also develop a coherent closed quasi-clique mining algorithm \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:NMxIlDl6LWMC",
            "Publisher": "Unknown"
        },
        {
            "Title": "WSMP: Watson sparse matrix package (Part-III: iterative solution of sparse systems)",
            "Publication year": 2007,
            "Publication url": "https://scholar.google.com/scholar?cluster=15594883376665175334&hl=en&oi=scholarr",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:t-hv7AR41mYC",
            "Publisher": "Technical Report RC-24398, IBM TJ Watson Research Center, Yorktown Heights, NY"
        },
        {
            "Title": "Affinity-based Structure-Activity-Relationship Models: Improving Structure-Activity-Relationship Models by Incorporating Activity Information from Related Targets",
            "Publication year": 2009,
            "Publication url": "https://conservancy.umn.edu/handle/11299/215804",
            "Abstract": "Structure-activity-relationship SAR models are used to inform and guide the iterative optimization of chemical leads, and play a fundamental role in modern drug discovery. In this paper we present a new class of methods for building SAR models, referred to as affinity-based, that utilize activity information from different targets. These methods first identify a set of targets that are related to the target under consideration and then they employ various machine-learning techniques that utilize activity information from these targets in order to build the desired SAR model. We developed different methods for identifying the set of related targets, which take into account the primary sequence of the targets or the structure of their ligands,and we also developed different machine learning techniques that were derived by using principles of semi-supervised learning, multi-task learning, and classifier ensembles.The comprehensive evaluation of these methods shows that they lead to considerable improvements over the standard SAR models that are based only on the ligands of the target under consideration. On a set of 117 protein targets obtained from PubChem, these affinity-based methods achieve an ROC score that is on the average 7.0% - 7.2% higher than that achieved by the standard SAR models. Moreover, on a set of targets belonging to six protein families, the affinity-based methods outperform chemogenomics-based approaches by 4.33%.",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:bz8QjSJIRt4C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Message from the conference chairs",
            "Publication year": 2017,
            "Publication url": "https://experts.umn.edu/en/publications/message-from-the-conference-chairs",
            "Abstract": "Karypis, G & Miele, L 2017,'Message from the conference chairs', Proceedings-IEEE International Conference on Data Mining, ICDM, vol. 2017-November, pp. xvi-xvii. https://doi. org/10.1109/ICDM. 2017.5",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:MGPUR4WVBMEC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Distributed representation of multi-sense words: A loss driven approach",
            "Publication year": 2018,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-319-93037-4_27",
            "Abstract": "Word2Vec\u2019s Skip Gram model is the current state-of-the-art approach for estimating the distributed representation of words. However, it assumes a single vector per word, which is not well-suited for representing words that have multiple senses. This work presents LDMI, a new model for estimating distributional representations of words. LDMI relies on the idea that, if a word carries multiple senses, then having a different representation for each of its senses should lead to a lower loss associated with predicting its co-occurring words, as opposed to the case when a single vector representation is used for all the senses. After identifying the multi-sense words, LDMI clusters the occurrences of these words to assign a sense to each occurrence. Experiments on the contextual word similarity task show that LDMI leads to better performance than competing approaches.",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:Vztgr1qGG8IC",
            "Publisher": "Springer, Cham"
        },
        {
            "Title": "Promoter Prediction of Prokaryotes",
            "Publication year": 2001,
            "Publication url": "https://conservancy.umn.edu/handle/11299/215479",
            "Abstract": "The availability of computational methods to identify and define the precise structure and location of promoters in prokaryotic genomes will provide a critical first step towards understanding the mechanisms by which genes are organized and regulated.  We examine three different methods for promoter identification, two of which are adopted from related work and the other is a novel approach based on feature extraction.  By the results of a set of experiments we evaluated prediction accuracy for identifying promoter regions fromnon-coding regions.",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:SpPTWFSNUtQC",
            "Publisher": "Unknown"
        },
        {
            "Title": "A novel two-box search paradigm for query disambiguation",
            "Publication year": 2013,
            "Publication url": "https://link.springer.com/article/10.1007/s11280-011-0154-0",
            "Abstract": "Precision-oriented search results such as those typically returned by the major search engines are vulnerable to issues of polysemy. When the same term refers to different things, the dominant sense is preferred in the rankings of search results. In this paper, we propose a novel two-box technique in the context of Web search that utilizes contextual terms provided by users for query disambiguation, making it possible to prefer other senses without altering the original query. A prototype system, Bobo, has been implemented. In Bobo, contextual terms are used to capture domain knowledge from users, help estimate relevance of search results, and route them towards a user-intended domain. A vast advantage of Bobo is that a wide range of domain knowledge can be effectively utilized, where helpful contextual terms do not even need to co-occur with query terms on any page. We have extensively evaluated \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:a9-T7VOCCH8C",
            "Publisher": "Springer US"
        },
        {
            "Title": "Fast supervised dimensionality reduction algorithm with applications to document categorization & retrieval",
            "Publication year": 2000,
            "Publication url": "https://dl.acm.org/doi/pdf/10.1145/354756.354772",
            "Abstract": "Retriev al techniques based on dimensionality reduction, such as Latent Semantic Indexing (LSI), have been shown to improve the quality of the information being retrieved by capturing the latent meaning of the words present in the documents. Unfortunately, the high computational and memory requirements of LSI and its inabilit yto compute an effective dimensionality reduction in a supervised setting limits its applicability. In this paper we present a fast supervised dimensionality reduction algorithm that is derived from the recently dev eloped cluster-based unsupervised dimensionality reduction algorithms. We experimentally evaluate the quality of the low er dimensional spaces both in the context of document categorization and improvements in retrieval performance on a variety of different document collections. Our experiments show that the lower dimensional spaces computed by our algorithm consistently \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:RHpTSmoSYBkC",
            "Publisher": "Unknown"
        },
        {
            "Title": "gCLUTO: An interactive clustering, visualization, and analysis system",
            "Publication year": 2004,
            "Publication url": "https://conservancy.umn.edu/handle/11299/215615",
            "Abstract": "Clustering algorithms are exploratory data analysis tools that have proved to be essential for gaining valuable insights on various aspects and relationships of the underlying systems. In this paper we present gCLUTO, a stand-alone clustering software package which serves as an easy-to-use platform that combines clustering algorithms along with a number of analysis, reporting, and visualization tools to aid in interactive exploration and clustering-driven analysis of large datasets. gCLUTO provides a wide-range of algorithms that operate either directly on the original feature-based representation of the objects or on the object-to-object similarity graphs and are capable of analyzing different types of datasets and finding clusters with different characteristics. In addition, gCLUTO implements a project-oriented work-flow that eases the process of data analysis.",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:yD5IFk8b50cC",
            "Publisher": "Unknown"
        },
        {
            "Title": "EX3: Explainable Attribute-aware Item-set Recommendations",
            "Publication year": 2021,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/3460231.3474240",
            "Abstract": "Existing recommender systems in the e-commerce domain primarily focus on generating a set of relevant items as recommendations; however, few existing systems utilize underlying item attributes as a key organizing principle in presenting recommendations to users. Mining important attributes of items from customer perspectives and presenting them along with item sets as recommendations can provide users more explainability and help them make better purchase decision. In this work, we generalize the attribute-aware item-set recommendation problem, and develop a new approach to generate sets of items (recommendations) with corresponding important attributes (explanations) that can best justify why the items are recommended to users. In particular, we propose a system that learns important attributes from historical user behavior to derive item set recommendations, so that an organized view of \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:oXKBmVzQOggC",
            "Publisher": "Unknown"
        },
        {
            "Title": "TR O8-O35",
            "Publication year": 2008,
            "Publication url": "https://scholar.google.com/scholar?cluster=1474301729955853387&hl=en&oi=scholarr",
            "Abstract": "Drug discovery is an expensive process. It has been estimated that a new drug compound that is introduced in the market after FDA approval carries a cost of approximately $800 million from the conception of target implicated for a disease to successful identi\ufb01cation of chemical entity or drug that is successful in human trials. There is a need to cut the cost of developing new drugs (to bring overall cost lower for the producers and consumers alike) by identifying promising candidate targets as well as compounds and to tackle problems such an toxicity, lack of e\ufb02icacy in humans, and poor physical properties in the early stages ofdrug discovery. In order to achieve this objective, in recent years the development of computational techniques that identify all the likely targets for a given chemical compound has been an active area of research. Identification of all the potential targets for a chemical compound provides \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:Ug5p-4gJ2f0C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Computational tools for protein\u2013DNA interactions",
            "Publication year": 2012,
            "Publication url": "https://onlinelibrary.wiley.com/doi/abs/10.1002/widm.48",
            "Abstract": "Interactions between deoxyribonucleic acid (DNA) and proteins are central to living systems, and characterizing how and when they occur would greatly enhance our understanding of working genomes. We review the computational problems associated with protein\u2013DNA interactions and the various methods used to solve them. A wide range of topics is covered including physics\u2010based models for direct and indirect recognition, identification of transcription\u2010factor\u2010binding sites, and methods to predict DNA\u2010binding proteins. Our goal is to introduce this important problem domain to data mining researchers by identifying the key issues and challenges inherent to the area as well as provide directions for fruitful future research. \u00a9 2011 Wiley Periodicals, Inc.This article is categorized under:  Algorithmic Development > Biological Data Mining Technologies > Machine Learning ",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:zCSUwVk65WsC",
            "Publisher": "John Wiley & Sons, Inc."
        },
        {
            "Title": "SPLATT: Efficient and Parallel Sparse Tensor-Matrix Multiplication",
            "Publication year": 2015,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/7161496/",
            "Abstract": "Multi-dimensional arrays, or tensors, are increasingly found in fields such as signal processing and recommender systems. Real-world tensors can be enormous in size and often very sparse. There is a need for efficient, high-performance tools capable of processing the massive sparse tensors of today and the future. This paper introduces SPLATT, a C library with shared-memory parallelism for three-mode tensors. SPLATT contains algorithmic improvements over competing state of the art tools for sparse tensor factorization. SPLATT has a fast, parallel method of multiplying a matricide tensor by a Khatri-Rao product, which is a key kernel in tensor factorization methods. SPLATT uses a novel data structure that exploits the sparsity patterns of tensors. This data structure has a small memory footprint similar to competing methods and allows for the computational improvements featured in our work. We also present a \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:R-LXmdHK_14C",
            "Publisher": "Unknown"
        },
        {
            "Title": "2nd International Workshop on Industrial Recommendation Systems (IRS)",
            "Publication year": 2021,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/3447548.3469448",
            "Abstract": "Recommendation systems are used widely across many industries, such as e-commerce, multimedia content platforms and social networks, to provide suggestions that a user will most likely consume or connect; thus, improving the user experience. This motivates people in both industry and research organizations to focus on personalization or recommendation algorithms, which has resulted in a plethora of research papers. While academic research mostly focuses on the performance of recommendation algorithms in terms of ranking quality or accuracy, it often neglects key factors that impact how a recommendation system will perform in a real-world environment. These key factors include but are not limited to: business metric definition and evaluation, recommendation quality control, data and model scalability, model interpretability, model robustness and fairness, and resource limitations, such as computing \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:PZE8UkGerEcC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Evaluation of techniques for classifying biological sequences",
            "Publication year": 2002,
            "Publication url": "https://link.springer.com/chapter/10.1007/3-540-47887-6_41",
            "Abstract": "In recent years we have witnessed an exponential increase in the amount of biological information, either DNA or protein sequences, that has become available in public databases. This has been followed by an increased interest in developing computational techniques to automatically classify these large volumes of sequence data into various categories corresponding to either their role in the chromosomes, their structure, and/or their function. In this paper we evaluate some of the widely-used sequence classification algorithms and develop a framework for modeling sequences in a fashion so that traditional machine learning algorithms, such as support vector machines, can be applied easily. Our detailed experimental evaluation shows that the SVM-based approaches are able to achieve higher classification accuracy compared to the more traditional sequence classification algorithms such as Markov \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:rO6llkc54NcC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "Decentralized Autonomous Evaluation Engine for Intellectual Property Assets",
            "Publication year": 2020,
            "Publication url": "https://patents.google.com/patent/US20200250780A1/en",
            "Abstract": "Valuation determinants, including remuneration structures from prior transactions, registrability, and ability to withstand challenge are extracted, analyzed and weighted and loaded into a knowledge base. The knowledge base growing based on a decentralized and public facing approach. Remuneration structures are normalized and used to train predictive algorithms based on a market analysis and previous transactions. The algorithms are able both to learn from previous transactions and to assess the importance of particular valuation determinants in determining the value under particular circumstances. An equitable rate for a new transaction is determined by examining the knowledge base and varying the valuation determinants.",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:dFKc6_kCK1wC",
            "Publisher": "Unknown"
        },
        {
            "Title": "TR O2-O23",
            "Publication year": 2002,
            "Publication url": "https://scholar.google.com/scholar?cluster=10934379678484153020&hl=en&oi=scholarr",
            "Abstract": "Over the years, a variety of algorithms for finding frequent sequential patterns in very large sequential databases have been developed. The key feature in most of these algorithms is that they use a constant support constraint to control the inherently exponential complexity of the problem. In general, patterns that contain only a few items will tend to be interesting ifthey have a high support, whereas long patterns can still be interesting even their support is relatively small. Ideally, we desire to have an algorithm that\ufb01nds all the frequent patterns whose support decreases as afunction of their length. In this paper we present an algorithm called SLPMinet; that \ufb01nds all sequential patterns that satisfy a length-decreasing support constraint. SLPMiner combines an e\ufb01icient database-projection-based approach for sequential pattern discovery with three e\ufb02ective database pruning methods that dramatically reduce the search \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:WAzi4Gm8nLoC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Message from the workshop chairs",
            "Publication year": 2010,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/5470902/",
            "Abstract": "Welcome to the 9th International Workshop on High Performance Computational Biology (HiCOMB). Computational Biology and related disciplines are fast emerging as an important area for academic research and industrial application. The large size of biological data sets, the inherent complexity of biological problems, and the ability to deal with error-prone data require the development of novel parallel algorithms in order to address the underlying computational and memory requirements. The goal of this workshop is to provide a forum for discussion of latest research in developing high-performance computing solutions to problems arising from molecular biology and related life sciences areas.",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:jgBuDB5drN8C",
            "Publisher": "IEEE"
        },
        {
            "Title": "HOSLIM: Higher-Order Sparse LInear Method for Top-N Recommender Systems",
            "Publication year": 2014,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-319-06605-9_4",
            "Abstract": "Current top-N recommendation methods compute the recommendations by taking into account only relations between pairs of items, thus leading to potential unused information when higher-order relations between the items exist. Past attempts to incorporate the higher-order information were done in the context of neighborhood-based methods. However, in many datasets, they did not lead to significant improvements in the recommendation quality. We developed a top-N recommendation method that revisits the issue of higher-order relations, in the context of the model-based Sparse LInear Method (SLIM). The approach followed (Higher-Order Sparse LInear Method, or HOSLIM) learns two sparse aggregation coefficient matrices S and S\u2032 that capture the item-item and itemset-item similarities, respectively. Matrix S\u2032 allows HOSLIM to capture higher-order relations, whose complexity is determined by \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:SxCCDk4iOpsC",
            "Publisher": "Springer, Cham"
        },
        {
            "Title": "Mining chemical compounds",
            "Publication year": 2005,
            "Publication url": "https://link.springer.com/chapter/10.1007/1-84628-059-1_9",
            "Abstract": "In this chapter we study the problem of classifying chemical compound datasets. We present a substructure-based classification algorithm that decouples the substructure discovery process from the classification model construction and uses frequent subgraph discovery algorithms to find all topological and geometric substructures present in the dataset. The advantage of this approach is that during classification model construction, all relevant substructures are available allowing the classifier to intelligently select the most discriminating ones. The computational scalability is ensured by the use of highly efficient frequent subgraph discovery algorithms coupled with aggressive feature selection. Experimental evaluation on eight different classification problems shows that our approach is computationally scalable and on the average outperforms existing schemes by 10% to 35%.",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:b1wdh0AR-JQC",
            "Publisher": "Springer, London"
        },
        {
            "Title": "PAFI: A Pattern Finding Toolkit",
            "Publication year": 2003,
            "Publication url": "https://apps.dtic.mil/sti/citations/ADA439568",
            "Abstract": "PAFI is a set of programs that can be used to find frequent patterns in large and diverse databases. The current release of PAFI includes three different pattern discovery programs called LPMiner, SLPMiner, and FSG. LPMiner finds patterns corresponding to itemsets in a transaction database and is based on the algorithm described. SLPMiner finds patterns corresponding to sub-sequences in a sequential database and is based on the algorithm described. Finally, FSG finds patterns corresponding to connected undirected subgraphs in an undirected graph database and is based on the algorithms described. These programs can be used to mine a wide-range of datasets arising in commercial, information retrieval, and scientific applications. All three programs can be used to find patterns that satisfy a constant minimum support. Moreover, a key feature of LPMiner and SLPMiner is that they can find long frequent patterns without finding a large number of short patterns that are often useless. This is achieved by using length-decreasing support constraints, where the minimum occurrence frequency of a pattern is given as a non-increasing function of pattern length. PAFIs pattern discovery programs usually provide three additional functionalities. First, all three programs can generate maximal frequent patterns. A maximal frequent pattern is a frequent pattern that is not contained by any other frequent patterns. Generally, the number of maximal frequent patterns is much smaller than the number of all the frequent patterns, leading to higher readability of frequent pattern files. Second, SLPMiner and FSG can generate transaction-ID lists TID-lists \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:z_wVstp3MssC",
            "Publisher": "ARMY HIGH PERFORMANCE COMPUTING RESEARCH CENTER MINNEAPOLIS MN"
        },
        {
            "Title": "Parallel cosine nearest neighbor graph construction",
            "Publication year": 2019,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S0743731517303283",
            "Abstract": "The nearest neighbor graph is an important structure in many data mining methods for clustering, advertising, recommender systems, and outlier detection. Constructing the graph requires computing up to n 2 similarities for a set of n objects. This high complexity has led researchers to seek approximate methods, which find many but not all of the nearest neighbors. In contrast, we leverage shared memory parallelism and recent advances in similarity joins to solve the problem exactly. Our method considers all pairs of potential neighbors but quickly filters pairs that could not be a part of the nearest neighbor graph, based on similarity upper bound estimates. The filtering is data dependent and not easily predicted, which poses load balance challenges in parallel execution. We evaluated our methods on several real-world datasets and found they work up to two orders of magnitude faster than existing methods \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:bXQfdp6S9ecC",
            "Publisher": "Academic Press"
        },
        {
            "Title": "ClustKNN: a highly scalable hybrid model-& memory-based CF algorithm",
            "Publication year": 2006,
            "Publication url": "https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.333.506&rep=rep1&type=pdf",
            "Abstract": "Collaborative Filtering (CF)-based recommender systems are indispensable tools to find items of interest from the unmanageable number of available items. Moreover, companies who deploy a CF-based recommender system may be able to increase revenue by drawing customers\u2019 attention to items that they are likely to buy. However, the sheer number of customers and items typical in e-commerce systems demand specially designed CF algorithms that can gracefully cope with the vast size of the data. Many algorithms proposed thus far, where the principal concern is recommendation quality, may be too expensive to operate in a large-scale system. We propose ClustKnn, a simple and intuitive algorithm that is well suited for large data sets. The method first compresses data tremendously by building a straightforward but efficient clustering model. Recommendations are then generated quickly by using a simple Nearest Neighbor-based approach. We demonstrate the feasibility of ClustKnn both analytically and empirically. We also show, by comparing with a number of other popular CF algorithms that, apart from being highly scalable and intuitive, ClustKnn provides very good recommendation accuracy as well.",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:ns9cj8rnVeAC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Gene expression profiling of peripheral blood cells reveals clinical subets of patients with systemic lupus erythematosus.",
            "Publication year": 2004,
            "Publication url": "https://scholar.google.com/scholar?cluster=3856911197275179999&hl=en&oi=scholarr",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:PQEM9vzQD9gC",
            "Publisher": "WILEY-LISS"
        },
        {
            "Title": "Data mining in bioinformatics (BIOKDD)",
            "Publication year": 2007,
            "Publication url": "https://link.springer.com/article/10.1186/1748-7188-2-4",
            "Abstract": "Data Mining is the process of automatic discovery of novel and understandable models and patterns from large amounts of data. Bioinformatics is the science of storing, analyzing, and utilizing information from biological data such as sequences, molecules, gene expressions, and pathways. Development of novel data mining methods will play a fundamental role in understanding these rapidly expanding sources of biological data.Data mining approaches seem ideally suited for bioinformatics, which is data-rich, but lacks a comprehensive theory of life's organization at the molecular level. The extensive databases of biological information create both challenges and opportunities for developing novel data mining methods. The 6th Workshop on Data Mining in Bioinformatics (BIOKDD) was held on August 20th, 2006, Philadelphia, PA, USA, in conjunction with the 12th ACM SIGKDD International Conference on \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:PaBasH6fAo0C",
            "Publisher": "BioMed Central"
        },
        {
            "Title": "Towards a Scalable",
            "Publication year": 2006,
            "Publication url": "https://openreview.net/forum?id=B1-RWV-Obr",
            "Abstract": "Collaborative Filtering (CF)-based recommender systems bring mutual benefits to both users and the operators of the sites with too much information. Users benefit as they are able to find items of interest from an unmanageable number of available items. On the other hand, e-commerce sites that employ recommender systems can increase sales revenue in at least two ways: a) by drawing customers\u2019 attention to items that they are likely to buy, and b) by cross-selling items. However, the sheer number of customers and items typical in e-commerce systems demand specially designed CF algorithms that can gracefully cope with the vast size of the data. Many algorithms proposed thus far, where the principal concern is recommendation quality, may be too expensive to operate in a large-scale system. We propose ClustKnn, a simple and intuitive algorithm that is well suited for large data sets. The method first \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:2Q0AJrNhS-QC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Identifying Genotype-Phenotype Signatures in Genome-Wide Association Data Sets Using Market-Basket-Analysis",
            "Publication year": 2009,
            "Publication url": "https://scholar.google.com/scholar?cluster=13873662609322321904&hl=en&oi=scholarr",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:silx2ntsSuwC",
            "Publisher": "ELSEVIER SCIENCE INC"
        },
        {
            "Title": "Preface to the International Workshop on Data Mining in Networks",
            "Publication year": 2011,
            "Publication url": "https://iris.unimore.it/handle/11380/1248486",
            "Abstract": "La simulazione pu\u00f2 differire dall'esito di un\u2019eventuale domanda ASN sia per errori di catalogazione e/o dati mancanti in IRIS, sia per la variabilit\u00e0 dei dati bibliometrici nel tempo. L\u2019Universit\u00e0 di Modena e Reggio Emilia non si assume alcuna responsabilit\u00e0 in merito all\u2019uso che il diretto interessato o terzi faranno della simulazione.",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:9VeumLvkZSQC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Genotype-phenotype association mining in bipolar disorder: market research meets complex genetics",
            "Publication year": 2017,
            "Publication url": "https://www.biorxiv.org/content/10.1101/116624v1.abstract",
            "Abstract": "Disentangling the etiology of common, complex diseases is a major challenge in genetic research. For bipolar disorder (BD), several genome-wide association studies (GWAS) have been performed. Similar to other complex disorders, major breakthroughs in explaining the high heritability of BD through GWAS have remained elusive. To overcome this dilemma, genetic research into BD, has embraced a variety of strategies such as the formation of large consortia to increase sample size and sequencing approaches. Here we advocate a complementary approach making use of already existing GWAS data: applying a data mining procedure to identify yet undetected genotype-phenotype relationships. We adapted association rule mining, a data mining technique traditionally used in retail market research, to identify frequent and characteristic genotype patterns showing strong associations to phenotype clusters. We applied this strategy to three independent GWAS datasets from 2,835 phenotypically characterized patients with BD. In a discovery step, 20,882 candidate association rules were extracted. Two of these - one associated with eating disorder and the other with anxiety - remained significant in an independent dataset after robust correction for multiple testing, showing considerable effect sizes (odds ratio ~ 3.4 and 3.0, respectively). Our approach may help detect novel specific genotype-phenotype relationships in BD typically not explored by analyses like GWAS. While we adapted the data mining tool within the context of BD gene discovery, it may facilitate identifying highly specific genotype-phenotype relationships in subsets of genome \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:_9Xh93LWpsYC",
            "Publisher": "Cold Spring Harbor Laboratory"
        },
        {
            "Title": "A virtual memory manager optimized for node-level cooperative multi-tasking in memory constrained systems",
            "Publication year": 2018,
            "Publication url": "https://journals.sagepub.com/doi/abs/10.1177/1094342017690975",
            "Abstract": "There is a growing need to perform large computations on small systems, as access to large systems is not widely available and cannot keep up with the size of the data that needs to be processed. Recently, a runtime system for programs using a library that implements the Message Passing Interface (MPI), called Big Data MPI (BDMPI), that allows MPI programs whose aggregate amount of memory exceeds the physical amount of memory to be executed efficiently by utilizing node-level cooperative multi-tasking. In this paper we present a virtual memory subsystem which we implemented as part of the BDMPI runtime. Our new virtual memory subsystem, which we call SBMA takes advantage of BDMPI\u2019s node-level cooperative multi-tasking in order to intelligently determine the parts of the virtual address space that need to be loaded to and unloaded from the main memory. Benchmarking using a synthetic \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:RXiHnyRawswC",
            "Publisher": "SAGE Publications"
        },
        {
            "Title": "AREM: A novel associative regression model based on EM algorithm",
            "Publication year": 2013,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-642-37453-1_38",
            "Abstract": "In recent years, there have been increasing efforts in applying association rule mining to build Associative Classification (AC) models. However, the similar area that applies association rule mining to build Associative Regression (AR) models has not been well explored. In this work, we fill this gap by presenting a novel regression model based on association rules called AREM. AREM starts with finding a set of regression rules by applying the instance based pruning strategy, in which the best rules for each instance are discovered and combined. Then a probabilistic model is trained by applying the EM algorithm, in which the right hand side of the rules and their importance weights are updated. The extensive experimental evaluation shows that our model can perform better than both the previously proposed AR model and some of the state of the art regression models, including Boosted Regression Trees \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:sszUF3NjhM4C",
            "Publisher": "Springer Berlin Heidelberg"
        },
        {
            "Title": "Advanced Data Mining and Applications: 8th International Conference, ADMA 2012, Nanjing, China, December 15-18, 2012, Proceedings",
            "Publication year": 2012,
            "Publication url": "https://books.google.com/books?hl=en&lr=&id=jjzxobmYwQkC&oi=fnd&pg=PR3&dq=info:8MjkdeNeDU8J:scholar.google.com&ots=dsIZ5hWDrJ&sig=685t_UDS6hB4WtmWL7ktSrH6W8E",
            "Abstract": "This book constitutes the refereed proceedings of the 8th International Conference on Advanced Data Mining and Applications, ADMA 2012, held in Nanjing, China, in December 2012. The 32 regular papers and 32 short papers presented in this volume were carefully reviewed and selected from 168 submissions. They are organized in topical sections named: social media mining; clustering; machine learning: algorithms and applications; classification; prediction, regression and recognition; optimization and approximation; mining time series and streaming data; Web mining and semantic analysis; data mining applications; search and retrieval; information recommendation and hiding; outlier detection; topic modeling; and data cube computing.",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:69ZgNCALVd0C",
            "Publisher": "Springer Science & Business Media"
        },
        {
            "Title": "Data Acquisition, Sampling, and Data Preparation Considerations for Quantitative Social Science Research Using Social Media Data",
            "Publication year": 2021,
            "Publication url": "https://www.jonathanmladd.com/uploads/5/3/6/6/5366295/dataacquisition.pdf",
            "Abstract": "In 2019, a group of computer and social scientists began a project to converge these disciplines, with the aim of harnessing data from social media to improve our understanding of human behavior. People all over the world have started using social media, search engines, smart devices, and other technologies that record their moment-to-moment behaviors (often called,\u201cdigital traces\u201d). Social media, in particular, provides a massive amount of information on the everyday activities, opinions, thoughts, emotions, and behaviors of individuals, groups, and organizations in near real-time. Today, most adults in the US use some form of social media (Perrin & Anderson, 2019) to share and discuss topics as wide-ranging as politics, employment, parenthood, leisure activities, travel, sports, and health, to name only a few, making these platforms potentially excellent sources of information on constructs relevant to all social science fields.Expanding the availability and utility of this extremely rich but still underutilized data source in the social sciences, however, requires attention to the unique features of these data. Unlike many forms of standard social science data, social media data have no set structure and are not the product of a designed process initiated by the researcher to answer specific hypotheses or questions. Instead, the data are provided \u201cas is,\u201d which often means they are raw, complex, and highly dense in nature. Moreover, these data involve unique bias concerns not typically at issue in traditional social science methods, including often not knowing who generated the data or what population they represent. The organic nature of the data \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:PklR0melJeUC",
            "Publisher": "PsyArXiv"
        },
        {
            "Title": "Analysis of recommendation algorithms for e-commerce",
            "Publication year": 2000,
            "Publication url": "https://www.academia.edu/download/42466817/Analysis_of_Recommendation_Algorithms_fo20160209-30080-djj1lb.pdf",
            "Abstract": "\u042a \u0433\u0431\u0431 \u0432 \u0436 \u0437\u043d\u0437\u0438 \u0431\u0437 \u0434\u0434\u0430\u043d \u0437\u0438 \u0438 \u0437\u0438 \u0430 \u0432 \u0432\u0433\u043b\u0430 \u0437\u0419 \u0433\u043a \u0436\u043d \u0438 \u0432 \u0435\u0439 \u0437 \u0438\u0433 \u0438 \u0434\u0436\u0433 \u0430 \u0431 \u0433 \u0431 \u0432 \u0434\u0436\u0433 \u0439 \u0438 \u0436 \u0433\u0431\u0419 \u0431 \u0432 \u0438 \u0433\u0432\u0437 \u0439\u0436 \u0432 \u0430 \u043a \u0439\u0437\u0438\u0433\u0431 \u0436 \u0432\u0438 \u0436 \u0438 \u0433\u0432 \u0432 \u0438 \u043d \u0436 \u043a \u0432 \u043b \u0437\u0434\u0436 \u0437\u0439 \u0437\u0437 \u0432 \u0419 \u0433\u0431\u0431 \u0436 \u0432\u0433\u043b \u043d\u0437\u041a \u0421\u0432 \u0438 \u0437 \u0434 \u0434 \u0436\u0418 \u043b \u0432\u043a \u0437\u0438 \u0438 \u0437 \u043a \u0436 \u0430 \u0438 \u0432 \u0435\u0439 \u0437 \u0433\u0436 \u0432 \u0430\u043d\u043e \u0432 \u0430 \u0436 \u0419\u0437 \u0430 \u0434\u0439\u0436 \u0437 \u0432 \u0434\u0436 \u0436 \u0432 \u0438 \u0433\u0436 \u0438 \u0434\u0439\u0436\u0434\u0433\u0437 \u0433 \u0434\u0436\u0433 \u0439 \u0432 \u0439\u0437 \u0439\u0430 \u0436 \u0433\u0431\u0431 \u0432 \u0438 \u0433\u0432\u0437 \u0438\u0433 \u0439\u0437\u0438\u0433\u0431 \u0436\u0437\u041a \u0421\u0432 \u0434 \u0436\u0419 \u0438 \u0439\u0430 \u0436\u0418 \u043b \u0434\u0434\u0430\u043d \u0433\u0430\u0430 \u0438 \u0433\u0432 \u0433 \u0430 \u0433\u0436 \u0438 \u0431\u0437 \u0437\u0439 \u0437 \u0438\u0436 \u0419 \u0438 \u0433\u0432 \u0430 \u0438 \u0431 \u0432 \u0432 \u0418 \u0432 \u0436 \u0437\u0438\u0419\u0432 \u0433\u0436 \u0433\u0430\u0430 \u0433\u0436 \u0438 \u043a \u040c\u0430\u0438 \u0436 \u0432 \u0418 \u0432 \u0431 \u0432\u0437 \u0433\u0432 \u0430 \u0438\u043d \u0436 \u0439 \u0438 \u0433\u0432 \u0433\u0432 \u0438\u043b\u0433 \u040b \u0436 \u0432\u0438 \u0438 \u0437 \u0438\u0437\u041a \u042c \u040c\u0436\u0437\u0438 \u0438 \u0437 \u0438 \u043b \u0437 \u0436 \u043a \u0436\u0433\u0431 \u0438 \u043b \u0419\u0434\u0439\u0436 \u0437 \u0432 \u0438\u0436 \u0432\u0437 \u0419 \u0438 \u0433\u0432 \u0433 \u0430 \u0436 \u0419 \u0433\u0431\u0431 \u0436 \u0433\u0431\u0434 \u0432\u043d \u043b \u0436 \u0437 \u0438 \u0437 \u0433\u0432 \u0438 \u0437 \u0438 \u043b \u0437 \u0433\u0430\u0430 \u0438 \u0436\u0433\u0431 \u0425\u0433\u043a \u0424 \u0432\u0437 \u0431\u0433\u043a \u0436 \u0433\u0431\u0431 \u0432 \u0419 \u0438 \u0433\u0432 \u0437 \u0438 \u041a \u0433\u0436 \u0438 \u043c\u0434 \u0436 \u0431 \u0432\u0438 \u0430 \u0434\u0439\u0436\u0434\u0433\u0437 \u0418 \u043b \u043a \u0438 \u0436 \u0419 \u0433\u0431\u0431 \u0432 \u0438 \u0433\u0432 \u0432 \u0436 \u0438 \u0433\u0432 \u0434\u0436\u0433 \u0437\u0437 \u0432\u0438\u0433 \u0438 \u0436 \u0437\u0439 \u0434\u0436\u0433 \u0437\u0437 \u0437\u043f \u0436 \u0434\u0436 \u0437 \u0432\u0438 \u0438 \u0433\u0432 \u0433 \u0432\u0434\u0439\u0438 \u0438 \u0418 \u0432 \u0433\u0436 \u0433\u0433 \u0433\u0436\u0431 \u0438 \u0433\u0432\u0418 \u0432 \u0436 \u0433\u0431\u0431 \u0432 \u0438 \u0433\u0432 \u0432 \u0436 \u0438 \u0433\u0432\u041a \u042f \u043a \u0437 \u040b \u0436 \u0432\u0438 \u0438 \u0432 \u0435\u0439 \u0437 \u0433\u0436 \u040b \u0436 \u0432\u0438 \u0437\u0439 \u0434\u0436\u0433 \u0437\u0437 \u0437 \u0432 \u0434\u0434\u0430\u043d \u0438 \u0436 \u0433\u0431 \u0432 \u0438 \u0433\u0432\u0437 \u0433\u0432 \u0433\u0439\u0436 \u0438 \u0437 \u0438\u0437 \u0438\u0433 \u0433\u0431\u0434 \u0436 \u0433\u0436 \u0436 \u0433\u0431\u0431 \u0432 \u0438 \u0433\u0432 \u0435\u0439 \u0430 \u0438\u043d \u0432 \u0434 \u0436 \u0433\u0436\u0431 \u0432 \u041a",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:o-PowTg_VKEC",
            "Publisher": "Unknown"
        },
        {
            "Title": "The identification of gene expression signatures in the PBMCs of patients with Systemic Lupus Erythematosus.",
            "Publication year": 2001,
            "Publication url": "https://scholar.google.com/scholar?cluster=7166164686126474640&hl=en&oi=scholarr",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:N4u4nq0IxgcC",
            "Publisher": "Unknown"
        },
        {
            "Title": "BIOT 361-Discovering the regulatory hubs of Strepotmyces secondary metabolism through transcriptome data mining",
            "Publication year": 2008,
            "Publication url": "https://scholar.google.com/scholar?cluster=15393453282602992549&hl=en&oi=scholarr",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:2v_ZtQDX9iAC",
            "Publisher": "AMER CHEMICAL SOC"
        },
        {
            "Title": "Parallel tree-projection-based sequence mining algorithms",
            "Publication year": 2004,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S0167819104000456",
            "Abstract": "Discovery of sequential patterns is becoming increasingly useful and essential in many scientific and commercial domains. Enormous sizes of available datasets and possibly large number of mined patterns demand efficient, scalable, and parallel algorithms. Even though a number of algorithms have been developed to efficiently parallelize frequent pattern discovery algorithms that are based on the candidate-generation-and-counting framework, the problem of parallelizing the more efficient projection-based algorithms has received relatively little attention and existing parallel formulations have been targeted only toward shared-memory architectures. The irregular and unstructured nature of the task-graph generated by these algorithms and the fact that these tasks operate on overlapping sub-databases makes it challenging to efficiently parallelize these algorithms on scalable distributed-memory parallel \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:abG-DnoFyZgC",
            "Publisher": "North-Holland"
        },
        {
            "Title": "TR O2-O16",
            "Publication year": 2002,
            "Publication url": "https://scholar.google.com/scholar?cluster=13368066556009253549&hl=en&oi=scholarr",
            "Abstract": "Clustering is the task of organizing a set of objects into meaningful groups. These groups can be disjoint, overlapping, or organized in some hierarchical fashion. The key element of clustering is the notion that the discovered groups are meaningful. This de\ufb01nition is intentionally vague, as what constitutes meaningful is to a large extent, application dependent. In some applications this may translate to groups in which the pairwise similarity between their objects is maximized, and the pairwise similarity between objects of different groups is minimized. In some other applications this may translate to groups that contain objects that share some key characteristics, even though their overall similarity is not the highest. Clustering is an exploratory tool for analyzing large datasets, and has been used extensively in numerous application areas. Clustering has a wide range of applications in life sciences and over the years \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:5bg8sr1QxYwC",
            "Publisher": "Unknown"
        },
        {
            "Title": "PanRep: Graph neural networks for extracting universal node embeddings in heterogeneous graphs",
            "Publication year": 2020,
            "Publication url": "https://arxiv.org/abs/2007.10445",
            "Abstract": "Learning unsupervised node embeddings facilitates several downstream tasks such as node classification and link prediction. A node embedding is universal if it is designed to be used by and benefit various downstream tasks. This work introduces PanRep, a graph neural network (GNN) model, for unsupervised learning of universal node representations for heterogenous graphs. PanRep consists of a GNN encoder that obtains node embeddings and four decoders, each capturing different topological and node feature properties. Abiding to these properties the novel unsupervised framework learns universal embeddings applicable to different downstream tasks. PanRep can be furthered fine-tuned to account for possible limited labels. In this operational setting PanRep is considered as a pretrained model for extracting node embeddings of heterogenous graph data. PanRep outperforms all unsupervised and certain supervised methods in node classification and link prediction, especially when the labeled data for the supervised methods is small. PanRep-FT (with fine-tuning) outperforms all other supervised approaches, which corroborates the merits of pretraining models. Finally, we apply PanRep-FT for discovering novel drugs for Covid-19. We showcase the advantage of universal embeddings in drug repurposing and identify several drugs used in clinical trials as possible drug candidates.",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:cww_0JKUTDwC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Multi-objective circuit partitioning for cutsize and path-based delay minimization",
            "Publication year": 2002,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/774572.774599",
            "Abstract": "In this paper we present multi-objective hMetis partitioning for simultaneous cutsize and circuit delay minimization. We change the partitioning process itself by introducing a new objective function that incorporates a truly path-based delay component for the most critical paths. To avoid semi-critical paths from becoming critical, the traditional slack based delay component is also included in the cost function. The proposed timing driven partitioning algorithm is built on top of the hMetis algorithm, which is very efficient. Simulations results show that 14% average delay improvement can be obtained. Smooth trade-off between cutsize and delay is possible in our algorithm.",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:vV6vV6tmYwMC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Tensor-matrix products with a compressed sparse tensor",
            "Publication year": 2015,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/2833179.2833183",
            "Abstract": "The Canonical Polyadic Decomposition (CPD) of tensors is a powerful tool for analyzing multi-way data and is used extensively to analyze very large and extremely sparse datasets. The bottleneck of computing the CPD is multiplying a sparse tensor by several dense matrices. Algorithms for tensor-matrix products fall into two classes. The first class saves floating point operations by storing a compressed tensor for each dimension of the data. These methods are fast but suffer high memory costs. The second class uses a single uncompressed tensor at the cost of additional floating point operations. In this work, we bridge the gap between the two approaches and introduce the compressed sparse fiber (CSF) a data structure for sparse tensors along with a novel parallel algorithm for tensor-matrix multiplication. CSF offers similar operation reductions as existing compressed methods while using only a single tensor \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:x21FZCSn4ZoC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Global Neighbor Sampling for Mixed CPU-GPU Training on Giant Graphs",
            "Publication year": 2021,
            "Publication url": "https://arxiv.org/abs/2106.06150",
            "Abstract": "Graph neural networks (GNNs) are powerful tools for learning from graph data and are widely used in various applications such as social network recommendation, fraud detection, and graph search. The graphs in these applications are typically large, usually containing hundreds of millions of nodes. Training GNN models on such large graphs efficiently remains a big challenge. Despite a number of sampling-based methods have been proposed to enable mini-batch training on large graphs, these methods have not been proved to work on truly industry-scale graphs, which require GPUs or mixed-CPU-GPU training. The state-of-the-art sampling-based methods are usually not optimized for these real-world hardware setups, in which data movement between CPUs and GPUs is a bottleneck. To address this issue, we propose Global Neighborhood Sampling that aims at training GNNs on giant graphs specifically for mixed-CPU-GPU training. The algorithm samples a global cache of nodes periodically for all mini-batches and stores them in GPUs. This global cache allows in-GPU importance sampling of mini-batches, which drastically reduces the number of nodes in a mini-batch, especially in the input layer, to reduce data copy between CPU and GPU and mini-batch computation without compromising the training convergence rate or model accuracy. We provide a highly efficient implementation of this method and show that our implementation outperforms an efficient node-wise neighbor sampling baseline by a factor of 2X-4X on giant graphs. It outperforms an efficient implementation of LADIES with small layers by a factor of 2X-14X while \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:1_W9tMSvGuwC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Basic communication operations",
            "Publication year": 2003,
            "Publication url": "https://www.cs.uic.edu/~ajayk/c566/chap4_AG.pdf",
            "Abstract": "\u2022 Assume that source processor is the root of this tree. In the first step, the source sends the data to the right child (assuming the source is also the left child). The problem has now been decomposed into two problems with half the number of processors.",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:J4E9jCG1tHUC",
            "Publisher": "Addison-Wesley"
        },
        {
            "Title": "Big data frequent pattern mining",
            "Publication year": 2014,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-319-07821-2_10",
            "Abstract": "Frequent pattern mining is an essential data mining task, with a goal of discovering knowledge in the form of repeated patterns. Many efficient pattern mining algorithms have been discovered in the last two decades, yet most do not scale to the type of data we are presented with today, the so-called \u201cBig Data\u201d. Scalable parallel algorithms hold the key to solving the problem in this context. In this chapter, we review recent advances in parallel frequent pattern mining, analyzing them through the Big Data lens. We identify three areas as challenges to designing parallel frequent pattern mining algorithms: memory scalability, work partitioning, and load balancing. With these challenges as a frame of reference, we extract and describe key algorithmic design patterns from the wealth of research conducted in this domain.",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:nqdriD65xNoC",
            "Publisher": "Springer, Cham"
        },
        {
            "Title": "NSF BIGDATA PI meeting-domain-specific research directions and data sets",
            "Publication year": 2019,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/3316416.3316425",
            "Abstract": "In March 2017, PIs and co-PIs funded through the NSF BIGDATA program were brought together along with selected industry and government invitees to discuss current research, identify current challenges, discuss promising future directions, foster new collaborations, and share accomplishments, at BDPI-2017. Given that two recent NITRD [2] and NSF [1] meeting reports contained a set of recommendations, grand challenges, and high impact priorities for Big Data, the organizers of this meeting shifted the focus of the breakout sessions to discuss problems and available data sets that exist in five application domains - policy, health, education, economy & finance, and environment & energy. These domains were selected based on a survey of the PIs/co-PIs and should not be interpreted as being more important than others. Slides that were presented by the different breakout group leaders are available at https \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:N6_Y7JlWxwsC",
            "Publisher": "ACM"
        },
        {
            "Title": "Comparative profiling of the CHO transcriptome by RNA-Seq",
            "Publication year": 2010,
            "Publication url": "https://scholar.google.com/scholar?cluster=3059411894963824&hl=en&oi=scholarr",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:CYCckWUYoCcC",
            "Publisher": "AMER CHEMICAL SOC"
        },
        {
            "Title": "Computation-time efficient and robust attribute tree mining with DRYADEPARENT",
            "Publication year": 2005,
            "Publication url": "http://faui20a.informatik.uni-erlangen.de/publication/download/mgts2005.pdf#page=69",
            "Abstract": "In this paper, we present a new tree mining algorithm, Dryade-Parent, based on the hooking principle first introduced in Dryade [1]. In the experiments, we demonstrate that the branching factor and depth of the frequent patterns to find are key factor of complexity for tree mining algorithms, even if often overlooked in previous work. We show that DryadeParent outperforms the current fastest algorithm, CMTreeM-iner, by orders of magnitude on datasets where the frequent patterns have a high branching factor.",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:oTdOBqtIf_kC",
            "Publisher": "Unknown"
        },
        {
            "Title": "YASSPP: better kernels and coding schemes lead to improvements in protein secondary structure prediction",
            "Publication year": 2006,
            "Publication url": "https://onlinelibrary.wiley.com/doi/abs/10.1002/prot.21036",
            "Abstract": "The accurate prediction of a protein's secondary structure plays an increasingly critical role in predicting its function and tertiary structure, as it is utilized by many of the current state\u2010of\u2010the\u2010art methods for remote homology, fold recognition, and ab initio structure prediction. We developed a new secondary structure prediction algorithm called YASSPP, which uses a pair of cascaded models constructed from two sets of binary SVM\u2010based models. YASSPP uses an input coding scheme that combines both position\u2010specific and nonposition\u2010specific information, utilizes a kernel function designed to capture the sequence conservation signals around the local window of each residue, and constructs a second\u2010level model by incorporating both the three\u2010state predictions produced by the first\u2010level model and information about the original sequence. Experiments on three standard datasets (RS126, CB513, and EVA \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:hMod-77fHWUC",
            "Publisher": "Wiley Subscription Services, Inc., A Wiley Company"
        },
        {
            "Title": "TR O4-O28",
            "Publication year": 2004,
            "Publication url": "https://scholar.google.com/scholar?cluster=5802119226352095777&hl=en&oi=scholarr",
            "Abstract": "Discovery of biological relationships between genes is one of the keys to understanding the complex functional nature of the human genome. Currently, most of the knowledge about interrelating genes are found in immense amounts of various biomedical literature. Hence, extraction of biological contexts occurring in free text represents a valuable tool in gaining knowledge about gene interactions. V\\/\" e present a textual analysis of documents associated with pairs of genes, and describe how this approach can be used to discover and annotate functional relationships among genes. A study on a subset of human genes show that our analysis tool can act as a ranking mechanism for sets of genes based 011 their functional relatedness.",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:QYdC8u9Cj1oC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Mining manufacturing data for discovery of high productivity process characteristics",
            "Publication year": 2010,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S0168165610001902",
            "Abstract": "Modern manufacturing facilities for bioproducts are highly automated with advanced process monitoring and data archiving systems. The time dynamics of hundreds of process parameters and outcome variables over a large number of production runs are archived in the data warehouse. This vast amount of data is a vital resource to comprehend the complex characteristics of bioprocesses and enhance production robustness. Cell culture process data from 108 \u2018trains\u2019 comprising production as well as inoculum bioreactors from Genentech's manufacturing facility were investigated. Each run constitutes over one-hundred on-line and off-line temporal parameters. A kernel-based approach combined with a maximum margin-based support vector regression algorithm was used to integrate all the process parameters and develop predictive models for a key cell culture performance parameter. The model was also used \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:UHK10RUVsp4C",
            "Publisher": "Elsevier"
        },
        {
            "Title": "Methods for effective virtual screening and scaffold-hopping in chemical compounds",
            "Publication year": 2007,
            "Publication url": "https://www.worldscientific.com/doi/abs/10.1142/9781860948732_0041",
            "Abstract": "Methods that can screen large databases to retrieve a structurally diverse set of compounds with desirable bioactivity properties are critical in the drug discovery and development process. This paper presents a set of such methods, which are designed to find compounds that are structurally different to a certain query compound while retaining its bioactivity properties (scaffold hops). These methods utilize various indirect ways of measuring the similarity between the query and a compound that take into account additional information beyond their structure-based similarities. Two sets of techniques are presented that capture these indirect similarities using approaches based on automatic relevance feedback and on analyzing the similarity network formed by the query and the database compounds. Experimental evaluation shows that many of these methods substantially outperform previously developed \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:qSd0DAb9jMoC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Hierarchical clustering algorithms for document datasets",
            "Publication year": 2005,
            "Publication url": "https://link.springer.com/article/10.1007/s10618-005-0361-3",
            "Abstract": "Fast and high-quality document clustering algorithms play an important role in providing intuitive navigation and browsing mechanisms by organizing large amounts of information into a small number of meaningful clusters. In particular, clustering algorithms that build meaningful hierarchies out of large document collections are ideal tools for their interactive visualization and exploration as they provide data-views that are consistent, predictable, and at different levels of granularity. This paper focuses on document clustering algorithms that build such hierarchical solutions and (i) presents a comprehensive study of partitional and agglomerative algorithms that use different criterion functions and merging schemes, and (ii) presents a new class of clustering algorithms called constrained agglomerative algorithms, which combine features from both partitional and agglomerative approaches that allows them to \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:eQOLeE2rZwMC",
            "Publisher": "Springer Netherlands"
        },
        {
            "Title": "Document Clustering.",
            "Publication year": 2009,
            "Publication url": "https://scholar.google.com/scholar?cluster=10753174782846077156&hl=en&oi=scholarr",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:1tZ8xJnm2c8C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Predicting student performance using personalized analytics",
            "Publication year": 2016,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/7452320/",
            "Abstract": "To help solve the ongoing problem of student retention, new expected performance-prediction techniques are needed to facilitate degree planning and determine who might be at risk of failing or dropping a class. Personalized multiregression and matrix factorization approaches based on recommender systems, initially developed for e-commerce applications, accurately forecast students' grades in future courses as well as on in-class assessments.",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:H7nrzBkawXsC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Learning Course Sequencing for Course Recommendation",
            "Publication year": 2018,
            "Publication url": "https://conservancy.umn.edu/handle/11299/216025",
            "Abstract": "The alarming graduation statistics in higher education institutions have resulted in an increased demand on finding ways to improve the learning environment for students to help them graduate in a successful and timely manner. With the rise of data available about past students, machine learning researchers have been able to learn predictive models that solve different problems in the education domain. In this paper, we focus on the problem of course recommendation that aims to recommend to each student a set of courses from which they can register for in their following term, for the ultimate goal of improving the student's GPA and graduation time. We first propose a different definition for the course recommendation problem statement, by focusing on recommending courses on which the students' expected grades will help maintain or improve their GPAs. We then leverage two widely-known representation learning techniques, in order to learn the sequence by which students take courses and create better personalized rankings for students. Our experiments on a large dataset obtained from the University of Minnesota that includes students from 23 different majors show that the methods based on the proposed problem statement can better recommend courses on which the students are expected to perform well and that align with their degree programs. Moreover, the results show that the proposed methods achieve statistically significant results for course recommendation over the current methods.",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:cRMvf6lLvU8C",
            "Publisher": "Unknown"
        },
        {
            "Title": "A Boolean algorithm for reconstructing the structure of regulatory networks",
            "Publication year": 2004,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S1096717604000394",
            "Abstract": "Advances in transcriptional analysis offer great opportunities to delineate the structure and hierarchy of regulatory networks in biochemical systems. We present an approach based on Boolean analysis to reconstruct a set of parsimonious networks from gene disruption and over expression data. Our algorithms, Causal Predictor (CP) and Relaxed Causal Predictor (RCP) distinguish the direct and indirect causality relations from the non-causal interactions, thus significantly reducing the number of miss-predicted edges. The algorithms also yield substantially fewer plausible networks. This greatly reduces the number of experiments required to deduce a unique network from the plausible network structures. Computational simulations are presented to substantiate these results. The algorithms are also applied to reconstruct the entire network of galactose utilization pathway in Saccharomyces cerevisiae. These \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:P5F9QuxV20EC",
            "Publisher": "Academic Press"
        },
        {
            "Title": "Scalable Graph Neural Networks with Deep Graph Library",
            "Publication year": 2021,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/3437963.3441663",
            "Abstract": "Learning from graph and relational data plays a major role in many applications including social network analysis, marketing, e-commerce, information retrieval, knowledge modeling, medical and biological sciences, engineering, and others. Recently, Graph Neural Networks (GNNs) have emerged as a promising new learning framework capable of bringing the power of deep representation learning to graph and relational data. This ever-growing body of research has shown that GNNs achieve state-of-the-art performance for problems such as link prediction, fraud detection, target-ligand binding activity prediction, knowledge-graph completion, and product recommendations. In practice, many of the real-world graphs are very large. It is urgent to have scalable solutions to train GNN on large graphs efficiently.",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:5VjbC5aozO0C",
            "Publisher": "Unknown"
        },
        {
            "Title": "BIOT 22-Mining cell culture process data to unveil high productivity characteristics",
            "Publication year": 2008,
            "Publication url": "https://scholar.google.com/scholar?cluster=4923389134662097420&hl=en&oi=scholarr",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:DyXnQzXoVgIC",
            "Publisher": "AMER CHEMICAL SOC"
        },
        {
            "Title": "Detection of coherent structures in extreme-scale simulations",
            "Publication year": 2012,
            "Publication url": "https://www.osti.gov/biblio/1047790",
            "Abstract": "The analysis of coherent structures is a common problem in many scientific domains ranging from astrophysics to combustion, fusion, and materials science. The data from three-dimensional simulations are analyzed to detect the structures, extract statistics on them, and track them over time to gain insights into the phenomenon being modeled. This analysis is typically done off-line, using data that have been written out by the simulations. However, the move towards extreme scale architectures, with multi-core processors and graphical processing units, will affect how such analysis is done as it is unlikely that the systems will support the I/O bandwidth required for off-line analysis. Moving the analysis in-situ is a solution only if we know a priori what analysis will be done, as well as the algorithms used and their parameter settings. Even then, we need to ensure that this will not substantially increase the memory requirements or the data movement as the former will be limited and the latter will be expensive. In the Exa-DM project, a collaboration between Lawrence Livermore National Laboratory and University of Minnesota, we are exploring ways in which we can address the conflicting demands of coherent structure analysis of simulation data and the architecture of more\u00bb",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:fbc8zXXH2BUC",
            "Publisher": "Lawrence Livermore National Lab.(LLNL), Livermore, CA (United States)"
        },
        {
            "Title": "TR O1-O30",
            "Publication year": 2001,
            "Publication url": "https://scholar.google.com/scholar?cluster=1102325417647295118&hl=en&oi=scholarr",
            "Abstract": "The availability of computational methods to identify and de\ufb01ne the precise structure and location of promoters in prokaryotic genomes will provide a critical \ufb01rst step towards understanding the mechanisms by which genes are organized and regulated. We examine three different methods for promoter identi\ufb01cation, two of which are adopted from related work and the other is a novel approach based on feature extraction. By the results of a set of experiments we evaluated prediction accuracy for identifying promoter regions from non-coding regions.",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:foquWX3nUaYC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Gang scheduling for distributed memory systems",
            "Publication year": 2000,
            "Publication url": "https://conservancy.umn.edu/handle/11299/215403",
            "Abstract": "Time-sliced gang scheduling improves the average response time of the jobs in a typical job stream.  Recent research has shown that time-slicing is most effective when the jobs admitted for execution fit entirely into physical memory.  We investigate two techniques for improving the performance of gang scheduling in the presence of memory pressure:  1) a novel backfill approach which improves memory utilization, and 2) an adaptive multi-programming level which balances processor/memory utilization with job response time performance.  Our simulations show that these techniques reduce the slow-down performance metrics over naive FCFS methods on a distributed memory parallel system.",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:tzM49s52ZIMC",
            "Publisher": "Unknown"
        },
        {
            "Title": "BDMPI: conquering BigData with small clusters using MPI",
            "Publication year": 2013,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/2534645.2534652",
            "Abstract": "The problem of processing massive amounts of data on clusters with finite amount of memory has become an important problem facing the parallel/distributed computing community. While MapReduce-style technologies provide an effective means for addressing various problems that fit within the MapReduce paradigm, there are many classes of problems for which this paradigm is ill-suited. In this paper we present a runtime system for traditional MPI programs that enables the efficient and transparent disk-based execution of distributed-memory parallel programs. This system, called BDMPI, leverages the semantics of MPI's API to orchestrate the execution of a large number of MPI processes on much fewer compute nodes, so that the running processes maximize the amount of computation that they perform with the data fetched from the disk. BDMPI enables the development of efficient parallel distributed memory \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:unp9ATQDT5gC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Deep Graph Library: Overview, Updates, and Future Developments [GrAPL 2020 Keynote Speaker]",
            "Publication year": 2020,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/9150436/",
            "Abstract": "Summary form only given, as follows. The complete presentation was not made available for publication as part of the conference proceedings. Learning from graph and relational data plays a major role in many applications including social network analysis, marketing, ecommerce, information retrieval, knowledge modeling, medical and biological sciences, engineering, and others. In the last few years, Graph Neural Networks (GNNs) have emerged as a promising new supervised learning framework capable of bringing the power of deep representation learning to graph and relational data. This ever-growing body of research has shown that GNNs achieve state-of-the-art performance for problems such as link prediction, fraud detection, target-ligand binding activity prediction, knowledge-graph completion, and product recommendations. Deep Graph Library (DGL) is an open source development framework for \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:w7CBUyPWg-0C",
            "Publisher": "IEEE"
        },
        {
            "Title": "Item-based collaborative filtering recommendation algorithms",
            "Publication year": 2001,
            "Publication url": "https://dl.acm.org/doi/pdf/10.1145/371920.372071",
            "Abstract": "Recommender systems apply knowledge discovery techniques to the problem of making personalized recommendations for information, products or services during a live interaction. These systems, especially the k-nearest neighbor collaborative filtering based ones, are achieving widespread success on the Web. The tremendous growth in the amount of available information and the number of visitors to Web sites in recent years poses some key challenges for recommender systems. These are: producing high quality recommendations, performing many recommendations per second for millions of users and items and achieving high coverage in the face of data sparsity. In traditional collaborative filtering systems the amount of work increases with the number of participants in the system. New recommender system technologies are needed that can quickly produce high quality recommendations, even for very \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:u5HHmVD_uO8C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Automated approaches for classifying structures",
            "Publication year": 2002,
            "Publication url": "https://apps.dtic.mil/sti/citations/ADA439498",
            "Abstract": "In this paper we study the problem of classifying chemical compound datasets. We present an algorithm that first mines the chemical compound dataset to discover discriminating sub-structures these discriminating sub-structures are used as features to build a powerful classifier. The advantage of our classification technique is that it requires very little domain knowledge and can easily handle large chemical datasets. We evaluated the performance of our classifier on two widely available chemical compound datasets and have found it to give good results.Descriptors:",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:blknAaTinKkC",
            "Publisher": "MINNESOTA UNIV MINNEAPOLIS DEPT OF COMPUTER SCIENCE"
        },
        {
            "Title": "Context, Language Modeling, and Multimodal Data in Finance",
            "Publication year": 2021,
            "Publication url": "https://jfds.pm-research.com/content/early/2021/06/01/jfds.2021.1.063.abstract",
            "Abstract": "The authors enhance pretrained language models with Securities and Exchange Commission filings data to create better language representations for features used in a predictive model. Specifically, they train RoBERTa class models with additional financial regulatory text, which they denote as a class of RoBERTa-Fin models. Using different datasets, the authors assess whether there is material improvement over models that use only text-based numerical features (e.g., sentiment, readability, polarity), which is the traditional approach adopted in academia and practice. The RoBERTa-Fin models also outperform generic bidirectional encoder representations from transformers (BERT) class models that are not trained with financial text. The improvement in classification accuracy is material, suggesting that full text and context are important in classifying financial documents and that the benefits from the use of \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:BFa5h04uPMwC",
            "Publisher": "Institutional Investor Journals Umbrella"
        },
        {
            "Title": "Collaborative multi-regression models for predicting students' performance in course activities",
            "Publication year": 2015,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/2723576.2723590",
            "Abstract": "Methods that accurately predict the grade of a student at a given activity or course can identify students that are at risk in failing a course and allow their educational institution to take corrective actions. Though a number of prediction models have been developed, they either estimate a single model for all students based on their past course performance and interactions with learning management systems (LMS), or estimate student-specific models that do not take into account LMS interactions; thus, failing to exploit fine-grain information related to a student's engagement. In this work we present a class of collaborative multi-regression models that are personalized to each student and also take into account features related to student's past performance, engagement and course characteristics. These models use all historical information to estimate a small number of regression models shared by all students along \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:DXE8ND7PrJAC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Average Positive of User Clicks as an Automated and Not-Intrusive Way of Evaluating Ranking Methods",
            "Publication year": 2003,
            "Publication url": "https://apps.dtic.mil/sti/citations/ADA441204",
            "Abstract": "The need for an objective and automated way of evaluating the performance of different ranking methods is becoming increasingly important in the web search domain. There are various methods for ranking search results ranging from traditional information retrieval approaches to more recent methods based on link analysis and other quality measures that can be derived from the documents. There are also a number of strategies for combining different heuristics and answers from multiple experts. With all of these possibilities it is becoming increasingly difficult cult to find the best parameters, the best method, or the best mixture of methods that will maximize the quality for a particular query type or domain. This paper addresses the problem of automatically comparing the quality of the ordering of documents that are presented to the user as a sorted list according to believed relevance for a given topic or query. We introduce the average position of user clicks metric as an implicit, automated, and non-intrusive way of evaluating ranking methods. We also discuss under which situations and assumptions this metric can be used objectively by addressing various bias sources. Experiments performed in our meta search engine suggests that, this approach has the potential to sample a wide range of query types and users with greater statistical significance compared to methods that rely on explicit user judgements.Descriptors:",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:uWiczbcajpAC",
            "Publisher": "MINNESOTA UNIV MINNEAPOLIS DEPT OF COMPUTER SCIENCE"
        },
        {
            "Title": "Streaming and batch algorithms for truss decomposition",
            "Publication year": 2019,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/9030981/",
            "Abstract": "Truss decomposition is a method used to analyze large sparse graphs in order to identify successively better connected subgraphs. Since in many domains the underlying graph changes over time, its associated truss decomposition needs to be updated as well. This work focuses on the problem of incrementally updating an existing truss decomposition and makes the following three significant contributions. First, it presents a theory that identifies how the truss decomposition can change as new edges get added. Second, it develops an efficient incremental algorithm that incorporates various optimizations to update the truss decomposition after every edge addition. These optimizations are designed to reduce the number of edges that are explored by the algorithm. Third, it extends this algorithm to batch updates (i.e., where the truss decomposition needs to be updated after a set of edges are added), which reduces \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:WMtz-WDmgKQC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Memory-efficient parallel computation of tensor and matrix products for big tensor decomposition",
            "Publication year": 2014,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/7094512/",
            "Abstract": "Low-rank tensor decomposition has many applications in signal processing and machine learning, and is becoming increasingly important for analyzing big data. A significant challenge is the computation of intermediate products which can be much larger than the final result of the computation, or even the original tensor. We propose a scheme that allows memory-efficient in-place updates of intermediate matrices. Motivated by recent advances in big tensor decomposition from multiple compressed replicas, we also consider the related problem of memory-efficient tensor compression. The resulting algorithms can be parallelized, and can exploit but do not require sparsity.",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:4e5Qn2KL_jwC",
            "Publisher": "IEEE"
        },
        {
            "Title": "MALDI-TOF MS combined with magnetic beads for detecting serum protein biomarkers and establishment of boosting decision tree model for diagnosis of systemic lupus erythematosus.",
            "Publication year": 2010,
            "Publication url": "https://scholar.google.com/scholar?cluster=15087105095492008912&hl=en&oi=scholarr",
            "Abstract": "Systemic lupus erythematosus (SLE) is a complex auto-immune disorder which involves various facets of the immune system. In addition to autoantibody production and immune complex deposition, emerging evidences suggest that cytokines may act as key players in the immunopathogenesis of SLE. These cytokines assume a critical role in the differentiation, maturation and activation of cells and also participate in the local inflammatory processes that mediate tissue insults in SLE. Certain cytokines such as the IL-6, IL-10, IL-17, BLys, type I interferons (IFN) and tumor necrosis factor-\u03b1 (TNF-\u03b1) are closely linked to pathogenesis of SLE. The delineation of the role played by these cytokines not only fosters our understanding of this disease but also provides a sound rationale for various therapeutic approaches. In this context, this review focuses on selected cytokines which exert significant effect in the pathogenesis \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:txeM2kYbVNMC",
            "Publisher": "Elsevier Science BV"
        },
        {
            "Title": "Genome-wide inference of regulatory networks in Streptomyces coelicolor",
            "Publication year": 2010,
            "Publication url": "https://bmcgenomics.biomedcentral.com/articles/10.1186/1471-2164-11-578",
            "Abstract": "The onset of antibiotics production in Streptomyces species is co-ordinated with differentiation events. An understanding of the genetic circuits that regulate these coupled biological phenomena is essential to discover and engineer the pharmacologically important natural products made by these species. The availability of genomic tools and access to a large warehouse of transcriptome data for the model organism, Streptomyces coelicolor, provides incentive to decipher the intricacies of the regulatory cascades and develop biologically meaningful hypotheses. In this study, more than 500 samples of genome-wide temporal transcriptome data, comprising wild-type and more than 25 regulatory gene mutants of Streptomyces coelicolor probed across multiple stress and medium conditions, were investigated. Information based on transcript and functional similarity was used to update a previously-predicted whole-genome operon map and further applied to predict transcriptional networks constituting modules enriched in diverse functions such as secondary metabolism, and sigma factor. The predicted network displays a scale-free architecture with a small-world property observed in many biological networks. The networks were further investigated to identify functionally-relevant modules that exhibit functional coherence and a consensus motif in the promoter elements indicative of DNA-binding elements. Despite the enormous experimental as well as computational challenges, a systems approach for integrating diverse genome-scale datasets to elucidate complex regulatory networks is beginning to emerge. We present an integrated analysis of \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:tKAzc9rXhukC",
            "Publisher": "BioMed Central"
        },
        {
            "Title": "TR O4-O22",
            "Publication year": 2004,
            "Publication url": "https://scholar.google.com/scholar?cluster=8506643991335809376&hl=en&oi=scholarr",
            "Abstract": "Recently published studies have shown that partitional clustering algorithms that optimize certain criterion functions, which measure key aspects of inter-and intra-cluster similarity, are very effective in producing hard clustering solutions for document datasets and outperform traditional partitional and agglomerative algorithms. In this paper we study the extent to which these criterion functions can be modi\ufb01ed to include soft membership functions and whether or not the resulting soft clustering algorithms can further improve the clustering solutions. Speci\ufb01cally, we focus on four of these hard criterion functions, derive their soft-clustering extensions, present a comprehensive experimental evaluation involving twelve different datasets, and analyze their overall characteristics. Our results show that introducing softness into the criterion functions tends to lead to better clustering results for most datasets and consistently \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:WC9gN4BGCRcC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Genomic view of systemic autoimmunity in MRL lpr mice",
            "Publication year": 2006,
            "Publication url": "https://www.nature.com/articles/6364286",
            "Abstract": "MRLlpr mice develop spontaneous systemic autoimmunity with many hallmarks of the human disease systemic lupus erythematosus. Although a variety of genes have been implicated in this model, disease pathogenesis is still poorly understood. In an effort to identify novel genes and pathways, we performed genome-wide mRNA expression analysis in the spleens and kidneys of MRLlpr mice throughout the disease course. Samples were collected from cohorts of C57BL/6, MRL+/+ and MRLlpr mice, and profiled by flow cytometry and gene expression microarrays. Serum autoantibodies and renal pathology were studied in parallel. We identified 236 genes in MRLlpr spleen that showed significant threefold or greater changes in expression between 6 and 20 weeks. Of interest, a number of interferon-responsive genes were expressed early, and remained dysregulated throughout the disease course. Many \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:pyW8ca7W8N0C",
            "Publisher": "Nature Publishing Group"
        },
        {
            "Title": "Science and technology text mining: wireless LANS",
            "Publication year": 2005,
            "Publication url": "https://apps.dtic.mil/sti/citations/ADA437247",
            "Abstract": "Database Tomography DT is a textual database analysis system consisting of two major components 1 algorithms for extracting multi-word phrase frequencies and phrase proximities physical closeness of the multi-word technical phrases from any type of large textual database, to augment 2 interpretative capabilities of the expert human analyst. DT was used to obtain technical intelligence from a Wireless LAN Local Area Network database derived from the Science Citation Index Social Science Citation Index SCI. Phrase frequency analysis by the technical domain experts provided the pervasive technical themes of the Wireless LAN database, and the phrase proximity analysis provided the relationships among the pervasive technical themes. Bibliometric analysis of the Wireless LAN literature supplemented the DT results with authorjournalinstitution publication and citation data.Descriptors:",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:e_rmSamDkqQC",
            "Publisher": "OFFICE OF NAVAL RESEARCH ARLINGTON VA"
        },
        {
            "Title": "A generalized framework for protein sequence annotation",
            "Publication year": 2007,
            "Publication url": "https://conservancy.umn.edu/handle/11299/215737",
            "Abstract": "Over the last decade several data mining techniques have been developed for determining structural and functional properties of individual protein residues using sequence and sequence-derived information. These protein residue annotation problems are often formulated as either classification or regression problems and solved using a common set of techniques.  We develop a generalized protein sequence annotation toolkit (prosat) for solving classification or regression problems using support vector machines. The key characteristic of our method is its effective use of window-based information to capture the local environment of a protein sequence residue. This window information is used with several kernel functions available within our framework. We show the effectiveness of using the previously developed normalized second order exponential kernel function and experiment with local window-based information at different levels of granularity.  We report empirical results on a diverse set of classification and regression problems: prediction of solvent accessibility, secondary structure, local structure alphabet, transmembrane helices, DNA-protein interaction sites, contact order, and regions of disorder are all explored. Our methods show either comparable or superior results to several state-of-the-art application tuned prediction methods for these problems. prosat provides practitioners an efficient and easy-to-use tool for a wide variety of annotation problems. The results of some of these predictions can be used to assist in solving the overarching 3D structure prediction problem.",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:Y5dfb0dijaUC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Frequent substructure-based approaches for classifying chemical compounds",
            "Publication year": 2005,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/1458698/",
            "Abstract": "Computational techniques that build models to correctly assign chemical compounds to various classes of interest have many applications in pharmaceutical research and are used extensively at various phases during the drug development process. These techniques are used to solve a number of classification problems such as predicting whether or not a chemical compound has the desired biological activity, is toxic or nontoxic, and filtering out drug-like compounds from large compound libraries. This paper presents a substructure-based classification algorithm that decouples the substructure discovery process from the classification model construction and uses frequent subgraph discovery algorithms to find all topological and geometric substructures present in the data set. The advantage of this approach is that during classification model construction, all relevant substructures are available allowing the \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:rTD5ala9j4wC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Comparison of descriptor spaces for chemical compound retrieval and classification",
            "Publication year": 2008,
            "Publication url": "https://link.springer.com/article/10.1007/s10115-007-0103-5",
            "Abstract": "In recent years the development of computational techniques that build models to correctly assign chemical compounds to various classes or to retrieve potential drug-like compounds has been an active area of research. Many of the best-performing techniques for these tasks utilize a descriptor-based representation of the compound that captures various aspects of the underlying molecular graph\u2019s topology. In this paper we compare five different set of descriptors that are currently used for chemical compound classification. We also introduce four different descriptors derived from all connected fragments present in the molecular graphs primarily for the purpose of comparing them to the currently used descriptor spaces and analyzing what properties of descriptor spaces are helpful in providing effective representation for molecular graphs. In addition, we introduce an extension to existing vector-based \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:zA6iFVUQeVQC",
            "Publisher": "Springer-Verlag"
        },
        {
            "Title": "Recent advances in recommender systems: Sets, local models, coverage, and errors",
            "Publication year": 2018,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/3184558.3191588",
            "Abstract": "Recommender systems are designed to identify the items that a user will like or find useful based on the user's prior preferences and activities. These systems have become ubiquitous and are an essential tool for information filtering and (e-) commerce. Over the years, collaborative filtering, which derive these recommendations by leveraging past activities of groups of users, has emerged as the most prominent approach for solving this problem. This talk will present some of our recent work towards improving the performance of collaborative filtering-based recommender systems and understanding some of their fundamental limitations and characteristics. It will start by analyzing how the ratings that users provide to a set of items relate to their ratings of the set's individual items and, using these insights, will present rating prediction approaches that utilize distant supervision. It will then discuss extensions to \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:c1AJUTjuCtUC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Local item-item models for top-n recommendation",
            "Publication year": 2016,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/2959100.2959185",
            "Abstract": "Item-based approaches based on SLIM (Sparse LInear Methods) have demonstrated very good performance for top-N recommendation; however they only estimate a single model for all the users. This work is based on the intuition that not all users behave in the same way--instead there exist subsets of like-minded users. By using different item-item models for these user subsets, we can capture differences in their preferences and this can lead to improved performance for top-N recommendations. In this work, we extend SLIM by combining global and local SLIM models. We present a method that computes the prediction scores as a user-specific combination of the predictions derived by a global and local item-item models. We present an approach in which the global model, the local models, their user-specific combination, and the assignment of users to the local models are jointly optimized to improve the top-N \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:Y9VhQm-5nPIC",
            "Publisher": "Unknown"
        },
        {
            "Title": "An Empirical Comparison of Deep Learning Models for Knowledge Tracing on Large-Scale Dataset",
            "Publication year": 2021,
            "Publication url": "https://arxiv.org/abs/2101.06373",
            "Abstract": "Knowledge tracing (KT) is the problem of modeling each student's mastery of knowledge concepts (KCs) as (s)he engages with a sequence of learning activities. It is an active research area to help provide learners with personalized feedback and materials. Various deep learning techniques have been proposed for solving KT. Recent release of large-scale student performance dataset \\cite{choi2019ednet} motivates the analysis of performance of deep learning approaches that have been proposed to solve KT. Our analysis can help understand which method to adopt when large dataset related to student performance is available. We also show that incorporating contextual information such as relation between exercises and student forget behavior further improves the performance of deep learning models.",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:hB2aVRuWZNwC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Expert Agreement and Content Based Reranking in a Meta Search Environment Using Mearf",
            "Publication year": 2001,
            "Publication url": "https://conservancy.umn.edu/handle/11299/215475",
            "Abstract": "Recent increase in the number of search engines on the Web and the availability of meta search engines that can query multiple search engines makes it important to find effective methods for combining results coming from different sources. In this paper we introduce novel methods for reranking in a meta search environment based on expert agreement and contents of the snippets. We also introduce an objective way of evaluating different methods for ranking search results. Our experimental evaluation shows that some of our methods produce rankings that are consistently better than the rankings produced by methods that are commonly used in many meta search engines as well as rankings produced by a popular search engine.",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:MNNNGtAgD4EC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Schema-Aware Deep Graph Convolutional Networks for Heterogeneous Graphs",
            "Publication year": 2021,
            "Publication url": "https://arxiv.org/abs/2105.00644",
            "Abstract": "Graph convolutional network (GCN) based approaches have achieved significant progress for solving complex, graph-structured problems. GCNs incorporate the graph structure information and the node (or edge) features through message passing and computes 'deep' node representations. Despite significant progress in the field, designing GCN architectures for heterogeneous graphs still remains an open challenge. Due to the schema of a heterogeneous graph, useful information may reside multiple hops away. A key question is how to perform message passing to incorporate information of neighbors multiple hops away while avoiding the well-known over-smoothing problem in GCNs. To address this question, we propose our GCN framework 'Deep Heterogeneous Graph Convolutional Network (DHGCN)', which takes advantage of the schema of a heterogeneous graph and uses a hierarchical approach to effectively utilize information many hops away. It first computes representations of the target nodes based on their 'schema-derived ego-network' (SEN). It then links the nodes of the same type with various pre-defined metapaths and performs message passing along these links to compute final node representations. Our design choices naturally capture the way a heterogeneous graph is generated from the schema. The experimental results on real and synthetic datasets corroborate the design choice and illustrate the performance gains relative to competing alternatives.",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:oH8HCDhqVGsC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Topic Modeling for Segment-based Documents.",
            "Publication year": 2012,
            "Publication url": "http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.679.5664&rep=rep1&type=pdf#page=221",
            "Abstract": "Statistical topic models have traditionally assumed that a document is an indivisible unit for the generative process, which may not be appropriate to handle documents that are relatively long and show an explicit multi-topic structure. In this paper we describe a generative model that exploits a given decomposition of documents in smaller, topically cohesive text units, or segments. The key-idea is to introduce a new variable in the generative process to model the document segments in order to relate the word generation not only to the topics but also to the segments. Moreover, the topic latent variable is directly associated to the segments, rather than to the document as a whole. Experimental results have shown the significance of the proposed model and its better support for the document clustering task compared to other existing generative models.",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:H_jBuBxbQIAC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Mining Transcriptome Data of Recombinant Mammalian Cells for Hyperproductivity Trait",
            "Publication year": 2008,
            "Publication url": "https://sim.confex.com/sim/2008/techprogram/P7910.HTM",
            "Abstract": "The productivity of recombinant mammalian cells has reached levels that rival professional protein secretors in vivo. Such hyperproductivity is a composite of many superior characteristics. To elucidate the high productivity trait, comparative transcriptome analysis of high producing cell lines and high productivity culture conditions have proved to be illuminating.Supervised machine learning tools were employed to identify expression patterns that correlate with productivity. Gene testing (GST) analysis was used to identify physiological functions that are enriched in high producers and high productivity culture conditions. Major functional classes identified include those involved in protein processing and transport, such as protein modification, vesicle trafficking and protein turnover. A significant proportion of genes involved in mitochondrial ribosomal function, cell cycle regulation, cytoskeleton-related elements are also differentially up-regulated in high producers.",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:uDGL6kOW6j0C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Efficient closed pattern mining in the presence of tough block constraints",
            "Publication year": 2004,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/1014052.1014070",
            "Abstract": "Various constrained frequent pattern mining problem formulations and associated algorithms have been developed that enable the user to specify various itemset-based constraints that better capture the underlying application requirements and characteristics. In this paper we introduce a new class of block constraints that determine the significance of an itemset pattern by considering the dense block that is formed by the pattern's items and its associated set of transactions. Block constraints provide a natural framework by which a number of important problems can be specified and make it possible to solve numerous problems on binary and real-valued datasets. However, developing computationally efficient algorithms to find these block constraints poses a number of challenges as unlike the different itemset-based constraints studied earlier, these block constraints are tough as they are neither anti-monotone \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:D03iK_w7-QYC",
            "Publisher": "Unknown"
        },
        {
            "Title": "GrAPL 2020 Keynote Speaker Deep Graph Library: Overview, Updates, and Future Developments.",
            "Publication year": 2020,
            "Publication url": "https://scholar.google.com/scholar?cluster=2076176650896424473&hl=en&oi=scholarr",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:U5uP8zs9lfgC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Proceedings of the 7th ACM Conference on Recommender Systems",
            "Publication year": 2013,
            "Publication url": "https://repository.ust.hk/ir/Record/1783.1-78400",
            "Abstract": "The proceedings contain 95 papers. The topics discussed include: context-aware review helpfulness rating prediction; query-driven context aware recommendation; location-aware music recommendation using auto-tagging and hybrid matching; spatial topic modeling in online social media for location recommendation; orthogonal query recommendation; understanding and improving relational matrix factorization in recommender systems; retargeted matrix factorization for collaborative filtering; trading-off among accuracy, similarity, diversity, and long-tail: a graph-based recommendation approach; nonlinear latent factorization by embedding multiple user interests; diffusion-aware personalized social update recommendation; recommending branded products from social media; and exploring temporal effects for location recommendation on location-based social networks.",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:1Aeql8wG3wEC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Target fishing for chemical compounds using target-ligand activity data and ranking based methods",
            "Publication year": 2009,
            "Publication url": "https://pubs.acs.org/doi/abs/10.1021/ci9000376",
            "Abstract": "In recent years, the development of computational techniques that identify all the likely targets for a given chemical compound, also termed as the problem of Target Fishing, has been an active area of research. Identification of likely targets of a chemical compound in the early stages of drug discovery helps to understand issues such as selectivity, off-target pharmacology, and toxicity. In this paper, we present a set of techniques whose goal is to rank or prioritize targets in the context of a given chemical compound so that most targets against which this compound may show activity appear higher in the ranked list. These methods are based on our extensions to the SVM and ranking perceptron algorithms for this problem. Our extensive experimental study shows that the methods developed in this work outperform previous approaches 2% to 60% under different evaluation criterions.",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:eMMeJKvmdy0C",
            "Publisher": "American Chemical Society"
        },
        {
            "Title": "Programming shared address space platforms",
            "Publication year": 2003,
            "Publication url": "http://www.cs.purdue.edu/homes/ayg/book/Slides/chap7_slides.pdf",
            "Abstract": "Programming Shared Address Space Platforms Page 1 Programming Shared Address Space \nPlatforms Ananth Grama, Anshul Gupta, George Karypis, and Vipin Kumar To accompany the \ntext \u201cIntroduction to Parallel Computing\u201d, Addison Wesley, 2003. Page 2 Topic Overview \u2022 \nThread Basics \u2022 The POSIX Thread API \u2022 Synchronization Primitives in Pthreads \u2022 Controlling \nThread and Synchronization Attributes \u2022 Composite Synchronization Constructs \u2022 OpenMP: a \nStandard for Directive Based Parallel Programming Page 3 Overview of Programming Models \n\u2022 Programming models provide support for expressing concurrency and synchronization. \u2022 \nProcess based models assume that all data associated with a process is private, by default, \nunless otherwise specified. \u2022 Lightweight processes and threads assume that all memory is \nglobal. \u2022 Directive based programming models extend the threaded model by facilitating and [\u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:IExZWSxeYXUC",
            "Publisher": "Addison-Wesley"
        },
        {
            "Title": "Sparse neural attentive knowledge-based models for grade prediction",
            "Publication year": 2019,
            "Publication url": "https://arxiv.org/abs/1904.11858",
            "Abstract": "Grade prediction for future courses not yet taken by students is important as it can help them and their advisers during the process of course selection as well as for designing personalized degree plans and modifying them based on their performance. One of the successful approaches for accurately predicting a student's grades in future courses is Cumulative Knowledge-based Regression Models (CKRM). CKRM learns shallow linear models that predict a student's grades as the similarity between his/her knowledge state and the target course. A student's knowledge state is built by linearly accumulating the learned provided knowledge components of the courses he/she has taken in the past, weighted by his/her grades in them. However, not all the prior courses contribute equally to the target course. In this paper, we propose a novel Neural Attentive Knowledge-based model (NAK) that learns the importance of each historical course in predicting the grade of a target course. Compared to CKRM and other competing approaches, our experiments on a large real-world dataset consisting of 1.5 grades show the effectiveness of the proposed NAK model in accurately predicting the students' grades. Moreover, the attention weights learned by the model can be helpful in better designing their degree plans.",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:QKtdBID3u5MC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Nlmf: Nonlinear matrix factorization methods for top-n recommender systems",
            "Publication year": 2014,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/7022594/",
            "Abstract": "Many existing state-of-the-art top-N recommendation methods model users and items in the same latent space and the recommendation scores are computed via the dot product between those vectors. These methods assume that the user preference is consistent across all the items that he/she has rated. This assumption is not necessarily true, since many users can have multiple personas/interests and their preferences can vary with each such interest. To address this, a recently proposed method modeled the users with multiple interests. In this paper, we build on this approach and model users using a much richer representation. We propose a method which models the user preference as a combination of having global preference and interest-specific preference. The proposed method uses a nonlinear model for predicting the recommendation score, which is used to perform top-N recommendation task. The \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:sfnaS5RM6jYC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Assessing synthetic accessibility of chemical compounds using machine learning methods",
            "Publication year": 2010,
            "Publication url": "https://pubs.acs.org/doi/abs/10.1021/ci900301v",
            "Abstract": "With de novo rational drug design, scientists can rapidly generate a very large number of potentially biologically active probes. However, many of them may be synthetically infeasible and, therefore, of limited value to drug developers. On the other hand, most of the tools for synthetic accessibility evaluation are very slow and can process only a few molecules per minute. In this study, we present two approaches to quickly predict the synthetic accessibility of chemical compounds by utilizing support vector machines operating on molecular descriptors. The first approach, RSsvm, is designed to identify the compounds that can be synthesized using a specific set of reactions and starting materials and builds its model by training on the compounds identified as synthetically accessible or not by retrosynthetic analysis. The second approach, DRsvm, is designed to provide a more general assessment of synthetic \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:ye4kPcJQO24C",
            "Publisher": "American Chemical Society"
        },
        {
            "Title": "On mining instance-centric classification rules",
            "Publication year": 2006,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/1704802/",
            "Abstract": "Many studies have shown that rule-based classifiers perform well in classifying categorical and sparse high-dimensional databases. However, a fundamental limitation with many rule-based classifiers is that they find the rules by employing various heuristic methods to prune the search space and select the rules based on the sequential database covering paradigm. As a result, the final set of rules that they use may not be the globally best rules for some instances in the training database. To make matters worse, these algorithms fail to fully exploit some more effective search space pruning methods in order to scale to large databases. In this paper, we present a new classifier, HARMONY, which directly mines the final set of classification rules. HARMONY uses an instance-centric rule-generation approach and it can assure that, for each training instance, one of the highest-confidence rules covering this instance is \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:_xSYboBqXhAC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Graph partitioning and parallel computing",
            "Publication year": 2000,
            "Publication url": "https://dl.acm.org/doi/abs/10.1016/S0167-8191%2800%2900042-9",
            "Abstract": "Graph partitioning and parallel computing | Parallel Computing ACM Digital Library home ACM \nhome Google, Inc. (search) Advanced Search Browse About Sign in Register Advanced Search \nJournals Magazines Proceedings Books SIGs Conferences People More Search ACM Digital \nLibrary SearchSearch Advanced Search Parallel Computing Periodical Home Latest Issue \nArchive Authors Affiliations Award Winners More HomeBrowse by TitlePeriodicalsParallel \nComputingVol. , No. Graph partitioning and parallel computing article Graph partitioning and \nparallel computing Share on Authors: Rupak Biswas View Profile , Bruce Hendrickson View \nProfile , George Karypis View Profile Authors Info & Affiliations Parallel ComputingVolume \n26Issue 12Nov. 2000 pp 1515\u20131517 https://doi.org/10.1016/S0167-8191(00)00042-9 \nPublished:01 November 2000 3citation 0 Downloads Metrics Total Citations3 Total Downloads0 \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:PR6Y55bgFSsC",
            "Publisher": "Elsevier Science Publishers BV"
        },
        {
            "Title": "Partitioning algorithms for simultaneously balancing iterative and direct methods",
            "Publication year": 2004,
            "Publication url": "Unknown",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:zLWjf1WUPmwC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Learning preferences of new users in recommender systems: an information theoretic approach",
            "Publication year": 2008,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/1540276.1540302",
            "Abstract": "Recommender systems are an effective tool to help find items of interest from an overwhelming number of available items. Collaborative Filtering (CF), the best known technology for recommender systems, is based on the idea that a set of like-minded users can help each other find useful information. A new user poses a challenge to CF recommenders, since the system has no knowledge about the preferences of the new user, and therefore cannot provide personalized recommendations. A new user preference elicitation strategy needs to ensure that the user does not a) abandon a lengthy signup process, and b) lose interest in returning to the site due to the low quality of initial recommendations. We extend the work of [23] in this paper by incrementally developing a set of information theoretic strategies for the new user problem. We propose an offline simulation framework, and evaluate the strategies through \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:UxriW0iASnsC",
            "Publisher": "ACM"
        },
        {
            "Title": "Frequent subgraph discovery",
            "Publication year": 2001,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/989534/",
            "Abstract": "As data mining techniques are being increasingly applied to non-traditional domains, existing approaches for finding frequent itemsets cannot be used as they cannot model the requirement of these domains. An alternate way of modeling the objects in these data sets is to use graphs. Within that model, the problem of finding frequent patterns becomes that of discovering subgraphs that occur frequently over the entire set of graphs.The authors present a computationally efficient algorithm for finding all frequent subgraphs in large graph databases. We evaluated the performance of the algorithm by experiments with synthetic datasets as well as a chemical compound dataset. The empirical results show that our algorithm scales linearly with the number of input transactions and it is able to discover frequent subgraphs from a set of graph transactions reasonably fast, even though we have to deal with computationally \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:zYLM7Y9cAGgC",
            "Publisher": "IEEE"
        },
        {
            "Title": "User-Specific Feature-Based Similarity Models for Top-n Recommendation of New Items",
            "Publication year": 2015,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/2700495",
            "Abstract": "Recommending new items for suitable users is an important yet challenging problem due to the lack of preference history for the new items. Noncollaborative user modeling techniques that rely on the item features can be used to recommend new items. However, they only use the past preferences of each user to provide recommendations for that user. They do not utilize information from the past preferences of other users, which can potentially be ignoring useful information. More recent factor models transfer knowledge across users using their preference information in order to provide more accurate recommendations. These methods learn a low-rank approximation for the preference matrix, which can lead to loss of information. Moreover, they might not be able to learn useful patterns given very sparse datasets. In this work, we present UFSM, a method for top-n recommendation of new items given binary user \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:dAp6zn-oMfAC",
            "Publisher": "ACM"
        },
        {
            "Title": "Finding frequent patterns in a large sparse graph",
            "Publication year": 2005,
            "Publication url": "https://link.springer.com/article/10.1007/s10618-005-0003-9",
            "Abstract": "Graph-based modeling has emerged as a powerful abstraction capable of capturing in a single and unified framework many of the relational, spatial, topological, and other characteristics that are present in a variety of datasets and application areas. Computationally efficient algorithms that find patterns corresponding to frequently occurring subgraphs play an important role in developing data mining-driven methodologies for analyzing the graphs resulting from such datasets. This paper presents two algorithms, based on the horizontal and vertical pattern discovery paradigms, that find the connected subgraphs that have a sufficient number of edge-disjoint embeddings in a single large undirected labeled sparse graph. These algorithms use three different methods for determining the number of edge-disjoint embeddings of a subgraph and employ novel algorithms for candidate generation and frequency \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:4TOpqqG69KYC",
            "Publisher": "Springer US"
        },
        {
            "Title": "Incremental window-based protein sequence alignment algorithms",
            "Publication year": 2007,
            "Publication url": "https://academic.oup.com/bioinformatics/article-abstract/23/2/e17/201850",
            "Abstract": " Motivation: Protein sequence alignment plays a critical role in computational biology as it is an integral part in many analysis tasks designed to solve problems in comparative genomics, structure and function prediction, and homology modeling. Methods: We have developed novel sequence alignment algorithms that compute the alignment between a pair of sequences based on short fixed- or variable-length high-scoring subsequences. Our algorithms build the alignments by repeatedly selecting the highest scoring pairs of subsequences and using them to construct small portions of the final alignment. We utilize PSI-BLAST generated sequence profiles and employ a profile-to-profile scoring scheme derived from PICASSO. Results: We evaluated the performance of the computed alignments on two recently published benchmark datasets and compared them against the alignments \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:D_sINldO8mEC",
            "Publisher": "Oxford University Press"
        },
        {
            "Title": "Global gene expression profiling in three lupus mouse models identifies distinct and conserved immune pathways contributing to disease.",
            "Publication year": 2005,
            "Publication url": "https://scholar.google.com/scholar?cluster=10090966102381834578&hl=en&oi=scholarr",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:LXmCCkuhhTsC",
            "Publisher": "WILEY-BLACKWELL"
        },
        {
            "Title": "Scalability and Distribution of Collaborative Recommenders.",
            "Publication year": 2018,
            "Publication url": "https://www-users.cs.umn.edu/~chri2951/chapter11.pdf",
            "Abstract": "Recommender systems are ubiquitous; they are foundational to a wide variety of industries ranging from media companies such as Netflix to ecommerce companies such as Amazon. As recommender systems continue to permeate the marketplace, we observe two major shifts which must be addressed. First, the amount of data used to provide quality recommendations grows at an unprecedented rate. Secondly, modern computer architectures display great processing capabilities that significantly outpace memory speeds. These two trend shifts must be taken into account in order to design recommendation systems that can efficiently handle the amount of available data by distributing computations in order to take advantage of modern parallel architectures. In this chapter, we present ways to scale popular collaborative recommendation methods via parallel computing.",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:wBLCggQE-ToC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Comparative Analysis of Genomic Alternations Between Chinese Hamster and CHO Cell Line.",
            "Publication year": 2012,
            "Publication url": "https://scholar.google.com/scholar?cluster=11669606138079257484&hl=en&oi=scholarr",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:3A3nxV7CjKIC",
            "Publisher": "AMER SOC CELL BIOLOGY"
        },
        {
            "Title": "Expert agreement and content based reranking in a meta search environment using Mearf",
            "Publication year": 2002,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/511446.511490",
            "Abstract": "Recent increase in the number of search engines on the Web and the availability of meta search engines that can query multiple search engines makes it important to find effective methods for combining results coming from different sources. In this paper we introduce novel methods for reranking in a meta search environment based on expert agreement and contents of the snippets. We also introduce an objective way of evaluating different methods for ranking search results that is based upon implicit user judgements. We incorporated our methods and two variations of commonly used merging methods in our meta search engine, Mearf, and carried out an experimental study using logs accumulated over a period of twelve months. Our experiments show that the choice of the method used for merging the output produced by different search engines plays a significant role in the overall quality of the search results. In \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:GnPB-g6toBAC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Soft clustering criterion functions for partitional document clustering: a summary of results",
            "Publication year": 2004,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/1031171.1031225",
            "Abstract": "Recently published studies have shown that partitional clustering algorithms that optimize certain criterion functions, which measure key aspects of inter-and intra-cluster similarity, are very effective in producing hard clustering solutions for document datasets and outperform traditional partitional and agglomerative algorithms. In this paper we study the extent to which these criterion functions can be modified to include soft membership functions and whether or not the resulting soft clustering algorithms can further improve the clustering solutions. Specifically, we focus on four of these hard criterion functions, derive their soft-clustering extensions, and present an experimental evaluation involving twelve different datasets. Our results show that introducing softness into the criterion functions tends to lead to better clustering results for most datasets.",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:738O_yMBCRsC",
            "Publisher": "Unknown"
        },
        {
            "Title": "TR O1-O27",
            "Publication year": 2001,
            "Publication url": "https://scholar.google.com/scholar?cluster=13237683552701727193&hl=en&oi=scholarr",
            "Abstract": "Recent increase in the number of search engines On the Web and the availability of meta search engines that can query multiple search engines makes it important to \ufb01nd effective methods for combining results coming from different sources. In this paper we introduce novel methods for reranking in a meta search environment based on expert agreement and contents of the snippets. We also introduce an objective way of evaluating different methods for ranking search results. Our experimental evaluation shows that some of our methods produce rankings that are consistently better than the rankings produced by methods that are commonly used in many meta search engines as well as rankings produced by a popular search engine.",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:4xDN1ZYqzskC",
            "Publisher": "Unknown"
        },
        {
            "Title": "AFGEN2. 0",
            "Publication year": 2008,
            "Publication url": "https://conservancy.umn.edu/handle/11299/215763",
            "Abstract": "AFGEN2.0 is a program that generates descriptor spaces for chemical compound(s). The descriptor space consists of graph fragments that can have three different types of topologies: paths (PF), acyclic subgraphs (AF), and arbitrary topology subgraphs (GF).",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:TeJ9juy8vcMC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Universal Representation for Code",
            "Publication year": 2021,
            "Publication url": "https://arxiv.org/abs/2103.03116",
            "Abstract": "Learning from source code usually requires a large amount of labeled data. Despite the possible scarcity of labeled data, the trained model is highly task-specific and lacks transferability to different tasks. In this work, we present effective pre-training strategies on top of a novel graph-based code representation, to produce universal representations for code. Specifically, our graph-based representation captures important semantics between code elements (e.g., control flow and data flow). We pre-train graph neural networks on the representation to extract universal code properties. The pre-trained model then enables the possibility of fine-tuning to support various downstream applications. We evaluate our model on two real-world datasets -- spanning over 30M Java methods and 770K Python methods. Through visualization, we reveal discriminative properties in our universal code representation. By comparing multiple benchmarks, we demonstrate that the proposed framework achieves state-of-the-art results on method name prediction and code graph link prediction.",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:jRIwE-1ttnoC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Coarse\u2010and fine\u2010grained models for proteins: Evaluation by decoy discrimination",
            "Publication year": 2013,
            "Publication url": "https://onlinelibrary.wiley.com/doi/abs/10.1002/prot.24222",
            "Abstract": "Coarse\u2010grained models for protein structure are increasingly used in simulations and structural bioinformatics. In this study, we evaluated the effectiveness of three granularities of protein representation based on their ability to discriminate between correctly folded native structures and incorrectly folded decoy structures. The three levels of representation used one bead per amino acid (coarse), two beads per amino acid (medium), and all atoms (fine). Multiple structure features were compared at each representation level including two\u2010body interactions, three\u2010body interactions, solvent exposure, contact numbers, and angle bending. In most cases, the all\u2010atom level was most successful at discriminating decoys, but the two\u2010bead level provided a good compromise between the number of model parameters which must be estimated and the accuracy achieved. The most effective feature type appeared to be two \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:w1MjKQ0l0TYC",
            "Publisher": "Wiley Subscription Services, Inc., A Wiley Company"
        },
        {
            "Title": "Meta-learning via Language Model In-context Tuning",
            "Publication year": 2021,
            "Publication url": "https://arxiv.org/abs/2110.07814",
            "Abstract": "The goal of meta-learning is to learn to adapt to a new task with only a few labeled examples. To tackle this problem in NLP, we propose $\\textit{in-context tuning}$, which recasts adaptation and prediction as a simple sequence prediction problem: to form the input sequence, we concatenate the task instruction, the labeled examples, and the target input to predict; to meta-train the model to learn from in-context examples, we fine-tune a pre-trained language model (LM) to predict the target label from the input sequences on a collection of tasks. We benchmark our method on two collections of text classification tasks: LAMA and BinaryClfs. Compared to first-order MAML which adapts the model with gradient descent, our method better leverages the inductive bias of LMs to perform pattern matching, and outperforms MAML by an absolute $6\\%$ AUC ROC score on BinaryClfs, with increasing advantage w.r.t. model size. Compared to non-fine-tuned in-context learning (i.e. prompting a raw LM), in-context tuning directly learns to learn from in-context examples. On BinaryClfs, in-context tuning improves the average AUC-ROC score by an absolute $10\\%$, and reduces the variance with respect to example ordering by 6x and example choices by 2x.",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:EsrhoZGmrkoC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Multi-task learning for recommender system",
            "Publication year": 2010,
            "Publication url": "http://proceedings.mlr.press/v13/ning10a.html",
            "Abstract": "This paper focuses on exploring personalized multi-task learning approaches for collaborative filtering towards the goal of improving the prediction performance of rating prediction systems. These methods first specifically identify a set of users that are closely related to the user under consideration (ie, active user), and then learn multiple rating prediction models simultaneously, one for the active user and one for each of the related users. Such learning for multiple models (tasks) in parallel is implemented by representing all learning instances (users and items) using a coupled user-item representation, and within errorinsensitive Support Vector Regression (e-SVR) framework applying multi-task kernel tricks. A comprehensive set of experiments shows that multi-task learning approaches lead to significant performance improvement over conventional alternatives.",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:p__nRnzSRKYC",
            "Publisher": "JMLR Workshop and Conference Proceedings"
        },
        {
            "Title": "Within-network classification using local structure similarity",
            "Publication year": 2009,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-642-04180-8_34",
            "Abstract": "Within-network classification, where the goal is to classify the nodes of a partly labeled network, is a semi-supervised learning problem that has applications in several important domains like image processing, the classification of documents, and the detection of malicious activities. While most methods for this problem infer the missing labels collectively based on the hypothesis that linked or nearby nodes are likely to have the same labels, there are many types of networks for which this assumption fails, e.g., molecular graphs, trading networks, etc. In this paper, we present a collective classification method, based on relaxation labeling, that classifies entities of a network using their local structure. This method uses a marginalized similarity kernel that compares the local structure of two nodes with random walks in the network. Through experimentation on different datasets, we show our method to be more \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:t6usbXjVLHcC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "A medium-grained algorithm for sparse tensor factorization",
            "Publication year": 2016,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/7516087/",
            "Abstract": "Modeling multi-way data can be accomplished using tensors, which are data structures indexed along three or more dimensions. Tensors are increasingly used to analyze extremely large and sparse multi-way datasets in life sciences, engineering, and business. The canonical polyadic decomposition (CPD) is a popular tensor factorization for discovering latent features and is most commonly found via the method of alternating least squares (CPD-ALS). The computational time and memory required to compute CPD limits the size and dimensionality of the tensors that can be solved on a typical workstation, making distributed solution approaches the only viable option. Most methods for distributed-memory systems have focused on distributing the tensor in a coarse-grained, one-dimensional fashion that prohibitively requires the dense matrix factors to be fully replicated on each node. Recent work overcomes this \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:xGWFX6Gbr9MC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Deep graph library: A graph-centric, highly-performant package for graph neural networks",
            "Publication year": 2019,
            "Publication url": "https://arxiv.org/abs/1909.01315",
            "Abstract": "Advancing research in the emerging field of deep graph learning requires new tools to support tensor computation over graphs. In this paper, we present the design principles and implementation of Deep Graph Library (DGL). DGL distills the computational patterns of GNNs into a few generalized sparse tensor operations suitable for extensive parallelization. By advocating graph as the central programming abstraction, DGL can perform optimizations transparently. By cautiously adopting a framework-neutral design, DGL allows users to easily port and leverage the existing components across multiple deep learning frameworks. Our evaluation shows that DGL significantly outperforms other popular GNN-oriented frameworks in both speed and memory consumption over a variety of benchmarks and has little overhead for small scale workloads.",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:pxXbYLTb8EgC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Cluto: Software for clustering high dimensional datasets",
            "Publication year": 2006,
            "Publication url": "https://scholar.google.com/scholar?cluster=6449303008247396662&hl=en&oi=scholarr",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:ybfzIt2tCtgC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Efficient algorithms for creating product catalogs",
            "Publication year": 2000,
            "Publication url": "https://apps.dtic.mil/sti/citations/ADA439548",
            "Abstract": "For the purposes of this paper we define a catalog to be a promotional catalog, ie, a collection of products items presented to a customer with the hope of encouraging a purchase. The single mailing problem addresses how to build a collection of catalogs and distribute them to customers one per customer so as to achieve an optimal outcome, eg, the most profit. Each catalog is a subset of a given set of items and different catalogs may contain some of the same items, ie, catalogs may overlap. A slightly more general, but important extension of the single mailing problem seeks the optimal set of catalogs when multiple mailings are allowed, ie, multiple catalogs can be sent to each customer. Catalog creation has important applications for e-commerce and traditional brick-and-mortar retailers, especially when used with personalized recommender systems. The catalog creation problem is NP complete and some relatively expensive approximation algorithms have recently been developed. In this paper we describe more efficient techniques for building catalogs and show that these algorithms outperform one of the previously suggested approaches. Indeed, the techniques previously suggested are not feasible for realistic numbers of customers and catalogs. Some of our techniques directly use the objective function, eg, maximize profit, to find a locally optimal solution in an approach based on gradient ascent. However, by combining such techniques with the clustering of similar customers, better results can sometimes be obtained. We also analyze the performance of our algorithms with respect to a theoretical bound and show that, in some cases \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:WqliGbK-hY8C",
            "Publisher": "MINNESOTA UNIV MINNEAPOLIS DEPT OF COMPUTER SCIENCE"
        },
        {
            "Title": "Feature-based similarity models for top-n recommendation of new items",
            "Publication year": 2014,
            "Publication url": "https://conservancy.umn.edu/handle/11299/215953",
            "Abstract": "Recommending new items for suitable users is an important yet challenging problem due to the lack of preference history for the new items. Non-collaborative user modeling techniques that rely on the item features can be used to recommend new items. However, they only use the past preferences of each user to provide recommendations for that user. They do not utilize information from the past preferences of other users which can potentially be ignoring useful information. More recent factor models transfer knowledge across users using their preference information in order to provide more accurate recommendations. These methods learn a low rank approximation for the preference matrix which can lead to loss of information. Moreover, they might not be able to learn useful patterns given very sparse datasets. In this work we present FSM, a method for top-n recommendation of new items given binary user preferences. FSM learns Feature-based item-Similarity Models and its strength lies in combining two points: (i) exploiting preference information across all users to learn multiple global item similarity functions, and (ii) learning user-specific weights that determine the contribution of each global similarity function in generating recommendations for each user. FSM can be considered as a sparse high-dimensional factor model where the previous preferences of each user are incorporated within his latent representation. This way FSM combines the merits of item similarity models that capture local relations among items and factor models that learn global preference patterns. A comprehensive set of experiments was conduced to compare FSM \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:s85pQhAUCrAC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Parallel programming platforms",
            "Publication year": 2003,
            "Publication url": "https://web.cse.msstate.edu/~ioana/Courses/CS8843/SLIDES/INTRO_PAR_COMP/Chapter%202.pdf",
            "Abstract": "2.1. 1 Pipelining and Superscalar Execution: Processors have long relied on pipelines for improving execution rates. By overlapping various stages in instruction execution (fetch, schedule, decode, operand fetch, execute, store, among others), pipelining enables faster execution. The speed of a single pipeline is limited by the largest atomic task in the pipeline. In typical instruction traces, every fifth to sixth instruction is a branch instruction. Long instruction pipelines needs effective techniques for predicting branch destinations so that pipelines can be speculatively filled.The penalty of a misprediction increases as the pipelines become deeper since a larger number of instructions need to be flushed. These factors place limitations on the depth of a processor pipeline and the resulting performance gains. way to improve the performance beyond this level is to use multiple pipelines. An example to illustrate pipelining:",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:KqnX2w3egDsC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Upm: Discovering course enrollment sequences associated with success",
            "Publication year": 2019,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/3303772.3303799",
            "Abstract": "Identifying enrollment patterns associated with course success can help educators design better degree plans, and students make informed decisions about future enrollments. While discriminating pattern mining techniques can be used to address this problem, course enrollment patterns include sequence and quantity (grades) information. None of the existing methods were designed to account for both factors. In this work we present UPM, a Universal discriminating Pattern Mining framework that simultaneously mines various types of enrollment patterns while accounting for sequence and quantity using an expansion-specific approach. Unlike the existing methods, UPM expands a given pattern with an item by finding a minimum-entropy split over the item's quantities. We then use UPM to extract discriminating enrollment patterns from the high and the low performing student groups. These patterns can be utilized \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:oldoQiaHq2UC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Soft Clustering Criterion Functions for Partitional Document Clustering: A Summary of Results",
            "Publication year": 2004,
            "Publication url": "https://scholar.google.com/scholar?cluster=9138072221655659633&hl=en&oi=scholarr",
            "Abstract": "Recently published studies have shown that partitional clustering algorithms that optimize certain criterion functions, which measure key aspects of inter-and intra-cluster similarity, are very effective in producing hard clustering solutions for document datasets and outperform traditional partitional and agglomerative algorithms. In this paper we study the extent to which these criterion functions can be modified to include soft membership functions and whether or not the resulting soft clustering algorithms can further improve the clustering solutions. Specifically, we focus on four of these hard criterion functions, derive their soft-clustering extensions, and present an experimental evaluation involving twelve different datasets. Our results show that introducing softness into the criterion func-tions tends to lead to better clustering results for most datasets.",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:Q3-QASNKTMEC",
            "Publisher": "Association for Computing Machinery"
        },
        {
            "Title": "Multi-threaded modularity based graph clustering using the multilevel paradigm",
            "Publication year": 2015,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S0743731514001750",
            "Abstract": "Graphs are an important tool for modeling data in many diverse domains. Recent increase in sensor technology and deployment, the adoption of online services, and the scale of VLSI circuits has caused the size of these graphs to skyrocket. Finding clusters of highly connected vertices within these graphs is a critical part of their analysis. In this paper we apply the multilevel paradigm to the modularity graph clustering problem. We improve upon the state of the art by introducing new efficient methods for coarsening graphs, creating initial clusterings, and performing local refinement on the resulting clusterings. We establish that for a graph with n vertices and m edges, these algorithms have an O (m+ n) runtime complexity and an O (m+ n) space complexity, and show that in practice they are extremely fast. We present shared-memory parallel formulations of these algorithms to take full advantage of modern \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:YB4bud6kWLwC",
            "Publisher": "Academic Press"
        },
        {
            "Title": "Evaluation of Item-Based Top-N Recommendation Algorithms",
            "Publication year": 2001,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/502585.502627",
            "Abstract": "The explosive growth of the world-wide-web and the emergence of e-commerce has led to the development of recommender systems---a personalized information filtering technology used to identify a set of N items that will be of interest to a certain user. User-based Collaborative filtering is the most successful technology for building recommender systems to date, and is extensively used in many commercial recommender systems. Unfortunately, the computational complexity of these methods grows linearly with the number of customers that in typical commercial applications can grow to be several millions. To address these scalability concerns item-based recommendation techniques have been developed that analyze the user-item matrix to identify relations between the different items, and use these relations to compute the list of recommendations. In this paper we present one such class of item-based \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:Se3iqnhoufwC",
            "Publisher": "Unknown"
        },
        {
            "Title": "HARMONY: Efficiently mining the best rules for classification",
            "Publication year": 2005,
            "Publication url": "https://epubs.siam.org/doi/abs/10.1137/1.9781611972757.19",
            "Abstract": "Many studies have shown that rule-based classifiers perform well in classifying categorical and sparse high-dimensional databases. However, a fundamental limitation with many rule-based classifiers is that they find the rules by employing various heuristic methods to prune the search space, and select the rules based on the sequential database covering paradigm. As a result, the final set of rules that they use may not be the globally best rules for some instances in the training database. To make matters worse, these algorithms fail to fully exploit some more effective search space pruning methods in order to scale to large databases.In this paper we present a new classifier, HARMONY, which directly mines the final set of classification rules. HARMONY uses an instance-centric rule-generation approach and it can assure for each training instance, one of the highest-confidence rules covering this instance is \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:qUcmZB5y_30C",
            "Publisher": "Society for Industrial and Applied Mathematics"
        },
        {
            "Title": "Protein structure prediction using string kernels",
            "Publication year": 2007,
            "Publication url": "https://books.google.com/books?hl=en&lr=&id=uQJ8JIRBVxYC&oi=fnd&pg=PA145&dq=info:jb7-21fgyAgJ:scholar.google.com&ots=xph1CaW_Dn&sig=l1syjYhPvhtXRTRwusdFh1oMn5g",
            "Abstract": "With recent advances in large-scale sequencing technologies, we have seen exponential growth in protein sequence information. Currently, our ability to produce sequence information far outpaces the rate at which we can produce structural and functional information. Consequently, researchers rely increasingly on computational techniques to extract useful information from known structures contained in large databases, although such approaches remain incomplete. As such, unraveling the relationship between pure sequence information and three-dimensional structure remains one of the great fundamental problems in molecular biology. The motivation behind the structural determination of proteins is based on the belief that structural information will ultimately result in a better understanding of intricate biological processes. Many methods exist to predict protein structure at different levels of granularity. Due to the interest in this subject from a wide range of research communities, a biennial competition, the Critical Assessment for Structure Prediction (CASP; http://predictioncenter. org/) assesses the performance of current structure prediction methods. In this chapter we show several ways in which researchers try to characterize the structural, functional, and evolutionary nature of proteins.",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:uLbwQdceFCQC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Towards Enhancing Manufacturing Process Performance Through Multivariate Data Mining",
            "Publication year": 2012,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-94-007-0884-6_43",
            "Abstract": "Several newly approved protein-based therapeutics in the past decade are manufactured in modern production plants with automated systems for process control and comprehensive data archival. The hundreds of process parameters and key output variables for several production batches in the vast historical databases provide a valuable resource to improve process understanding and robustness. Multivariate data analysis is a critical process analytical technology tool to unearth any hidden patterns within process trends and identify key parameters for enhancing process performance and product quality. Cell culture process data from more than hundred \u201ctrains\u201d comprising production as well as inoculum bioreactors was investigated in this study. Each batch encompasses over 130 on-line and off-line temporal parameters. A maximum margin support vector algorithm was coupled with a kernel-based \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:artPoR2Yc-kC",
            "Publisher": "Springer, Dordrecht"
        },
        {
            "Title": "Document clustering: the next frontier",
            "Publication year": 2018,
            "Publication url": "Unknown",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:tHtfpZlB6tUC",
            "Publisher": "Chapman and Hall/CRC"
        },
        {
            "Title": "SUMMARY: Efficiently summarizing transactions for clustering",
            "Publication year": 2004,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/1410290/",
            "Abstract": "Frequent itemset mining was initially proposed and has been studied extensively in the context of association rule mining. In recent years, several studies have also extended its application to the transaction (or document) classification and clustering. However, most of the frequent-itemset based clustering algorithms need to first mine a large intermediate set of frequent itemsets in order to identify a subset of the most promising ones that can be used for clustering. In this paper, we study how to directly find a subset of high quality frequent itemsets that can be used as a concise summary of the transaction database and to cluster the categorical data. By exploring some properties of the subset of itemsets that we are interested in, we proposed several search space pruning methods and designed an efficient algorithm called SUMMARY. Our empirical results have shown that SUMMARY runs very fast even when the \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:Tiz5es2fbqcC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Using conjunction of attribute values for classification",
            "Publication year": 2002,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/584792.584851",
            "Abstract": "Advances in the efficient discovery of frequent itemsets have led to the development of a number of schemes that use frequent itemsets to aid developing accurate and efficient classifiers. These approaches use the frequent itemsets to generate a set of composite features that expand the dimensionality of the underlying dataset. In this paper, we build upon this work and (i) present a variety of schemes for composite feature selection that achieve a substantial reduction in the number of features without adversely affecting the accuracy gains, and (ii) show (both analytically and experimentally) that the composite features can lead to improved classification models even in the context of support vector machines, in which the dimensionality can automatically be expanded by the use of appropriate kernel functions.",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:CHSYGLWDkRkC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Repurpose open data to discover therapeutics for COVID-19 using deep learning",
            "Publication year": 2020,
            "Publication url": "https://pubs.acs.org/doi/abs/10.1021/acs.jproteome.0c00316",
            "Abstract": "There have been more than 2.2 million confirmed cases and over 120\u202f000 deaths from the human coronavirus disease 2019 (COVID-19) pandemic, caused by the novel severe acute respiratory syndrome coronavirus (SARS-CoV-2), in the United States alone. However, there is currently a lack of proven effective medications against COVID-19. Drug repurposing offers a promising route for the development of prevention and treatment strategies for COVID-19. This study reports an integrative, network-based deep-learning methodology to identify repurposable drugs for COVID-19 (termed CoV-KGE). Specifically, we built a comprehensive knowledge graph that includes 15 million edges across 39 types of relationships connecting drugs, diseases, proteins/genes, pathways, and expression from a large scientific corpus of 24 million PubMed publications. Using Amazon\u2019s AWS computing resources and a network \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:E8ajGqO0XoUC",
            "Publisher": "American Chemical Society"
        },
        {
            "Title": "Indirect similarity based methods for effective scaffold-hopping in chemical compounds",
            "Publication year": 2008,
            "Publication url": "Unknown",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:K3LRdlH-MEoC",
            "Publisher": "American Chemical Society"
        },
        {
            "Title": "Trust your neighbors: A comprehensive survey of neighborhood-based methods for recommender systems",
            "Publication year": 2021,
            "Publication url": "https://arxiv.org/abs/2109.04584",
            "Abstract": "Collaborative recommendation approaches based on nearest-neighbors are still highly popular today due to their simplicity, their efficiency, and their ability to produce accurate and personalized recommendations. This chapter offers a comprehensive survey of neighborhood-based methods for the item recommendation problem. It presents the main characteristics and benefits of such methods, describes key design choices for implementing a neighborhood-based recommender system, and gives practical information on how to make these choices. A broad range of methods is covered in the chapter, including traditional algorithms like k-nearest neighbors as well as advanced approaches based on matrix factorization, sparse coding and random walks.",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:KqW5X_olkfQC",
            "Publisher": "Unknown"
        },
        {
            "Title": "TR O5-O28",
            "Publication year": 2005,
            "Publication url": "https://scholar.google.com/scholar?cluster=2029721048858611224&hl=en&oi=scholarr",
            "Abstract": "Detecting and predicting a program's execution phases is crucial to dynamically adaptable systems and dynamic optimizations. Program execution phases have a strong connection to program control structures, in particular, loops and procedure calls. Intuitively, a phase can be associated with some dynamic code regions that are embedded in loops and procedures. This paper proposes ojf-line and on-line analysis techniques that could e\ufb02ectively identify and predict program phases by exploiting program control flow information. For ojf-line analyses, we introduce a dynamic interval analysis method that converts the complete program execution into an annotated tree with statistical information attached to each dynamic code region. It can ejficiently identify dynamic code regions associated with program execution phases at dijferent granularities. For on-line analyses, we propose new phase tracking hardware \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:PVjk1bu6vJQC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Multi-assay-based structure\u2212 activity relationship models: improving structure\u2212 activity relationship models by incorporating activity information from related targets",
            "Publication year": 2009,
            "Publication url": "https://pubs.acs.org/doi/abs/10.1021/ci900182q",
            "Abstract": "Structure\u2212activity relationship (SAR) models are used to inform and to guide the iterative optimization of chemical leads, and they play a fundamental role in modern drug discovery. In this paper, we present a new class of methods for building SAR models, referred to as multi-assay based, that utilize activity information from different targets. These methods first identify a set of targets that are related to the target under consideration, and then they employ various machine learning techniques that utilize activity information from these targets in order to build the desired SAR model. We developed different methods for identifying the set of related targets, which take into account the primary sequence of the targets or the structure of their ligands, and we also developed different machine learning techniques that were derived by using principles of semi-supervised learning, multi-task learning, and classifier ensembles \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:eflP2zaiRacC",
            "Publisher": "American Chemical Society"
        },
        {
            "Title": "A novel regression model combining instance based rule mining with em algorithm",
            "Publication year": 2013,
            "Publication url": "https://conservancy.umn.edu/handle/11299/215914",
            "Abstract": "In recent years, there have been increasing efforts to apply association rule mining to build Associative Classification (AC) models. However, the similar area that applies association rule mining to build Associative Regression (AR) models has not been well explored. In this work, we fill this gap by presenting a novel regression model based on association rules called AREM. AREM derives a set of regression rules by: (i) applying an instance based approach to mine itemsets which form the regression rules' left hand side, and (ii) developing a probabilistic model which determines, for each mined itemset, the corresponding rule's right hand side and the importance weight. To address the computational bottleneck of the traditional two-step approach for itemset mining, AREM utilizes an Instance-Based Itemset Miner (IBIMiner) algorithm that directly discovers the final set of itemsets. IBIMiner incorporates various methods to bound the quality of any future extensions of the itemset under consideration. These bounds are then used to prune the search space. In addition, AREM treats the regression rules' right hand side and importance weights as parameters of a probabilistic model, which are then learned in the expectation and maximization (EM) framework. The extensive experimental evaluation shows that our bounding strategies allow IBIMiner to considerably reduce the runtime and the EM optimization can improve the predictive performance dramatically. We also show that our model can perform better than some of the state of the art regression models.",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:PkcyUWeTMh0C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Content-based methods for predicting web-site demographic attributes",
            "Publication year": 2010,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/5694052/",
            "Abstract": "Demographic information plays an important role in gaining valuable insights about a web-site's user-base and is used extensively to target online advertisements and promotions. This paper investigates machine-learning approaches for predicting the demographic attributes of web-sites using information derived from their content and their hyper linked structure and not relying on any information directly or indirectly obtained from the web-site's users. Such methods are important because users are becoming increasingly more concerned about sharing their personal and behavioral information on the Internet. Regression-based approaches are developed and studied for predicting demographic attributes that utilize different content-derived features, different ways of building the prediction models, and different ways of aggregating web-page level predictions that take into account the web's hyper linked structure. In \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:TIZ-Mc8IlK0C",
            "Publisher": "IEEE"
        },
        {
            "Title": "TR O1-O21",
            "Publication year": 2001,
            "Publication url": "https://scholar.google.com/scholar?cluster=12473947185365670936&hl=en&oi=scholarr",
            "Abstract": "Geometric Multigrid methods have gained widespread acceptance for solving large systems of linear equations, especially for structured grids. One of the challenges in successfully extending these methods to unstructured grids is the problem of generating an appropriate set of coarse grids. Even though a number of different agglomerative approaches have been developed for coarse grid construction, there is still a great need for improvement because of the following two reasons. First, existing methods use locally greedy heuristics that often lead to coarse grids whose elements have poor quality (eg, bad aspect ratios). Second, these algorithms are serial in nature, and they cannot be efficiently parallelized. The focus of this paper is the development of robust algorithms, both serial and parallel, for generating a sequence of coarse grids from the original unstructured grid. Our algorithms treat the problem of coarse \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:sJsF-0ZLhtgC",
            "Publisher": "Unknown"
        },
        {
            "Title": "On efficiently summarizing categorical databases",
            "Publication year": 2006,
            "Publication url": "https://link.springer.com/article/10.1007/s10115-005-0216-7",
            "Abstract": "Frequent itemset mining was initially proposed and has been studied extensively in the context of association rule mining. In recent years, several studies have also extended its application to transaction or document clustering. However, most of the frequent itemset based clustering algorithms need to first mine a large intermediate set of frequent itemsets in order to identify a subset of the most promising ones that can be used for clustering. In this paper, we study how to directly find a subset of high quality frequent itemsets that can be used as a concise summary of the transaction database and to cluster the categorical data. By exploring key properties of the subset of itemsets that we are interested in, we proposed several search space pruning methods and designed an efficient algorithm called SUMMARY. Our empirical results show that SUMMARY runs very fast even when the minimum support is \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:uWQEDVKXjbEC",
            "Publisher": "Springer-Verlag"
        },
        {
            "Title": "A self-attentive model for knowledge tracing",
            "Publication year": 2019,
            "Publication url": "https://arxiv.org/abs/1907.06837",
            "Abstract": "Knowledge tracing is the task of modeling each student's mastery of knowledge concepts (KCs) as (s)he engages with a sequence of learning activities. Each student's knowledge is modeled by estimating the performance of the student on the learning activities. It is an important research area for providing a personalized learning platform to students. In recent years, methods based on Recurrent Neural Networks (RNN) such as Deep Knowledge Tracing (DKT) and Dynamic Key-Value Memory Network (DKVMN) outperformed all the traditional methods because of their ability to capture complex representation of human learning. However, these methods face the issue of not generalizing well while dealing with sparse data which is the case with real-world data as students interact with few KCs. In order to address this issue, we develop an approach that identifies the KCs from the student's past activities that are \\textit{relevant} to the given KC and predicts his/her mastery based on the relatively few KCs that it picked. Since predictions are made based on relatively few past activities, it handles the data sparsity problem better than the methods based on RNN. For identifying the relevance between the KCs, we propose a self-attention based approach, Self Attentive Knowledge Tracing (SAKT). Extensive experimentation on a variety of real-world dataset shows that our model outperforms the state-of-the-art models for knowledge tracing, improving AUC by 4.43% on average.",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:hKjooKYXoHIC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Parallel algorithms for mining sequential associations: Issues and challenges",
            "Publication year": 2000,
            "Publication url": "https://conservancy.umn.edu/handle/11299/215419",
            "Abstract": "Discovery of predictive sequential associations among events is becoming increasingly useful and essential in many scientific and commercial domains.  Enormous sizes of available datasets and possibly large number of mined associations demand efficient and scalable parallel algorithms.  In this paper, we first present a concept of universal sequential associations.  Developing parallel algorithms for discovering such associations becomes quite challenging depending on the nature of the input data and the timing constraints imposed on the desired associations.  We discuss possible challenging scenarios, and propose four different parallel algorithms that cater to various situations.  This paper is written to serve as a comprehensive account of the design issues and challenges involved in parallelizing sequential association discovery algorithms.",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:CdxZDUztZiMC",
            "Publisher": "Unknown"
        },
        {
            "Title": "TR O3-O47",
            "Publication year": 2003,
            "Publication url": "https://scholar.google.com/scholar?cluster=10653174867318383343&hl=en&oi=scholarr",
            "Abstract": "The explosive growth of the world-wide-web and the emergence of e-commerce has led to the development of recommender systems\u2014a personalized information \ufb01ltering technology used to identify a set of N items that will be of interest to a certain user. User-based Collaborative \ufb01ltering is the most successful technology for building recommender systems to date, and is extensively used in many commercial recommender systems. Unfortunately, the computational complexity of these methods grows linearly with the number of customers that in typical commercial applications can grow to be several millions. To address these scalability concerns item-based recommendation techniques have been developed that analyze the user-item matrix to identify relations between the different items, and use these relations to compute the list of recommendations. In this paper we present one such class of item-based \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:5icHVeHT4IsC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Conserved GU-rich elements mediate mRNA decay by binding to CUG-binding protein 1",
            "Publication year": 2008,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S1097276507008192",
            "Abstract": "We used computational algorithms to find conserved sequences in the 3\u2032 untranslated region (UTR) of transcripts that exhibited rapid decay in primary human T cells and found that the consensus sequence UGUUUGUUUGU, which we have termed a GU-rich element (GRE), was enriched in short-lived transcripts. Using a tet-off reporter system, we showed that insertion of GRE-containing sequences from c-jun, jun B, or TNF receptor 1B, but not mutated GRE sequences, into the 3\u2032UTR of a \u03b2-globin transcript conferred instability on the otherwise stable \u03b2-globin transcript. CUG-binding protein 1 (CUGBP1) was identified as the major GRE-binding activity in cytoplasmic extracts from primary human T cells based on supershift and immunoprecipitation assays. siRNA-mediated knockdown of CUGBP1 in HeLa cells caused stabilization of GRE-containing transcripts, suggesting that CUGBP1 is a mediator of GRE \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:j3f4tGmQtD8C",
            "Publisher": "Cell Press"
        },
        {
            "Title": "Introduction to parallel computing",
            "Publication year": 2003,
            "Publication url": "https://scholar.google.com/scholar?cluster=6234486233257882624&hl=en&oi=scholarr",
            "Abstract": "Introducation to Parallel Computing is a complete end-to-end source of information on almost all aspects of parallel computing from introduction to architectures to programming paradigms to algorithms to programming standards. It is the only book to have complete coverage of traditional Computer Science algorithms (sorting, graph and matrix algorithms), scientific computing algorithms (FFT, sparse matrix computations, N-body methods), and data intensive algorithms (search, dynamic programming, data-mining).",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:3x-KLxxGyuUC",
            "Publisher": "Pearson Education"
        },
        {
            "Title": "Mpi for big data: New tricks for an old dog",
            "Publication year": 2014,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S0167819114000830",
            "Abstract": "The processing of massive amounts of data on clusters with finite amount of memory has become an important problem facing the parallel/distributed computing community. While MapReduce-style technologies provide an effective means for addressing various problems that fit within the MapReduce paradigm, there are many classes of problems for which this paradigm is ill-suited. In this paper we present a runtime system for traditional MPI programs that enables the efficient and transparent out-of-core execution of distributed-memory parallel programs. This system, called BDMPI,1 leverages the semantics of MPI\u2019s API to orchestrate the execution of a large number of MPI processes on much fewer compute nodes, so that the running processes maximize the amount of computation that they perform with the data fetched from the disk. BDMPI enables the development of efficient out-of-core parallel distributed \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:A8cqit5AE6sC",
            "Publisher": "North-Holland"
        },
        {
            "Title": "Causal inference in higher education: Building better curriculums",
            "Publication year": 2019,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/3330430.3333663",
            "Abstract": "Higher educational institutions constantly look for ways to meet students' needs and support them through graduation. However, even though institutions provide degree program curriculums and prerequisite courses to guide students, these often fail to capture some of the underlying skills and knowledge imparted by courses that may be necessary for a student.",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:vxA22ZmNLkoC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Domain-aware grade prediction and top-n course recommendation",
            "Publication year": 2016,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/2959100.2959133",
            "Abstract": "Automated course recommendation can help deliver personalized and effective college advising and degree planning. Nearest neighbor and matrix factorization based collaborative filtering approaches have been applied to student-course grade data to help students select suitable courses. However, the student-course enrollment patterns exhibit grouping structures that are tied to the student and course academic features, which lead to grade data that are not missing at random (NMAR). Existing approaches for dealing with NMAR data, such as Response-aware and context-aware matrix factorization, do not model NMAR data in terms of the user and item features and are not designed with the characteristics of grade data in mind. In this work we investigate how the student and course academic features influence the enrollment patterns and we use these features to define student and course groups at various \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:6ZzL7HXColQC",
            "Publisher": "Unknown"
        },
        {
            "Title": "L2knng: Fast exact k-nearest neighbor graph construction with l2-norm pruning",
            "Publication year": 2015,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/2806416.2806534",
            "Abstract": "The k-nearest neighbor graph is often used as a building block in information retrieval, clustering, online advertising, and recommender systems algorithms. The complexity of constructing the exact k-nearest neighbor graph is quadratic on the number of objects that are compared, and most existing methods solve the problem approximately. We present L2Knng, an efficient algorithm that finds the exact cosine similarity k-nearest neighbor graph for a set of sparse high-dimensional objects. Our algorithm quickly builds an approximate solution to the problem, identifying many of the most similar neighbors, and then uses theoretic bounds on the similarity of two vectors, based on the L 2-norm of part of the vectors, to find each object's exact k-neighborhood. We perform an extensive evaluation of our algorithm, comparing against both exact and approximate baselines, and demonstrate the efficiency of our method across \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:6VlyvFCUEfcC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Local Latent Space Models for Top-N Recommendation Appendix",
            "Publication year": 2018,
            "Publication url": "https://conservancy.umn.edu/handle/11299/216026",
            "Abstract": "This report shows the local ranks  for which rLSVD and rGLSVD achieve their best performance, in terms of HR and ARHR. It is the appendix of the paper \"Local Latent Space Models for Top-N Recommendation\".",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:rzmi0EmCOGEC",
            "Publisher": "Unknown"
        },
        {
            "Title": "A comprehensive survey of neighborhood-based recommendation methods",
            "Publication year": 2011,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-0-387-85820-3_4",
            "Abstract": "Among collaborative recommendation approaches, methods based on nearest-neighbors still enjoy a huge amount of popularity, due to their simplicity, their efficiency, and their ability to produce accurate and personalized recommendations. This chapter presents a comprehensive survey of neighborhood-based methods for the item recommendation problem. In particular, the main benefits of such methods, as well as their principal characteristics, are described. Furthermore, this document addresses the essential decisions that are required while implementing a neighborhood-based recommender system, and gives practical information on how to make such decisions. Finally, the problems of sparsity and limited coverage, often observed in large commercial recommender systems, are discussed, and a few solutions to overcome these problems are presented.",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:EUQCXRtRnyEC",
            "Publisher": "Springer, Boston, MA"
        },
        {
            "Title": "Criterion functions for document clustering: Experiments and analysis",
            "Publication year": 2001,
            "Publication url": "https://conservancy.umn.edu/handle/11299/215490",
            "Abstract": "In recent years, we have witnessed a tremendous growth in the volume of text documents available on the Internet, digital libraries, news sources, and company-wide intranets. This has led to an increased interest in developing methods that can help users to effectively navigate, summarize, and organize this information with the ultimate goal of helping them to find what they are looking for. Fast and high-quality document clustering algorithms play an important role towards this goal as they have been shown to provide both an intuitive navigation/browsing mechanism by organizing large amounts of information into a small number of meaningful clusters as well as to greatlyimprove the retrieval performance either via cluster-driven dimensionality reduction, term-weighting, or query expansion. This ever-increasing importance of document clustering and the expanded range of its applications led to the development of a number of new and novel algorithms with different complexity-quality trade-offs. Among them, a class of clustering algorithms that have relatively low computational requirements are those that treat the clustering problem as an optimization process which seeks to maximize or minimize a particular {em clustering criterion function} defined over the entire clustering solution.  The focus of this paper is to evaluate the performance of different criterion functions for the problem of clustering documents. Our study involves a total of eight different criterion functions, three of which are introduced inthis paper and five that have been proposed in the past. Our evaluation consists ofboth a comprehensive experimental evaluation involving fifteen \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:_FxGoFyzp5QC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Profile-based direct kernels for remote homology detection and fold recognition",
            "Publication year": 2005,
            "Publication url": "https://academic.oup.com/bioinformatics/article-abstract/21/23/4239/194750",
            "Abstract": "Motivation: Protein remote homology detection is a central problem in computational biology. Supervised learning algorithms based on support vector machines are currently one of the most effective methods for remote homology detection. The performance of these methods depends on how the protein sequences are modeled and on the method used to compute the kernel function between them.Results: We introduce two classes of kernel functions that are constructed by combining sequence profiles with new and existing approaches for determining the similarity between pairs of protein sequences. These kernels are constructed directly from these explicit protein similarity measures and employ effective profile-to-profile scoring schemes for measuring the similarity between pairs of proteins. Experiments with remote homology detection and fold recognition problems show that these kernels are capable of \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:L8Ckcad2t8MC",
            "Publisher": "Oxford University Press"
        },
        {
            "Title": "BAMBOO: Accelerating closed itemset mining by deeply pushing the length-decreasing support constraint",
            "Publication year": 2004,
            "Publication url": "https://epubs.siam.org/doi/abs/10.1137/1.9781611972740.41",
            "Abstract": "Mining valid closed itemsets with the length-decreasing support constraint is a particularly challenging problem due to the fact that the downward-closure property cannot be used to prune the search space. In this paper, we have newly proposed several pruning methods and optimization techniques which can push deeply the length-decreasing support constraint into the closed itemset mining, and developed an efficient algorithm, BAMBOO. Our performance study based on various length-decreasing support constraints and datasets with different characteristics has shown that BAMBOO not only generates more concise result set, but also runs orders of magnitude faster than several efficient pattern discovery algorithms. In addition, BAMBOO also shows very good scalability in terms of the database size.",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:1sJd4Hv_s6UC",
            "Publisher": "Society for Industrial and Applied Mathematics"
        },
        {
            "Title": "Dgl-ke: Training knowledge graph embeddings at scale",
            "Publication year": 2020,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/3397271.3401172",
            "Abstract": "Knowledge graphs have emerged as a key abstraction for organizing information in diverse domains and their embeddings are increasingly used to harness their information in various information retrieval and machine learning tasks. However, the ever growing size of knowledge graphs requires computationally efficient algorithms capable of scaling to graphs with millions of nodes and billions of edges. This paper presents DGL-KE, an open-source package to efficiently compute knowledge graph embeddings. DGL-KE introduces various novel optimizations that accelerate training on knowledge graphs with millions of nodes and billions of edges using multi-processing, multi-GPU, and distributed parallelism. These optimizations are designed to increase data locality, reduce communication overhead, overlap computations with memory accesses, and achieve high operation efficiency. Experiments on knowledge \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:vjZqxyZ7hS4C",
            "Publisher": "Unknown"
        },
        {
            "Title": "TR O8-O11",
            "Publication year": 2008,
            "Publication url": "https://scholar.google.com/scholar?cluster=11699816434211589111&hl=en&oi=scholarr",
            "Abstract": "Small organic molecules, by binding to different proteins, can be used to modulate (inhibit/activate) their functions for therapeutic purposes and to elucidate the molecular mechanisms underlying biological processes. Over the decades structure-activity-relationship (SAR) models have been developed to quantify the bioactivity relationship of a chemical compound interacting with a target protein, with advances focussing on the chemical compound representation and the statistical learning methods. We have developed approaches to improve the performance of SAR models using compound activity information from different targets. The methods developed in the study aim to determine the candidacy of a target to help another target in improving the performance of its SAR model by providing supplemental activity information. Having identi\ufb01ed a helping target we also develop methods to identify a subset of \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:yFnVuubrUp4C",
            "Publisher": "Unknown"
        },
        {
            "Title": "TR O5-O07",
            "Publication year": 2005,
            "Publication url": "https://scholar.google.com/scholar?cluster=4586523060195753959&hl=en&oi=scholarr",
            "Abstract": "MOtlV3llOl \u2018lI Remote homology detection between protein sequences is a central problem in computational biology. Supervised learning algorithms based on support vector machines are currently the most e\ufb02ective method for remote homology detection. The performance of these methods depends on how the protein sequences are modeled and on the method used to compute the kernel function between them.Results: are constructed by directly combining automatically generated se-",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:DUooU5lO8OsC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Program chairs' welcome",
            "Publication year": 2013,
            "Publication url": "https://experts.umn.edu/en/publications/program-chairs-welcome-2",
            "Abstract": "Program chairs' welcome \u2014 Experts@Minnesota Skip to main navigation Skip to search Skip to \nmain content Experts@Minnesota Logo Home Profiles Research Units University Assets \nProjects and Grants Research output Press / Media Datasets Activities Fellowships, Honors, \nand Prizes Search by expertise, name or affiliation Program chairs' welcome Pearl Pu, George \nKarypis Computer Science and Engineering Research output: Contribution to journal \u203a Editorial \n\u203a peer-review Overview Fingerprint Original language English (US) Pages (from-to) iii Journal \nRecSys 2013 - Proceedings of the 7th ACM Conference on Recommender Systems State \nPublished - Nov 20 2013 Event 7th ACM Conference on Recommender Systems, RecSys 2013 \n- Hong Kong, China Duration: Oct 12 2013 \u2192 Oct 16 2013 Cite this APA Standard Harvard \nVancouver Author BIBTEX RIS Pu, P., & Karypis, G. (2013). Program chairs' welcome. , \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:EBV337fEn3EC",
            "Publisher": "Unknown"
        },
        {
            "Title": "IACN: Influence-Aware and Attention-Based Co-evolutionary Network for Recommendation",
            "Publication year": 2021,
            "Publication url": "https://arxiv.org/abs/2103.02866",
            "Abstract": "Recommending relevant items to users is a crucial task on online communities such as Reddit and Twitter. For recommendation system, representation learning presents a powerful technique that learns embeddings to represent user behaviors and capture item properties. However, learning embeddings on online communities is a challenging task because the user interest keep evolving. This evolution can be captured from 1) interaction between user and item, 2) influence from other users in the community. The existing dynamic embedding models only consider either of the factors to update user embeddings. However, at a given time, user interest evolves due to a combination of the two factors. To this end, we propose Influence-aware and Attention-based Co-evolutionary Network (IACN). Essentially, IACN consists of two key components: interaction modeling and influence modeling layer. The interaction modeling layer is responsible for updating the embedding of a user and an item when the user interacts with the item. The influence modeling layer captures the temporal excitation caused by interactions of other users. To integrate the signals obtained from the two layers, we design a novel fusion layer that effectively combines interaction-based and influence-based embeddings to predict final user embedding. Our model outperforms the existing state-of-the-art models from various domains.",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:kvJssbFybhEC",
            "Publisher": "Springer, Cham"
        },
        {
            "Title": "TR O1-O20",
            "Publication year": 2001,
            "Publication url": "https://scholar.google.com/scholar?cluster=4336206079552799569&hl=en&oi=scholarr",
            "Abstract": "Discovery of sequential patterns is becoming increasingly useful and essential in many scienti\ufb01c and commercial domains. Enormous sizes of available datasets and possibly large number of mined patterns demand ef\ufb01cient, scalable, and parallel algorithms. Even though a number of algorithms have been developed to ef\ufb01ciently parallelize frequent pattern discovery algorithms that are based on the candidate-generation-and-counting framework, the problem of parallelizing the more ef\ufb01cient projection-based algorithms has received relatively little attention and existing parallel formulations have been targeted only toward shared-memory architectures. The irregular and unstructured nature of the task-graph generated by these algorithms and the fact that these tasks operate on overlapping sub-databases makes it challenging to ef\ufb01ciently parallelize these algorithms on scalable distributed-memory parallel \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:kF1pexMAQbMC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Mining transcriptome data for function\u2013trait relationship of hyper productivity of recombinant antibody",
            "Publication year": 2009,
            "Publication url": "https://onlinelibrary.wiley.com/doi/abs/10.1002/bit.22210",
            "Abstract": "In the past decade we have witnessed a drastic increase in the productivity of mammalian cell culture\u2010based processes. High\u2010producing cell lines that synthesize and secrete these therapeutics have contributed largely to the advances in process development. To elucidate the productivity trait in the context of physiological functions, the transcriptomes of several NS0 cell lines with a wide range of antibody productivity were compared. Gene set testing (GST) analysis was used to identify pathways and biological functions that are altered in high producers. Three complementary tools for GST\u2014gene set enrichment analysis (GSEA), gene set analysis (GSA), and MAPPFinder, were used to identify groups of functionally coherent genes that are up\u2010 or downregulated in high producers. Major functional classes identified include those involved in protein processing and transport, such as protein modification, vesicle \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:B3FOqHPlNUQC",
            "Publisher": "Wiley Subscription Services, Inc., A Wiley Company"
        },
        {
            "Title": "Method and system for real-time location and inquiry based information delivery",
            "Publication year": 2010,
            "Publication url": "https://patents.google.com/patent/US20100318412A1/en",
            "Abstract": "Systems and methods for real-time location and inquiry based information delivery are described. Embodiments of a method for real-time location and inquiry based information delivery include receiving, using a processor and memory, a customer inquiry. The customer inquiry includes product information indicative of a customer's interest in a particular product. The method further receives location information indicative of the customer's current geographical location, determines additional product information based on the customer inquiry, identifies one or more incentives for presentation to the customer based on at least a portion of the product information and the location information. The customer inquiry is received prior to any solicitation of the customer's interest in the particular product.",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:OTTXONDVkokC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Advanced data mining and applications",
            "Publication year": 2006,
            "Publication url": "https://link.springer.com/content/pdf/10.1007/11811305.pdf",
            "Abstract": "The Second International Conference on Advanced Data Mining and Applications (ADMA) aimed at establishing its identity in the research community. The theme of ADMA is to focus on the innovative applications of data mining approaches to real-world problems that involve large data sets, incomplete and noisy data, or demand optimal solutions. Data mining is essentially a problem involving different knowledge of data, algorithms, and application domains. The first is about data that are regarded as the \u201cfirst-class citizens\u201d in application system development. Understanding data is always critical: their structures, high dimensionality, and their qualification and quantification issues. The second is about algorithms: their effectiveness, efficiency, scalability, and their applicability. Amongst a variety of applicable algorithms, selecting a right one to deal with a specific problem is always a challenge that demands \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:rOcdG6UcVlcC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Efficient parallel algorithms for mining associations",
            "Publication year": 2002,
            "Publication url": "https://link.springer.com/chapter/10.1007/3-540-46502-2_5",
            "Abstract": "The problem of mining hidden associations present in the large amounts of data has seen widespread applications in many practical domains such as customer-oriented planning and marketing, telecommunication network monitoring, and analyzing data from scientific experiments. The combinatorial complexity of the problem and phenomenal growth in the sizes of available datasets motivate the need for efficient and scalable parallel algorithms. The design of such algorithms is challenging. This chapter presents an evolutionary and comparative review of many existing representative serial and parallel algorithms for discovering two kinds of associations. The first part of the chapter is devoted to the non-sequential associations, which utilize the relationships between events that happen together. The second part is devoted to the more general and potentially more useful sequential associations, which \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:u9iWguZQMMsC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "Feature extraction for next-term prediction of poor student performance",
            "Publication year": 2019,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/8700250/",
            "Abstract": "Developing tools to support students and learning in a traditional or online setting is a significant task in today's educational environment. The initial steps toward enabling such technologies using machine learning techniques focused on predicting the student's performance in terms of the achieved grades. However, these approaches do not perform as well in predicting poor-performing students. The objective of our work is twofold. First, in order to overcome this limitation, we explore if poorly performing students can be more accurately predicted by formulating the problem as binary classification, based on data provided before the start of the semester. Second, in order to gain insights as to which are the factors that can lead to poor performance, we engineered a number of human-interpretable features that quantify these factors. These features were derived from the students' grades from the University of \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:Gb6Hms-Uo9kC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Effective optimization algorithms for fragment-assembly based protein structure prediction",
            "Publication year": 2007,
            "Publication url": "https://www.worldscientific.com/doi/abs/10.1142/s0219720007002618",
            "Abstract": "Despite recent developments in protein structure prediction, an accurate new fold prediction algorithm remains elusive. One of the challenges facing current techniques is the size and complexity of the space containing possible structures for a query sequence. Traditionally, to explore this space fragment assembly approaches to new fold prediction have used stochastic optimization techniques. Here, we examine deterministic algorithms for optimizing scoring functions in protein structure prediction. Two previously unused techniques are applied to the problem, called the Greedy algorithm and the Hill-climbing (HC) algorithm. The main difference between the two is that the latter implements a technique to overcome local minima. Experiments on a diverse set of 276 proteins show that the HC algorithms consistently outperform existing approaches based on Simulated Annealing optimization (a traditional stochastic \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:nrtMV_XWKgEC",
            "Publisher": "Imperial College Press"
        },
        {
            "Title": "Exploring the transcriptome space of a recombinant BHK cell line through next generation sequencing",
            "Publication year": 2014,
            "Publication url": "https://onlinelibrary.wiley.com/doi/abs/10.1002/bit.25135",
            "Abstract": "Baby Hamster Kidney (BHK) cell lines are used in the production of veterinary vaccines and recombinant proteins. To facilitate transcriptome analysis of BHK cell lines, we embarked on an effort to sequence, assemble, and annotate transcript sequences from a recombinant BHK cell line and Syrian hamster liver and brain. RNA\u2010seq data were supplemented with 6,170 Sanger ESTs from parental and recombinant BHK lines to generate 221,583 contigs. Annotation by homology to other species, primarily mouse, yielded more than 15,000 unique Ensembl mouse gene IDs with high coverage of KEGG canonical pathways. High coverage of enzymes and isoforms was seen for cell metabolism and N\u2010glycosylation pathways, areas of highest interest for biopharmaceutical production. With the high sequencing depth in RNA\u2010seq data, we set out to identify single\u2010nucleotide variants in the transcripts. A majority of the \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:-6RzNnnwWf8C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Mining bioprocess data: opportunities and challenges",
            "Publication year": 2008,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S016777990800245X",
            "Abstract": "Modern biotechnology production plants are equipped with sophisticated control, data logging and archiving systems. These data hold a wealth of information that might shed light on the cause of process outcome fluctuations, whether the outcome of concern is productivity or product quality. These data might also provide clues on means to further improve process outcome. Data-driven knowledge discovery approaches can potentially unveil hidden information, predict process outcome, and provide insights on implementing robust processes. Here we describe the steps involved in process data mining with an emphasis on recent advances in data mining methods pertinent to the unique characteristics of biological process data.",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:VOx2b1Wkg3QC",
            "Publisher": "Elsevier Current Trends"
        },
        {
            "Title": "Interferon-inducible gene expression signature in peripheral blood cells of patients with severe lupus",
            "Publication year": 2003,
            "Publication url": "https://www.pnas.org/content/100/5/2610.short",
            "Abstract": "Systemic lupus erythematosus (SLE) is a complex, inflammatory autoimmune disease that affects multiple organ systems. We used global gene expression profiling of peripheral blood mononuclear cells to identify distinct patterns of gene expression that distinguish most SLE patients from healthy controls. Strikingly, about half of the patients studied showed dysregulated expression of genes in the IFN pathway. Furthermore, this IFN gene expression \u201csignature\u201d served as a marker for more severe disease involving the kidneys, hematopoetic cells, and/or the central nervous system. These results provide insights into the genetic pathways underlying SLE, and identify a subgroup of patients who may benefit from therapies targeting the IFN pathway.",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:IjCSPb-OGe4C",
            "Publisher": "National Academy of Sciences"
        },
        {
            "Title": "2019 IEEE International Conference on Data Science and Advanced Analytics",
            "Publication year": 2019,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/8964191/",
            "Abstract": "[Title page iii] - IEEE Conference Publication [Title page iii] Abstract: Presents the title page of \nthe proceedings record. Published in: 2019 IEEE International Conference on Data Science and \nAdvanced Analytics (DSAA) Article #: Date of Conference: 5-8 Oct. 2019 Date Added to IEEE \nXplore: 23 January 2020 ISBN Information: Electronic ISBN: 978-1-7281-4493-1 Print on \nDemand(PoD) ISBN: 978-1-7281-4494-8 INSPEC Accession Number: Persistent Link: \nhttps://xplorestaging.ieee.org/servlet/opac?punumber=8961324 More \u00bb Publisher: IEEE IEEE \nAccount Change Username/Password Update Address Purchase Details Payment Options \nOrder History View Purchased Documents Profile Information Communications Preferences \nProfession and Education Technical Interests Need Help? US & Canada: +1 800 678 4333 \nWorldwide: +1 732 981 0060 Contact & Support About IEEE Xplore Contact Us Help Terms of & -\u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:VjBpw8Hezy4C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Grade prediction with models specific to students and courses",
            "Publication year": 2016,
            "Publication url": "https://link.springer.com/article/10.1007/s41060-016-0024-z",
            "Abstract": "The accurate estimation of students\u2019 grades in future courses is important as it can inform the selection of next term\u2019s courses and create personalized degree pathways to facilitate successful and timely graduation. This paper presents future course grade predictions methods based on sparse linear and low-rank matrix factorization models that are specific to each course or student\u2013course tuple. These methods identify the predictive subsets of prior courses on a course-by-course basis and better address problems associated with the not-missing-at-random nature of the student\u2013course historical grade data. The methods were evaluated on a dataset obtained from the University of Minnesota, for two different departments with different characteristics. This evaluation showed that focusing on course-specific data improves the accuracy of grade prediction.",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:PuOEWVtPfzwC",
            "Publisher": "Springer International Publishing"
        },
        {
            "Title": "Feature-based factorized Bilinear Similarity Model for Cold-Start Top-n Item Recommendation",
            "Publication year": 2015,
            "Publication url": "https://epubs.siam.org/doi/abs/10.1137/1.9781611974010.22",
            "Abstract": "Recommending new items to existing users has remained a challenging problem due to absence of user's past preferences for these items. The user personalized non-collaborative methods based on item features can be used to address this item cold-start problem. These methods rely on similarities between the target item and user's previous preferred items. While computing similarities based on item features, these methods overlook the interactions among the features of the items and consider them independently. Modeling interactions among features can be helpful as some features, when considered together, provide a stronger signal on the relevance of an item when compared to case where features are considered independently. To address this important issue, in this work we introduce the Feature-based factorized Bilinear Similarity Model (FBSM), which learns factorized bilinear similarity model for Top \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:1r-w4gtu6w8C",
            "Publisher": "Unknown"
        },
        {
            "Title": "A comparison of document clustering techniques Proceeding of the 6th ACM-SIGKDD International Conference on Text Mining",
            "Publication year": 2000,
            "Publication url": "https://scholar.google.com/scholar?cluster=12964472135345737632&hl=en&oi=scholarr",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:zzCxg_vo7cAC",
            "Publisher": "USA: ACM Press"
        },
        {
            "Title": "Slim: Sparse linear methods for top-n recommender systems",
            "Publication year": 2011,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/6137254/",
            "Abstract": "This paper focuses on developing effective and efficient algorithms for top-N recommender systems. A novel Sparse Linear Method (SLIM) is proposed, which generates top-N recommendations by aggregating from user purchase/rating profiles. A sparse aggregation coefficient matrix W is learned from SLIM by solving an \u2113 1 -norm and \u2113 2 -norm regularized optimization problem. W is demonstrated to produce high quality recommendations and its sparsity allows SLIM to generate recommendations very fast. A comprehensive set of experiments is conducted by comparing the SLIM method and other state-of-the-art top-N recommendation methods. The experiments show that SLIM achieves significant improvements both in run time performance and recommendation quality over the best existing methods.",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:sJK75vZXtG0C",
            "Publisher": "IEEE"
        },
        {
            "Title": "A software package for partitioning unstructured graphs and computing fill-reducing orderings of sparse matrices",
            "Publication year": 2005,
            "Publication url": "https://scholar.google.com/scholar?cluster=7848775029338191850&hl=en&oi=scholarr",
            "Abstract": "The first argument,\u00a4\u00a6\u00a5 \u00a7 )\u00a9 0 1\u00a6 2 3, is the name of the file that stores the graph (whose format is described in detail in Section 1.1). The second argument\"\u00a9# \u00a7 $\u00a5 &%('is the number of partitions that is desired. Upon successful execution, the program displays statistics regarding the quality of the computed partitioning, fill reducing ordering, and the amount of time taken to find them. The actual partitioning is stored in a file named\u00a4\u00a6\u00a5 \u00a7 )\u00a9 0 1\u00a6 2 3. part. 45\u00a9 6 \u00a7 $\u00a5 &%('. The ordering of the nodes is stored in a file named\u00a4\u00a6\u00a5 \u00a7 \u00a9\u00a6. iperm. The format of both files is described in Section 1.2. You may also invoke kfmetis and specify what type of refinement method to be used, by providing it as a command line option-rseptype= ar| rr| mrr| rref| rrss. More informartion about the resulting partitioning/ordering can be seen by providing the command line argument-dbglvl= 256. Therefore kfmetis can also be invoked in a more \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:M_lZXyI38BkC",
            "Publisher": "Unknown"
        },
        {
            "Title": "FROSTT: The formidable repository of open sparse tensors and tools",
            "Publication year": 2017,
            "Publication url": "https://scholar.google.com/scholar?cluster=5258257979114600091&hl=en&oi=scholarr",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:BCdnXsLIVDwC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Gene classification using expression profiles: A feasibility study",
            "Publication year": 2005,
            "Publication url": "https://www.worldscientific.com/doi/abs/10.1142/S0218213005002302",
            "Abstract": "As various genome sequencing projects have already been completed or are near completion, genome researchers are shifting their focus to functional genomics. Functional genomics represents the next phase, that expands the biological investigation to studying the functionality of genes of a single organism as well as studying and correlating the functionality of genes across many different organisms. Recently developed methods for monitoring genome-wide mRNA expression changes hold the promise of allowing us to inexpensively gain insights into the function of unknown genes. In this paper we focus on evaluating the feasibility of using supervised machine learning methods for determining the function of genes based solely on their expression profiles. We experimentally evaluate the performance of traditional classification algorithms such as support vector machines and k-nearest neighbors on the yeast \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:fPk4N6BV_jEC",
            "Publisher": "World Scientific Publishing Company"
        },
        {
            "Title": "COVID-19 knowledge graph: accelerating information retrieval and discovery for scientific literature",
            "Publication year": 2020,
            "Publication url": "https://arxiv.org/abs/2007.12731",
            "Abstract": "The coronavirus disease (COVID-19) has claimed the lives of over 350,000 people and infected more than 6 million people worldwide. Several search engines have surfaced to provide researchers with additional tools to find and retrieve information from the rapidly growing corpora on COVID-19. These engines lack extraction and visualization tools necessary to retrieve and interpret complex relations inherent to scientific literature. Moreover, because these engines mainly rely upon semantic information, their ability to capture complex global relationships across documents is limited, which reduces the quality of similarity-based article recommendations for users. In this work, we present the COVID-19 Knowledge Graph (CKG), a heterogeneous graph for extracting and visualizing complex relationships between COVID-19 scientific articles. The CKG combines semantic information with document topological information for the application of similar document retrieval. The CKG is constructed using the latent schema of the data, and then enriched with biomedical entity information extracted from the unstructured text of articles using scalable AWS technologies to form relations in the graph. Finally, we propose a document similarity engine that leverages low-dimensional graph embeddings from the CKG with semantic embeddings for similar article retrieval. Analysis demonstrates the quality of relationships in the CKG and shows that it can be used to uncover meaningful information in COVID-19 scientific articles. The CKG helps power www.cord19.aws and is publicly available.",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:Ul_CLA4dPeMC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Improved SAR Models-Exploiting the Target-Ligand Relationships",
            "Publication year": 2008,
            "Publication url": "https://conservancy.umn.edu/handle/11299/215754",
            "Abstract": "Small organic molecules, by binding to different proteins, can be used to modulate (inhibit/activate) their functions for therapeutic purposes and to elucidate the molecular mechanisms underlying biological processes. Over the decades structure-activity-relationship (SAR) models have been developed to quantify the bioactivity relationship of a chemical compound interacting with a target protein, with advances focussing on the chemical compound representation and the statistical learning methods.  We have developed approaches to improve the performance of SAR models using compound activity information from different targets. The methods developed in the study aim to determine the candidacy of a target to help another target in improving the performance of its SAR model by providing supplemental activity information. Having identified a helping target we also develop methods to identify a subset of compounds that would result in improving the sensitivity of the SAR model.  Identification of helping targets as well as helping compounds is performed using various nearest neighbor approaches using similarity measures derived from the targets as well as active compounds. We also developed methods that involve use of cross-training a series of SVM-based models for identifying the helping set of targets. Our experimental results show that our methods show statistically significant results and incorporate the target-ligand activity relationship well.",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:anf4URPfarAC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Multi-resource aware partitioning algorithms for FPGAs with heterogeneous resources",
            "Publication year": 2004,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/996566.996768",
            "Abstract": "As FPGA densities increase, partitioning-based FPGA placement approaches are becoming increasingly important as they can be used to provide high-quality and computationally scalable placement solutions. However, modern FPGA architectures incorporate heterogeneous resources, which place additional requirements on the partitioning algorithms because they now need to not only minimize the cut and balance the partitions, but also they must ensure that none of the resources in each partition is oversubscribed. In this paper, we present a number of multilevel multi-resource hypergraph partitioning algorithms that are guaranteed to produce solutions that balance the utilization of the different resources across the partitions. We evaluate our algorithms on twelve industrial benchmarks ranging in size from 5,236 to 140,118 vertices and show that they achieve minimal degradation in the min-cut while balancing \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:eJXPG6dFmWUC",
            "Publisher": "Unknown"
        },
        {
            "Title": "CANDIDATES ANNOUNCED FOR BOARD OF GOVERNORS ELECTION",
            "Publication year": 2013,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/6515042/",
            "Abstract": "Technical activities not only represent the lifeblood of IEEE; they also comprise its core values, and as such they are of paramount importance towards our members\u2019 well being. I have had the privilege to serve IEEE, and the IEEE Communications Society (ComSoc) in particular, as a longtime and tireless volunteer. If elected as Vice-President for Technical Activities, it will be my honor to continue serving IEEE ComSoc while sustaining its role as a major resource supporting members\u2019 needs throughout the world. I will rely on my diverse background and extensive leadership experience to:\u2022 Enhance our technical activities to better address the needs of current and prospective members while putting greater focus on transparency and openness.\u2022 Strengthen ComSoc globalization activities and further opening the door to recruiting young and talented volunteers.\u2022 Grow our value to academics while intensifying and \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:8VtEwCQfWZkC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Importance assessment in scholarly networks",
            "Publication year": 2021,
            "Publication url": "https://experts.umn.edu/en/publications/importance-assessment-in-scholarly-networks",
            "Abstract": "We present approaches to estimate content-aware bibliometrics to quantitatively measure the scholarly impact of a publication. Traditional measures to assess quality-related aspects such as citation counts and h-index, do not take into account the content of the publications, which limits their ability to provide rigorous quality-related metrics and can significantly skew the results. Our proposed metric, denoted by Content Informed Index (CII), uses the content of the paper as a source of distant-supervision, to weight the edges of a citation network. These content-aware weights quantify the information in the citation ie, these weights quantify the extent to which the cited-node informs the citing-node. The weights convert the original unweighted citation network to a weighted one. Consequently, this weighted network can be used to derive impact metrics for the various entities involved, like the publications, authors etc. We evaluate the weights estimated by our approach on three manually annotated datasets, where the annotations quantify the extent of information in the citation. Particularly, we evaluate how well the ranking imposed by our approach associates with the ranking imposed by the manual annotations. The proposed approach achieves up to 103% improvement in performance as compared to second best performing approach.",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:uPCvBZYD9qUC",
            "Publisher": "CEUR-WS"
        },
        {
            "Title": "Text categorization using weight adjusted k-nearest neighbor classification",
            "Publication year": 2001,
            "Publication url": "https://link.springer.com/chapter/10.1007/3-540-45357-1_9",
            "Abstract": "Text categorization presents unique challenges due to the large number of attributes present in the data set, large number of training samples, attribute dependency, and multi-modality of categories. Existing classification techniques have limited applicability in the data sets of these natures. In this paper, we present a Weight Adjusted k-Nearest Neighbor (WAKNN) classification that learns feature weights based on a greedy hill climbing technique. We also present two performance optimizations of WAKNN that improve the computational performance by a few orders of magnitude, but do not compromise on the classification quality. We experimentally evaluated WAKNN on 52 document data sets from a variety of domains and compared its performance against several classification algorithms, such as C4.5, RIPPER, Naive-Bayesian, PEBLS and VSM. Experimental results on these data sets confirm that \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:_kc_bZDykSQC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "Common pharmacophore identification using frequent clique detection algorithm",
            "Publication year": 2009,
            "Publication url": "https://pubs.acs.org/doi/abs/10.1021/ci8002478",
            "Abstract": "The knowledge of a pharmacophore, or the 3D arrangement of features in the biologically active molecule that is responsible for its pharmacological activity, can help in the search and design of a new or better drug acting upon the same or related target. In this paper, we describe two new algorithms based on the frequent clique detection in the molecular graphs. The first algorithm mines all frequent cliques that are present in at least one of the conformers of each (or a portion of all) molecules. The second algorithm exploits the similarities among the different conformers of the same molecule and achieves an order of magnitude performance speedup compared to the first algorithm. Both algorithms are guaranteed to find all common pharmacophores in the data set, which is confirmed by the validation on the set of molecules for which pharmacophores have been determined experimentally. In addition, these \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:WbkHhVStYXYC",
            "Publisher": "American Chemical Society"
        },
        {
            "Title": "TR O3-O40",
            "Publication year": 2003,
            "Publication url": "https://scholar.google.com/scholar?cluster=14716479428922637657&hl=en&oi=scholarr",
            "Abstract": "Previous study has shown that mining frequent patterns with length-decreasing support constraint is very helpful in removing some uninteresting patterns based on the observation that short patterns Will tend to be interesting if they have a high support, whereas long patterns can still be very interesting even if their support is relatively low. However, a large number of non-closed (ie, redundant) patterns can still not be \ufb01ltered out by simply applying the lengtl1-decreasing support constraint. As a result, a more desirable pattern discovery task could be mining closed patterns under the length-decreasing support constraint. In this paper we study how to push deeply the lengthdecreasing support constraint into closed itemset mining, which is a particularly challenging problem due to the fact that the downward-closure property cannot be used to prune the search space. Therefore, we have proposed several pruning \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:An6A6Jpfc1oC",
            "Publisher": "Unknown"
        },
        {
            "Title": "A novel approach to compute similarities and its application to item recommendation",
            "Publication year": 2010,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-642-15246-7_7",
            "Abstract": "Several key applications like recommender systems deal with data in the form of ratings made by users on items. In such applications, one of the most crucial tasks is to find users that share common interests, or items with similar characteristics. Assessing the similarity between users or items has several valuable uses, among which are the recommendation of new items, the discovery of groups of like-minded individuals, and the automated categorization of items. It has been recognized that popular methods to compute similarities, based on correlation, are not suitable for this task when the rating data is sparse. This paper presents a novel approach, based on the SimRank algorithm, to compute similarity values when ratings are limited. Unlike correlation-based methods, which only consider user ratings for common items, this approach uses all the available ratings, allowing it to compute meaningful \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:9Nmd_mFXekcC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "Building multiclass classifiers for remote homology detection and fold recognition",
            "Publication year": 2006,
            "Publication url": "https://bmcbioinformatics.biomedcentral.com/articles/10.1186/1471-2105-7-455",
            "Abstract": "Protein remote homology detection and fold recognition are central problems in computational biology. Supervised learning algorithms based on support vector machines are currently one of the most effective methods for solving these problems. These methods are primarily used to solve binary classification problems and they have not been extensively used to solve the more general multiclass remote homology prediction and fold recognition problems. We present a comprehensive evaluation of a number of methods for building SVM-based multiclass classification schemes in the context of the SCOP protein classification. These methods include schemes that directly build an SVM-based multiclass model, schemes that employ a second-level learning approach to combine the predictions generated by a set of binary SVM-based classifiers, and schemes that build and combine binary classifiers for various levels of the SCOP hierarchy beyond those defining the target classes. Analyzing the performance achieved by the different approaches on four different datasets we show that most of the proposed multiclass SVM-based classification approaches are quite effective in solving the remote homology prediction and fold recognition problems and that the schemes that use predictions from binary models constructed for ancestral categories within the SCOP hierarchy tend to not only lead to lower error rates but also reduce the number of errors in which a superfamily is assigned to an entirely different fold and a fold is predicted as being from a different SCOP class. Our results also show that the limited size of the training data makes it hard to learn \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:SP6oXDckpogC",
            "Publisher": "BioMed Central"
        },
        {
            "Title": "Graph Partitioning for Dynamic, Adaptive and Multi-phase Scientific",
            "Publication year": 2001,
            "Publication url": "https://scholar.google.com/scholar?cluster=13247609964285083836&hl=en&oi=scholarr",
            "Abstract": "The efficient execution of scientific simulations on HPC systems requires a partitioning of the underlying mesh among the processors such that the load is balanced and the inter-processor communication is minimized. Graph partitioning algorithms have been applied with much success for this purpose. However, the parallelization of multi-phase and multi-physics computations poses new challenges that require fundamental advances in graph partitioning technology. In addition, most existing graph partitioning al-gorithms are not suited for the newer heterogeneous highperformance computing platforms. This talk will describe research efforts in our group that are focused on develop-ing novel multi-constraint and multi-objective graph parti-tioning algorithms that can support the advancing state-ofthe-art in numerical simulation technologies. In addition, present our preliminary work on new partitioning algorithms that are well suited for heterogeneous architec-tures. such simulations on distributed-memory machines requires a mapping of the computational mesh onto the processors that equalizes the number of mesh elements assigned to each processor and minimizes the interprocessor communication required to perform the information exchange between adjacent elements (10). Such a mapping is commonly found by solving a graph partitioning problem (3, 4). Simulations performed on shared-memory multiprocessors also benefit from partitioning, as this increases data locality, and so, leads to better cache performance. Although the graph partitioning problem is NP-complete, good heuristic solutions for instances arising in scientific simulation \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:QtA78RmWg5MC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Improve precategorized collection retrieval by using supervised term weighting schemes",
            "Publication year": 2002,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/1000353/",
            "Abstract": "The emergence of the World Wide Web has led to an increased interest in methods for searching for information. A key characteristic of many online document collections is that the documents have pre-defined category information, such as the variety of scientific articles accessible via digital libraries (e.g. ACM, IEEE, etc.), medical articles, news-wires and various directories (e.g. Yahoo, OpenDirectory Project, etc.). However, most previous information retrieval systems have not taken the pre-existing category information into account. In this paper, we present weight adjustment schemes based upon the category information in the vector-space model, which are able to select the most content-specific and discriminating features. Our experimental results on TREC data sets show that the pre-existing category information does provide additional beneficial information to improve retrieval. The proposed weight \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:kRWSkSYxWN8C",
            "Publisher": "IEEE"
        },
        {
            "Title": "Recwalk: Nearly uncoupled random walks for top-n recommendation",
            "Publication year": 2019,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/3289600.3291016",
            "Abstract": "Random walks can provide a powerful tool for harvesting the rich network of interactions captured within item-based models for top-n recommendation. They can exploit indirect relations between the items, mitigate the effects of sparsity, ensure wider itemspace coverage, as well as increase the diversity of recommendation lists. Their potential however, is hindered by the tendency of the walks to rapidly concentrate towards the central nodes of the graph, thereby significantly restricting the range of K-step distributions that can be exploited for personalized recommendations. In this work we introduce RecWalk; a novel random walk-based method that leverages the spectral properties of nearly uncoupled Markov chains to provably lift this limitation and prolong the influence of users' past preferences on the successive steps of the walk--allowing the walker to explore the underlying network more fruitfully. A \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:DIubQTN3OvUC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Architecture aware partitioning algorithms",
            "Publication year": 2008,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-540-69501-1_6",
            "Abstract": "Existing partitioning algorithms provide limited support for load balancing simulations that are performed on heterogeneous parallel computing platforms. On such architectures, effective load balancing can only be achieved if the graph is distributed so that it properly takes into account the available resources (CPU speed, network bandwidth). With heterogeneous technologies becoming more popular, the need for suitable graph partitioning algorithms is critical. We developed such algorithms that can address the partitioning requirements of scientific computations, and can correctly model the architectural characteristics of emerging hardware platforms.",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:q3oQSFYPqjQC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "Proceedings of the 2007 SIAM International Conference on Data Mining",
            "Publication year": 2007,
            "Publication url": "https://epubs.siam.org/doi/pdf/10.1137/1.9781611972771.fm",
            "Abstract": "We are pleased to welcome you to the Seventh SIAM International Conference on Data Mining (SDM 2007) in Minneapolis, Minnesota. This year the conference received a record number of papers (302, as compared to 242 last year). Each submitted paper was reviewed initially by at least three members of the international program committee. Area chairs then initiated discussion on papers with discrepant scores and subsequently provided their recommendations to the program co-chairs, who then collated and refined these suggestions across all areas. In the end, 36 papers were selected to appear as full papers, and 39 papers were selected as short papers or posters. We believe that the hard work of all the authors, reviewers, and area chairs has resulted in an excellent set of papers that will be valuable both to researchers and practitioners in data mining for many years to come.",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:zwpXiJ37cpgC",
            "Publisher": "Society for Industrial and Applied Mathematics"
        },
        {
            "Title": "Signaling adverse drug reactions with novel feature-based similarity model",
            "Publication year": 2014,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/6999227/",
            "Abstract": "Adverse drug reactions (ADRs) are a main cause of hospitalization and deaths worldwide. These unanticipated episodes are generally infrequent, but almost all existing ADR signaling techniques are designed to use dataset extracted from spontaneous reporting systems or employed a predefined type of information (e.g., drugs), which suffer from failures to detect unexpected and latent ADRs. In this paper, we propose a novel Feature-based Similarity model (FS) to detect the potential ADRs for medical cases using the electronic patient dataset. FS is tested on the real patient data retrieved from the US Food Drug Administration that includes 54,070 patients detail information and 9,567 ADRs records. Our model ranked all ADRs for the given medical case that combined the information of drugs, medical conditions, and patient profiles and can be applied in therapy decision support systems and unexpected ADR \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:jmjb1lOE9QIC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Improving graph partitioning for modern graphs and architectures",
            "Publication year": 2015,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/2833179.2833188",
            "Abstract": "Graph partitioning is an important preprocessing step in applications dealing with sparse-irregular data. As such, the ability to efficiently partition a graph in parallel is crucial to the performance of these applications. The number of compute cores in a compute node continues to increase, demanding ever more scalability from shared-memory graph partitioners. In this paper we present algorithmic improvements to the multithreaded graph partitioner mt-Metis. We experimentally evaluate our methods on a 36 core machine, using 20 different graphs from a variety of domains. Our improvements decrease the runtime by 1.5-11.7 X and improve strong scaling by 82%.",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:EaFouW7jFu4C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Automatically separating claim into elements/limitations and automatically finding art for each element/limitation",
            "Publication year": 2019,
            "Publication url": "https://patents.google.com/patent/US20190258687A1/en",
            "Abstract": "The present invention is a patent search and analytics software tool (Zuse) that finds prior art for each claim limitation/element. The software automatically breaks up every claim into individual claim limitations. For example, our software can automatically break up a claim into about five (5) separate, different claim limitations/elements. Then, it can find the best prior art for each of the five (5) separate, different claim limitations/elements. This is very helpful when you cannot find a prior art reference for only part of a claim. Also, the software finds the best prior art for the entire claims. Our software also includes non-patent literature (NPL) searching. ZUSE identifies relevant prior art by taking into account the limitations of the claim under consideration (query claim of query patent), the text of the art, the link structure of the citation network, and the patent classification. The present invention constructs a network that consists \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:htyGaKyDgHMC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Grade prediction with course and student specific models",
            "Publication year": 2016,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-319-31753-3_8",
            "Abstract": "The accurate estimation of students\u2019 grades in future courses is important as it can inform the selection of next term\u2019s courses and create personalized degree pathways to facilitate successful and timely graduation. This paper presents future-course grade predictions methods based on sparse linear models and low-rank matrix factorizations that are specific to each course or student-course tuple. These methods identify the predictive subsets of prior courses on a course-by-course basis and better address problems associated with the not-missing-at-random nature of the student-course historical grade data. The methods were evaluated on a dataset obtained from the University of Minnesota. This evaluation showed that the course specific models outperformed various competing schemes with the best performing scheme achieving a RMSE across the different courses of 0.632 vs 0.661 for the best \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:yeL6HyUMUGUC",
            "Publisher": "Springer, Cham"
        },
        {
            "Title": "TR O0-O57",
            "Publication year": 2000,
            "Publication url": "https://scholar.google.com/scholar?cluster=10327256324674971474&hl=en&oi=scholarr",
            "Abstract": "For the purposes of this paper we de\ufb01ne a catalog to be a promotional catalog, ie, a collection of products (items) presented to a customer with the hope of encouraging a purchase. The single mailing problem addresses how to build a collection of catalogs and distribute them to customers (one per customer) so as to achieve an optimal outcome, eg, the most pro\ufb01t. Each catalog is a subset of a given set of items and different catalogs may contain some of the same items, ie, catalogs may overlap. A slightly more general, but important extension of the single mailing problem seeks the optimal set of catalogs when multiple mailings are allowed, ie, multiple catalogs can be sent to each customer. Catalog creation has important applications for e-commerce and traditional brick-and-mortar retailers, especially when used with personalized recommender systems.The catalog creation problem is NP complete and some \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:pS0ncopqnHgC",
            "Publisher": "Unknown"
        },
        {
            "Title": "METIS and ParMETIS.",
            "Publication year": 2011,
            "Publication url": "https://scholar.google.com/scholar?cluster=11968243356669955542&hl=en&oi=scholarr",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:AzKEL7Gb_04C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Accelerating the tucker decomposition with compressed sparse tensors",
            "Publication year": 2017,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-319-64203-1_47",
            "Abstract": "The Tucker decomposition is a higher-order analogue of the singular value decomposition and is a popular method of performing analysis on multi-way data (tensors). Computing the Tucker decomposition of a sparse tensor is demanding in terms of both memory and computational resources. The primary kernel of the factorization is a chain of tensor-matrix multiplications (TTMc). State-of-the-art algorithms accelerate the underlying computations by trading off memory to memoize the intermediate results of TTMc in order to reuse them across iterations. We present an algorithm based on a compressed data structure for sparse tensors and show that many computational redundancies during TTMc can be identified and pruned without the memory overheads of memoization. In addition, our algorithm can further reduce the number of operations by exploiting an additional amount of user-specified memory. We \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:V_vSwabWVtYC",
            "Publisher": "Springer, Cham"
        },
        {
            "Title": "Data clustering in life sciences",
            "Publication year": 2005,
            "Publication url": "https://link.springer.com/article/10.1385/MB:31:1:055",
            "Abstract": "Clustering has a wide range of applications in life sciences and over the years has been used in many areas ranging from the analysis of clinical information, phylogeny, genomics, and proteomics. The primary goal of this article is to provide an overview of the various issues involved in clustering large biological datasets, describe the merits and underlying assumptions of some of the commonly used clustering approaches, and provide insights on how to cluster datasets arising in various areas within life sciences. We also provide a brief introduction to Cluto, a general purpose toolkit for clustering various datasets, with an emphasis on its applications to problems and analysis requirements within life sciences.",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:70eg2SAEIzsC",
            "Publisher": "Humana Press"
        },
        {
            "Title": "Advances in knowledge discovery and data mining",
            "Publication year": 2003,
            "Publication url": "https://link.springer.com/content/pdf/10.1007/978-3-642-37453-1.pdf",
            "Abstract": "As the Program Committee Co-chairs, we welcome you to the proceedings of the 17th Pacific-Asia Conference on Knowledge Discovery and Data Mining (PAKDD 2013), held at Gold Coast, Australia, during April 14-17, 2013. The PAKDD conference series, since its inception in 1997, has been a leading international conference in the areas of data mining and knowledge discovery (KDD). It provides an inviting and inspiring forum for researchers and practitioners, from both academia and industry, to share new ideas, original research results, and practical experience. The 17th edition continued the great tradition, and had three world-class keynote speeches, a wonderful technical program, a handful of high-quality tutorials and workshops, as well as an interesting invited talk from industry.The PAKDD 2013 conference received 363 submissions to the technical program, involving more than 1,000 authors in total. In \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:YsrPvlHIBpEC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Mining transcriptome profile for unveiling genetic markers associated with high productivity.",
            "Publication year": 2005,
            "Publication url": "https://scholar.google.com/scholar?cluster=16976973572641001589&hl=en&oi=scholarr",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:qe6vwMD2xtsC",
            "Publisher": "AMER CHEMICAL SOC"
        },
        {
            "Title": "Macromolecule mass spectrometry: citation mining of user documents",
            "Publication year": 2004,
            "Publication url": "https://link.springer.com/article/10.1016/j.jasms.2003.11.010",
            "Abstract": "Identifying research users, applications, and impact is important for research performers, managers, evaluators, and sponsors. Identification of the user audience and the research impact is complex and time consuming due to the many indirect pathways through which fundamental research can impact applications. This paper identified the literature pathways through which two highly-cited papers of 2002 Chemistry Nobel Laureates Fenn and Tanaka impacted research, technology development, and applications. Citation Mining, an integration of citation bibliometrics and text mining, was applied to the >1600 first generation Science Citation Index (SCI) citing papers to Fenn\u2019s 1989 Science paper on Electrospray Ionization for Mass Spectrometry, and to the >400 first generation SCI citing papers to Tanakarss 1988 Rapid Communications in Mass Spectrometry paper on Laser Ionization Time-of-Flight Mass \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:4fKUyHm3Qg0C",
            "Publisher": "Springer-Verlag"
        },
        {
            "Title": "Introduction to special issue on bioinformatics",
            "Publication year": 2008,
            "Publication url": "https://dl.acm.org/doi/pdf/10.1145/1342320.1342321",
            "Abstract": "The first article, Compositional Mining of Multirelational Biological Datasets by Ying Jin, TM Murali, and Naren Ramakrishnan, presents a compositional framework over redescription mining and biclustering primitives to create a chain of inferences, moving from one \u201cvocabulary\u201d to the next. Applications in gene ontology matching and cell stress response show the effectiveness of their approach. In the article, Discovering Semantic Biomedical Relations Utilizing the Web, Saurav Sahay, Sougata Mukherjea, Eugene Agichtein, Ernest V. Garcia, Shamkant B. Navathe, and Ashwin Ram describe automated methods to discover relations between biomedical resources on the Web. These relations have applications in constructing and augmenting ontologies and other knowledge bases and in enabling the vision of the Semantic Web for life sciences. The article, Developmental Stage Annotation of Drosophila Gene \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:IaI1MmNe2tcC",
            "Publisher": "ACM"
        },
        {
            "Title": "When being weak is brave: Privacy in recommender systems",
            "Publication year": 2001,
            "Publication url": "https://arxiv.org/abs/cs/0105028",
            "Abstract": "We explore the conflict between personalization and privacy that arises from the existence of weak ties. A weak tie is an unexpected connection that provides serendipitous recommendations. However, information about weak ties could be used in conjunction with other sources of data to uncover identities and reveal other personal information. In this article, we use a graph-theoretic model to study the benefit and risk from weak ties.",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:R3hNpaxXUhUC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Beyond the gene body in the Chinese hamster genome",
            "Publication year": 2013,
            "Publication url": "https://scholar.google.com/scholar?cluster=6349329259774434026&hl=en&oi=scholarr",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:z6xuaG2dYH0C",
            "Publisher": "AMER CHEMICAL SOC"
        },
        {
            "Title": "Learning over Families of Sets-Hypergraph Representation Learning for Higher Order Tasks",
            "Publication year": 2021,
            "Publication url": "https://epubs.siam.org/doi/abs/10.1137/1.9781611976700.85",
            "Abstract": "Graph representation learning has made major strides over the past decade. However, in many relational domains, the input data are not suited for simple graph representations as the relationships between entities go beyond pairwise interactions. In such cases, the relationships in the data are better represented as hyperedges (set of entities) of a non-uniform hypergraph. While there have been works on principled methods for learning representations of nodes of a hypergraph, these approaches are limited in their applicability to tasks on non-uniform hypergraphs (hyperedges with different cardinalities). In this work, we exploit the incidence structure to develop a hypergraph neural network to learn provably expressive representations of variable sized hyperedges which preserve local-isomorphism in the line graph of the hypergraph, while also being invariant to permutations of its constituent vertices. Specifically \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:1wZ_wKGpLuwC",
            "Publisher": "Society for Industrial and Applied Mathematics"
        },
        {
            "Title": "TR O3-O29",
            "Publication year": 2003,
            "Publication url": "https://scholar.google.com/scholar?cluster=12495383466302327361&hl=en&oi=scholarr",
            "Abstract": "PAFI is a set of programs that can be used to \ufb01nd frequent patterns in large and diverse databases. The current release of PAFI includes three different pattern discovery programs called LPMiner, SLPMiner, and FSG. LPMiner \ufb01nds patterns corresponding to itemsets in a transaction database and is based on the algorithm described in [5]. SLPMiner \ufb01nds patterns corresponding to sub-sequences in a sequential database and is based on the algorithm described in [6]. Finally, FSG \ufb01nds patterns corresponding to connected undirected subgraphs in an undirected graph database and is based on the algorithms described in [3, 4]. These programs can be used to mine a Wide-range of datasets arising in commercial, information retrieval, and scienti\ufb01c applications [l]. All three programs can be used to \ufb01nd patterns that satisfy a constant minimum support. Moreover, a key feature of LPMiner and SLPMiner is that they can \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:eO3_k5sD8BwC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Heterogeneous molecular graph neural networks for predicting molecule properties",
            "Publication year": 2020,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/9338432/",
            "Abstract": "As they carry great potential for modeling complex interactions, graph neural network (GNN)-based methods have been widely used to predict quantum mechanical properties of molecules. Most of the existing methods treat molecules as molecular graphs in which atoms are modeled as nodes. They characterize each atom's chemical environment by modeling its pairwise interactions with other atoms in the molecule. Although these methods achieve a great success, limited amount of works explicitly take many-body interactions, i.e., interactions between three and more atoms, into consideration. In this paper, we introduce a novel graph representation of molecules, heterogeneous molecular graph (HMG) in which nodes and edges are of various types, to model many-body interactions. HMGs have the potential to carry complex geometric information. To leverage the rich information stored in HMGs for chemical \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:yCjxvIMm6_oC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Trends in chemical graph data mining",
            "Publication year": 2010,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-1-4419-6045-0_19",
            "Abstract": "Mining chemical compounds in silico has drawn increasing attention from both academia and pharmaceutical industry due to its effectiveness in aiding the drug discovery process. Since graphs are the natural representation for chemical compounds, most of the mining algorithms focus on mining chemical graphs. Chemical graph mining approaches have many applications in the drug discovery process that include structure-activity-relationship (SAR) model construction and bioactivity classification, similar compound search and retrieval from chemical compound database, target identification from phenotypic assays, etc. Solving such problems in silico through studying and mining chemical graphs can provide novel perspective to medicinal chemists, biologist and toxicologist. Moreover, since the large scale chemical graph mining is usually employed at the early stages of drug discovery, it has the potential \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:_Re3VWB3Y0AC",
            "Publisher": "Springer, Boston, MA"
        },
        {
            "Title": "svm PRAT: SVM-based Protein Residue Annotation Toolkit",
            "Publication year": 2009,
            "Publication url": "https://bmcbioinformatics.biomedcentral.com/articles/10.1186/1471-2105-10-439",
            "Abstract": "Over the last decade several prediction methods have been developed for determining the structural and functional properties of individual protein residues using sequence and sequence-derived information. Most of these methods are based on support vector machines as they provide accurate and generalizable prediction models. We present a general purpose protein residue annotation toolkit (svm PRAT) to allow biologists to formulate residue-wise prediction problems. svm PRAT formulates the annotation problem as a classification or regression problem using support vector machines. One of the key features of svm PRAT is its ease of use in incorporating any user-provided information in the form of feature matrices. For every residue svm PRAT captures local information around the reside to create fixed length feature vectors. svm PRAT implements accurate and fast kernel functions, and also introduces a flexible window-based encoding scheme that accurately captures signals and pattern for training effective predictive models. In this work we evaluate svm PRAT on several classification and regression problems including disorder prediction, residue-wise contact order estimation, DNA-binding site prediction, and local structure alphabet prediction. svm PRAT has also been used for the development of state-of-the-art transmembrane helix prediction method called TOPTMH, and secondary structure prediction method called YASSPP. This toolkit developed provides practitioners an efficient and easy-to-use tool for a wide variety of annotation problems. Availability:                      http://www.cs.gmu.edu/~mlbio/svmprat",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:JoZmwDi-zQgC",
            "Publisher": "BioMed Central"
        },
        {
            "Title": "Mgridgen/Parmgridgen Serial/Parallel Library for Generating Coarse Grids for Multigrid Methods",
            "Publication year": 2001,
            "Publication url": "Unknown",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:mKu_rENv82IC",
            "Publisher": "Unknown"
        },
        {
            "Title": "A Software Package for Analysis of Resource Utilization Evolution",
            "Publication year": 2014,
            "Publication url": "http://www.davidanastasiu.net/software/orion/manual-orion-1.0.0.pdf",
            "Abstract": "Understanding how utilization of resources evolves over time is an important task with diverse business applications. For example, an analysis of how PC usage evolves over time can help provide the best overall user experience for current customers, can help determine when they need brand new systems vs. upgraded components, and can inform future product design to better anticipate user needs. As a way to understand usage evolution, consider application (resource) usage in a computer or mobile device. The variables being observed may describe daily time spent by a user interacting with a given application. Figure 1 illustrates the idea of computer usage and its evolution at a high level, grouping individual applications used by users into categories, such as Productivity and Games, and representing usage in these categories as vectors. A user\u2019s behavioral pattern may change over time. For example, our hypothetical user has a decreased overall PC usage as time progresses. Towards the end of the sequence, she spends more time surfing the Web, and less time using productivity tools. Characterizing usage evolution of many users enables us to find groups of users with similar trends (right-hand side of Figure 1), which may also benefit computer hardware and software designers by providing design feedback and insight into upcoming trends.",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:Og1tA8FjbJAC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Interleaving of gate sizing and constructive placement for predictable performance",
            "Publication year": 2007,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/4239417/",
            "Abstract": "This paper presents a fast fixed-die standard cell placement algorithm. Placement is achieved by a combination of top-down partitioning with the incremental row-by-row construction. This paper concentrates on the construction part of this process. Gate sizing is interleaved with the placement construction process. Before placement, every gate is given its minimal size. During the placement, gates are resized to satisfy the timing constraints. Behavior of the placement is adapted based on dynamically recomputed net delay bounds. Experimental results show significant improvement in timing, predictability of results, and run time with respect to a commercial placement tool.",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:yqoGN6RLRZoC",
            "Publisher": "IEEE"
        },
        {
            "Title": "frmsdpred: Predicting local rmsd between structural fragments using sequence information",
            "Publication year": 2008,
            "Publication url": "https://onlinelibrary.wiley.com/doi/abs/10.1002/prot.21998",
            "Abstract": "The effectiveness of comparative modeling approaches for protein structure prediction can be substantially improved by incorporating predicted structural information in the initial sequence\u2010structure alignment. Motivated by the approaches used to align protein structures, this article focuses on developing machine learning approaches for estimating the RMSD value of a pair of protein fragments. These estimated fragment\u2010level RMSD values can be used to construct the alignment, assess the quality of an alignment, and identify high\u2010quality alignment segments. We present algorithms to solve this fragment\u2010level RMSD prediction problem using a supervised learning framework based on support vector regression and classification that incorporates protein profiles, predicted secondary structure, effective information encoding schemes, and novel second\u2010order pairwise exponential kernel functions. Our \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:5ugPr518TE4C",
            "Publisher": "Wiley Subscription Services, Inc., A Wiley Company"
        },
        {
            "Title": "A polynomial time approximation scheme for rectilinear Steiner minimum tree construction in the presence of obstacles",
            "Publication year": 2002,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/1046286/",
            "Abstract": "One problem in VLSI physical designs is to route multiterminal nets in the presence of obstacles. This paper presents a polynomial time approximation scheme for construction of a rectilinear Steiner minimum tree in the presence of obstacles. Given any m rectangular obstacles, n nodes and /spl epsiv/>0, the scheme finds a (1+/spl epsiv/)-approximation to the optimum solution in the time n/sup o(1//spl epsiv/)/, providing an alternative of previous heuristics. Note that m is assumed to be a constant; otherwise when we solve the sub-problem in a brute force manner, we cannot declare that it can be solved in constant time.",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:WA5NYHcadZ8C",
            "Publisher": "IEEE"
        },
        {
            "Title": "Scholars Walk: A Markov Chain Framework for Course Recommendation.",
            "Publication year": 2019,
            "Publication url": "https://eric.ed.gov/?id=ED599254",
            "Abstract": "Course selection is a crucial and challenging problem that students have to face while navigating through an undergraduate degree program. The decisions they make shape their future in ways that they cannot conceive in advance. Available departmental sample degree plans are not personalized for each student, and personal discussion time with an academic advisor is usually limited. Data-driven methods supporting decision making have gained importance to empower student choices and scale advice to large cohorts. We propose Scholars Walk, a random-walk-based approach that captures the sequential relationships between the different courses. Based on the \u201cwisdom of the crowd\u201d and the students\u2019 prior courses, we recommend a short list of courses for next semester. Our experimental evaluation illustrates that Scholars Walk outperforms other collaborative filtering and popularity-based approaches. At the same time, our framework is very efficient, easily interpretable, while also being able to take into consideration important aspects of the educational domain.",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:adHtZc2wMuEC",
            "Publisher": "International Educational Data Mining Society"
        },
        {
            "Title": "Partitioning and load balancing for emerging parallel applications and architectures",
            "Publication year": 2006,
            "Publication url": "https://epubs.siam.org/doi/abs/10.1137/1.9780898718133.ch6",
            "Abstract": "An important component of parallel scientific computing is partitioning\u2014the assignment of work to processors. This assignment occurs at the start of a computation (static partitioning). Often, reassignment also is done during a computation (dynamic partitioning) to redistribute work as the computation changes. The goal of partitioning is to assign work to processors in a way that minimizes total solution time. In general, this goal is pursued by equally distributing work to processors (i.e., load balancing) while attempting to minimize interprocessor communication within the simulation. While distinctions can be made between partitioning and load balancing, in this chapter, we use the terms interchangeably.A wealth of partitioning research exists for mesh-based PDE solvers (e.g., finite volume and FEMs) and their sparse linear solvers. Here, graph-based partitioners have become the tools of choice, due to their excellent \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:1yQoGdGgb4wC",
            "Publisher": "Society for Industrial and Applied Mathematics"
        },
        {
            "Title": "Memory management techniques for gang scheduling",
            "Publication year": 2000,
            "Publication url": "https://link.springer.com/chapter/10.1007/3-540-44520-X_34",
            "Abstract": "The addition of time-slicing to space-shared gang scheduling improves the average response time of the jobs in a typical job stream. Recent research has shown that time-slicing is most effective when the jobs admitted for execution fit entirely into physical memory. The question is, how to select and map jobs to make the best use of the available physical memory. Specifically, the achievable degree of multi-programming is limited by the memory requirements, or physical memory pressure, of the admitted jobs. We investigate two techniques for improving the performance of gang scheduling in the presence of memory pressure: 1) a novel backfill approach which improves memory utilization, and 2) an adaptive multi-programming level which balances processor/memory utilization with job response time performance. Our simulations show that these techniques reduce the average wait time and slow-down \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:g3aElNc5_aQC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "Evaluation of connected-component labeling algorithms for distributed-memory systems",
            "Publication year": 2015,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S0167819115000435",
            "Abstract": "Connected component labeling is a key step in a wide-range of applications, such as community detection in social networks and coherent structure identification in massively-parallel scientific simulations. There have been several distributed-memory connected component algorithms described in literature; however, little has been done regarding their scalability analysis. Theoretical and experimental results are presented for five algorithms: three that are direct implementations of previous approaches, one that is an implementation of a previous approach that is optimized to reduce communication, and one that is a novel approach based on graph contraction. Under weak scaling and for certain classes of graphs, the graph contraction algorithm scales consistently better than the four other algorithms. Furthermore, it uses significantly less memory than two of the alternative methods and is of the same order in terms \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:TaaCk18tZOkC",
            "Publisher": "North-Holland"
        },
        {
            "Title": "Multilevel hypergraph partitioning",
            "Publication year": 2003,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-1-4757-3748-6_3",
            "Abstract": "Hypergraph partitioning is an important problem with extensive application to many areas, including VLSI design [Alpert and Kahng, 1995], efficient storage of large databases on disks [Shekhar and Liu, 1996], and data mining [Mobasher et al., 1996; Karypis et al., 1999b] . The problem is to partition the vertices of a hypergraph into k equal-size parts, such that the number of hyperedges connecting vertices in different parts is minimized.",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:LPZeul_q3PIC",
            "Publisher": "Springer, Boston, MA"
        },
        {
            "Title": "A parallel hill-climbing refinement algorithm for graph partitioning",
            "Publication year": 2016,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/7573823/",
            "Abstract": "Graph partitioning is important in distributing workloads on parallel compute systems, computing sparse matrix re-orderings, and designing VLSI circuits. Refinement algorithms are used to improve existing partitionings, and are essential for obtaining high-quality partitionings. Existing parallel refinement algorithms either extract concurrency by sacrificing in terms of quality, or preserve quality by restricting concurrency. In this work we present a new shared-memory parallel algorithm for refining an existing k-way partitioning that can break out of local minima and produce high-quality partitionings. This allows our algorithm to scale well in terms of the number of processing cores and produce clusterings of quality equal to serial algorithms. Our algorithm achieves speedups of 5.7 - 16.7\u00d7 using 24 cores, while exhibiting only 0.52% higher edgecuts than when run serially. This is 6.3\u00d7 faster and 1.9% better quality than \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:W2uZP3ddy8sC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Introduction to protein structure prediction: methods and algorithms",
            "Publication year": 2011,
            "Publication url": "https://books.google.com/books?hl=en&lr=&id=LeRhAoz4NwEC&oi=fnd&pg=PA1&dq=info:Qe0F_WMequoJ:scholar.google.com&ots=yC3i_z4KOY&sig=0SDCZBTnScd8QqhnU4_gcqRznDc",
            "Abstract": "A look at the methods and algorithms used to predict protein structure A thorough knowledge of the function and structure of proteins is critical for the advancement of biology and the life sciences as well as the development of better drugs, higher-yield crops, and even synthetic bio-fuels. To that end, this reference sheds light on the methods used for protein structure prediction and reveals the key applications of modeled structures. This indispensable book covers the applications of modeled protein structures and unravels the relationship between pure sequence information and three-dimensional structure, which continues to be one of the greatest challenges in molecular biology. With this resource, readers will find an all-encompassing examination of the problems, methods, tools, servers, databases, and applications of protein structure prediction and they will acquire unique insight into the future applications of the modeled protein structures. The book begins with a thorough introduction to the protein structure prediction problem and is divided into four themes: a background on structure prediction, the prediction of structural elements, tertiary structure prediction, and functional insights. Within those four sections, the following topics are covered: Databases and resources that are commonly used for protein structure prediction The structure prediction flagship assessment (CASP) and the protein structure initiative (PSI) Definitions of recurring substructures and the computational approaches used for solving sequence problems Difficulties with contact map prediction and how sophisticated machine learning methods can solve those problems \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:ZqLB7dQ1iF4C",
            "Publisher": "John Wiley & Sons"
        },
        {
            "Title": "Context-aware recommendation-based learning analytics using tensor and coupled matrix factorization",
            "Publication year": 2017,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/7931546/",
            "Abstract": "Student retention and timely graduation are enduring challenges in higher education. With the rapidly expanding collection and availability of learning data and related analytics, student performance can be accurately monitored, and possibly predicted ahead of time, thus, enabling early warning and degree planning \u201cexpert systems\u201d to provide disciplined decision support to counselors, advisors, and educators. Previous work in educational data mining has explored matrix factorization techniques for grade prediction, albeit without taking contextual information into account. Temporal information should be informative as it distinguishes between the different class offerings and indirectly captures student experience as well. To exploit temporal and/or other kinds of context, we develop three approaches under the framework of collaborative filtering (CF). Two of the proposed approaches build upon coupled matrix \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:g_UdREhPGEoC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Science and technology text mining: electric power sources",
            "Publication year": 2004,
            "Publication url": "https://apps.dtic.mil/sti/citations/ADA421789",
            "Abstract": "Database Tomography DT is a textual database analysis system consisting of two major components 1 algorithms for extracting multi-word phrase frequencies and phrase proximities physical closeness of the multi-word technical phrases from any type of large textual database, to augment 2 interpretative capabilities of the expert human analyst. DT was used to derive technical intelligence from a Power Sources database derived from the Science Citation Index SCI. Phrase frequency analysis by the technical domain experts provided the pervasive technical themes of the Power Sources database, and the phrase proximity analysis provided the relationships among the pervasive technical themes. Bibliometric analysis of the Power Sources literature supplemented the DT results with author journal institution country publication and citation data.Descriptors:",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:V3AGJWp-ZtQC",
            "Publisher": "OFFICE OF NAVAL RESEARCH ARLINGTON VA"
        },
        {
            "Title": "TOPTMH: Topology Predictor for Transmembrane a-Helices",
            "Publication year": 2008,
            "Publication url": "https://scholar.google.com/scholar?cluster=11994295205982918609&hl=en&oi=scholarr",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:VnuxuLaQPLMC",
            "Publisher": "Unknown"
        },
        {
            "Title": "System and method for quality based ranking of patents",
            "Publication year": 2019,
            "Publication url": "https://patents.google.com/patent/US20190259114A1/en",
            "Abstract": "Qscore is the most advanced tool available for ranking the potential commercial value of a patent or a portfolio of patents. Other ranking methods typically rely heavily on a patent's reference graph (citations to/from other patents). Qscore is far more sophisticated: using data mining tokenization techniques, Qscore takes into account multiple factors correlated with patent value. This document generally describes the method used to assign a quality score to each patent, which is used to bias the ranking of the results returned from the keyword-based searching in the analytics embodiment of the present invention. This quality score, denoted by Qscore, is designed to identify the patents that are not only relevant to the user's query but also possess some additional, query independent, quality characteristics. Consequently, Qscore can be considered as an information filtering aid\u2014designed to identify the \u201cgood \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:B2rIPIGFPLEC",
            "Publisher": "Unknown"
        },
        {
            "Title": "CTKG: A Knowledge Graph for Clinical Trials",
            "Publication year": 2021,
            "Publication url": "https://europepmc.org/article/ppr/ppr417390",
            "Abstract": "Effective and successful clinical trials are essential in developing new drugs and advancing new treatments. However, clinical trials are very expensive and easy to fail. The high cost and low success rate of clinical trials motivate research on inferring knowledge from existing clinical trials in innovative ways for designing future clinical trials. In this manuscript, we present our efforts on constructing the first publicly available Clinical Trials Knowledge Graph, denoted as CTKG. CTKG includes nodes representing medical entities in clinical trials (eg, studies, drugs and conditions), and edges representing the relations among these entities (eg, drugs used in studies). Our embedding analysis demonstrates the potential utilities of CTKG in various applications such as drug repurposing and similarity search, among others.",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:oYwriLWYh5YC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Proceedings of the 7th ACM Conference on Recommender Systems",
            "Publication year": 2013,
            "Publication url": "Unknown",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:5rMqqAh47xYC",
            "Publisher": "Unknown"
        },
        {
            "Title": "A scalable algorithm for clustering sequential data",
            "Publication year": 2001,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/989516/",
            "Abstract": "In recent years, we have seen an enormous growth in the amount of available commercial and scientific data. Data from domains such as protein sequences, retail transactions, intrusion detection, and Web-logs have an inherent sequential nature. Clustering of such data sets is useful for various purposes. For example, clustering of sequences from commercial data sets may help marketer identify different customer groups based upon their purchasing patterns. Grouping protein sequences that share similar structure helps in identifying sequences with similar functionality. Over the years, many methods have been developed for clustering objects according to their similarity. However these methods tend to have a computational complexity that is at least quadratic on the number of sequences. In this paper we present an entirely different approach to sequence clustering that does not require an all-against-all analysis \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:HDshCWvjkbEC",
            "Publisher": "IEEE"
        },
        {
            "Title": "TR O3-O16",
            "Publication year": 2003,
            "Publication url": "https://scholar.google.com/scholar?cluster=14137997491972756127&hl=en&oi=scholarr",
            "Abstract": "In this paper we study the problem of classifying chemical compound datasets. We present a sub-structure-based classi\ufb01cation algorithm that decouples the sub-structure discovery process from the classi\ufb01cation model construction and uses frequent subgraph discovery algorithms to \ufb01nd all topological and geometric sub-structures present in the dataset. The advantage of our approach is that during classi\ufb01cation model construction, all relevant sub-structures are available allowing the classi\ufb01er to intelligently select the most discriminating ones. The computational scalability is ensured by the use of highly ef\ufb01cient frequent subgraph discovery algorithms coupled with aggressive feature selection. Our experimental evaluation on eight different classi\ufb01cation problems shows that our approach is computationally scalable and outperforms existing schemes by 10% to 35%, on the average.",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:hCrLmN-GePgC",
            "Publisher": "Unknown"
        },
        {
            "Title": "The set classification problem and solution methods",
            "Publication year": 2009,
            "Publication url": "https://epubs.siam.org/doi/abs/10.1137/1.9781611972795.73",
            "Abstract": "This paper focuses on developing classification algorithms for problems in which there is a need to predict the class based on multiple observations (examples) of the same phenomenon (class). These problems give rise to a new classification problem, referred to as set classification, that requires the prediction of a set of instances given the prior knowledge that all the instances of the set belong to the same unknown class. This problem falls under the general class of problems whose instances have class label dependencies. Four methods for solving the set classification problem are developed and studied. The first is based on a straightforward extension of the traditional classification paradigm whereas the other three are designed to explicitly take into account the known dependencies among the instances of the unlabeled set during learning or classification. A comprehensive experimental evaluation of the \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:-_dYPAW6P2MC",
            "Publisher": "Society for Industrial and Applied Mathematics"
        },
        {
            "Title": "Introduction to protein structure prediction",
            "Publication year": 2010,
            "Publication url": "https://www.researchgate.net/profile/Jeffrey-Skolnick/publication/220804507_Protein_Structure_Prediction_-_Session_Introduction/links/56df02cd08ae9b93f79a876e/Protein-Structure-Prediction-Session-Introduction.pdf",
            "Abstract": "relationship between pure sequence information and 3D structure and/or function remains one of the fundamental challenges in molecular biology. Function prediction is generally approached by using inheritance through homology [2], that is, proteins with similar sequences (common evolutionary ancestry) frequently carry out similar functions. However, several studies [2\u20134] have shown that a stronger correlation exists between structure conservation and function, that is, structure implies function, and a higher correlation exists between sequence conservation and structure, that is, sequence implies structure (sequence\u2192 structure\u2192 function).",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:8JTMrWI6FdcC",
            "Publisher": "John Wiley & Sons"
        },
        {
            "Title": "Learning graph neural networks with deep graph library",
            "Publication year": 2020,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/3366424.3383111",
            "Abstract": "Learning from graph and relational data plays a major role in many applications including social network analysis, marketing, e-commerce, information retrieval, knowledge modeling, medical and biological sciences, engineering, and others. In the last few years, Graph Neural Networks (GNNs) have emerged as a promising new supervised learning framework capable of bringing the power of deep representation learning to graph and relational data. This ever-growing body of research has shown that GNNs achieve state-of-the-art performance for problems such as link prediction, fraud detection, target-ligand binding activity prediction, knowledge-graph completion, and product recommendations.",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:e3CVSTJ63dQC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Systems analysis of regulatory interactions in Streptomyces coelicolor.",
            "Publication year": 2005,
            "Publication url": "https://scholar.google.com/scholar?cluster=8684573917725233155&hl=en&oi=scholarr",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:SIv7DqKytYAC",
            "Publisher": "AMER CHEMICAL SOC"
        },
        {
            "Title": "Storing Dynamic Graphs: Speed vs. Storage Trade-offs",
            "Publication year": 2014,
            "Publication url": "https://conservancy.umn.edu/handle/11299/215955",
            "Abstract": "With the ever increasing size and availability of web and social graph comes the need for compact and efficient data structures in which to store them. The problem of compact representations for sparse static graphs is a well studied problem in the domain of web and online social graphs, namely the WebGraph Framework and the Layered Label Propagation ordering for extending WebGraph to online social networks, among others. While these techniques do a satisfactory job in the context of static sparse graphs, there is little literature on how these techniques can be extended to dynamic sparse graphs. In this paper, we present algorithms and experimental analysis for five data structures for representing dynamic sparse graphs: Linked-List (LL), Batch Compressed Sparse Row (BCSR), Dynamic Adjacency Array (DAA), Dynamic Intervalized Adjacency Array (DIAA), and Dynamic Compressed Adjacency Array (DCAA). The goal of the presented data structures is two fold. First, the data structures must be compact, as the size of the graphs being operated on continues to grow to less manageable sizes. Second, the cost of operating on the data structures must be within a small factor of the cost of operating on the static graph, else these data structures will not be useful. Of these five algorithms, LL, BCSR, and DAA are baseline approaches, DCAA is semi-compact, but suited for fast operation, and DIAA is focused on compactness and is a dynamic extension of the WebGraph Framework. Our results show that for well intervalized graphs, like web graphs, DCAA is superior to all other data structures in terms of memory and access time. Furthermore \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:jtI9f0ekYq0C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Influence in ratings-based recommender systems: An algorithm-independent approach",
            "Publication year": 2005,
            "Publication url": "https://epubs.siam.org/doi/abs/10.1137/1.9781611972757.60",
            "Abstract": "Recommender systems have been shown to help users find items of interest from among a large pool of potentially interesting items. Influence is a measure of the effect of a user on the recommendations from a recommender system. Influence is a powerful tool for understanding the workings of a recommender system. Experiments show that users have widely varying degrees of influence in ratings-based recommender systems. Proposed influence measures have been algorithm-specific, which limits their generality and comparability. We propose an algorithm-independent definition of influence that can be applied to any ratings-based recommender system. We show experimentally that influence may be effectively estimated using simple, inexpensive metrics.",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:L_l9e5I586QC",
            "Publisher": "Society for Industrial and Applied Mathematics"
        },
        {
            "Title": "QCRNA 1.0: A database of quantum calculations for RNA catalysis",
            "Publication year": 2006,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S1093326306000507",
            "Abstract": "This work outlines a new on-line database of quantum calculations for RNA catalysis (QCRNA) available via the worldwide web at http://theory.chem.umn.edu/QCRNA. The database contains high-level density functional calculations for a large range of molecules, complexes and chemical mechanisms important to phosphoryl transfer reactions and RNA catalysis. Calculations are performed using a strict, consistent protocol such that a wealth of cross-comparisons can be made to elucidate meaningful trends in biological phosphate reactivity. Currently, around 2000 molecules have been collected in varying charge states in the gas phase and in solution. Solvation was treated with both the PCM and COSMO continuum solvation models. The data can be used to study important trends in reactivity of biological phosphates, or used as benchmark data for the design of new semiempirical quantum models for hybrid \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:dshw04ExmUIC",
            "Publisher": "Elsevier"
        },
        {
            "Title": "Guest Editor's Introduction: Data Mining",
            "Publication year": 2002,
            "Publication url": "https://www.computer.org/csdl/magazine/cs/2002/04/c4012/13rRUwIF6gm",
            "Abstract": "Data mining is the process of automatically extracting new and useful knowledge hidden in large data sets. This emerging discipline is becoming increasingly important as advances in data collection lead to the explosive growth in the amount of available data. Data mining techniques primarily help analyze commercial data sets and play a critical role in analyzing and understanding purchasing behaviors for effective consumer relations management, process optimization, personalized marketing, and customer segmentation.",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:NJ774b8OgUMC",
            "Publisher": "IEEE Computer Society"
        },
        {
            "Title": "Efficient nested dissection for multicore architectures",
            "Publication year": 2015,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-662-48096-0_36",
            "Abstract": "Sparse matrices are common in scientific computing and machine learning. By storing and processing only the non-zero elements of a matrix containing mostly zeros, sparse matrix algorithms often reduce computation and storage requirements of operations by an order of complexity. The order of the rows and columns of the matrix can have a significant impact on the efficiency of sparse direct methods. For example, in a Cholesky decomposition, it is desirable to re-order the input matrix so as to reduce the number of non-zeros in the factors. One of the most effective methods for re-ordering is nested dissection, where vertex separators are recursively found in the graph representation of the matrix and are used to permute the rows and columns. In this work we investigate the creation of vertex separators on shared memory parallel architectures and their use in nested dissection. We introduce a new effective scheme \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:Azgs6IHzeyYC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "TR O0-O43",
            "Publication year": 2000,
            "Publication url": "https://scholar.google.com/scholar?cluster=16210014957696262964&hl=en&oi=scholarr",
            "Abstract": "We investigate the use of dimensionality reduction to improve performance for a new class of data analysis software called \u201crecommender systems\u201d. Recommender systems apply knowledge discovery techniques to the problem of making product recommendations during a live customer interaction. These systems are achieving widespread success in E-commerce nowadays, especially with the advent of the Internet. The tremendous growth of customers and products poses three key challenges for recommender systems in the E-commerce domain. These are: producing high quality recommendations, performing many recommendations per second for millions of customers and products, and achieving high coverage in the face of data sparsity. One successful recommender system technology is collaborative filtering, which works by matching customer preferences to other customers in making recommendations \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:LdasjJ6CEcoC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Truss decomposition on shared-memory parallel systems",
            "Publication year": 2017,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/8091049/",
            "Abstract": "The scale of data used in graph analytics grows at an unprecedented rate. More than ever, domain experts require efficient and parallel algorithms for tasks in graph analytics. One such task is the truss decomposition, which is a hierarchical decomposition of the edges of a graph and is closely related to the task of triangle enumeration. As evidenced by the recent GraphChallenge, existing algorithms and implementations for truss decomposition are insufficient for the scale of modern datasets. In this work, we propose a parallel algorithm for computing the truss decomposition of massive graphs on a shared-memory system. Our algorithm breaks a computation-efficient serial algorithm into several bulk-synchronous parallel steps which do not rely on atomics or other fine-grained synchronization. We evaluate our algorithm across a variety of synthetic and real-world datasets on a 56-core Intel Xeon system. Our serial \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:4n0clTBhZ78C",
            "Publisher": "IEEE"
        },
        {
            "Title": "An exploration of optimization algorithms for high performance tensor completion",
            "Publication year": 2016,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/7877109/",
            "Abstract": "Tensor completion is a powerful tool used to estimate or recover missing values in multi-way data. It has seen great success in domains such as product recommendation and healthcare. Tensor completion is most often accomplished via low-rank sparse tensor factorization, a computationally expensive non-convex optimization problem which has only recently been studied in the context of parallel computing. In this work, we study three optimization algorithms that have been successfully applied to tensor completion: alternating least squares (ALS), stochastic gradient descent (SGD), and coordinate descent (CCD++). We explore opportunities for parallelism on shared- and distributed-memory systems and address challenges such as memory- and operation-efficiency, load balance, cache locality, and communication. Among our advancements are an SGD algorithm which combines stratification with \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:BAanoTsO0WEC",
            "Publisher": "IEEE"
        },
        {
            "Title": "KUMAR.\"",
            "Publication year": 2007,
            "Publication url": "https://scholar.google.com/scholar?cluster=7477352259274222285&hl=en&oi=scholarr",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:U3qCfcK-7lkC",
            "Publisher": "Unknown"
        },
        {
            "Title": "A study on curriculum planning and its relationship with graduation gpa and time to degree",
            "Publication year": 2019,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/3303772.3303783",
            "Abstract": "In recent years, several data-driven methods have been developed to help undergraduate students during course selection and sequencing. These methods tend to utilize the whole set of past course registration data, regardless of the past students' graduation GPA and time to degree (TTD). Though some previous work has shown through the results of their developed models that students of different GPA tend to take courses in different sequence, the actual analysis of the degree plans and how/if they relate to the students' graduation GPA and time-to-degree has not received much attention. This study analyzes how the student's academic level when they take different courses, as well as the pairwise degree similarity between pairs of students relate to the students' graduation GPA and TTD. Our study uses a large-scale dataset that contains 25 majors from different colleges at the University of Minnesota and \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:5LPo_wSKItgC",
            "Publisher": "Unknown"
        },
        {
            "Title": "In silico structure\u2010activity\u2010relationship (SAR) models from machine learning: a review",
            "Publication year": 2011,
            "Publication url": "https://onlinelibrary.wiley.com/doi/abs/10.1002/ddr.20410",
            "Abstract": "In this article, we review the recent development for in silico Structure\u2010Activity\u2010Relationship (SAR) models using machine\u2010learning techniques. The review focuses on the following topics: machine\u2010learning algorithms for computational SAR models, single\u2010target\u2010oriented SAR methodologies, Chemogenomics, and future trends. We try to provide the state\u2010of\u2010the\u2010art SAR methods as well as the most up\u2010to\u2010date advancement, in order for the researchers to have a general overview at this area. Drug Dev Res 72: 138\u2013146, 2011. \u00a9 2010 Wiley\u2010Liss, Inc.",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:KUbvn5osdkgC",
            "Publisher": "Wiley Subscription Services, Inc., A Wiley Company"
        },
        {
            "Title": "Clustering in life sciences",
            "Publication year": 2003,
            "Publication url": "https://link.springer.com/protocol/10.1385/1-59259-364-X:183",
            "Abstract": "Clustering is the task of organizing a set of objects into meaningful groups. These groups can be disjoint, overlapping, or organized in some hierarchical fashion. The key element of clustering is the notion that the discovered groups are meaningful. This definition is intentionally vague, because what constitutes meaningful is, to a large extent, application dependent. In some applications, this may translate to groups in which the pairwise similarity between their objects is maximized, and the pairwise similarity between objects of different groups is minimized. In some other applications, this may translate to groups that contain objects that share some key characteristics, even though their overall similarity is not the highest. Clustering is an exploratory tool for analyzing large data sets and has been used extensively in numerous application areas.",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:BqipwSGYUEgC",
            "Publisher": "Humana Press"
        },
        {
            "Title": "Soft clustering criterion functions for partitional document clustering",
            "Publication year": 2004,
            "Publication url": "https://apps.dtic.mil/sti/citations/ADA439425",
            "Abstract": "Recently published studies have shown that partitional clustering algorithms that optimize certain criterion functions, which measure key aspects of inter-and intra-cluster similarity, are very effective in producing hard clustering solutions for document datasets and outperform traditional partitional and agglomerative algorithms. In this paper we study the extent to which these criterion functions can be modified to include soft membership functions and whether or not the resulting soft clustering algorithms can further improve the clustering solutions. Specifically, we focus on four of these hard criterion functions, derive their soft-clustering extensions, present a comprehensive experimental evaluation involving twelve different datasets, and analyze their overall characteristics. Our results show that introducing softness into the criterion functions tends to lead to better clustering results for most datasets and consistently improve the separation between the clusters.Descriptors:",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:pRWBApOjXDcC",
            "Publisher": "MINNESOTA UNIV MINNEAPOLIS DEPT OF COMPUTER SCIENCE"
        },
        {
            "Title": "Indirect similarity based methods for effective scaffold-hopping in chemical compounds",
            "Publication year": 2008,
            "Publication url": "https://pubs.acs.org/doi/abs/10.1021/ci700369e",
            "Abstract": "Methods that can screen large databases to retrieve a structurally diverse set of compounds with desirable bioactivity properties are critical in the drug discovery and development process. This paper presents a set of such methods that are designed to find compounds that are structurally different to a certain query compound while retaining its bioactivity properties (scaffold hops). These methods utilize various indirect ways of measuring the similarity between the query and a compound that take into account additional information beyond their structure-based similarities. The set of techniques that are presented capture these indirect similarities using approaches based on analyzing the similarity network formed by the query and the database compounds. Experimental evaluation shows that most of these methods substantially outperform previously developed approaches both in terms of their ability to identify \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:gkldIfsazJcC",
            "Publisher": "American Chemical Society"
        },
        {
            "Title": "Evaluating Scholarly Impact: Towards Content-Aware Bibliometrics",
            "Publication year": 2021,
            "Publication url": "https://aclanthology.org/2021.emnlp-main.488/",
            "Abstract": "Quantitatively measuring the impact-related aspects of scientific, engineering, and technological (SET) innovations is a fundamental problem with broad applications. Traditional citation-based measures for assessing the impact of innovations and related entities do not take into account the content of the publications. This limits their ability to provide rigorous quality-related metrics because they cannot account for the reasons that led to a citation. We present approaches to estimate content-aware bibliometrics to quantitatively measure the scholarly impact of a publication. Our approaches assess the impact of a cited publication by the extent to which the cited publication informs the citing publication. We introduce a new metric, called \u201cContent Informed Index\u201d(CII), that uses the content of the paper as a source of distant-supervision, to quantify how much the cited-node informs the citing-node. We evaluate the weights estimated by our approach on three manually annotated datasets, where the annotations quantify the extent of information in the citation. Particularly, we evaluate how well the ranking imposed by our approach associates with the ranking imposed by the manual annotations. CII achieves up to 103% improvement in performance as compared to the second-best performing approach.",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:-fu4zM_6qcIC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Streaming and Batch Algorithms for Truss Decomposition",
            "Publication year": 2019,
            "Publication url": "https://ui.adsabs.harvard.edu/abs/2019arXiv190810550R/abstract",
            "Abstract": "Truss decomposition is a method used to analyze large sparse graphs in order to identify successively better connected subgraphs. Since in many domains the underlying graph changes over time, its associated truss decomposition needs to be updated as well. This work focuses on the problem of incrementally updating an existing truss decomposition and makes the following three significant contributions. First, it presents a theory that identifies how the truss decomposition can change as new edges get added. Second, it develops an efficient incremental algorithm that incorporates various optimizations to update the truss decomposition after every edge addition. These optimizations are designed to reduce the number of edges that are explored by the algorithm. Third, it extends this algorithm to batch updates (ie, where the truss decomposition needs to be updated after a set of edges are added), which reduces \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:4oJvMfeQlr8C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Nerstrand: Fast Multi-Threaded Graph Clustering",
            "Publication year": 2013,
            "Publication url": "http://sc13.supercomputing.org/sites/default/files/PostersArchive/tech_posters/post193s2-file3.pdf",
            "Abstract": "In this work we apply the multilevel paradigm to optimizing the modularity of a graph clustering on parallel shared memory architectures. We improve upon the state of the art by introducing new methods for effectively and efficiently coarsening graphs with power-law degree distributions, detecting an unknown number of communities, and for performing greedy modularity refinement in parallel. Finally, we present the culmination of this research, the graph clustering tool Nerstrand1. In serial mode, Nerstrand runs in a fraction of the time of current methods and produces results of equal quality. When run with multiple threads, Nerstrand exhibits significant speedup without decreasing quality. Nerstrand works well on large graphs, clustering a graph with over 18 million vertices and 261 million edges in 18.3 seconds.",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:EsEWqaRxkBgC",
            "Publisher": "Unknown"
        },
        {
            "Title": "A comparison of document clustering techniques",
            "Publication year": 2000,
            "Publication url": "https://conservancy.umn.edu/handle/11299/215421",
            "Abstract": "This paper presents the results of an experimental study of some common document clustering techniques.  In particular, we compare the two main approaches to document clustering, agglomerative hierarchical clustering and K-means.  (For K-means we used a \"standard\" K-means algorithm and a variant of K-means, \"bisecting\" K-means.)  Hierarchical clustering is often portrayed as the better quality clustering approach, but is limited because of its quadratic time complexity.  In contrast, K-means and its variants have a time complexity which is linear in the number of documents, but are thought to produce inferior clusters.  Sometimes K-means and agglomerative hierarchical approaches are combined so as to \"get the best of both worlds.\"  However, our results indicate that the bisecting K-means technique is better than the standard K-means approach and as good or better than the hierarchical approaches that we tested for a variety of cluster evaluation metrics.  We propose an explanation for these results that is based on an analysis of the specifics of the clustering algorithms and the nature of document data.",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:9yKSN-GCB0IC",
            "Publisher": "Unknown"
        },
        {
            "Title": "LPMiner: An algorithm for finding frequent itemsets using length-decreasing support constraint",
            "Publication year": 2001,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/989558/",
            "Abstract": "Over the years, a variety of algorithms for finding frequent item sets in very large transaction databases has been developed. The key feature in most of these algorithms is that they use a constant support constraint to control the inherently exponential complexity of the problem. In general, item sets that contain only a few items tend to be interesting if they have a high support, whereas long item sets can still be interesting even if their support is relatively small. Ideally, we desire to have an algorithm that finds all the frequent item sets whose support decreases as a function of their length. In this paper, we present an algorithm called LPMiner (Long Pattern Miner) that finds all item sets that satisfy a length-decreasing support constraint. Our experimental evaluation shows that LPMiner is up to two orders of magnitude faster than the FP-growth algorithm for finding item sets at a constant support constraint, and that its run \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:_Qo2XoVZTnwC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Average Position of User Clicks as an Automated and Non-Intrusive Way of Evaluating Ranking Methods",
            "Publication year": 2003,
            "Publication url": "https://conservancy.umn.edu/handle/11299/215552",
            "Abstract": "The need for an objective and automated way of evaluating the performance of different ranking/reranking methods is becoming increasingly important in the web search/meta search domain. There are various methods for ranking search results ranging from traditional information retrieval approaches to more recent methods based on link analysis and other quality measures that can be derived from the documents. There are also a number of strategies for combining different heuristics and answers from multiple experts. With all of these possibilities it is becoming increasingly difficult to find the best parameters, the best method, or the best mixture of methods that will maximize the quality for a particular query type or domain. This paper addresses the problem of automatically comparing the quality of the ordering of documents that are presented to the user as a sorted list according to believed relevance for a given topic or query. We introduce the average position of user clicks metric as an implicit, automated, and non-intrusive way of evaluating ranking methods. We also discuss under which situations and assumptions this metric can be used objectively by addressing various bias sources. Experiments performed in our meta search engine suggests that, this approach has the potential to sample a wide range of query types and users with greater statistical significance compared to methods that rely on explicit user judgements.",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:IyxfXMz2bNAC",
            "Publisher": "Unknown"
        },
        {
            "Title": "LIBRUS: Combined machine learning and homology information for sequence-based ligand-binding residue prediction",
            "Publication year": 2009,
            "Publication url": "https://academic.oup.com/bioinformatics/article-abstract/25/23/3099/216185",
            "Abstract": " Motivation: Identifying residues that interact with ligands is useful as a first step to understanding protein function and as an aid to designing small molecules that target the protein for interaction. Several studies have shown that sequence features are very informative for this type of prediction, while structure features have also been useful when structure is available. We develop a sequence-based method, called LIBRUS, that combines homology-based transfer and direct prediction using machine learning and compare it to previous sequence-based work and current structure-based methods. Results: Our analysis shows that homology-based transfer is slightly more discriminating than a support vector machine learner using profiles and predicted secondary structure. We combine these two approaches in a method called LIBRUS. On a benchmark of 885 sequence-independent proteins, it \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:epqYDVWIO7EC",
            "Publisher": "Oxford University Press"
        },
        {
            "Title": "Department of Computer Science and Engineering University of Minnesota, Minneapolis, Minnesota 55414 Email: rangwala@ cs. umn. edu",
            "Publication year": 2008,
            "Publication url": "https://scholar.google.com/scholar?cluster=1983969018256650054&hl=en&oi=scholarr",
            "Abstract": "As the sequence identity between a pair of proteins decreases, alignment strategies that are based on sequence and/or sequence profiles become progressively less effective in identifying the correct structural correspondence between residue pairs. This significantly reduces the ability of comparative modeling-based approaches to build accurate structural models. Incorporating into the alignment process predicted information about the local structure of the protein holds the promise of significantly improving the alignment quality of distant proteins. This paper studies the impact on the alignment quality of a new class of predicted local structural features that measure how well fixed-length backbone fragments centered around each residue-pair align with each other. It presents a comprehensive experimental evaluation comparing these new features against existing state-of-the-art approaches utilizing profile-based and predicted secondary-structure information. It shows that for protein pairs with low sequence similarity (less than 12% sequence identity) the new structural features alone or in conjunction with profile-based information lead to alignments that are considerably better than those obtained by previous schemes.",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:5qfkUJPXOUwC",
            "Publisher": "Imperial College Press"
        },
        {
            "Title": "TOPTMH: Topology Predictor for Transmembrane \u03b1-Helices",
            "Publication year": 2010,
            "Publication url": "https://www.worldscientific.com/doi/abs/10.1142/S0219720010004501",
            "Abstract": "Alpha-helical transmembrane proteins mediate many key biological processes and represent 20%\u201330% of all genes in many organisms. Due to the difficulties in experimentally determining their high-resolution 3D structure, computational methods to predict the location and orientation of transmembrane helix segments using sequence information are essential. We present TOPTMH, a new transmembrane helix topology prediction method that combines support vector machines, hidden Markov models, and a widely used rule-based scheme. The contribution of this work is the development of a prediction approach that first uses a binary SVM classifier to predict the helix residues and then it employs a pair of HMM models that incorporate the SVM predictions and hydropathy-based features to identify the entire transmembrane helix segments by capturing the structural characteristics of these proteins. TOPTMH \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:W5xh706n7nkC",
            "Publisher": "Imperial College Press"
        },
        {
            "Title": "Opportunities for data-driven cloud-based mobile optimization",
            "Publication year": 2014,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/6867611/",
            "Abstract": "In this paper, we present our vision for cloud-based mobile computing using user profile information. Such information enables a series of data-driven optimizations: filtering, aggregation, and speculation, that go beyond the well-researched benefit of mobile outsourcing. These optimizations can improve performance, reliability, and energy usage. A novel aspect of our approach is to exploit the unique ability of the cloud to collect and analyze large amounts of user profile data, cache shared data, and even enable sharing of computations, across different mobile users. We present results for two exemplar mobile-cloud applications, driven by workload traces derived from Twitter feeds and Wikipedia document editing, to illustrate these opportunities.",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:_AeoHAGD03cC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Towards a Scalable kNN CF Algorithm: Exploring Effective Applications of Clustering",
            "Publication year": 2006,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-540-77485-3_9",
            "Abstract": "Collaborative Filtering (CF)-based recommender systems bring mutual benefits to both users and the operators of the sites with too much information. Users benefit as they are able to find items of interest from an unmanageable number of available items. On the other hand, e-commerce sites that employ recommender systems can increase sales revenue in at least two ways: a) by drawing customers\u2019 attention to items that they are likely to buy, and b) by cross-selling items. However, the sheer number of customers and items typical in e-commerce systems demand specially designed CF algorithms that can gracefully cope with the vast size of the data. Many algorithms proposed thus far, where the principal concern is recommendation quality, may be too expensive to operate in a large-scale system. We propose ClustKnn, a simple and intuitive algorithm that is well suited for large data sets. The method first \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:tkaPQYYpVKoC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "Discovering geometric frequent subgraphs",
            "Publication year": 2002,
            "Publication url": "https://conservancy.umn.edu/handle/11299/215528",
            "Abstract": "As data mining techniques are being increasingly applied tonon-traditional domains, existing approaches for finding frequent itemsets cannot be used as they cannot model the requirement of these domains. An alternate way of modeling the objects in these data sets, is to use a graph to model the database objects. Within that model, the problem of finding frequent patterns becomes that of discoveringsubgraphs that occur frequently over the entire set of graphs. In this paper we present a computationally efficient algorithm for finding frequent geometric subgraphs in a large collection of geometric graphs. Our algorithm is able to discover geometric subgraphs that can be translation, rotation, and scaling invariant, and it can accommodate inherent errors on the coordinates of the vertices.  We evaluated the performance of the algorithm using a large database of over 20,000 real two-dimensional chemical structures, and our experimental results show that our algorithms requires relatively little time, can accommodate low support values, and scales linearly on the number of transactions.",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:CNPyR2KL9-0C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Algorithms for mining the coevolving relational motifs in dynamic networks",
            "Publication year": 2015,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/2733380",
            "Abstract": "Computational methods and tools that can efficiently and effectively analyze the temporal changes in dynamic complex relational networks enable us to gain significant insights regarding the entity relations and their evolution. This article introduces a new class of dynamic graph patterns, referred to as coevolving relational motifs (CRMs), which are designed to identify recurring sets of entities whose relations change in a consistent way over time. CRMs can provide evidence to the existence of, possibly unknown, coordination mechanisms by identifying the relational motifs that evolve in a similar and highly conserved fashion. We developed an algorithm to efficiently analyze the frequent relational changes between the entities of the dynamic networks and capture all frequent coevolutions as CRMs. Our algorithm follows a depth-first exploration of the frequent CRM lattice and incorporates canonical labeling for \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:s9ia6_kGH2AC",
            "Publisher": "ACM"
        },
        {
            "Title": "Discerning key parameters influencing high productivity and quality through recognition of patterns in process data",
            "Publication year": 2011,
            "Publication url": "https://bmcproc.biomedcentral.com/articles/10.1186/1753-6561-5-S8-P91",
            "Abstract": "BackgroundThe adoption of Quality by Design (QbD) approach to biologics manufacturing requires fundamental understanding of complex relationship between the quality of the product, especially critical quality attributes (CQAs), and various parameters of the manufacturing process [1]. This can be approached through multivariate analysis of historical cell culture bioprocess data [2]. In this study, process parameters and raw materials data obtained from 51 runs with final titer varying from 0.8 to 2.0 units and Gal0 glycan ranging from 47.5 to 67.5% was investigated. The aim was to discover prominent patterns which may cause the spread of final process outcome.Materials and methodsOffline and online data were processed using linear interpolation and a moving window average method, respectively as described previously [3]. Data from the 1,000 L scale was organized into six cumulative datasets corresponding to days 3, 6, 8, 10, 13, and 15. Euclidean distance for each process parameter between all pairs of runs was calculated and normalized to 0-1. The similarity measure was determined using exponential transformation of the negative of the corresponding distance, and organized into a matrix form. The overall similarity matrix was computed as the weighted combination of all individual similarity matrices. The weight of each reflects how well it correlates to the deviation in final process outcome. A support vector regression (SVR) model was constructed using the overall similarity of all process parameters to predict the final product titer and glycosylation profiles for each cumulative dataset. Prediction accuracy was assessed using the \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:r_AWSJRzSzQC",
            "Publisher": "BioMed Central"
        },
        {
            "Title": "Fast parallel cosine k-nearest neighbor graph construction",
            "Publication year": 2016,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/7833303/",
            "Abstract": "The k-nearest neighbor graph is an important structure in many data mining methods for clustering, advertising, recommender systems, and outlier detection. Constructing the graph requires computing up to n 2  similarities for a set of n objects. This has led researchers to seek approximate methods, which find many but not all of the nearest neighbors. In contrast, we leverage shared memory parallelism and recent advances in similarity joins to solve the problem exactly, via a filtering based approach. Our method considers all pairs of potential neighbors but quickly filters those that could not be a part of the k-nearest neighbor graph, based on similarity upper bound estimates. We evaluated our solution on several real-world datasets and found that, using 16 threads, our method achieves up to 12.9\u00d7 speedup over our exact baseline and is sometimes faster even than approximate methods. Moreover, an approximate \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:J3LtWjKFLicC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Parmetis",
            "Publication year": 2003,
            "Publication url": "https://dev.ece.ubc.ca/projects/gpgpu-sim/export/96f6ad00d6d3e9a58b1d51edaac76d061c02fa82/ispass2009-benchmarks/DG/3rdParty/ParMetis-3.1/Manual/manual.pdf",
            "Abstract": "PARMETIS is an MPI-based parallel library that implements a variety of algorithms for partitioning and repartitioning unstructured graphs and for computing fill-reducing orderings of sparse matrices. PARMETIS is particularly suited for parallel numerical simulations involving large unstructured meshes. In this type of computation, PARMETIS dramatically reduces the time spent in communication by computing mesh decompositions such that the numbers of interface elements are minimized.The algorithms in PARMETIS are based on the multilevel partitioning and fill-reducing ordering algorithms that are implemented in the widely-used serial package METIS [5]. However, PARMETIS extends the functionality provided by METIS and includes routines that are especially suited for parallel computations and large-scale numerical simulations. In particular, PARMETIS provides the following functionality:\u2022 Partition unstructured graphs and meshes.",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:UarirCmVI0EC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Feature-Based Recommendation System",
            "Publication year": 2005,
            "Publication url": "https://scholar.google.com/scholar?cluster=14288373203793925584&hl=en&oi=scholarr",
            "Abstract": "The explosive growth of the world-wide-web and the emer-gence of e-commerce has led to the development of recom-mender systems a personalized information filtering tech-nology used to identify a set of N items that will be of interest to a certain user. User-based and model-based col-laborative filtering are the most successful technology for building recommender systems to date and is extensively used in many commercial recommender systems. The basic assumption in these algorithms is that there are sufficient historical data for measuring similarity between products or users. However, this assumption does not hold in various ap-plication domains such as electronics retail, home shopping network, on-line retail where new products are introduced and existing products disappear from the catalog. Another such application domains is home improvement retail indus-try where a lot of products (such as window treatments, bathroom, kitchen or deck) are custom made. Each product is unique and there are very little duplicate products. In this domain, the probability of the same exact two products bought together is close to zero. In this paper, we discuss the challenges of providing recommendation in the domains where no sufficient historical data exist for measuring simi-larity between products or users. We present feature-based recommendation algorithms that overcome the limitations of the existing top-N recommendation algorithms. The ex-perimental evaluation of the proposed algorithms in the real life data sets shows a great promise. The pilot project de-ploying the proposed feature-based recommendation algo rithms in the on-line retail \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:-38epGy1wY0C",
            "Publisher": "Assn for Computing Machinery"
        },
        {
            "Title": "Learning from sets of items in recommender systems",
            "Publication year": 2019,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/3326128",
            "Abstract": "Most of the existing recommender systems use the ratings provided by users on individual items. An additional source of preference information is to use the ratings that users provide on sets of items. The advantages of using preferences on sets are twofold. First, a rating provided on a set conveys some preference information about each of the set\u2019s items, which allows us to acquire a user\u2019s preferences for more items than the number of ratings that the user provided. Second, due to privacy concerns, users may not be willing to reveal their preferences on individual items explicitly but may be willing to provide a single rating to a set of items, since it provides some level of information hiding. This article investigates two questions related to using set-level ratings in recommender systems. First, how users\u2019 item-level ratings relate to their set-level ratings. Second, how collaborative filtering-based models for item-level \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:i_7YvbSbtFEC",
            "Publisher": "ACM"
        },
        {
            "Title": "Data mining algorithms for virtual screening of bioactive compounds",
            "Publication year": 2007,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-0-387-69319-4_5",
            "Abstract": "In this chapter we study the problem of classifying chemical compound datasets. We present a sub-structure-based classification algorithm that decouples the sub-structure discovery process from the classification model construction and uses frequent subgraph discovery algorithms to find all topological and geometric sub-structures present in the dataset. The advantage of this approach is that during classification model construction, all relevant sub-structures are available allowing the classifier to intelligently select the most discriminating ones. The computational scalability is ensured by the use of highly efficient frequent subgraph discovery algorithms coupled with aggressive feature selection. Experimental evaluation on eight different classification problems shows that our approach is computationally scalable and on the average, outperforms existing schemes by 10% to 35%.",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:4X0JR2_MtJMC",
            "Publisher": "Springer, Boston, MA"
        },
        {
            "Title": "Feature-based recommendation system",
            "Publication year": 2005,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/1099554.1099683",
            "Abstract": "The explosive growth of the world-wide-web and the emergence of e-commerce has led to the development of recommender systems--a personalized information filtering technology used to identify a set of N items that will be of interest to a certain user. User-based and model-based collaborative filtering are the most successful technology for building recommender systems to date and is extensively used in many commercial recommender systems. The basic assumption in these algorithms is that there are sufficient historical data for measuring similarity between products or users. However, this assumption does not hold in various application domains such as electronics retail, home shopping network, on-line retail where new products are introduced and existing products disappear from the catalog. Another such application domains is home improvement retail industry where a lot of products (such as window \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:a0OBvERweLwC",
            "Publisher": "Unknown"
        },
        {
            "Title": "TheTo---A Fast, Scalable and High-Quality Partitioning Driven Placement Tool.",
            "Publication year": 2004,
            "Publication url": "https://conservancy.umn.edu/handle/11299/215634",
            "Abstract": "Partitioning driven placement approaches are often preferred for fast and scalable solutions to large placement problems. However, due to the inaccuracy of representing wirelength objective by cut objective the quality of such placements often trails the quality of placements produced by pure wirelength driven placements. In this paper we present TheTo, a new partitioning driven placement algorithm that retains the speed associated with traditional partitioning driven placement algorithms but incorporates a number of novel ideas that allows it to produce solutions whose quality is better than those produced by more sophisticated and computationally expensive algorithms. The keys to TheTo's success are a new terminal propagation method that allows the partitioner to exactly map the half-perimeter wirelength cost to min-cut cost, and an integral post-bisectioning refinement step that enhances the effectiveness of the new terminal propagation. Experimental validations show that TheTo is fast and also quite effective in reducing half-perimeter wirelength.",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:e0LTWoPxLYMC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Sparse linear methods with side information for top-n recommendations",
            "Publication year": 2012,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/2365952.2365983",
            "Abstract": "The increasing amount of side information associated with the items in E-commerce applications has provided a very rich source of information that, once properly exploited and incorporated, can significantly improve the performance of the conventional recommender systems. This paper focuses on developing effective algorithms that utilize item side information for top-N recommender systems. A set of sparse linear methods with side information (SSLIM) is proposed, which involve a regularized optimization process to learn a sparse aggregation coefficient matrix based on both user-item purchase profiles and item side information. This aggregation coefficient matrix is used within an item-based recommendation framework to generate recommendations for the users. Our experimental results demonstrate that SSLIM outperforms other methods in effectively utilizing side information and achieving performance \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:ruyezt5ZtCIC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Graph-based Recommendation with Personalized Diffusions,\" Proc. of Intl. Work. on Mining and Learning with Graphs, KDD Conf., Anchorage, Alaska, August 2019.(171141)",
            "Publication year": 2019,
            "Publication url": "https://par.nsf.gov/servlets/purl/10182246",
            "Abstract": "The present work introduces PerDif; a novel framework for learning personalized diffusions over item-to-item graphs for top-n recommendation. PerDif learns the teleportation probabilities of a time-inhomogeneous random walk with restarts capturing a userspecific underlying item exploration process. Such approach can lead to significant improvements in recommendation accuracy, while also providing useful information about the users in the system. Per-user fitting can be performed in parallel and very efficiently even in large-scale settings. A comprehensive set of experiments on real-world datasets demonstrate the scalability as well as the qualitative merits of the proposed framework. PerDif achieves high recommendation accuracy, outperforming state-ofthe-art competing approaches\u2014including several recently proposed methods relying on deep neural networks.",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:GJVTs2krol4C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Solving the sparsity problem: collaborative filtering via indirect similarities",
            "Publication year": 2008,
            "Publication url": "https://conservancy.umn.edu/handle/11299/215787",
            "Abstract": "Collaborative filtering is an important technique of information filtering, commonly used to predict the interest of a user for a new item. In collaborative filtering systems, this prediction is made based on user-item preference data involving similar users or items. When the data is sparse, however, direct similarity measures between users or items provide little information that can be used for the prediction. In this paper, we present a new collaborative filtering approach that computes global similarities between pairs of items and users, as the equilibrium point of a system relating user similarities to item similarities. We show how this approach extends the classical techniques based on direct similarity, and illustrate, by testing on various datasets, its advantages over such techniques.",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:yB1At4FlUx8C",
            "Publisher": "Unknown"
        },
        {
            "Title": "CONTOUR: an efficient algorithm for discovering discriminating subsequences",
            "Publication year": 2009,
            "Publication url": "https://link.springer.com/article/10.1007/s10618-008-0100-7",
            "Abstract": "In recent years we have witnessed several applications of frequent sequence mining, such as feature selection for protein sequence classification and mining block correlations in storage systems. In typical applications such as clustering, it is not the complete set but only a subset of discriminating frequent subsequences which is of interest. One approach to discovering the subset of useful frequent subsequences is to apply any existing frequent sequence mining algorithm to find the complete set of frequent subsequences. Then, a subset of interesting subsequences can be further identified. Unfortunately, it is very time consuming to mine the complete set of frequent subsequences for large sequence databases. In this paper, we propose a new algorithm, CONTOUR, which efficiently mines a subset of high-quality subsequences directly in order to cluster the input sequences. We mainly focus on how to \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:Fu2w8maKXqMC",
            "Publisher": "Springer US"
        },
        {
            "Title": "Sparse tensor factorization on many-core processors with high-bandwidth memory",
            "Publication year": 2017,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/7967196/",
            "Abstract": "HPC systems are increasingly used for data intensive computations which exhibit irregular memory accesses, non-uniform work distributions, large memory footprints, and high memory bandwidth demands. To address these challenging demands, HPC systems are turning to many-core architectures that feature a large number of energy-efficient cores backed by high-bandwidth memory. These features are exemplified in Intel's recent Knights Landing many-core processor (KNL), which typically has 68 cores and 16GB of on-package multi-channel DRAM (MCDRAM). This work investigates how the novel architectural features offered by KNL can be used in the context of decomposing sparse, unstructured tensors using the canonical polyadic decomposition (CPD). The CPD is used extensively to analyze large multi-way datasets arising in various areas including precision healthcare, cybersecurity, and e-commerce \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:BJtnxTr0fRcC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Wavefront diffusion and LMSR: Algorithms for dynamic repartitioning of adaptive meshes",
            "Publication year": 2001,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/926167/",
            "Abstract": "Current multilevel repartitioning schemes tend to perform well on certain types of problems while obtaining worse results for other types of problems. We present two new multilevel algorithms for repartitioning adaptive meshes that improve the performance of multilevel schemes for the types of problems that current schemes perform poorly while maintaining similar or better results for those problems that current schemes perform well. Specifically, we present a new scratch-remap scheme called Locally-matched Multilevel Scratch-remap (or simply LMSR) for repartitioning of adaptive meshes. LMSR tries to compute a high-quality partitioning that has a large amount of overlap with the original partitioning. We show that LMSR generally decreases the data redistribution costs required to balance the load compared to current scratch-remap schemes. We present a new diffusion-based scheme that we refer to as \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:ZHo1McVdvXMC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Analysis of recommendation algorithms for e-commerce",
            "Publication year": 2000,
            "Publication url": "https://dl.acm.org/doi/pdf/10.1145/352871.352887",
            "Abstract": "Recommender systems apply statistical and knowledge discovery techniques to the problem of making product recommendations during a live customer interaction and they are achieving widespread success in E-Commerce nowadays. In this paper, we investigate several techniques for analyzing large-scale purchase and preference data for the purpose of producing useful recommendations to customers. In particular, we apply a collection of algorithms such as traditional data mining, nearest-neighbor collaborative filtering, and dimensionality reduction on two different data sets. The first data set was derived from the web-purchasing transaction of a large E-commerce company whereas the second data set was collected from MovieLens movie recommendation site. For the experimental purpose, we divide the recommendation generation process into three sub processesrepresentation of input data \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:qjMakFHDy7sC",
            "Publisher": "Unknown"
        },
        {
            "Title": "TR O3-O04",
            "Publication year": 2003,
            "Publication url": "https://scholar.google.com/scholar?cluster=7858691801147163055&hl=en&oi=scholarr",
            "Abstract": "Finding prevalent patterns in large amount of data has been one of the major problems in the area of data mining. Particularly, the problem of \ufb01nding frequent itemset or sequential patterns in very large databases has been studied extensively over the years, and a variety of algorithms have been developed for each problem. The key feature in most of these algorithms is that they use a constant support constraint to control the inherently exponential complexity of these two problems. In general, pattems that contain only a few items will tend to be interesting if they have a high support, Whereas long patterns can still be interesting even if their support is relatively small. Ideally, we Want to \ufb01nd all the frequent patterns whose support decreases as a function of their length without having to \ufb01nd many uninteresting infrequent short patterns. Developing such algorithms is particularly challenging because the downward \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:HJSXoJQnj-YC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Scalable Consistency Training for Graph Neural Networks via Self-Ensemble Self-Distillation",
            "Publication year": 2021,
            "Publication url": "https://arxiv.org/abs/2110.06290",
            "Abstract": "Consistency training is a popular method to improve deep learning models in computer vision and natural language processing. Graph neural networks (GNNs) have achieved remarkable performance in a variety of network science learning tasks, but to date no work has studied the effect of consistency training on large-scale graph problems. GNNs scale to large graphs by minibatch training and subsample node neighbors to deal with high degree nodes. We utilize the randomness inherent in the subsampling of neighbors and introduce a novel consistency training method to improve accuracy. For a target node we generate different neighborhood expansions, and distill the knowledge of the average of the predictions to the GNN. Our method approximates the expected prediction of the possible neighborhood samples and practically only requires a few samples. We demonstrate that our training method outperforms standard GNN training in several different settings, and yields the largest gains when label rates are low.",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:fF_gHTpLxhAC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Distdgl: distributed graph neural network training for billion-scale graphs",
            "Publication year": 2020,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/9407264/",
            "Abstract": "Graph neural networks (GNN) have shown great success in learning from graph-structured data. They are widely used in various applications, such as recommendation, fraud detection, and search. In these domains, the graphs are typically large, containing hundreds of millions of nodes and several billions of edges. To tackle this challenge, we develop DistDGL, a system for training GNNs in a mini-batch fashion on a cluster of machines. DistDGL is based on the Deep Graph Library (DGL), a popular GNN development framework. DistDGL distributes the graph and its associated data (initial features and embeddings) across the machines and uses this distribution to derive a computational decomposition by following an owner-compute rule. DistDGL follows a synchronous training approach and allows ego-networks forming the mini-batches to include non-local nodes. To minimize the overheads associated with \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:TiIbgCYny7sC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Graph partitioning for dynamic, adaptive and multi-phase scientific simulations",
            "Publication year": 2002,
            "Publication url": "https://www.worldscientific.com/doi/abs/10.1142/9781860949630_0004",
            "Abstract": "The efficient execution of scientific simulations on HPC systems requires a partitioning of the underlying mesh among the processors such that the load is balanced and the inter-processor communication is minimized. Graph partitioning algorithms have been applied with much success for this purpose. However, the parallelization of multi-phase and multi-physics computations poses new challenges that require fundamental advances in graph partitioning technology. In addition, most existing graph partitioning algorithms are not suited for the newer heterogeneous high-performance computing platforms. This talk will describe research efforts in our group that are focused on developing novel multi-constraint and multi-objective graph partitioning algorithms that can support the advancing state-of-the-art in numerical simulation technologies. In addition, we will present our preliminary work on new partitioning \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:evX43VCCuoAC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Final Report of Enabling Scientific Discovery in Exascale Simulations",
            "Publication year": 2014,
            "Publication url": "https://www.osti.gov/servlets/purl/1154916",
            "Abstract": "The process of scientific discovery often requires scientists to run simulations, analyze the output, draw conclusions, then re-run the simulations to confirm or expand hypothesis. One of the most significant bottlenecks for current and future extreme-scale systems is I/O. In order to facilitate the scientific process described above, it is necessary for scientists to have efficient means to output and store data for offline analysis. To facilitate this, data compression is turned to, to create reduced representations of the resulting data for output, in such a way that the original result data can be reconstructed off-line for further analysis. Straightforward approaches for scientific data compression exist in lossless techniques designed specifically for floating-point data. However, due to the high variability of the representation of floating-point numbers at the hardware level, the compression factors realized by these schemes are often very modest [10, 24]. Since most post-run analysis is robust in the presence of some degree of error, it is possible to employ lossy compression techniques rather than lossless, which are capable of achieving much higher compression rates at the cost of a small amount of reconstruction error. As a result, a number of approaches have been investigated for lossy compression of scientific simulation datasets including classical [20] and diffusion wavelets [8], spectral methods [15], and methods based on the techniques used for transmission of HDTV signals [6]. However, these approaches are either applicable only to simulations performed on structured grids or have computational requirements too high for in situ data compression \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:Ic1VZgkJnDsC",
            "Publisher": "University of Minnesota"
        },
        {
            "Title": "Pl2ap: Fast parallel cosine similarity search",
            "Publication year": 2015,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/2833179.2833182",
            "Abstract": "Solving the AllPairs similarity search problem entails finding all pairs of vectors in a high dimensional sparse dataset that have a similarity value higher than a given threshold. The output form this problem is a crucial component in many real-world applications, such as clustering, online advertising, recommender systems, near-duplicate document detection, and query refinement. A number of serial algorithms have been proposed that solve the problem by pruning many of the possible similarity candidates for each query object, after accessing only a few of their non-zero values. The pruning process results in unpredictable memory access patterns that can reduce search efficiency. In this context, we introduce pL2AP, which efficiently solves the AllPairs cosine similarity search problem in a multi-core environment. Our method uses a number of cache-tiling optimizations, combined with fine-grained dynamically \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:rCNdntzdTkkC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Big data and recommender systems",
            "Publication year": 2016,
            "Publication url": "https://conservancy.umn.edu/handle/11299/215998",
            "Abstract": "Recommender systems are ubiquitous in today's marketplace and have great commercial importance, as evidenced by the large number of companies that sell recommender systems solutions. Successful recommender systems use past product purchase and satisfaction data to make high quality personalized recommendations. The vast amounts of data available to recommender systems today forces a total re-evaluation of the methods used to compute recommendations. In this paper, we provide an overview of recommender systems in the era of Big Data.  We highlight prevailing recommendation algorithms and how they have been adapted to operate in parallel and distributed computing environments.  Within the recommender systems context, we focus our discussion on two specific challenges: how to scale up finding nearest neighbors and how to scale latent factor recommendation methods.",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:mJbmKSuM8toC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Chairs Forward",
            "Publication year": 2005,
            "Publication url": "https://experts.umn.edu/en/publications/chairs-forward",
            "Abstract": "Chairs Forward \u2014 Experts@Minnesota Skip to main navigation Skip to search Skip to main \ncontent Experts@Minnesota Logo Home Profiles Research Units University Assets Projects \nand Grants Research Output Press / Media Datasets Activities Fellowships, Honors, and \nPrizes Search by expertise, name or affiliation Chairs Forward George Karypis, Nikolaos G. \nBourbakis, Jeffrey J. Tsai Computer Science and Engineering Research output: \nContribution to journal \u203a Editorial \u203a peer-review Overview Fingerprint Original language \nEnglish (US) Article number 1544440 Pages (from-to) 9 Number of pages 1 Journal \nProceedings - BIBE 2005: 5th IEEE Symposium on Bioinformatics and Bioengineering \nVolume 2005 DOIs https://doi.org/10.1109/BIBE.State Published - 2005 Event BIBE 2005: \n5th IEEE Symposium on Bioinformatics and Bioengineering - Minneapolis, MN, United \nStates Duration: Oct 19 2005 \u2192 Oct 21 2005 /., \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:SrKkpNFED5gC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Multi-constraint mesh partitioning for contact/impact computations",
            "Publication year": 2003,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/1592959/",
            "Abstract": "We present a novel approach for decomposing contact/impact computations in which the mesh elements come in contact with each other during the course of the simulation. Effective decomposition of these computations poses a number of challenges as it needs to both balance the computations and minimize the amount of communication that is performed during the finite element and the contact search phase. Our approach achieves the first goal by partitioning the underlying mesh such that it simultaneously balances both the work that is performed during the finite element phase and that performed during contact search phase, while producing subdomains whose boundaries consist of piecewise axes-parallel lines or planes. The second goal is achieved by using a decision tree to decompose the space into rectangular or box-shaped regions that contain contact points from a single partition. Our experimental \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:sSrBHYA8nusC",
            "Publisher": "IEEE"
        },
        {
            "Title": "The design and evaluation of a peer ratings system for online learning communities",
            "Publication year": 2010,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/5428759/",
            "Abstract": "In this paper we explore the idea that ratings systems, common across successful e-commerce sites, can better engage individuals in online learning networks. To test this we implement a ratings system as a mechanism for influencing social interaction in our university's online learning community (OLC). Our research measures the impact this system had on five graduate courses over the course of two semesters. Our research also provides insight into how user-driven content can provide input into other systems, such as a recommender system to aid in fostering new online social connections.",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:1yWc8FF-_SYC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Acyclic subgraph based descriptor spaces for chemical compound retrieval and classification",
            "Publication year": 2006,
            "Publication url": "https://apps.dtic.mil/sti/citations/ADA444816",
            "Abstract": "In recent years the development of computational techniques that build models to correctly assign chemical compounds to various classes or to retrieve potential drug-like compounds has been an active area of research. These techniques are used extensively at various phases during the drug development process. Many of the best-performing techniques for these tasks utilize a descriptor-based representation of the compound that captures various aspects of the underlying molecular graphs topology. In this paper we introduce and describe algorithms for efficiently generating a new set of descriptors that are derived from all connected acrylic fragments present in the molecular graphs. In addition, we introduce an extension to existing vector-based kernel functions to take into account the length of the fragments present in the descriptors. We experimentally evaluate the performance of the new descriptors in the context of SVM-based classification and ranked-retrieval on 28 classification and retrieval problems derived from 17 datasets. Our experiments show that for both the classification and retrieval tasks, these new descriptors consistently and statistically outperform previously developed schemes based on the widely used fingerprint-and Maccs keys-based descriptors, as well as recently introduced descriptors obtained by mining and analyzing the structure of the molecular graphs.Descriptors:",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:SdhP9T11ey4C",
            "Publisher": "MINNESOTA UNIV MINNEAPOLIS DEPT OF COMPUTER SCIENCE"
        },
        {
            "Title": "Power source roadmaps using bibliometrics and database tomography",
            "Publication year": 2005,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S0360544204002531",
            "Abstract": "Database Tomography (DT) is a textual database analysis system consisting of two major components: (1) algorithms for extracting multi-word phrase frequencies and phrase proximities (physical closeness of the multi-word technical phrases) from any type of large textual database, to augment (2) interpretative capabilities of the expert human analyst. DT was used to derive technical intelligence from a Power Sources database derived from the Science Citation Index. Phrase frequency analysis by the technical domain experts provided the pervasive technical themes of the Power Sources database, and the phrase proximity analysis provided the relationships among the pervasive technical themes. Bibliometric analysis of the Power Sources literature supplemented the DT results with author/journal/institution/country publication and citation data.",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:2P1L_qKh6hAC",
            "Publisher": "Pergamon"
        },
        {
            "Title": "PROSAT: Protein Sequence Annotation Toolkit-Software Manual",
            "Publication year": 2007,
            "Publication url": "https://conservancy.umn.edu/handle/11299/215743",
            "Abstract": "We provide a generalized protein sequence annotation toolkit (prosat) for solving classification or regression problems using support vector machines. The key characteristic of our method is its effective use of window-based information to capture the local environment of a protein sequence residue. This window information is used with several kernel functions available within our framework. We show the effectiveness of using the previously developed normalized second order exponential kernel function and experiment with local window-based information at different levels of granularity. This is the manual for this developed software.",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:XeErXHja3Z8C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Partitioning algorithms for simultaneously balancing iterative and direct methods",
            "Publication year": 2004,
            "Publication url": "https://conservancy.umn.edu/handle/11299/215608",
            "Abstract": "This paper focuses on domain decomposition-based numerical simulations whose sub-problems corresponding to the various subdomains are solved using sparse direct factorization methods (eg., FETI). Effective load-balancing of such computations requires that the resulting partitioning simultaneously balances the amount of time required to factor the local subproblem using direct factorization, and the number of elements assigned to each processor. Unfortunately, existing graph-partitioning algorithms cannot be used to load-balance these type of computations as they can only compute partitionings that simultaneously balance numerous constraints defined a~priori on the vertices and optimize different objectives defined locally on the edges. To address this problem, we developed an algorithm that follows a {em predictor-corrector} approach that first computes a high-quality partitioning of the underlying graph, and then modifies it to achieve the desired balancing constraints.  During the corrector step we compute a fill reducing ordering for each partition, and then we modify the initial partitioning and ordering so that our objectives are satisfied. Experimental results show that the proposed algorithm is able to reduce the fill-in of the overweight sub-domains and achieve a considerably better balance.",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:RVqaWcrwK10C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Will this course increase or decrease your gpa? towards grade-aware course recommendation",
            "Publication year": 2019,
            "Publication url": "https://arxiv.org/abs/1904.11798",
            "Abstract": "In order to help undergraduate students towards successfully completing their degrees, developing tools that can assist students during the course selection process is a significant task in the education domain. The optimal set of courses for each student should include courses that help him/her graduate in a timely fashion and for which he/she is well-prepared for so as to get a good grade in. To this end, we propose two different grade-aware course recommendation approaches to recommend to each student his/her optimal set of courses. The first approach ranks the courses by using an objective function that differentiates between courses that are expected to increase or decrease a student's GPA. The second approach combines the grades predicted by grade prediction methods with the rankings produced by course recommendation methods to improve the final course rankings. To obtain the course rankings in the first approach, we adapt two widely-used representation learning techniques to learn the optimal temporal ordering between courses. Our experiments on a large dataset obtained from the University of Minnesota that includes students from 23 different majors show that the grade-aware course recommendation methods can do better on recommending more courses in which the students are expected to perform well and recommending fewer courses in which they are expected not to perform well in than grade-unaware course recommendation methods.",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:3BvdIg-l-ZAC",
            "Publisher": "Unknown"
        },
        {
            "Title": "KDD 2019 program chairs' welcome",
            "Publication year": 2019,
            "Publication url": "https://experts.umn.edu/en/publications/kdd-2019-program-chairs-welcome",
            "Abstract": "KDD 2019 program chairs' welcome \u2014 Experts@Minnesota Skip to main navigation Skip to \nsearch Skip to main content Experts@Minnesota Logo Home Profiles Research Units \nUniversity Assets Projects and Grants Research Output Press / Media Datasets Activities \nFellowships, Honors, and Prizes Search by expertise, name or affiliation KDD 2019 \nprogram chairs' welcome Ying Li, Romer Rosales, Evimaria Terzi, George Karypis \nResearch output: Contribution to journal \u203a Editorial \u203a peer-review Overview Fingerprint \nOriginal language English (US) Pages (from-to) V-VI Journal Proceedings of the ACM \nSIGKDD International Conference on Knowledge Discovery and Data Mining State \nPublished - Jul 25 2019 Externally published Yes Event 25th ACM SIGKDD International \nConference on Knowledge Discovery and Data Mining, KDD 2019 - Anchorage, United \nStates Duration: Aug 4 2019 \u2192 Aug 8 2019 Access Link to , \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:wkm4DBaukwsC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Multivariate analysis of cell culture bioprocess data\u2013Lactate consumption as process indicator",
            "Publication year": 2012,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S0168165612006232",
            "Abstract": "Multivariate analysis of cell culture bioprocess data has the potential of unveiling hidden process characteristics and providing new insights into factors affecting process performance. This study investigated the time-series data of 134 process parameters acquired throughout the inoculum train and the production bioreactors of 243 runs at the Genentech's Vacaville manufacturing facility. Two multivariate methods, kernel-based support vector regression (SVR) and partial least square regression (PLSR), were used to predict the final antibody concentration and the final lactate concentration. Both product titer and the final lactate level were shown to be predicted accurately when data from the early stages of the production scale were employed. Using only process data from the inoculum train, the prediction accuracy of the final process outcome was lower; the results nevertheless suggested that the history of the \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:jU7OWUQzBzMC",
            "Publisher": "Elsevier"
        },
        {
            "Title": "Scientific data analysis",
            "Publication year": 2009,
            "Publication url": "https://experts.umn.edu/en/publications/scientific-data-analysis",
            "Abstract": "The analysis of data is a key part of any scientific endeavor, as it leads to a better understanding of the world around us. With scientific data now being measured in terabytes and petabytes, this analysis is becoming quite challenging. In addition, the complexity of the data is increasing as well due to several factors such as improved sensor technologies and increased computing power. This complexity can take various forms such as multisensor, multispectral, multiresolution data, spatio-temporal data, high-dimensional data, structured and unstructured mesh data from simulations, data contaminated with different types of noise, three-dimensional data, and so on.",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:Ej9njvOgR2oC",
            "Publisher": "CRC Press"
        },
        {
            "Title": "A statistical model for topically segmented documents",
            "Publication year": 2011,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-642-24477-3_21",
            "Abstract": "Generative models for text data are based on the idea that a document can be modeled as a mixture of topics, each of which is represented as a probability distribution over the terms. Such models have traditionally assumed that a document is an indivisible unit for the generative process, which may not be appropriate to handle documents with an explicit multi-topic structure. This paper presents a generative model that exploits a given decomposition of documents in smaller text blocks which are topically cohesive (segments). A new variable is introduced to model the within-document segments: using this variable at document-level, word generation is related not only to the topics but also to the segments, while the topic latent variable is directly associated to the segments, rather than to the document as a whole. Experimental results have shown that, compared to existing generative models, our proposed \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:HtEfBTGE9r8C",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "Multilevel algorithms for generating coarse grids for multigrid methods",
            "Publication year": 2001,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/582034.582079",
            "Abstract": "Geometric Multigrid methods have gained widespread acceptance for solving large systems of linear equations, especially for structured grids. One of the challenges in successfully extending these methods to unstructured grids is the problem of generating an appropriate set of coarse grids. The focus of this paper is the development of robust algorithms, both serial and parallel, for generating a sequence of coarse grids from the original unstructured grid. Our algorithms treat the problem of coarse grid construction as an optimization problem that tries to optimize the overall quality of the resulting fused elements. We solve this problem using the multilevel paradigm that has been very successful in solving the related grid/graph partitioning problem. The parallel formulation of our algorithm incurs a very small communication overhead, achieves high degree of concurrency, and maintains the high quality of the coarse \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:vRqMK49ujn8C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Parallel processing with cooperative multitasking",
            "Publication year": 2017,
            "Publication url": "https://patents.google.com/patent/US9678497B2/en",
            "Abstract": "Multiple parallel slave processes and a master process are assigned to a node executing an operating system such that the operating system maintains a ready queue comprising a list of one or more processes that are ready to be executed by at least one processing core. A parallel slave process takes an action that causes the operating system to keep the parallel slave process out of the ready queue. Based on receiving an indication that the parallel slave process is to be kept out of the ready queue, the master process sets the parallel slave process to a blocking state, selects a second parallel slave process that is in a runnable state but is currently kept from being in the ready queue, and takes an action that causes the operating system to add the parallel slave process that is in the runnable state to the ready queue.",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:pYKElYtJMmwC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Improving homology models for protein-ligand binding sites",
            "Publication year": 2008,
            "Publication url": "https://www.worldscientific.com/doi/abs/10.1142/9781848162648_0019",
            "Abstract": "In order to improve the prediction of protein-ligand binding sites through homology modeling, we incorporate knowledge of the binding residues into the modeling framework. Residues are identified as binding or nonbinding based on their true labels as well as labels predicted from structure and sequence. The sequence predictions were made using a support vector machine framework which employs a sophisticated window-based kernel. Binding labels are used with a very sensitive sequence alignment method to align the target and template. Relevant parameters governing the alignment process are searched for optimal values. Based on our results, homology models of the binding site can be improved if a priori knowledge of the binding residues is available. For target-template pairs with low sequence identity and high structural diversity our sequence-based prediction method provided sufficient information \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:HE397vMXCloC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Few-shot link prediction via graph neural networks for covid-19 drug-repurposing",
            "Publication year": 2020,
            "Publication url": "https://arxiv.org/abs/2007.10261",
            "Abstract": "Predicting interactions among heterogenous graph structured data has numerous applications such as knowledge graph completion, recommendation systems and drug discovery. Often times, the links to be predicted belong to rare types such as the case in repurposing drugs for novel diseases. This motivates the task of few-shot link prediction. Typically, GCNs are ill-equipped in learning such rare link types since the relation embedding is not learned in an inductive fashion. This paper proposes an inductive RGCN for learning informative relation embeddings even in the few-shot learning regime. The proposed inductive model significantly outperforms the RGCN and state-of-the-art KGE models in few-shot learning tasks. Furthermore, we apply our method on the drug-repurposing knowledge graph (DRKG) for discovering drugs for Covid-19. We pose the drug discovery task as link prediction and learn embeddings for the biological entities that partake in the DRKG. Our initial results corroborate that several drugs used in clinical trials were identified as possible drug candidates. The method in this paper are implemented using the efficient deep graph learning (DGL)",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:4E1Y8I9HL1wC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Evaluation of hierarchical clustering algorithms for document datasets",
            "Publication year": 2002,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/584792.584877",
            "Abstract": "Fast and high-quality document clustering algorithms play an important role in providing intuitive navigation and browsing mechanisms by organizing large amounts of information into a small number of meaningful clusters. In particular, hierarchical clustering solutions provide a view of the data at different levels of granularity, making them ideal for people to visualize and interactively explore large document collections. In this paper we evaluate different partitional and agglomerative approaches for hierarchical clustering. Our experimental evaluation showed that partitional algorithms always lead to better clustering solutions than agglomerative algorithms, which suggests that partitional clustering algorithms are well-suited for clustering large document datasets due to not only their relatively low computational requirements, but also comparable or even better clustering performance. We present a new class of \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:EPG8bYD4jVwC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Application of dimensionality reduction in recommender system-a case study",
            "Publication year": 2000,
            "Publication url": "https://apps.dtic.mil/sti/citations/ADA439541",
            "Abstract": "We investigate the use of dimensionality reduction to improve performance for a new class of data analysis software called recommender systems Recommender systems apply knowledge discovery techniques to the problem of making product recommendations during a live customer interaction. These systems are achieving widespread success in E-commerce nowadays, especially with the advent of the Internet. The tremendous growth of customers and products poses three key challenges for recommender systems in the E-commerce domain. These are producing high quality recommendations, performing many recommendations per second for millions of customers and products, and achieving high coverage in the face of data sparsity. One successful recommender system technology is collaborative filtering, which works by matching customer preferences to other customers in making recommendations. Collaborative filtering has been shown to produce high quality recommendations, but the performance degrades with the number of customers and products. New recommender system technologies are needed that can quickly produce high quality recommendations, even for very largescale problems. This paper presents two different experiments where we have explored one technology called Singular Value Decomposition SVD to reduce the dimensionality of recommender system databases. Each experiment compares the quality of a recommender system using SVD with the quality of a recommender system using collaborative filtering. The first experiment compares the effectiveness of the two recommender systems at predicting \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:Y0pCki6q_DkC",
            "Publisher": "Minnesota Univ Minneapolis Dept of Computer Science"
        },
        {
            "Title": "Welcome from DSAA 2014 chairs",
            "Publication year": 2014,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/7058034/",
            "Abstract": "Data driven scientific discovery approach has already been agreed to be an important emerging paradigm for computing in areas including social, service, Internet of Things (or sensor networks), and cloud. Under this paradigm, Big Data is the core that drives new researches in many areas, from environmental to social. There are many new scientific challenges when facing this big data phenomenon, ranging from capture, creation, storage, search, sharing, analysis, and visualization. The complication here is not just the storage, I/O, query, and performance, but also the integration across heterogeneous, interdependent complex data resources for real-time decision-making, collaboration, and ultimately value co-creation. Data sciences encompass the larger areas of data analytics, machine learning and managing big data. Advanced data analytics has become essential to glean a deep understanding of large data \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:lg2tdxc6qMwC",
            "Publisher": "IEEE"
        },
        {
            "Title": "CLUTO--A Clusteruing Toolkit--Release 2.0",
            "Publication year": 2002,
            "Publication url": "http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.402.4745",
            "Abstract": "CiteSeerX \u2014 CLUTO -- A Clusteruing Toolkit -- Release 2.0 Documents Authors Tables Log \nin Sign up MetaCart DMCA Donate CiteSeerX logo Documents: Advanced Search Include \nCitations Authors: Advanced Search Include Citations Tables: DMCA CLUTO -- A \nClusteruing Toolkit -- Release 2.0 (2002) Cached Download as a PDF Download Links [www.cs.umn.edu] \nSave to List Add to Collection Correct Errors Monitor Changes by George Karypis Summary \nCitations Active Bibliography Co-citation Clustered Documents Version History Share \nFacebook Twitter Reddit Bibsonomy OpenURL Abstract Powered by: Apache Solr About \nCiteSeerX Submit and Index Documents Privacy Policy Help Data Source Contact Us \nDeveloped at and hosted by The College of Information Sciences and Technology \u00a9 2007-2019 \nThe Pennsylvania State University \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:Cvh0bltMcLgC",
            "Publisher": "Unknown"
        },
        {
            "Title": "wCLUTO: A Web-Enabled Clustering Toolkit",
            "Publication year": 2003,
            "Publication url": "https://academic.oup.com/plphys/article-abstract/133/2/510/6111153",
            "Abstract": "As structural and functional genomics efforts provide the biological community with ever-broadening sets of interrelated data, the need to explore such complex information for subtle relationships expands. We present wCLUTO, a Web-enabled version of the stand-alone application CLUTO, designed to apply clustering methods to genomic information. Its first application is focused on the clustering transcriptome data from microarrays. Data can be uploaded by the user into the clustering tool, a choice of several clustering methods can be made and configured, and data are presented to the user in a variety of visual formats, including a three-dimensional \u201cmountain\u201d view of the clusters. Parameters can be explored to rapidly examine a variety of clustering results, and the resulting clusters can be downloaded either for manipulation by other programs or to be saved in a format for publication.",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:l7t_Zn2s7bgC",
            "Publisher": "American Society of Plant Biologists"
        },
        {
            "Title": "MGTS 2005: Proceedings of the 3rd International Workshop on Mining Graphs, Trees and Sequences",
            "Publication year": 2005,
            "Publication url": "https://dial.uclouvain.be/pr/boreal/object/boreal:186580",
            "Abstract": "MGTS 2005: Proceedings of the 3rd International Workshop on Mining Graphs, Trees and \nSequences | DIAL.pr - BOREAL Skip to main content User menu Cart Login Home DIAL.pr - \nBOREAL Search form Search Home All Publications Export Help You are here Home\u00bb MGTS \n2005: Proceedings of the 3rd International Workshop on Mining Graphs, Trees and Sequences \nS'identifier sur le proxy UCLouvain : https://proxy.bib.ucl.ac.be/proxy-dial S'identifier sur le proxy \nSaint-Louis : https://usaintlouis.idm.oclc.org/login?url=https://dial.uclouvain.be MGTS 2005: \nProceedings of the 3rd International Workshop on Mining Graphs, Trees and Sequences Primary \ntabs Voir(active tab) Fichiers attach\u00e9s Validit\u00e9 FNRS Meinl, Thorsten [Universit\u00e4t Konstanz] \nNijssen, Siegfried [UCL] Karypis, George [University of Minnesota] metadata Document \ntype Monographie (Book) \u2013 Actes de colloque Publication date 2005 Language Anglais ((\u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:hHIA4WEVY-EC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Topic-driven clustering for document datasets",
            "Publication year": 2005,
            "Publication url": "https://epubs.siam.org/doi/abs/10.1137/1.9781611972757.32",
            "Abstract": "In this paper, we define the problem of topic-driven clustering, which organizes a document collection according to a given set of topics. We propose three topic-driven schemes that consider the similarity between documents and topics and the relationship among documents themselves simultaneously. We present a comprehensive experimental evaluation of the proposed topic-driven schemes on five datasets. Our experimental results show that the proposed topic-driven schemes are efficient and effective with topic prototypes of different levels of specificity.",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:bFI3QPDXJZMC",
            "Publisher": "Society for Industrial and Applied Mathematics"
        },
        {
            "Title": "Distiller: A Systematic Study of Model Distillation Methods in Natural Language Processing",
            "Publication year": 2021,
            "Publication url": "https://arxiv.org/abs/2109.11105",
            "Abstract": "We aim to identify how different components in the KD pipeline affect the resulting performance and how much the optimal KD pipeline varies across different datasets/tasks, such as the data augmentation policy, the loss function, and the intermediate representation for transferring the knowledge between teacher and student. To tease apart their effects, we propose Distiller, a meta KD framework that systematically combines a broad range of techniques across different stages of the KD pipeline, which enables us to quantify each component's contribution. Within Distiller, we unify commonly used objectives for distillation of intermediate representations under a universal mutual information (MI) objective and propose a class of MI- objective functions with better bias/variance trade-off for estimating the MI between the teacher and the student. On a diverse set of NLP datasets, the best Distiller configurations are identified via large-scale hyperparameter optimization. Our experiments reveal the following: 1) the approach used to distill the intermediate representations is the most important factor in KD performance, 2) among different objectives for intermediate distillation, MI- performs the best, and 3) data augmentation provides a large boost for small training datasets or small student networks. Moreover, we find that different datasets/tasks prefer different KD algorithms, and thus propose a simple AutoDistiller algorithm that can recommend a good KD pipeline for a new dataset.",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:dMpQl7XwOw4C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Augmenting Chinese hamster genome assembly by identifying regions of high confidence",
            "Publication year": 2016,
            "Publication url": "https://onlinelibrary.wiley.com/doi/abs/10.1002/biot.201500455",
            "Abstract": "Chinese hamster Ovary (CHO) cell lines are the dominant industrial workhorses for therapeutic recombinant protein production. The availability of genome sequence of Chinese hamster and CHO cells will spur further genome and RNA sequencing of producing cell lines. However, the mammalian genomes assembled using shot\u2010gun sequencing data still contain regions of uncertain quality due to assembly errors. Identifying high confidence regions in the assembled genome will facilitate its use for cell engineering and genome engineering. We assembled two independent drafts of Chinese hamster genome by de novo assembly from shotgun sequencing reads and by re\u2010scaffolding and gap\u2010filling the draft genome from NCBI for improved scaffold lengths and gap fractions. We then used the two independent assemblies to identify high confidence regions using two different approaches. First, the two independent \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:TesyEGJKHF4C",
            "Publisher": "WILEY\u2010VCH Verlag"
        },
        {
            "Title": "Finding functionally related genes by local and global analysis of MEDLINE abstracts",
            "Publication year": 2004,
            "Publication url": "https://apps.dtic.mil/sti/citations/ADA439461",
            "Abstract": "Discovery of biological relationships between genes is one of the keys to understanding the complex functional nature of the human genome. Currently, most of the knowledge about interrelating genes are found in immense amounts of various biomedical literature. Hence, extraction of biological contexts occurring in free text represents a valuable tool in gaining knowledge about gene interactions. We present a textual analysis of documents associated with pairs of genes, and describe how this approach can be used to discover and annotate functional relationships among genes. A study on a subset of human genes show that our analysis tool can act as a ranking mechanism for sets of genes based on their functional relatedness.Descriptors:",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:fEOibwPWpKIC",
            "Publisher": "MINNESOTA UNIV MINNEAPOLIS DEPT OF COMPUTER SCIENCE"
        },
        {
            "Title": "Personalized diffusions for top-n recommendation",
            "Publication year": 2019,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/3298689.3346985",
            "Abstract": "This paper introduces PerDif; a novel framework for learning personalized diffusions over item-to-item graphs for top-n recommendation. PerDif learns the teleportation probabilities of a time-inhomogeneous random walk with restarts capturing a user-specific underlying item exploration process. Such an approach can lead to significant improvements in recommendation accuracy, while also providing useful information about the users in the system. Per-user fitting can be performed in parallel and very efficiently even in large-scale settings. A comprehensive set of experiments on real-world datasets demonstrate the scalability as well as the qualitative merits of the proposed framework. PerDif achieves high recommendation accuracy, outperforming state-of-the-art competing approaches---including several recently proposed methods relying on deep neural networks.",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:NZNkWSpQBv0C",
            "Publisher": "Unknown"
        },
        {
            "Title": "CINF 72-Methods for effective virtual screening and scaffold-hopping in chemical compounds",
            "Publication year": 2007,
            "Publication url": "https://scholar.google.com/scholar?cluster=4311686206904448598&hl=en&oi=scholarr",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:8Xgff_V0N9gC",
            "Publisher": "AMER CHEMICAL SOC"
        },
        {
            "Title": "Finding topological frequent patterns from graph datasets",
            "Publication year": 2006,
            "Publication url": "https://books.google.com/books?hl=en&lr=&id=bHGy0_H0g8QC&oi=fnd&pg=PA117&dq=info:1jFbpNjShQ8J:scholar.google.com&ots=FuTdUPf_hV&sig=FDpePcLog6qGhhJNyy6MIYd4NGw",
            "Abstract": "Efficient algorithms for finding frequent patterns\u2014both sequential and nonsequential\u2014in very large datasets have been one of the key success stories of data mining research [1, 2, 26, 54, 60, 69]. Nevertheless, as data mining techniques have been increasingly applied to nontraditional domains, there is a need to develop efficient and general-purpose frequent pattern discovery algorithms that are capable of capturing the spatial, topological, geometric, and/or relational nature of the datasets that characterize these domains. In many application domains, there exist datasets that possess inherently structural or relational characteristics, which are suitable for graph-based representations, and can greatly benefit from graph-based data mining algorithms [eg, network topology, very large scale integration (VLSI) circuit design, protein\u2013protein interactions, biological pathways, Web graph, etc.]. The power of graphs to model complex datasets has been recognized by various researchers [4, 9, 13, 18, 24, 31, 38, 46, 55, 62, 66] as it allows us to represent arbitrary relations among entities and solve problems that we could not previously solve. One way of formulating the frequent pattern discovery problem for graph datasets is that of discovering subgraphs occurring frequently in the given input graph dataset. For instance, consider the problem of mining chemical compounds",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:L7CI7m0gUJcC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Document clustering: the next frontier",
            "Publication year": 2018,
            "Publication url": "https://www.taylorfrancis.com/chapters/edit/10.1201/9781315373515-13/document-clustering-next-frontier-david-anastasiu-andrea-tagarelli-george-karypis",
            "Abstract": "This chapter provides an overview of general purpose document clustering and focuses on advancements in the next frontier in document clustering: long and short documents. The proliferation of documents, on both the Web and in private systems, makes knowledge discovery in document collections arduous. Clustering has been long recognized as a useful tool for the task. While most document clustering research to date has focused on moderate length single topic documents, real-life collections are often made up of very short or long documents. The clustering algorithm and the measure used to compute similarity between documents is highly dependent on the chosen document model. Some document models have been proposed to overcome vector space model limitations. Some models build corpus representations that allow computing semantic similarity between documents. The Generalized Vector \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:yKzB5RS27GgC",
            "Publisher": "Chapman and Hall/CRC"
        },
        {
            "Title": "Algorithms for mining the evolution of conserved relational states in dynamic networks",
            "Publication year": 2012,
            "Publication url": "https://link.springer.com/article/10.1007/s10115-012-0537-2",
            "Abstract": "Dynamic networks have recently being recognized as a powerful abstraction to model and represent the temporal changes and dynamic aspects of the data underlying many complex systems. Significant insights regarding the stable relational patterns among the entities can be gained by analyzing temporal evolution of the complex entity relations. This can help identify the transitions from one conserved state to the next and may provide evidence to the existence of external factors that are responsible for changing the stable relational patterns in these networks. This paper presents a new data mining method that analyzes the time-persistent relations or states between the entities of the dynamic networks and captures all maximal non-redundant evolution paths of the stable relational states. Experimental results based on multiple datasets from real-world applications show that the method is efficient and \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:vbGhcppDl1QC",
            "Publisher": "Springer-Verlag"
        },
        {
            "Title": "Recsys 11 Proceedings of the Fifth Acm Conference on Recommender Systems",
            "Publication year": 2011,
            "Publication url": "https://scholar.google.com/scholar?cluster=2302893108071968027&hl=en&oi=scholarr",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:e9bUPLv0EjcC",
            "Publisher": "Association for Computing Machinery"
        },
        {
            "Title": "A Scalable Algorithm for Clustering Protein Sequences \u0403",
            "Publication year": 2001,
            "Publication url": "https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.24.1152&rep=rep1&type=pdf",
            "Abstract": "\u042c \u0432\u0433\u0436\u0431\u0433\u0439\u0437 \u0436\u0433\u043b\u0438 \u0433 \u0434\u0439 \u0430 \u0437 \u0435\u0439 \u0432 \u0438 \u0437 \u0437 \u0432 \u0433\u0432\u0419 \u0438 \u0432\u0439 \u0432 \u0438 \u0433\u0432 \u0433 \u0439\u0430\u0430\u043d \u0437 \u0435\u0439 \u0432 \u0432\u0433\u0431 \u0437 \u0437 \u0436 \u0438 \u0431 \u0432\u043d \u0430\u0430 \u0432 \u0437 \u0432 \u043a \u0430\u0433\u0434 \u0432 \u0432\u0433\u043a \u0430 \u0432 \u0437 \u0430 \u0430 \u0433\u0431\u0434\u0439\u0438 \u0438 \u0433\u0432 \u0430 \u0438 \u0432 \u0435\u0439 \u0437 \u0433\u0436 \u0437 \u0436 \u0432 \u0418 \u0433\u0431\u0434 \u0436 \u0432 \u0418 \u0432 \u0432 \u0430\u043d\u043e \u0432 \u0438 \u0437 \u0438 \u0437 \u0437\u041a \u0427\u043a \u0436 \u0438 \u043d \u0436\u0437\u0418 \u0431 \u0432\u043d \u0431 \u0438 \u0433 \u0437 \u043a \u0432 \u0419 \u043a \u0430\u0433\u0434 \u0433\u0436 \u0430\u0439\u0437\u0438 \u0436 \u0432 \u0434\u0436\u0433\u0438 \u0432\u0437 \u0433\u0436 \u0432 \u0438\u0433 \u0438 \u0436 \u0437 \u0435\u0439 \u0432 \u0437 \u0431 \u0430 \u0436 \u0438\u043d\u041a \u0420\u0433\u043b \u043a \u0436\u0418 \u0431\u0433\u0437\u0438 \u0433 \u0438 \u0437 \u0431 \u0438 \u0433 \u0437 \u0438 \u0432 \u0438\u0433 \u043a \u0433\u0431\u0434\u0439\u0438 \u0438 \u0433\u0432 \u0430 \u0433\u0431\u0434\u0430 \u043c \u0438\u043d \u0438 \u0438 \u0437 \u0438 \u0430 \u0437\u0438 \u0435\u0439 \u0436 \u0438 \u0433\u0432 \u0438 \u0432\u0439\u0431 \u0436 \u0433 \u0437 \u0435\u0439 \u0432 \u0437\u041a \u0421\u0432 \u0438 \u0437 \u0434 \u0434 \u0436 \u043b \u0434\u0436 \u0437 \u0432\u0438 \u0432 \u0432\u0438 \u0436 \u0430\u043d \u040b \u0436 \u0432\u0438 \u0434\u0434\u0436\u0433 \u0438\u0433 \u0434\u0436\u0433\u0438 \u0432 \u0430\u0439\u0437\u0438 \u0436 \u0432 \u0438 \u0438 \u0433 \u0437 \u0432\u0433\u0438 \u0436 \u0435\u0439 \u0436 \u0432 \u0430\u0430\u0419 \u0432\u0437\u0438\u0419 \u0430\u0430 \u0432 \u0430\u043d\u0437 \u0437 \u0432 \u0439\u0437 \u0437 \u0432 \u0436\u0419\u0430 \u0432 \u0436 \u0433\u0431\u0434\u0430 \u043c\u0419 \u0438\u043d \u0423\u0419\u0431 \u0432\u0437 \u0437 \u0430\u0439\u0437\u0438 \u0436 \u0432 \u0430 \u0433\u0436 \u0438 \u0431\u041a \u0427\u0439\u0436 \u043c\u0434 \u0436 \u0431 \u0432\u0419 \u0438 \u0430 \u043a \u0430\u0439 \u0438 \u0433\u0432 \u0433\u0432 \u0438 \u0436 \u040b \u0436 \u0432\u0438 \u0438 \u0437 \u0438\u0437 \u0433\u0432\u0438 \u0432 \u0432 \u0439\u0434 \u0438\u0433 \u041f\u0418 \u0434\u0436\u0433\u0438 \u0432 \u0437 \u0435\u0439 \u0432 \u0437\u0418 \u0437 \u0433\u043b \u0438 \u0438 \u0438 \u0437 \u0434\u0434\u0436\u0433 \u0430 \u0437 \u0438\u0433 \u0436 \u0437\u0433\u0432 \u0430\u043d \u0433\u0433 \u0430\u0439\u0437\u0438 \u0436\u0437\u041a",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:f2IySw72cVMC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Ligand-binding residue prediction",
            "Publication year": 2010,
            "Publication url": "https://books.google.com/books?hl=en&lr=&id=LeRhAoz4NwEC&oi=fnd&pg=PA343&dq=info:f_aUlkPu46sJ:scholar.google.com&ots=yC3i_z4LMX&sig=-4heAWoS_RA0hea60jHm4r6A3wk",
            "Abstract": "In this chapter, we explore means for predicting protein residues that interact with small molecules. We will motivate the problem by describing potential uses for such information and proceed to discuss methods advanced for prediction. We describe our sequence-based approach and contrast it with another current method that relies on predicted protein structure to help identify ligand-binding residues. In the last part of the chapter, we employ sequencebased predictions in a homology modeling task that shows that the predictions are presently accurate enough to improve downstream performance.",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:F1b5ZUV5XREC",
            "Publisher": "John Wiley & Sons, Inc."
        },
        {
            "Title": "DMS: Distributed sparse tensor factorization with alternating least squares",
            "Publication year": 2015,
            "Publication url": "https://conservancy.umn.edu/handle/11299/215972",
            "Abstract": "Tensors are data structures indexed along three or more dimensions. Tensors have found increasing use in domains such as data mining and recommender systems where dimensions can have enormous length and are resultingly very sparse. The canonical polyadic decomposition (CPD) is the most popular tensor factorization for discovering latent features and is most commonly found via the method of alternating least squares (CPD-ALS). Factoring large, sparse tensors is a computationally challenging task which can no longer be done in the memory of a typical workstation. State of the art methods for distributed memory systems have focused on decomposing the tensor in a one-dimensional (1D) fashion that prohibitively requires the dense matrix factors to be fully replicated on each node. To that effect, we present DMS, a novel distributed CPD-ALS algorithm. DMS utilizes a 3D decomposition that avoids complete factor replication and communication. DMS has a hybrid MPI+OpenMP implementation that utilizes multi-core architectures with a low memory footprint. We theoretically evaluate DMS against leading CPD-ALS methods and experimentally compare them across a variety of datasets. Our 3D decomposition reduces communication volume by 74% on average and is over 35x faster than state of the art MPI code on a tensor with 1.7 billion nonzeros.",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:_tF6a-HnqWAC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Improved estimation of structure predictor quality",
            "Publication year": 2009,
            "Publication url": "https://bmcstructbiol.biomedcentral.com/articles/10.1186/1472-6807-9-41",
            "Abstract": "Methods that can automatically assess the quality of computationally predicted protein structures are important, as they enable the selection of the most accurate structure from an ensemble of predictions. Assessment methods that determine the quality of a predicted structure by comparing it against the various structures predicted by different servers have been shown to outperform approaches that rely on the intrinsic characteristics of the structure itself. We examined techniques to estimate the quality of a predicted protein structure based on prediction consensus. LGA is used to align the structure in question to the structures for the same protein predicted by different servers. We examine both static (e.g. averaging) and dynamic (e.g. support vector machine) methods for aggregating these distances on two datasets. We find that a constrained regression approach shows consistently good performance. Although it is not always the absolute best performing scheme, it is always performs on par with the best schemes across multiple datasets. The work presented here provides the basis for the construction of a regression model trained on data from existing structure prediction servers.",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:BUYA1_V_uYcC",
            "Publisher": "BioMed Central"
        },
        {
            "Title": "Recommender systems for large-scale e-commerce: Scalable neighborhood formation using clustering",
            "Publication year": 2002,
            "Publication url": "http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.4.6985&rep=rep1&type=pdf",
            "Abstract": "Recommender systems apply knowledge discovery techniques to the problem of making personalized product recommendations during a live customer interaction. These systems, especially the k-nearest neighbor collaborative filtering based ones, are achieving widespread success in E-commerce nowadays. The tremendous growth of customers and products in recent years poses some key challenges for recommender systems. These are: producing high quality recommendations and performing many recommendations per second for millions of customers and products. New recommender system technologies are needed that can quickly produce high quality recommendations, even for very large-scale problems. We address the performance issues by scaling up the neighborhood formation process through the use of clustering techniques.",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:QIV2ME_5wuYC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Constrained tensor factorization with accelerated AO-ADMM",
            "Publication year": 2017,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/8025285/",
            "Abstract": "Low-rank sparse tensor factorization is a popular tool for analyzing multi-way data and is used in domains such as recommender systems, precision healthcare, and cybersecurity. Imposing constraints on a factorization, such as non-negativity or sparsity, is a natural way of encoding prior knowledge of the multi-way data. While constrained factorizations are useful for practitioners, they can greatly increase factorization time due to slower convergence and computational overheads. Recently, a hybrid of alternating optimization and alternating direction method of multipliers (AO-ADMM) was shown to have both a high convergence rate and the ability to naturally incorporate a variety of popular constraints. In this work, we present a parallelization strategy and two approaches for accelerating AO-ADMM. By redefining the convergence criteria of the inner ADMM iterations, we are able to split the data in a way that not only \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:qsWQJNntlusC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Boosting Item-based collaborative filtering via nearly uncoupled random walks",
            "Publication year": 2020,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/3406241",
            "Abstract": "Item-based models are among the most popular collaborative filtering approaches for building recommender systems. Random walks can provide a powerful tool for harvesting the rich network of interactions captured within these models. They can exploit indirect relations between the items, mitigate the effects of sparsity, ensure wider itemspace coverage, as well as increase the diversity of recommendation lists. Their potential however, can be hindered by the tendency of the walks to rapidly concentrate towards the central nodes of the graph, thereby significantly restricting the range of K-step distributions that can be exploited for personalized recommendations. In this work, we introduce RecWalk; a novel random walk-based method that leverages the spectral properties of nearly uncoupled Markov chains to provably lift this limitation and prolong the influence of users\u2019 past preferences on the successive steps of \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:BPS1z4jHU5cC",
            "Publisher": "ACM"
        },
        {
            "Title": "Perimeter-degree: A priori metric for directly measuring and homogenizing interconnection complexity in multilevel placement",
            "Publication year": 2003,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/639929.639941",
            "Abstract": "In this paper, we describe an accurate metric (perimeter-degree) for measuring interconnection complexity and effective use of it for controlling congestion in a multilevel framework. Perimeter-degree is useful for uniformly spreading interconnection density. In modern designs interconnects consume significant area and power. By making interconnect spread homogeneous, it is possible to improve routability as well as power dissipation distribution. Most of the existing congestion minimization heuristics are posteriori. In this work, we extend and complement our previous work [16] on priori congestion minimization techniques. In [16], we identified and used perimeter-degree for constructing congestion friendly clusters. This paper extends that work by unveiling perimeter-degree based whitespace allocation techniques. We show why\" number of external nets\" is not a desirable candidate for identifying potential \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:8AbLer7MMksC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Elucidating the regulatory network of secondary metabolism in streptomyces coelicolor.",
            "Publication year": 2002,
            "Publication url": "https://scholar.google.com/scholar?cluster=6563362361168783228&hl=en&oi=scholarr",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:UmS_249rOGwC",
            "Publisher": "AMER CHEMICAL SOC"
        },
        {
            "Title": "FISM: Factored item similarity models for top-n recommender systems",
            "Publication year": 2013,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/2487575.2487589",
            "Abstract": "The effectiveness of existing top-N recommendation methods decreases as the sparsity of the datasets increases. To alleviate this problem, we present an item-based method for generating top-N recommendations that learns the item-item similarity matrix as the product of two low dimensional latent factor matrices. These matrices are learned using a structural equation modeling approach, wherein the value being estimated is not used for its own estimation. A comprehensive set of experiments on multiple datasets at three different sparsity levels indicate that the proposed methods can handle sparse datasets effectively and outperforms other state-of-the-art top-N recommendation methods. The experimental results also show that the relative performance gains compared to competing methods increase as the data gets sparser.",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:qwy9JoKyICEC",
            "Publisher": "ACM"
        },
        {
            "Title": "An analysis of information content present in protein-DNA interactions",
            "Publication year": 2008,
            "Publication url": "https://www.worldscientific.com/doi/abs/10.1142/9789812776136_0046",
            "Abstract": "Understanding the role proteins play in regulating DNA replication is essential to forming a complete picture of how the genome manifests itself. In this work, we examine the feasibility of predicting the residues of a protein essential to binding by analyzing protein-DNA interactions from an information theoretic perspective. Through the lens of mutual information, we explore which properties of protein sequence and structure are most useful in determining binding residues with a particular focus on sequence features. We find that the quantity of information carried in most features is small with respect to DNA-contacting residues, the bulk being provided by sequence features along with a select few structural features. Supplemental information for this article is available at http://www.cs.umn.edu/~kauffman/supplements/psb2008",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:ZuybSZzF8UAC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Scalable Partitioning Algorithms for FPGAs with Heterogeneous Resources",
            "Publication year": 2004,
            "Publication url": "https://apps.dtic.mil/sti/citations/ADA439474",
            "Abstract": "As FPGA densities increase, partitioning-based FPGA placement approaches are becoming increasingly important as they can be used to provide high-quality and computationally scalable placement solutions. However, modern FPGA architectures incorporate heterogeneous resources, which place additional requirements on the partitioning algorithms because they now need to not only minimize the cut and balance the partitions, but also they must ensure that none of the resources in each partition is over-subscribed. In this paper, we present a number of multilevel multiresource hypergraph partitioning algorithms that are guaranteed to produce solutions that balance the utilization of the different resources across the partitions. We evaluate our algorithms on twelve industrial benchmarks ranging in size from 5,236 to 140,118 cells and show that they achieve minimal degradation in the min-cut while balancing the various resources. Comparing the quality of the solution produced by some of our algorithms against that produced by hMETIS, we show that our algorithms are capable of balancing the different resources while incurring only a 3.3-5.7 higher cut.Descriptors:",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:WIXB4To3Tx4C",
            "Publisher": "MINNESOTA UNIV MINNEAPOLIS DEPT OF COMPUTER SCIENCE"
        },
        {
            "Title": "Effective document clustering for large heterogeneous law firm collections",
            "Publication year": 2005,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/1165485.1165513",
            "Abstract": "Computational resources for research in legal environments have historically implied remote access to large databases of legal documents such as case law, statutes, law reviews and administrative materials. Today, by contrast, there exists enormous growth in lawyers' electronic work product within these environments, specifically within law firms. Along with this growth has come the need for accelerated knowledge management---automated assistance in organizing, analyzing, retrieving and presenting this content in a useful and distributed manner. In cases where a relevant legal taxonomy is available, together with representative labeled data, automated text classification tools can be applied. In the absence of these resources, document clustering offers an alternative approach to organizing collections, and an adjunct to search. To explore this approach further, we have conducted sets of successively more \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:NhqRSupF_l8C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Accounting for language changes over time in document similarity search",
            "Publication year": 2016,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/2934671",
            "Abstract": "Given a query document, ranking the documents in a collection based on how similar they are to the query is an essential task with extensive applications. For collections that contain documents whose creation dates span several decades, this task is further complicated by the fact that the language changes over time. For example, many terms add or lose one or more senses to meet people\u2019s evolving needs. To address this problem, we present methods that take advantage of two types of information to account for the language change. The first is the citation network that often exists within the collection, which can be used to link related documents with significantly different creation dates (and hence different language use). The second is the changes in the usage frequency of terms that occur over time, which can indicate changes in their senses and uses. These methods utilize the preceding information while \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:7Frjd3zlGBUC",
            "Publisher": "ACM"
        },
        {
            "Title": "Proceedings of MGTS 2005: 3rd International Workshop on Mining Graphs, Trees and Sequences; in conjunction with ECML/PKDD 2005, Porto, Portugal, 7th October 2005",
            "Publication year": 2005,
            "Publication url": "http://kops.uni-konstanz.de/handle/123456789/24302",
            "Abstract": "Proceedings of MGTS 2005 : 3rd International Workshop on Mining Graphs, Trees and Sequences \n; in conjunction with ECML/PKDD 2005, Porto, Portugal, 7th October 2005 KOPS - Das \nInstitutionelle Repositorium der Universit\u00e4t Konstanz Proceedings of MGTS 2005 : 3rd International \nWorkshop on Mining Graphs, Trees and Sequences ; in conjunction with ECML/PKDD 2005, \nPorto, Portugal, 7th October 2005 Home Suche Ver\u00f6ffentlichen \u00dcber KOPS Hilfe Startseite \n\u2192 Informatik und Informationswissenschaft \u2192 Informatik und Informationswissenschaft \u2192 \nDokumentanzeige Einloggen Deutsch English Proceedings of MGTS 2005 : 3rd International \nWorkshop on Mining Graphs, Trees and Sequences ; in conjunction with ECML/PKDD 2005, \nPorto, Portugal, 7th October 2005 Publikationstyp: Konferenzband Herausgeber/in: Nijssen, \nSiegfried; Meinl, Thorsten; Karypis, George Erscheinungsjahr: 2005 URL der : http://.ist.\u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:QVtou7C4vgoC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Centroid-based document classification: Analysis and experimental results",
            "Publication year": 2000,
            "Publication url": "https://link.springer.com/chapter/10.1007/3-540-45372-5_46",
            "Abstract": "In this paper we present a simple linear-time centroid-based document classification algorithm, that despite its simplicity and robust performance, has not been extensively studied and analyzed. Our experiments show that this centroidbased classifier consistently and substantially outperforms other algorithms such as Naive Bayesian, k-nearest-neighbors, and C4.5, on a wide range of datasets. Our analysis shows that the similarity measure used by the centroid-based scheme allows it to classify a new document based on how closely its behavior matches the behavior of the documents belonging to different classes. This matching allows it to dynamically adjust for classes with different densities and accounts for dependencies between the terms in the different classes.",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:8k81kl-MbHgC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "Intent term selection and refinement in e-commerce queries",
            "Publication year": 2019,
            "Publication url": "https://arxiv.org/abs/1908.08564",
            "Abstract": "In e-commerce, a user tends to search for the desired product by issuing a query to the search engine and examining the retrieved results. If the search engine was successful in correctly understanding the user's query, it will return results that correspond to the products whose attributes match the terms in the query that are representative of the query's product intent. However, the search engine may fail to retrieve results that satisfy the query's product intent and thus degrading user experience due to different issues in query processing: (i) when multiple terms are present in a query it may fail to determine the relevant terms that are representative of the query's product intent, and (ii) it may suffer from vocabulary gap between the terms in the query and the product's description, i.e., terms used in the query are semantically similar but different from the terms in the product description. Hence, identifying the terms that describe the query's product intent and predicting additional terms that describe the query's product intent better than the existing query terms to the search engine is an essential task in e-commerce search. In this paper, we leverage the historical query reformulation logs of a major e-commerce retailer to develop distant-supervised approaches to solve both these problems. Our approaches exploit the fact that the significance of a term is dependent upon the context (other terms in the neighborhood) in which it is used in order to learn the importance of the term towards the query's product intent. We show that identifying and emphasizing the terms that define the query's product intent leads to a 3% improvement in ranking. Moreover, for \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:mVC4hKzE2FoC",
            "Publisher": "Unknown"
        },
        {
            "Title": "CINF 82-Evaluation of 3-D descriptors in virtual screening",
            "Publication year": 2007,
            "Publication url": "https://scholar.google.com/scholar?cluster=14052770391128492750&hl=en&oi=scholarr",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:Xz60mAmATU4C",
            "Publisher": "AMER CHEMICAL SOC"
        },
        {
            "Title": "Criterion functions for clustering on high-dimensional data",
            "Publication year": 2006,
            "Publication url": "https://link.springer.com/chapter/10.1007/3-540-28349-8_8",
            "Abstract": "In recent years, we have witnessed a tremendous growth in the volume of text documents available on the Internet, digital libraries, news sources, and company-wide intranets. This has led to an increased interest in developing methods that can help users to effectively navigate, summarize, and organize this information with the ultimate goal of helping them to find what they are looking for. Fast and high-quality document clustering algorithms play an important role toward this goal as they have been shown to provide both an intuitive navigation/browsing mechanism by organizing large amounts of information into a small number of meaningful clusters as well as to greatly improve the retrieval performance either via cluster-driven dimensionality reduction, term-weighting, or query expansion. This ever-increasing importance of document clustering and the expanded range of its applications led to the \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:URolC5Kub84C",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "Streaming tensor factorization for infinite data sources",
            "Publication year": 2018,
            "Publication url": "https://epubs.siam.org/doi/abs/10.1137/1.9781611975321.10",
            "Abstract": "Sparse tensor factorization is a popular tool in multi-way data analysis and is used in applications such as cybersecurity, recommender systems, and social network analysis. In many of these applications, the tensor is not known a priori and instead arrives in a streaming fashion for a potentially unbounded amount of time. Existing approaches for streaming sparse tensors are not practical for unbounded streaming because they rely on maintaining the full factorization of the data, which grows linearly with time. In this work, we present CP-stream, an algorithm for streaming factorization in the model of the canonical polyadic decomposition which does not grow linearly in time or space, and is thus practical for long-term streaming. Additionally, CP-stream incorporates user-specified constraints such as non-negativity which aid in the stability and interpretability of the factorization. An evaluation of CP-stream \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:X5YyAB84Iw4C",
            "Publisher": "Society for Industrial and Applied Mathematics"
        },
        {
            "Title": "Enhancing link-based similarity through the use of non-numerical labels and prior information",
            "Publication year": 2010,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/1830252.1830256",
            "Abstract": "Several key applications like recommender systems require to compute similarities between the nodes (objects or entities) of a bipartite network. These similarities serve many important purposes, such as finding users sharing common interests or items with similar characteristics, as well as the automated recommendation and categorization of items. While a broad range of methods have been proposed to compute similarities in networks, such methods have two limitations:(1) they require the link values to be in the form of numerical weights representing the strength of the corresponding relation, and (2) they do not take into account prior information on the similarities. This paper presents a novel approach, based on the SimRank algorithm, to compute similarities between the nodes of a bipartite network. Unlike current methods, this approach allows one to model the agreement between link values using any \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:uc_IGeMz5qoC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Parallel algorithms in data mining",
            "Publication year": 2001,
            "Publication url": "https://conservancy.umn.edu/handle/11299/215466",
            "Abstract": "Recent times have seen an explosive growth in the availability ofvarious kinds of data. It has resulted in an unprecedented opportunity todevelop automated data-driven techniques of extracting useful knowledge.Data mining, an important step in this process of knowledge discovery,consists of methods that discover interesting, non-trivial, and usefulpatterns hidden in the data.To date, the primary driving force behind the research in data mininghas been the development of algorithms for data-sets arising in variousbusiness, information retrieval, and financial applications.Due to the latest technological advances,very large data-sets are becoming available in many scientificdisciplines as well. The rate of production of such data-sets far outstripsthe ability to analyze them manually.Data mining techniques hold great promises for developing new sets of toolsthat can be used to automatically analyze the massive data-sets resultingfrom such simulations, and thushelp engineers and scientists unravel the causal relationships in theunderlying mechanisms of the dynamic physical processes.The huge size of the available data-sets and their high-dimensionalitymake large-scale data mining applications computationally very demanding,to an extent that high-performance parallel computing is fast becomingan essential component of the solution.Moreover, the quality of the data mining results often depends directlyon the amount of computing resources available.In fact, data mining applications are poised to become the dominant consumersof supercomputing in the near future. There is a necessity to developeffective parallel algorithms for various data \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:XUvXOeBm_78C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Recent advances in recommender systems and future directions",
            "Publication year": 2015,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-319-19941-2_1",
            "Abstract": "This article presents an overview of recent methodological advances in developing nearest-neighbor-based recommender systems that have substantially improved their performance. The key components in these methods are: (i) the use of statistical learning to estimate from the data the desired user-user and item-item similarity matrices, (ii) the use of lower-dimensional representations to handle issues associated with data sparsity, (iii) the combination of neighborhood and latent space models, and (iv) the direct incorporation of auxiliary information during model estimation. The article will also provide illustrative examples for these methods in the context of item-item nearest-neighbor methods for rating prediction and Top-N recommendation. In addition, the article will present an overview of exciting new application areas of recommender systems along with the challenges and opportunities associated \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:xm0LlTxljI0C",
            "Publisher": "Springer, Cham"
        },
        {
            "Title": "Automatic detection of vaccine adverse reactions by incorporating historical medical conditions",
            "Publication year": 2011,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/2147805.2147896",
            "Abstract": "This paper extends the problem of vaccine adverse reaction detection by incorporating historical medical conditions. We propose a novel measure called dual-lift for this task, and formulate this problem in the framework of constraint pattern mining. We present a pattern mining algorithm DLiftMiner which utilizes a novel approach to upper bound the dual-lift measure for reducing the search space. Experimental results on both synthetic and real world datasets show that our method is effective and promising.",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:_OXeSy2IsFwC",
            "Publisher": "Unknown"
        },
        {
            "Title": "CLUTO: A Clustering Toolkit",
            "Publication year": 2002,
            "Publication url": "https://apps.dtic.mil/sti/citations/ADA439508",
            "Abstract": "Clustering algorithms divide data into meaningful or useful groups, called clusters, such that the intra-cluster similarity is maximized and the inter-cluster similarity is minimized. These discovered clusters can be used to explain the characteristics of the underlying data distribution and thus serve as the foundation for various data mining and analysis techniques. The applications of clustering include characterization of different customer groups based upon purchasing patterns, categorization of documents on the World Wide Web, grouping of genes and proteins that have similar functionality, grouping of spatial locations prone to earth quakes from seismological data, etc. CLUTO is a software package for clustering low and high dimensional datasets and for analyzing the characteristics of the various clusters.Descriptors:",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:roLk4NBRz8UC",
            "Publisher": "MINNESOTA UNIV MINNEAPOLIS DEPT OF COMPUTER"
        },
        {
            "Title": "Learning Student Interest Trajectory for MOOC Thread Recommendation",
            "Publication year": 2020,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/9346454/",
            "Abstract": "In recent years, Massive Open Online Courses (MOOCs) have witnessed immense growth in popularity. Now, due to the recent Covid19 pandemic situation, it is important to push the limits of online education. Discussion forums are primary means of interaction among learners and instructors. However, with growing class size, students face the challenge of finding useful and informative discussion forums. This problem can be solved by matching the interest of students with thread contents. The fundamental challenge is that the student interests drift as they progress through the course, and forum contents evolve as students or instructors update them. In our paper, we propose to predict future interest trajectories of students. Our model consists of two key operations: 1) Update operation and 2) Projection operation. Update operation models the inter-dependency between the evolution of student and thread using \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:j2GSQqY3pL0C",
            "Publisher": "IEEE"
        },
        {
            "Title": "A kernel framework for protein residue annotation",
            "Publication year": 2009,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-642-01307-2_40",
            "Abstract": "Over the last decade several prediction methods have been developed for determining structural and functional properties of individual protein residues using sequence and sequence-derived information. Most of these methods are based on support vector machines as they provide accurate and generalizable prediction models. We developed a general purpose protein residue annotation toolkit (Pro                 SAT) to allow biologists to formulate residue-wise prediction problems. Pro                 SAT formulates annotation problem as a classification or regression problem using support vector machines. For every residue Pro                 SAT captures local information (any sequence-derived information) around the reside to create fixed length feature vectors. Pro                 SAT implements accurate and fast kernel functions, and also introduces a flexible window-based encoding scheme that allows better capture \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:IUKN3-7HHlwC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "HeMI: Multi-view Embedding in Heterogeneous Graphs",
            "Publication year": 2021,
            "Publication url": "https://arxiv.org/abs/2109.07008",
            "Abstract": "Many real-world graphs involve different types of nodes and relations between nodes, being heterogeneous by nature. The representation learning of heterogeneous graphs (HGs) embeds the rich structure and semantics of such graphs into a low-dimensional space and facilitates various data mining tasks, such as node classification, node clustering, and link prediction. In this paper, we propose a self-supervised method that learns HG representations by relying on knowledge exchange and discovery among different HG structural semantics (meta-paths). Specifically, by maximizing the mutual information of meta-path representations, we promote meta-path information fusion and consensus, and ensure that globally shared semantics are encoded. By extensive experiments on node classification, node clustering, and link prediction tasks, we show that the proposed self-supervision both outperforms and improves competing methods by 1% and up to 10% for all tasks.",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:dhpJJ7xvgBgC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Cumulative knowledge-based regression models for next-term grade prediction",
            "Publication year": 2017,
            "Publication url": "https://epubs.siam.org/doi/abs/10.1137/1.9781611974973.62",
            "Abstract": "Grade prediction for courses not yet taken by students is important so as to guide them while registering for next-term courses. Moreover, it can help their advisers for designing personalized degree plans and modifying them based on the students' performance. In this paper, we present cumulative knowledge-based regression models with different course-knowledge spaces for the task of next-term grade prediction. These models utilize historical student-course grade data as well as the information available about the courses that capture the relationships between courses in terms of the knowledge components provided by them. Our experiments on a large dataset obtained from the College of Science and Engineering at University of Minnesota show that our proposed methods achieve better performance than competing methods and that these performance gains are statistically significant.",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:as0KMg8qHbkC",
            "Publisher": "Society for Industrial and Applied Mathematics"
        },
        {
            "Title": "Multi-threaded graph partitioning",
            "Publication year": 2013,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/6569814/",
            "Abstract": "In this paper we explore the design space of creating a multi-threaded graph partitioner. We present and compare multiple approaches for parallelizing each of the three phases of multilevel graph partitioning: coarsening, initial partitioning, and uncoarsening. We also explore the differences in thread lifetimes and data ownership in this context. We show that despite the options for fine-grain synchronization and task decomposition offered by current threading technologies, the best performance is achieved by preserving data ownership and minimizing synchronization. In addition to this we also present an unprotected approach to generating a vertex matching in parallel with little overhead. We use these findings to develop an OpenMP based implementation of the Metis algorithms and compare it against MPI based partitioners on three different multi-core architectures. Our multi-threaded implementation not only \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:oi2SiIJ9l4AC",
            "Publisher": "IEEE"
        },
        {
            "Title": "David C. Anastasiu1, Evangelia Christakopoulou2, Shaden Smith2, Mohit Sharma2",
            "Publication year": 2016,
            "Publication url": "https://scholar.google.com/scholar?cluster=3548166787646887585&hl=en&oi=scholarr",
            "Abstract": "Los sistemas de recomendaci\u00f3n son hoy en d\u00eda ubicuos en el mercado y tienen una enorme importancia comercial como se evidencia a partir del gran n\u00famero de empresas que comercializan soluciones de sistemas de recomendaci\u00f3n. Los sistemas de recomendaci\u00f3n exitosos usan datos de compras pasadas y datos de satisfacci\u00f3n para realizar recomendaciones personalizadas de alta calidad. Las enormes cantidades de datos disponibles para los sistemas de recomendaci\u00f3n actuales hacen necesaria una reevaluaci\u00f3n de los m\u00e9todos que se usan para calcular recomendaciones. En este art\u00edculo, proporcionamos una revisi\u00f3n de los sistemas de recomendaci\u00f3n de la era Big Data. Destacamos los algoritmos de recomendaci\u00f3n prevalentes y como \u00e9stos se adaptan para operar en entornos de computaci\u00f3n paralelos y distribuidos. En el contexto de los sistemas de recomendaci\u00f3n, centramos nuestra \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:bCjgOgSFrM0C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Prosat: A generalized framework for protein sequence annotation",
            "Publication year": 2008,
            "Publication url": "https://cs.gmu.edu/~kauffman/mypapers/prosat.pdf",
            "Abstract": "Motivation: Over the last decade several prediction methods have been developed for determining structural and functional properties of individual protein residues using sequence and sequencederived information. These protein residue annotation problems are often formulated as either classification or regression problems and solved using a common set of techniques.Methods: We developed a generalized protein sequence annotation toolkit (PROSAT) for solving classification or regression problems using support vector machines. The key characteristic of our method is its effective use of window-based information to capture the local environment of a protein sequence residue. This window information is used with several kernel functions available within our framework. We show the effectiveness of using the previously developed normalized second order exponential kernel function and experiment with local window-based information at different levels of granularity.Results: We report empirical results on a diverse set of classification and regression problems: prediction of solvent accessibility, secondary structure, local structure alphabet, transmembrane helices, DNA-protein interaction sites, contact order, and regions of disorder are all explored. Our methods show either comparable or superior results to several state-of-the-art application tuned prediction methods for these problems. PROSAT provides practitioners an efficient and easy-to-use tool for a wide variety of annotation problems. The results of some of these predictions can be used to assist in solving the overarching 3D structure prediction problem.Availibility: http://bio. dtc. umn \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:AvfA0Oy_GE0C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Item-based top-n recommendation algorithms",
            "Publication year": 2004,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/963770.963776",
            "Abstract": "The explosive growth of the world-wide-web and the emergence of e-commerce has led to the development of recommender systems---a personalized information filtering technology used to identify a set of items that will be of interest to a certain user. User-based collaborative filtering is the most successful technology for building recommender systems to date and is extensively used in many commercial recommender systems. Unfortunately, the computational complexity of these methods grows linearly with the number of customers, which in typical commercial applications can be several millions. To address these scalability concerns model-based recommendation techniques have been developed. These techniques analyze the user--item matrix to discover relations between the different items and use these relations to compute the list of recommendations.In this article, we present one such class of model \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:YsMSGLbcyi4C",
            "Publisher": "ACM"
        },
        {
            "Title": "Graph partitioning for high performance scientific simulations",
            "Publication year": 2000,
            "Publication url": "https://conservancy.umn.edu/handle/11299/215407",
            "Abstract": "Algorithms that find good partitionings of unstructured and irregular graphs are critical for the efficient execution of scientific simulations on high performance parallel computers.  This paper presents an overview of graph partitioning algorithms.  Recent developments in graph partitioning for adaptive and dynamic simulations, as well as partitioning algorithms for sophisticated simulations such as multi-phase, multi-physics, and multi-mesh computations are also discussed.",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:kNdYIx-mwKoC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Structured dictionary learning for energy disaggregation",
            "Publication year": 2019,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/3307772.3328301",
            "Abstract": "The increased awareness regarding the impact of energy consumption on the environment has led to an increased focus on reducing energy consumption. Feedback on the appliance level energy consumption can help in reducing the energy demands of the consumers. Energy disaggregation techniques are used to obtain the appliance level energy consumption from the aggregated energy consumption of a house. These techniques extract the energy consumption of an individual appliance as features and hence face the challenge of distinguishing two similar energy consuming devices. To address this challenge we develop methods that leverage the fact that some devices tend to operate concurrently at specific operation modes. The aggregated energy consumption patterns of a subgroup of devices allows us to identify the concurrent operating modes of devices in the subgroup. Thus, we design hierarchical \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:GiYFt9mpioMC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Theto-a fast and high-quality partitioning driven global placer",
            "Publication year": 2003,
            "Publication url": "https://apps.dtic.mil/sti/citations/ADA439412",
            "Abstract": "Partitioning driven placement approaches are often preferred for fast and scalable solutions to large placement problems. However, due to the inaccuracy of representing wirelength objective by cut objective the quality of such placements often trails the quality of placements produced by pure wirelength driven placements. In this paper we present THETO, a new partitioning driven global placement algorithm that retains the speed associated with traditional partitioning driven placement algorithms but incorporates a number of novel ideas that allows it to produce solutions whose quality is better than those produced by more sophisticated and computationally expensive algorithms. The keys to THETOs success are a new terminal propagation method that allows the partitioner to better capture the characteristics of the various cut nets and a new post-bisectioning refinement step that enhances the effectiveness of the new terminal propagation. Experiments on the ISPD98 benchmarks shows that THETO produces global placement solutions that are 6 better in terms of the half perimeter wirelength than Dragon while requiring significantly less time.Descriptors:",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:w0odbtu79TwC",
            "Publisher": "MINNESOTA UNIV MINNEAPOLIS DEPT OF COMPUTER SCIENCE"
        },
        {
            "Title": "Dynamic load balancing algorithms for sequence mining",
            "Publication year": 2001,
            "Publication url": "https://apps.dtic.mil/sti/citations/AD1020012",
            "Abstract": "Discovery of sequential patterns is becoming increasingly useful and essential in many scientific and commercial domains. Enormous sizes of available datasets and possibly large number of mined patterns demand efficient and scalable algorithms. In this paper we present a parallel formulation of a serial sequential pattern discovery algorithm based on tree projection that uses a novel dynamic load balancing algorithm which is well suited for distributed memory parallel computers. Our experimental evaluation on a 32 processor IBM SP show that this algorithms are capable of achieving good speedups, substantially reducing the amount of the required work to find sequential patterns in large databases.Descriptors:Subject Categories:Operations ResearchComputer Programming and SoftwareDistribution Statement:[A, Approved For Public Release]",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:Mojj43d5GZwC",
            "Publisher": "University of Minnesota Department of Computer Science and Engineering"
        },
        {
            "Title": "Local latent space models for top-n recommendation",
            "Publication year": 2018,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/3219819.3220112",
            "Abstract": "Users' behaviors are driven by their preferences across various aspects of items they are potentially interested in purchasing, viewing, etc. Latent space approaches model these aspects in the form of latent factors. Although such approaches have been shown to lead to good results, the aspects that are important to different users can vary. In many domains, there may be a set of aspects for which all users care about and a set of aspects that are specific to different subsets of users. To explicitly capture this, we consider models in which there are some latent factors that capture the shared aspects and some user subset specific latent factors that capture the set of aspects that the different subsets of users care about.",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:cB__R-XWw9UC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Algorithms for graph partitioning and fill reducing ordering for domain decomposition methods",
            "Publication year": 2006,
            "Publication url": "https://www.dtc.umn.edu/publications/reports/2006_03.pdf",
            "Abstract": "This paper focuses on domain decomposition-based numerical simulations whose subproblems corresponding to the various subdomains are solved using sparse direct factorization methods (eg., FETI). Effective load-balancing of such computations requires that the resulting partitioning simultaneously balances the amount of time required to factor the local subproblem using direct factorization and the number of elements assigned to each processor. Unfortunately, existing graph-partitioning algorithms cannot be used to load-balance this type of computations as they can only compute partitionings that simultaneously balance numerous constraints defined a priori on the vertices and optimize different objectives defined locally on the edges. To address this problem, we developed an algorithm that follows a predictorcorrector approach that first computes a high-quality partitioning of the underlying graph, and then modifies it to achieve the desired balancing constraints. During the corrector step we compute a fill reducing ordering for each partition, and then we modify the initial partitioning and ordering so that our objectives are satisfied. Experimental results show that the proposed algorithm is able to reduce the fill-in of the overweight sub-domains and achieve a considerably better balance.\u2217 This work was supported in part by NSF CCR-9972519, EIA-9986042, ACI-9982274, ACI-0133464, and ACI-0312828; the Digital Technology Center at the University of Minnesota; and by the Army High Performance Computing Research Center (AHPCRC) under the auspices of the Department of the Army, Army Research Laboratory (ARL) under \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:6pF0wJmtdfAC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Mining Coevolving Induced Relational Motifs in Dynamic Networks",
            "Publication year": 2015,
            "Publication url": "http://glaros.dtc.umn.edu/gkhome/fetch/papers/cirm2015.pdf",
            "Abstract": "A fundamental task associated with the analysis of a dynamic network is to study and understand how the network changes over time. Co-evolution of patterns, where all the relations among a set of entities change in a consistent way over time, can provide evidence of possibly unknown coordination mechanism among the entities of a dynamic network. This paper introduces a new class of dynamic network patterns, referred to as coevolving induced relational motifs (CIRMs), which are designed to identify a recurring set of nodes whose complete set of intra-relations undergo some changes in a consistent way over time. We develop an algorithm to analyze all relational changes between entities and find all frequent coevolving induced relational motifs. Experimental results based on multiple dynamic networks derived from real world datasets show that the algorithm is able to identify all frequent CIRMs in small amount of time. In addition, a qualitative analysis of the results shows that the discovered CIRMs are able to capture network characteristics that can be used as features for modeling the underlying dynamic network in the context of a classification task.",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:4Yq6kJLCcecC",
            "Publisher": "Unknown"
        },
        {
            "Title": "BIOKDD02: Workshop on Data Mining in Bioinformatics July 23rd, 2002 Edmonton, Alberta, Canada in conjunction with",
            "Publication year": 2002,
            "Publication url": "https://scholar.google.com/scholar?cluster=1936608535349834486&hl=en&oi=scholarr",
            "Abstract": "Foreword Bioinformatics provides opportunities for developing novel data mining methods. Some of the grand challenges in bioinformatics include protein structure prediction, homology search, multiple alignment and phylogeny construction, genomic sequence analysis, gene finding and gene mapping, as well as applications in gene expression data analysis, drug discovery in pharmaceutical industry, etc. This workshop aims to present latest results in this important area at the intersection of biology and KDD.",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:aDl3D7KC1E4C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Prediction of contact maps using support vector machines",
            "Publication year": 2005,
            "Publication url": "https://www.worldscientific.com/doi/abs/10.1142/S0218213005002429",
            "Abstract": "Contact map prediction is of great interest for its application in fold recognition and protein 3D structure determination. In this paper we present a contact-map prediction algorithm that employs Support Vector Machines as the machine learning tool and incorporates various features such as sequence profiles and their conservations, correlated mutation analysis based on various amino acid physicochemical properties, and secondary structure. In addition, we evaluated the effectiveness of the different features on contact map prediction for different fold classes. On average, our predictor achieved a prediction accuracy of 0.224 with an improvement over a random predictor of a factor 11.7, which is better than reported studies. Our study showed that predicted secondary structure features play an important roles for the proteins containing beta-structures. Models based on secondary structure features and correlated \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:u_35RYKgDlwC",
            "Publisher": "World Scientific Publishing Company"
        },
        {
            "Title": "PanRep: Universal node embeddings for heterogeneous graphs",
            "Publication year": 2020,
            "Publication url": "https://openreview.net/forum?id=2nm0fGwWBMr",
            "Abstract": "Learning unsupervised node embeddings facilitates several downstream tasks such as node classification and link prediction. A node embedding is universal if it is designed to be used by and benefit various downstream tasks. This work introduces PanRep, a graph neural network (GNN) model, for unsupervised learning of universal node representations for heterogenous graphs. PanRep consists of a GNN encoder that obtains node embeddings and four decoders, each capturing different topological and node feature properties. Abiding to these properties the novel unsupervised framework learns universal embeddings applicable to different downstream tasks. PanRep can be furthered fine-tuned to account for possible limited labels. In this operational setting PanRep is considered as a pretrained model for extracting node embeddings of heterogenous graph data. PanRep outperforms all unsupervised and certain supervised methods in node classification and link prediction, especially when the labeled data for the supervised methods is small. PanRep-FT (with fine-tuning) outperforms all other supervised approaches, which corroborates the merits of pretraining models. Finally, we apply PanRep-FT for discovering novel drugs for Covid-19. We showcase the advantage of universal embeddings in drug repurposing and identify several drugs used in clinical trials as possible drug candidates.",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:ehoypfNsBj8C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Systems and methods of making content-based demographics predictions for website cross-reference to related applications",
            "Publication year": 2013,
            "Publication url": "https://patents.google.com/patent/US8412648B2/en",
            "Abstract": "Systems and methods for making demographic predictions for websites and web-pages. Embodiments include a system and a method of making demographic predictions for websites. The system and method select one or more websites with known demographic attributes for use as training websites, obtain demographic attributes data of the training websites, determine first features of web-pages of the training websites and develop a prediction model using the determined first features and the obtained demographic attributes data. The prediction model predicts one or more values for a target demographic attribute. The system and method determine second features of web-pages of a target website and apply the prediction model to the determined second features of the target website to predict one or more values for the target demographic attribute of the target website.",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:MpfHP-DdYjUC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Whole genome alignments using MPI-LAGAN",
            "Publication year": 2008,
            "Publication url": "https://conservancy.umn.edu/handle/11299/215762",
            "Abstract": "Advances in sequencing technologies have substantially increased the number of fully sequenced genomes. Alignment algorithms play a crucial rule in analyzing whole genomes, identifying similar and conserved regions between pairs of genomes, leading to annotation of genomes with site-specific properties and functions.  In this work we introduce a parallel algorithm for a widely used whole genome alignment method called LAGAN. We use the MPI-based protocol, to develop parallel solutions for two phases of the algorithm which take up a significant portion of the total runtime, and also have  a high memory requirement. The serial LAGAN program uses CHAOS to quickly determine initial anchor or seeds,  which are extended using a sparse dynamic programming based longest-increasing subsequence method. Our work involves parallelizing the CHAOS  and LIS phases of the algorithm using a  one-dimensional block cyclic partitioning of the computation. This leads to development of an efficient algorithm that utilizes the processors in a balanced way. We also ensure minimum time spent in communication or transfer of information across processors.   We also report experimental evaluation of our parallel implementation using pairs of human contigs of varying lengths. We discuss and illustrate the challenges faced in parallelizing a sparse dynamic programming formulation as in this work, and show equivalent to theoretical speedups for our parallelized phases of the LAGAN algorithm.",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:-yGd096yOn8C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Concept indexing: A fast dimensionality reduction algorithm with applications to document retrieval & categorization",
            "Publication year": 2000,
            "Publication url": "https://conservancy.umn.edu/handle/11299/215405",
            "Abstract": "In recent years, we have seen a tremendous growth in the volume of online text documents available on the Internet, digital libraries, news sources, and company-wide intranet.  This has led to an increased interest in developing methods that can efficiently retrieve relevant information.  In recent years, retrieval techniques based on dimensionality reduction, such as latent semantic indexing (LSI), have been shown to improve the quality of the information being retrieved by capturing the latent meaning of the words that are present in the documents.  Unfortunately, LSI is computationally expensive and cannot be used in a supervised setting.  In this paper we present a new fast dimensionality reduction algorithm, called concept indexing (CI), that is based on document clustering.  CI computes a k-dimensional representation of a collection of documents by first clustering the documents in k groups, and then using the centroid vectors of the clusters to derive the axes of the reduced k-dimensional space.  The low computational complexity of CI is achieved by using an almost linear time clustering algorithm.  Furthermore, CI can be used to compute the dimensionality reduction in a supervised setting.  Experimental results show that the dimensionality reduction computed by CI achieves comparable retrieval performance to that obtained using LSI, while requiring an order of magnitude less time.  Moreover, the supervised dimensionality reduction computed by CI greatly improved the classification accuracies of existing classification algorithms such as C4.5 and kNN.",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:dhFuZR0502QC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Selective markov models for predicting web page accesses",
            "Publication year": 2004,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/990301.990304",
            "Abstract": "The problem of predicting a user's behavior on a Web site has gained importance due to the rapid growth of the World Wide Web and the need to personalize and influence a user's browsing experience. Markov models and their variations have been found to be well suited for addressing this problem. Of the different variations of Markov models, it is generally found that higher-order Markov models display high predictive accuracies on Web sessions that they can predict. However, higher-order models are also extremely complex due to their large number of states, which increases their space and run-time requirements. In this article, we present different techniques for intelligently selecting parts of different order Markov models so that the resulting model has a reduced state complexity, while maintaining a high predictive accuracy.",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:LkGwnXOMwfcC",
            "Publisher": "ACM"
        },
        {
            "Title": "CINF 76-New approaches to 3-D pharmacophore searches in virtual screening for bioactive molecules",
            "Publication year": 2007,
            "Publication url": "https://scholar.google.com/scholar?cluster=4096820113395563187&hl=en&oi=scholarr",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:sA9dB-pw3HoC",
            "Publisher": "AMER CHEMICAL SOC"
        },
        {
            "Title": "Structure-based machine learning models for computational mutagenesis",
            "Publication year": 2010,
            "Publication url": "https://books.google.com/books?hl=en&lr=&id=LeRhAoz4NwEC&oi=fnd&pg=PA403&dq=info:KOdYmkvXEmMJ:scholar.google.com&ots=yC3i_z4MHZ&sig=hlkaUpQncq2an09Nbxpmyv7JAxw",
            "Abstract": "Proteins exhibit a wide range of functional consequences upon mutation. In this chapter, we will focus speci\ufb01cally on mutations that are the result of single or multiple amino acid substitutions. Experimentally well-studied functional effects of residue replacements in proteins include relative changes to protein activity or stability. The activities for a large number of single residue replacements in a particular protein, studied under identical experimental conditions and protocols, are typically reported quantitatively as percentages of the wildtype protein activity. More frequently, however, such mutants are qualitatively described as each belonging to one of a few categorical classes based on the degree of activity. Mutant stability changes can measured experimentally using a variety of quantitative measures: \u0394\u0394G and \u0394\u0394GH2O represent the freeenergy change of unfolding due to thermal and chemical denaturations, respectively, while \u0394Tm refers to mutant thermal stability change. With zero as a cutoff value for these measures, mutant stability can also be described qualitatively as either increased or decreased relative to the wild-type protein. In the case of a protein that serves as a target for an inhibitor drug, a more broadly de\ufb01ned functional consequence refers to the relative change in",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:wUn16MOA3RoC",
            "Publisher": "John Wiley and Sons Inc. Hoboken, New Jersey, USA"
        },
        {
            "Title": "Feature Extraction for Classifying Students Based on Their Academic Performance.",
            "Publication year": 2018,
            "Publication url": "https://eric.ed.gov/?id=ED593215",
            "Abstract": "Developing tools to support students and learning in a traditional or online setting is a significant task in today\u2019s educational environment. The initial steps towards enabling such technologies using machine learning techniques focused on predicting the student\u2019s performance in terms of the achieved grades. The disadvantage of these approaches is that they do not perform as well in predicting poor-performing students. The objective of our work is two-fold. First, in order to overcome this limitation, we explore if poorly performing students can be more accurately predicted by formulating the problem as binary classification. Second, in order to gain insights as to which are the factors that can lead to poor performance, we engineered a number of humaninterpretable features that quantify these factors. These features were derived from the students\u2019 grades from the University of Minnesota, an undergraduate public institution. Based on these features, we perform a study to identify different student groups of interest, while at the same time, identify their importance.",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:cSdaV2aYdYsC",
            "Publisher": "International Educational Data Mining Society"
        },
        {
            "Title": "BIOT 180-Towards defining gene-trait relationship for hyper productivity in recombinant mammalian cells through transcriptome analysis",
            "Publication year": 2006,
            "Publication url": "https://scholar.google.com/scholar?cluster=3149559381975777842&hl=en&oi=scholarr",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:aIdbFUkbNIkC",
            "Publisher": "AMER CHEMICAL SOC"
        },
        {
            "Title": "Data mining for turbulent flows",
            "Publication year": 2001,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-1-4615-1733-7_14",
            "Abstract": "Data mining techniques hold great promise for enabling the automatic analysis of large data sets generated by scientific simulation, and thus, may help engineers and scientists unravel the causal relationships in the underlying system. In this chapter, we propose several data modeling methods to incorporate spatial and temporal features of scientific simulation data and investigate some of them in the context of developing models for predicting burst events in turbulent flow. We use the classification rules algorithm C4.5rules and support-vector machines on the turbulent flow simulation data to develop predictive models for identifying upward or downward velocity movements of the flow close to the wall as a function of swirl strength in the nearby region.",
            "Abstract entirety": 1,
            "Author pub id": "ElqwScwAAAAJ:olpn-zPbct0C",
            "Publisher": "Springer, Boston, MA"
        },
        {
            "Title": "TR O2-O26",
            "Publication year": 2002,
            "Publication url": "https://scholar.google.com/scholar?cluster=6803477066177928421&hl=en&oi=scholarr",
            "Abstract": "Over the years, frequent iteniset discovery algorithms have been used to \ufb01nd interesting patterns in various application areas. However, as data mining techniques are being increasingly applied to non-traditional domains, existing frequent pattern discovery approach cannot be used. This is because the transaction framework that is assumed by these algorithms cannot be used to effectively model the datasets in these domains. An alternate Way of modeling the objects in these datasets is to represent them using graphs. VVithin that model, the problem of finding frequent patterns becomes that of discovering subgraphs that occur frequently over the entire set of graphs. In this paper We present a computationally ef\ufb01cient algorithm, called FSG, for \ufb01nding all frequent subgraphs in large graph databases. We experimentally evaluate the performance of FSG using a variety of real and synthetic datasets. Our results show \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:HtS1dXgVpQUC",
            "Publisher": "Unknown"
        },
        {
            "Title": "TR O7-O14",
            "Publication year": 2007,
            "Publication url": "https://scholar.google.com/scholar?cluster=8931657302371854323&hl=en&oi=scholarr",
            "Abstract": "As the sequence identity between a pair of proteins decreases, alignment strategies that are based on sequence and/or sequence pro\ufb01les become progressively less effective in identifying the correct structural correspondence between residue pairs. This signi\ufb01cantly reduces the ability of comparative modeling-based approaches to build accurate structural models. Incorporating into the alignment process predicted information about the local structure of the protein holds the promise of signi\ufb01cantly improving7 the alignment quality of distant proteins. This paper studies the impact on the alignment quality of a new class of predicted local structural features that measure how well\ufb01xed-length backbonefragments centered around each residue-pair align with each other. It presents a comprehensive experimental evaluation comparing these new features against existing state-of-the-art approaches utilizing pro\ufb01le-based \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ElqwScwAAAAJ:BrOSOlqYqPUC",
            "Publisher": "Unknown"
        }
    ]
}]