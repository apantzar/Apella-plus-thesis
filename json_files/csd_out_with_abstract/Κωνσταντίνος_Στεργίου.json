[{
    "name": "\u039a\u03c9\u03bd\u03c3\u03c4\u03b1\u03bd\u03c4\u03af\u03bd\u03bf\u03c2 \u03a3\u03c4\u03b5\u03c1\u03b3\u03af\u03bf\u03c5",
    "romanize name": "Konstantinos Stergiou",
    "School-Department": "\u039c\u03b7\u03c7\u03b1\u03bd\u03b9\u03ba\u03ce\u03bd \u03a0\u03bb\u03b7\u03c1\u03bf\u03c6\u03bf\u03c1\u03b9\u03ba\u03ae\u03c2 \u03ba\u03b1\u03b9 \u03a4\u03b7\u03bb\u03b5\u03c0\u03b9\u03ba\u03bf\u03b9\u03bd\u03c9\u03bd\u03b9\u03ce\u03bd",
    "University": "uowm",
    "Rank": "\u039a\u03b1\u03b8\u03b7\u03b3\u03b7\u03c4\u03ae\u03c2",
    "Apella_id": 19516,
    "Scholar name": "Kostas Stergiou",
    "Scholar id": "Om3gYEYAAAAJ",
    "Affiliation": "University of Western Macedonia, Greece",
    "Citedby": 1766,
    "Interests": [
        "Artificial Intelligence"
    ],
    "Scholar url": "https://scholar.google.com/citations?user=Om3gYEYAAAAJ&hl=en",
    "Publications": [
        {
            "Title": "Overlay networks for task allocation and coordination in dynamic large-scale networks of cooperative agents",
            "Publication year": 2007,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/1329125.1329190",
            "Abstract": "This work proposes a method for allocating temporally interdependent tasks to homogeneous or heterogeneous cooperative agents in dynamic large-scale networks. This method views searching, task allocation and scheduling as an integrated problem that has to be efficiently solved in such networks. Solving the general problem optimally in a decentralized way is very hard and can only be solved by a centralized method, be approximated by means of heuristics, or by relaxations of the original problem. Our method facilitates effective searching through the dynamic assignment of gateway roles to agents and the exploitation of routing indices. In combination to searching, it exploits distributed constraint satisfaction techniques and dynamic re-organization of agent teams to efficiently handle the allocation of complex tasks with interdependent subtasks.",
            "Abstract entirety": 1,
            "Author pub id": "Om3gYEYAAAAJ:eQOLeE2rZwMC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Evaluating simple fully automated heuristics for adaptive constraint propagation",
            "Publication year": 2012,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/6495136/",
            "Abstract": "Despite the advancements in constraint propagation methods, most CP solvers still apply fixed predetermined propagators on each constraint of the problem. However, selecting the appropriate propagator for a constraint can be a difficult task that requires expertise. One way to overcome this is through the use of machine learning. A different approach uses heuristics to dynamically adapt the propagation method during search. The heuristics of this category proposed in [1] displayed promising results, but their evaluation and application suffered from two important drawbacks: They were only defined and tested on binary constraints and they required calibration of their input parameters. In this paper we follow this line of work by describing and evaluating simple, fully automated heuristics that are applicable on constraints of any arity. Experimental results from various problems show that the proposed heuristics can \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Om3gYEYAAAAJ:mVmsd5A6BfQC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Integration of Constraint Programming, Artificial Intelligence, and Operations Research: 17th International Conference, CPAIOR 2020, Vienna, Austria, September 21-24, 2020, Proceedings",
            "Publication year": 2020,
            "Publication url": "https://books.google.com/books?hl=en&lr=&id=tAX-DwAAQBAJ&oi=fnd&pg=PR5&dq=info:jDNzGgAY2S8J:scholar.google.com&ots=_XypOyxAzG&sig=OLYjiy1fUP051vGoy5qV23zs8os",
            "Abstract": "The volume LNCS 12296 constitutes the papers of the 17th International Conference on the Integration of Constraint Programming, Artificial Intelligence, and Operations Research which will be held online in September 2020. The 32 regular papers presented together with 4 abstracts of fast-track papers were carefully reviewed and selected from a total of 72 submissions. Additionally, this volume includes the 4 abstracts and 2 invited papers by plenary speakers. The conference program also included a Master Class on the topic\" Recent Advances in Optimization Paradigms and Solving Technology\"",
            "Abstract entirety": 1,
            "Author pub id": "Om3gYEYAAAAJ:HoB7MX3m0LUC",
            "Publisher": "Springer Nature"
        },
        {
            "Title": "On algorithms for decomposable constraints",
            "Publication year": 2002,
            "Publication url": "https://link.springer.com/chapter/10.1007/3-540-46014-4_7",
            "Abstract": "Non-binary constraints are present in many real-world constraint satisfaction problems. Certain classes of these constraints, like the all-different constraint, are \u201cdecomposable\u201d. That is, they can be represented by binary constraints on the same set of variables. For example, a non-binary all-different constraint can be decomposed into a clique of binary not-equals constraints. In this paper we make a theoretical analysis of local consistency and search algorithms for decomposable constraints. First, we prove a new lower bound for the worst-case time complexity of arc consistency on binary not-equals constraints. We show that the complexity is O(e), where e is the number of constraints, instead of O(ed), with d being the domain size, as previously known. Then, we compare theoretically local consistency and search algorithms that operate on the non-binary representation of decomposable constraints to their \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Om3gYEYAAAAJ:IWHjjKOFINEC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "Heuristics for dynamically adapting propagation in constraint satisfaction problems",
            "Publication year": 2009,
            "Publication url": "https://content.iospress.com/articles/ai-communications/aic450",
            "Abstract": "Building adaptive constraint solvers is a major challenge in constraint programming. An important line of research towards this goal is concerned with ways to dynamically adapt the propagation method applied on the constraints of the problem during search. In this paper we present a heuristic approach to this problem based on the monitoring of propagation events like value deletions and domain wipeouts. We develop a number of heuristics that allow the constraint solver to dynamically switch between a weaker and cheap local consistency and a stronger, but more expensive one, when certain conditions are met. The success of this approach is based on the observation that propagation events for individual constraints in structured problems mostly occur in clusters of nearby revisions. Hence, parts of the search space where certain constraints are highly active can be identified and exploited paving the way for \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Om3gYEYAAAAJ:LkGwnXOMwfcC",
            "Publisher": "IOS Press"
        },
        {
            "Title": "Solving quantified constraint satisfaction problems",
            "Publication year": 2008,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S0004370207001932",
            "Abstract": "We make a number of contributions to the study of the Quantified Constraint Satisfaction Problem (QCSP). The QCSP is an extension of the constraint satisfaction problem that can be used to model combinatorial problems containing contingency or uncertainty. It allows for universally quantified variables that can model uncertain actions and events, such as the unknown weather for a future party, or an opponent's next move in a game. In this paper we report significant contributions to two very different methods for solving QCSPs. The first approach is to implement special purpose algorithms for QCSPs; and the second is to encode QCSPs as Quantified Boolean Formulas and then use specialized QBF solvers. The discovery of particularly effective encodings influenced the design of more effective algorithms: by analyzing the properties of these encodings, we identify the features in QBF solvers responsible for their \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Om3gYEYAAAAJ:ufrVoPGSRksC",
            "Publisher": "Elsevier"
        },
        {
            "Title": "Strong bounds consistencies and their application to linear constraints",
            "Publication year": 2015,
            "Publication url": "https://www.aaai.org/ocs/index.php/AAAI/AAAI15/paper/viewPaper/9985",
            "Abstract": "We propose two local consistencies that extend bounds consistency (BC) by simultaneously considering combinations of constraints as opposed to single constraints. We prove that these two local consistencies are both stronger than BC, but are NP-hard to enforce even when constraints are linear. Hence, we propose two polynomial-time techniques to enforce approximations of these two consistencies on linear constraints. One is a reformulation of the constraints on which we enforce BC whereas the other is a polynomial time algorithm. Both achieve stronger pruning than BC. Our experiments show large differences in favor of our approaches.",
            "Abstract entirety": 1,
            "Author pub id": "Om3gYEYAAAAJ:TFP_iSt0sucC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Propagation in CSP and SAT",
            "Publication year": 2006,
            "Publication url": "https://link.springer.com/chapter/10.1007/11889205_12",
            "Abstract": "Constraint Satisfaction Problems and Propositional Satisfiability, are frameworks widely used to represent and solve combinatorial problems. A concept of primary importance in both frameworks is that of constraint propagation. In this paper we study and compare the amount of propagation that can be achieved, using various methods, when translating a problem from one framework into another. Our results complement, extend, and tie together recent similar studies. We provide insight as to which translation is preferable, with respect to the strength of propagation in the original problem and the encodings.",
            "Abstract entirety": 1,
            "Author pub id": "Om3gYEYAAAAJ:UebtZRa9Y70C",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "Towards automatic merging of domain ontologies: The HCONE-merge approach",
            "Publication year": 2006,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S1570826805000259",
            "Abstract": "Latest research efforts on the semi-automatic coordination of ontologies \u201ctouch\u201d on the mapping/merging of ontologies using the whole breadth of available knowledge. Addressing this issue, this paper presents the HCONE-merge approach, which is further extended towards automating the merging process. HCONE-merge makes use of the intended informal meaning of concepts by mapping them to WordNet senses using the Latent Semantic Indexing (LSI) method. Based on these mappings and using the reasoning services of description logics, HCONE-merge automatically aligns and then merges ontologies. Since the mapping of concepts to their intended meaning is an essential step of the HCONE-merge approach, this paper explores the level of human involvement required for mapping concepts of the source ontologies to their intended meanings. We propose a series of methods for ontology mapping \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Om3gYEYAAAAJ:isC4tDSrTZIC",
            "Publisher": "Elsevier"
        },
        {
            "Title": "On Neighborhood Singleton Consistencies.",
            "Publication year": 2017,
            "Publication url": "https://www.researchgate.net/profile/Anastasia-Paparrizou/publication/318830262_On_Neighborhood_Singleton_Consistencies/links/5a664199a6fdccb61c5a71a7/On-Neighborhood-Singleton-Consistencies.pdf",
            "Abstract": "CP solvers predominantly use arc consistency (AC) as the default propagation method. Many stronger consistencies, such as triangle consistencies (eg RPC and maxRPC) exist, but their use is limited despite results showing that they outperform AC on many problems. This is due to the intricacies involved in incorporating them into solvers. On the other hand, singleton consistencies such as SAC can be easily crafted into solvers but they are too expensive. We seek a balance between the efficiency of triangle consistencies and the ease of implementation of singleton ones. Using the recently proposed variant of SAC called Neighborhood SAC as basis, we propose a family of weaker singleton consistencies. We study them theoretically, comparing their pruning power to existing consistencies. We make a detailed experimental study using a very simple algorithm for their implementation. Results demonstrate that they outperform the existing propagation techniques, often by orders of magnitude, on a wide range of problems.",
            "Abstract entirety": 1,
            "Author pub id": "Om3gYEYAAAAJ:NMxIlDl6LWMC",
            "Publisher": "Unknown"
        },
        {
            "Title": "New algorithms for max restricted path consistency",
            "Publication year": 2011,
            "Publication url": "https://link.springer.com/content/pdf/10.1007/s10601-011-9110-y.pdf",
            "Abstract": "Max Restricted Path Consistency (maxRPC) is a local consistency for binary constraints that enforces a higher order of consistency than arc consistency. Despite the strong pruning that can be achieved, maxRPC is rarely used because existing maxRPC algorithms suffer from overheads and redundancies as they can repeatedly perform many constraint checks without triggering any value deletions. In this paper we propose and evaluate techniques that can boost the performance of maxRPC algorithms by eliminating many of these overheads and redundancies. These include the combined use of two data structures to avoid many redundant constraint checks, and the exploitation of residues to quickly verify the existence of supports. Based on these, we propose a number of closely related maxRPC algorithms. The first one, maxRPC3, has optimal O(end 3) time complexity, displays good \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Om3gYEYAAAAJ:MXK_kJrjxJIC",
            "Publisher": "Springer Netherlands"
        },
        {
            "Title": "Strong local consistency algorithms for table constraints",
            "Publication year": 2016,
            "Publication url": "https://link.springer.com/content/pdf/10.1007/s10601-014-9179-1.pdf",
            "Abstract": "Table constraints are important in constraint programming as they are present in many real problems from areas such as configuration and databases. As a result, numerous specialized algorithms that achieve generalized arc consistency (GAC) on table constraints have been proposed. Since these algorithms achieve GAC, they operate on one constraint at a time. In this paper we propose new filtering algorithms for positive table constraints that achieve stronger local consistency properties than GAC by exploiting intersections between constraints. The first algorithm, called maxRPWC+, is a domain filtering algorithm that is based on the local consistency maxRPWC and extends the GAC algorithm of Lecoutre and Szymanek (2006). The second algorithm extends the state-of-the-art STR-based algorithms to stronger relation filtering consistencies, i.e., consistencies that can remove tuples from constraints \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Om3gYEYAAAAJ:R3hNpaxXUhUC",
            "Publisher": "Springer US"
        },
        {
            "Title": "Efficient multiple constraint acquisition",
            "Publication year": 2020,
            "Publication url": "https://link.springer.com/article/10.1007/s10601-020-09311-4",
            "Abstract": "Constraint acquisition systems such as QuAcq and MultiAcq can assist non-expert users to model their problems as constraint networks by classifying (partial) examples as positive or negative. For each negative example, the former focuses on one constraint of the target network, while the latter can learn a maximum number of constraints. Two bottlenecks of the acquisition process where both these algorithms encounter problems are the large number of queries required to reach convergence, and the high cpu times needed to generate queries, especially near convergence. In this paper we propose algorithmic and heuristic methods to deal with both these issues. We first describe an algorithm, called MQuAcq, that blends the main idea of MultiAcq into QuAcq resulting in a method that learns as many constraints as MultiAcq does after a negative example, but with a lower complexity. A detailed theoretical \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Om3gYEYAAAAJ:ldfaerwXgEUC",
            "Publisher": "Springer US"
        },
        {
            "Title": "Strong domain filtering consistencies for non-binary constraint satisfaction problems",
            "Publication year": 2008,
            "Publication url": "https://www.worldscientific.com/doi/abs/10.1142/S0218213008004163",
            "Abstract": "Domain filtering local consistencies, such as inverse consistencies, that only delete values and do not add new constraints are particularly useful in Constraint Programming. Although many such consistencies for binary constraints have been proposed and evaluated, the situation with non-binary constraints is quite different. Only very recently have domain filtering consistencies stronger than GAC started to attract interest. Following this line of research, we define a number of strong domain filtering consistencies for non-binary constraints and theoretically compare their pruning power. We prove that three of these consistencies are equivalent to maxRPC in binary CSPs while another is equivalent to PIC. We also describe a generic algorithm for domain filtering consistencies in non-binary CSPs. We show how this algorithm can be instantiated to enforce some of the proposed consistencies and analyze the worst \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Om3gYEYAAAAJ:9ZlFYXVOiuMC",
            "Publisher": "World Scientific Publishing Company"
        },
        {
            "Title": "Extending generalized arc consistency",
            "Publication year": 2012,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-642-30448-4_22",
            "Abstract": "Generalized arc consistency (GAC) is the most widely used local consistency in constraint programming. Several GAC algorithms for specific constraints, as well as generic algorithms that can be used on any constraint, have been proposed in the literature. Stronger local consistencies than GAC have also been studied but algorithms for such consistencies are generally considered too expensive. In this paper we propose an extension to the standard GAC algorithm GAC2001/3.1 that achieves a stronger local consistency than GAC by considering intersections of constraints. Importantly, the worst-case time complexity of the proposed algorithm, called GAC+, is higher than that of GAC2001/3.1 only by a factor e, where e is the number of constraints in the problem. Experimental results demonstrate that in many cases GAC+ can reduce the size of the search tree compared to GAC, resulting in improved cpu \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Om3gYEYAAAAJ:L8Ckcad2t8MC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "Representation and reasoning with non-binary constraints",
            "Publication year": 2001,
            "Publication url": "http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.57.9559",
            "Abstract": "Many problems from the\\real world\" can be eciently expressed as constraint satisfaction problems (CSPs). Most of these can be naturally modelled using n-ary (or non-binary) constraints. Representing problems with n-ary constraints and reasoning with them is therefore very important in constraint satisfaction. However, issues regarding n-ary constraints have been neglected compared to binary constraints. The reasons were the simplicity of dealing with binary constraints compared to nary and the fact that any non-binary CSP can be encoded into an equivalent binary. This thesis makes an empirical and theoretical study on representation and solution methods for n-ary CSPs. The results we present demonstrate the importance of the choice of representation and reasoning techniques in n-ary problems.",
            "Abstract entirety": 1,
            "Author pub id": "Om3gYEYAAAAJ:kNdYIx-mwKoC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Fair resource allocation in a simple multi-agent setting: Search algorithms and experimental evaluation",
            "Publication year": 2005,
            "Publication url": "https://www.worldscientific.com/doi/abs/10.1142/S0218213005002454",
            "Abstract": "We study the problem of fair resource allocation in a simple cooperative multi-agent setting where we have k  agents and a set of n objects to be allocated to those  agents. Each object is associated with a weight represented  by a positive integer or real number. We would like to allocate  all objects to the agents so that each object is allocated to  only one agent and the weight is distributed fairly. We adopt  the fairness index popularized by the networking community as our measure of fairness, and study centralized algorithms for fair resource allocation. Based on the relationship between our problem and number partitioning, we devise a greedy algorithm for fair resource allocation that runs in polynomial time but is not guaranteed to find the optimal solution, and a complete anytime algorithm that finds the optimal solution but runs in exponential time. Then we study the phase transition behavior of the complete \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Om3gYEYAAAAJ:4DMP91E08xMC",
            "Publisher": "World Scientific Publishing Company"
        },
        {
            "Title": "Improving the Performance of maxRPC.",
            "Publication year": 2010,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-642-15396-9_9",
            "Abstract": "Max Restricted Path Consistency (maxRPC) is a local consistency for binary constraints that can achieve considerably stronger pruning than arc consistency. However, existing maxRPC algorithms suffer from overheads and redundancies as they can repeatedly perform many constraint checks without triggering any value deletions. In this paper we propose techniques that can boost the performance of maxRPC algorithms. These include the combined use of two data structures to avoid many redundant constraint checks, and heuristics for the efficient ordering and execution of certain operations. Based on these, we propose two closely related maxRPC algorithms. The first one has optimal O(end 3) time complexity, displays good performance when used stand-alone, but is expensive to apply during search. The second one has O(en 2 d 4) time complexity, but a restricted \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Om3gYEYAAAAJ:BqipwSGYUEgC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Introduction to the special issue on quantified CSPs and QBF",
            "Publication year": 2009,
            "Publication url": "https://link.springer.com/content/pdf/10.1007/s10601-008-9056-x.pdf",
            "Abstract": "Constraint satisfaction problems (CSPs) and satisfiability problem (SAT) are very successful frameworks that are used to model and solve a wide variety of combinatorial problems. However, there are classes of problems containing uncertainty that arise in areas such as contingent planning, adversarial game playing, control design, and model checking that cannot be expressed within these frameworks. Typically, such problems involve decisions or events that are beyond the control of the problem solving agent and thus cannot be handled using standard (existentially quantified) variables. Quantified CSPs and quantified Boolean formulae (QBF), which are the extensions of CSPs and SAT that allow for universally quantified variables, make it possible to model and reason with such problems, as well as other problems that contain \u201cbounded uncertainty\u201d. As a result, these frameworks have been attracting significant \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Om3gYEYAAAAJ:hFOr9nPyWt4C",
            "Publisher": "Springer US"
        },
        {
            "Title": "Using auxiliary variables and implied constraints to model non-binary problems",
            "Publication year": 2000,
            "Publication url": "https://www.aaai.org/Papers/AAAI/2000/AAAI00-028.pdf",
            "Abstract": "We perform an extensive theoretical and empirical analysis of the use of auxiliary variables and implied constraints in modelling a class of non-binary constraint satisfaction problems called problems of distance. This class of problems include 1-d, 2-d and circular Golomb rulers. We identify a large number of different models, both binary and non-binary, and compare theoretically the level of consistency achieved by generalized arc consistency on them. Our experiments show that the introduction of auxiliary variables and implied constraints can significantly reduce the size of the search space. For instance, our final models reduce the time to find an optimal 10-mark Golomb ruler 50-fold.",
            "Abstract entirety": 1,
            "Author pub id": "Om3gYEYAAAAJ:UeHWp8X0CEIC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Neighborhood singleton consistencies",
            "Publication year": 2019,
            "Publication url": "https://link.springer.com/content/pdf/10.1007/s10601-018-9298-1.pdf",
            "Abstract": "CP solvers predominantly use arc consistency (AC) as the default propagation method for binary constraints. Many stronger consistencies, such as triangle consistencies (e.g. RPC and maxRPC) exist, but their use is limited despite results showing that they outperform AC on many problems. This is due to the intricacies involved in incorporating them into solvers. On the other hand, singleton consistencies such as SAC can be easily crafted into solvers but they are too expensive in practice. Seeking a balance between the efficiency of triangle consistencies and the ease of implementation of singleton ones, we study the family of neighborhood singleton consistencies (NSCs) which extends the recently proposed neighborhood SAC (NSAC). We propose several new members of this family and study them both theoretically and experimentally. Our theroretical results show that the pruning power of the \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Om3gYEYAAAAJ:ns9cj8rnVeAC",
            "Publisher": "Springer US"
        },
        {
            "Title": "Preprocessing quantified constraint satisfaction problems with value reordering and directional arc and path consistency",
            "Publication year": 2008,
            "Publication url": "https://www.worldscientific.com/doi/abs/10.1142/S0218213008003911",
            "Abstract": "The Quantified Constraint Satisfaction Problem (QCSP) is an extension of the CSP that can be used to model combinatorial problems containing contingency or uncertainty. It allows for universally quantified variables that can model uncertain actions and events, such as the unknown weather for a future party, or an opponent's next move in a game. Although interest in QCSPs is increasing in recent years, the development of techniques for handling QCSPs is still at an early stage. For example, although it is well known that local consistencies are of primary importance in CSPs, only arc consistency has been extended to quantified problems. In this paper we contribute towards the development of solution methods for QCSPs in two ways. First, by extending directional arc and path consistency, two popular local consistencies in constraint satisfaction, to the quantified case and proposing an algorithm that achieves \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Om3gYEYAAAAJ:qUcmZB5y_30C",
            "Publisher": "World Scientific Publishing Company"
        },
        {
            "Title": "Repair-based methods for quantified CSPs",
            "Publication year": 2005,
            "Publication url": "https://link.springer.com/chapter/10.1007/11564751_48",
            "Abstract": "The Quantified CSP (QCSP) is a generalization of the CSP which allows for universally quantified variables. For each possible sequence of assignments to such variables, we have to find a way to set the values of the remaining, existentially quantified, variables so that all the constraints are satisfied. Such problems arise in areas such as planning under uncertainty, model checking, and adversary game playing. QCSPs are starting to attract interest following the development of numerous efficient solvers for the closely related area of QBF. Two approaches have been studied so far; the encoding of QCSPs into QBF, and the generalization of well-known search procedures for CSPs, like FC and MAC, to the quantified case. In this paper we introduce a new approach which utilizes repair-based techniques. We describe a framework for a QCSP solver in which complete and incomplete repair-based methods \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Om3gYEYAAAAJ:roLk4NBRz8UC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "Adaptive constraint propagation in constraint satisfaction: review and evaluation",
            "Publication year": 2021,
            "Publication url": "https://link.springer.com/article/10.1007/s10462-021-10012-4",
            "Abstract": "Several methods for dynamically adapting the local consistency property applied by a CP solver during search have been put forward in recent and older literature. We propose the classification of such methods in three categories depending on the level of granularity where decisions about which local consistency property to apply are taken: node, variable, and value oriented. We then present a detailed review of existing methods from each category, and evaluate them theoretically according to several criteria. Taking one recent representative method from each class, we then perform an experimental study. Results show that simple variable and value oriented methods are quite efficient when the older dom/ddeg heuristic is used for variable ordering, while a carefully tuned node oriented method does not seem to offer notable improvement compared to standard arc consistency propagation. In contrast, under the \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Om3gYEYAAAAJ:g5m5HwL7SMYC",
            "Publisher": "Springer Netherlands"
        },
        {
            "Title": "Constraint satisfaction in semi-structured data graphs",
            "Publication year": 2004,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-540-30201-8_30",
            "Abstract": "XML data can be modeled as node-labeled graphs and XML queries can be expressed by structural relationships between labeled elements. XML query evaluation has been addressed using mainly database, and in some cases graph search, techniques. We propose an alternative method that models and solves such queries as constraint satisfaction problems (CSPs). We describe common constraint types occurring in XML queries and show how query evaluation can benefit from methods for preprocessing and solving CSPs. We identify an important non-binary constraint that is a common module of XML queries and describe a generalized arc consistency algorithm with low cost that can ensure polynomial query evaluation. Finally, we demonstrate that maintaining the consistency of such non-binary constraints can greatly accelerate search in intractable queries that include referential relationships.",
            "Abstract entirety": 1,
            "Author pub id": "Om3gYEYAAAAJ:KlAtU1dfN6UC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "Solution directed backjumping for QCSP",
            "Publication year": 2007,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-540-74970-7_13",
            "Abstract": "In this paper we present new techniques for improving backtracking based Quantified Constraint Satisfaction Problem (QCSP) solvers. QCSP is a generalization of CSP in which variables are either universally or existentially quantified and these quantifiers can be alternated in arbitrary ways. Our main new technique is solution directed backjumping (SBJ). In analogue to conflict directed backjumping, SBJ allows the solver to backtrack out of solved sub-trees without having to find all of the distinct solutions normally required to validate the universal variables. Experiments with the solver QCSP-Solve demonstrate that SBJ can improve its performance on random instances by orders of magnitude. In addition to this contribution, we demonstrate that performing varying levels of propagation for universal vs. existential variables can also be useful for enhancing performance. Finally, we discuss some techniques \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Om3gYEYAAAAJ:RGFaLdJalmkC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "Solving non-binary CSPs using the hidden variable encoding",
            "Publication year": 2001,
            "Publication url": "https://link.springer.com/chapter/10.1007/3-540-45578-7_12",
            "Abstract": "Non-binary constraint satisfaction problems (CSPs) can be solved in two different ways. We can either translate the problem into an equivalent binary one and solve it using well-established binary CSP techniques or use extended versions of binary techniques directly on the non-binary problem. Recently, it has been shown that the hidden variable encoding is a promising method of translating non-binary CSPs into binary ones. In this paper we make a theoretical and empirical investigation of arc consistency and search algorithms for the hidden variable encoding. We analyze the potential benefits of applying arc consistency on the hidden encoding compared to generalized arc consistency on the non-binary representation. We also show that search algorithms for nonbinary constraints can be emulated by corresponding binary algorithms that operate on the hidden variable encoding and only instantiate \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Om3gYEYAAAAJ:hqOjcs7Dif8C",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "Building portfolios for parallel constraint solving by varying the local consistency applied",
            "Publication year": 2014,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/6984548/",
            "Abstract": "Portfolio based approaches to constraint solving aim at exploiting the variability in performance displayed by different solvers or different parameter settings of a single solver. Such approaches have been quite successful in both a sequential and a parallel processing mode. Given the increasingly larger number of available processors for parallel processing, an important challenge when designing portfolios is to identify solver parameters that offer diversity in the exploration of the search space and to generate different solver configurations by automatically tuning these parameters. In this paper we propose, for the first time, a way to build porfolios for parallel solving by parameter zing the local consistency property applied during search. To achieve this we exploit heuristics for adaptive propagation proposed in stergiou08. We show how this approach can result in the easy automatic generation of portfolios that \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Om3gYEYAAAAJ:ZeXyd9-uunAC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Exploiting constraint weights for revision ordering in Arc Consistency Algorithms",
            "Publication year": 2008,
            "Publication url": "http://users.uowm.gr/kstergiou/ECAIworkshop08.pdf",
            "Abstract": "Coarse grained arc consistency algorithms, like AC-3, operate by maintaining a list of arcs (or variables) that records the revisions that are still to be performed. It is well known that the performance of such algorithms is affected by the order in which revisions are carried out. As a result, several heuristics for ordering the elements of the revision list have been proposed. These heuristics exploit information about the original and the current state of the problem, such as domain sizes, variable degrees, and allowed combinations of values, to reduce the number of constraint checks and list operations aiming at speeding up arc consistency computation. Recently, Boussemart et al. proposed novel variable ordering heuristics that exploit information about failures gathered throughout search and recorded in the form of constraint weights. Such heuristics are now considered as the most efficient general purpose variable ordering heuristic for CSPs. In this paper we show how information about constraint weights can be exploited to efficiently order the revision list when AC is applied during search. We propose a number of simple revision ordering heuristics based on constraint weights for arc, variable, and constraint oriented implementations of coarse grained arc consistency algorithms, and compare them to the most efficient existing revision ordering heuristic. Importantly, the new heuristics can not only reduce the numbers of constraints checks and list operations, but also cut down the size of the explored search tree. Results from various structured and random problems demonstrate that some of the proposed heuristics can offer significant speed-ups.",
            "Abstract entirety": 1,
            "Author pub id": "Om3gYEYAAAAJ:3fE2CSJIrl8C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Algorithms for stochastic CSPs",
            "Publication year": 2006,
            "Publication url": "https://link.springer.com/chapter/10.1007/11889205_6",
            "Abstract": "The Stochastic CSP (SCSP) is a framework recently introduced by Walsh to capture combinatorial decision problems that involve uncertainty and probabilities. The SCSP extends the classical CSP by including both decision variables, that an agent can set, and stochastic variables that follow a probability distribution and can model uncertain events beyond the agent\u2019s control. So far, two approaches to solving SCSPs have been proposed; backtracking-based procedures that extend standard methods from CSPs, and scenario-based methods that solve SCSPs by reducing them to a sequence of CSPs. In this paper we further investigate the former approach. We first identify and correct a flaw in the forward checking (FC) procedure proposed by Walsh. We also extend FC to better take advantage of probabilities and thus achieve stronger pruning. Then we define arc consistency for SCSPs and introduce an \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Om3gYEYAAAAJ:YsMSGLbcyi4C",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "Revisiting restricted path consistency",
            "Publication year": 2017,
            "Publication url": "https://link.springer.com/article/10.1007/s10601-016-9255-9",
            "Abstract": "Restricted path consistency (RPC) is a strong local consistency for binary constraints that was proposed 20 years ago and was identified as a promising alternative to arc consistency (AC) in an early experimental study of local consistencies for binary constraints. However, in contrast to other strong local consistencies such as singleton arc consistency (SAC) and max restricted path consistency (maxRPC), it has been neglected since then. In this paper we revisit RPC. First we propose RPC3, a new RPC algorithm that is very easy to implement and can be efficiently applied throughout search. Then we perform a wide experimental study of RPC3 and a light version that achieves an approximation of RPC, comparing them to state-of-the-art AC and maxRPC algorithms. Experimental results obtained under various solver settings, regarding the branching scheme, the variable ordering heuristic, and restarts \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Om3gYEYAAAAJ:JV2RwH3_ST0C",
            "Publisher": "Springer US"
        },
        {
            "Title": "Partial Queries for Constraint Acquisition",
            "Publication year": 2020,
            "Publication url": "https://arxiv.org/abs/2003.06649",
            "Abstract": "Learning constraint networks is known to require a number of membership queries exponential in the number of variables. In this paper, we learn constraint networks by asking the user partial queries. That is, we ask the user to classify assignments to subsets of the variables as positive or negative. We provide an algorithm, called QUACQ, that, given a negative example, focuses onto a constraint of the target network in a number of queries logarithmic in the size of the example. The whole constraint network can then be learned with a polynomial number of partial queries. We give information theoretic lower bounds for learning some simple classes of constraint networks and show that our generic algorithm is optimal in some cases.",
            "Abstract entirety": 1,
            "Author pub id": "Om3gYEYAAAAJ:35N4QoGY0k4C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Experimental Evaluation of Modern Variable Selection Strategies in Constraint Satisfaction Problems.",
            "Publication year": 2008,
            "Publication url": "http://users.sch.gr/abalafoutis/pdf/RCRA2008.pdf",
            "Abstract": "Constraint programming is a powerful technique for solving combinatorial search problems that draws on a wide range of methods from artificial intelligence and computer science. Constraint solvers search the solution space either systematically, as with backtracking or branch and bound algorithms, or use forms of local search which may be incomplete. Systematic methods typically interleave search and inference. A key factor that can dramatically reduce the search space is the criterion under which we decide which variable will be the next to be instantiated. Numerous heuristics have been proposed for this purpose in the literature. Recent years have seen the emergence of new and powerful methods for choosing variables during CSP search. Some of these methods exploit information about failures gathered throughout search and recorded in the form of constraint weights, while others measure the importance/impact of variable assignments for reducing the search space. In this paper we experimentally evaluate the most recent and powerful variable ordering heuristics, and new variants of them, over a wide range of academic, random and real world problems. Results demonstrate that heuristics based on failures are in general faster. To be precise, heuristic dom/wdeg and its variants are the dominant heuristics in most instances tried.",
            "Abstract entirety": 1,
            "Author pub id": "Om3gYEYAAAAJ:YOwf2qJgpHMC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Structure-driven multiple constraint acquisition",
            "Publication year": 2019,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-030-30048-7_41",
            "Abstract": "MQuAcq is an algorithm for active constraint acquisition that has been shown to outperform previous algorithms such as QuAcq and MultiAcq. In this paper, we exhibit two important drawbacks of MQuAcq. First, for each negative example, the number of recursive calls to the main procedure of MQuAcq can be non-linear, making it impractical for large problems. Second, MQuAcq, as well as QuAcq and MultiAcq, does not take into account the structure of the learned problem. We propose MQuAcq-2, a new algorithm based on MQuAcq that integrates solutions to both these problems. MQuAcq-2 exploits the structure of the learned problem by focusing the queries it generates to quasi-cliques of constraints. When dealing with a negative query, it only requires a linear number of iterations. MQuAcq-2 outperforms MQuAcq, especially on large problems.",
            "Abstract entirety": 1,
            "Author pub id": "Om3gYEYAAAAJ:lSLTfruPkqcC",
            "Publisher": "Springer, Cham"
        },
        {
            "Title": "Experimental evaluation of branching schemes for the csp",
            "Publication year": 2010,
            "Publication url": "https://arxiv.org/abs/1009.0407",
            "Abstract": "The search strategy of a CP solver is determined by the variable and value ordering heuristics it employs and by the branching scheme it follows. Although the effects of variable and value ordering heuristics on search effort have been widely studied, the effects of different branching schemes have received less attention. In this paper we study this effect through an experimental evaluation that includes standard branching schemes such as 2-way, d-way, and dichotomic domain splitting, as well as variations of set branching where branching is performed on sets of values. We also propose and evaluate a generic approach to set branching where the partition of a domain into sets is created using the scores assigned to values by a value ordering heuristic, and a clustering algorithm from machine learning. Experimental results demonstrate that although exponential differences between branching schemes, as predicted in theory between 2-way and d-way branching, are not very common, still the choice of branching scheme can make quite a difference on certain classes of problems. Set branching methods are very competitive with 2-way branching and outperform it on some problem classes. A statistical analysis of the results reveals that our generic clustering-based set branching method is the best among the methods compared.",
            "Abstract entirety": 1,
            "Author pub id": "Om3gYEYAAAAJ:4TOpqqG69KYC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Domain filtering consistencies for non-binary constraints",
            "Publication year": 2008,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S0004370207001610",
            "Abstract": "In non-binary constraint satisfaction problems, the study of local consistencies that only prune values from domains has so far been largely limited to generalized arc consistency or weaker local consistency properties. This is in contrast with binary constraints where numerous such domain filtering consistencies have been proposed. In this paper we present a detailed theoretical, algorithmic and empirical study of domain filtering consistencies for non-binary problems. We study three domain filtering consistencies that are inspired by corresponding variable based domain filtering consistencies for binary problems. These consistencies are stronger than generalized arc consistency, but weaker than pairwise consistency, which is a strong consistency that removes tuples from constraint relations. Among other theoretical results, and contrary to expectations, we prove that these new consistencies do not reduce to the \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Om3gYEYAAAAJ:qjMakFHDy7sC",
            "Publisher": "Elsevier"
        },
        {
            "Title": "New algorithms for max restricted path consistency",
            "Publication year": 2011,
            "Publication url": "https://link.springer.com/content/pdf/10.1007/s10601-011-9110-y.pdf",
            "Abstract": "Max Restricted Path Consistency (maxRPC) is a local consistency for binary constraints that enforces a higher order of consistency than arc consistency. Despite the strong pruning that can be achieved, maxRPC is rarely used because existing maxRPC algorithms suffer from overheads and redundancies as they can repeatedly perform many constraint checks without triggering any value deletions. In this paper we propose and evaluate techniques that can boost the performance of maxRPC algorithms by eliminating many of these overheads and redundancies. These include the combined use of two data structures to avoid many redundant constraint checks, and the exploitation of residues to quickly verify the existence of supports. Based on these, we propose a number of closely related maxRPC algorithms. The first one, maxRPC3, has optimal O(end 3) time complexity, displays good \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Om3gYEYAAAAJ:YFjsv_pBGBYC",
            "Publisher": "Springer Netherlands"
        },
        {
            "Title": "Using Parallelization to Efficiently Exploit the Pruning Power of Strong Local Consistencies",
            "Publication year": 2016,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/2903220.2903228",
            "Abstract": "Local consistencies stronger than arc consistency have received a lot of attention since the early days of CSP research because of the strong pruning they can achieve. However, they have not been widely adopted by CSP solvers. This is because applying such consistencies can sometimes result in considerably smaller search tree sizes and therefore in important speed-ups, but in other cases the search space reduction may be small, causing severe run time penalties. Taking advantage of recent advances in parallelization, we propose a novel approach for the application of strong local consistencies that can improve their performance by largely preserving the speed-ups they offer in cases where they are successful, and eliminating the run time penalties in cases where they are unsuccessful. This approach is presented in the form of a search algorithm consisting of a master search process, which is a typical \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Om3gYEYAAAAJ:M3NEmzRMIkIC",
            "Publisher": "Unknown"
        },
        {
            "Title": "An efficient higher-order consistency algorithm for table constraints",
            "Publication year": 2012,
            "Publication url": "https://ojs.aaai.org/index.php/AAAI/article/view/8135",
            "Abstract": "Table constraints are very important in constraint programming as they are present in many real problems from areas such as configuration and databases. As a result, numerous specialized algorithms that achieve generalized arc consistency (GAC) on table constraints have been proposed. Since these algorithms achieve GAC, they operate on one constraint at a time. In this paper we propose an efficient algorithm for table constraints that achieves a stronger local consistency than GAC. This algorithm, called maxRPWC+, is based on the local consistency maxRPWC and allows the efficient handling of intersecting table constraints. Experimental results from benchmark problems demonstrate that maxRPWC+ is clearly more robust than a state-of-the-art GAC algorithm in classes of problems with interleaved table constraints, being orders of magnitude faster in some of these classes.",
            "Abstract entirety": 1,
            "Author pub id": "Om3gYEYAAAAJ:5nxA0vEk-isC",
            "Publisher": "Unknown"
        },
        {
            "Title": "QCSP-Solve: A solver for quantified constraint satisfaction problems",
            "Publication year": 2005,
            "Publication url": "https://www.ijcai.org/Proceedings/05/Papers/0754.pdf",
            "Abstract": "The Quantified Constraint Satisfaction Problem (QCSP) is a generalization of the CSP in which some variables are universally quantified. It has been shown that a solver based on an encoding of QCSP into QBF can outperform the existing direct QCSP approaches by several orders of magnitude. In this paper we introduce an efficient QCSP solver. We show how knowledge learned from the successful encoding of QCSP into QBF can be utilized to enhance the existing QCSP techniques and speed up search by orders of magnitude. We also show how the performance of the solver can be further enhanced by incorporating advanced lookback techniques such as CBJ and solution-directed pruning. Experiments demonstrate that our solver is several orders of magnitude faster than existing direct approaches to QCSP solving, and significantly outperforms approaches based on encoding QCSPs as QBFs.",
            "Abstract entirety": 1,
            "Author pub id": "Om3gYEYAAAAJ:9yKSN-GCB0IC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Backtracking algorithms for disjunctions of temporal constraints",
            "Publication year": 2000,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S0004370200000199",
            "Abstract": "We extend the framework of simple temporal problems studied originally by Dechter, Meiri and Pearl to consider constraints of the form x 1\u2212 y 1\u2264 r 1\u2228\u22ef\u2228 x n\u2212 y n\u2264 r n, where x 1,\u2026, x n, y 1,\u2026, y n are variables ranging over the real numbers, r 1,\u2026, r n are real constants, and n\u2265 1. This is a wide class of temporal constraints that can be used to model a variety of problems in temporal reasoning, scheduling, planning, and temporal constraint databases. We have implemented several progressively more efficient algorithms for the consistency checking problem for this class of temporal constraints: backtracking, backjumping, three variations of forward checking, and forward checking with backjumping. We have partially ordered the above algorithms according to the number of visited search nodes and the number of performed consistency checks. Although our problem is non-binary, our results agree with the results \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Om3gYEYAAAAJ:u5HHmVD_uO8C",
            "Publisher": "Elsevier"
        },
        {
            "Title": "Algorithms for quantified constraint satisfaction problems",
            "Publication year": 2004,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-540-30201-8_60",
            "Abstract": "Many propagation and search algorithms have been developed for constraint satisfaction problems (CSPs). In a standard CSP all variables are existentially quantified. The CSP formalism can be extended to allow universally quantified variables, in which case the complexity of the basic reasoning tasks rises from NP-complete to PSPACE-complete. Such problems have, so far, been studied mainly in the context of quantified Boolean formulae. Little work has been done on problems with discrete non-Boolean domains. We attempt to fill this gap by extending propagation and search algorithms from standard CSPs to the quantified case. We also show how the notion of value interchangeability can be exploited to break symmetries and speed up search by orders of magnitude. Finally, we test experimentally the algorithms and methods proposed.",
            "Abstract entirety": 1,
            "Author pub id": "Om3gYEYAAAAJ:zYLM7Y9cAGgC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "Efficient methods for constraint acquisition",
            "Publication year": 2018,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-319-98334-9_25",
            "Abstract": "Constraint acquisition systems such as QuAcq and MultiAcq can assist non-expert users to model their problems as constraint networks by classifying (partial) examples as positive or negative. For each negative example, the former focuses on one constraint of the target network, while the latter can learn a maximum number of constraints. Two bottlenecks of the acquisition process where both these algorithms encounter problems are the large number of queries required to reach convergence, and the high cpu times needed to generate queries, especially near convergence. We propose methods that deal with both these issues. The first one is an algorithm that blends the main idea of MultiAcq into QuAcq resulting in a method that learns as many constraints as MultiAcq does after a negative example, but with a lower complexity. The second is a technique that helps reduce the number of queries \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Om3gYEYAAAAJ:O3NaXMp0MMsC",
            "Publisher": "Springer, Cham"
        },
        {
            "Title": "Evaluating and improving modern variable and revision ordering strategies in CSPs",
            "Publication year": 2010,
            "Publication url": "https://content.iospress.com/articles/fundamenta-informaticae/fi102-3-4-02",
            "Abstract": "A key factor that can dramatically reduce the search space during constraint solving is the criterion under which the variable to be instantiated next is selected. For this purpose numerous heuristics have been proposed. Some of the best of such heuristics exploit information about failures gathered throughout search and recorded in the form of constraint weights, while others measure the importance of variable assignments in reducing the search space. In this work we experimentally evaluate the most recent and powerful variable ordering heuristics, and new variants of them, over a wide range of benchmarks. Results demonstrate that heuristics based on failures are in general more efficient. Based on this, we then derive new revision ordering heuristics that exploit recorded failures to efficiently order the propagation list when arc consistency is maintained during search. Interestingly, in addition to reducing the \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Om3gYEYAAAAJ:qxL8FJ1GzNcC",
            "Publisher": "IOS Press"
        },
        {
            "Title": "Learning how to propagate using random probing",
            "Publication year": 2009,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-642-01929-6_20",
            "Abstract": "In constraint programming there are often many choices regarding the propagation method to be used on the constraints of a problem. However, simple constraint solvers usually only apply a standard method, typically (generalized) arc consistency, on all constraints throughout search. Advanced solvers additionally allow for the modeler to choose among an array of propagators for certain (global) constraints. Since complex interactions exist among constraints, deciding in the modelling phase which propagation method to use on given constraints can be a hard task that ideally we would like to free the user from. In this paper we propose a simple technique towards the automation of this task. Our approach exploits information gathered from a random probing preprocessing phase to automatically decide on the propagation method to be used on each constraint. As we demonstrate, data gathered though \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Om3gYEYAAAAJ:0EnyYjriUFMC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "Worst case examples of an exterior point algorithm for the assignment problem",
            "Publication year": 2008,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S1572528608000030",
            "Abstract": "An efficient exterior point simplex type algorithm for the assignment problem has been developed by Paparrizos [K. Paparrizos, An infeasible (exterior point) simplex algorithm for assignment problems, Math. Program. 51 (1991) 45\u201354]. This algorithm belongs to the category of forest algorithms and solves an n\u00d7 n assignment problem in at most n (n\u2212 1) 2 iterations and in at most O (n 3) time. In this paper worst case examples are presented. Specifically, a systematic procedure to construct worst case assignment problems is presented for the exterior point algorithm. The algorithm applied to these examples executes exactly n (n\u2212 1) 2 iterations. This result verifies that the bound O (n 3) is the best possible for the above-mentioned algorithm.",
            "Abstract entirety": 1,
            "Author pub id": "Om3gYEYAAAAJ:maZDTaKrznsC",
            "Publisher": "Elsevier"
        },
        {
            "Title": "Decomposable constraints",
            "Publication year": 2000,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S0004370200000515",
            "Abstract": "Many constraint satisfaction problems can be naturally and efficiently modelled using non-binary constraints like the \u201call-different\u201d and \u201cglobal cardinality\u201d constraints. Certain classes of these non-binary constraints are \u201cnetwork decomposable\u201d as they can be represented by binary constraints on the same set of variables. We compare theoretically the levels of consistency which are achieved on non-binary constraints to those achieved on their binary decomposition. We present many results about the level of consistency achieved by the forward checking algorithm and its various generalizations to non-binary constraints. We also compare the level of consistency achieved by arc-consistency and its generalization to non-binary constraints, and identify special cases of non-binary decomposable constraints where weaker or stronger conditions, than in the general case, hold. We also analyze the cost, in consistency \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Om3gYEYAAAAJ:W7OEmFMy1HYC",
            "Publisher": "Elsevier"
        },
        {
            "Title": "Towards automatic of domain ontologies: the HCONE-merge approach",
            "Publication year": 2005,
            "Publication url": "https://scholar.google.com/scholar?cluster=16751606353987328143&hl=en&oi=scholarr",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "Om3gYEYAAAAJ:NaGl4SEjCO4C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Learning Max-CSPs via Active Constraint Acquisition",
            "Publication year": 2021,
            "Publication url": "https://drops.dagstuhl.de/opus/volltexte/2021/15345/",
            "Abstract": "Constraint acquisition can assist non-expert users to model their problems as constraint networks. In active constraint acquisition, this is achieved through an interaction between the learner, who posts examples, and the user who classifies them as solutions or not. Although there has been recent progress in active constraint acquisition, the focus has only been on learning satisfaction problems with hard constraints. In this paper, we deal with the problem of learning soft constraints in optimization problems via active constraint acquisition, specifically in the context of the Max-CSP. Towards this, we first introduce a new type of queries in the context of constraint acquisition, namely partial preference queries, and then we present a novel algorithm for learning soft constraints in Max-CSPs, using such queries. We also give some experimental results.",
            "Abstract entirety": 1,
            "Author pub id": "Om3gYEYAAAAJ:SeFeTyx0c_EC",
            "Publisher": "Schloss Dagstuhl-Leibniz-Zentrum f\u00fcr Informatik"
        },
        {
            "Title": "Arc consistency in binary encodings of Non-binary CSPs: Theoretical and experimental evaluation",
            "Publication year": 2004,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-540-24674-9_37",
            "Abstract": "A Non-binary Constraint Satisfaction Problem (CSP) can be solved by converting the problem into an equivalent binary one and applying well-established binary CSP techniques. An alternative way is to use extended versions of binary techniques directly on the non-binary problem. There are two well-known computational methods in the literature for translating a non-binary CSP to an equivalent binary CSP; (i) the hidden variable encoding and (ii) the dual encoding. In this paper we make a theoretical and empirical study of arc consistency for the binary encodings. An arc consistency algorithm for the hidden variable encoding with optimal O(ekd  k ) worst-case time complexity is presented. This algorithm is compared theoretically and empirically to an optimal generalized arc consistency algorithm that operates on the non-binary representation. We also describe an arc \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Om3gYEYAAAAJ:iH-uZ7U-co4C",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "Extending STR to a higher-order consistency",
            "Publication year": 2013,
            "Publication url": "https://ojs.aaai.org/index.php/AAAI/article/view/8622",
            "Abstract": "One of the most widely studied classes of constraints in constraint programming (CP) is that of table constraints. Numerousspecialized filtering algorithms, enforcing the wellknown property called generalized arc consistency (GAC), have been developed for such constraints. Among the most successful GAC algorithms for table constraints, we find variants of simple tabular reduction (STR), like STR2. In this paper, we propose an extension of STR-based algorithms that achieves full pairwise consistency (FPWC), a consistency stronger than GAC and max restricted pairwise consistency (maxRPWC). Our approach involves counting the number of occurrences of specific combinations of values in constraint intersections. Importantly, the worst-case time complexity of one call to the basic filtering procedure at the heart of our new algorithm is quite close to that of STR algorithms. Experiments demonstrate that our method can outperform STR2 in many classes of problems, being significantly faster in some cases. Also, it is clearly superior to maxRPWC+, an algorithm that has been recently proposed.",
            "Abstract entirety": 1,
            "Author pub id": "Om3gYEYAAAAJ:8k81kl-MbHgC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Exploiting the Pruning Power of Strong Local Consistencies Through Parallelization",
            "Publication year": 2017,
            "Publication url": "https://arxiv.org/abs/1705.05316",
            "Abstract": "Local consistencies stronger than arc consistency have received a lot of attention since the early days of CSP research. %because of the strong pruning they can achieve. However, they have not been widely adopted by CSP solvers. This is because applying such consistencies can sometimes result in considerably smaller search tree sizes and therefore in important speed-ups, but in other cases the search space reduction may be small, causing severe run time penalties. Taking advantage of recent advances in parallelization, we propose a novel approach for the application of strong local consistencies (SLCs) that can improve their performance by largely preserving the speed-ups they offer in cases where they are successful, and eliminating the run time penalties in cases where they are unsuccessful. This approach is presented in the form of two search algorithms. Both algorithms consist of a master search process, which is a typical CSP solver, and a number of slave processes, with each one implementing a SLC method. The first algorithm runs the different SLCs synchronously at each node of the search tree explored in the master process, while the second one can run them asynchronously at different nodes of the search tree. Experimental results demonstrate the benefits of the proposed method.",
            "Abstract entirety": 1,
            "Author pub id": "Om3gYEYAAAAJ:hMod-77fHWUC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Inverse consistencies for non-binary constraints",
            "Publication year": 2006,
            "Publication url": "https://books.google.com/books?hl=en&lr=&id=qNTvAgAAQBAJ&oi=fnd&pg=PA153&dq=info:EiYrkNw24xMJ:scholar.google.com&ots=QV6bLpCd4x&sig=J1Dfqy74BlliIdqoEp14tYqrGSA",
            "Abstract": "We present a detailed study of two inverse consistencies for non-binary constraints: relational path inverse consistency (rel PIC) and pairwise inverse consistency (PWIC). These are stronger than generalized arc consistency (GAC), even though they also only prune domain values. We propose algorithms to achieve rel PIC and PWIC, that have a time complexity better than the previous generic algorithm for inverse consistencies. One of our algorithms for PWIC has a complexity comparable to that for GAC despite doing more pruning. Our experiments demonstrate that inverse consistencies can be more efficient than GAC on a range of non-binary problems.",
            "Abstract entirety": 1,
            "Author pub id": "Om3gYEYAAAAJ:Se3iqnhoufwC",
            "Publisher": "IOS Press"
        },
        {
            "Title": "Omissions in Constraint Acquisition",
            "Publication year": 2020,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-030-58475-7_54",
            "Abstract": "Interactive constraint acquisition is a special case of query-directed learning, also known as \u201cexact\u201d learning. It is used to assist non-expert users in modeling a constraint problem automatically by posting examples to the user that have to be classified as solutions or non-solutions. One significant issue that has not been addressed in the literature of constraint acquisition is the possible presence of uncertainty in the answers of the users. We address this by introducing Limited Membership Queries, where the user has the option of replying \u201cI don\u2019t know\u201d, corresponding to \u201comissions\u201d in exact learning. We present two algorithms for handling omissions. The first one deals with omissions that are independent events, while the second assumes that omissions are related to gaps in the user\u2019s knowledge. We present theoretical results about both methods and we evaluate them on benchmark problems. Importantly, our \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Om3gYEYAAAAJ:2P1L_qKh6hAC",
            "Publisher": "Springer, Cham"
        },
        {
            "Title": "On Conflict-driven variable ordering heuristics",
            "Publication year": 2008,
            "Publication url": "https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.330.6667&rep=rep1&type=pdf",
            "Abstract": "It is well known that the order in which variables are instantiated by a backtracking search algorithm can make an enormous difference to the search effort in solving CSPs. Among the plethora of heuristics that have been proposed in the literature to efficiently order variables during search, a significant recently proposed class uses the learning-from-failure approach. Prime examples of such heuristics are the wdeg and dom/wdeg heuristics of Boussemart et al. which store and exploit information about failures in the form of constraint weights. The efficiency of all the proposed conflict-directed heuristics is due to their ability to learn though conflicts encountered during search. As a result, they can guide search towards hard parts of the problem and identify contentious constraints. Such heuristics are now considered as the most efficient general purpose variable ordering heuristic for CSPs. In this paper we show how information about constraint weights can be used in order to create several new variants of the wdeg and dom/wdeg heuristics. The proposed conflict-driven variable ordering heuristics have been tested over a wide range of benchmarks. Experimental results show that they are quite competitive compared to existing ones and in some cases they can increase efficiency.",
            "Abstract entirety": 1,
            "Author pub id": "Om3gYEYAAAAJ:Zph67rFs4hoC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Conflict directed variable selection strategies for constraint satisfaction problems",
            "Publication year": 2010,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-642-12842-4_7",
            "Abstract": "It is well known that the order in which variables are instantiated by a backtracking search algorithm can make an enormous difference to the search effort in solving CSPs. Among the plethora of heuristics that have been proposed in the literature to efficiently order variables during search, a significant recently proposed class uses the learning-from-failure approach. Prime examples of such heuristics are the wdeg and dom/wdeg heuristics of Boussemart et al. which store and exploit information about failures in the form of constraint weights. The efficiency of all the proposed conflict-directed heuristics is due to their ability to learn though conflicts encountered during search. As a result, they can guide search towards hard parts of the problem and identify contentious constraints. Such heuristics are now considered as the most efficient general purpose variable ordering heuristic for CSPs. In this paper we \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Om3gYEYAAAAJ:QIV2ME_5wuYC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "Heuristics for dynamically adapting propagation",
            "Publication year": 2008,
            "Publication url": "https://ebooks.iospress.nl/volumearticle/4418",
            "Abstract": "Building adaptive constraint solvers is a major challenge in constraint programming. An important line of research towards this goal is concerned with ways to dynamically adapt the level of local consistency applied during search. A related problem that is receiving a lot of attention is the design of adaptive branching heuristics. The recently proposed adaptive variable ordering heuristics of Boussemart et al. use information derived from domain wipeouts to identify highly active constraints and focus search on hard parts of the problem resulting in important saves in search effort. In this paper we show how information about domain wipeouts and value deletions gathered during search can be exploited, not only to perform variable selection, but also to dynamically adapt the level of constraint propagation achieved on the constraints of the problem. First we demonstrate that when an adaptive heuristic is used, value \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Om3gYEYAAAAJ:WF5omc3nYNoC",
            "Publisher": "IOS Press"
        },
        {
            "Title": "Overlay networks for task allocation and coordination in large-scale networks of cooperative agents",
            "Publication year": 2012,
            "Publication url": "https://link.springer.com/article/10.1007/s10458-010-9143-4",
            "Abstract": "This paper proposes a novel method for scheduling and allocating atomic and complex tasks in large-scale networks of homogeneous or heterogeneous cooperative agents. Our method encapsulates the concepts of searching, task allocation and scheduling seamlessly in a decentralized process where no accumulated or centralized knowledge or coordination is necessary. Efficient searching for agent groups that can facilitate the scheduling of tasks is accomplished through the use of a dynamic overlay structure of gateway agents and the exploitation of routing indices. The task allocation and the scheduling of complex tasks are accomplished by combining dynamic reorganization of agent groups and distributed constraint optimization methods. Experimental results display the efficiency of the proposed method.",
            "Abstract entirety": 1,
            "Author pub id": "Om3gYEYAAAAJ:Wp0gIr-vW9MC",
            "Publisher": "Springer US"
        },
        {
            "Title": "Adaptive branching for constraint satisfaction problems",
            "Publication year": 2010,
            "Publication url": "https://arxiv.org/abs/1008.0660",
            "Abstract": "The two standard branching schemes for CSPs are d-way and 2-way branching. Although it has been shown that in theory the latter can be exponentially more effective than the former, there is a lack of empirical evidence showing such differences. To investigate this, we initially make an experimental comparison of the two branching schemes over a wide range of benchmarks. Experimental results verify the theoretical gap between d-way and 2-way branching as we move from a simple variable ordering heuristic like dom to more sophisticated ones like dom/ddeg. However, perhaps surprisingly, experiments also show that when state-of-the-art variable ordering heuristics like dom/wdeg are used then d-way can be clearly more efficient than 2-way branching in many cases. Motivated by this observation, we develop two generic heuristics that can be applied at certain points during search to decide whether 2-way branching or a restricted version of 2-way branching, which is close to d-way branching, will be followed. The application of these heuristics results in an adaptive branching scheme. Experiments with instantiations of the two generic heuristics confirm that search with adaptive branching outperforms search with a fixed branching scheme on a wide range of problems.",
            "Abstract entirety": 1,
            "Author pub id": "Om3gYEYAAAAJ:_kc_bZDykSQC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Binary encodings of non-binary constraint satisfaction problems: Algorithms and experimental results",
            "Publication year": 2005,
            "Publication url": "https://www.jair.org/index.php/jair/article/view/10428",
            "Abstract": "A non-binary Constraint Satisfaction Problem (CSP) can be solved directly using extended versions of binary techniques. Alternatively, the non-binary problem can be translated into an equivalent binary one. In this case, it is generally accepted that the translated problem can be solved by applying well-established techniques for binary CSPs. In this paper we evaluate the applicability of the latter approach. We demonstrate that the use of standard techniques for binary CSPs in the encodings of non-binary problems is problematic and results in models that are very rarely competitive with the non-binary representation. To overcome this, we propose specialized arc consistency and search algorithms for binary encodings, and we evaluate them theoretically and empirically. We consider three binary representations; the hidden variable encoding, the dual encoding, and the double encoding. Theoretical and empirical results show that, for certain classes of non-binary constraints, binary encodings are a competitive option, and in many cases, a better one than the non-binary representation.",
            "Abstract entirety": 1,
            "Author pub id": "Om3gYEYAAAAJ:-f6ydRqryjwC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Singleton consistencies",
            "Publication year": 2000,
            "Publication url": "https://link.springer.com/chapter/10.1007/3-540-45349-0_26",
            "Abstract": "We perform a comprehensive theoretical and empirical study of the benefits of singleton consistencies. Our theoretical results help place singleton consistencies within the hierarchy of local consistencies. To determine the practical value of these theoretical results, we measured the cost-effectiveness of pre-processing with singleton consistency algorithms. Our experiments use both random and structured problems. Whilst pre-processing with singleton consistencies is not in general beneficial for random problems, it starts to pay off when randomness and structure are combined, and it is very worthwhile with structured problems like Golomb rulers. On such problems, pre-processing with consistency techniques as strong as singleton generalized arc-consistency (the singleton extension of generalized arc-consistency) can reduce runtimes. We also show that limiting algorithms that enforce singleton \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Om3gYEYAAAAJ:u-x6o8ySG0sC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "A Study of SAT-Based Branching Heuristics for the CSP",
            "Publication year": 2008,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-540-87881-0_5",
            "Abstract": "Constraint Satisfaction Problems (CSPs) and Propositional Satisfiability (SAT) are two closely related frameworks used for solving hard combinatorial problems. Despite their similarities regarding the problem formulation and the basic backtracking search algorithms they use, several advanced techniques have been developed and standardized in one framework but have been rather ignored in the other. One class of such techniques includes branching heuristics for variable and value ordering. Typically, SAT heuristics are highly sophisticated while CSP ones tend to be simplistic. In this paper we study some well known SAT heuristics with the aim of transferring them to the CSP framework. Through this attempt, new CSP branching techniques are developed; exploiting information not used by most of the standard CSP heuristics. For instance such information can be the arity of the constraints and the \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Om3gYEYAAAAJ:dhFuZR0502QC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "Methods for Parallelizing Constraint Propagation through the Use of Strong Local Consistencies",
            "Publication year": 2018,
            "Publication url": "https://www.worldscientific.com/doi/abs/10.1142/S0218213018600023",
            "Abstract": "Constraint programming (CP) is a powerful paradigm for various types of hard combinatorial problems. Constraint propagation techniques, such as arc consistency (AC), are used within solvers to prune inconsistent values from the domains of the variables and narrow down the search space. Local consistencies stronger than AC have the potential to prune the search space even more, but they are not widely used because they incur a high run time penalty in cases where they are unsuccessful. All constraint propagation techniques are sequential by nature, and thus they cannot be scaled up to modern multicore machines. For this reason, research on parallelizing constraint propagation is very limited. Contributing towards this direction, we exploit the parallelization possibilities of modern CPUs in tandem with strong local propagation methods in a novel way. Instead of trying to parallelize constraint propagation \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Om3gYEYAAAAJ:GnPB-g6toBAC",
            "Publisher": "World Scientific Publishing Company"
        },
        {
            "Title": "Capturing semantics towards automatic coordination of domain ontologies",
            "Publication year": 2004,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-540-30106-6_3",
            "Abstract": "Existing efforts on ontology mapping, alignment and merging vary from methodological and theoretical frameworks, to methods and tools that support the semi-automatic coordination of ontologies. However, only latest research efforts \u201ctouch\u201d on the mapping /merging of ontologies using the whole breadth of available knowledge. Addressing this issue, the work presented in this paper is based on the HCONE-merge approach that makes use of the intended informal interpretations of concepts by mapping them to WordNet senses using lexical semantic indexing (LSI). Our aim is to explore the level of human involvement required for mapping concepts of the source ontologies to their intended interpretations. We propose a series of methods for ontology mapping/merging with varying degrees of human involvement and evaluate them experimentally. We conclude that, although an effective fully automated \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Om3gYEYAAAAJ:_FxGoFyzp5QC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "Decomposable constraints\u2606\u2606 Supported by EPSRC award GR/L/24014. The authors wish to thank other members of the APES research group",
            "Publication year": 2000,
            "Publication url": "https://philpapers.org/rec/GENDCB",
            "Abstract": "Ian Gent, Kostas Stergiou & Toby Walsh, Decomposable constraints\u2606\u2606Supported by EPSRC \naward GR/L/24014. The authors wish to thank other members of the APES research group - \nPhilPapers Sign in | Create an account PhilPapers PhilPeople PhilArchive PhilEvents PhilJobs \nPhilPapers home Syntax Advanced Search Syntax Advanced Search Syntax Advanced Search \nDecomposable constraints\u2606\u2606Supported by EPSRC award GR/L/24014. The authors wish to \nthank other members of the APES research group Ian Gent, Kostas Stergiou & Toby Walsh \nArtificial Intelligence 123 (1-2):133-156 (2000) Abstract This article has no associated abstract. \n(fix it) Keywords No keywords specified (fix it) Categories Science, Logic, and Mathematics \n(categorize this paper) DOI 10.1016/s0004-3702(00)00051-5 Options Edit this record \nMark as duplicate Export citation Find it on Scholar Request removal from index Revision : \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Om3gYEYAAAAJ:M05iB0D1s5AC",
            "Publisher": "Unknown"
        },
        {
            "Title": "of Domain Ontologies",
            "Publication year": 2004,
            "Publication url": "https://scholar.google.com/scholar?cluster=4940644320379611924&hl=en&oi=scholarr",
            "Abstract": "Existing efforts on ontology mapping, alignment and merging vary from methodological and theoretical frameworks, to methods and tools that support the semi-automatic coordination of ontologies. However, only latest re-search efforts\" touch\" on the mapping/merging of ontologies using the whole breadth of available knowledge. Addressing this issue, the work presented in this paper is based on the HCONE-merge approach that makes use of the intended informal interpretations of concepts by mapping them to WordNet senses using lexical semantic indexing (LSI). Our aim is to explore the level of human involvement required for mapping concepts of the source ontologies to their intended interpretations. We propose a series of methods for ontology mapping/merging with varying degrees of human involvement and evaluate them experimentally. We conclude that, although an effective fully automated process is not attainable, we can reach a point where the process of ontology mapping/merging can be carried out efficiently with minimum human involve-ment.",
            "Abstract entirety": 1,
            "Author pub id": "Om3gYEYAAAAJ:pqnbT2bcN3wC",
            "Publisher": "North Holland"
        }
    ]
}]