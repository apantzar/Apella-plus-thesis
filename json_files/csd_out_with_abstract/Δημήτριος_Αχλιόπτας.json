[{
    "name": "\u0394\u03b7\u03bc\u03ae\u03c4\u03c1\u03b9\u03bf\u03c2 \u0391\u03c7\u03bb\u03b9\u03cc\u03c0\u03c4\u03b1\u03c2",
    "romanize name": "Dimitrios Achlioptas",
    "School-Department": "\u03a0\u03bb\u03b7\u03c1\u03bf\u03c6\u03bf\u03c1\u03b9\u03ba\u03ae\u03c2 \u03ba\u03b1\u03b9 \u0395\u03c0\u03b9\u03ba\u03bf\u03b9\u03bd\u03c9\u03bd\u03b9\u03ce\u03bd",
    "University": "uoa",
    "Rank": "\u039a\u03b1\u03b8\u03b7\u03b3\u03b7\u03c4\u03ae\u03c2",
    "Apella_id": 19967,
    "Scholar name": "Dimitris Achlioptas",
    "Scholar id": "GBQ6w8IAAAAJ",
    "Affiliation": "Professor of Computer Science, University of Athens",
    "Citedby": 10565,
    "Interests": [
        "Randomized Algorithms",
        "Machine Learning",
        "Random Structures"
    ],
    "Scholar url": "https://scholar.google.com/citations?user=GBQ6w8IAAAAJ&hl=en",
    "Publications": [
        {
            "Title": "Partitioning social networks",
            "Publication year": 2010,
            "Publication url": "https://patents.google.com/patent/US7668957B2/en",
            "Abstract": "The present invention provides a unique system and method that facilitates reducing network traffic between a plurality of servers located on a social-based network. The system and method involve identifying a plurality of vertices or service users on the network with respect to their server or network locations. The vertices' contacts or connections can be located or determined as well. In order to minimize communication traffic, the vertices and their connections with respect to their respective server locations can be analyzed to determine whether at least a subset of nodes should be moved or relocated to another server to facilitate mitigating network traffic while balancing user load among the various servers or parts of the network. Thus, an underlying social network can be effectively partitioned. In addition, the network can be parsed into a collection of nested layers, whereby each successively less dense layer can \u2026",
            "Abstract entirety": 0,
            "Author pub id": "GBQ6w8IAAAAJ:KxtntwgDAa4C",
            "Publisher": "Unknown"
        },
        {
            "Title": "On spectral learning of mixtures of distributions",
            "Publication year": 2005,
            "Publication url": "https://link.springer.com/chapter/10.1007/11503415_31",
            "Abstract": "We consider the problem of learning mixtures of distributions via spectral methods and derive a characterization of when such methods are useful. Specifically, given a mixture-sample, let  denote the empirical mean, covariance matrix, and mixing weight of the samples from the i-th component. We prove that a very simple algorithm, namely spectral projection followed by single-linkage clustering, properly classifies every point in the sample provided that each pair of means  is well separated, in the sense that  is at least  plus a term that depends on the concentration properties of the distributions in the mixture. This second term is very small for many distributions, including Gaussians, Log-concave, and many others. As a result, we get the best known bounds for learning mixtures of arbitrary Gaussians in terms of the required mean separation. At the same time, we prove \u2026",
            "Abstract entirety": 0,
            "Author pub id": "GBQ6w8IAAAAJ:g5m5HwL7SMYC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "Random matrices in data analysis",
            "Publication year": 2004,
            "Publication url": "https://link.springer.com/content/pdf/10.1007/978-3-540-30115-8_1.pdf",
            "Abstract": "We show how carefully crafted random matrices can achieve distance-preserving dimensionality reduction, accelerate spectral computations, and reduce the sample complexity of certain kernel methods.",
            "Abstract entirety": 1,
            "Author pub id": "GBQ6w8IAAAAJ:fPk4N6BV_jEC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "Smart button",
            "Publication year": 2016,
            "Publication url": "https://patents.google.com/patent/US9367850B2/en",
            "Abstract": "The present invention provides for systems and methods that facilitate conveying user information between and among users effectively to thereby create a collaborative filtering environment with maintained user privacy. More specifically, the present invention allows user-profile building to occur coincident with user-browsing, for example. This can be accomplished in part by incorporating an input component on the user interface used for browsing and/or searching. A user who has opted-in to construct a personal profile makes declarations regarding his relationship with at least a portion of the information being currently viewed. The declarations are annotated to the user's profile. At the user's discretion, the user's profile can be disseminated to others in whole or in part such that other people can make use of the user's expertise, experience or opinions. In addition, the user profiles can be machine-readable and \u2026",
            "Abstract entirety": 0,
            "Author pub id": "GBQ6w8IAAAAJ:3s1wT3WcHBgC",
            "Publisher": "Unknown"
        },
        {
            "Title": "The number of satisfying assignments of random 2\u2010SAT formulas",
            "Publication year": 2021,
            "Publication url": "https://onlinelibrary.wiley.com/doi/abs/10.1002/rsa.20993",
            "Abstract": "We show that throughout the satisfiable phase the normalized number of satisfying assignments of a random 2\u2010SAT formula converges in probability to an expression predicted by the cavity method from statistical physics. The proof is based on showing that the Belief Propagation algorithm renders the correct marginal probability that a variable is set to \u201ctrue\u201d under a uniformly random satisfying assignment.",
            "Abstract entirety": 1,
            "Author pub id": "GBQ6w8IAAAAJ:tkaPQYYpVKoC",
            "Publisher": "John Wiley & Sons, Inc."
        },
        {
            "Title": "Interpersonal spacetime interaction system",
            "Publication year": 2019,
            "Publication url": "https://patents.google.com/patent/US10394856B2/en",
            "Abstract": "The present innovation provides a method of establishing a connection between two individuals using an interpersonal spacetime interaction system, including enabling a first user to specify a spacetime event and to provide annotations for the spacetime event, maintaining a spacetime database comprising data objects, each data object corresponding to a spacetime event, querying a spacetime database, using a query that includes at least a specification of a desired spacetime event, said query being initiated by a second user, retrieving information from those data objects in the spacetime database whose corresponding spacetime events are proximate to the desired spacetime event, and providing the retrieved information to the second user.",
            "Abstract entirety": 1,
            "Author pub id": "GBQ6w8IAAAAJ:eJXPG6dFmWUC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Time-invariant LDPC convolutional codes",
            "Publication year": 2017,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/8006551/",
            "Abstract": "Spatially coupled codes have been shown to achieve the capacity for a large class of channels universally. Many variants of such codes have been introduced to date. We discuss a further such variant that is particularly simple and is determined by a very small number of parameters. More precisely, we consider and ensemble of time-invariant low-density parity-check convolutional codes with very large constraint lengths. We show via simulations that, despite their extreme simplicity, such codes still show the threshold saturation behavior known from the spatially coupled codes discussed in the literature. Further, we show how the size of the typical minimum stopping set is related to basic parameters of the code. Due to their simplicity and good performance, these codes might be attractive from an implementation perspective.",
            "Abstract entirety": 1,
            "Author pub id": "GBQ6w8IAAAAJ:u9iWguZQMMsC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Navigability is a robust property",
            "Publication year": 2015,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-319-26784-5_7",
            "Abstract": "The Small World phenomenon has inspired researchers across a number of fields. A breakthrough in its understanding was made by Kleinberg who introduced Rank Based Augmentation (RBA): add to each vertex independently an arc to a random destination, selected from a carefully crafted probability distribution. Kleinberg proved that RBA makes many networks navigable, i.e., it allows greedy routing to successfully deliver messages between any two vertices in a polylogarithmic number of steps. Our goal in this work is to prove that navigability is an inherent, robust property of many random networks, requiring no augmentation, coordination, or even independence assumptions. Our framework assigns a cost to each edge and considers the uniform measure over all graphs on n vertices that satisfy a total budget constraint. We show that when the cost function is sufficiently correlated with the underlying \u2026",
            "Abstract entirety": 0,
            "Author pub id": "GBQ6w8IAAAAJ:YOwf2qJgpHMC",
            "Publisher": "Springer, Cham"
        },
        {
            "Title": "System and method for employing social networks for information discovery",
            "Publication year": 2013,
            "Publication url": "https://patents.google.com/patent/US8489570B2/en",
            "Abstract": "Systems and methods are provided that enable searches of social networks by acting as a \u201ccompass\u201d that assists users in navigating the social network. Individual user participation is not required in response to queries from other users. The systems and methods offer navigational assistance or information as opposed to a traditional search which returns requested information, thus currently acceptable social mechanisms for arbitrating trust can be exploited. As a result, users do not make their personal information publicly searchable, while at the same time, they are protected from potential misrepresentations of facts.",
            "Abstract entirety": 1,
            "Author pub id": "GBQ6w8IAAAAJ:0EnyYjriUFMC",
            "Publisher": "Unknown"
        },
        {
            "Title": "On the bias of traceroute sampling: or, power-law degree distributions in regular graphs",
            "Publication year": 2009,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/1538902.1538905",
            "Abstract": "Understanding the graph structure of the Internet is a crucial step for building accurate network models and designing efficient algorithms for Internet applications. Yet, obtaining this graph structure can be a surprisingly difficult task, as edges cannot be explicitly queried. For instance, empirical studies of the network of Internet Protocol (IP) addresses typically rely on indirect methods like traceroute to build what are approximately single-source, all-destinations, shortest-path trees. These trees only sample a fraction of the network's edges, and a paper by Lakhina et al. [2003] found empirically that the resulting sample is intrinsically biased. Further, in simulations, they observed that the degree distribution under traceroute sampling exhibits a power law even when the underlying degree distribution is Poisson.In this article, we study the bias of traceroute sampling mathematically and, for a very general class of \u2026",
            "Abstract entirety": 0,
            "Author pub id": "GBQ6w8IAAAAJ:ULOm3_A8WrAC",
            "Publisher": "ACM"
        },
        {
            "Title": "Methods and systems of testing software, and methods and systems of modeling user behavior",
            "Publication year": 2008,
            "Publication url": "https://patents.google.com/patent/US7464372B2/en",
            "Abstract": "Methods and systems of testing software and modeling user actions are described. In some embodiments, multiple different algorithms are provided for operating on a software model. The software model describes behavior associated with software that is to be tested. Different sets of algorithms can be selected for operating on the software model to produce a sequence of test actions that are to be used to test the software. The algorithms can be mixed and matched to achieve a desired testing result. In some embodiments, the different algorithms comprise deterministic algorithms, random algorithms, and various types of algorithms therebetween. In one embodiment, the software model comprises a state graph having nodes that represent state, and links between the nodes that represent actions. The different algorithms that are available for selection can have different graph traversal characteristics such that the \u2026",
            "Abstract entirety": 0,
            "Author pub id": "GBQ6w8IAAAAJ:D03iK_w7-QYC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Subscription partitioning and routing in content-based publish/subscribe systems",
            "Publication year": 2002,
            "Publication url": "https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.587.355&rep=rep1&type=pdf",
            "Abstract": "Content-based publish/subscribe systems allow subscribers to specify events of interest based on event contents, beyond pre-assigned event topics. When networks of servers are used to provide scalable content-based publish/subscribe services, we have the flexibility of partitioning existing subscriptions and routing new subscriptions among multiple servers to optimize various performance metrics including total network traffic, load balancing, and system throughput. We propose two approaches to subscription partitioning and routing, one based on partitioning the event space and the other based on partitioning the subscription set, and discuss their trade-offs. Finally, we collect and analyze a set of real-world stock-quote subscriptions and use that as the basis for our simulation study to demonstrate the effectiveness of the proposed schemes.",
            "Abstract entirety": 1,
            "Author pub id": "GBQ6w8IAAAAJ:pqnbT2bcN3wC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Near-optimal entrywise sampling for data matrices",
            "Publication year": 2013,
            "Publication url": "https://arxiv.org/abs/1311.4643",
            "Abstract": "We consider the problem of selecting non-zero entries of a matrix  in order to produce a sparse sketch of it, , that minimizes . For large  matrices, such that  (for example, representing  observations over  attributes) we give sampling distributions that exhibit four important properties. First, they have closed forms computable from minimal information regarding . Second, they allow sketching of matrices whose non-zeros are presented to the algorithm in arbitrary order as a stream, with  computation per non-zero. Third, the resulting sketch matrices are not only sparse, but their non-zero entries are highly compressible. Lastly, and most importantly, under mild assumptions, our distributions are provably competitive with the optimal offline distribution. Note that the probabilities in the optimal offline distribution may be complex functions of all the entries in the matrix. Therefore, regardless of computational complexity, the optimal distribution might be impossible to compute in the streaming model.",
            "Abstract entirety": 1,
            "Author pub id": "GBQ6w8IAAAAJ:e5wmG9Sq2KIC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Special section on foundations of computer science",
            "Publication year": 2007,
            "Publication url": "https://epubs.siam.org/doi/abs/10.1137/SMJCAT000037000001000165000001",
            "Abstract": "This volume comprises the polished and fully refereed versions of a selection of papers presented at the Forty\u2010Fifth Annual IEEE Symposium on Foundations of Computer Science (FOCS 2004), held in Rome, Italy, October 17\u201319, 2004. Unrefereed preliminary versions of the papers presented at the symposium appeared in the proceedings of the meeting, published by IEEE.The FOCS 2004 Program Committee consisted of Dimitris Achlioptas, Micah Adler, Eli Ben\u2010Sasson, Faith Fich, Oded Goldreich, Martin Grohe, Sean Hallgren, Johan H\u00e5stad, Giuseppe F. Italiano, Vladlen Koltun, Yuval Rabani, Miklos Santha, Leonard Schulman, Rocco Servedio, D. Sivakumar, Eli Upfal, and David Williamson.Out of 272 \u201cExtended Abstracts\u201d submitted to the FOCS 2004 Program Committee, 64 were selected for presentation at the symposium. Eight of those 64 papers are included in this volume. This collection encompasses a \u2026",
            "Abstract entirety": 0,
            "Author pub id": "GBQ6w8IAAAAJ:4DMP91E08xMC",
            "Publisher": "Society for Industrial and Applied Mathematics"
        },
        {
            "Title": "Fast computation of low-rank matrix approximations",
            "Publication year": 2007,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/1219092.1219097",
            "Abstract": "Given a matrix A, it is often desirable to find a good approximation to A that has low rank. We introduce a simple technique for accelerating the computation of such approximations when A has strong spectral features, that is, when the singular values of interest are significantly greater than those of a random matrix with size and entries similar to A. Our technique amounts to independently sampling and/or quantizing the entries of A, thus speeding up computation by reducing the number of nonzero entries and/or the length of their representation. Our analysis is based on observing that the acts of sampling and quantization can be viewed as adding a random matrix N to A, whose entries are independent random variables with zero-mean and bounded variance. Since, with high probability, N has very weak spectral features, we can prove that the effect of sampling and quantization nearly vanishes when a low-rank \u2026",
            "Abstract entirety": 0,
            "Author pub id": "GBQ6w8IAAAAJ:NMxIlDl6LWMC",
            "Publisher": "ACM"
        },
        {
            "Title": "Exponential lower bounds for DPLL algorithms on satisfiable random 3-CNF formulas",
            "Publication year": 2012,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-642-31612-8_25",
            "Abstract": "We consider the performance of a number of DPLL algorithms on random 3-CNF formulas with n variables and m\u2009=\u2009rn clauses. A long series of papers analyzing so-called \u201cmyopic\u201d DPLL algorithms has provided a sequence of lower bounds for their satisfiability threshold. Indeed, for each myopic algorithm  it is known that there exists an algorithm-specific clause-density, , such that if , the algorithm finds a satisfying assignment in linear time. For example,  equals 8/3\u2009=\u20092.66.. for orderred-dll and 3.003... for generalized unit clause. We prove that for densities well within the provably satisfiable regime, every backtracking extension of either of these algorithms takes exponential time. Specifically, all extensions of orderred-dll take exponential time for r\u2009>\u20092.78 and the same is true for generalized unit clause for all r\u2009>\u20093.1. Our results imply exponential lower bounds for many other myopic algorithms \u2026",
            "Abstract entirety": 0,
            "Author pub id": "GBQ6w8IAAAAJ:WbkHhVStYXYC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "Local computation algorithms for the Lov\u00e1sz Local Lemma",
            "Publication year": 2018,
            "Publication url": "https://deepai.org/publication/local-computation-algorithms-for-the-lovasz-local-lemma",
            "Abstract": "We consider the task of designing Local Computation Algorithms (LCA) for applications of the Lov\u00e1sz Local Lemma (LLL). LCA is a class of sublinear algorithms proposed by Rubinfeld et al. that have received a lot of attention in recent years. The LLL is an existential, sufficient condition for a collection of sets to have non-empty intersection (in applications, often, each set comprises all objects having a certain property). The ground-breaking algorithm of Moser and Tardos made the LLL fully constructive, following earlier works by Beck and Alon giving algorithms under significantly stronger LLL-like conditions. LCAs under those stronger conditions were given in the paper of Rubinfeld et al. and later work by Alon et al., where it was asked if the Moser-Tardos algorithm can be used to design LCAs under the standard LLL condition. The main contribution of this paper is to answer this question affirmatively. In fact, our techniques yields LCAs for settings beyond the standard LLL condition.",
            "Abstract entirety": 1,
            "Author pub id": "GBQ6w8IAAAAJ:M3NEmzRMIkIC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Smart button",
            "Publication year": 2005,
            "Publication url": "https://patents.google.com/patent/US20050071479A1/en",
            "Abstract": "The present invention provides for systems and methods that facilitate conveying user information between and among users effectively to thereby create a collaborative filtering environment with maintained user privacy. More specifically, the present invention allows user-profile building to occur coincident with user-browsing, for example. This can be accomplished in part by incorporating an input component on the user interface used for browsing and/or searching. A user who has opted-in to construct a personal profile makes declarations regarding his relationship with at least a portion of the information being currently viewed. The declarations are annotated to the user's profile. At the user's discretion, the user's profile can be disseminated to others in whole or in part such that other people can make use of the user's expertise, experience or opinions. In addition, the user profiles can be machine-readable and \u2026",
            "Abstract entirety": 0,
            "Author pub id": "GBQ6w8IAAAAJ:NhqRSupF_l8C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Balance and filtering in structured satisfiable problems (preliminary report)",
            "Publication year": 2001,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S1571065304003105",
            "Abstract": "New methods to generate hard random problem instances have driven progress on algorithms for deduction and constraint satisfaction. Recently Achlioptas et al. (AAAI 2000) introduced a new generator based on Latin squares that creates only satisfiable problems, and so can be used to accurately test incomplete (one sided) solvers. We investigate how this and other generators are biased away from the uniform distribution of satisfiable problems and show how they can be improved by imposing a balance condition. More generally, we show that the generator is one member of a family of related models that generate distributions ranging from ones that are everywhere tractable to ones that exhibit a sharp hardness threshold. We also discuss the critical role of the problem encoding in the performance of both systematic and local search solvers.",
            "Abstract entirety": 1,
            "Author pub id": "GBQ6w8IAAAAJ:NaGl4SEjCO4C",
            "Publisher": "North-Holland"
        },
        {
            "Title": "Database-friendly random projections",
            "Publication year": 2001,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/375551.375608",
            "Abstract": "A classic result of Johnson and Lindenstrauss asserts that any set of n points in d-dimensional Euclidean space can be embedded into k-dimensional Euclidean space where k is logarithmic in n and independent of d so that all pairwise distances are maintained within an arbitrarily small factor. All known constructions of such embeddings involve projecting the n points onto a random k-dimensional hyperplane. We give a novel construction of the embedding, suitable for database applications, which amounts to computing a simple aggregate over k random attribute partitions.",
            "Abstract entirety": 1,
            "Author pub id": "GBQ6w8IAAAAJ:K3LRdlH-MEoC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Special Section on the Fiftieth Annual ACM Symposium on Theory of Computing (STOC 2018)",
            "Publication year": 2020,
            "Publication url": "https://epubs.siam.org/doi/abs/10.1137/20N975154",
            "Abstract": "This issue of SICOMP contains 10 specially selected papers from the Fiftieth Annual ACM Symposium on Theory of Computing, otherwise known as STOC 2018, held June 25 to 29 in Los Angeles, California. The papers here were chosen to represent both the excellence and the broad range of the STOC program. The papers have been revised and extended by the authors and subjected to the standard thorough reviewing process of SICOMP. The program committee consisted of Dimitris Achlioptas (University of California, Santa Cruz), Dorit Aharonov (Hebrew University), Susanne Albers (Technical University Munich), Eric Allender (Rutgers University), Sayan Bhattacharya (University of Warwick), Richard Cole (New York University), Vitaly Feldman (Google Research), Uriel Feige (Weizmann Institute), Sanjam Garg (University of California, Berkeley), Ashish Goel (Stanford University), Parikshit Gopalan (VMware), Monika Henzinger, chair (University of Vienna), Giuseppe Italiano (Luiss University), Robert Kleinberg (Cornell University), Claire Matthieu (E\u0301cole Normale \u2026",
            "Abstract entirety": 0,
            "Author pub id": "GBQ6w8IAAAAJ:Y5dfb0dijaUC",
            "Publisher": "Society for Industrial and Applied Mathematics"
        },
        {
            "Title": "Clustering in random k-sat",
            "Publication year": 2005,
            "Publication url": "https://scholar.google.com/scholar?cluster=8413823421217439745&hl=en&oi=scholarr",
            "Abstract": "In a recent breakthrough, M\u00e9zard et al.[5] have developed an extremely efficient algorithm for finding satisfying assignments of random 3-CNF formulas in the satisfiable regime. For example, their algorithm typically finds a satisfying truth assignment of a random 3-CNF formula with n= 106 variables and 4.25 n clauses in minutes. The core of the algorithm is a procedure, called Survey Propagation (SP), in which messages are iteratively passed back and forth between variables and clauses, such that upon convergence each variable holds a probability distribution over the three values {0, 1,\u2217}. Intuitively, the more mass a variable has on\u2217, the less \u201cconstrained\u201d it is. Each step of the algorithm amounts to: computing statistics for the current formula using SP, setting the \u201cmost constrained\u201d variable to its favorite value, and simplifying the formula. The derivation of Survey Propagation was motivated by heuristic \u2026",
            "Abstract entirety": 0,
            "Author pub id": "GBQ6w8IAAAAJ:AXPGKjj_ei8C",
            "Publisher": "Manuscript"
        },
        {
            "Title": "The phase transition in 1-in-k SAT and NAE 3-SAT",
            "Publication year": 2001,
            "Publication url": "https://www.researchgate.net/profile/Cristopher-Moore-2/publication/2400280_The_phase_transition_in_1-in-k_SAT_and_NAE_3-SAT/links/09e41508553c00f9e1000000/The-phase-transition-in-1-in-k-SAT-and-NAE-3-SAT.pdf",
            "Abstract": "Determining bounds for the random k-SAT threshold has been an active area of research in recent years [1, 3]. Yet, in spite of significant efforts, neither a tight analysis nor the structural properties of this threshold have been determined. In this paper we study random instances of two other canonical variations of satisfiability, 1-in-k SAT and Not-All-Equal 3-SAT. Like random k-SAT, each generative model has one parameter c= m/n, the ratio of clauses to variables. Also similarly to random k-SAT, we focus on\" threshold phenomena\" occurring in these models and how they might relate to computational hardness.",
            "Abstract entirety": 1,
            "Author pub id": "GBQ6w8IAAAAJ:UxriW0iASnsC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Methods and systems for computing singular value decompositions of matrices and low rank approximations of matrices",
            "Publication year": 2009,
            "Publication url": "https://patents.google.com/patent/US7493297B2/en",
            "Abstract": "Methods and systems for finding a low rank approximation for an m\u00d7 n matrix A are described. The described embodiments can independently sample and/or quantize the entries of an input matrix A, and can thus speed up computation by reducing the number of non-zero entries and/or their representation length. The embodiments can be used in connection with Singular Value Decomposition techniques to greatly benefit the processing of high-dimensional data sets in terms of storage, transmission and computation.",
            "Abstract entirety": 1,
            "Author pub id": "GBQ6w8IAAAAJ:j3f4tGmQtD8C",
            "Publisher": "Unknown"
        },
        {
            "Title": "The threshold for random k-SAT is 2k (ln 2 - O(k))",
            "Publication year": 2003,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/780542.780577",
            "Abstract": "Let F k (n, m) be a random k-SAT formula on n variables formed by selecting uniformly and independently m out of all possible k-clauses. It is well-known that for r\u2265 2 k ln 2, F k (n, rn) is unsatisfiable with probability 1-o (1). We prove that there exists a sequence t k= O (k) such that for r\u2265 2 k ln 2-t k, F k (n, rn) is satisfiable with probability 1-o (1). Our technique yields an explicit lower bound for every k which for k> 3 improves upon all previously known bounds. For example, when k= 10 our lower bound is 704.94 while the upper bound is 708.94.",
            "Abstract entirety": 1,
            "Author pub id": "GBQ6w8IAAAAJ:l7t_Zn2s7bgC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Rigorous location of phase transitions in hard optimization problems",
            "Publication year": 2005,
            "Publication url": "https://www.nature.com/articles/nature03602",
            "Abstract": "It is widely believed that for many optimization problems, no algorithm is substantially more efficient than exhaustive search. This means that finding optimal solutions for many practical problems is completely beyond any current or projected computational capacity. To understand the origin of this extreme \u2018hardness\u2019, computer scientists, mathematicians and physicists have been investigating for two decades a connection between computational complexity and phase transitions in random instances of constraint satisfaction problems. Here we present a mathematically rigorous method for locating such phase transitions. Our method works by analysing the distribution of distances between pairs of solutions as constraints are added. By identifying critical behaviour in the evolution of this distribution, we can pinpoint the threshold location for a number of problems, including the two most-studied ones: random k-SAT \u2026",
            "Abstract entirety": 0,
            "Author pub id": "GBQ6w8IAAAAJ:XiSMed-E-HIC",
            "Publisher": "Nature Publishing Group"
        },
        {
            "Title": "Model counting with error-correcting codes",
            "Publication year": 2019,
            "Publication url": "https://link.springer.com/article/10.1007/s10601-018-9296-3",
            "Abstract": "The idea of counting the number of satisfying truth assignments (models) of a formula by adding random parity constraints can be traced back to the seminal work of Valiant and Vazirani showing that NP is as easy as detecting unique solutions. While theoretically sound, the random parity constraints used in that construction suffer from the following drawback: each constraint, on average, involves half of all variables. As a result, the branching factor associated with searching for models that also satisfy the parity constraints quickly gets out of hand. In this work we prove that one can work with much shorter parity constraints and still get rigorous mathematical guarantees, especially when the number of models is large so that many constraints need to be added. Our work is motivated by the realization that the essential feature for a system of parity constraints to be useful in probabilistic model counting is that its \u2026",
            "Abstract entirety": 0,
            "Author pub id": "GBQ6w8IAAAAJ:r0BpntZqJG4C",
            "Publisher": "Springer US"
        },
        {
            "Title": "Algorithmic barriers from phase transitions in graphs",
            "Publication year": 2010,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-642-16926-7_1",
            "Abstract": "For a number of optimization problems on random graphs and hypergraphs, e.g., k-colorings, there is a very big gap between the largest average degree for which known polynomial-time algorithms can find solutions, and the largest average degree for which solutions provably exist. We study this phenomenon by examining how sets of solutions evolve as edges are added. We prove in a precise mathematical sense that, for each problem studied, the barrier faced by algorithms corresponds to a phase transition in the problems solution-space geometry. Roughly speaking, at some problem-specific critical density, the set of solutions shatters and goes from being a single giant ball to exponentially many, well-separated, tiny pieces. All known polynomial-time algorithms work in the ball regime, but stop as soon as the shattering occurs. Besides giving a geometric view of the solution space of random instances \u2026",
            "Abstract entirety": 0,
            "Author pub id": "GBQ6w8IAAAAJ:738O_yMBCRsC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "Exponential bounds for DPLL below the satisfiability threshold",
            "Publication year": 2004,
            "Publication url": "http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.91.3198&rep=rep1&type=pdf",
            "Abstract": "For each k\u2265 4, we give rk> 0 such that a random k-CNF formula F with n variables and\u230a rkn\u230b clauses is satisfiable with high probability, but ordered-dll takes exponential time on F with uniformly positive probability. Using results of [2], this can be strengthened to a high probability result for certain natural backtracking schemes and extended to many other DPLL algorithms.",
            "Abstract entirety": 1,
            "Author pub id": "GBQ6w8IAAAAJ:R3hNpaxXUhUC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Random walks that find perfect objects and the Lov\u00e1sz local lemma",
            "Publication year": 2016,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/2818352",
            "Abstract": "We give an algorithmic local lemma by establishing a sufficient condition for the uniform random walk on a directed graph to reach a sink quickly. Our work is inspired by Moser\u2019s entropic method proof of the Lov\u00e1sz Local Lemma (LLL) for satisfiability and completely bypasses the Probabilistic Method formulation of the LLL. In particular, our method works when the underlying state space is entirely unstructured. Similarly to Moser\u2019s argument, the key point is that the inevitability of reaching a sink is established by bounding the entropy of the walk as a function of time.",
            "Abstract entirety": 1,
            "Author pub id": "GBQ6w8IAAAAJ:mVmsd5A6BfQC",
            "Publisher": "ACM"
        },
        {
            "Title": "System and method for employing social networks for information discovery",
            "Publication year": 2012,
            "Publication url": "https://patents.google.com/patent/US8335798B2/en",
            "Abstract": "Systems and methods are provided that enable searches of social networks by acting as a \u201ccompass\u201d that assists users in navigating the social network. Individual user participation is not required in response to queries from other users. The systems and methods offer navigational assistance or information as opposed to a traditional search which returns requested information, thus currently acceptable social mechanisms for arbitrating trust can be exploited. As a result, users do not make their personal information publicly searchable, while at the same time, they are protected from potential misrepresentations of facts.",
            "Abstract entirety": 1,
            "Author pub id": "GBQ6w8IAAAAJ:vV6vV6tmYwMC",
            "Publisher": "Unknown"
        },
        {
            "Title": "New bounds for random constraint satisfaction problems via spatial coupling",
            "Publication year": 2013,
            "Publication url": "https://infoscience.epfl.ch/record/195693",
            "Abstract": "This paper is about a novel technique called spatial coupling and its application in the analysis of random constraint satisfaction problems (CSP). Spatial Coupling was recently invented in the area of error correcting codes where it has resulted in efficient capacity-achieving codes for a wide range of channels. However, this technique is not limited to problems in communications. It can be applied in the much broader context of graphical models. We describe here a general methodology for applying spatial coupling to constraint satisfaction problems. We begin by describing how spatially coupled CSPs are constructed. We then use the results of a previous work to argue that spatially coupled CSPs are much easier to solve than standard CSPs while the satisfiability threshold of coupled and standard CSPs are the same. As a result, these features provide a new avenue for obtaining better, provable, algorithmic lower bounds on satisfiability thresholds of the standard (uncoupled) CSP models. We then consider simple algorithms for solving coupled CSPs and provide the necessary machinery to analyze such algorithms. As a consequence, we derive new lower bounds for the satisfiability threshold of standard random CSPs. As we will see, some of these lower bounds surpass the current best lower bounds in the literature.",
            "Abstract entirety": 1,
            "Author pub id": "GBQ6w8IAAAAJ:b0M2c_1WBrUC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Solution clustering in random satisfiability",
            "Publication year": 2008,
            "Publication url": "https://link.springer.com/article/10.1140/epjb/e2008-00324-5",
            "Abstract": "For a large number of random constraint satisfaction problems, such as random k-SAT and random graph and hypergraph coloring, we have very good estimates of the largest constraint density for which solutions exist. All known polynomial-time algorithms for these problems, though, fail to find solutions at much lower densities. To understand the origin of this gap we study how the structure of the space of solutions evolves in such problems as constraints are added. In particular, we show that in random k-SAT for k \u2265 8, much before solutions disappear, they organize into an exponential number of clusters, each of which is relatively small and far apart from all other clusters. Moreover, inside each cluster most variables are frozen, i.e., take only one value.",
            "Abstract entirety": 1,
            "Author pub id": "GBQ6w8IAAAAJ:1qzjygNMrQYC",
            "Publisher": "Springer-Verlag"
        },
        {
            "Title": "Random k\u2010SAT: Two Moments Suffice to Cross a Sharp Threshold",
            "Publication year": 2006,
            "Publication url": "https://epubs.siam.org/doi/abs/10.1137/S0097539703434231",
            "Abstract": "Many NP\u2010complete constraint satisfaction problems appear to undergo a \u201cphase transition\u201d from solubility to insolubility when the constraint density passes through a critical threshold. In all such cases it is easy to derive upper bounds on the location of the threshold by showing that above a certain density the first moment (expectation) of the number of solutions tends to zero. We show that in the case of certain symmetric constraints, considering the second moment of the number of solutions yields nearly matching lower bounds for the location of the threshold. Specifically, we prove that the threshold for both random hypergraph 2\u2010colorability (Property B) and random Not\u2010All\u2010Equal k\u2010SAT is . As a corollary, we establish that the threshold for random k\u2010SAT is of order , resolving a long\u2010standing open problem.",
            "Abstract entirety": 1,
            "Author pub id": "GBQ6w8IAAAAJ:ns9cj8rnVeAC",
            "Publisher": "Society for Industrial and Applied Mathematics"
        },
        {
            "Title": "On the maximum satisfiability of random formulas",
            "Publication year": 2007,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/1219092.1219098",
            "Abstract": "Say that a k-CNF a formula is p-satisfiable if there exists a truth assignment satisfying a fraction 1 \u2212 2\u2212k +p 2\u2212k of its clauses (note that every k-CNF formula is 0-satisfiable). Let Fk(n, m) denote a random k-CNF formula on n variables with m clauses. For every k\u22652 and every r>0 we determine p and \u03b4=\u03b4(k)=O(k2\u2212k/2) such that with probability tending to 1 as n\u2192\u221e, a random k-CNF formula Fk(n, rn) is p-satisfiable but not (p+\u03b4)-satisfiable.",
            "Abstract entirety": 1,
            "Author pub id": "GBQ6w8IAAAAJ:4TOpqqG69KYC",
            "Publisher": "ACM"
        },
        {
            "Title": "Interpersonal spacetime interaction system",
            "Publication year": 2015,
            "Publication url": "https://patents.google.com/patent/US9158774B2/en",
            "Abstract": "The present innovation provides a method of establishing a connection between two individuals using an interpersonal spacetime interaction system, including enabling a first user to specify a spacetime event and to provide annotations for the spacetime event, maintaining a spacetime database comprising data objects, each data object corresponding to a spacetime event, querying a spacetime database, using a query that includes at least a specification of a desired spacetime event, said query being initiated by a second user, retrieving information from those data objects in the spacetime database whose corresponding spacetime events are proximate to the desired spacetime event, and providing the retrieved information to the second user.",
            "Abstract entirety": 1,
            "Author pub id": "GBQ6w8IAAAAJ:bFI3QPDXJZMC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Random satisfiability",
            "Publication year": 2009,
            "Publication url": "https://books.google.com/books?hl=en&lr=&id=dUAvEAAAQBAJ&oi=fnd&pg=PA437&dq=info:l9Ot7lx5DNgJ:scholar.google.com&ots=KuAQmPoHMH&sig=_dfOeqBaFmarghJFVWO0PYYvGog",
            "Abstract": "Satisfiability has received a great deal of study as the canonical NP-complete prob-lem. In the last twenty years a significant amount of this effort has been devoted to the study of randomly generated satisfiability instances and the performance of different algorithms on them. Historically, the motivation for studying random instances has been the desire to understand the hardness of\" typical\" instances. In fact, some early results suggested that deciding satisfiability is \u201ceasy on average\u201d. Unfortunately, while \u201ceasy\u201d is easy to interpret,\u201con average\u201d is not. One of the earliest and most often quoted results for satisfiability being easy on average is due to Goldberg (Gol79]. In (FP83], though, Franco and Paull pointed out that the distribution of instances used in the analysis of (Gol79] is so greatly dominated by\" very satisfiable\" formulas that if one tries truth as-signments completely at random, the expected number of trials until finding a satisfying one is 0 (1). Alternatively, Franco and Paull pioneered the analysis of random instances of k-SAT, ie, asking the satisfiability question for random k-CNF formulas (defined precisely below). Among other things, they showed (FP83] that for all k> 3 the DPLL algorithm needs an exponential number of steps to report all cylinders of solutions of such a formula, or that no solutions exist.",
            "Abstract entirety": 1,
            "Author pub id": "GBQ6w8IAAAAJ:tS2w5q8j5-wC",
            "Publisher": "IOS Press"
        },
        {
            "Title": "Algorithmic improvements of the Lov\u00e1sz local lemma via cluster expansion",
            "Publication year": 2012,
            "Publication url": "https://drops.dagstuhl.de/opus/volltexte/2012/3844/",
            "Abstract": "The Lovasz Local Lemma (LLL) is a powerful tool that can be used to prove that an object having none of a set of bad properties exists, using the probabilistic method. In many applications of the LLL it is also desirable to explicitly construct the combinatorial object. Recently it was shown that this is possible using a randomized algorithm in the full asymmetric LLL setting [R. Moser and G. Tardos, 2010]. A strengthening of the LLL for the case of dense local neighborhoods proved in [R. Bissacot et al., 2010] was recently also made constructive in [W. Pegden, 2011]. In another recent work [B. Haupler, B. Saha, A. Srinivasan, 2010], it was proved that the algorithm of Moser and Tardos is still efficient even when the number of events is exponential. Here we prove that these last two contributions can be combined to yield a new version of the LLL.",
            "Abstract entirety": 1,
            "Author pub id": "GBQ6w8IAAAAJ:_Qo2XoVZTnwC",
            "Publisher": "Schloss Dagstuhl-Leibniz-Zentrum fuer Informatik"
        },
        {
            "Title": "Two\u2010coloring random hypergraphs",
            "Publication year": 2002,
            "Publication url": "https://onlinelibrary.wiley.com/doi/abs/10.1002/rsa.997",
            "Abstract": "A 2\u2010coloring of a hypergraph is a mapping from its vertex set to a set of two colors such that no edge is monochromatic. Let H= H (k, n, p) be a random k\u2010uniform hypergraph on a vertex set V of cardinality n, where each k\u2010subset of V is an edge of H with probability p, independently of all other k\u2010subsets. Let article empty m=pnk denote the expected number of edges in H. Let us say that a sequence of events \u2130n holds with high probability (whp) if limn\u2192\u221e Pr \u2130n= 1. It is easy to show that if m= c2kn then whp H is not 2\u2010colorable for c> ln 2/2. We prove that there exists a constant c> 0 such that if m=(c2k/k) n, then whp H is 2\u2010colorable.\u00a9 2002 Wiley Periodicals, Inc. Random Struct. Alg. 20: 249\u2013259, 2002",
            "Abstract entirety": 1,
            "Author pub id": "GBQ6w8IAAAAJ:zA6iFVUQeVQC",
            "Publisher": "Wiley Subscription Services, Inc., A Wiley Company"
        },
        {
            "Title": "Rapid mixing for lattice colourings with fewer colours",
            "Publication year": 2005,
            "Publication url": "https://iopscience.iop.org/article/10.1088/1742-5468/2005/10/P10012/meta",
            "Abstract": "We provide an optimally mixing Markov chain for 6-colourings of the square lattice on rectangular regions with free, fixed, or toroidal boundary conditions. This implies that the uniform distribution on the set of such colourings has strong spatial mixing, so the six-state Potts antiferromagnet has a finite correlation length and a unique Gibbs measure at zero temperature. Four and five are now the only remaining values of q for which it is not known whether there exists a rapidly mixing Markov chain for q-colourings of the square lattice.",
            "Abstract entirety": 1,
            "Author pub id": "GBQ6w8IAAAAJ:BrmTIyaxlBUC",
            "Publisher": "IOP Publishing"
        },
        {
            "Title": "Product measure approximation of symmetric graph properties",
            "Publication year": 2015,
            "Publication url": "https://arxiv.org/abs/1502.07787",
            "Abstract": "In the study of random structures we often face a trade-off between realism and tractability, the latter typically enabled by assuming some form of independence. In this work we initiate an effort to bridge this gap by developing tools that allow us to work with independence without assuming it. Let  be the set of all graphs on  vertices and let  be an arbitrary subset of , e.g., the set of graphs with  edges. The study of random networks can be seen as the study of properties that are true for most elements of , i.e., that are true with high probability for a uniformly random element of . With this in mind, we pursue the following question: What are general sufficient conditions for the uniform measure on a set of graphs  to be approximable by a product measure?",
            "Abstract entirety": 1,
            "Author pub id": "GBQ6w8IAAAAJ:J-pR_7NvFogC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Local Approximations of the Independent Set Polynomial",
            "Publication year": 2021,
            "Publication url": "https://drops.dagstuhl.de/opus/volltexte/2021/14077/",
            "Abstract": "The independent set polynomial of a graph has one variable for each vertex and one monomial for each independent set, comprising the product of the corresponding variables. Given a graph G on n vertices and a vector p\u2208[0, 1) \u207f, a central problem in statistical mechanics is determining whether the independent set polynomial of G is non-vanishing in the polydisk of p, ie, whether| Z_G (x)|> 0 for every x\u2208 \u2102\u207f such that| x_i|\u2264 p_i. Remarkably, when this holds, Z_G (-p) is a lower bound for the avoidance probability when G is a dependency graph for n events whose probabilities form vector p. A local sufficient condition for| Z_G|> 0 in the polydisk of p is the Lov\u00e1sz Local Lemma (LLL). In this work we derive several new results on the efficient evaluation and bounding of Z_G. Our starting point is a monotone mapping from subgraphs of G to truncations of the tree of self-avoiding walks of G. Using this mapping our first result is a local upper bound for Z (-p), similar in spirit to the local lower bound for Z (-p) provided by the LLL. Next, using this mapping, we show that when G is chordal, Z_G can be computed exactly and in linear time on the entire complex plane, implying perfect sampling for the hard-core model on chordal graphs. We also revisit the task of bounding Z (-p) from below, ie, the LLL setting, and derive four new lower bounds of increasing sophistication. Already our simplest (and weakest) bound yields a strict improvement of the famous asymmetric LLL, ie, a strict relaxation of the inequalities of the asymmetric LLL without any further assumptions. This new asymmetric local lemma is sharp enough to recover Shearer\u2019s optimal bound in \u2026",
            "Abstract entirety": 0,
            "Author pub id": "GBQ6w8IAAAAJ:JoZmwDi-zQgC",
            "Publisher": "Schloss Dagstuhl-Leibniz-Zentrum f\u00fcr Informatik"
        },
        {
            "Title": "System and method for employing social networks for information discovery",
            "Publication year": 2008,
            "Publication url": "https://patents.google.com/patent/US7472110B2/en",
            "Abstract": "Systems and methods are provided that enable searches of social networks by acting as a \u201ccompass\u201d that assists users in navigating the social network. Individual user participation is not required in response to queries from other users. The systems and methods offer navigational assistance or information as opposed to a traditional search which returns requested information, thus currently acceptable social mechanisms for arbitrating trust can be exploited. As a result, users do not make their personal information publicly searchable, while at the same time, they are protected from potential misrepresentations of facts.",
            "Abstract entirety": 1,
            "Author pub id": "GBQ6w8IAAAAJ:SeFeTyx0c_EC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Symmetric graph properties have independent edges",
            "Publication year": 2018,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S0890540118300208",
            "Abstract": "In the study of random structures we often face a trade-off between realism and tractability, the latter typically enabled by independence assumptions. In this work we initiate an effort to bridge this gap by developing tools that allow us to work with independence without assuming it. Let G n be the set of all graphs on n vertices and let S be an arbitrary subset of G n, eg, the set of all graphs with m edges. The study of random networks can be seen as the study of properties that are true for most elements of S, ie, that are true with high probability for a uniformly random element of S. With this in mind, we pursue the following question: What are general sufficient conditions for the uniform measure on a set of graphs S\u2286 G n to be well-approximable by a product measure on the set of all possible edges?",
            "Abstract entirety": 1,
            "Author pub id": "GBQ6w8IAAAAJ:UeHWp8X0CEIC",
            "Publisher": "Academic Press"
        },
        {
            "Title": "A sharp threshold in proof complexity",
            "Publication year": 2001,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/380752.380820",
            "Abstract": "We give the first example of a sharp threshold in proof complexity. More precisely, we show that for any sufficiently small \u03b5> 0 and \u0394> 2.28, random formulas consisting of (1-\u03b5) n 2-clauses and &Dgr n 3-clauses, which are known to be unsatisfiable almost certainly, almost certainly require resolution and Davis-Putnam proofs of unsatisfiability of exponential size, whereas it is easily seen that random formulas with (1+ \u03b5) n 2-clauses (and \u0394 n 3 clauses) have linear size proofs of unsatisfiability almost certainly.",
            "Abstract entirety": 1,
            "Author pub id": "GBQ6w8IAAAAJ:bEWYMUwI8FkC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Almost all graphs with average degree 4 are 3-colorable",
            "Publication year": 2003,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S002200000300120X",
            "Abstract": "We analyze a randomized version of the Brelaz heuristic on sparse random graphs. We prove that almost all graphs with average degree d\u2a7d4.03, i.e., G(n,p=d/n), are 3-colorable and that a constant fraction of all 4-regular graphs are 3-colorable.",
            "Abstract entirety": 1,
            "Author pub id": "GBQ6w8IAAAAJ:rO6llkc54NcC",
            "Publisher": "Academic Press"
        },
        {
            "Title": "Methods and systems for computing singular value decompositions of matrices and low rank approximations of matrices",
            "Publication year": 2004,
            "Publication url": "https://patents.google.com/patent/US6807536B2/en",
            "Abstract": "Methods and systems for finding a low rank approximation for an m\u00d7 n matrix A are described. The described embodiments can independently sample and/or quantize the entries of an input matrix A, and can thus speed up computation by reducing the number of non-zero entries and/or their representation length. The embodiments can be used in connection with Singular Value Decomposition techniques to greatly benefit the processing of high-dimensional data sets in terms of storage, transmission and computation.",
            "Abstract entirety": 1,
            "Author pub id": "GBQ6w8IAAAAJ:2osOgNQ5qMEC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Lower bounds for random 3-SAT via differential equations",
            "Publication year": 2001,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S0304397501001591",
            "Abstract": "It is widely believed that the probability of satisfiability for random k-SAT formulae exhibits a sharp threshold as a function of their clauses-to-variables ratio. For the most studied case, k= 3, there have been a number of results during the last decade providing upper and lower bounds for the threshold's potential location. All lower bounds in this vein have been algorithmic, ie, in each case a particular algorithm was shown to satisfy random instances of 3-SAT with probability 1\u2212 o (1) if the clauses-to-variables ratio is below a certain value. We show how differential equations can serve as a generic tool for analyzing such algorithms by rederiving most of the known lower bounds for random 3-SAT in a simple, uniform manner.",
            "Abstract entirety": 1,
            "Author pub id": "GBQ6w8IAAAAJ:WF5omc3nYNoC",
            "Publisher": "Elsevier"
        },
        {
            "Title": "Generating satisfiable problem instances",
            "Publication year": 2000,
            "Publication url": "https://www.aaai.org/Papers/AAAI/2000/AAAI00-039.pdf",
            "Abstract": "A major difficulty in evaluating incomplete local search style algorithms for constraint satisfaction problems is the need for a source of hard problem instances that are guaranteed to be satisfiable. A standard approach to evaluate incomplete search methods has been to use a general problem generator and a complete search method to filter out the unsatisfiable instances. Unfortunately, this approach cannot be used to create problem instances that are beyond the reach of complete search methods. So far, it has proven to be surprisingly difficult to develop a direct generator for satisfiable instances only. In this paper, we propose a generator that only outputs satisfiable problem instances. We also show how one can finely control the hardness of the satisfiable instances by establishing a connection between problem hardness and a new kind of phase transition phenomenon in the space of problem instances. Finally, we use our problem distribution to show the easy-hard-easy pattern in search complexity for local search procedures, analogous to the previously reported pattern for complete search methods.",
            "Abstract entirety": 1,
            "Author pub id": "GBQ6w8IAAAAJ:HoB7MX3m0LUC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Bad global minima exist and sgd can reach them",
            "Publication year": 2019,
            "Publication url": "https://arxiv.org/abs/1906.02613",
            "Abstract": "Several works have aimed to explain why overparameterized neural networks generalize well when trained by Stochastic Gradient Descent (SGD). The consensus explanation that has emerged credits the randomized nature of SGD for the bias of the training process towards low-complexity models and, thus, for implicit regularization. We take a careful look at this explanation in the context of image classification with common deep neural network architectures. We find that if we do not regularize \\emph{explicitly}, then SGD can be easily made to converge to poorly-generalizing, high-complexity models: all it takes is to first train on a random labeling on the data, before switching to properly training with the correct labels. In contrast, we find that in the presence of explicit regularization, pretraining with random labels has no detrimental effect on SGD. We believe that our results give evidence that explicit regularization plays a far more important role in the success of overparameterized neural networks than what has been understood until now. Specifically, by penalizing complicated models independently of their fit to the data, regularization affects training dynamics also far away from optima, making simple models that fit the data well discoverable by local methods, such as SGD.",
            "Abstract entirety": 1,
            "Author pub id": "GBQ6w8IAAAAJ:08ZZubdj9fEC",
            "Publisher": "Unknown"
        },
        {
            "Title": "The two possible values of the chromatic number of a random graph",
            "Publication year": 2005,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/1007352.1007442",
            "Abstract": "For every d> 0, let k d be the smallest integer k such that d< 2k log k. We prove that the chromatic number of a random graph G (n, d/n) is either k d or k d+ 1 almost surely. If d\u2208(2k log k-log k, 2k log k) we further prove that the chromatic number almost surely equals k+ 1.",
            "Abstract entirety": 1,
            "Author pub id": "GBQ6w8IAAAAJ:HE397vMXCloC",
            "Publisher": "Princeton University & Institute of Advanced Study"
        },
        {
            "Title": "System and method adapted to facilitate dimensional transform",
            "Publication year": 2008,
            "Publication url": "https://patents.google.com/patent/US7318078B1/en",
            "Abstract": "Systems and methods that facilitate dimensional transformations of data points are disclosed. In particular, the subject invention provides for a system and methodology that simplifies dimensional transformations while mitigating variations of a distance property between pairs of points. A set of n data points in d dimensional space is represented as an n\u00d7 d input matrix, where d also corresponds to the number of attributes per data point. A transformed matrix represents the n data points in a lower dimensionality k after being mapped. The transformed matrix is an n\u00d7 k matrix, where k is the number of attributes per data point and is less than d. The transformed matrix is obtained by multiplying the input matrix by a suitable projection matrix. The projection matrix is generated by randomly populating the entries of the matrix with binary or ternary values according to a probability distribution. Unlike previous methods, the \u2026",
            "Abstract entirety": 0,
            "Author pub id": "GBQ6w8IAAAAJ:ZeXyd9-uunAC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Focused stochastic local search and the Lov\u00e1sz local lemma",
            "Publication year": 2016,
            "Publication url": "https://epubs.siam.org/doi/abs/10.1137/1.9781611974331.ch141",
            "Abstract": "We develop tools for analyzing focused stochastic local search algorithms. These are algorithms that search a state space probabilistically by repeatedly selecting a constraint that is violated in the current state and moving to a random nearby state which, hopefully, addresses the violation without introducing many new ones. A large class of such algorithms arise from algorithmizations of the Lov\u00e1sz Local Lemma, a non-constructive tool for proving the existence of satisfying states. Here we give tools that provide a unified analysis of such algorithms and of many more, expressing them as instances of a general framework.",
            "Abstract entirety": 1,
            "Author pub id": "GBQ6w8IAAAAJ:3fE2CSJIrl8C",
            "Publisher": "Society for Industrial and Applied Mathematics"
        },
        {
            "Title": "High performance & low latency in solid-state drives through redundancy",
            "Publication year": 2013,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/2527792.2527798",
            "Abstract": "Solid-state drives are becoming increasingly popular in enterprise storage systems, playing the role of large caches and permanent storage. Although SSDs provide faster random access than hard-drives, their performance under read/write workloads is highly variable often exceeding that of hard-drives (eg, taking 100ms for a single read). Many systems with mixed workloads have low latency requirements, or require predictable performance and guarantees. In such cases, the performance variance of SSDs becomes a problem for both predictability and raw performance.",
            "Abstract entirety": 1,
            "Author pub id": "GBQ6w8IAAAAJ:a0OBvERweLwC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Sampling grid colorings with fewer colors",
            "Publication year": 2004,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-540-24698-5_12",
            "Abstract": "We provide an optimally mixing Markov chain for 6-colorings of the square grid. Furthermore, this implies that the uniform distribution on the set of such colorings has strong spatial mixing. Four and five are now the only remaining values of k for which it is not known whether there exists a rapidly mixing Markov chain for k-colorings of the square grid.",
            "Abstract entirety": 1,
            "Author pub id": "GBQ6w8IAAAAJ:dshw04ExmUIC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "Flash on rails: Consistent flash performance through redundancy",
            "Publication year": 2014,
            "Publication url": "https://www.usenix.org/conference/atc14/technical-sessions/presentation/skourtis",
            "Abstract": "Modern applications and virtualization require fast and predictable storage. Hard-drives have low and unpredictable performance, while keeping everything in DRAM is still prohibitively expensive or unnecessary in many cases. Solid-state drives offer a balance between performance and cost and are becoming increasingly popular in storage systems, playing the role of large caches and permanent storage. Although their read performance is high and predictable, SSDs frequently block in the presence of writes, exceeding hard-drive latency and leading to unpredictable performance.",
            "Abstract entirety": 1,
            "Author pub id": "GBQ6w8IAAAAJ:cFHS6HbyZ2cC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Immortal information storage and access platform",
            "Publication year": 2007,
            "Publication url": "https://patents.google.com/patent/US20070011109A1/en",
            "Abstract": "Immortal information storage is leveraged to provide an interactive means to retrieve information associated with a physical artifact. The information persists for a substantial portion of the life of the artifact. This allows users to interact with an artifact that symbolically represents an entity, where the entity can be an organic and/or non-organic entity. A physical artifact that symbolically represents a person, animal, or a structure can be utilized. The storage system can contain easy to discover information about building a decoder or providing power and interpreting the information stored therein. A personalized interaction model can also be utilized to facilitate in providing an interactive model that responds to user queries in a fashion characteristic of the entity. Access to the immortalized information can be controlled by identity of entity seeking access, the amount of time that has passed, or events that have occurred \u2026",
            "Abstract entirety": 0,
            "Author pub id": "GBQ6w8IAAAAJ:maZDTaKrznsC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Queries as data for revising and extending a sensor-based location service",
            "Publication year": 2012,
            "Publication url": "https://patents.google.com/patent/US8244240B2/en",
            "Abstract": "The claimed subject matter provides systems and/or methods that facilitate automatically maintaining a database of base stations. A location component can obtain a query that includes a listing of detected base stations. Additionally, the location component can identify whether the detected base stations are included in a base station database. Further, the location component can generate an estimated location related to the query. Moreover, a database update component can modify the base station database based at least in part upon the query.",
            "Abstract entirety": 1,
            "Author pub id": "GBQ6w8IAAAAJ:nb7KW1ujOQ8C",
            "Publisher": "Unknown"
        },
        {
            "Title": "System and method adapted to facilitate dimensional transform",
            "Publication year": 2010,
            "Publication url": "https://patents.google.com/patent/US7836115B1/en",
            "Abstract": "Systems and methods that facilitate dimensional transformations of data points are disclosed. In particular, the subject invention provides for a system and methodology that simplifies dimensional transformations while mitigating variations of a distance property between pairs of points. A set of n data points in d dimensional space is represented as an n\u00d7 d input matrix, where d also corresponds to the number of attributes per data point. A transformed matrix represents the n data points in a lower dimensionality k after being mapped. The transformed matrix is an n\u00d7 k matrix, where k is the number of attributes per data point and is less than d. The transformed matrix is obtained by multiplying the input matrix by a suitable projection matrix. The projection matrix is generated by randomly populating the entries of the matrix with binary or ternary values according to a probability distribution. Unlike previous methods, the \u2026",
            "Abstract entirety": 0,
            "Author pub id": "GBQ6w8IAAAAJ:hFOr9nPyWt4C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Fast sampling of perfectly uniform satisfying assignments",
            "Publication year": 2018,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-319-94144-8_9",
            "Abstract": "We present an algorithm for perfectly uniform sampling of satisfying assignments, based on the exact model counter sharpSAT and reservoir sampling. In experiments across several hundred formulas, our sampler is faster than the state of the art by 10 to over 100,000 times.",
            "Abstract entirety": 1,
            "Author pub id": "GBQ6w8IAAAAJ:MXK_kJrjxJIC",
            "Publisher": "Springer, Cham"
        },
        {
            "Title": "The solution space geometry of random linear equations",
            "Publication year": 2015,
            "Publication url": "https://onlinelibrary.wiley.com/doi/abs/10.1002/rsa.20494",
            "Abstract": "We consider random systems of linear equations over GF(2) in which every equation binds k variables. We obtain a precise description of the clustering of solutions in such systems. In particular, we prove that with probability that tends to 1 as the number of variables, n, grows: for every pair of solutions \u03c3,\u03c4, either there exists a sequence of solutions starting at \u03c3 and ending at \u03c4 such that successive solutions have Hamming distance O(log n), or every sequence of solutions starting at \u03c3 and ending at \u03c4 contains a pair of successive solutions with distance \u03a9(n). Furthermore, we determine precisely which pairs of solutions are in each category. Key to our results is establishing the following high probability property of cores of random hypergraphs which is of independent interest. Every vertex not in the r\u2010core of a random k\u2010uniform hypergraph can be removed by a sequence of O(log n) steps, where each step amounts to \u2026",
            "Abstract entirety": 0,
            "Author pub id": "GBQ6w8IAAAAJ:uWQEDVKXjbEC",
            "Publisher": "Unknown"
        },
        {
            "Title": "On the solution-space geometry of random constraint satisfaction problems",
            "Publication year": 2006,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/1132516.1132537",
            "Abstract": "For a number of random constraint satisfaction problems, such as random k-SAT and random graph/hypergraph coloring, there are very good estimates of the largest constraint density for which solutions exist. Yet, all known polynomial-time algorithms for these problems fail to find solutions even at much lower densities. To understand the origin of this gap we study how the structure of the space of solutions evolves in such problems as constraints are added. In particular, we prove that much before solutions disappear, they organize into an exponential number of clusters, each of which is relatively small and far apart from all other clusters. Moreover, inside each cluster most variables are frozen, ie, take only one value. The existence of such frozen variables gives a satisfying intuitive explanation for the failure of the polynomial-time algorithms analyzed so far. At the same time, our results establish rigorously one of \u2026",
            "Abstract entirety": 0,
            "Author pub id": "GBQ6w8IAAAAJ:hqOjcs7Dif8C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Principals and methods for balancing the timeliness of communications and information delivery with the expected cost of interruption via deferral policies",
            "Publication year": 2009,
            "Publication url": "https://patents.google.com/patent/US7529683B2/en",
            "Abstract": "A system is provided that facilitates information processing for a user. The system includes an analyzer to automatically determine one or more states of a user's availability based on patterns of the user's interruptability. A deferral component generates or forwards messages or alerts to the user in accordance with a cost-minimization analysis and determined availability. For example, the deferral component can process interrupts to the user and determine at least one of optimal and approximately optimal deferral times in which to direct an information item to the user, the information item being one of an email message, an incoming phone call, a push-to-talk message, an instant message, an alert, requests, offers of assistance, status or error reports, or a task from another application or autonomous system.",
            "Abstract entirety": 1,
            "Author pub id": "GBQ6w8IAAAAJ:hMod-77fHWUC",
            "Publisher": "Unknown"
        },
        {
            "Title": "The random 2-SAT partition function",
            "Publication year": 2020,
            "Publication url": "https://arxiv.org/abs/2002.03690",
            "Abstract": "We show that throughout the satisfiable phase the normalised number of satisfying assignments of a random -SAT formula converges in probability to an expression predicted by the cavity method from statistical physics. The proof is based on showing that the Belief Propagation algorithm renders the correct marginal probability that a variable is set to `true' under a uniformly random satisfying assignment.",
            "Abstract entirety": 1,
            "Author pub id": "GBQ6w8IAAAAJ:p2g8aNsByqUC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Algorithmic barriers from phase transitions",
            "Publication year": 2008,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/4691011/",
            "Abstract": "For many random constraint satisfaction problems, by now there exist asymptotically tight estimates of the largest constraint density for which solutions exist. At the same time, for many of these problems, all known polynomial-time algorithms stop finding solutions at much smaller densities. For example, it is well-known that it is easy to color a random graph using twice as many colors as its chromatic number. Indeed, some of the simplest possible coloring algorithms achieve this goal. Given the simplicity of those algorithms, one would expect room for improvement. Yet, to date, no algorithm is known that uses (2 - epsiv)chi colors, in spite of efforts by numerous researchers over the years. In view of the remarkable resilience of this factor of 2 against every algorithm hurled at it, we find it natural to inquire into its origin. We do so by analyzing the evolution of the set of k-colorings of a random graph, viewed as a subset of \u2026",
            "Abstract entirety": 0,
            "Author pub id": "GBQ6w8IAAAAJ:-f6ydRqryjwC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Fast computation of low rank matrix approximations",
            "Publication year": 2003,
            "Publication url": "https://scholar.google.com/scholar?cluster=15875819669817038563&hl=en&oi=scholarr",
            "Abstract": "Given a matrix A, it is often desirable to find an approximation to A that has low rank. We introduce a simple technique for accelerating the computation of such approximations when A has strong spectral structure, ie, when the singular values of interest are significantly greater than those of a random matrix with size and entries similar to A. Our technique amounts to independently sampling and/or quantizing the entries of A, thus speeding up computation by reducing the number of non-zero entries and/or the length of their representation. Our analysis is based on observing that the acts of sampling and quantization can be viewed as adding a random matrix N to A, whose entries are independent random variables with zero-mean and bounded variance. Since, with high probability, N has very weak spectral structure, we can prove that the effect of sampling and quantization nearly vanishes when a low rank \u2026",
            "Abstract entirety": 0,
            "Author pub id": "GBQ6w8IAAAAJ:geHnlv5EZngC",
            "Publisher": "manuscript"
        },
        {
            "Title": "On the k-colorability threshold",
            "Publication year": 2005,
            "Publication url": "https://scholar.google.com/scholar?cluster=8592125647677629457&hl=en&oi=scholarr",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "GBQ6w8IAAAAJ:t6usbXjVLHcC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Competitive analysis of randomized paging algorithms",
            "Publication year": 2000,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S0304397598001169",
            "Abstract": "The paging problem is defined as follows: we are given a two-level memory system, in which one level is a fast memory, called cache, capable of holding k items, and the second level is an unbounded but slow memory. At each given time step, a request to an item is issued. Given a request to an item p, a miss occurs if p is not present in the fast memory. In response to a miss, we need to choose an item q in the cache and replace it by p. The choice of q needs to be made on-line, without the knowledge of future requests. The objective is to design a replacement strategy with a small number of misses. In this paper we use competitive analysis to study the performance of randomized on-line paging algorithms. Our goal is to show how the concept of work functions, used previously mostly for the analysis of deterministic algorithms, can also be applied, in a systematic fashion, to the randomized case. We present two \u2026",
            "Abstract entirety": 0,
            "Author pub id": "GBQ6w8IAAAAJ:TQgYirikUcIC",
            "Publisher": "Elsevier"
        },
        {
            "Title": "On the 2-colorability of random hypergraphs",
            "Publication year": 2002,
            "Publication url": "https://link.springer.com/chapter/10.1007/3-540-45726-7_7",
            "Abstract": "A 2-coloring of a hypergraph is a mapping from its vertices to a set of two colors such that no edge is monochromatic. Let H  k  (n,m) be a random k-uniform hypergraph on n vertices formed by picking m edges uniformly, independently and with replacement. It is easy to show that if r \u2265r c = 2k-1ln2-(ln2)/2, then with high probability H  k  (n,m = rn) is not 2-colorable. We complement this observation by proving that if r \u2264r  c - 1 then with high probability  H k (n, m = rn) is 2-colorable.",
            "Abstract entirety": 1,
            "Author pub id": "GBQ6w8IAAAAJ:GnPB-g6toBAC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "Unsatisfiability bounds for random CSPs from an energetic interpolation method",
            "Publication year": 2012,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-642-31594-7_1",
            "Abstract": "The interpolation method, originally developed in statistical physics, transforms distributions of random CSPs to distributions of much simpler problems while bounding the change in a number of associated statistical quantities along the transformation path. After a number of further mathematical developments, it is now known that, in principle, the method can yield rigorous unsatisfiability bounds if one \u201cplugs in an appropriate functional distribution\u201d. A drawback of the method is that identifying appropriate distributions and plugging them in leads to major analytical challenges as the distributions required are, in fact, infinite dimensional objects. We develop a variant of the interpolation method for random CSPs on arbitrary sparse degree distributions which trades accuracy for tractability. In particular, our bounds only require the solution of a 1-dimensional optimization problem (which typically turns out to be \u2026",
            "Abstract entirety": 0,
            "Author pub id": "GBQ6w8IAAAAJ:qUcmZB5y_30C",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "Skip-Gram\u2212 Zipf+ Uniform= Vector Additivity",
            "Publication year": 2017,
            "Publication url": "https://www.aclweb.org/anthology/P17-1007.pdf",
            "Abstract": "In recent years word-embedding models have gained great popularity due to their remarkable performance on several tasks, including word analogy questions and caption generation. An unexpected \u201cside-effect\u201d of such models is that their vectors often exhibit compositionality, ie, addingtwo word-vectors results in a vector that is only a small angle away from the vector of a word representing the semantic composite of the original words, eg,\u201cman\u201d+\u201croyal\u201d=\u201cking\u201d. This work provides a theoretical justification for the presence of additive compositionality in word vectors learned using the Skip-Gram model. In particular, it shows that additive compositionality holds in an even stricter sense (small distance rather than small angle) under certain assumptions on the process generating the corpus. As a corollary, it explains the success of vector calculus in solving word analogies. When these assumptions do not hold, this work describes the correct non-linear composition operator. Finally, this work establishes a connection between the Skip-Gram model and the Sufficient Dimensionality Reduction (SDR) framework of Globerson and Tishby: the parameters of SDR models can be obtained from those of Skip-Gram models simply by adding information on symbol frequencies. This shows that Skip-Gram embeddings are optimal in the sense of Globerson and Tishby and, further, implies that the heuristics commonly used to approximately fit Skip-Gram models can be used to fit SDR models.",
            "Abstract entirety": 1,
            "Author pub id": "GBQ6w8IAAAAJ:yD5IFk8b50cC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Beyond the Lov\u00e1sz local lemma: Point to set correlations and their algorithmic applications",
            "Publication year": 2019,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/8948591/",
            "Abstract": "Following the groundbreaking algorithm of Moser and Tardos for the Lovasz Local Lemma (LLL), there has been a plethora of results analyzing local search algorithms for various constraint satisfaction problems. The algorithms considered fall into two broad categories: resampling algorithms, analyzed via different algorithmic LLL conditions; and backtracking algorithms, analyzed via entropy compression arguments. This paper introduces a new convergence condition that seamlessly handles resampling, backtracking, and hybrid algorithms, i.e., algorithms that perform both resampling and backtracking steps. Unlike previous work on the LLL, our condition replaces the notion of a dependency or causality graph by quantifying point-to-set correlations between bad events. As a result, our condition simultaneously: (i) captures the most general algorithmic LLL condition known as a special case; (ii) significantly \u2026",
            "Abstract entirety": 0,
            "Author pub id": "GBQ6w8IAAAAJ:Tiz5es2fbqcC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Latency minimization in SSD clusters for free",
            "Publication year": 2013,
            "Publication url": "https://users.soe.ucsc.edu/~carlosm/dev/publication/skourtis-ucsctr-13-a/skourtis-ucsctr-13-a.pdf",
            "Abstract": "Modern applications and virtualization require fast and predictable storage. Hard-drives have low and unpredictable performance, while keeping everything in DRAM, in many cases, is still prohibitively expensive or unnecessary. Solidstate drives offer a balance between performance and cost, and are becoming increasingly popular in storage systems, playing the role of large caches and permanent storage. Although their read performance is high and predictable, under read/write workloads solid-state drives frequently block and exceed hard-drive latency.In this paper, we propose an efficient approach for achieving performance predictability in distributed storage systems comprised of solid-state drives. By observing that virtually all storage systems incorporate significant redundancy for the purpose of reliability, we propose exploiting this latent resource to achieve the separation of reads from writes across nodes, allowing each drive to periodically serve either read or write workloads. Our proposed approach provides high performance and low latency for reads under read/write workloads while adding no extra cost to the system.",
            "Abstract entirety": 1,
            "Author pub id": "GBQ6w8IAAAAJ:B3FOqHPlNUQC",
            "Publisher": "Tech. Rep. UCSC-SOE-13-10, UC Santa Cruz"
        },
        {
            "Title": "The chromatic number of random regular graphs",
            "Publication year": 2004,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-540-27821-4_20",
            "Abstract": "Given any integer d \u2265 3, let k be the smallest integer such that d < 2k log k. We prove that with high probability the chromatic number of a random d-regular graph is k, k+1, or k+2.",
            "Abstract entirety": 1,
            "Author pub id": "GBQ6w8IAAAAJ:vRqMK49ujn8C",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "Random constraint satisfaction: A more accurate picture",
            "Publication year": 2001,
            "Publication url": "https://link.springer.com/article/10.1023/A:1011402324562",
            "Abstract": "In the last few years there has been a great amount of interest in Random Constraint Satisfaction Problems, both from an experimental and a theoretical point of view. Quite intriguingly, experimental results with various models for generating random CSP instances suggest that the probability of such problems having a solution exhibits a \u201cthreshold\u2013like\u201d behavior. In this spirit, some preliminary theoretical work has been done in analyzing these models asymptotically, i.e., as the number of variables grows. In this paper we prove that, contrary to beliefs based on experimental evidence, the models commonly used for generating random CSP instances do not have an asymptotic threshold. In particular, we prove that asymptotically almost all instances they generate are overconstrained, suffering from trivial, local inconsistencies. To complement this result we present an alternative, single\u2013parameter model for \u2026",
            "Abstract entirety": 0,
            "Author pub id": "GBQ6w8IAAAAJ:J_g5lzvAfSwC",
            "Publisher": "Kluwer Academic Publishers"
        },
        {
            "Title": "Rigorous results for random (2+ p)-SAT",
            "Publication year": 2001,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S0304397501001542",
            "Abstract": "In recent years there has been significant interest in the study of random k-SAT formulae. For a given set of n Boolean variables, let B k denote the set of all possible disjunctions of k distinct, non-complementary literals from its variables (k-clauses). A random k-SAT formula F k (n, m) is formed by selecting uniformly and independently m clauses from B k and taking their conjunction. Motivated by insights from statistical mechanics that suggest a possible relationship between the \u201corder\u201d of phase transitions and computational complexity, Monasson and Zecchina (Phys. Rev. E 56 (2)(1997) 1357) proposed the random (2+ p)-SAT model: for a given p\u2208[0, 1], a random (2+ p)-SAT formula, F 2+ p (n, m), has m randomly chosen clauses over n variables, where pm clauses are chosen from B 3 and (1\u2212 p) m from B 2. Using the heuristic \u201creplica method\u201d of statistical mechanics, Monasson and Zecchina gave a number of non \u2026",
            "Abstract entirety": 0,
            "Author pub id": "GBQ6w8IAAAAJ:2P1L_qKh6hAC",
            "Publisher": "Elsevier"
        },
        {
            "Title": "Hiding satisfying assignments: two are better than one",
            "Publication year": 2005,
            "Publication url": "https://www.jair.org/index.php/jair/article/view/10429",
            "Abstract": "The evaluation of incomplete satisfiability solvers depends critically on the availability of hard satisfiable instances. A plausible source of such instances consists of random k-SAT formulas whose clauses are chosen uniformly from among all clauses satisfying some randomly chosen truth assignment A. Unfortunately, instances generated in this manner tend to be relatively easy and can be solved efficiently by practical heuristics. Roughly speaking, for a number of different algorithms, A acts as a stronger and stronger attractor as the formula's density increases. Motivated by recent results on the geometry of the space of satisfying truth assignments of random k-SAT and NAE-k-SAT formulas, we introduce a simple twist on this basic model, which appears to dramatically increase its hardness. Namely, in addition to forbidding the clauses violated by the hidden assignment A, we also forbid the clauses violated by its complement, so that both A and compliment of A are satisfying. It appears that under this\" symmetrization\" the effects of the two attractors largely cancel out, making it much harder for algorithms to find any truth assignment. We give theoretical and experimental evidence supporting this assertion.",
            "Abstract entirety": 1,
            "Author pub id": "GBQ6w8IAAAAJ:35N4QoGY0k4C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Methods and systems for computing singular value decompositions of matrices and low rank approximations of matrices",
            "Publication year": 2008,
            "Publication url": "https://patents.google.com/patent/US7433850B2/en",
            "Abstract": "Methods and systems for finding a low rank approximation for an m\u00d7 n matrix A are described. The described embodiments can independently sample and/or quantize the entries of an input matrix A, and can thus speed up computation by reducing the number of non-zero entries and/or their representation length. The embodiments can be used in connection with Singular Value Decomposition techniques to greatly benefit the processing of high-dimensional data sets in terms of storage, transmission and computation.",
            "Abstract entirety": 1,
            "Author pub id": "GBQ6w8IAAAAJ:bnK-pcrLprsC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Bounds for random constraint satisfaction problems via spatial coupling",
            "Publication year": 2016,
            "Publication url": "https://epubs.siam.org/doi/abs/10.1137/1.9781611974331.ch35",
            "Abstract": "We report on a novel technique called spatial coupling and its application in the analysis of random constraint satisfaction problems (CSP). Spatial coupling was invented as an engineering construction in the area of error correcting codes where it has resulted in efficient capacity-achieving codes for a wide range of channels. However, this technique is not limited to problems in communications, and can be applied in the much broader context of graphical models. We describe here a general methodology for applying spatial coupling to random constraint satisfaction problems and obtain lower bounds for their (rough) satisfiability threshold. The main idea is to construct a distribution of geometrically structured random K-SAT instances \u2013 namely the spatially coupled ensemble \u2013 which has the same (rough) satisfiability threshold, and is at the same time algorithmically easier to solve. Then by running well-known \u2026",
            "Abstract entirety": 0,
            "Author pub id": "GBQ6w8IAAAAJ:u5HHmVD_uO8C",
            "Publisher": "Society for Industrial and Applied Mathematics"
        },
        {
            "Title": "The Lov\u00e1sz Local Lemma as a Random Walk",
            "Publication year": 2014,
            "Publication url": "https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.749.3098&rep=rep1&type=pdf",
            "Abstract": "We give an algorithmic local lemma by establishing a sufficient condition for the uniform random walk on a directed graph to reach a sink quickly. Our work is inspired by Moser\u2019s entropic method proof of the Lov\u00e1sz Local Lemma for satisfiability and completely bypasses the Probabilistic Method formulation of the LLL. In particular our method works when the set of underlying objects is entirely unstructured. Similarly to Moser\u2019s argument, the key point is that algorithmic progress is measured in terms of entropy rather than energy (number of violated constraints) so that termination can be established even under the proliferation of states in which every step of the algorithm (random walk) increases the total number of violated constraints.",
            "Abstract entirety": 1,
            "Author pub id": "GBQ6w8IAAAAJ:VOx2b1Wkg3QC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Methods and systems of testing software, and methods and systems of modeling user behavior",
            "Publication year": 2006,
            "Publication url": "https://patents.google.com/patent/US6996805B2/en",
            "Abstract": "Methods and systems of testing software and modeling user actions are described. In some embodiments, multiple different algorithms are provided for operating on a software model. The software model describes behavior associated with software that is to be tested. Different sets of algorithms can be selected for operating on the software model to produce a sequence of test actions that are to be used to test the software. The algorithms can be mixed and matched to achieve a desired testing result. In some embodiments, the different algorithms comprise deterministic algorithms, random algorithms, and various types of algorithms therebetween. In one embodiment, the software model comprises a state graph having nodes that represent state, and links between the nodes that represent actions. The different algorithms that are available for selection can have different graph traversal characteristics such that the \u2026",
            "Abstract entirety": 0,
            "Author pub id": "GBQ6w8IAAAAJ:O3NaXMp0MMsC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Fast and flexible probabilistic model counting",
            "Publication year": 2018,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-319-94144-8_10",
            "Abstract": "We present a probabilistic model counter that can trade off running time with approximation accuracy. As in several previous works, the number of models of a formula is estimated by adding random parity constraints (equations). One key difference with prior works is that the systems of parity equations used correspond to the parity check matrices of Low Density Parity Check (LDPC) error-correcting codes. As a result, the equations tend to be much shorter, often containing fewer than 10 variables each, making the search for models that also satisfy the parity constraints far more tractable. The price paid for computational tractability is that the statistical properties of the basic estimator are not as good as when longer constraints are used. We show how one can deal with this issue and derive rigorous approximation guarantees by performing more solver invocations.",
            "Abstract entirety": 1,
            "Author pub id": "GBQ6w8IAAAAJ:5nxA0vEk-isC",
            "Publisher": "Springer, Cham"
        },
        {
            "Title": "Database-friendly random projections: Johnson-Lindenstrauss with binary coins",
            "Publication year": 2003,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S0022000003000254",
            "Abstract": "A classic result of Johnson and Lindenstrauss asserts that any set of n points in d-dimensional Euclidean space can be embedded into k-dimensional Euclidean space\u2014where k is logarithmic in n and independent of d\u2014so that all pairwise distances are maintained within an arbitrarily small factor. All known constructions of such embeddings involve projecting the n points onto a spherically random k-dimensional hyperplane through the origin. We give two constructions of such embeddings with the property that all elements of the projection matrix belong in {\u22121,0,+1}. Such constructions are particularly well suited for database environments, as the computation of the embedding reduces to evaluating a single aggregate over k random partitions of the attributes.",
            "Abstract entirety": 1,
            "Author pub id": "GBQ6w8IAAAAJ:RYcK_YlVTxYC",
            "Publisher": "Academic Press"
        },
        {
            "Title": "Fast computation of low-rank matrix approximations",
            "Publication year": 2007,
            "Publication url": "https://scholar.google.com/scholar?cluster=14061363079781900196&hl=en&oi=scholarr",
            "Abstract": "Given a matrix A it is often desirable to find an approximation to A that has low rank. We introduce a simple technique for accelerating the computation of such approximations when A has strong spectral structure, ie, when the singular values of interest are significantly greater than those of a random matrix with size and entries similar to A. Our technique amounts to independently sampling and/or quantizing the entries of A, thus speeding up computation by reducing the number of non-zero entries and/or the length of their representation. Our analysis is based on observing that the acts of sampling and quantization can be viewed as adding a random matrix E to A, whose entries are independent random variables with zero-mean and bounded variance. Since, with high probability, E has very weak spectral structure, we can prove that the effect of sampling and quantization nearly vanishes when a low rank approximation to A+ E is computed. In fact, the stronger the spectral structure of A, the more of its entries we can afford to discard and, ultimately, the faster we can discover that structure. We give bounds on the quality of our approximation both in the L2 and in the Frobenius norm.",
            "Abstract entirety": 1,
            "Author pub id": "GBQ6w8IAAAAJ:PELIpwtuRlgC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Stateless, affinity-preserving load balancing",
            "Publication year": 2012,
            "Publication url": "https://patents.google.com/patent/US8134916B2/en",
            "Abstract": "The invention relates to an architecture that facilitates load balancing among a plurality of hosts and preserve session affinity to a given host. An incoming stream of data packets that include packet sessions is input to one or more forwarding mechanisms for forwarding to one or more hosts. The forwarders generate a routing function that takes into consideration host availability, and distributes session packets according to the routing function. A session is distributed to the same host to preserve session affinity. When host availability changes, a new routing function is generated, such that any new session is routed according to the new routing function and existing sessions are routed according to the old routing function. When the old routing function becomes irrelevant, it is phased out. An optimization utilizes a maximally backward compatible hash function to minimize the differences between the old and new \u2026",
            "Abstract entirety": 0,
            "Author pub id": "GBQ6w8IAAAAJ:eQOLeE2rZwMC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Random formulas have frozen variables",
            "Publication year": 2009,
            "Publication url": "https://epubs.siam.org/doi/abs/10.1137/070680382",
            "Abstract": "For a large number of random constraint satisfaction problems, such as random k-SAT and random graph and hypergraph coloring, there exist very good estimates of the largest constraint density for which solutions exist. All known polynomial-time algorithms for these problems, though, fail to find solutions even at much lower densities. To understand the origin of this gap one can study how the structure of the space of solutions evolves in such problems as constraints are added. In particular, it is known that much before solutions disappear, they organize into an exponential number of clusters, each of which is relatively small and far apart from all other clusters. Here we further prove that inside every cluster the vast majority of variables are frozen, i.e., take only one value. The existence of such frozen variables gives a satisfying intuitive explanation for the failure of the polynomial-time algorithms analyzed so far. At \u2026",
            "Abstract entirety": 0,
            "Author pub id": "GBQ6w8IAAAAJ:mB3voiENLucC",
            "Publisher": "Society for Industrial and Applied Mathematics"
        },
        {
            "Title": "Explosive percolation in random networks",
            "Publication year": 2009,
            "Publication url": "https://science.sciencemag.org/content/323/5920/1453.abstract",
            "Abstract": "Networks in which the formation of connections is governed by a random process often undergo a percolation transition, wherein around a critical point, the addition of a small number of connections causes a sizable fraction of the network to suddenly become linked together. Typically such transitions are continuous, so that the percentage of the network linked together tends to zero right above the transition point. Whether percolation transitions could be discontinuous has been an open question. Here, we show that incorporating a limited amount of choice in the classic Erd\u00f6s-R\u00e9nyi network formation model causes its percolation transition to become discontinuous.",
            "Abstract entirety": 1,
            "Author pub id": "GBQ6w8IAAAAJ:M05iB0D1s5AC",
            "Publisher": "American Association for the Advancement of Science"
        },
        {
            "Title": "Stochastic Integration via Error-Correcting Codes.",
            "Publication year": 2015,
            "Publication url": "http://auai.org/uai2015/proceedings/papers/248.pdf",
            "Abstract": "We consider the task of summing a non-negative function f over a discrete set \u2126, eg, to compute the partition function of a graphical model. Ermon et al. have shown that in a probabilistic approximate sense summation can be reduced to maximizing f over random subsets of \u2126 defined by parity (XOR) constraints. Unfortunately, XORs with many variables are computationally intractable, while XORs with few variables have poor statistical performance. We introduce two ideas to address this problem, both motivated by the theory of error-correcting codes. The first is to maximize f over explicitly generated random affine subspaces of \u2126, which is equivalent to unconstrained maximization of f over an exponentially smaller domain. The second idea, closer in spirit to the original approach, is to use systems of linear equations defining Low Density Parity Check (LDPC) error-correcting codes. Even though the equations in such systems only contain O (1) variables each, their sets of solutions (codewords) have excellent statistical properties. By combining these ideas we achieve dramatic speedup over the original approach and levels of accuracy that were completely unattainable.",
            "Abstract entirety": 1,
            "Author pub id": "GBQ6w8IAAAAJ:tOudhMTPpwUC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Method and apparatus for processing program threads",
            "Publication year": 2008,
            "Publication url": "https://patents.google.com/patent/US7337443B2/en",
            "Abstract": "A procedure identifies a program image and generates a basic block flow graph associated with the program image. Execution of the program image is benchmarked and the basic block flow graph is annotated with the results of the benchmarking of the program image. Basic blocks of the program are then grouped into bins. When the program image is executed, a drafting scheduler stops threads before they leave a bin and schedules any threads queued for the same bin.",
            "Abstract entirety": 1,
            "Author pub id": "GBQ6w8IAAAAJ:Se3iqnhoufwC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Sampling techniques for kernel methods",
            "Publication year": 2002,
            "Publication url": "https://books.google.com/books?hl=en&lr=&id=PGrlRWV5-v0C&oi=fnd&pg=PA335&dq=info:cH1VunNGXQgJ:scholar.google.com&ots=ax6QXyHPav&sig=R5UcFxrw9kYUBji3Zmd8V1oKMeo",
            "Abstract": "We propose randomized techniques for speeding up Kernel Principal Component Analysis on three levels: sampling and quantization of the Gram matrix in training, randomized rounding in evaluating the kernel expansions, and random projections in evaluating the kernel itself. In all three cases, we give sharp bounds on the accuracy of the obtained approximations. Rather intriguingly, all three techniques can be viewed as instantiations of the following idea: replace the kernel function A; by a\" randomized kernel\" which behaves like k in expectation.",
            "Abstract entirety": 1,
            "Author pub id": "GBQ6w8IAAAAJ:dfsIfKJdRG4C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Simple Local Computation Algorithms for the General Lov\u00e1sz Local Lemma",
            "Publication year": 2020,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/3350755.3400250",
            "Abstract": "We consider the task of designing Local Computation Algorithms (LCA) for applications of the Lovasz Local Lemma (LLL). LCA is a class of sublinear algorithms proposed by Rubinfeld et al. that have received a lot of attention in recent years. The LLL is an existential, sufficient condition for a collection of sets to have non-empty intersection (in applications, often, each set comprises all objects having a certain property). The ground-breaking algorithm of Moser and Tardos made the LLL fully constructive, following earlier results by Beck and Alon giving algorithms under significantly stronger LLL-like conditions. LCAs under those stronger conditions were given in Rubinfeld et al., where it was asked if the Moser-Tardos algorithm can be used to design LCAs under the standard LLL condition. The main contribution of this paper is to answer this question affirmatively. In fact, our techniques yield LCAs for settings beyond \u2026",
            "Abstract entirety": 0,
            "Author pub id": "GBQ6w8IAAAAJ:Mojj43d5GZwC",
            "Publisher": "Unknown"
        },
        {
            "Title": "A local lemma for focused stochastic algorithms",
            "Publication year": 2019,
            "Publication url": "https://epubs.siam.org/doi/abs/10.1137/16M109332X",
            "Abstract": "We develop a framework for the rigorous analysis of focused stochastic local search algorithms. These  algorithms search a state space by repeatedly selecting some constraint that is violated in the current state and moving to a random nearby state that addresses the violation, while (we hope) not introducing many new violations. An important class of focused local search algorithms with provable performance guarantees has recently arisen from algorithmizations of the Lova\u0301sz local lemma (LLL), a nonconstructive tool for proving the existence of satisfying states by introducing a background measure on the state space. While powerful, the state transitions of algorithms in this class must be, in a precise sense, perfectly compatible with the background measure. In many applications this is a very restrictive requirement, and one needs to step outside the class.  Here we introduce the notion of measure distortion and \u2026",
            "Abstract entirety": 0,
            "Author pub id": "GBQ6w8IAAAAJ:lSLTfruPkqcC",
            "Publisher": "Society for Industrial and Applied Mathematics"
        },
        {
            "Title": "Setting 2 variables at a time yields a new lower bound for random 3-SAT",
            "Publication year": 2000,
            "Publication url": "https://dl.acm.org/doi/pdf/10.1145/335305.335309",
            "Abstract": "Let X be a set of n Boolean variables and denote by C (X) the set of all 3-clauses over X, ie the set of all 8 (3) possible disjunctions of three distinct, non-complementary literais from variables in X. Let F (n, m) be a random 3-SAT formula formed by selecting, with replacement, m clauses uniformly at random from C (X) and taking their conjunction. The satisfiabili~ y threshold conjecture asserts that there exists a constant ra such that as n--+ c\u00a2, F (n, rn) is satisfiable with probability that tends to 1 if r< ra, but unsatisfiable with probability that tends to 1 if r:> r3. Experimental evidence suggests rz~ 4.2.We prove rz> 3.145 improving over the previous best lower bound r3> 3.003 due to Frieze and Suen. For this, we introduce a satisfiability heuristic that works iteratively, permanently setting the value of a pair of variables in each round. The framework we develop for the analysis of our heuristic allows us to also derive most \u2026",
            "Abstract entirety": 0,
            "Author pub id": "GBQ6w8IAAAAJ:sSrBHYA8nusC",
            "Publisher": "Unknown"
        },
        {
            "Title": "On the solution\u2010space geometry of random constraint satisfaction problems",
            "Publication year": 2011,
            "Publication url": "https://onlinelibrary.wiley.com/doi/abs/10.1002/rsa.20323",
            "Abstract": "For various random constraint satisfaction problems there is a significant gap between the largest constraint density for which solutions exist and the largest density for which any polynomial time algorithm is known to find solutions. Examples of this phenomenon include random k\u2010SAT, random graph coloring, and a number of other random constraint satisfaction problems. To understand this gap, we study the structure of the solution space of random k\u2010SAT (i.e., the set of all satisfying assignments viewed as a subgraph of the Hamming cube). We prove that for densities well below the satisfiability threshold, the solution space decomposes into an exponential number of connected components and give quantitative bounds for the diameter, volume, and number.\u00a9 2010 Wiley Periodicals, Inc. Random Struct. Alg., 38, 251\u2013268, 2011",
            "Abstract entirety": 1,
            "Author pub id": "GBQ6w8IAAAAJ:_FxGoFyzp5QC",
            "Publisher": "Wiley Subscription Services, Inc., A Wiley Company"
        },
        {
            "Title": "A sharp threshold in proof complexity yields lower bounds for satisfiability search",
            "Publication year": 2004,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S0022000003001466",
            "Abstract": "Let F(\u03c1n,\u0394n) denote a random CNF formula consisting of \u03c1n randomly chosen 2-clauses and \u0394n randomly chosen 3-clauses, for some arbitrary constants \u03c1,\u0394\u2a7e0. It is well-known that, with probability 1\u2212o(1), if \u03c1>1 then F(\u03c1n,\u0394n) has a linear-size resolution refutation. We prove that, with probability 1\u2212o(1), if \u03c1<1 then F(\u03c1n,\u0394n) has no subexponential-size resolution refutation.Our result also yields the first proof that random 3-CNF formulas with densities well below the generally accepted range of the satisfiability threshold (and thus believed to be satisfiable) cause natural Davis\u2013Putnam algorithms to take exponential time (to find a satisfying assignment).",
            "Abstract entirety": 1,
            "Author pub id": "GBQ6w8IAAAAJ:pyW8ca7W8N0C",
            "Publisher": "Academic Press"
        },
        {
            "Title": "On the bias of traceroute sampling",
            "Publication year": 2005,
            "Publication url": "http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.241.9516&rep=rep1&type=pdf",
            "Abstract": "Understanding the structure of the Internet graph is a crucial step for building accurate network models and designing efficient algorithms for Internet applications. Yet, obtaining its graph structure is a surprisingly difficult task, as edges cannot be explicitly queried. Instead, empirical studies rely on traceroutes to build what are essentially single-source, all-destinations, shortest-path trees. These trees only sample a fraction of the network\u2019s edges, and a recent paper by Lakhina et al. found empirically that the resuting sample is intrinsically biased. For instance, the observed degree distribution under traceroute sampling exhibits a power law even when the underlying degree distribution is Poisson. In this paper, we study the bias of traceroute sampling systematically, and, for a very general class of underlying degree distributions, calculate the likely observed distributions explicitly. To do this, we use a continuous-time realization of the process of exposing the BFS tree of a random graph with a given degree distribution, calculate the expected degree distribution of the tree, and show that it is sharply concentrated. As example applications of our machinery, we show how traceroute sampling finds power-law degree distributions in both \u03b4-regular and Poisson-distributed random graphs. Thus, our work puts the observations of Lakhina et al. on a rigorous footing, and extends them to nearly arbitrary degree distributions.",
            "Abstract entirety": 1,
            "Author pub id": "GBQ6w8IAAAAJ:RHpTSmoSYBkC",
            "Publisher": "Unknown"
        },
        {
            "Title": "The asymptotic order of the k-SAT threshold",
            "Publication year": 2002,
            "Publication url": "https://arxiv.org/abs/cond-mat/0209622",
            "Abstract": "Form a random k-SAT formula on n variables by selecting uniformly and independently m=rn clauses out of all 2^k (n choose k) possible k-clauses. The Satisfiability Threshold Conjecture asserts that for each k there exists a constant r_k such that, as n tends to infinity, the probability that the formula is satisfiable tends to 1 if r < r_k and to 0 if r > r_k. It has long been known that 2^k / k < r_k < 2^k. We prove that r_k > 2^{k-1} \\ln 2 - d_k, where d_k \\to (1+\\ln 2)/2. Our proof also allows a blurry glimpse of the ``geometry'' of the set of satisfying truth assignments, and a nearly exact location of the threshold for Not-All-Equal (NAE) k-SAT.",
            "Abstract entirety": 1,
            "Author pub id": "GBQ6w8IAAAAJ:WA5NYHcadZ8C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Random Solutions of Random Problems... are not just Random",
            "Publication year": 2008,
            "Publication url": "https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.313.7726&rep=rep1&type=pdf",
            "Abstract": "Let In, m denote a uniformly random instance of some constraint satisfaction problem CSP with n variables and m constraints. Assume that the density r= m/n is small enough so that with high probability In, m has a solution, and consider the experiment of first choosing an instance I= In, m at random, and then sampling a random solution \u03c3 of I (if one exists). For many CSPs (eg, k-SAT, k-NAE, or k-coloring), this experiment appears difficult both to implement and to analyze; in fact, for a large range of r, no efficient algorithm is known to even compute a single solution of I. In the present paper we show that for many CSPs the above experiment is essentially equivalent to first choosing a random assignment \u03c3 to the n variables, and then drawing a random instance satisfied by \u03c3 uniformly. In general, this second experiment is very easy to implement and amenable to a rigorous analysis. In fact, using this equivalence, we can analyze the solution space of random CSPs. Thus, we can achieve the longstanding goal of establishing rigorously a picture put forward by statistical physicists on the basis of sophisticated but non-rigorous techniques such as the cavity and the replica method. This picture is suggestive as to why random CSP instances seem difficult to deal with algorithmically. Furthermore, we show that the second experiment gives rise to one-way functions, if one assumes that random instances of CSP are hard for some range of densities.",
            "Abstract entirety": 1,
            "Author pub id": "GBQ6w8IAAAAJ:HDshCWvjkbEC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Probabilistic model counting with short XORs",
            "Publication year": 2017,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-319-66263-3_1",
            "Abstract": "The idea of counting the number of satisfying truth assignments (models) of a formula by adding random parity constraints can be traced back to the seminal work of Valiant and Vazirani, showing that NP is as easy as detecting unique solutions. While theoretically sound, the random parity constraints in that construction have the following drawback: each constraint, on average, involves half of all variables. As a result, the branching factor associated with searching for models that also satisfy the parity constraints quickly gets out of hand. In this work we prove that one can work with much shorter parity constraints and still get rigorous mathematical guarantees, especially when the number of models is large so that many constraints need to be added. Our work is based on the realization that the essential feature for random systems of parity constraints to be useful in probabilistic model counting is that the \u2026",
            "Abstract entirety": 0,
            "Author pub id": "GBQ6w8IAAAAJ:TFP_iSt0sucC",
            "Publisher": "Springer, Cham"
        },
        {
            "Title": "Stochastic control via entropy compression",
            "Publication year": 2016,
            "Publication url": "https://arxiv.org/abs/1607.06494",
            "Abstract": "We consider an agent trying to bring a system to an acceptable state by repeated probabilistic action. Several recent works on algorithmizations of the Lovasz Local Lemma (LLL) can be seen as establishing sufficient conditions for the agent to succeed. Here we study whether such stochastic control is also possible in a noisy environment, where both the process of state-observation and the process of state-evolution are subject to adversarial perturbation (noise). The introduction of noise causes the tools developed for LLL algorithmization to break down since the key LLL ingredient, the sparsity of the causality (dependence) relationship, no longer holds. To overcome this challenge we develop a new analysis where entropy plays a central role, both to measure the rate at which progress towards an acceptable state is made and the rate at which noise undoes this progress. The end result is a sufficient condition that allows a smooth tradeoff between the intensity of the noise and the amenability of the system, recovering an asymmetric LLL condition in the noiseless case.",
            "Abstract entirety": 1,
            "Author pub id": "GBQ6w8IAAAAJ:mvPsJ3kp5DgC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Database-friendly random projections",
            "Publication year": 2001,
            "Publication url": "https://ci.nii.ac.jp/naid/20001706865/",
            "Abstract": "\u96fb\u5b50\u60c5\u5831\u901a\u4fe1\u5b66\u4f1a\u6280\u8853\u7814\u7a76\u5831\u544a. IBISML, \u60c5\u5831\u8ad6\u7684\u5b66\u7fd2\u7406\u8ad6\u3068\u6a5f\u68b0\u5b66\u7fd2= IEICE technical report. IBISML, Information-based induction sciences and machine learning 112 (279), 151-155, 2012-10-31",
            "Abstract entirety": 1,
            "Author pub id": "GBQ6w8IAAAAJ:wbdj-CoPYUoC",
            "Publisher": "ACM"
        },
        {
            "Title": "Balance and filtering in structured satisfiable problems",
            "Publication year": 2001,
            "Publication url": "https://www.researchgate.net/profile/Bart-Selman/publication/228834534_Balance_and_filtering_in_structured_satisfiable_problems/links/00b7d51a82c8352e9b000000/Balance-and-filtering-in-structured-satisfiable-problems.pdf",
            "Abstract": "New methods to generate hard random problem instances have driven progress on algorithms for deduction and constraint satisfaction. Recently Achlioptas et al.(AAAI 2000) introduced a new generator based on Latin squares that creates only satisfiable problems, and so can be used to accurately test incomplete (one sided) solvers. We investigate how this and other generators are biased away from the uniform distribution of satisfiable problems and show how they can be improved by imposing a balance condition. More generally, we show that the generator is one member of a family of related models that generate distributions ranging from ones that are everywhere tractable to ones that exhibit a sharp hardness threshold. We also discuss the critical role of the problem encoding in the performance of both systematic and local search solvers.",
            "Abstract entirety": 1,
            "Author pub id": "GBQ6w8IAAAAJ:Tyk-4Ss8FVUC",
            "Publisher": "Unknown"
        },
        {
            "Title": "System and method adapted to facilitate dimensional transform",
            "Publication year": 2006,
            "Publication url": "https://patents.google.com/patent/US7043514B1/en",
            "Abstract": "Systems and methods that facilitate dimensional transformations of data points are disclosed. In particular, the subject invention provides for a system and methodology that simplifies dimensional transformations while mitigating variations of a distance property between pairs of points. A set of n data points in d dimensional space is represented as an n\u00d7 d input matrix, where d also corresponds to the number of attributes per data point. A transformed matrix represents the n data points in a lower dimensionality k after being mapped. The transformed matrix is an n\u00d7 k matrix, where k is the number of attributes per data point and is less than d. The transformed matrix is obtained by multiplying the input matrix by a suitable projection matrix. The projection matrix is generated by randomly populating the entries of the matrix with binary or ternary values according to a probability distribution. Unlike previous methods, the \u2026",
            "Abstract entirety": 0,
            "Author pub id": "GBQ6w8IAAAAJ:1sJd4Hv_s6UC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Methods and systems of testing software, and methods and systems of modeling user behavior",
            "Publication year": 2009,
            "Publication url": "https://patents.google.com/patent/US7624378B2/en",
            "Abstract": "Methods and systems of testing software and modeling user actions are described. In some embodiments, multiple different algorithms are provided for operating on a software model. The software model describes behavior associated with software that is to be tested. Different sets of algorithms can be selected for operating on the software model to produce a sequence of test actions that are to be used to test the software. The algorithms can be mixed and matched to achieve a desired testing result. In some embodiments, the different algorithms comprise deterministic algorithms, random algorithms, and various types of algorithms therebetween. In one embodiment, the software model comprises a state graph having nodes that represent state, and links between the nodes that represent actions. The different algorithms that are available for selection can have different graph traversal characteristics such that the \u2026",
            "Abstract entirety": 0,
            "Author pub id": "GBQ6w8IAAAAJ:dhFuZR0502QC",
            "Publisher": "Unknown"
        },
        {
            "Title": "A new perspective on stochastic local search and the lovasz local lemma",
            "Publication year": 2018,
            "Publication url": "https://scholar.google.com/scholar?cluster=17521603980123095360&hl=en&oi=scholarr",
            "Abstract": "We present a new perspective on the analysis of stochastic local search algorithms, via linear algebra, and use it to establish a new criterion for their convergence. Our criterion captures and unifies the analysis of all currently known LLL-inspired local search algorithms, including all current applications of the entropy compression method. It can be seen as a generalization of the Lov\u00e1sz Local Lemma that quantifies the interaction strength of bad events, so that weak interactions form correspondingly small obstacles to algorithmic convergence. As a demonstration of its power, we use our criterion to analyze a complex local search algorithm for the classical problem of coloring graphs with sparse neighborhoods. We prove that any improvement over our algorithm would require a major (and unexpected) breakthrough in random graph theory, suggesting that our criterion reaches the edge of tractability for this problem. Finally, we consider questions such as the number of possible distinct final states and the probability that certain portions of the state space are visited by a local search algorithm. Such information is currently available for the Moser-Tardos algorithm and for algorithms satisfying a combinatorial notion of commutativity introduced of Kolmogorov. Our framework provides a very natural and more general notion of commutativity (essentially matrix commutativity) which allows the recovery of all such results with much simpler proofs.",
            "Abstract entirety": 1,
            "Author pub id": "GBQ6w8IAAAAJ:q3oQSFYPqjQC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Erasure Coding & Read/Write Separation in Flash Storage",
            "Publication year": 2014,
            "Publication url": "https://www.usenix.org/conference/inflow14/workshop-program/presentation/skourtis",
            "Abstract": "We want to create a scalable flash storage system that provides read/write separation and uses erasure coding to provide reliability without the storage cost of replication. Flash on Rails is a system for enabling consistent performance in flash storage by physically separating reads from writes through redundancy. In principle, Rails supports erasure codes. However, it has only been evaluated using replication in small arrays, so it is currently uncertain how it would scale with erasure coding.",
            "Abstract entirety": 1,
            "Author pub id": "GBQ6w8IAAAAJ:IjCSPb-OGe4C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Optimal policies for greedy 3-SAT algorithms",
            "Publication year": 2000,
            "Publication url": "https://scholar.google.com/scholar?cluster=17202647502079845697&hl=en&oi=scholarr",
            "Abstract": "Random 30CNF formulas with low _density%~ ratio of number of clauses to number of variables~ are satisfiable with high probability. Lower bounds on the limiting density have come from analyzing algorithms that _reveal% all occurrences of one or more variables, set each to true or false, and proceed with the reduced formula. We show how to optimize the _policy% for setting a variable true or false, thereby both raising the density bound from 3.145 to 3.26, and closing out some lines of inquiry. We rely upon an e ciently solvable _multiple0choice knapsack problem%.",
            "Abstract entirety": 1,
            "Author pub id": "GBQ6w8IAAAAJ:eflP2zaiRacC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Stateless, affinity-preserving load balancing",
            "Publication year": 2010,
            "Publication url": "https://patents.google.com/patent/US7693050B2/en",
            "Abstract": "The invention relates to an architecture that facilitates load balancing among a plurality of hosts and preserve session affinity to a given host. An incoming stream of data packets that include packet sessions is input to one or more forwarding mechanisms for forwarding to one or more hosts. The forwarders generate a routing function that takes into consideration host availability, and distributes session packets according to the routing function. A session is distributed to the same host to preserve session affinity. When host availability changes, a new routing function is generated, such that any new session is routed according to the new routing function and existing sessions are routed according to the old routing function. When the old routing function becomes irrelevant, it is phased out. An optimization utilizes a maximally backward compatible hash function to minimize the differences between the old and new \u2026",
            "Abstract entirety": 0,
            "Author pub id": "GBQ6w8IAAAAJ:UebtZRa9Y70C",
            "Publisher": "Unknown"
        },
        {
            "Title": "The asymptotic order of the random k-SAT threshold",
            "Publication year": 2002,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/1182003/",
            "Abstract": "Form a random k-SAT formula on n variables by selecting uniformly and independently m=rn clauses out of all 2/sup k/ (/sub k//sup n/) possible k-clauses. The satisfiability threshold conjecture asserts that for each k there exists a constant r/sub k/ such that, as n tends to infinity, the probability that the formula is satisfiable tends to 1 if rr/sub k/. It has long been known that 2/sup k//k<r/sub k/<2/sup k/. We prove that r/sub k/>2/sup k-1/ ln 2-d/sub k/, where d/sub k//spl rarr/(1+ln2)/2. Our proof also allows a blurry glimpse of the \"geometry\" of the set of satisfying truth assignments.",
            "Abstract entirety": 1,
            "Author pub id": "GBQ6w8IAAAAJ:Wp0gIr-vW9MC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Summary-based routing for content-based event distribution networks",
            "Publication year": 2004,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/1039111.1039113",
            "Abstract": "Providing scalable distributed Web-based eventing services has been an important research topic. It is desirable to have an effective mechanism for the servers to summarize their filters for in-network preprocessing in order to optimize system performance. In this paper, we propose a summary-based routing mechanism and introduce the notion of imprecise summaries to provide a trade-off between routing overhead and event traffic. Our system uses similarity-based filter clustering to reduce overall event traffic and performs self-tuning summary precision selection to optimize throughput. We have implemented summary-based routing on top of an XML-based infrastructure that closely follows the proposed Web services standards. Measurements from the actual implementation validate our analytical and simulation results, and demonstrate the practical benefits of the proposed techniques.",
            "Abstract entirety": 1,
            "Author pub id": "GBQ6w8IAAAAJ:zYLM7Y9cAGgC",
            "Publisher": "ACM"
        },
        {
            "Title": "Web search via hub synthesis",
            "Publication year": 2001,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/959926/",
            "Abstract": "We present a model for web search that captures in a unified manner three critical components of the problem: how the link structure of the web is generated, how the content of a web document is generated, and how a human searcher generates a query. The key to this unification lies in capturing the correlations between these components in terms of proximity in a shared latent semantic space. Given such a combined model, the correct answer to a search query is well defined, and thus it becomes possible to evaluate web search algorithms rigorously. We present a new web search algorithm, based on spectral techniques, and prove that it is guaranteed to produce an approximately correct answer in our model. The algorithm assumes no knowledge of the model, and is well-defined regardless of the model's accuracy.",
            "Abstract entirety": 1,
            "Author pub id": "GBQ6w8IAAAAJ:u_35RYKgDlwC",
            "Publisher": "IEEE"
        }
    ]
}]