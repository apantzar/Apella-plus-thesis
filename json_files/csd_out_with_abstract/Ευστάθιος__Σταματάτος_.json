[{
    "name": "\u0395\u03c5\u03c3\u03c4\u03ac\u03b8\u03b9\u03bf\u03c2  \u03a3\u03c4\u03b1\u03bc\u03b1\u03c4\u03ac\u03c4\u03bf\u03c2 ",
    "romanize name": "Efstathios  Stamatatos ",
    "School-Department": "\u039c\u03b7\u03c7\u03b1\u03bd\u03b9\u03ba\u03ce\u03bd \u03a0\u03bb\u03b7\u03c1\u03bf\u03c6\u03bf\u03c1\u03b9\u03b1\u03ba\u03ce\u03bd \u03ba\u03b1\u03b9 \u0395\u03c0\u03b9\u03ba\u03bf\u03b9\u03bd\u03c9\u03bd\u03b9\u03b1\u03ba\u03ce\u03bd \u03a3\u03c5\u03c3\u03c4\u03b7\u03bc\u03ac\u03c4\u03c9\u03bd",
    "University": "aegean",
    "Rank": "\u039a\u03b1\u03b8\u03b7\u03b3\u03b7\u03c4\u03ae\u03c2",
    "Apella_id": 6081,
    "Scholar name": "Efstathios Stamatatos",
    "Scholar id": "xie8sAEAAAAJ",
    "Affiliation": "University of the Aegean",
    "Citedby": 8846,
    "Interests": [
        "Text mining",
        "Information retrieval",
        "Machine learning"
    ],
    "Scholar url": "https://scholar.google.com/citations?user=xie8sAEAAAAJ&hl=en",
    "Publications": [
        {
            "Title": "Masking domain-specific information for cross-domain deception detection",
            "Publication year": 2020,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S0167865520301422",
            "Abstract": "The facilities provided by social media and computer-mediated communication make easy the dissemination of deceptive behavior, after which different entities or people could be affected. The deception detection by supervised learning has been widely studied; however, the scenario in which there is one domain of interest and the labeled data is in another domain has received poor attention. This paper presents, to our knowledge, the first domain adaptation approach for cross-domain deception detection in texts. Our proposal consists in modifying original texts from the source and target domains in a form in which common content and style information is maintained, but domain-specific information is masked. In order to adequately select domain-specific terms to be masked, the proposed method uses unlabeled instances from both domains. Our experiments demonstrate that the masking technique is a good \u2026",
            "Abstract entirety": 0,
            "Author pub id": "xie8sAEAAAAJ:dTyEYWd-f8wC",
            "Publisher": "North-Holland"
        },
        {
            "Title": "Overview of the 5th international competition on plagiarism detection",
            "Publication year": 2012,
            "Publication url": "https://scholar.google.com/scholar?cluster=13452423156825806921&hl=en&oi=scholarr",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "xie8sAEAAAAJ:xtRiw3GOFMkC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Detection of text reuse in french medical corpora",
            "Publication year": 2016,
            "Publication url": "https://aclanthology.org/W16-5112/",
            "Abstract": "Electronic Health Records (EHRs) are increasingly available in modern health care institutions either through the direct creation of electronic documents in hospitals\u2019 health information systems, or through the digitization of historical paper records. Each EHR creation method yields the need for sophisticated text reuse detection tools in order to prepare the EHR collections for efficient secondary use relying on Natural Language Processing methods. Herein, we address the detection of two types of text reuse in French EHRs: 1) the detection of updated versions of the same document and 2) the detection of document duplicates that still bear surface differences due to OCR or de-identification processing. We present a robust text reuse detection method to automatically identify redundant document pairs in two French EHR corpora that achieves an overall macro F-measure of 0.68 and 0.60, respectively and correctly identifies all redundant document pairs of interest.",
            "Abstract entirety": 1,
            "Author pub id": "xie8sAEAAAAJ:SP6oXDckpogC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Who wrote the web? Revisiting influential author identification research applicable to information retrieval",
            "Publication year": 2016,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-319-30671-1_29",
            "Abstract": "In this paper, we revisit author identification research by conducting a new kind of large-scale reproducibility study: we select 15 of the most influential papers for author identification and recruit a group of students to reimplement them from scratch. Since no open source implementations have been released for the selected papers to date, our public release will have a significant impact on researchers entering the field. This way, we lay the groundwork for integrating author identification with information retrieval to eventually scale the former to the web. Furthermore, we assess the reproducibility of all reimplemented papers in detail, and conduct the first comparative evaluation of all approaches on three well-known corpora.",
            "Abstract entirety": 1,
            "Author pub id": "xie8sAEAAAAJ:CHSYGLWDkRkC",
            "Publisher": "Springer, Cham"
        },
        {
            "Title": "Text Sampling and Re-sampling for Imbalanced Authorship Identification Cases",
            "Publication year": 2006,
            "Publication url": "https://www.academia.edu/download/44789880/Text_Sampling_and_Re-Sampling_for_Imbala20160416-26596-n473v3.pdf",
            "Abstract": "Authorship identification can be seen as a single-label multi-class text categorization problem. Very often, there are extremely few training texts at least for some of the candidate authors. In this paper, we present methods to handle imbalanced multi-class textual datasets. The main idea is to segment the training texts into sub-samples according to the size of the class. Hence, minority classes can be segmented into many short samples and majority classes into less and longer samples. Moreover, we explore text re-sampling in order to construct a training set according to a desirable distribution over the classes. Essentially, text re-sampling can be viewed as providing new synthetic data that increase the training size of a class. Based on a corpus of newswire stories in English we present authorship identification experiments on various multi-class imbalanced cases.",
            "Abstract entirety": 1,
            "Author pub id": "xie8sAEAAAAJ:M3ejUd6NZC8C",
            "Publisher": "IOS Press"
        },
        {
            "Title": "Cross-domain authorship attribution using pre-trained language models",
            "Publication year": 2020,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-030-49161-1_22",
            "Abstract": "Authorship attribution attempts to identify the authors behind texts and has important applications mainly in cyber-security, digital humanities and social media analytics. An especially challenging but very realistic scenario is cross-domain attribution where texts of known authorship (training set) differ from texts of disputed authorship (test set) in topic or genre. In this paper, we modify a successful authorship verification approach based on a multi-headed neural network language model and combine it with pre-trained language models. Based on experiments on a controlled corpus covering several text genres where topic and genre is specifically controlled, we demonstrate that the proposed approach achieves very promising results. We also demonstrate the crucial effect of the normalization corpus in cross-domain attribution.",
            "Abstract entirety": 1,
            "Author pub id": "xie8sAEAAAAJ:9vf0nzSNQJEC",
            "Publisher": "Springer, Cham"
        },
        {
            "Title": "Extracting informative textual parts from web pages containing user-generated content",
            "Publication year": 2012,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/2362456.2362462",
            "Abstract": "The vast amount of user-generated content on the Web has increased the need for handling the problem of automatically processing content in web pages. The segmentation of web pages and noise (non-informative segment) removal are important pre-processing steps in a variety of applications such as sentiment analysis, text summarization and information retrieval. Currently, these two tasks tend to be handled separately or are handled together without emphasizing the diversity of the web corpora and the web page type detection. We present a unified approach that is able to provide robust identification of informative textual parts in web pages along with accurate type detection. The proposed algorithm takes into account visual and non-visual characteristics of a web page and is able to remove noisy parts from three major categories of pages which contain user-generated content (News, Blogs, Discussions \u2026",
            "Abstract entirety": 0,
            "Author pub id": "xie8sAEAAAAJ:_Qo2XoVZTnwC",
            "Publisher": "Unknown"
        },
        {
            "Title": "An Improved Impostors Method for Authorship Verification",
            "Publication year": 2017,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-319-65813-1_14",
            "Abstract": "Authorship verification has gained a lot of attention during the last years mainly due to the focus of PAN@CLEF shared tasks. A verification method called Impostors, based on a set of external (impostor) documents and a random subspace ensemble, is one of the most successful approaches. Variations of this method gained top-performing positions in recent PAN evaluation campaigns. In this paper, we propose a modification of the Impostors method that focuses on both appropriate selection of impostor documents and enhanced comparison of impostor documents with the documents under investigation. Our approach achieves competitive performance on PAN corpora, outperforming previous versions of the Impostors method.",
            "Abstract entirety": 1,
            "Author pub id": "xie8sAEAAAAJ:vRqMK49ujn8C",
            "Publisher": "Springer, Cham"
        },
        {
            "Title": "Author identification: Using text sampling to handle the class imbalance problem",
            "Publication year": 2008,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S0306457307001197",
            "Abstract": "Authorship analysis of electronic texts assists digital forensics and anti-terror investigation. Author identification can be seen as a single-label multi-class text categorization problem. Very often, there are extremely few training texts at least for some of the candidate authors or there is a significant variation in the text-length among the available training texts of the candidate authors. Moreover, in this task usually there is no similarity between the distribution of training and test texts over the classes, that is, a basic assumption of inductive learning does not apply. In this paper, we present methods to handle imbalanced multi-class textual datasets. The main idea is to segment the training texts into text samples according to the size of the class, thus producing a fairer classification model. Hence, minority classes can be segmented into many short samples and majority classes into less and longer samples. We explore text \u2026",
            "Abstract entirety": 0,
            "Author pub id": "xie8sAEAAAAJ:WF5omc3nYNoC",
            "Publisher": "Pergamon"
        },
        {
            "Title": "Empirical Music Performance Research: OFAI\u2019s Position",
            "Publication year": 2001,
            "Publication url": "https://www.researchgate.net/profile/Efstathios-Stamatatos/publication/2407435_Empirical_Music_Performance_Research_OFAI's_Position/links/0912f514494cca7f0f000000/Empirical-Music-Performance-Research-OFAIs-Position.pdf",
            "Abstract": "This short paper presents our view on some general questions regarding empirical research on expressive music performance. The main direction of performance research going on at the Austrian Research Institute for Artificial Intelligence (OFAI) is briefly reviewed and positioned relative to three general issues, namely, different research strategies, different dimensions of performance, and the question of empirical evaluation of performance models.",
            "Abstract entirety": 1,
            "Author pub id": "xie8sAEAAAAJ:aqlVkmm33-oC",
            "Publisher": "Panel Discussion Paper, MOSART Workshop on Current Research Directions in Computer Music"
        },
        {
            "Title": "Recent trends in digital text forensics and its evaluation",
            "Publication year": 2013,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-642-40802-1_28",
            "Abstract": "This paper outlines the concepts and achievements of our evaluation lab on digital text forensics, PAN 13, which called for original research and development on plagiarism detection, author identification, and author profiling. We present a standardized evaluation framework for each of the three tasks and discuss the evaluation results of the altogether 58 submitted contributions. For the first time, instead of accepting the output of software runs, we collected the softwares themselves and run them on a computer cluster at our site. As evaluation and experimentation platform we use TIRA, which is being developed at the Webis Group in Weimar. TIRA can handle large-scale software submissions by means of virtualization, sandboxed execution, tailored unit testing, and staged submission. In addition to the achieved evaluation results, a major achievement of our lab is that we now have the largest collection of \u2026",
            "Abstract entirety": 0,
            "Author pub id": "xie8sAEAAAAJ:GnPB-g6toBAC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "Identifying authorship by byte-level n-grams: The source code author profile (scap) method",
            "Publication year": 2007,
            "Publication url": "https://www.utica.edu/academic/institutes/ecii/publications/articles/B41158D1-C829-0387-009D214D2170C321.pdf",
            "Abstract": "Source code author identification deals with identifying the most likely author of a computer program, given a set of predefined author candidates. There are several scenarios where digital evidence of this kind plays a role in investigation and adjudication, such as code authorship disputes, intellectual property infringement, tracing the source of code left in the system after a cyber attack, and so forth. As in any identification task, the disputed program is compared to undisputed, known programming samples by the predefined author candidates. We present a new approach, called the SCAP (Source Code Author Profiles) approach, based on byte-level n-gram profiles representing the source code author\u2019s style. The SCAP method extends a method originally applied to natural language text authorship attribution; we show that an n-gram approach also suits the characteristics of source code analysis. The methodological extension includes a simplified profile and a less complicated, but more effective, similarity measure. Experiments on data sets of different programming-language (Java or C++) and commented/commentless code demonstrate the effectiveness of these extensions. The SCAP approach is programming-language independent. Moreover, the SCAP approach deals surprisingly well with cases where only a limited amount of very short programs per programmer is available for training. Finally, it is also demonstrated that SCAP effectiveness persists even in the absence of comments in the source code, a condition usually met in cyber-crime cases.",
            "Abstract entirety": 1,
            "Author pub id": "xie8sAEAAAAJ:5nxA0vEk-isC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Plagiarism detection using stopword n\u2010grams",
            "Publication year": 2011,
            "Publication url": "https://asistdl.onlinelibrary.wiley.com/doi/abs/10.1002/asi.21630",
            "Abstract": "In this paper a novel method for detecting plagiarized passages in document collections is presented. In contrast to previous work in this field that uses content terms to represent documents, the proposed method is based on a small list of stopwords (i.e., very frequent words). We show that stopword n\u2010grams reveal important information for plagiarism detection since they are able to capture syntactic similarities between suspicious and original documents and they can be used to detect the exact plagiarized passage boundaries. Experimental results on a publicly available corpus demonstrate that the performance of the proposed approach is competitive when compared with the best reported results. More importantly, it achieves significantly better results when dealing with difficult plagiarism cases where the plagiarized passages are highly modified and most of the words or phrases have been replaced with \u2026",
            "Abstract entirety": 0,
            "Author pub id": "xie8sAEAAAAJ:TQgYirikUcIC",
            "Publisher": "Wiley Subscription Services, Inc., A Wiley Company"
        },
        {
            "Title": "The Class Imbalance Problem in Author Identification.",
            "Publication year": 2007,
            "Publication url": "http://ceur-ws.org/Vol-276/paper1.pdf",
            "Abstract": "Author identification can be seen as a single-label multi-class text categorization problem. Very often, there are extremely few training texts at least for some of the candidate authors or there is a significant variation in the text-length among the available training texts of the candidate authors. Moreover, in this task usually there is no similarity between the distribution of training and test texts over the classes, that is, a basic assumption of inductive learning does not apply. Previous work [3] provided solutions to this problem for instance-based author identification approaches (ie, each training text is considered a separate training instance). This work [4] deals with the class imbalance problem in profile-based author identification approaches (ie, a profile is extracted from all the training texts per author). In particular, a variation of the Common N-Grams (CNG) method, a language-independent profile-based approach [2] with good results in many author identification experiments so far [1], is presented based on new distance measures that are quite stable for large profile length values. Special emphasis is given to the degree upon which the effectiveness of the method is affected by the available training text samples per author. Experiments based on text samples on the same topic from the Reuters Corpus Volume 1 are presented using both balanced and imbalanced training corpora. The results show that CNG with the proposed distance measures is more accurate when only limited training text samples are available, at least for some of the candidate authors, a realistic condition in author identification problems.",
            "Abstract entirety": 1,
            "Author pub id": "xie8sAEAAAAJ:L8Ckcad2t8MC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Dynamic ensemble selection for author verification",
            "Publication year": 2019,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-030-15712-8_7",
            "Abstract": "Author verification is a fundamental task in authorship analysis and associated with significant applications in humanities, cyber-security, and social media analytics. In some of the relevant studies, there is evidence that heterogeneous ensembles can provide very reliable solutions, better than any individual verification model. However, there is no systematic study of examining the application of ensemble methods in this task. In this paper, we start from a large set of base verification models covering the main paradigms in this area and study how they can be combined to build an accurate ensemble. We propose a simple stacking ensemble as well as a dynamic ensemble selection approach that can use the most reliable base models for each verification case separately. The experimental results in ten benchmark corpora covering multiple languages and genres verify the suitability of ensembles for this \u2026",
            "Abstract entirety": 0,
            "Author pub id": "xie8sAEAAAAJ:5ugPr518TE4C",
            "Publisher": "Springer, Cham"
        },
        {
            "Title": "Syntactic n-grams as machine learning features for natural language processing",
            "Publication year": 2014,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S0957417413006271",
            "Abstract": "In this paper we introduce and discuss a concept of syntactic n-grams (sn-grams). Sn-grams differ from traditional n-grams in the manner how we construct them, i.e., what elements are considered neighbors. In case of sn-grams, the neighbors are taken by following syntactic relations in syntactic trees, and not by taking words as they appear in a text, i.e., sn-grams are constructed by following paths in syntactic trees. In this manner, sn-grams allow bringing syntactic knowledge into machine learning methods; still, previous parsing is necessary for their construction. Sn-grams can be applied in any natural language processing (NLP) task where traditional n-grams are used. We describe how sn-grams were applied to authorship attribution. We used as baseline traditional n-grams of words, part of speech (POS) tags and characters; three classifiers were applied: support vector machines (SVM), naive Bayes (NB), and \u2026",
            "Abstract entirety": 0,
            "Author pub id": "xie8sAEAAAAJ:ns9cj8rnVeAC",
            "Publisher": "Pergamon"
        },
        {
            "Title": "Overview of PAN 2020: Authorship Verification, Celebrity Profiling, Profiling Fake News Spreaders on Twitter, and Style Change Detection",
            "Publication year": 2020,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-030-58219-7_25",
            "Abstract": "We briefly report on the four shared tasks organized as part of the PAN 2020 evaluation lab on digital text forensics and authorship analysis. Each tasks is introduced, motivated, and the results obtained are presented. Altogether, the four tasks attracted 230 registrations, yielding 83 successful submissions. This, and the fact that we continue to invite the submissions of software rather than its run output using the TIRA experimentation platform, marks for a good start into the second decade of PAN evaluations labs.",
            "Abstract entirety": 1,
            "Author pub id": "xie8sAEAAAAJ:LjlpjdlvIbIC",
            "Publisher": "Springer, Cham"
        },
        {
            "Title": "Fourth international workshop on uncovering plagiarism, authorship, and social software misuse",
            "Publication year": 2011,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/1988852.1988860",
            "Abstract": "The Fourth International Workshop on Uncovering Plagiarism, Authorship, and Social Software Misuse (PAN10) was held in conjunction with the 2010 Conference on Multilingual and Multimodal Information Access Evaluation (CLEF-10) in Padua, Italy. The workshop was organized as a competition covering two tasks: plagiarism detection and Wikipedia vandalism detection. This report gives a short overview of the plagiarism detection task. Detailed analyses of both tasks have been published as CLEF Notebook Papers [3, 6], which can be downloaded at www.webis.de/publications.",
            "Abstract entirety": 1,
            "Author pub id": "xie8sAEAAAAJ:qUcmZB5y_30C",
            "Publisher": "ACM"
        },
        {
            "Title": "A survey of modern authorship attribution methods",
            "Publication year": 2009,
            "Publication url": "https://asistdl.onlinelibrary.wiley.com/doi/abs/10.1002/asi.21001",
            "Abstract": "Authorship attribution supported by statistical or computational methods has a long history starting from the 19th century and is marked by the seminal study of Mosteller and Wallace (1964) on the authorship of the disputed \u201cFederalist Papers.\u201d During the last decade, this scientific field has been developed substantially, taking advantage of research advances in areas such as machine learning, information retrieval, and natural language processing. The plethora of available electronic texts (e.g., e\u2010mail messages, online forum messages, blogs, source code, etc.) indicates a wide variety of applications of this technology, provided it is able to handle short and noisy text from multiple candidate authors. In this article, a survey of recent advances of the automated approaches to attributing authorship is presented, examining their characteristics for both text representation and text classification. The focus of this survey \u2026",
            "Abstract entirety": 0,
            "Author pub id": "xie8sAEAAAAJ:9yKSN-GCB0IC",
            "Publisher": "Wiley Subscription Services, Inc., A Wiley Company"
        },
        {
            "Title": "CEUR WORKSHOP PROCEEDINGS",
            "Publication year": 2016,
            "Publication url": "https://scholar.google.com/scholar?cluster=12955903500856407196&hl=en&oi=scholarr",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "xie8sAEAAAAJ:ye4kPcJQO24C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Improving the quality of degraded document images",
            "Publication year": 2006,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/1612976/",
            "Abstract": "It is common for libraries to provide public access to historical and ancient document image collections. It is common for such document images to require specialized processing in order to remove background noise and become more legible. In this paper, we propose a hybrid binarization approach for improving the quality of old documents using a combination of global and local thresholding. First, a global thresholding technique specifically designed for old document images is applied to the entire image. Then, the image areas that still contain background noise are detected and the same technique is re-applied to each area separately. Hence, we achieve better adaptability of the algorithm in cases where various kinds of noise coexist in different areas of the same image while avoiding the computational and time cost of applying a local thresholding in the entire image. Evaluation results based on a collection of \u2026",
            "Abstract entirety": 0,
            "Author pub id": "xie8sAEAAAAJ:zYLM7Y9cAGgC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Examining the significance of high-level programming features in source code author classification",
            "Publication year": 2008,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S0164121207000829",
            "Abstract": "The use of Source Code Author Profiles (SCAP) represents a new, highly accurate approach to source code authorship identification that is, unlike previous methods, language independent. While accuracy is clearly a crucial requirement of any author identification method, in cases of litigation regarding authorship, plagiarism, and so on, there is also a need to know why it is claimed that a piece of code is written by a particular author. What is it about that piece of code that suggests a particular author? What features in the code make one author more likely than another? In this study, we describe a means of identifying the high-level features that contribute to source code authorship identification using as a tool the SCAP method. A variety of features are considered for Java and Common Lisp and the importance of each feature in determining authorship is measured through a sequence of experiments in which we \u2026",
            "Abstract entirety": 0,
            "Author pub id": "xie8sAEAAAAJ:Wp0gIr-vW9MC",
            "Publisher": "Elsevier"
        },
        {
            "Title": "Identification of plagiarism using syntactic and semantic filters",
            "Publication year": 2014,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-642-54903-8_41",
            "Abstract": "We present a work on detection of manual paraphrasing in documents in comparison with a set of source documents. Manual paraphrasing is a realistic type of plagiarism, where the obfuscation is introduced manually in documents. We have used PAN-PC-10 data set to develop and evaluate our algorithm. The proposed approach consists of two steps, namely, identification of probable plagiarized passages using dice similarity measure and filtering the obtained passages using syntactic rules and lexical semantic features extracted from obfuscation patterns. The algorithm works at sentence level. The results are encouraging in difficult cases of plagiarism that most of the existing approaches fail to detect.",
            "Abstract entirety": 1,
            "Author pub id": "xie8sAEAAAAJ:u_35RYKgDlwC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "PAN20 Authorship Analysis: Authorship Verification",
            "Publication year": 2020,
            "Publication url": "https://scholar.google.com/scholar?cluster=2755225466898891748&hl=en&oi=scholarr",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "xie8sAEAAAAJ:1yQoGdGgb4wC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Authorship verification: a review of recent advances",
            "Publication year": 2016,
            "Publication url": "https://rcs.cic.ipn.mx/2016_123/Authorship%20Verification_%20A%20Review%20of%20Recent%20Advances.pdf",
            "Abstract": "Authorship verification attempts to decide whether the author of a given set of texts is also the author of a disputed text. In comparison to closed-set and open-set attribution, the most popular tasks in relevant literature, the verification setting has some important advantages. First, it is more general since any attribution problem can be decomposed into a series of verification cases. Then, certain factors that affect the performance of closed-set and open-set attribution, like the candidate set size and the distribution of training texts over the candidate authors have limited impact on authorship verification. It is, therefore, more feasible to estimate the error rate of authorship attribution technology, needed in the framework of forensic applications, when focusing on the verification setting. Recently, there has been increasing interest for authorship verification, mainly due to the PAN shared tasks organized in 2013, 2014, and 2015. Multiple methods were developed and tested in new benchmark corpora covering several languages and genres. This paper presents a review of recent advances in this field focusing on the evaluation results of PAN shared tasks. Moreover, it discusses successes, failures, and open issues.",
            "Abstract entirety": 1,
            "Author pub id": "xie8sAEAAAAJ:mvPsJ3kp5DgC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Automatic text categorization in terms of genre and author",
            "Publication year": 2000,
            "Publication url": "https://direct.mit.edu/coli/article-abstract/26/4/471/1675",
            "Abstract": "The two main factors that characterize a text are its content and its style, and both can be used as a means of categorization. In this paper we present an approach to text categorization in terms of genre and author for Modern Greek. In contrast to previous stylometric approaches, we attempt to take full advantage of existing natural language processing (NLP) tools. To this end, we propose a set of style markers including analysis-level measures that represent the way in which the input text has been analyzed and capture useful stylistic information without additional cost. We present a set of small-scale but reasonable experiments in text genre detection, author identification, and author verification tasks and show that the proposed method performs better than the most popular distributional lexical measures, i.e., functions of vocabulary richness and frequencies of occurrence of the most frequent words. All the \u2026",
            "Abstract entirety": 0,
            "Author pub id": "xie8sAEAAAAJ:u5HHmVD_uO8C",
            "Publisher": "MIT Press"
        },
        {
            "Title": "Syntactic dependency-based n-grams: More evidence of usefulness in classification",
            "Publication year": 2013,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-642-37247-6_2",
            "Abstract": "The paper introduces and discusses a concept of syntactic n-grams (sn-grams) that can be applied instead of traditional n-grams in many NLP tasks. Sn-grams are constructed by following paths in syntactic trees, so sn-grams allow bringing syntactic knowledge into machine learning methods. Still, previous parsing is necessary for their construction. We applied sn-grams in the task of authorship attribution for corpora of three and seven authors with very promising results.",
            "Abstract entirety": 1,
            "Author pub id": "xie8sAEAAAAJ:blknAaTinKkC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "Authorship attribution using text distortion",
            "Publication year": 2017,
            "Publication url": "https://www.aclweb.org/anthology/E17-1107.pdf",
            "Abstract": "Authorship attribution is associated with important applications in forensics and humanities research. A crucial point in this field is to quantify the personal style of writing, ideally in a way that is not affected by changes in topic or genre. In this paper, we present a novel method that enhances authorship attribution effectiveness by introducing a text distortion step before extracting stylometric measures. The proposed method attempts to mask topic-specific information that is not related to the personal style of authors. Based on experiments on two main tasks in authorship attribution, closed-set attribution and authorship verification, we demonstrate that the proposed approach can enhance existing methods especially under cross-topic conditions, where the training and test corpora do not match in topic.",
            "Abstract entirety": 1,
            "Author pub id": "xie8sAEAAAAJ:Tiz5es2fbqcC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Words versus character n-grams for anti-spam filtering",
            "Publication year": 2007,
            "Publication url": "https://www.worldscientific.com/doi/abs/10.1142/S0218213007003692",
            "Abstract": "The increasing number of unsolicited e-mail messages (spam) reveals the need for the development of reliable anti-spam filters. The vast majority of content-based techniques rely on word-based representation of messages. Such approaches require reliable tokenizers for detecting the token boundaries. As a consequence, a common practice of spammers is to attempt to confuse tokenizers using unexpected punctuation marks or special characters within the message. In this paper we explore an alternative low-level representation based on character n-grams which avoids the use of tokenizers and other language-dependent tools. Based on experiments on two well-known benchmark corpora and a variety of evaluation measures, we show that character n-grams are more reliable features than word-tokens despite the fact that they increase the dimensionality of the problem. Moreover, we propose a method for \u2026",
            "Abstract entirety": 0,
            "Author pub id": "xie8sAEAAAAJ:Se3iqnhoufwC",
            "Publisher": "World Scientific Publishing Company"
        },
        {
            "Title": "On the robustness of authorship attribution based on character n-gram features",
            "Publication year": 2012,
            "Publication url": "https://heinonline.org/hol-cgi-bin/get_pdf.cgi?handle=hein.journals/jlawp21&section=24",
            "Abstract": "A number of independent authorship attribution studies have demonstrated the effectiveness of character n-gram features for representing the stylistic properties of text. However, the vast majority of these studies examined the simple case where the training and test corpora are similar in terms of genre, topic, and distribution of the texts. Hence, there are doubts whether such a simple and low-level representation is equally effective in realistic conditions where some of the above factors are not possible to remain stable. In this study, the robustness of authorship attribution based on character n-gram features is tested under cross-genre and cross-topic conditions. In addition, the distribution of texts over the candidate authors varies in training and test corpora to imitate real cases. Comparative results with another competitive text representation approach based on very frequent words show that character n-grams are \u2026",
            "Abstract entirety": 0,
            "Author pub id": "xie8sAEAAAAJ:O3NaXMp0MMsC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Automatic generation of summary obfuscation corpus for plagiarism detection",
            "Publication year": 2017,
            "Publication url": "https://www.researchgate.net/profile/Efstathios-Stamatatos/publication/321704912_Automatic_Generation_of_Summary_Obfuscation_Corpus_for_Plagiarism_Detection/links/5a61b73b4585158bca4a1382/Automatic-Generation-of-Summary-Obfuscation-Corpus-for-Plagiarism-Detection.pdf",
            "Abstract": "In this paper, we describe an approach to create a summary obfuscation corpus for the task of plagiarism detection. Our method is based on information from the Document Understanding Conferences related to years 2001 and 2006, for the English language. Overall, an unattributed summary used within someone else\u2019s document is considered a kind of plagiarism because the main author\u2019s ideas are still in a succinct form. In order to create the corpus, we use a Named Entity Recognizer (NER) to identify the entities within an original document, its associated summaries, and target documents. After, these entities, together with similar paragraphs in target documents, are used to make fake suspicious documents and plagiarized documents. The corpus was tested in plagiarism competition.",
            "Abstract entirety": 1,
            "Author pub id": "xie8sAEAAAAJ:geHnlv5EZngC",
            "Publisher": "Unknown"
        },
        {
            "Title": "An Intelligent Distributed System for Automatic Sentiment Analysis from Topic-Specific Web Sources: Confidence Model and Sentiment Analysis",
            "Publication year": 2011,
            "Publication url": "http://www.icsd.aegean.gr/website_files/diplomatikes/msc/189758729.pdf",
            "Abstract": "The present document deals with the design and analysis of an intelligent system that uses distributed structure to achieve automatic sentiment analysis on opinions extracted from sources related to a specific topic from the World Wide Web (WWW). Starting from a set of simple user-defined parameters including topic; relevant documents are discovered by Focused Crawler Agents who use state-of-the-art focused crawling methods. In cooperation with Miner Agents the retrieval of the segments (useful regions) of those documents is accomplished. Next, a confidence is calculated for extracting segmented regions with high probability of containing opinions and a complete sentiment analysis is made to these regions, which includes subjectivity and polarity classification methods bootstrapped for optimized precision. In order to be applied to a variety of topics, the system follows unsupervised and supervised learning methods derived the Machine Learning (ML) domain. The contents of this document address the first part of the above procedure which includes the discovery and the extraction of the relevant data.",
            "Abstract entirety": 1,
            "Author pub id": "xie8sAEAAAAJ:08ZZubdj9fEC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Overview of PAN 2021: Authorship Verification, Profiling Hate Speech Spreaders on Twitter, and Style Change Detection",
            "Publication year": 2021,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-030-85251-1_26",
            "Abstract": "The paper gives a brief overview of the three shared tasks organized at the PAN 2021 lab on digital text forensics and stylometry hosted at the CLEF conference. The tasks include authorship verification across domains, author profiling for hate speech spreaders, and style change detection for multi-author documents. In part the tasks are new and in part they continue and advance past shared tasks, with the overall goal of advancing the state of the art, providing for an objective evaluation on newly developed benchmark datasets.",
            "Abstract entirety": 1,
            "Author pub id": "xie8sAEAAAAJ:N5tVd3kTz84C",
            "Publisher": "Springer, Cham"
        },
        {
            "Title": "Plagiarism detection based on structural information",
            "Publication year": 2011,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/2063576.2063754",
            "Abstract": "In this paper a novel method for detecting plagiarized passages in document collections is presented. In contrast to previous work in this field that uses mainly content terms to represent documents, the proposed method is based on structural information provided by occurrences of a small list of stopwords (ie, very frequent words). We show that stopword n-grams are able to capture local syntactic similarities between suspicious and original documents. Moreover, an algorithm for detecting the exact boundaries of plagiarized and source passages is proposed. Experimental results on a publicly-available corpus demonstrate that the performance of the proposed approach is competitive when compared with the best reported results. More importantly, it achieves significantly better results when dealing with difficult plagiarism cases where the plagiarized passages are highly modified by replacing most of the words or \u2026",
            "Abstract entirety": 0,
            "Author pub id": "xie8sAEAAAAJ:R3hNpaxXUhUC",
            "Publisher": "Unknown"
        },
        {
            "Title": "N-gram feature selection for authorship identification",
            "Publication year": 2006,
            "Publication url": "https://link.springer.com/chapter/10.1007/11861461_10",
            "Abstract": "Automatic authorship identification offers a valuable tool for supporting crime investigation and security. It can be seen as a multi-class, single-label text categorization task. Character n-grams are a very successful approach to represent text for stylistic purposes since they are able to capture nuances in lexical, syntactical, and structural level. So far, character n-grams of fixed length have been used for authorship identification. In this paper, we propose a variable-length n-gram approach inspired by previous work for selecting variable-length word sequences. Using a subset of the new Reuters corpus, consisting of texts on the same topic by 50 different authors, we show that the proposed approach is at least as effective as information gain for selecting the most significant n-grams although the feature sets produced by the two methods have few common members. Moreover, we explore the significance of \u2026",
            "Abstract entirety": 0,
            "Author pub id": "xie8sAEAAAAJ:UeHWp8X0CEIC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "The importance of suppressing domain style in authorship analysis",
            "Publication year": 2020,
            "Publication url": "https://arxiv.org/abs/2005.14714",
            "Abstract": "The prerequisite of many approaches to authorship analysis is a representation of writing style. But despite decades of research, it still remains unclear to what extent commonly used and widely accepted representations like character trigram frequencies actually represent an author's writing style, in contrast to more domain-specific style components or even topic. We address this shortcoming for the first time in a novel experimental setup of fixed authors but swapped domains between training and testing. With this setup, we reveal that approaches using character trigram features are highly susceptible to favor domain information when applied without attention to domains, suffering drops of up to 55.4 percentage points in classification accuracy under domain swapping. We further propose a new remedy based on domain-adversarial learning and compare it to ones from the literature based on heuristic rules. Both can work well, reducing accuracy losses under domain swapping to 3.6% and 3.9%, respectively.",
            "Abstract entirety": 1,
            "Author pub id": "xie8sAEAAAAJ:SdhP9T11ey4C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Open-Set Web Genre Identification Using Distributional Features and Nearest Neighbors Distance Ratio",
            "Publication year": 2019,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-030-15719-7_1",
            "Abstract": "Web genre identification can boost information retrieval systems by providing rich descriptions of documents and enabling more specialized queries. The open-set scenario is more realistic for this task as web genres evolve over time and it is not feasible to define a universally agreed genre palette. In this work, we bring to bear a novel approach to web genre identification underpinned by distributional features acquired by doc2vec and a recently-proposed open-set classification algorithm\u2014the nearest neighbors distance ratio classifier. We present experimental results using a benchmark corpus and a strong baseline and demonstrate that the proposed approach is highly competitive, especially when emphasis is given on precision.",
            "Abstract entirety": 1,
            "Author pub id": "xie8sAEAAAAJ:bnK-pcrLprsC",
            "Publisher": "Springer, Cham"
        },
        {
            "Title": "Ensemble-based author identification using character n-grams",
            "Publication year": 2006,
            "Publication url": "https://webis.de/events/tir-06/tir06-proceedings/tir-06-proceedings.pdf#page=45",
            "Abstract": "This paper deals with the problem of identifying the most likely author of a text. Several thousands of character n-grams, rather than lexical or syntactic information, are used to represent the style of a text. Thus, the author identification task can be viewed as a single-label multiclass classification problem of high dimensional feature space and sparse data. In order to cope with such properties, we propose a suitable learning ensemble based on feature set subspacing. Performance results on two well-tested benchmark text corpora for author identification show that this classification scheme is quite effective, significantly improving the best reported results so far. Additionally, this approach is proved to be quite stable in comparison with support vector machines when using limited number of training texts, a condition usually met in this kind of problem.",
            "Abstract entirety": 1,
            "Author pub id": "xie8sAEAAAAJ:eQOLeE2rZwMC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Music performer verification based on learning ensembles",
            "Publication year": 2004,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-540-24674-9_14",
            "Abstract": "In this paper the problem of music performer verification is introduced. Given a certain performance of a musical piece and a set of candidate pianists the task is to examine whether or not a particular pianist is the actual performer. A database of 22 pianists playing pieces by F. Chopin in a computer-controlled piano is used in the presented experiments. An appropriate set of features that captures the idiosyncrasies of music performers is proposed. Well-known machine learning techniques for constructing learning ensembles are applied and remarkable results are described in verifying the actual pianist, a very difficult task even for human experts.",
            "Abstract entirety": 1,
            "Author pub id": "xie8sAEAAAAJ:qxL8FJ1GzNcC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "Overview of PAN 2018",
            "Publication year": 2018,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-319-98932-7_25",
            "Abstract": "PAN 2018 explores several authorship analysis tasks enabling a systematic comparison of competitive approaches and advancing research in digital text forensics. More specifically, this edition of PAN introduces a shared task in cross-domain authorship attribution, where texts of known and unknown authorship belong to distinct domains, and another task in style change detection that distinguishes between single-author and multi-author texts. In addition, a shared task in multimodal author profiling examines, for the first time, a combination of information from both texts and images posted by social media users to estimate their gender. Finally, the author obfuscation task studies how a text by a certain author can be paraphrased so that existing author identification tools are confused and cannot recognize the similarity with other texts of the same author. New corpora have been built to support these \u2026",
            "Abstract entirety": 0,
            "Author pub id": "xie8sAEAAAAJ:BrmTIyaxlBUC",
            "Publisher": "Springer, Cham"
        },
        {
            "Title": "Intrinsic plagiarism detection using character n-gram profiles",
            "Publication year": 2009,
            "Publication url": "http://ceur-ws.org/Vol-502/paper8.pdf",
            "Abstract": "The task of intrinsic plagiarism detection deals with cases where no reference corpus is available and it is exclusively based on stylistic changes or inconsistencies within a given document. In this paper a new method is presented that attempts to quantify the style variation within a document using character n-gram profiles and a style change function based on an appropriate dissimilarity measure originally proposed for author identification. In addition, we propose a set of heuristic rules that attempt to detect plagiarism\u2013free documents and plagiarized passages, as well as to reduce the effect of irrelevant style changes within a document. The proposed approach is evaluated on the recently-available corpus of the 1st Int. Competition on Plagiarism Detection with promising results.",
            "Abstract entirety": 1,
            "Author pub id": "xie8sAEAAAAJ:Y0pCki6q_DkC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Overview of the Author Identification Task at PAN 2014.",
            "Publication year": 2014,
            "Publication url": "https://core.ac.uk/download/pdf/275905758.pdf",
            "Abstract": "The author identification task at PAN-2014 focuses on author verification. Similar to PAN-2013 we are given a set of documents by the same author along with exactly one document of questioned authorship, and the task is to determine whether the known and the questioned documents are by the same author or not. In comparison to PAN-2013, a significantly larger corpus was built comprising hundreds of documents in four natural languages (Dutch, English, Greek, and Spanish) and four genres (essays, reviews, novels, opinion articles). In addition, more suitable performance measures are used focusing on the accuracy and the confidence of the predictions as well as the ability of the submitted methods to leave some problems unanswered in case there is great uncertainty. To this end, we adopt the c@ 1 measure, originally proposed for the question answering task. We received 13 software submissions that were evaluated in the TIRA framework. Analytical evaluation results are presented where one language-independent approach serves as a challenging baseline. Moreover, we continue the successful practice of the PAN labs to examine meta-models based on the combination of all submitted systems. Last but not least, we provide statistical significance tests to demonstrate the important differences between the submitted approaches.",
            "Abstract entirety": 1,
            "Author pub id": "xie8sAEAAAAJ:dfsIfKJdRG4C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Overview of the pan/clef 2015 evaluation lab",
            "Publication year": 2015,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-319-24027-5_49",
            "Abstract": "This paper presents an overview of the PAN/CLEF evaluation lab. During the last decade, PAN has been established as the main forum of text mining research focusing on the identification of personal traits of authors left behind in texts unintentionally. PAN 2015 comprises three tasks: plagiarism detection, author identification and author profiling studying important variations of these problems. In plagiarism detection, community-driven corpus construction is introduced as a new way of developing evaluation resources with diversity. In author identification, cross-topic and cross-genre author verification (where the texts of known and unknown authorship do not match in topic and/or genre) is introduced. A new corpus was built for this challenging, yet realistic, task covering four languages. In author profiling, in addition to usual author demographics, such as gender and age, five personality traits are \u2026",
            "Abstract entirety": 0,
            "Author pub id": "xie8sAEAAAAJ:EUQCXRtRnyEC",
            "Publisher": "Springer, Cham"
        },
        {
            "Title": "Overview of PAN 2019: author profiling, celebrity profiling, cross-domain authorship attribution and style change detection",
            "Publication year": 2019,
            "Publication url": "https://scholar.google.com/scholar?cluster=10014399999373883610&hl=en&oi=scholarr",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "xie8sAEAAAAJ:JoZmwDi-zQgC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Tensor space models for authorship identification",
            "Publication year": 2008,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-540-87881-0_22",
            "Abstract": "Authorship identification can be viewed as a text categorization task. However, in this task the most frequent features appear to be the most important discriminators, there is usually a shortage of training texts, and the training texts are rarely evenly distributed over the authors. To cope with these problems, we propose tensors of second order for representing the stylistic properties of texts. Our approach requires the calculation of much fewer parameters in comparison to the traditional vector space representation. We examine various methods for building appropriate tensors taking into account that similar features should be placed in the same neighborhood. Based on an existing generalization of SVM able to handle tensors we perform experiments on corpora controlled for genre and topic and show that the proposed approach can effectively handle cases where only limited training texts are available.",
            "Abstract entirety": 1,
            "Author pub id": "xie8sAEAAAAJ:kNdYIx-mwKoC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "Overview of the 5th international competition on plagiarism detection",
            "Publication year": 2013,
            "Publication url": "https://riunet.upv.es/handle/10251/46635",
            "Abstract": "This paper overviews 18 plagiarism detectors that have been evaluated within the fifth international competition on plagiarism detection at PAN 2013. We report on their performances for the two tasks source retrieval and text alignment of external plagiarism detection. Furthermore, we continue last year\u2019s initiative to invite software submissions instead of run submissions, and, re-evaluate this year\u2019s submissions on last year\u2019s evaluation corpora and vice versa, thus demonstrating the benefits of software submissions in terms of reproducibility.",
            "Abstract entirety": 1,
            "Author pub id": "xie8sAEAAAAJ:bFI3QPDXJZMC",
            "Publisher": "CELCT"
        },
        {
            "Title": "Universality of stylistic traits in texts",
            "Publication year": 2016,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-319-24403-7_9",
            "Abstract": "The style of documents is an important property that can be used as discriminant factor in text mining applications. Among the great number of possible measures proposed to quantify writing style there are some features that can be characterized as universal, in the sense that they can be easily extracted from any kind of text in practically any natural language and provide accurate results when used in style-based text categorization tasks. In this paper we examine whether such universal stylometric features remain effective under difficult scenarios where the topic and/or genre of documents used in the training phase differ from that of the questioned documents. Based on a series of experiments in authorship attribution, we demonstrate that character n-gram features are reliable and effective given that the appropriate number of features is used. It is also shown that when the number of candidate authors \u2026",
            "Abstract entirety": 0,
            "Author pub id": "xie8sAEAAAAJ:P5F9QuxV20EC",
            "Publisher": "Springer, Cham"
        },
        {
            "Title": "Author identification using imbalanced and limited training texts",
            "Publication year": 2007,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/4312893/",
            "Abstract": "This paper deals with the problem of author identification. The common N-grams (CNG) method [6] is a language-independent profile-based approach with good results in many author identification experiments so far. A variation of this approach is presented based on new distance measures that are quite stable for large profile length values. Special emphasis is given to the degree upon which the effectiveness of the method is affected by the available training text samples per author. Experiments based on text samples on the same topic from the Reuters Corpus Volume 1 are presented using both balanced and imbalanced training corpora. The results show that CNG with the proposed distance measures is more accurate when only limited training text samples are available, at least for some of the candidate authors, a realistic condition in author identification problems.",
            "Abstract entirety": 1,
            "Author pub id": "xie8sAEAAAAJ:hqOjcs7Dif8C",
            "Publisher": "IEEE"
        },
        {
            "Title": "The significance of user-defined identifiers in Java source code authorship identification",
            "Publication year": 2021,
            "Publication url": "https://arxiv.org/abs/2101.12384",
            "Abstract": "When writing source code, programmers have varying levels of freedom when it comes to the creation and use of identifiers. Do they habitually use the same identifiers, names that are different to those used by others? Is it then possible to tell who the author of a piece of code is by examining these identifiers? If so, can we use the presence or absence of identifiers to assist in correctly classifying programs to authors? Is it possible to hide the provenance of programs by identifier renaming? In this study, we assess the importance of three types of identifiers in source code author classification for two different Java program data sets. We do this through a sequence of experiments in which we disguise one type of identifier at a time. These experiments are performed using as a tool the Source Code Author Profiles (SCAP) method. The results show that, although identifiers when examined as a whole do not seem to reflect program authorship for these data sets, when examined separately there is evidence that class names do signal the author of the program. In contrast, simple variables and method names used in Java programs do not appear to reflect program authorship. On the contrary, our analysis suggests that such identifiers are so common as to mask authorship. We believe that these results have applicability in relation to the robustness of code plagiarism analysis and that the underlying methods could be valuable in cases of litigation arising from disputes over program authorship.",
            "Abstract entirety": 1,
            "Author pub id": "xie8sAEAAAAJ:mVmsd5A6BfQC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Open-set classification for automated genre identification",
            "Publication year": 2013,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-642-36973-5_18",
            "Abstract": " Automated Genre Identification (AGI) of web pages is a problem of increasing importance since web genre (e.g. blog, news, e-shops, etc.) information can enhance modern Information Retrieval (IR) systems. The state-of-the-art in this field considers AGI as a closed-set classification problem where a variety of web page representation and machine learning models have intensively studied. In this paper, we study AGI as an open-set classification problem which better formulates the real world conditions of exploiting AGI in practice. Focusing on the use of content information, different text representation methods (words and character n-grams) are tested. Moreover, two classification methods are examined, one-class SVM learners, used as a baseline, and an ensemble of classifiers based on random feature subspacing, originally proposed for author identification. It is demonstrated that very high \u2026",
            "Abstract entirety": 0,
            "Author pub id": "xie8sAEAAAAJ:hMod-77fHWUC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "Authorship attribution for social media forensics",
            "Publication year": 2016,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/7555393/",
            "Abstract": "The veil of anonymity provided by smartphones with pre-paid SIM cards, public Wi-Fi hotspots, and distributed networks like Tor has drastically complicated the task of identifying users of social media during forensic investigations. In some cases, the text of a single posted message will be the only clue to an author's identity. How can we accurately predict who that author might be when the message may never exceed 140 characters on a service like Twitter? For the past 50 years, linguists, computer scientists, and scholars of the humanities have been jointly developing automated methods to identify authors based on the style of their writing. All authors possess peculiarities of habit that influence the form and content of their written works. These characteristics can often be quantified and measured using machine learning algorithms. In this paper, we provide a comprehensive review of the methods of authorship \u2026",
            "Abstract entirety": 0,
            "Author pub id": "xie8sAEAAAAJ:dshw04ExmUIC",
            "Publisher": "IEEE"
        },
        {
            "Title": "A practical chunker for unrestricted text",
            "Publication year": 2000,
            "Publication url": "https://link.springer.com/chapter/10.1007/3-540-45154-4_13",
            "Abstract": "In this paper we present a practical approach to text chunking for unrestricted Modern Greek text that is based on multiple-pass parsing. Two versions of this chunker are proposed: one based on a large lexicon and one based on minimal resources. In the latter case the morphological analysis is performed using exclusively two small lexicons containing closed-class words and common suffixes of the Modern Greek words. We give comparative performance results on the basis of a corpus of unrestricted text and show that very good results can be obtained by omitting the large and complicate resources. Moreover, the considerable time cost introduced by the use of the large lexicon indicates that the minimal-resources chunker is the best solution regarding a practical application that requires rapid response and less than perfect parsing results.",
            "Abstract entirety": 1,
            "Author pub id": "xie8sAEAAAAJ:IjCSPb-OGe4C",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "Effective identification of source code authors using byte-level information",
            "Publication year": 2006,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/1134285.1134445",
            "Abstract": "Source code author identification deals with the task of identifying the most likely author of a computer program, given a set of predefined author candidates. This is usually. based on the analysis of other program samples of undisputed authorship by the same programmer. There are several cases where the application of such a method could be of a major benefit, such as authorship disputes, proof of authorship in court, tracing the source of code left in the system after a cyber attack, etc. We present a new approach, called the SCAP (Source Code Author Profiles) approach, based on byte-level n-gram profiles in order to represent a source code author's style. Experiments on data sets of different programming-language (Java or C++) and varying difficulty (6 to 30 candidate authors) demonstrate the effectiveness of the proposed approach. A comparison with a previous source code authorship identification study \u2026",
            "Abstract entirety": 0,
            "Author pub id": "xie8sAEAAAAJ:UebtZRa9Y70C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Author identification in imbalanced sets of source code samples",
            "Publication year": 2012,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/6495124/",
            "Abstract": "Similarly to natural language texts, source code documents can be distinguished by their style. Source code author identification can be viewed as a text classification task given that samples of known authorship by a set of candidate authors are available. Although very promising results have been reported for this task, the evaluation of existing approaches avoids focusing on the class imbalance problem and its effect on the performance. In this paper, we present a systematic experimental study of author identification in skewed training sets where the training samples are unequally distributed over the candidate authors. Two representative author identification methods are examined, one follows the profile-based paradigm (where a single representation is produced for all the available training samples per author) and the other follows the instance-based paradigm (where each training sample has its own \u2026",
            "Abstract entirety": 0,
            "Author pub id": "xie8sAEAAAAJ:M3NEmzRMIkIC",
            "Publisher": "IEEE"
        },
        {
            "Title": "An Intelligent Distributed System for Automatic Sentiment Analysis from Topic-Specific Web Sources: Discovery and Extraction of Relevant Documents",
            "Publication year": 2011,
            "Publication url": "http://www.icsd.aegean.gr/website_files/diplomatikes/msc/750784841.pdf",
            "Abstract": "The present document deals with the design and analysis of an intelligent system that uses distributed structure to achieve automatic sentiment analysis on opinions extracted from sources related to a specific topic from the World Wide Web (WWW). Starting from a set of simple user-defined parameters including topic; relevant documents are discovered by Focused Crawler Agents who use state-of-the-art focused crawling methods. In cooperation with Miner Agents the retrieval of the segments (useful regions) of those documents is accomplished. Next, a confidence is calculated for extracting segmented regions with high probability of containing opinions and a complete sentiment analysis is made to these regions, which includes subjectivity and polarity classification methods bootstrapped for optimized precision. In order to be applied to a variety of topics, the system follows unsupervised and supervised learning methods derived the Machine Learning (ML) domain. The contents of this document address the first part of the above procedure which includes the discovery and the extraction of the relevant data.",
            "Abstract entirety": 1,
            "Author pub id": "xie8sAEAAAAJ:M05iB0D1s5AC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Author identification using semi-supervised learning",
            "Publication year": 2011,
            "Publication url": "https://www.researchgate.net/profile/Rafael-Guzman-Cabrera/publication/348371486_Author_Identification_Using_Semi-supervised_Learning_Notebook/links/5ffb4f3b92851c13fe02db48/Author-Identification-Using-Semi-supervised-Learning-Notebook.pdf",
            "Abstract": "Author identification models fall into two major categories according to the way they handle the training texts: profile-based models produce one representation per author while instance-based models produce one representation per text. In this paper, we propose an approach that combines two well-known representatives of these categories, namely the Common n-Grams method and a Support Vector Machine classifier based on character n-grams. The outputs of these classifiers are combined to enrich the training set with additional documents in a repetitive semi-supervised procedure inspired by the co-training algorithm. The evaluation results on closed-set author identification are encouraging, especially when the set of candidate authors is large.",
            "Abstract entirety": 1,
            "Author pub id": "xie8sAEAAAAJ:9ZlFYXVOiuMC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Learning to recognize webpage genres",
            "Publication year": 2009,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S0306457309000491",
            "Abstract": "Webpages are mainly distinguished by their topic (e.g., politics, sports etc.) and genre (e.g., blogs, homepages, e-shops, etc.). Automatic detection of webpage genre could considerably enhance the ability of modern search engines to focus on the requirements of the user\u2019s information need. In this paper, we present an approach to webpage genre detection based on a fully-automated extraction of the feature set that represents the style of webpages. The features we propose (character n-grams of variable length and HTML tags) are language-independent and easily-extracted while they can be adapted to the properties of the still evolving web genres and the noisy environment of the web. Experiments based on two publicly-available corpora show that the performance of the proposed approach is superior in comparison to previously reported results. It is also shown that character n-grams are better features than \u2026",
            "Abstract entirety": 0,
            "Author pub id": "xie8sAEAAAAJ:0EnyYjriUFMC",
            "Publisher": "Pergamon"
        },
        {
            "Title": "A decade of shared tasks in digital text forensics at PAN",
            "Publication year": 2019,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-030-15719-7_39",
            "Abstract": "Digital text forensics aims at examining the originality and credibility of information in electronic documents and, in this regard, to extract and analyze information about the authors of these documents. The research field has been substantially developed during the last decade. PAN is a series of shared tasks that started in 2009 and significantly contributed to attract the attention of the research community in well-defined digital text forensics tasks. Several benchmark datasets have been developed to assess the state-of-the-art performance in a wide range of tasks. In this paper, we present the evolution of both the examined tasks and the developed datasets during the last decade. We also briefly introduce the upcoming PAN 2019 shared tasks.",
            "Abstract entirety": 1,
            "Author pub id": "xie8sAEAAAAJ:wbdj-CoPYUoC",
            "Publisher": "Springer, Cham"
        },
        {
            "Title": "Improving the reproducibility of PAN\u2019s shared tasks",
            "Publication year": 2014,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-319-11382-1_22",
            "Abstract": "This paper reports on the PAN 2014 evaluation lab which hosts three shared tasks on plagiarism detection, author identification, and author profiling. To improve the reproducibility of shared tasks in general, and PAN\u2019s tasks in particular, the Webis group developed a new web service called TIRA, which facilitates software submissions. Unlike many other labs, PAN asks participants to submit running softwares instead of their run output. To deal with the organizational overhead involved in handling software submissions, the TIRA experimentation platform helps to significantly reduce the workload for both participants and organizers, whereas the submitted softwares are kept in a running state. This year, we addressed the matter of responsibility of successful execution of submitted softwares in order to put participants back in charge of executing their software at our site. In sum, 57 softwares have been \u2026",
            "Abstract entirety": 0,
            "Author pub id": "xie8sAEAAAAJ:4OULZ7Gr8RgC",
            "Publisher": "Springer, Cham"
        },
        {
            "Title": "Masking topic\u2010related information to enhance authorship attribution",
            "Publication year": 2018,
            "Publication url": "https://asistdl.onlinelibrary.wiley.com/doi/abs/10.1002/asi.23968",
            "Abstract": "Authorship attribution attempts to reveal the authors of documents. In recent years, research in this field has grown rapidly. However, the performance of state\u2010of\u2010the\u2010art methods is heavily affected when text of known authorship and texts under investigation differ in topic and/or genre. So far, it is not clear how to quantify the personal style of authors in a way that is not affected by topic shifts or genre variations. In this paper, a set of text distortion methods are used attempting to mask topic\u2010related information. These methods transform the input texts into a more topic\u2010neutral form while maintaining the structure of documents associated with the personal style of the author. Using a controlled corpus that includes a fine\u2010grained range of topics and genres it is demonstrated how the proposed approach can be combined with existing authorship attribution methods to enhance their performance in very challenging tasks \u2026",
            "Abstract entirety": 0,
            "Author pub id": "xie8sAEAAAAJ:B3FOqHPlNUQC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Overview of PAN\u201917",
            "Publication year": 2017,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-319-65813-1_25",
            "Abstract": "The PAN 2017 shared tasks on digital text forensics were held in conjunction with the annual CLEF conference. This paper gives a high-level overview of each of the three shared tasks organized this year, namely author identification, author profiling, and author obfuscation. For each task, we give a brief summary of the evaluation data, performance measures, and results obtained. Altogether, 29 participants submitted a total of 33 pieces of software for evaluation, whereas 4 participants submitted to more than one task. All submitted software has been deployed to the TIRA evaluation platform, where it remains hosted for reproducibility purposes.",
            "Abstract entirety": 1,
            "Author pub id": "xie8sAEAAAAJ:tS2w5q8j5-wC",
            "Publisher": "Springer, Cham"
        },
        {
            "Title": "Improved algorithms for extrinsic author verification",
            "Publication year": 2020,
            "Publication url": "https://link.springer.com/article/10.1007/s10115-019-01408-4",
            "Abstract": "Author verification is a fundamental problem in authorship attribution, and it suits most relevant applications where it is not possible to predefine a closed set of suspects. So far, the most successful approaches attempt to sample the non-target class (all documents by all other authors) and transform author verification to a binary classification task. Moreover, they follow the instance-based paradigm (all documents of known authorship are treated separately). In this paper, we propose two algorithms, one instance-based and one profile-based (all known documents are treated cumulatively) that are able to outperform state-of-the-art methods in several benchmark datasets. We demonstrate that the proposed methods are capable of taking advantage of the availability of multiple documents of known authorship and that they are robust when text length is reduced.",
            "Abstract entirety": 1,
            "Author pub id": "xie8sAEAAAAJ:Mojj43d5GZwC",
            "Publisher": "Springer London"
        },
        {
            "Title": "PAN19 Authorship Analysis: Cross-Domain Authorship Attribution",
            "Publication year": 2019,
            "Publication url": "https://scholar.google.com/scholar?cluster=17425897564020161749&hl=en&oi=scholarr",
            "Abstract": "Authorship attribution is an important problem in information retrieval and computational linguistics but also in applied areas such as law and journalism where knowing the author of a document (such as a ransom note) may enable eg law enforcement to save lives. The most common framework for testing candidate algorithms is the closed-set attribution task: given a sample of reference documents from a restricted and finite set of candidate authors, the task is to determine the most likely author of a previously unseen document of unknown authorship. This task may be quite challenging in cross-domain conditions, when documents of known and unknown authorship come from different domains (eg, thematic area, genre). In addition, it is often more realistic to assume that the true author of a disputed document is not necessarily included in the list of candidates.",
            "Abstract entirety": 1,
            "Author pub id": "xie8sAEAAAAJ:PR6Y55bgFSsC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Adaptive binarization of historical document images",
            "Publication year": 2006,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/1699632/",
            "Abstract": "In this paper, we present a binarization technique specifically designed for historical document images. Existing methods for this problem focus on either finding a good global threshold or adapting the threshold for each area to remove smear, strains, uneven illumination etc. We propose a hybrid approach that first applies a global thresholding method and, then, identifies the image areas that are more likely to still contain noise. Each of these areas is re-processed separately to achieve better quality of binarization. We evaluate the proposed approach for different kinds of degradation problems. The results show that our method can handle hard cases while documents already in good condition are not affected drastically",
            "Abstract entirety": 1,
            "Author pub id": "xie8sAEAAAAJ:j3f4tGmQtD8C",
            "Publisher": "IEEE"
        },
        {
            "Title": "Discriminative subprofile-specific representations for author profiling in social media",
            "Publication year": 2015,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S0950705115002427",
            "Abstract": "The Author Profiling (AP) task aims to reveal as much as possible information from a given author\u2019s document (e.g., age, gender, etc.). AP is crucial for several applications, ranging from customized advertising to computer forensics, psychology, and entertainment. Nonetheless, the AP task is far from being solved, particularly in social media domains, where the nature of documents hinder the applicability of state-of-the-art text mining tools (e.g., because of spelling-grammar errors, huge vocabularies, and the presence of many out-of-vocabulary terms). Currently, most of the work in AP for social media has been devoted to the development of descriptive features, which are used under standard representations, such as the Bag-of-Words (BoW). Nevertheless, BoW-like representations have some well known shortcomings, namely: (i) the sparsity and high dimensionality of the representation, and (ii) the failure to \u2026",
            "Abstract entirety": 0,
            "Author pub id": "xie8sAEAAAAJ:_xSYboBqXhAC",
            "Publisher": "Elsevier"
        },
        {
            "Title": "Music performer recognition using an ensemble of simple classifiers",
            "Publication year": 2002,
            "Publication url": "https://books.google.com/books?hl=en&lr=&id=5ZuuF0ogxU4C&oi=fnd&pg=PA335&dq=info:yDiEdmGGvcQJ:scholar.google.com&ots=e1jp4kR8DT&sig=E_Y5yJ9KQ3oRavJDkW-2EfSbbAU",
            "Abstract": "This paper addresses the problem of identifying the most likely music performer, given a set of performances of the same piece by a number of skilled candidate pianists. We propose a set of features for representing the stylistic characteristics of a music performer. A database of piano performances of 22 pianists playing two pieces by F. Chopin is used in the presented experiments. Due to the limitations of the training set size and the characteristics of the input features we propose an ensemble of simple classifiers derived by both subsampling the training set and subsampling the input features. Preliminary experiments show that the resulting ensemble is able to efficiently cope with this difficult musical task, displaying a level of accuracy unlikely to be matched by human listeners (under similar conditions).",
            "Abstract entirety": 1,
            "Author pub id": "xie8sAEAAAAJ:W7OEmFMy1HYC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Finding participants in a chat: Authorship attribution for conversational documents",
            "Publication year": 2013,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/6693342/",
            "Abstract": "In this work we study the problem of Authorship Attribution for a novel set of documents, namely online chats. Although the problem of Authorship Attribution has been extensively investigated for different document types, from books to letters and from emails to blog posts, to the best of our knowledge this is the first study of Authorship Attribution for conversational documents (IRC chat logs) using statistical models. We experimentally demonstrate the unsuitability of the classical statistical models for conversational documents and propose a novel approach which is able to achieve a high accuracy rate (up to 95%) for hundreds of authors.",
            "Abstract entirety": 1,
            "Author pub id": "xie8sAEAAAAJ:RGFaLdJalmkC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Overview of the Cross-domain Authorship Attribution Task at PAN 2019.",
            "Publication year": 2019,
            "Publication url": "https://webis.de/downloads/publications/papers/kestemont_2019.pdf",
            "Abstract": "Authorship identification remains a highly topical research problem in computational text analysis, with many relevant applications in contemporary society and industry. In this edition of PAN, we focus on authorship attribution, where the task is to attribute an unknown text to a previously seen candidate author. Like in the previous edition we continue to work with fanfiction texts (in four Indo-European languages), written by non-professional authors in a crossdomain setting: the unknown texts belong to a different domain than the training material that is available for the candidate authors. An important novelty of this year\u2019s setup is the focus on open-set attribution, meaning that the test texts contain writing samples by previously unseen authors. For these, systems must consequently refrain from an attribution. We received altogether 12 submissions for this task, which we critically assess in this paper. We provide a detailed comparison of these approaches, including three generic baselines.",
            "Abstract entirety": 1,
            "Author pub id": "xie8sAEAAAAJ:WA5NYHcadZ8C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Author identification using a tensor space representation",
            "Publication year": 2008,
            "Publication url": "https://ebooks.iospress.nl/doi/10.3233/978-1-58603-891-5-833",
            "Abstract": "Author identification is a text categorization task with applications in intelligence, criminal law, computer forensics, etc. Usually, in such cases there is shortage of training texts. In this paper, we propose the use of second order tensors for representing texts for this problem, in contrast to the traditional vector space model. Based on a generalization of the SVM algorithm that can handle tensors, we explore various methods for filling the matrix of features taking into account that similar features should be placed in the same neighborhood. To this end, we propose a frequency-based metric. Experiments on a corpus controlled for genre and topic and variable amount of training texts show that the proposed approach is more effective than traditional vector-based SVM when only limited amount of training texts is used.",
            "Abstract entirety": 1,
            "Author pub id": "xie8sAEAAAAJ:ULOm3_A8WrAC",
            "Publisher": "IOS Press"
        },
        {
            "Title": "Authorship Attribution for Social Media Forensics",
            "Publication year": 2016,
            "Publication url": "https://www.wjscheirer.com/papers/wjs_tifs2016_authorship.pdf",
            "Abstract": "The veil of anonymity provided by smartphones with pre-paid SIM cards, public Wi-Fi hotspots, and distributed networks like Tor has drastically complicated the task of identifying users of social media during forensic investigations. In some cases, the text of a single posted message will be the only clue to an author\u2019s identity. How can we accurately predict who that author might be when the message may never exceed 140 characters on a service like Twitter? For the past 50 years, linguists, computer scientists and scholars of the humanities have been jointly developing automated methods to identify authors based on the style of their writing. All authors possess peculiarities of habit that influence the form and content of their written works. These characteristics can often be quantified and measured using machine learning algorithms. In this article, we provide a comprehensive review of the methods of authorship attribution that can be applied to the problem of social media forensics. Further, we examine emerging supervised learningbased methods that are effective for small sample sizes, and provide step-by-step explanations for several scalable approaches as instructional case studies for newcomers to the field. We argue that there is a significant need in forensics for new authorship attribution algorithms that can exploit context, can process multimodal data, and are tolerant to incomplete knowledge of the space of all possible authors at training time.",
            "Abstract entirety": 1,
            "Author pub id": "xie8sAEAAAAJ:uWQEDVKXjbEC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Handwritten character segmentation using transformation-based learning",
            "Publication year": 2000,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/906155/",
            "Abstract": "Presents a character segmentation algorithm for unconstrained cursive handwritten text. The transformation-based learning method and a simplified variation of it are used in order to extract automatically rules that detect the segment boundaries. Comparative experimental results are given for a collection of multiwriter handwritten words. The achieved accuracy in detecting segment boundaries exceeds 82%. Moreover limited training data can provide very satisfactory results.",
            "Abstract entirety": 1,
            "Author pub id": "xie8sAEAAAAJ:ufrVoPGSRksC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Plagiarism analysis, authorship identification, and near-duplicate detection PAN'07",
            "Publication year": 2007,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/1328964.1328976",
            "Abstract": "Goal of the workshop was to bring together experts and prospective researchers around the exciting and future-oriented topic of plagiarism analysis, authorship identification, and high similarity search. This topic receives increasing attention, which results, among others, from the fact that information about nearly any subject can be found on the World Wide Web.",
            "Abstract entirety": 1,
            "Author pub id": "xie8sAEAAAAJ:_FxGoFyzp5QC",
            "Publisher": "ACM"
        },
        {
            "Title": "A transfer learning approach to cross-domain authorship attribution",
            "Publication year": 2021,
            "Publication url": "https://link.springer.com/article/10.1007/s12530-021-09377-2",
            "Abstract": "Authorship attribution attempts to identify the authors behind texts and has important applications mainly in digital forensics, cyber-security, digital humanities, and social media analytics. A challenging yet realistic scenario is cross-domain attribution where texts of known authorship (training set) differ from texts of disputed authorship (test set) in, for example, topic or genre. In this paper, we propose the use of transfer learning based on pre-trained neural network language models and a multi-headed classifier. A series of experiments is reported to compare the effectiveness of our approach on cross-topic, cross-genre, and cross-fandom conditions with state-of-the-art methods. We also demonstrate the crucial effect of the normalization corpus (an unlabeled corpus used to adjust the output of our classifier) in cross-domain attribution and the usefulness of shallower layers of pre-trained models.",
            "Abstract entirety": 1,
            "Author pub id": "xie8sAEAAAAJ:VL0QpB8kHFEC",
            "Publisher": "Springer Berlin Heidelberg"
        },
        {
            "Title": "Distinguishing the popularity between topics: a system for up-to-date opinion retrieval and mining in the web",
            "Publication year": 2013,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-642-37256-8_17",
            "Abstract": "The constantly increasing amount of opinionated texts found in the Web had a significant impact in the development of sentiment analysis. So far, the majority of the comparative studies in this field focus on analyzing fixed (offline) collections from certain domains, genres, or topics. In this paper, we present an online system for opinion mining and retrieval that is able to discover up-to-date web pages on given topics using focused crawling agents, extract opinionated textual parts from web pages, and estimate their polarity using opinion mining agents. The evaluation of the system on real-world case studies, demonstrates that is appropriate for opinion comparison between topics, since it provides useful indications on the popularity based on a relatively small amount of web pages. Moreover, it can produce genre-aware results of opinion retrieval, a valuable option for decision-makers.",
            "Abstract entirety": 1,
            "Author pub id": "xie8sAEAAAAJ:JV2RwH3_ST0C",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "Overview of the author profiling task at PAN 2013",
            "Publication year": 2013,
            "Publication url": "https://riunet.upv.es/handle/10251/46636",
            "Abstract": "[EN] This overview presents the framework and results for the Author Profiling task at PAN 2013. We describe in detail the corpus and its characteristics, and the evaluation framework we used to measure the participants performance to solve the problem of identifying age and gender from anonymous texts. Finally, the approaches of the 21 participants and their results are described.",
            "Abstract entirety": 1,
            "Author pub id": "xie8sAEAAAAJ:35N4QoGY0k4C",
            "Publisher": "CELCT"
        },
        {
            "Title": "Authorship attribution based on feature set subspacing ensembles",
            "Publication year": 2006,
            "Publication url": "https://www.worldscientific.com/doi/abs/10.1142/S0218213006002965",
            "Abstract": "Authorship attribution can assist the criminal investigation procedure as well as cybercrime analysis. This task can be viewed as a single-label multi-class text categorization problem. Given that the style of a text can be represented as mere word frequencies selected in a language-independent method, suitable machine learning techniques able to deal with high dimensional feature spaces and sparse data can be directly applied to solve this problem. This paper focuses on classifier ensembles based on feature set subspacing. It is shown that an effective ensemble can be constructed using, exhaustive disjoint subspacing, a simple method producing many poor but diverse base classifiers. The simple model can be enhanced by a variation of the technique of cross-validated committees applied to the feature set. Experiments on two benchmark text corpora demonstrate the effectiveness of the presented method \u2026",
            "Abstract entirety": 0,
            "Author pub id": "xie8sAEAAAAJ:8k81kl-MbHgC",
            "Publisher": "World Scientific Publishing Company"
        },
        {
            "Title": "Plagiarism and authorship analysis: introduction to the special issue",
            "Publication year": 2011,
            "Publication url": "https://link.springer.com/article/10.1007/s10579-011-9136-1",
            "Abstract": "The Internet has facilitated both the dissemination of anonymous texts as well as easy \u2018\u2018borrowing\u2019\u2019of ideas and words of others. This has raised a number of important questions regarding authorship. Can we identify the anonymous author of a text by comparing the text with the writings of known authors? Can we determine if a text, or parts of it, has been plagiarized? Such questions are clearly of both academic and commercial importance.The task of determining or verifying the authorship of an anonymous text based solely on internal evidence is a very old one, dating back at least to the medieval scholastics, for whom the reliable attribution of a given text to a known ancient authority was essential to determining the text\u2019s veracity. More recently, the problem of authorship attribution has gained greater prominence due to new applications in forensic analysis, humanities scholarship, and electronic commerce, and \u2026",
            "Abstract entirety": 0,
            "Author pub id": "xie8sAEAAAAJ:ZeXyd9-uunAC",
            "Publisher": "Springer Netherlands"
        },
        {
            "Title": "Clustering by Authorship Within and Across Documents.",
            "Publication year": 2016,
            "Publication url": "http://repository.uantwerpen.be/docman/irua/48ca6d/139273.pdf",
            "Abstract": "The vast majority of previous studies in authorship attribution assume the existence of documents (or parts of documents) labeled by authorship to be used as training instances in either closed-set or open-set attribution. However, in several applications it is not easy or even possible to find such labeled data and it is necessary to build unsupervised attribution models that are able to estimate similarities/differences in personal style of authors. The shared tasks on author clustering and author diarization at PAN 2016 focus on such unsupervised authorship attribution problems. The former deals with single-author documents and aims at grouping documents by authorship and establishing authorship links between documents. The latter considers multi-author documents and attempts to segment a document into authorial components, a task strongly associated with intrinsic plagiarism detection. This paper presents an overview of the two tasks including evaluation datasets, measures, results, as well as a survey of a total of 10 submissions (8 for author clustering and 2 for author diarization).",
            "Abstract entirety": 1,
            "Author pub id": "xie8sAEAAAAJ:KxtntwgDAa4C",
            "Publisher": "Unknown"
        },
        {
            "Title": "A profile-based method for authorship verification",
            "Publication year": 2014,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-319-07064-3_25",
            "Abstract": "Authorship verification is one of the most challenging tasks in style-based text categorization. Given a set of documents, all by the same author, and another document of unknown authorship the question is whether or not the latter is also by that author. Recently, in the framework of the PAN-2013 evaluation lab, a competition in authorship verification was organized and the vast majority of submitted approaches, including the best performing models, followed the instance-based paradigm where each text sample by one author is treated separately. In this paper, we show that the profile-based paradigm (where all samples by one author are treated cumulatively) can be very effective surpassing the performance of PAN-2013 winners without using any information from external sources. The proposed approach is fully-trainable and we demonstrate an appropriate tuning of parameter settings for PAN-2013 \u2026",
            "Abstract entirety": 0,
            "Author pub id": "xie8sAEAAAAJ:zA6iFVUQeVQC",
            "Publisher": "Springer, Cham"
        },
        {
            "Title": "Overview of the Author Identification Task at PAN-2017: Style Breach Detection and Author Clustering.",
            "Publication year": 2017,
            "Publication url": "https://webis.de/downloads/publications/papers/tschuggnall_2017.pdf",
            "Abstract": "Several authorship analysis tasks require the decomposition of a multiauthored text into its authorial components. In this regard two basic prerequisites need to be addressed:(1) style breach detection, ie, the segmenting of a text into stylistically homogeneous parts, and (2) author clustering, ie, the grouping of paragraph-length texts by authorship. In the current edition of PAN we focus on these two unsupervised authorship analysis tasks and provide both benchmark data and an evaluation framework to compare different approaches. We received three submissions for the style breach detection task and six submissions for the author clustering task; we analyze the submissions with different baselines while highlighting their strengths and weaknesses.",
            "Abstract entirety": 1,
            "Author pub id": "xie8sAEAAAAJ:tOudhMTPpwUC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Shared tasks on authorship analysis at pan 2020",
            "Publication year": 2020,
            "Publication url": "https://www.ncbi.nlm.nih.gov/pmc/articles/pmc7148014/",
            "Abstract": "The paper gives a brief overview of the four shared tasks that are to be organized at the PAN 2020 lab on digital text forensics and stylometry, hosted at CLEF conference. The tasks include author profiling, celebrity profiling, cross-domain author verification, and style change detection, seeking to advance the state of the art and to evaluate it on new benchmark datasets.",
            "Abstract entirety": 1,
            "Author pub id": "xie8sAEAAAAJ:PELIpwtuRlgC",
            "Publisher": "Nature Publishing Group"
        },
        {
            "Title": "Intrinsic author verification using topic modeling",
            "Publication year": 2018,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/3200947.3201013",
            "Abstract": "Author verification is a fundamental task in authorship analysis and associated with important applications in humanities and forensics. In this paper, we propose the use of an intrinsic profile-based verification method that is based on latent semantic indexing (LSI). Our proposed approach is easy-to-follow and language independent. Based on experiments using benchmark corpora from the PAN shared task in author verification, we demonstrate that LSI is both more effective and more stable than latent Dirichlet allocation in this task. Moreover, LSI models are able to outperform existing approaches especially when multiple texts of known authorship are available per verification instance and all documents belong to the same thematic area and genre. We also study several feature types and similarity measures to be combined with the proposed topic models.",
            "Abstract entirety": 1,
            "Author pub id": "xie8sAEAAAAJ:D_sINldO8mEC",
            "Publisher": "Unknown"
        },
        {
            "Title": "An agent-based focused crawling framework for topic-and genre-related web document discovery",
            "Publication year": 2012,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/6495087/",
            "Abstract": "The discovery of web documents about certain topics is an important task for web-based applications including web document retrieval, opinion mining and knowledge extraction. In this paper, we propose an agent-based focused crawling framework able to retrieve topic- and genre-related web documents. Starting from a simple topic query, a set of focused crawler agents explore in parallel topic-specific web paths using dynamic seed URLs that belong to certain web genres and are collected from web search engines. The agents make use of an internal mechanism that weighs topic and genre relevance scores of unvisited web pages. They are able to adapt to the properties of a given topic by modifying their internal knowledge during search, handle ambiguous queries, ignore irrelevant pages with respect to the topic and retrieve collaboratively topic-relevant web pages. We performed an experimental study to \u2026",
            "Abstract entirety": 0,
            "Author pub id": "xie8sAEAAAAJ:iH-uZ7U-co4C",
            "Publisher": "IEEE"
        },
        {
            "Title": "Overview of PAN 2019: bots and gender profiling, celebrity profiling, cross-domain authorship attribution and style change detection",
            "Publication year": 2019,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-030-28577-7_30",
            "Abstract": "We briefly report on the four shared tasks organized as part of the PAN 2019 evaluation lab on digital text forensics and authorship analysis. Each task is introduced, motivated, and the results obtained are presented. Altogether, the four tasks attracted 373 registrations, yielding 72 successful submissions. This, and the fact that we continue to invite the submission of software rather than its run output using the TIRA experimentation platform, demarcates a good start into the second decade of PAN evaluations labs.",
            "Abstract entirety": 1,
            "Author pub id": "xie8sAEAAAAJ:olpn-zPbct0C",
            "Publisher": "Springer, Cham"
        },
        {
            "Title": "The impact of noise in web genre identification",
            "Publication year": 2015,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-319-24027-5_27",
            "Abstract": "Genre detection of web documents fits an open-set classification task. The web documents not belonging to any predefined genre or where multiple genres co-exist is considered as noise. In this work we study the impact of noise on automated genre identification within an open-set classification framework. We examine alternative classification models and document representation schemes based on two corpora, one without noise and one with noise showing that the recently proposed RFSE model can remain robust with noise. Moreover, we show how that the identification of certain genres is not practically affected by the presence of noise.",
            "Abstract entirety": 1,
            "Author pub id": "xie8sAEAAAAJ:b0M2c_1WBrUC",
            "Publisher": "Springer, Cham"
        },
        {
            "Title": "An image processing self-training system for ruling line removal algorithms",
            "Publication year": 2013,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/6622767/",
            "Abstract": "Ruling line removal is an important pre-processing step in document image processing. Several algorithms have been proposed for this task. However, it is important to be able to take full advantage of the existing algorithms by adapting them to the specific properties of a document image collection. In this paper, a system is presented, appropriate for fine-tuning the parameters of ruling line removal algorithms or appropriately adapt them to a specific document image collection, in order to improve the results. The application of our method to an existed line removal algorithms is presented.",
            "Abstract entirety": 1,
            "Author pub id": "xie8sAEAAAAJ:lSLTfruPkqcC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Source code author identification based on n-gram author profiles",
            "Publication year": 2006,
            "Publication url": "https://link.springer.com/chapter/10.1007/0-387-34224-9_59",
            "Abstract": "Source code author identification deals with the task of identifying the most likely author of a computer program, given a set of predefined author candidates. This is usually. based on the analysis of other program samples of undisputed authorship by the same programmer. There are several cases where the application of such a method could be of a major benefit, such as authorship disputes, proof of authorship in court, tracing the source of code left in the system after a cyber attack, etc. We present a new approach, called the SCAP (Source Code Author Profiles) approach, based on byte-level n-gram profiles in order to represent a source code author\u2019s style. Experiments on data sets of different programming language (Java or C++) and varying difficulty (6 to 30 candidate authors) demonstrate the effectiveness of the proposed approach. A comparison with a previous source code authorship identification \u2026",
            "Abstract entirety": 0,
            "Author pub id": "xie8sAEAAAAJ:Zph67rFs4hoC",
            "Publisher": "Springer, Boston, MA"
        },
        {
            "Title": "Learning how to propagate using random probing",
            "Publication year": 2009,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-642-01929-6_20",
            "Abstract": "In constraint programming there are often many choices regarding the propagation method to be used on the constraints of a problem. However, simple constraint solvers usually only apply a standard method, typically (generalized) arc consistency, on all constraints throughout search. Advanced solvers additionally allow for the modeler to choose among an array of propagators for certain (global) constraints. Since complex interactions exist among constraints, deciding in the modelling phase which propagation method to use on given constraints can be a hard task that ideally we would like to free the user from. In this paper we propose a simple technique towards the automation of this task. Our approach exploits information gathered from a random probing preprocessing phase to automatically decide on the propagation method to be used on each constraint. As we demonstrate, data gathered though \u2026",
            "Abstract entirety": 0,
            "Author pub id": "xie8sAEAAAAJ:YOwf2qJgpHMC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "Quantifying the differences between music performers: Score vs. norm",
            "Publication year": 2002,
            "Publication url": "http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.207.4967&rep=rep1&type=pdf",
            "Abstract": "In this study, a comparison of features for discriminating between different music performers playing the same piece is presented. Based on a series of statistical experiments on a data set of piano pieces played by 22 performers, it is shown that the deviation from the performance norm (average performance) is better able to reveal the performers\u2019 individualities in comparison to the deviation from the printed score. In the framework of automatic music performer recognition, the norm-based features prove to be very accurate in intra-piece tests (training and test set taken from the same piece) and very stable in inter-piece tests (training and test sets taken from different pieces). Moreover, it is empirically demonstrated that the average performance is at least as effective as the best of the constituent individual performances while \u2018extreme\u2019performances have the lowest discriminatory potential when used as norm.",
            "Abstract entirety": 1,
            "Author pub id": "xie8sAEAAAAJ:MXK_kJrjxJIC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Overview of the author identification task at PAN-2018: cross-domain authorship attribution and style change detection",
            "Publication year": 2018,
            "Publication url": "https://elibrary.ru/item.asp?id=36215537",
            "Abstract": "Overview of the author identification task at PAN-2018: Cross-domain authorship attribution and \nstyle change detection \u041a\u041e\u0420\u0417\u0418\u041d\u0410 \u041f\u041e\u0418\u0421\u041a \u041d\u0410\u0412\u0418\u0413\u0410\u0422\u041e\u0420 \u0416\u0423\u0420\u041d\u0410\u041b\u042b \u041a\u041d\u0418\u0413\u0418 \u041f\u0410\u0422\u0415\u041d\u0422\u042b \n\u041f\u041e\u0418\u0421\u041a \u0410\u0412\u0422\u041e\u0420\u042b \u041e\u0420\u0413\u0410\u041d\u0418\u0417\u0410\u0426\u0418\u0418 \u041a\u041b\u042e\u0427\u0415\u0412\u042b\u0415 \u0421\u041b\u041e\u0412\u0410 \u0420\u0423\u0411\u0420\u0418\u041a\u0410\u0422\u041e\u0420 \u041d\u0430\u0447\u0430\u043b\u044c\u043d\u0430\u044f \u0441\u0442\u0440\u0430\u043d\u0438\u0446\u0430 \n\u0421\u0415\u0421\u0421\u0418\u042f \u041a\u041e\u041d\u0422\u0410\u041a\u0422\u042b \u0418\u041d\u0424\u041e\u0420\u041c\u0410\u0426\u0418\u042f \u041e \u041f\u0423\u0411\u041b\u0418\u041a\u0410\u0426\u0418\u0418 eLIBRARY ID: 36215537 OVERVIEW \nOF THE AUTHOR IDENTIFICATION TASK AT PAN-2018: CROSS-DOMAIN AUTHORSHIP \nATTRIBUTION AND STYLE CHANGE DETECTION KESTEMONT M. , DAELEMANS W. , \nTSCHUGGNALL M. , SPECHT G. , STAMATATOS E. , STEIN B. , POTTHAST M. 1 University of \nAntwerp 2 University of Innsbruck 3 University of the Aegean 4 Bauhaus-Universit\u00e4t Weimar \n5 Leipzig University \u0422\u0438\u043f: \u0441\u0442\u0430\u0442\u044c\u044f \u0432 \u0441\u0431\u043e\u0440\u043d\u0438\u043a\u0435 \u0442\u0440\u0443\u0434\u043e\u0432 \u043a\u043e\u043d\u0444\u0435\u0440\u0435\u043d\u0446\u0438\u0438 \u042f\u0437\u044b\u043a: \u0430\u043d\u0433\u043b\u0438\u0439\u0441\u043a\u0438\u0439 \u0413\u043e\u0434 \n\u0438\u0437\u0434\u0430\u043d\u0438\u044f: 2018 \u0418\u0421\u0422\u041e\u0427\u041d\u0418\u041a: CEUR WORKSHOP PROCEEDINGS 19. \u0421\u0435\u0440. \"CLEF 2018 - \" \u2026",
            "Abstract entirety": 0,
            "Author pub id": "xie8sAEAAAAJ:q3oQSFYPqjQC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Source code authorship analysis for supporting the cybercrime investigation process",
            "Publication year": 2010,
            "Publication url": "https://www.igi-global.com/chapter/source-code-authorship-analysis-supporting/39230",
            "Abstract": "Nowadays, in a wide variety of situations, source code authorship identification has become an issue of major concern. Such situations include authorship disputes, proof of authorship in court, cyber attacks in the form of viruses, trojan horses, logic bombs, fraud, and credit card cloning. Source code author identification deals with the task of identifying the most likely author of a computer program, given a set of predefined author candidates. We present a new approach, called the SCAP (Source Code Author Profiles) approach, based on byte-level n-grams in order to represent a source code author\u2019s style. Experiments on data sets of different programming-language (Java, C++ and Common Lisp) and varying difficulty (6 to 30 candidate authors) demonstrate the effectiveness of the proposed approach. A comparison with a previous source code authorship identification study based on more complicated information \u2026",
            "Abstract entirety": 0,
            "Author pub id": "xie8sAEAAAAJ:LPZeul_q3PIC",
            "Publisher": "IGI Global"
        },
        {
            "Title": "Overview of the Cross-Domain Authorship Verification Task at PAN 2020.",
            "Publication year": 2020,
            "Publication url": "https://webis.de/downloads/publications/papers/kestemont_2020.pdf",
            "Abstract": "Authorship identification remains a highly topical research problem in computational text analysis with many relevant applications in contemporary society and industry. For this edition of PAN, we focused on authorship verification, where the task is to assess whether a pair of documents has been authored by the same individual. Like in previous editions, we continued to work with (English-language) fanfiction, written by non-professional authors. As a novelty, we substantially increased the size of the provided dataset to enable more datahungry approaches. In total, thirteen systems (from ten participating teams) have been submitted, which are substantially more diverse than the submissions from previous years. We provide a detailed comparison of these approaches and two generic baselines. Our findings suggest that the increased scale of the training data boosts the state of the art in the field, but we also confirm the conventional issue that the field struggles with an overreliance on topic-related information.",
            "Abstract entirety": 1,
            "Author pub id": "xie8sAEAAAAJ:WqliGbK-hY8C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Webpage genre identification using variable-length character n-grams",
            "Publication year": 2007,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/4410349/",
            "Abstract": "An important factor for discriminating between Web pages is their genre (e.g., blogs, personal homepages, e-shops, online newspapers, etc). Web page genre identification has a great potential in information retrieval since users of search engines can combine genre-based and traditional topic-based queries to improve the quality of the results. So far, various features have been proposed to quantify the style of Web pages including word and HTML-tag frequencies. In this paper, we propose a low-level representation for this problem based on character n-grams. Using an existing approach, we produce feature sets of variable-length character n- grams and combine this representation with information about the most frequent HTML-tags. Based on two benchmark corpora, we present Web page genre identification experiments and improve the best reported results in both cases.",
            "Abstract entirety": 1,
            "Author pub id": "xie8sAEAAAAJ:Tyk-4Ss8FVUC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Automatic identification of music performers with learning ensembles",
            "Publication year": 2005,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S0004370205000196",
            "Abstract": "This article addresses the problem of identifying the most likely music performer, given a set of performances of the same piece by a number of skilled candidate pianists. We propose a set of very simple features for representing stylistic characteristics of a music performer, introducing \u2018norm-based\u2019 features that relate to a kind of \u2018average\u2019 performance. A database of piano performances of 22 pianists playing two pieces by Fr\u00e9d\u00e9ric Chopin is used in the presented experiments. Due to the limitations of the training set size and the characteristics of the input features we propose an ensemble of simple classifiers derived by both subsampling the training set and subsampling the input features. Experiments show that the proposed features are able to quantify the differences between music performers. The proposed ensemble can efficiently cope with multi-class music performer recognition under inter-piece conditions, a \u2026",
            "Abstract entirety": 0,
            "Author pub id": "xie8sAEAAAAJ:qjMakFHDy7sC",
            "Publisher": "Elsevier"
        },
        {
            "Title": "5HOHYDQW: RUN",
            "Publication year": 2000,
            "Publication url": "https://books.google.com/books?hl=en&lr=&id=JllqCQAAQBAJ&oi=fnd&pg=PA139&dq=info:Jc1NtvmwN1MJ:scholar.google.com&ots=1G9EqBHlPu&sig=TpbaVeLdX-cBdQY6y_zYj0yGO-Q",
            "Abstract": "The term WH [W FKXQNLQJ refers to techniques used for dividing sentences into relatively simple syntactic structures, such as noun phrases and prepositional phrases. It has been proposed by Abney [7] as a useful precursor to full parsing. A parser for Modern Greek texts is presented in [8]. This parser is able to mark the type of clauses contained in long sentences as well as to identify the phrases included in these clauses, based on a set of keywords and a set of heuristic rules. An accuracy of 84% is reported (this percentage increases to 96% after the use of some enhanced heuristics). This approach requires complete morphological analysis of every word",
            "Abstract entirety": 1,
            "Author pub id": "xie8sAEAAAAJ:f2IySw72cVMC",
            "Publisher": "Springer Science & Business Media"
        },
        {
            "Title": "On the robustness of authorship attribution based on character n-gram features",
            "Publication year": 2013,
            "Publication url": "https://www.researchgate.net/profile/Efstathios-Stamatatos/publication/303443999_On_the_robustness_of_authorship_attribution_based_on_character_n-gram_features/links/5a60df9f0f7e9bfbc3f8f409/On-the-robustness-of-authorship-attribution-based-on-character-n-gram-features.pdf",
            "Abstract": "A number of independent authorship attribution studies have demonstrated the effectiveness of character n-gram features for representing the stylistic properties of text. However, the vast majority of these studies examined the simple case where the training and test corpora are similar in terms of genre, topic, and distribution of the texts. Hence, there are doubts whether such a simple and low-level representation is equally effective in realistic conditions where some of the above factors are not possible to remain stable. In this study, the robustness of authorship attribution based on character n-gram features is tested under cross-genre and cross-topic conditions. In addition, the distribution of texts over the candidate authors varies in training and test corpora to imitate real cases. Comparative results with another competitive text representation approach based on very frequent words show that character n-grams are better able to capture stylistic properties of text when there are significant differences among the training and test corpora. Moreover, a set of guidelines to tune an authorship attribution model according to the properties of training and test corpora is provided.",
            "Abstract entirety": 1,
            "Author pub id": "xie8sAEAAAAJ:VOx2b1Wkg3QC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Open set evaluation of web genre identification",
            "Publication year": 2018,
            "Publication url": "https://link.springer.com/article/10.1007/s10579-018-9418-y",
            "Abstract": "Web genre detection is a task that can enhance information retrieval systems by providing rich descriptions of documents and enabling more specialized queries. Most of previous studies in this field adopt the closed-set scenario where a given palette comprises all available genre labels. However this is not a realistic setup since web genres are constantly enriched with new labels and existing web genres are evolving in time. Open-set classification, where some pages used in the evaluation phase do not belong to any of the known genres, is a more realistic setup for this task. In this case, all pages not belonging to known genres can be seen as noise. This paper focuses on systematic evaluation of open-set web genre identification when the noise is either structured or unstructured. Two open-set methods combined with alternative text representation schemes and similarity measures are tested based on \u2026",
            "Abstract entirety": 0,
            "Author pub id": "xie8sAEAAAAJ:eJXPG6dFmWUC",
            "Publisher": "Springer Netherlands"
        },
        {
            "Title": "Improving author verification based on topic modeling",
            "Publication year": 2019,
            "Publication url": "https://asistdl.onlinelibrary.wiley.com/doi/abs/10.1002/asi.24183",
            "Abstract": "Authorship analysis attempts to reveal information about authors of digital documents enabling applications in digital humanities, text forensics, and cyber\u2010security. Author verification is a fundamental task where, given a set of texts written by a certain author, we should decide whether another text is also by that author. In this article we systematically study the usefulness of topic modeling in author verification. We examine several author verification methods that cover the main paradigms, namely, intrinsic (attempt to solve a one\u2010class classification task) and extrinsic (attempt to solve a binary classification task) methods as well as profile\u2010based (all documents of known authorship are treated cumulatively) and instance\u2010based (each document of known authorship is treated separately) approaches combined with well\u2010known topic modeling methods such as Latent Semantic Indexing (LSI) and Latent Dirichlet \u2026",
            "Abstract entirety": 0,
            "Author pub id": "xie8sAEAAAAJ:J-pR_7NvFogC",
            "Publisher": "John Wiley & Sons, Inc."
        },
        {
            "Title": "Overview of PAN\u201916",
            "Publication year": 2016,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-319-44564-9_28",
            "Abstract": "This paper presents an overview of the PAN/CLEF evaluation lab. During the last decade, PAN has been established as the main forum of digital text forensic research. PAN 2016 comprises three shared tasks: (i) author identification, addressing author clustering and diarization (or intrinsic plagiarism detection); (ii) author profiling, addressing age and gender prediction from a cross-genre perspective; and (iii) author obfuscation, addressing author masking and obfuscation evaluation. In total, 35 teams participated in all three shared tasks of PAN 2016 and, following the practice of previous editions, software submissions were required and evaluated within the TIRA experimentation framework.",
            "Abstract entirety": 1,
            "Author pub id": "xie8sAEAAAAJ:nb7KW1ujOQ8C",
            "Publisher": "Springer, Cham"
        },
        {
            "Title": "Spam detection using character n-grams",
            "Publication year": 2006,
            "Publication url": "https://link.springer.com/chapter/10.1007/11752912_12",
            "Abstract": "This paper presents a content-based approach to spam detection based on low-level information. Instead of the traditional \u2019bag of words\u2019 representation, we use a \u2019bag of character n-grams\u2019 representation which avoids the sparse data problem that arises in n-grams on the word-level. Moreover, it is language-independent and does not require any lemmatizer or \u2019deep\u2019 text preprocessing. Based on experiments on Ling-Spam corpus we evaluate the proposed representation in combination with support vector machines. Both binary and term-frequency representations achieve high precision rates while maintaining recall on equally high level, which is a crucial factor for anti-spam filters, a cost sensitive application.",
            "Abstract entirety": 1,
            "Author pub id": "xie8sAEAAAAJ:_kc_bZDykSQC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "Improving cross-topic authorship attribution: The role of pre-processing",
            "Publication year": 2017,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-319-77116-8_21",
            "Abstract": "The effectiveness of character n-gram features for representing the stylistic properties of a text has been demonstrated in various independent Authorship Attribution (AA) studies. Moreover, it has been shown that some categories of character n-grams perform better than others both under single and cross-topic AA conditions. In this work, we present an improved algorithm for cross-topic AA. We demonstrate that the effectiveness of character n-grams representation can be significantly enhanced by performing simple pre-processing steps and appropriately tuning the number of features, especially in cross-topic conditions.",
            "Abstract entirety": 1,
            "Author pub id": "xie8sAEAAAAJ:738O_yMBCRsC",
            "Publisher": "Springer, Cham"
        },
        {
            "Title": "Computer-based authorship attribution without lexical measures",
            "Publication year": 2001,
            "Publication url": "https://link.springer.com/article/10.1023/A:1002681919510",
            "Abstract": "The most important approaches to computer-assistedauthorship attribution are exclusively based onlexical measures that either represent the vocabularyrichness of the author or simply comprise frequenciesof occurrence of common words. In this paper wepresent a fully-automated approach to theidentification of the authorship of unrestricted textthat excludes any lexical measure. Instead we adapt aset of style markers to the analysis of the textperformed by an already existing natural languageprocessing tool using three stylometric levels, i.e.,token-level, phrase-level, and analysis-levelmeasures. The latter represent the way in which thetext has been analyzed. The presented experiments ona Modern Greek newspaper corpus show that the proposedset of style markers is able to distinguish reliablythe authors of a randomly-chosen group and performsbetter than a lexically-based approach. However \u2026",
            "Abstract entirety": 0,
            "Author pub id": "xie8sAEAAAAJ:u-x6o8ySG0sC",
            "Publisher": "Kluwer Academic Publishers"
        },
        {
            "Title": "3rd PAN workshop on uncovering plagiarism, authorship and social software misuse",
            "Publication year": 2009,
            "Publication url": "http://ftp.informatik.rwth-aachen.de/Publications/CEUR-WS/Vol-502/pan09-proceedings.pdf",
            "Abstract": "The PAN workshop brought together experts and researchers around the exciting and future-oriented topics of plagiarism detection, authorship identification, and the detection of social software misuse. The development of new solutions for these problems can benefit from the combination of existing technologies, and in this sense the workshop provides a platform that spans different views and approaches.Plagiarism analysis is a collective term for computer-based methods to identify a plagiarism offense. In connection with text documents we distinguish between corpus-based and intrinsic analysis: the former compares suspicious documents against a set of potential original documents, the latter identifies potentially plagiarized passages by analyzing the suspicious document with respect to changes in writing style.",
            "Abstract entirety": 1,
            "Author pub id": "xie8sAEAAAAJ:4DMP91E08xMC",
            "Publisher": "Unknown"
        },
        {
            "Title": "A SURVEY ON PLAGIARISM DETECTION IN TEXT MINING",
            "Publication year": 2013,
            "Publication url": "https://www.academia.edu/download/32636751/v1i916.pdf",
            "Abstract": "Plagiarism detection means detecting the document whether copied or stealing from the other document. The main goal is to detect the word by analyzing the writing style using technique intrinsic plagiarism detection. Text mining is used to extract the useful information from the text. Intrinsic plagiarism detection is used to take the few words from the document and then it compared to the original document whether it\u2019s plagiarized or not. In addition, it performs the modern method in intrinsic plagiarism detection such as Recall, Precision, F-measure and Granularity.",
            "Abstract entirety": 1,
            "Author pub id": "xie8sAEAAAAJ:ZuybSZzF8UAC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Supporting the cybercrime investigation process: effective discrimination of source code authors based on byte-level information",
            "Publication year": 2005,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-540-75993-5_14",
            "Abstract": "Source code authorship analysis is the particular field that attempts to identify the author of a computer program by treating each program as a linguistically analyzable entity. This is usually based on other undisputed program samples from the same author. There are several cases where the application of such a method could be of a major benefit, such as tracing the source of code left in the system after a cyber attack, authorship disputes, proof of authorship in court, etc. In this paper, we present our approach which is based on byte-level n-gram profiles and is an extension of a method that has been successfully applied to natural language text authorship attribution. We propose a simplified profile and a new similarity measure which is less complicated than the algorithm followed in text authorship attribution and it seems more suitable for source code identification since is better able to deal with very \u2026",
            "Abstract entirety": 0,
            "Author pub id": "xie8sAEAAAAJ:IWHjjKOFINEC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "Overview of the Author Identification Task at PAN 2013.",
            "Publication year": 2013,
            "Publication url": "https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.667.2799&rep=rep1&type=pdf",
            "Abstract": "The author identification task at PAN-2013 focuses on author verification where given a set of documents by a single author and a questioned document, the problem is to determine if the questioned document was written by that particular author or not. In this paper we present the evaluation setup, the performance measures, the new corpus we built for this task covering three languages and the evaluation results of the 18 participant teams that submitted their software. Moreover, we survey the characteristics of the submitted approaches and show that a very effective meta-model can be formed based on the output of the participant methods.",
            "Abstract entirety": 1,
            "Author pub id": "xie8sAEAAAAJ:70eg2SAEIzsC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Paraphrase plagiarism identification with character-level features",
            "Publication year": 2019,
            "Publication url": "https://link.springer.com/article/10.1007/s10044-017-0674-z",
            "Abstract": " Several methods have been proposed for determining plagiarism between pairs of sentences, passages or even full documents. However, the majority of these methods fail to reliably detect paraphrase plagiarism due to the high complexity of the task, even for human beings. Paraphrase plagiarism identification consists in automatically recognizing document fragments that contain reused text, which is intentionally hidden by means of some rewording practices such as semantic equivalences, discursive changes and morphological or lexical substitutions. Our main hypothesis establishes that the original author\u2019s writing style fingerprint prevails in the plagiarized text even when paraphrases occur. Thus, in this paper we propose a novel text representation scheme that gathers both content and style characteristics of texts, represented by means of character-level features. As an additional contribution, we \u2026",
            "Abstract entirety": 0,
            "Author pub id": "xie8sAEAAAAJ:sSrBHYA8nusC",
            "Publisher": "Springer London"
        },
        {
            "Title": "Devising Rhesus: A strange \u2018collaboration\u2019 between Aeschylus and Euripides",
            "Publication year": 2018,
            "Publication url": "https://academic.oup.com/dsh/article-abstract/33/2/347/3772155",
            "Abstract": "In recent years, one of the two fully preserved ancient Greek tragic plays of disputed authorship, Rhesus, traditionally attributed to Euripides, has been the object of a quite lively scholarly interest. The rather extreme number, for the standards of classical philology, of four published commentaries in 10 years, by Athanasios D. Stefanis, [Euripides\u2019]: Rhesus, Athens: Academy of Athens, , Arne Feickert, Euripidis: Rhesus, Frankfurt: Lang, , Vayos Liapis, A Commentary on the Rhesus Attributed to Euripides, Oxford: Oxford University Press, 2012, and Almut Fries, Pseudo-Euripides: Rhesus, Berlin: De Gruyter, 2014 (two of them in English), and one forthcoming by Marco Fantuzzi (also in English), tangibly prove the great vogue this drama enjoys nowadays. Its doubtful nature, as far as the fusion of tragic and comic elements is concerned (see further Burnett, Directions in Euripidean Criticism: A Collection of Essays \u2026",
            "Abstract entirety": 0,
            "Author pub id": "xie8sAEAAAAJ:WbkHhVStYXYC",
            "Publisher": "Oxford University Press"
        },
        {
            "Title": "A computational model for discriminating music performers",
            "Publication year": 2001,
            "Publication url": "https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.207.3745&rep=rep1&type=pdf",
            "Abstract": "In this study, a computational model that aims at the automatic discrimination of different human music performers playing the same piece is presented. The proposed model is based on the note level and does not require any deep (eg, structural or harmonic, etc.) analysis. A set of measures that attempts to capture both the style of the author and the style of the piece is introduced. The presented approach has been applied to a database of piano sonatas by WA Mozart performed by both a French and a Viennese pianist with very encouraging preliminary results.",
            "Abstract entirety": 1,
            "Author pub id": "xie8sAEAAAAJ:LkGwnXOMwfcC",
            "Publisher": "Unknown"
        },
        {
            "Title": "SUPP\u039fRTING THE CYBERCRIME INVESTIGATION PROCESS: EFFECTIVE DISCRIMINATION OF SOURCE CODE AUTHORS BASED ON BYTE-LEVEL INFORMATION",
            "Publication year": 2005,
            "Publication url": "https://www.scitepress.org/Papers/2005/14149/14149.pdf",
            "Abstract": "Source code authorship analysis is the particular field that attempts to identify the author of a computer program by treating each program as a linguistically analyzable entity. This is usually based on other undisputed program samples from the same author. There are several cases where the application of such a method could be of a major benefit, such as tracing the source of code left in the system after a cyber attack, authorship disputes, proof of authorship in court, etc. In this paper, we present our approach which is based on byte-level n-gram profiles and is an extension of a method that has been successfully applied to natural language text authorship attribution. We propose a simplified profile and a new similarity measure which is less complicated than the algorithm followed in text authorship attribution and it seems more suitable for source code identification since is better able to deal with very small training sets. Experiments were performed on two different data sets, one with programs written in C++ and the second with programs written in Java. Unlike the traditional language-dependent metrics used by previous studies, our approach can be applied to any programming language with no additional cost. The presented accuracy rates are much better than the best reported results for the same data sets.",
            "Abstract entirety": 1,
            "Author pub id": "xie8sAEAAAAJ:eMMeJKvmdy0C",
            "Publisher": "SCITEPRESS"
        },
        {
            "Title": "Syntactic dependency-based n-grams",
            "Publication year": 2013,
            "Publication url": "https://scholar.google.com/scholar?cluster=10645359373633239813&hl=en&oi=scholarr",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "xie8sAEAAAAJ:abG-DnoFyZgC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Evolution of the PAN lab on digital text forensics",
            "Publication year": 2019,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-030-22948-1_19",
            "Abstract": "PAN is a networking initiative for digital text forensics, where researchers and practitioners study technologies for text analysis with regard to originality, authorship, and trustworthiness. The practical importance of such technologies is obvious for law enforcement, cyber-security , and marketing, yet the general public needs to be aware of their capabilities as well to make informed decisions about them. This is particularly true since almost all of these technologies are still in their infancy, and active research is required to push them forward. Hence PAN focuses on the evaluation of selected tasks from the digital text forensics in order to develop large-scale, standardized benchmarks, and to assess the state of the art. In this chapter we present the evolution of three shared tasks: plagiarism detection, author identification, and author profiling.",
            "Abstract entirety": 1,
            "Author pub id": "xie8sAEAAAAJ:XiVPGOgt02cC",
            "Publisher": "Springer, Cham"
        },
        {
            "Title": "Syntactic dependency-based n-grams as classification features",
            "Publication year": 2012,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-642-37798-3_1",
            "Abstract": "In this paper we introduce a concept of syntactic n-grams (sn-grams). Sn-grams differ from traditional n-grams in the manner of what elements are considered neighbors. In case of sn-grams, the neighbors are taken by following syntactic relations in syntactic trees, and not by taking the words as they appear in the text. Dependency trees fit directly into this idea, while in case of constituency trees some simple additional steps should be made. Sn-grams can be applied in any NLP task where traditional n-grams are used. We describe how sn-grams were applied to authorship attribution. SVM classifier for several profile sizes was used. We used as baseline traditional n-grams of words, POS tags and characters. Obtained results are better when applying sn-grams.",
            "Abstract entirety": 1,
            "Author pub id": "xie8sAEAAAAJ:bEWYMUwI8FkC",
            "Publisher": "Springer, Berlin, Heidelberg"
        }
    ]
}]