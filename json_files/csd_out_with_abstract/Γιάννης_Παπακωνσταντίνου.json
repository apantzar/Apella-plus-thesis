[{
    "name": "\u0393\u03b9\u03ac\u03bd\u03bd\u03b7\u03c2 \u03a0\u03b1\u03c0\u03b1\u03ba\u03c9\u03bd\u03c3\u03c4\u03b1\u03bd\u03c4\u03af\u03bd\u03bf\u03c5",
    "romanize name": "Giannis Papakonstantinou",
    "School-Department": "Computer Science and Engineering ",
    "University": "University of California, San Diego",
    "Rank": "\u039a\u03b1\u03b8\u03b7\u03b3\u03b7\u03c4\u03ae\u03c2",
    "Apella_id": 9165,
    "Scholar name": "Yannis Papakonstantinou",
    "Scholar id": "81cvn3sAAAAJ",
    "Affiliation": "UCSD",
    "Citedby": 17870,
    "Scholar url": "https://scholar.google.com/citations?user=81cvn3sAAAAJ&hl=en",
    "Publications": [
        {
            "Title": "Minimization and Group-By Detection for Nested XQueries.",
            "Publication year": 2004,
            "Publication url": "https://univcergy.phpnet.org/alire/nested.pdf",
            "Abstract": "We describe and evaluate a query minimization technique that applies to XQueries, which are nested, perform arbitrary joins, and freely mix bag and set semantics. These features create key challenges that fundamentally extend the problem of minimizing conjunctive queries (no nesting, no mixed semantics) or tree pattern XPath expressions (no nesting, no joins, no bag semantics). The technique detects and removes redundant navigation across and within nested subqueries. An important application of this technique is group-by detection.",
            "Abstract entirety": 1,
            "Author pub id": "81cvn3sAAAAJ:_Qo2XoVZTnwC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Privacy in database publishing",
            "Publication year": 2005,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-540-30570-5_16",
            "Abstract": "We formulate and study a privacy guarantee to data owners, who share information with clients by publishing views of a proprietary database. The owner identi.es the sensitive proprietary data using a secret query against the proprietary database. Given an extra view, the privacy guarantee ensures that potential attackers will not learn any information about the secret that could not already be obtained from the existing views. We de.ne \u201clearning\u201d as the modi.cation of the attacker\u2019s a-priori probability distribution on the set of possible secrets. We assume arbitrary a-priori distributions (including distributions that correlate the existence of particular tuples) and solve the problem when secret and views are expressed as unions of conjunctive queries with non-equalities, under integrity constraints. We consider guarantees (a) for given view extents (b) for given domain of the secret and (c) independent of the \u2026",
            "Abstract entirety": 0,
            "Author pub id": "81cvn3sAAAAJ:Wp0gIr-vW9MC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "Challenges and Opportunities with Big Data 2012-2",
            "Publication year": 2011,
            "Publication url": "https://docs.lib.purdue.edu/ccpubs/448/",
            "Abstract": "The promise of data-driven decision-making is now being recognized broadly, and there is growing enthusiasm for the notion of\" Big Data\". While the promis of Big Data is real-for example, it is estimated that Google alone contributed 54 billion dollars to the US economy in 2009-there is currently a wide gap between its potential and its realization.",
            "Abstract entirety": 1,
            "Author pub id": "81cvn3sAAAAJ:PVjk1bu6vJQC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Maintaining data stream history for generating materialized views",
            "Publication year": 2021,
            "Publication url": "https://patents.google.com/patent/US20210165783A1/en",
            "Abstract": "Materialized views may be generated at a managed materialized view platform that accepts data streams as a source. When updating a materialized view with a data stream as a source, a stored portion of the stream is used to maintain a history of changes to be made. When a join operation needs to utilize the data stream source to determine an update to the materialized view, the data stream is preserved to complete the join and update the materialized view.",
            "Abstract entirety": 1,
            "Author pub id": "81cvn3sAAAAJ:XvxMoLDsR5gC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Interactive source registration in community-oriented information integration",
            "Publication year": 2008,
            "Publication url": "https://dl.acm.org/doi/abs/10.14778/1453856.1453887",
            "Abstract": "Modern Internet communities need to integrate and query structured information. Employing current information integration infrastructure, data integration is still a very costly effort, since source registration is performed by a central authority which becomes a bottleneck. We propose the community-based integration paradigm which pushes the source registration task to the independent community members. This creates new challenges caused by each community member's lack of a global overview on how her data interacts with the application queries of the community and the data from other sources. How can the source owner maximize the visibility of her data to existing applications, while minimizing the clean-up and reformatting cost associated with publishing? Does her data contradict (or could it contradict in the future) the data of other sources? We introduce RIDE, a visual registration tool that extends \u2026",
            "Abstract entirety": 0,
            "Author pub id": "81cvn3sAAAAJ:ns9cj8rnVeAC",
            "Publisher": "VLDB Endowment"
        },
        {
            "Title": "Plato: Approximate analytics over compressed time series with tight deterministic error guarantees",
            "Publication year": 2018,
            "Publication url": "https://dbucsd.github.io/paperpdfs/2018_1.pdf",
            "Abstract": "Plato provides sound and tight deterministic error guarantees for approximate analytics over compressed time series. Plato supports expressions that are compositions of the (commonly used in time series analytics) linear algebra operators over vectors, along with arithmetic operators. Such analytics can express common statistics (such as correlation and crosscorrelation) that may combine multiple time series. The time series are segmented either by fixed-length segmentation or by (more effective) variable-length segmentation. Each segment (i) is compressed by an estimation function that approximates the actual values and is coming from a userchosen estimation function family, and (ii) is associated with one to three (depending on the case) precomputed error measures. Then Plato is able to provide tight deterministic error guarantees for the analytics over the compressed time series.This work identifies two broad estimation function family groups. The Vector Space (VS) family and the presently defined Linear Scalable Family (LSF) lead to theoretically and practically high-quality guarantees, even for queries that combine multiple time series that have been independently compressed. Well-known function families (eg, the polynomial function family) belong to LSF. The theoretical aspect of \u201chigh quality\u201d is crisply captured by the Amplitude Independence (AI) property: An AI guarantee does not depend on the amplitude of the involved time series, even when we combine multiple time series. The experiments on four real-life datasets validated the importance of the Amplitude Independent (AI) error guarantees: When the novel AI guarantees \u2026",
            "Abstract entirety": 0,
            "Author pub id": "81cvn3sAAAAJ:SpbeaW3--B0C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Challenges and Opportunities with Big Data. A community white paper developed by leading researchers across the United States",
            "Publication year": 2012,
            "Publication url": "https://scholar.google.com/scholar?cluster=4640634377300043712&hl=en&oi=scholarr",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "81cvn3sAAAAJ:SP6oXDckpogC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Architecture and implementation of an XQuery-based information integration platform",
            "Publication year": 2002,
            "Publication url": "https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.117.9373&rep=rep1&type=pdf#page=20",
            "Abstract": "An increasing number of business users and software applications need to process information that is accessible via multiple diverse information systems, such as database systems, file systems, legacy applications or web services. We describe the Enosys XML Integration Platform (EXIP), a commercial XQuery-based data integration software platform that provides a queryable integrated view of such information. We describe the platform architecture and describe what the main principles and challenges are for the query engine. In particular, we discuss the query engine architecture and the underlying semistructured algebra, which is tuned for enabling query plan optimizations.",
            "Abstract entirety": 1,
            "Author pub id": "81cvn3sAAAAJ:hC7cP41nSMkC",
            "Publisher": "Unknown"
        },
        {
            "Title": "XML query forms (XQForms) declarative specification of XML query interfaces",
            "Publication year": 2001,
            "Publication url": "https://dl.acm.org/doi/pdf/10.1145/371920.372170",
            "Abstract": "XQForms is the first generator of Web-based query forms and reports for XML data. XQForms takes as input (i) XML Schemas that model the data to be queried and presented,(ii) declarative specifications, called annotations, of the logic of the query forms and reports that will be generated, and (iii) a set of template presentation libraries. The output is a set of query forms and reports that provide automated query construction and report formatting in order for the end users to query and browse the underlying XML data. Thus XQForms separates content (given by the XML Schema of the data), query form logic (specified by the annotations) and presentation of the forms and reports. The system architecture is modular and consists of four main components:(a) a collection of query form controls that incorporate query capabilities and allow parameter passing from the end users via the form page. A set of query form controls \u2026",
            "Abstract entirety": 0,
            "Author pub id": "81cvn3sAAAAJ:mB3voiENLucC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Do-It-Yourself database-driven web applications",
            "Publication year": 2009,
            "Publication url": "https://www.skylineuniversity.ac.ae/pdf/database/Database%20driven%20web%20sites.pdf",
            "Abstract": "UCSD\u2019s app2you project [15](commercialized as app2you. com) and its successor FORWARD project [11] 1 belong to the emerging space of Do-It-Yourself (DIY), custom, hosted, database-driven web application platforms that empower non-programmer business process owners to rapidly and cheaply create and evolve applications customized to their organizations\u2019 data and process needs. The hoped-for outcome of DIY platforms is paralleled to the emergence of spreadsheets in the 80s and of graphical presentation tools in the 90s [1]. Before the arrival of tools such as powerpoint, polished presentations had to be prepared by graphics professionals. PowerPoint enabled us to do them ourselves.",
            "Abstract entirety": 1,
            "Author pub id": "81cvn3sAAAAJ:NaGl4SEjCO4C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Waldo: An adaptive human interface for crowd entity resolution",
            "Publication year": 2017,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/3035918.3035931",
            "Abstract": "In Entity Resolution, the objective is to find which records of a dataset refer to the same real-world entity. Crowd Entity Resolution uses humans, in addition to machine algorithms, to improve the quality of the outcome. We study a hybrid approach that combines two common interfaces for human tasks in Crowd Entity Resolution, taking into account key observations about the advantages and disadvantages of the two interfaces. We give a formal definition to the problem of human task selection and we derive algorithms with strong optimality guarantees. Our experiments with four real-world datasets show that our hybrid approach gives an improvement of 50% to 300% in the crowd cost to resolve a dataset, compared to using a single interface.",
            "Abstract entirety": 1,
            "Author pub id": "81cvn3sAAAAJ:t7zJ5fGR-2UC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Navigation-driven evaluation of virtual mediated views",
            "Publication year": 2000,
            "Publication url": "https://link.springer.com/chapter/10.1007/3-540-46439-5_10",
            "Abstract": "The MIX mediator systems incorporates a novel framework for navigation-driven evaluation of virtual mediated views. Its architecture allows the on-demand computation of views and query results as the user navigates them. The evaluation scheme minimizes superfluous source access through the use of lazy mediators that translate incoming client navigations on virtual XML views into navigations on lower level mediators or wrapped sources. The proposed demand-driven approach is inevitable for handling up-to-date mediated views of large Web sources or query results. The non-materialization of the query answer is transparent to the client application since clients can navigate the query answer using a subset of the standard DOM API for XML documents. We elaborate on query evaluation in such a framework and show how algebraic plans can be implemented as trees of lazy mediators. Finally, we \u2026",
            "Abstract entirety": 0,
            "Author pub id": "81cvn3sAAAAJ:KlAtU1dfN6UC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "Using Context-sensitive Statistics to Rank Documents",
            "Publication year": 2010,
            "Publication url": "https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.188.3537&rep=rep1&type=pdf",
            "Abstract": "We study the problem of context-sensitive ranking for document retrieval, where a context is defined as a sub-collection of documents, and is specified by queries provided by domain-interested users. The motivation of context-sensitive search is that the ranking of the same",
            "Abstract entirety": 1,
            "Author pub id": "81cvn3sAAAAJ:B3FOqHPlNUQC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Keyword proximity search on XML graphs",
            "Publication year": 2003,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/1260806/",
            "Abstract": "XKeyword provides efficient keyword proximity queries on large XML graph databases. A query is simply a list of keywords and does not require any schema or query language knowledge for its formulation. XKeyword is built on a relational database and, hence, can accommodate very large graphs. Query evaluation is optimized by using the graph's schema. In particular, XKeyword consists of two stages. In the preprocessing stage a set of keyword indices are built along with indexed path relations that describe particular patterns of paths in the graph. In the query processing stage plans are developed that use a near optimal set of path relations to efficiently locate the keyword query results. The results are presented graphically using the novel idea of interactive result graphs, which are populated on-demand according to the user's navigation and allow efficient information discovery. We provide theoretical and \u2026",
            "Abstract entirety": 0,
            "Author pub id": "81cvn3sAAAAJ:Y0pCki6q_DkC",
            "Publisher": "IEEE"
        },
        {
            "Title": "CLIDE: interactive query formulation for service oriented architectures",
            "Publication year": 2007,
            "Publication url": "https://dl.acm.org/doi/pdf/10.1145/1247480.1247627",
            "Abstract": "Integration systems typically support a restricted set of queries over the schema they export. The reason is that the participating information sources contribute limited content and limited access methods. In prior work, these limited access methods have often been specified using a set of parameterized views exported as Web services, with the understanding that the integration system accepts only queries which have an equivalent rewriting using the views [5, 7, 9, 10]. These queries are called feasible. Infeasible queries are rejected without an explanatory feedback. To help a user, who is building an integration application, avoid a frustrating trial-and-error cycle, we demonstrate the CLIDE query formulation interface, which employes a coloring scheme to guide the user toward formulating feasible queries. CLIDE is based on Microsoft\u2019s Query Builder which is incorporated in MS SQL Server [1] and is, in turn, based \u2026",
            "Abstract entirety": 0,
            "Author pub id": "81cvn3sAAAAJ:vV6vV6tmYwMC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Index-Based, High-Dimensional, Cosine Threshold Querying with Optimality Guarantees",
            "Publication year": 2021,
            "Publication url": "https://link.springer.com/article/10.1007/s00224-020-10009-6",
            "Abstract": "Given a database of vectors, a cosine threshold query returns all vectors in the database having cosine similarity to a query vector above a given threshold \u03b8. These queries arise naturally in many applications, such as document retrieval, image search, and mass spectrometry. The paper considers the efficient evaluation of such queries, as well as of the closely related top-k cosine similarity queries. It provides novel optimality guarantees that exhibit good performance on real datasets. We take as a starting point Fagin\u2019s well-known Threshold Algorithm (TA), which can be used to answer cosine threshold queries as follows: an inverted index is first built from the database vectors during pre-processing; at query time, the algorithm traverses the index partially to gather a set of candidate vectors to be later verified for \u03b8-similarity. However, directly applying TA in its raw form misses significant optimization \u2026",
            "Abstract entirety": 0,
            "Author pub id": "81cvn3sAAAAJ:HbR8gkJAVGIC",
            "Publisher": "Springer US"
        },
        {
            "Title": "Querying XML with XQuery",
            "Publication year": 2005,
            "Publication url": "https://scholar.google.com/scholar?cluster=1285144092971996508&hl=en&oi=scholarr",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "81cvn3sAAAAJ:vRqMK49ujn8C",
            "Publisher": "Springer"
        },
        {
            "Title": "The SQL++ semi-structured data model and query language: A capabilities survey of sql-on-hadoop, nosql and newsql databases",
            "Publication year": 2014,
            "Publication url": "https://scholar.google.com/scholar?cluster=2982806101500804663&hl=en&oi=scholarr",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "81cvn3sAAAAJ:uLbwQdceFCQC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Query set specification language (QSSL)",
            "Publication year": 2003,
            "Publication url": "http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.8.1778",
            "Abstract": "Applications require access to multiple information sources and the data of other applications. WSDLbased web services are becoming a popular way of making information sources available on the web and, hence, to applications that need to consume them--often via data integration systems that combine the data of multiple sources. We argue that the function signature paradigm that is used today by web services cannot capture the query capabilities provided by structurally rich and functionally powerful information sources, such as relational databases. We propose the Query Set Specification Language (QSSL) that allows the concise description of sets of parameterized XPath queries. A QSS is embedded in a WSDL specification to form a specialized type of web services, called Data Services. Data Services connect the calls that the source accepts with the underlying schema. QSSL will be enhanced to describe subsets of XQuery expressions beyond XPath ones.",
            "Abstract entirety": 1,
            "Author pub id": "81cvn3sAAAAJ:j3f4tGmQtD8C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Cryptographic verification of database transactions",
            "Publication year": 2020,
            "Publication url": "https://patents.google.com/patent/US20200169412A1/en",
            "Abstract": "A database management system receives a request to perform a transaction. The database management system commits the transaction, and in response to committing the transaction, generates a cryptographic hash based on an attribute of the transaction. The cryptographic hash is stored in a leaf-region of a hash tree. In response to a request to verify the transaction, signatures are retrieved from the tree based on a traversal of the tree to locate the node corresponding to the transaction. The retrieved signatures are used to verify the transaction.",
            "Abstract entirety": 1,
            "Author pub id": "81cvn3sAAAAJ:LO7wyVUgiFcC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Polystore Query Rewriting: The Challenges of Variety.",
            "Publication year": 2016,
            "Publication url": "http://ceur-ws.org/Vol-1558/paper46.pdf",
            "Abstract": "Numerous databases marketed as SQL-on-Hadoop, NewSQL [16] and NoSQL have emerged to catalyze Big Data applications. These databases generally support the 3Vs [7].(i) Volume: amount of data (ii) Velocity: speed of data in and out (iii) Variety: semi-structured and heterogeneous data. As a result of differing use cases and design considerations around the Variety requirement, these new databases have adopted semi-structured data models that vary among each other. Their query languages have even more variations. Some variations are due to superficial syntactic differences. Some variations arise from the data model differences. Other variations are genuine differences in query capabilities. Yet another kind of variations involves subtly different semantics for seemingly similar query functionalities. Eg, equality may have subtle and unexpected meanings in the presence of missing attributes in NoSQL databases.Even in a single organization, it is common to find multiple databases that exhibit high variety. Often applications require integrated access to those databases. It is difficult to write optimized software that retrieves data from multiple such databases, given the different data models, different query syntaxes and the (often subtly) different query semantics. This problem has been recognized for many decades in the database community. It is now accentuated, as a plethora of different and specialized databases finds its place in the enterprise. For example, the problem happens whenever an enterprise adopts a fast and scalable NoSQL database to capture its users\u2019 activity on its web site (web log) and then builds applications that \u2026",
            "Abstract entirety": 0,
            "Author pub id": "81cvn3sAAAAJ:z_wVstp3MssC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Interactive query formulation over web service-accessed sources",
            "Publication year": 2006,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/1142473.1142503",
            "Abstract": "Integration systems typically support only a restricted set of queries over the schema they export. The reason is that the participating information sources contribute limited content and limited access methods. In prior work, these limited access methods have often been specified using a set of parameterized views, with the understanding that the integration system accepts only queries which have an equivalent rewriting using the views. These queries are called feasible. Infeasible queries are rejected without an explanatory feedback. To help a developer, who is building an integration application, avoid a frustrating trial-and-error cycle, we introduce the CLIDE query formulation interface, which extends the QBE-like query builder of Microsoft's SQL Server with a coloring scheme that guides the user toward formulating feasible queries. We provide guarantees that the suggested query edit actions are complete (ie \u2026",
            "Abstract entirety": 0,
            "Author pub id": "81cvn3sAAAAJ:TFP_iSt0sucC",
            "Publisher": "Unknown"
        },
        {
            "Title": "The NEXT framework for logical XQuery optimization",
            "Publication year": 2004,
            "Publication url": "https://books.google.com/books?hl=en&lr=&id=R780l9ETyw8C&oi=fnd&pg=PA168&dq=info:ZNfb7TQnuJMJ:scholar.google.com&ots=XJE9OXDVYi&sig=h5Gf0os-9h-jDFJbz4RPPek47Oo",
            "Abstract": "Classical logical optimization techniques rely on a logical semantics of the query language. The adaptation of these techniques to XQuery is precluded by its definition as a functional language with operational semantics. We introduce Nested XML Tableaux which enable a logical foundation for XQuery semantics and provide the logical plan optimization framework of our XQuery processor. As a proof of concept, we develop and evaluate a minimization algorithm for removing redundant navigation within and across nested subqueries. The rich XQuery features create key challenges that fundamentally extend the prior work on the problems of minimizing conjunctive and tree pattern queries.",
            "Abstract entirety": 1,
            "Author pub id": "81cvn3sAAAAJ:_kc_bZDykSQC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Searching digital information and databases",
            "Publication year": 2010,
            "Publication url": "https://patents.google.com/patent/US7698267B2/en",
            "Abstract": "This application describes methods for searching digital information such as digital documents (eg, web pages) and computer databases, and specific search techniques such as authority ranking and information retrieval (IR) relevance ranking in keyword searches. In some implementations, the technique includes analyzing digital information viewed as a labeled graph, including nodes and edges, based on a flow of authority among the nodes along the edges, the flow of authority being derived at least in part from different authority transfer rates assigned to the edges based on edge type schema information. In some implementations, the system includes an object rank module configured to generate multiple initial rankings corresponding to multiple query keywords, each of the multiple initial rankings indicating authority of nodes in a graph with respect to each respective query keyword individually; and a query \u2026",
            "Abstract entirety": 0,
            "Author pub id": "81cvn3sAAAAJ:VOx2b1Wkg3QC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Searching digital information and databases",
            "Publication year": 2014,
            "Publication url": "https://patents.google.com/patent/US8862594B2/en",
            "Abstract": "This application describes methods for searching digital information such as digital documents (eg, web pages) and computer databases, and specific search techniques such as authority ranking and information retrieval (IR) relevance ranking in keyword searches. In some implementations, the technique includes analyzing digital information viewed as a labeled graph, including nodes and edges, based on a flow of authority among the nodes along the edges, the flow of authority being derived at least in part from different authority transfer rates assigned to the edges based on edge type schema information. In some implementations, the system includes an object rank module configured to generate multiple initial rankings corresponding to multiple query keywords, each of the multiple initial rankings indicating authority of nodes in a graph with respect to each respective query keyword individually; and a query \u2026",
            "Abstract entirety": 0,
            "Author pub id": "81cvn3sAAAAJ:WbkHhVStYXYC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Storing and querying XML data using denormalized relational databases",
            "Publication year": 2005,
            "Publication url": "https://link.springer.com/article/10.1007/s00778-003-0113-1",
            "Abstract": "XML database systems emerge as a result of the acceptance of the XML data model. Recent works have followed the promising approach of building XML database management systems on underlying RDBMS\u2019s. Achieving query processing performance reduces to two questions: (i) How should the XML data be decomposed into data that are stored in the RDBMS? (ii) How should the XML query be translated into an efficient plan that sends one or more SQL queries to the underlying RDBMS and combines the data into the XML result? We provide a formal framework for XML Schema-driven decompositions, which encompasses the decompositions proposed in prior work and extends them with decompositions that employ denormalized tables and binary-coded XML fragments. We provide corresponding query processing algorithms that translate the XML query conditions into conditions on the relational \u2026",
            "Abstract entirety": 0,
            "Author pub id": "81cvn3sAAAAJ:dhFuZR0502QC",
            "Publisher": "Springer-Verlag"
        },
        {
            "Title": "Replicating materialized views across heterogeneous target systems",
            "Publication year": 2021,
            "Publication url": "https://patents.google.com/patent/US20210165803A1/en",
            "Abstract": "A materialized view created by a materialized view management platform may be replicated across many different target systems. The materialized view management platform allows users to specify different target systems. To create the materialized view in the different target systems, the materialized view management platform can translate the materialized view into different formats in order to store the materialized view in the different formats. Updates to the different instances of the materialized view are then made to keep the different materialized view formats in the different target systems up-to-date.",
            "Abstract entirety": 1,
            "Author pub id": "81cvn3sAAAAJ:a9-T7VOCCH8C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Fast In-Memory SQL Analytics on Graphs",
            "Publication year": 2016,
            "Publication url": "https://arxiv.org/abs/1602.00033",
            "Abstract": "We study a class of graph analytics SQL queries, which we call relationship queries. Relationship queries are a wide superset of fixed-length graph reachability queries and of tree pattern queries. Intuitively, it discovers target entities that are reachable from source entities specified by the query. It usually also finds aggregated scores, which correspond to the target entities and are calculated by applying aggregation functions on measure attributes, which are found on the target entities, the source entities and the paths from the sources to the targets. We present real-world OLAP scenarios, where efficient relationship queries are needed. However, row stores, column stores and graph databases are unacceptably slow in such OLAP scenarios. We briefly comment on the straightforward extension of relationship queries that allows accessing arbitrary schemas. The GQ-Fast in-memory analytics engine utilizes a bottom-up fully pipelined query execution model running on a novel data organization that combines salient features of column-based organization, indexing and compression. Furthermore, GQ-Fast compiles its query plans into executable C++ source codes. Besides achieving runtime efficiency, GQ-Fast also reduces main memory requirements because, unlike column databases, GQ-Fast selectively allows more dense forms of compression including heavy-weighted compressions, which do not support random access. We used GQ-Fast to accelerate queries for two OLAP dashboards in the biomedical field. It outperforms Postgres by 2-4 orders of magnitude and outperforms MonetDB and Neo4j by 1-3 orders of magnitude when all of them \u2026",
            "Abstract entirety": 0,
            "Author pub id": "81cvn3sAAAAJ:nrtMV_XWKgEC",
            "Publisher": "Unknown"
        },
        {
            "Title": "ViDeTTe Interactive Notebooks",
            "Publication year": 2018,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/3209900.3209907",
            "Abstract": "Interactive notebooks allow the use of popular languages, such as python, for composing data analytics projects. The interface they provide, enables data scientists to import data, analyze them and compose the results into easily readable report-like web pages, that can contain re-runnable code, visualizations and textual description of the entire process, all in one place. Scientists can then share such pages with other users in order to present their findings, collaborate and further explore the underlying data.",
            "Abstract entirety": 1,
            "Author pub id": "81cvn3sAAAAJ:M7yex6snE4oC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Mixing querying and navigation in mix",
            "Publication year": 2002,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/994714/",
            "Abstract": "Web-based information systems provide to their users the ability to interleave querying and browsing during their information discovery efforts. The MIX system provides an API called QDOM (Querible Document Object Model) that supports the interleaved querying and browsing of virtual XML views, specified in an XQuery-like language. QDOM is based on the DOM standard. It allows the client applications to navigate into the view using standard DOM navigation commands. Then the application can use any visited node as the root for a query that creates a new view. The query/navigation processing algorithms of MIX perform decontextualization, i.e., they translate a query that has been issued from within the context of other queries and navigations into efficient queries that are understood by the source outside of the context of previous operations. In addition, MIX provides a navigation-driven query evaluation \u2026",
            "Abstract entirety": 0,
            "Author pub id": "81cvn3sAAAAJ:R3hNpaxXUhUC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Context-sensitive ranking",
            "Publication year": 2012,
            "Publication url": "https://escholarship.org/uc/item/6gm3z8t9",
            "Abstract": "We are witnessing a growing number of applications that involve both structured data and unstructured data. A simple example is academic citations : while the citation's content is unstructured text, the citation is associated with structured data such as author list, categories and publication time. To query such hybrid data, a natural approach is to combine structured queries with keyword search. Two fundamental problems arise for this unique marriage : (1) How to evaluate hybrid queries efficiently? (2) How to model relevance ranking? The second problem is especially difficult, because all the foundations of relevance ranking in information retrieval are built on unstructured text and no structures are considered. We present context-sensitive ranking, a ranking framework that integrates structured queries and relevance ranking. The key insight is that structured queries provide expressive search contexts. The ranking model collects keyword statistics in the contexts and feeds them into conventional ranking formulas to compute ranking scores. The query evaluation challenge is the computation of keyword statistics at runtime, which involves expensive online aggregations. At the core of our solution to overcome the efficiency issue is an innovative reduction from computing keyword statistics to answering aggregation queries. Many statistics, such as document frequency, require aggregations over the data space returned by the structured query. This is analogous to analytical queries in OLAP applications, which involve a large number of aggregations. We leverage and extend the materialized view research in OLAP to deliver algorithms and data \u2026",
            "Abstract entirety": 0,
            "Author pub id": "81cvn3sAAAAJ:5awf1xo2G04C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Assisting discovery in public health",
            "Publication year": 2017,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/3077257.3077269",
            "Abstract": "Several public health (PH) researchers have lately been arguing that big data can play a profound role in scientific discovery. Leveraging the vast amount of population-level data collected by public agencies and other organizations, could lead to important discoveries that were not necessarily suspected to be true. However, they also warn about the pitfalls of data-driven discovery: The large amount of data can easily lead to information overload for the researchers. Additionally, data-driven studies that make a lot of tests in the search for important discoveries have the potential to lead to discoveries that seem important but are in fact random.",
            "Abstract entirety": 1,
            "Author pub id": "81cvn3sAAAAJ:gsN89kCJA0AC",
            "Publisher": "Unknown"
        },
        {
            "Title": "MILC: Inverted list compression in memory",
            "Publication year": 2017,
            "Publication url": "https://dl.acm.org/doi/abs/10.14778/3090163.3090164",
            "Abstract": "Inverted list compression is a topic that has been studied for 50 years due to its fundamental importance in numerous applications including information retrieval, databases, and graph analytics. Typically, an inverted list compression algorithm is evaluated on its space overhead and query processing time. Earlier list compression designs mainly focused on minimizing the space overhead to reduce expensive disk I/O time in disk-oriented systems. But the recent trend is shifted towards reducing query processing time because the underlying systems tend to be memory-resident. Although there are many highly optimized compression approaches in main memory, there is still a considerable performance gap between query processing over compressed lists and uncompressed lists, which motivates this work.In this work, we set out to bridge this performance gap for the first time by proposing a new compression \u2026",
            "Abstract entirety": 0,
            "Author pub id": "81cvn3sAAAAJ:KUbvn5osdkgC",
            "Publisher": "VLDB Endowment"
        },
        {
            "Title": "Using Proximity Search to Estimate Authority Flow",
            "Publication year": 2010,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/5551130/",
            "Abstract": "Authority flow and proximity search have been used extensively in measuring the association between entities in data graphs, ranging from the web to relational and XML databases. These two ranking factors have been used and studied separately in the past. In addition to their semantic differences, a key advantage of proximity search is the existence of efficient execution algorithms. In contrast, due to the complexity of calculating the authority flow, current systems only use precomputed authority flows in runtime. This limitation prohibits authority flow to be used more effectively as a ranking factor. In this paper, we present a comparative analysis of the two ranking factors. We present an efficient approximation of authority flow based on proximity search. We analytically estimate the approximation error and how this affects the ranking of the results of a query.",
            "Abstract entirety": 1,
            "Author pub id": "81cvn3sAAAAJ:UxriW0iASnsC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Expressive capabilities description languages and query rewriting algorithms",
            "Publication year": 2000,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S0743106699000266",
            "Abstract": "Information integration systems have to cope with a wide variety of different information sources, which support query interfaces with very varied capabilities. To deal with this problem, the integration systems need descriptions of the query capabilities of each source, i.e., the set of queries supported by each source. Moreover, the integration systems need algorithms for deciding how a query can be answered given the capabilities of the sources. Finally, they need to translate a query into the format that the source understands. We present two languages suitable for descriptions of query capabilities of sources and compare their expressive power. We also use one of the languages to automatically derive the capabilities description of the integration system itself, in terms of the capabilities of the sources it integrates. We describe algorithms for deciding whether a query \u201cmatches\u201d the description and show their \u2026",
            "Abstract entirety": 0,
            "Author pub id": "81cvn3sAAAAJ:qxL8FJ1GzNcC",
            "Publisher": "North-Holland"
        },
        {
            "Title": "Incremental validation of XML documents",
            "Publication year": 2003,
            "Publication url": "https://link.springer.com/chapter/10.1007/3-540-36285-1_4",
            "Abstract": "We investigate the incremental validation of XML documents with respect to DTDs and XML Schemas, under updates consisting of element tag renamings, insertions and deletions. DTDs are modeled as extended context-free grammars and XML Schemas are abstracted as \u201cspecialized DTDs\u201d, allowing to decouple element types from element tags. For DTDs, we exhibit an O(m log n) incremental validation algorithm using an auxiliary structure of size O(n), where n is the size of the document and m the number of updates. For specialized DTDs, we provide an O(m log2 n) incremental algorithm, again using an auxiliary structure of size O(n). This is a significant improvement over brute-force re-validation from scratch.",
            "Abstract entirety": 1,
            "Author pub id": "81cvn3sAAAAJ:3fE2CSJIrl8C",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "The Enosys Markets data integration platform: lessons from the trenches",
            "Publication year": 2001,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/502585.502681",
            "Abstract": "Enosys Markets offers a state-of-the-art data integration software platform to support the development of the next generation of eBusiness applications that deliver value by providing new levels of function for customer relationship management, e-commerce, supply chain management, and decision support. These applications require that data be integrated from information sources that exist both within and across organizational boundaries. The Enosys Markets data integration architecture and product family provides a complete end-to-end XML-based solution for integrating and querying distributed information sources. It incorporates advanced research into XML and database technology. We present the product architecture and components, discuss the key technical challenges, and outline the technical concepts and innovations employed in the Enosys platform.",
            "Abstract entirety": 1,
            "Author pub id": "81cvn3sAAAAJ:4JMBOYKVnBMC",
            "Publisher": "Unknown"
        },
        {
            "Title": "FORWARD: Design Specification Techniques for Do-It-Yourself Application Platforms.",
            "Publication year": 2009,
            "Publication url": "http://microbiology.ucdavis.edu/kowalczykowski/PDF_files/KK-WebDB%202009.pdf",
            "Abstract": "The FORWARD project, as well as its app2you predecessor, is a Do-It-Yourself web application platform that enables non-programmers to create custom forms-driven workflow applications, where users with potentially different roles and rights interact. Our experience with the commercialized version of app2you (app2you. com) shows that formsdriven workflow applications exhibit a viable balance between application scope and ease of specification. The proposed demo uses a real-world application, the TechCrunch50 2008 reviewing application, to illustrate key specification techniques the Do-It-Yourself design facility provides to nonprogrammer application creators. The demo audience will also have hands-on experience building applications without any programming.",
            "Abstract entirety": 1,
            "Author pub id": "81cvn3sAAAAJ:35N4QoGY0k4C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Objectrank: Authority-based keyword search in databases",
            "Publication year": 2004,
            "Publication url": "https://www.cs.ucr.edu/~vagelis/publications/ObjectRankExtended.pdf",
            "Abstract": "The ObjectRank system applies authority-based ranking to keyword search in databases modeled as labeled graphs. Conceptually, authority originates at the nodes (objects) containing the keywords and flows to objects according to their semantic connections. Each node is ranked according to its authority with respect to the particular",
            "Abstract entirety": 1,
            "Author pub id": "81cvn3sAAAAJ:IjCSPb-OGe4C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Keyword proximity search in XML trees",
            "Publication year": 2006,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/1599390/",
            "Abstract": "Recent works have shown the benefits of keyword proximity search in querying XML documents in addition to text documents. For example, given query keywords over Shakespeare's plays in XML, the user might be interested in knowing how the keywords cooccur. In this paper, we focus on XML trees and define XML keyword, proximity queries to return the (possibly heterogeneous) set of minimum connecting trees (MCTs) of the matches to the individual keywords in the query. We consider efficiently executing keyword proximity queries on labeled trees (XML) in various settings: 1) when the XML database has been preprocessed and 2) when no indices are available on the XML database. We perform a detailed experimental evaluation to study the benefits of our approach and show that our algorithms considerably outperform prior algorithms and other applicable approaches.",
            "Abstract entirety": 1,
            "Author pub id": "81cvn3sAAAAJ:hqOjcs7Dif8C",
            "Publisher": "IEEE"
        },
        {
            "Title": "Index and view updates in a ledger-based database",
            "Publication year": 2021,
            "Publication url": "https://patents.google.com/patent/US11119998B1/en",
            "Abstract": "A database management system stores data for a table using a ledger which comprises journal and summary portions. A query processor of the database identifies a first set of operations to update a document of a table in accordance with an update command. The query processor identifies a second set of operations to update tables or views that are potentially affected by the update to the document. The query processor then causes the first and second sets of operations to be executed as an atomic unit.",
            "Abstract entirety": 1,
            "Author pub id": "81cvn3sAAAAJ:WJVC3Jt7v1AC",
            "Publisher": "Unknown"
        },
        {
            "Title": "RIDE: a tool for interactive source registration in community-oriented information integration",
            "Publication year": 2008,
            "Publication url": "https://dl.acm.org/doi/abs/10.14778/1454159.1454202",
            "Abstract": "Modern Internet communities need to integrate and query structured information. Employing current information integration infrastructure, data integration is still a very costly effort, since source registration is performed by a central authority which becomes a bottleneck. We propose the community-based integration paradigm which pushes the source registration task to the independent community members. This creates new challenges caused by each member's lack of a global overview on how her data interacts with the application queries of the community and the data from other sources. How can the source owner maximize the visibility of her data to existing applications, while minimizing the clean-up and reformatting cost associated with publishing? Does her data contradict (or could it contradict in the future) the data of other sources?",
            "Abstract entirety": 1,
            "Author pub id": "81cvn3sAAAAJ:NhqRSupF_l8C",
            "Publisher": "VLDB Endowment"
        },
        {
            "Title": "The SQL++ unifying semi-structured query language, and an expressiveness benchmark of SQL-on-Hadoop, NoSQL and NewSQL databases",
            "Publication year": 2014,
            "Publication url": "http://www.cslab.ece.ntua.gr/~dtsouma/papers/375.pdf",
            "Abstract": "SQL-on-Hadoop, NewSQL and NoSQL databases provide semi-structured data models (typically JSON based) and respective query languages. Lack of formal syntax and semantics, idiomatic (non-SQL) language constructs and large variations in syntax, semantics and actual capabilities pose problems even to database experts: It is hard to understand, compare and use these languages. It is especially tedious to write software that interoperates between two of them or an SQL database and one of them. Towards solving these problems, first we formally specify the syntax and semantics of SQL++. It consists of a semi-structured data model (which extends both JSON and the relational data model) and a query language that is fully backwards compatible with SQL. SQL++ is \u201cunifying\u201d in the sense that it is explicitly designed to encompass the data model and query language capabilities of current SQL-on-Hadoop, NoSQL and NewSQL databases.Then, we itemize fifteen SQL++ data model and query language features and benchmark eleven databases on their support of the multiple options associated with each feature, leading to feature matrices and commentary. Each feature matrix is the result of empirical validation through sample queries.",
            "Abstract entirety": 1,
            "Author pub id": "81cvn3sAAAAJ:PR6Y55bgFSsC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Technical perspective: Supporting linear algebra operations in SQL",
            "Publication year": 2020,
            "Publication url": "https://dl.acm.org/doi/fullHtml/10.1145/3405468",
            "Abstract": "Linear algebra operations are at the core of machine learning. Multiple specialized systems have emerged for the scalable, distributed execution of matrix and vector operations. The relationship of such computations to data management and databases however brings frictions. It is well known that a great deal of human time and machine time is being spent nowadays on fetching data out of the database and performing a computation on a specialized system. One answer to the issue is that we truly need a new kind of non-SQL database that is tuned to these computations.The creators of SimSQL opted for the decidedly incremental approach. Can we make a very small set of changes to the relational model and RDBMS software to render them suitable for executing linear algebra in the database?",
            "Abstract entirety": 1,
            "Author pub id": "81cvn3sAAAAJ:NXb4pA-qfm4C",
            "Publisher": "ACM"
        },
        {
            "Title": "Structured materialized views for XML queries",
            "Publication year": 2006,
            "Publication url": "https://hal.inria.fr/inria-00001233/",
            "Abstract": "The performance of XML database queries can be greatly enhanced by employing materialized views. We present containment and rewriting algorithms for tree pattern queries that correspond to a large and important subset of XQuery, in the presence of a structural summary of the database (ie, in the presence of a Dataguide). The tree pattern language captures structural identifiers and optional nodes, which allow us to translate nested XQueries into tree patterns. We characterize the complexity of tree pattern containment and rewriting, under the constraints expressed in the structural summary, whose enhanced form also entails integrity constraints. Our approach is implemented in the ULoad [4] prototype and we present a performance analysis.",
            "Abstract entirety": 1,
            "Author pub id": "81cvn3sAAAAJ:RGFaLdJalmkC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Computer with a mechanism for securing a storage medium drive and a mother board",
            "Publication year": 2004,
            "Publication url": "https://patents.google.com/patent/US6711007B2/en",
            "Abstract": "A computer with a security mechanism, for securing a motherboard and a storage medium drive such as a hard disk, is provided. The computer comprises a chassis, a pan, a first latch, a locking mechanism and a lock. The pan, disposed under the chassis, has the motherboard mounted thereon. The first latch, moveably disposed at the chassis, detachably engages the pan so that the pan combines with the chassis. The hard disk drive is accessibly disposed on the chassis. The locking mechanism is moveably disposed at the chassis to lock the hard disk drive in a separable manner.",
            "Abstract entirety": 1,
            "Author pub id": "81cvn3sAAAAJ:q3CdL3IzO_QC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Data Compression for Analytics over Large-scale In-memory Column Databases",
            "Publication year": 2016,
            "Publication url": "https://arxiv.org/abs/1606.09315",
            "Abstract": "Data compression schemes have exhibited their importance in column databases by contributing to the high-performance OLAP (Online Analytical Processing) query processing. Existing works mainly concentrate on evaluating compression schemes for disk-resident databases as data is mostly stored on disks. With the continuously decreasing of the price/capacity ratio of main memory, it is the tendencies of the times to reside data in main memory. But the discussion of data compression on in-memory databases is very vague in the literature. In this work, we present an updated discussion about whether it is valuable to use data compression techniques in memory databases. If yes, how should memory databases apply data compression schemes to maximize performance?",
            "Abstract entirety": 1,
            "Author pub id": "81cvn3sAAAAJ:epqYDVWIO7EC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Generating Query Forms and Reports for Semistructured Data: The QURSED Editor",
            "Publication year": 2003,
            "Publication url": "https://www.academia.edu/download/1405365/l2804docg1m7305.pdf",
            "Abstract": "The wide adoption of semistructured XML databases requires the existence of systems for the generation and execution of web-based interactive database query forms and reports. Such systems are most effective when they allow the construction of the query forms and reports without programming, via the use of intuitive graphical tools. We describe the architecture of the QURSED system for the declarative specification and automatic generation of web-based query forms and reports (QFRs) for semistructured XML data. We then focus on the QURSED Editor, a powerful GUI tool for the generation of the declarative specifications of QFRs. We describe the Editor's architecture and present the techniques and heuristics the Editor employs for translating visual designer input into meaningful specifications of query forms and reports. An on-line demonstration of the system is available at http://www. db. ucsd. edu/qursed",
            "Abstract entirety": 1,
            "Author pub id": "81cvn3sAAAAJ:SeFeTyx0c_EC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Declarative ajax web applications through sql++ on a unified application state",
            "Publication year": 2013,
            "Publication url": "https://arxiv.org/abs/1308.0656",
            "Abstract": "Implementing even a conceptually simple web application requires an inordinate amount of time. FORWARD addresses three problems that reduce developer productivity: (a) Impedance mismatch across the multiple languages used at different tiers of the application architecture. (b) Distributed data access across the multiple data sources of the application (SQL database, user input of the browser page, session data in the application server, etc). (c) Asynchronous, incremental modification of the pages, as performed by Ajax actions. FORWARD belongs to a novel family of web application frameworks that attack impedance mismatch by offering a single unifying language. FORWARD's language is SQL++, a minimally extended SQL. FORWARD's architecture is based on two novel cornerstones: (a) A Unified Application State (UAS), which is a virtual database over the multiple data sources. The UAS is accessed via distributed SQL++ queries, therefore resolving the distributed data access problem. (b) Declarative page specifications, which treat the data displayed by pages as rendered SQL++ page queries. The resulting pages are automatically incrementally modified by FORWARD. User input on the page becomes part of the UAS. We show that SQL++ captures the semi-structured nature of web pages and subsumes the data models of two important data sources of the UAS: SQL databases and JavaScript components. We show that simple markup is sufficient for creating Ajax displays and for modeling user input on the page as UAS data sources. Finally, we discuss the page specification syntax and semantics that are needed in order to avoid \u2026",
            "Abstract entirety": 0,
            "Author pub id": "81cvn3sAAAAJ:N5tVd3kTz84C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Evaluating List Intersection on SSDs for Parallel I/O Skipping",
            "Publication year": 2021,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/9458605/",
            "Abstract": "List intersection is at the core of information retrieval systems. Existing disk-based intersection algorithms were optimized for hard disk drives (HDDs) since HDDs have dominated the storage market for decades. In particular, those HDD-centric algorithms read every relevant list entirely to memory to minimize expensive random reads by performing sequential reads, although many entries in the list may be useless. Such a tradeoff makes perfect sense on HDDs, because random reads are one to two orders of magnitude slower than sequential reads. However, fast solid state drives (SSDs) have changed this landscape by improving random I/O performance dramatically. More importantly, they are manufactured with multiple flash channels to support parallel I/Os. As a result, the performance gap between random and sequential reads becomes very small on SSDs. This means that HDD-optimized intersection \u2026",
            "Abstract entirety": 0,
            "Author pub id": "81cvn3sAAAAJ:kh2fBNsKQNwC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Graphical query interfaces for semistructured data: the QURSED system",
            "Publication year": 2005,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/1064340.1064344",
            "Abstract": "We describe the QURSED system for the declarative specification and automatic generation of Web-based query forms and reports (QFRs) for semistructured XML data. In QURSED, a QFR is formally described by its query set specification (QSS) which captures the complex query and reporting capabilities of the QFR and the associations of the query set specification with visual elements that implement these capabilities on a Web page. The design-time component of QURSED, called QURSED Editor, semi-automates the development of the query set specification and its association with visual elements by translating intuitive visual actions taken by a developer into appropriate specification fragments. The run-time component of QURSED produces XQuery statements by synthesizing fragments from the query set specification that have been activated during the interaction of the end-user with the QFR and renders \u2026",
            "Abstract entirety": 0,
            "Author pub id": "81cvn3sAAAAJ:iH-uZ7U-co4C",
            "Publisher": "ACM"
        },
        {
            "Title": "Supporting top-k keyword search in xml databases",
            "Publication year": 2010,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/5447818/",
            "Abstract": "Keyword search is considered to be an effective information discovery method for both structured and semi-structured data. In XML keyword search, query semantics is based on the concept of Lowest Common Ancestor (LCA). However, naive LCA-based semantics leads to exponential computation and result size. In the literature, LCA-based semantic variants (e.g., ELCA and SLCA) were proposed, which define a subset of all the LCAs as the results. While most existing work focuses on algorithmic efficiency, top-K processing for XML keyword search is an important issue that has received very little attention. Existing algorithms focusing on efficiency are designed to optimize the semantic pruning and are incapable of supporting top-K processing. On the other hand, straightforward applications of top-K techniques from other areas (e.g., relational databases) generate LCAs that may not be the results and \u2026",
            "Abstract entirety": 0,
            "Author pub id": "81cvn3sAAAAJ:qUcmZB5y_30C",
            "Publisher": "IEEE"
        },
        {
            "Title": "Graph data models, query languages and programming paradigms",
            "Publication year": 2018,
            "Publication url": "https://dl.acm.org/doi/abs/10.14778/3229863.3229879",
            "Abstract": "Numerous databases support semi-structured, schemaless and heterogeneous data, typically in the form of graphs (often restricted to trees and nested data). They also provide corresponding high-level query languages or graph-tailored programming paradigms.The evolving query languages present multiple variations: Some are superficial syntactic ones, while other ones are genuine differences in modeling, language capabilities and semantics. Incompatibility with SQL presents a learning challenge for graph databases, while table orientation often leads to cumbersome syntactic/semantic structures that are contrary to graph data. Furthermore, the query languages often fall short of full-fledged semistructured and graph query language capabilities, when compared to the yardsticks set by prior academic efforts.We survey features, the designers' options and differences in the approaches taken by current systems \u2026",
            "Abstract entirety": 0,
            "Author pub id": "81cvn3sAAAAJ:PoWvk5oyLR8C",
            "Publisher": "VLDB Endowment"
        },
        {
            "Title": "Big data techniques for public health: a case study",
            "Publication year": 2017,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/8010636/",
            "Abstract": "Public health researchers increasingly recognize that to advance their field they must grapple with the availability of increasingly large (i.e., thousands of variables) traditional population-level datasets (e.g., electronic medical records), while at the same time integrating additional large datasets (e.g., data on genomics, the microbiome, environmental exposures, socioeconomic factors, and health behaviors). Leveraging these multiple forms of data might well provide unique and unexpected discoveries about the determinants of health and wellbeing. However, we are in the very early stages of advancing the techniques required to understand and analyze big population-level data for public health research. To address this problem, this paper describes how we propose that big data can be efficiently used for public health discoveries. We show that data analytics techniques traditionally employed in public health \u2026",
            "Abstract entirety": 0,
            "Author pub id": "81cvn3sAAAAJ:lmc2jWPfTJgC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Building XML query forms and reports with XQForms",
            "Publication year": 2002,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S1389128602002189",
            "Abstract": "XQForms is the first generator of Web-based query forms and reports for XML data. XQForms takes inputs (i) an XML Schema that models the source data to be queried and presented, (ii) a declarative specification, called XQForm annotation, of the query forms and reports that will be generated, and (iii) a set of template presentation libraries. The output is a set of query form and report pages that provide automated query construction and report formatting so that the end users can query and browse the underlying XML data. XQForms separates content (given by the XML Schema of the source data), query form semantics (specified by the annotations) and presentation of the pages (provided by the template library). The system architecture is modular and consists of four main components: (a) a collection of query controls that generate query fragments based on the values that the end user submits via the query form \u2026",
            "Abstract entirety": 0,
            "Author pub id": "81cvn3sAAAAJ:maZDTaKrznsC",
            "Publisher": "Elsevier"
        },
        {
            "Title": "Web application development framework",
            "Publication year": 2015,
            "Publication url": "https://patents.google.com/patent/US9052908B2/en",
            "Abstract": "Techniques, systems, apparatus and computer-program products are disclosed for developing a web-hosted shared database system with improved user interface and reduced programming. In one aspect, using a web application development framework includes declaratively specifying a web application's pages using page configurations. The framework can automatically coordinate page state with the state of a database server and an applications server, so that the specified page is first rendered and then one or more portions of the page can be updated in response to a server data change, Also, programs that are executed when a request is issued are declaratively specified using program configurations. Either or both of the page configurations and the program configurations can be implemented by access to a unified application state virtual database. Further, the unified application state virtual database \u2026",
            "Abstract entirety": 0,
            "Author pub id": "81cvn3sAAAAJ:a0OBvERweLwC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Asterix: towards a scalable, semistructured data platform for evolving-world models",
            "Publication year": 2011,
            "Publication url": "https://link.springer.com/article/10.1007/s10619-011-7082-y",
            "Abstract": "ASTERIX is a new data-intensive storage and computing platform project spanning UC Irvine, UC Riverside, and UC San Diego. In this paper we provide an overview of the ASTERIX project, starting with its main goal\u2014the storage and analysis of data pertaining to evolving-world models. We describe the requirements and associated challenges, and explain how the project is addressing them. We provide a technical overview of ASTERIX, covering its architecture, its user model for data and queries, and its approach to scalable query processing and data management. ASTERIX utilizes a new scalable runtime computational platform called Hyracks that is also discussed at an overview level; we have recently made Hyracks available in open source for use by other interested parties. We also relate our work on ASTERIX to the current state of the art and describe the research challenges that we are currently \u2026",
            "Abstract entirety": 0,
            "Author pub id": "81cvn3sAAAAJ:RHpTSmoSYBkC",
            "Publisher": "Springer US"
        },
        {
            "Title": "Blended browsing and querying of xml in a lazy mediator system",
            "Publication year": 2000,
            "Publication url": "https://www.sdsc.edu/~ludaesch/Paper/edbt00-bbq-demo.ps.gz",
            "Abstract": "Research in semistructured data and XML has focused on query languages, data extraction, and mediator systems for integrating heterogeneous sources. However, the issue of user interfaces for browsing and querying semistructured data has largely been ignored despite the fact that it is of primary importance as XML becomes more widely used as a data exchange format and information model on the Web. To facilitate XML query construction and browsing of results by the non-expert user, the DTD-based graphical user interface BBQ (Blended Browsing and Querying) has been developed as a front end to XML sources. It is currently used as a front-end to the virtual sources exported by the MIX mediator system [MIX, LPV00]. A virtual source may be an actual XML source or an XML view constructed by the mediator.",
            "Abstract entirety": 1,
            "Author pub id": "81cvn3sAAAAJ:M3NEmzRMIkIC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Merging results from multi-parametric ranked queries",
            "Publication year": 2001,
            "Publication url": "http://www.cs.ucr.edu/~vagelis/publications/RankMerging.pdf",
            "Abstract": "Many Web sources rank objects according to multiple attributes. As the number of such sources increases, so does the number of meta-brokers, which provide integrated access to the sources. Metabrokers answer to user queries by accessing the sources and merging the source responses. We study the fundamental problem of how a metabroker can deliver a prefix of the user query result (ie, the top results of the user query) by accessing only a minimum prefix of the result of each source. The challenge is that the sources support different ranking functions from each other and from the ranking that the user query requests. We present an algorithm that inputs the query ranking function and the ranking functions of the sources and computes the minimum prefix required by each source in order to deliver a prefix of the query result. We consider ranking functions that are either linear functions of the object attributes or linear combinations of the attributes' logarithms or cosine functions. Our algorithm can be used in many applications, such as data streaming and multimedia, that need to efficiently merge ranked lists.",
            "Abstract entirety": 1,
            "Author pub id": "81cvn3sAAAAJ:fPk4N6BV_jEC",
            "Publisher": "Technical Report 174, UCSD"
        },
        {
            "Title": "Message from the ICDE 2010 PhD workshop general co-chairs",
            "Publication year": 2010,
            "Publication url": "https://scholar.google.com/scholar?cluster=9699486678752411334&hl=en&oi=scholarr",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "81cvn3sAAAAJ:0KyAp5RtaNEC",
            "Publisher": "United States"
        },
        {
            "Title": "Proceedings of the 2003 ACM SIGMOD International Conference on Management of Data",
            "Publication year": 2003,
            "Publication url": "https://scholar.google.com/scholar?cluster=4083131552642556506&hl=en&oi=scholarr",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "81cvn3sAAAAJ:tuHXwOkdijsC",
            "Publisher": "Association for Computing Machinery"
        },
        {
            "Title": "GQFast: Fast graph exploration with context-aware autocompletion",
            "Publication year": 2017,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/7930086/",
            "Abstract": "There is an increasing demand to explore similar entities in big graphs. For example, in domains like biomedical science, identifying similar entities may contribute to developing new drugs or discovering new diseases. In this paper, we demonstrate a graph exploration system, called GQFast, which provides a graphical interface to help users efficiently explore similar entities. Methodologically, GQFast first builds efficient indices combining column database optimizations and compression techniques, then it explores similar entities by using the indices. GQFast operates on the real-world Pubmed dataset consisting of over 23 million biomedical entities and 1.3 billion relationships. Relying on GQFast's high performance, GQFast provides (i) type-ahead-search to instantly visualize search results while a user is typing a query, and (ii) context-aware query completion to guide users typing queries.",
            "Abstract entirety": 1,
            "Author pub id": "81cvn3sAAAAJ:b1wdh0AR-JQC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Join-Based Algorithms for Keyword Search in XML Databases",
            "Publication year": 2009,
            "Publication url": "https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.189.5228&rep=rep1&type=pdf",
            "Abstract": "We consider the problem of keyword search in XML databases under the excluding lowest common ancestor (ELCA) semantics. Our analysis shows that ELCA semantics may lead to conflict with keyword proximity concept, and under such semantics, lower ELCAs are preferable because lower elements tend to be more specific. However, existing algorithms (stack-based and index-based) do not provide efficient support either for this the lower the better intuition or for general ranking functions, which is mainly due to the fact that generated results follow the document order. In this paper, we propose a join-based algorithm to compute complete ELCAs, which achieves complexity optimality for queries with various frequencies, as well as guarantees that lowest ELCAs are generated first. More importantly, we shed the new light on the connection between relational join and XML keyword search. Basically, many mature techniques in relational databases can be leveraged in this scenario to optimize query plan and improve execution efficiency. We further adopt the idea from top-K join in relational databases and propose a top-K algorithm for one type of ranking functions. Extensive experimental results demonstrate that the proposed algorithms outperform existing systems.",
            "Abstract entirety": 1,
            "Author pub id": "81cvn3sAAAAJ:zA6iFVUQeVQC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Algorithms and applications for answering ranked queries using ranked views",
            "Publication year": 2004,
            "Publication url": "https://link.springer.com/article/10.1007/s00778-003-0099-8",
            "Abstract": "Ranked queries return the top objects of a database according to a preference function. We present and evaluate (experimentally and theoretically) a core algorithm that answers ranked queries in an efficient pipelined manner using materialized ranked views. We use and extend the core algorithm in the described PREFER and MERGE systems. PREFER precomputes a set of materialized views that provide guaranteed query performance. We present an algorithm that selects a near optimal set of views under space constraints. We also describe multiple optimizations and implementation aspects of the downloadable version of PREFER. Then we discuss MERGE, which operates at a metabroker and answers ranked queries by retrieving a minimal number of objects from sources that offer ranked queries. A speculative version of the pipelining algorithm is described.",
            "Abstract entirety": 1,
            "Author pub id": "81cvn3sAAAAJ:YOwf2qJgpHMC",
            "Publisher": "Springer-Verlag"
        },
        {
            "Title": "Managed materialized views created from heterogeneous data sources",
            "Publication year": 2021,
            "Publication url": "https://patents.google.com/patent/US11113273B2/en",
            "Abstract": "Managed materialized views may be generated from across heterogeneous data sources. A request to create a materialized view may be received and performed by a materialized view management platform, which may obtain and generate the materialized view from different data sources and store the materialized view in a target system. Changes to the data sources may be obtained at the materialized view management platform and updates to the materialized view may be determined. The materialized view in the target system may be updated.",
            "Abstract entirety": 1,
            "Author pub id": "81cvn3sAAAAJ:4hFrxpcac9AC",
            "Publisher": "Unknown"
        },
        {
            "Title": "XML research midflight",
            "Publication year": 2008,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/1416691.1416693",
            "Abstract": "XML emerged 10 years ago as the flexible standard for information exchange and representation. The database research community had presciently already produced related works on semi-structured data models and proceeded to generate multiple research contributions in the field, influencing along the way standards and industrial products. Since then much of the XML future has arrived: complex standards (notably XQuery) emerged, first industrial systems have been released. Naturally XML research changes gears. We will discuss successes, failures, open issues and provide thoughts on what is needed to make XML research even more effective.",
            "Abstract entirety": 1,
            "Author pub id": "81cvn3sAAAAJ:_xSYboBqXhAC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Rewriting nested XML queries using nested views",
            "Publication year": 2006,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/1142473.1142524",
            "Abstract": "We present and analyze an algorithm for equivalent rewriting of XQuery queries using XQuery views, which is complete for a large class of XQueries featuring nested FLWR blocks, XML construction and join equalities by value and identity. These features pose significant challenges which lead to fundamental extension of prior work on the problems of rewriting conjunctive and tree pattern queries. Our solution exploits the Nested XML Tableaux (NEXT) notation which enables a logical foundation for specifying XQuery semantics. We present a tool which inputs XQuery queries and views and outputs an XQuery rewriting, thus being usable on top of any of the existing XQuery processing engines. Our experimental evaluation shows that the tool scales well for large numbers of views and complex queries.",
            "Abstract entirety": 1,
            "Author pub id": "81cvn3sAAAAJ:mVmsd5A6BfQC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Trading with plans and patterns in XQuery optimization",
            "Publication year": 2006,
            "Publication url": "https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.569.5632&rep=rep1&type=pdf",
            "Abstract": "The query optimizer is a central component of a database management system that attempts to determine the most efficient way to execute a query. During the optimization phase the query optimizer builds execution plans-(functional) programs that are interpreted by the evaluation engine to produce the query result. The optimizer decides then which of the possible query plans will be the most efficient in terms in terms of CPU requirements and the number of I/O operations.A simplified view of the optimization process for XML queries is depicted in Figure 1. To process a query expressed in some query language, first, data access plans are built by examining all the possible access paths (eg index scan, sequential scan) of the existing storage modules, views and indices. Then, these plans are combined with the help of algebraic operators (such as selections, joins...) into increasingly larger plans, aiming towards building plans for the complete query (at this step several join orderings and equivalent algebraic alternatives are considered thus further increasing the total number of query evaluation plans that are explored). In the final phase of the optimization process the best plan that is equivalent to the original query is picked for execution.",
            "Abstract entirety": 1,
            "Author pub id": "81cvn3sAAAAJ:70eg2SAEIzsC",
            "Publisher": "Tech. report, available at www-rocq. inria. fr/arion"
        },
        {
            "Title": "Application design and data flow analysis",
            "Publication year": 2014,
            "Publication url": "https://patents.google.com/patent/US8898623B2/en",
            "Abstract": "Techniques, apparatuses, and systems for application design and application data flow analysis. Techniques, apparatuses, and systems can include providing a design interface to create an application with different user groups and access rights, the design interface operable to specify an action to include to a page of the application, where the action, when invoked, modifies the application state; receiving an action specification that describes an access rights modification that results from an invocation of the action during an execution of the application, where the access rights modification indicates an enabling or disabling of one or more access rights of a user; and generating application specification queries and commands to enforce access rights based on the access rights modification.",
            "Abstract entirety": 1,
            "Author pub id": "81cvn3sAAAAJ:dfsIfKJdRG4C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Report on the first\" XQuery Implementation, Experience and Perspectives\" workshop (XIME-P)",
            "Publication year": 2004,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/1041410.1041434",
            "Abstract": "The XQuery Implementation, Experience and Perspectives (XIME-P) workshop was organized by Ioana Manolescu and Yannis Papakonstantinou in cooperation with the ACM SIGMOD Conference, and was held in Maison de la Chimie, in Paris, France, on June 17 and 18, 2004. This report summarizes the goals and topics of the workshop, presents the major workshop highlights and the main issues discussed during the workshop.",
            "Abstract entirety": 1,
            "Author pub id": "81cvn3sAAAAJ:rO6llkc54NcC",
            "Publisher": "ACM"
        },
        {
            "Title": "Incremental and approximate inference for faster occlusion-based deep cnn explanations",
            "Publication year": 2019,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/3299869.3319874",
            "Abstract": "Deep Convolutional Neural Networks (CNNs) now match human accuracy in many image prediction tasks, resulting in a growing adoption in e-commerce, radiology, and other domains. Naturally, explaining CNN predictions is a key concern for many users. Since the internal workings of CNNs are unintuitive for most users, occlusion-based explanations (OBE) are popular for understanding which parts of an image matter most for a prediction. One occludes a region of the image using a patch and moves it around to produce a heat map of changes to the prediction probability. Alas, this approach is computationally expensive due to the large number of re-inference requests produced, which wastes time and raises resource costs. We tackle this issue by casting the OBE task as a new instance of the classical incremental view maintenance problem. We create a novel and comprehensive algebraic framework for \u2026",
            "Abstract entirety": 0,
            "Author pub id": "81cvn3sAAAAJ:Ri6SYOTghG4C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Semistructured Models, Queries and Algebras in the Big Data Era: Tutorial Summary",
            "Publication year": 2016,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/2882903.2912573",
            "Abstract": "Numerous databases promoted as SQL-on-Hadoop, NewSQL and NoSQL support semi-structured, schemaless and heterogeneous data, typically in the form of enriched JSON. They also provide corresponding query languages. In addition to these genuine JSON databases, relational databases also provide special functions and language features for the support of JSON columns, typically piggybacking on non-1NF (non first normal form) features that SQL acquired over the years. We refer to SQL databases with JSON support as SQL/JSON databases.",
            "Abstract entirety": 1,
            "Author pub id": "81cvn3sAAAAJ:zLWjf1WUPmwC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Bes, A., see Wijsen, J. 165\u2013192",
            "Publication year": 2003,
            "Publication url": "https://scholar.google.com/scholar?cluster=4422174317588632373&hl=en&oi=scholarr",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "81cvn3sAAAAJ:JoZmwDi-zQgC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Delphi: Data e-platform for personalized population health",
            "Publication year": 2013,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/6720650/",
            "Abstract": "Recent studies recognize that health is influenced broadly by a multitude of factors of different types, including medical, genetic, environmental, social and behavioral factors. Developing successful health interventions therefore requires taking into account all these factors as well as the interactions between them. However, intervention designers have traditionally had access only to a very limited subset of health data (typically medical record data). Other health data, such as environmental or physical activity data, although already collected and stored, have been very difficult to access, since they are maintained by different providers and isolated in their own proprietary silos. This prevents physicians and intervention designers from acquiring a true overview of all factors influencing a condition and acting towards its prevention or cure. To solve this problem, we propose DELPHI: a platform allowing the integration of \u2026",
            "Abstract entirety": 0,
            "Author pub id": "81cvn3sAAAAJ:1yQoGdGgb4wC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Journal queries of a ledger-based database",
            "Publication year": 2021,
            "Publication url": "https://patents.google.com/patent/US10942910B1/en",
            "Abstract": "A database management system stores data for a table as a journal of transaction. The records of the journal comprise information indicative of changes applied to a document of the table. The database receives a query on a table of transactions performed on the table. In response to the query on the table of transactions, the database generates results by retrieving and projecting the records of the journal in accordance with the query. The results of the query are indicative of changes applied to the document of the table.",
            "Abstract entirety": 1,
            "Author pub id": "81cvn3sAAAAJ:HtEfBTGE9r8C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Determining source contribution in integration systems",
            "Publication year": 2005,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/1065167.1065205",
            "Abstract": "Owners of sources registered in an information integration system, which provides answers to a (potentially evolving) set of client queries, need to know their contribution to the query results. We study the problem of deciding, given a client query Q and a source registration R, whether R is (i)\" self-sufficient\"(can contribute to the result of Q even if it is the only source in the system) or (ii)\" now complementary\"(can contribute, but only in cooperation with other specific existing sources), or (iii)\" later complementary\"(can contribute if in the future appropriate new sources join the system). We consider open-world integration systems in which registrations are expressed using source-to-target constraints, and queries are answered under\" certain answer\" semantics.",
            "Abstract entirety": 1,
            "Author pub id": "81cvn3sAAAAJ:bEWYMUwI8FkC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Ajax-based report pages as incrementally rendered views",
            "Publication year": 2010,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/1807167.1807229",
            "Abstract": "While Ajax-based programming enables faster performance and higher interface quality over pure server-side programming, it is demanding and error prone as each action that partially updates the page requires custom, ad-hoc code. The problem is exacerbated by distributed programming between the browser and server, where the developer uses JavaScript to access the page state and Java/SQL for the database. The FORWARD framework simplifies the development of Ajax pages by treating them as rendered views, where the developer declares a view using an extension of SQL and page units, which map to the view and render the data in the browser. Such a declarative approach leads to significantly less code, as the framework automatically solves performance optimization problems that the developer would otherwise hand-code. Since pages are fueled by views, FORWARD leverages years of database \u2026",
            "Abstract entirety": 0,
            "Author pub id": "81cvn3sAAAAJ:JV2RwH3_ST0C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Improving ssd lifetime with byte-addressable metadata",
            "Publication year": 2017,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/3132402.3132420",
            "Abstract": "Existing solid state drives (SSDs) provide flash-based out-of-band (OOB) data that can only be updated on a page write. Consequently, the metadata stored in their OOB region lack flexibility due to the idiosyncrasies of flash memory, incurring unnecessary flash write operations detrimental to device lifetime.",
            "Abstract entirety": 1,
            "Author pub id": "81cvn3sAAAAJ:LI9QrySNdTsC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Utilizing ids to accelerate incremental view maintenance",
            "Publication year": 2015,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/2723372.2750546",
            "Abstract": "Prior Incremental View Maintenance (IVM) algorithms specify the view tuples that need to be modified by computing diff sets, which we call tuple-based diffs since a diff set contains one diff tuple for each to-be-modified view tuple. idIVM assumes the base tables have keys and performs IVM by computing ID-based diff sets that compactly identify the to-be-modified tuples through their IDs.",
            "Abstract entirety": 1,
            "Author pub id": "81cvn3sAAAAJ:dQ2og3OwTAUC",
            "Publisher": "Unknown"
        },
        {
            "Title": "DTD inference for views of XML data",
            "Publication year": 2000,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/335168.335173",
            "Abstract": "We study the inference of Data Type Definitions (DTDs) for views of XML data, using an abstraction that focuses on document content structure. The views are defined by a query language that produces a list of documents selected from one or more input sources. The selection conditions involve vertical and horizontal navigation, thus querying explicitly the order present in input documents. We point several strong limitations in the descriptive ability of current DTDs and the need for extending them with (i) a subtyping mechanism and (ii) a more powerful specification mechanism than regular languages, such as context-free languages. With these extensions, we show that one can always infer tight DTDs, that precisely characterize a selection view on sources satisfying given DTDs. We also show important special cases where one can infer a tight DTD without requiring extension (ii). Finally we consider related \u2026",
            "Abstract entirety": 0,
            "Author pub id": "81cvn3sAAAAJ:ufrVoPGSRksC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Blending browsing and querying of XML in a lazy mediator system",
            "Publication year": 2000,
            "Publication url": "https://scholar.google.com/scholar?cluster=12776620725128279461&hl=en&oi=scholarr",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "81cvn3sAAAAJ:k_IJM867U9cC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Web-page-based system for designing database driven web applications",
            "Publication year": 2011,
            "Publication url": "https://patents.google.com/patent/US7971148B2/en",
            "Abstract": "In a web-page-based system for designing database driven web applications, a page is initiated containing one or more top level iterators. A user introduces fields to the page from a palette including: input, display, hyperlink, iterator. In one case, the user creates iterators nested in a user-selected iterator, and retaining context of the selected iterator, where the system accommodates iterators that are recursive. In an alternative embodiment, the user adds both display and entry fields pertaining to a given user-selected iterator, retaining context of the selected iterator. Responsive to user introduced fields, the system automatically creates representative data structures in a database and automatically relates fields of the pages to the data structures in accordance with a predetermined logic.",
            "Abstract entirety": 1,
            "Author pub id": "81cvn3sAAAAJ:4OULZ7Gr8RgC",
            "Publisher": "Unknown"
        },
        {
            "Title": "View-based data integration",
            "Publication year": 2009,
            "Publication url": "http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.224.3076",
            "Abstract": "Data Integration (or Information Integration) is the problem of finding and combining data from different sources. Viewbased Data Integration is a framework that solves the data integration problem for structured data by integrating sources into a single unified view. This integration is facilitated by a declarative mapping language that allows the specification of how each source relates to the unified view. Depending on the type of view specification language used, view-based data",
            "Abstract entirety": 1,
            "Author pub id": "81cvn3sAAAAJ:eq2jaN3J8jMC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Technical Perspective: Supporting Linear Algebra Operations in SQL",
            "Publication year": 2018,
            "Publication url": "https://dl.acm.org/doi/pdf/10.1145/3277006.3277012",
            "Abstract": "Linear algebra operations are at the core of Machine Learning. Multiple specialized systems have emerged for the scalable, distributed execution of matrix and vector operations. The relationship of such computations to data management and databases however brings frictions. It is well known that a great deal of human time and machine time is being spent nowadays on fetching data out of the database and performing a computation on a specialized system. One answer to the issue is that we truly need a new kind of non-SQL database that is tuned to these computations. The creators of SimSQL opted for the decidedly incremental approach. Can we make a very small set of changes to the relational model and RDBMS software to render them suitable for executing linear algebra in the database?We have come across the\" brand new system\" versus\" incremental to relational\" question many times in the database \u2026",
            "Abstract entirety": 0,
            "Author pub id": "81cvn3sAAAAJ:Dip1O2bNi0gC",
            "Publisher": "ACM"
        },
        {
            "Title": "A system for keyword proximity search on XML databases",
            "Publication year": 2003,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/B9780127224428501075",
            "Abstract": "This chapter discusses keyword proximity search on XML database. Keyword proximity search is a user-friendly information discovery technique that has been extensively studied for text documents. In extending this technique to structured databases, recent works provide keyword proximity search on labeled graphs. A keyword proximity search does not require the user to know the structure of the graph, the role of the objects containing the keywords, or the type of the connections between the objects. The user simply submits a list of keywords and the system returns the sub-graphs that connect the objects containing the keywords. XML and its labeled graph/tree abstractions are becoming the data model of choice for representing semistructured, self-describing data, and keyword proximity search is well-suited to XML documents as well.",
            "Abstract entirety": 1,
            "Author pub id": "81cvn3sAAAAJ:ZeXyd9-uunAC",
            "Publisher": "Morgan Kaufmann"
        },
        {
            "Title": "A Transducer-Based XML Query Processor",
            "Publication year": 2002,
            "Publication url": "https://books.google.com/books?hl=en&lr=&id=CDENPiGOQSAC&oi=fnd&pg=PA227&dq=info:YgZnemA45nEJ:scholar.google.com&ots=3l4f9O8TD9&sig=YCTw7Cns6fSKJzU0KV5KBcLPDC0",
            "Abstract": "The XML Stream Machine (XSM) system is a novel XQuery processing paradigm that is tuned to the efficient processing of sequentially accessed XML data (streams). The system compiles a given XQuery into an XSM, which is an XML stream transducer, ie, an abstract device that takes as input one or more XML data streams and produces one or more output streams, potentially using internal buffers. We present a systematic way to translate XQueries into efficient XSMs: First the XQuery is translated into a network of XSMs that correspond to the basic operators of the XQuery language and exchange streams. The network is reduced to a single XSM by repeated application of an XSM com-position operation that is optimized to reduce the number of tests and actions that the XSM performs as well as the number of intermediate buffers that it uses. Finally, the optimized XSM is compiled into a C program. First empirical results illustrate the performance benefits of the XSM-based processor.",
            "Abstract entirety": 1,
            "Author pub id": "81cvn3sAAAAJ:tkaPQYYpVKoC",
            "Publisher": "Elsevier"
        },
        {
            "Title": "SSD in-storage computing for list intersection",
            "Publication year": 2016,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/2933349.2933353",
            "Abstract": "Recently, there has been a renewed interest of in-storage computing in the context of solid state drives (SSDs), called\" Smart SSDs.\" Smart SSDs allow application-specific code to execute inside SSDs. This allows applications to take advantage of the high internal bandwidth that Smart SSDs provide. This work studies the offloading of list intersection into Smart SSDs, because intersection is prominent in both search engines and analytics queries. Furthermore, intersection is interesting because the algorithms are more complex than plain scans; they are affected by multiple parameters, as we show, and provide lessons that can be used in other operations also.",
            "Abstract entirety": 1,
            "Author pub id": "81cvn3sAAAAJ:yB1At4FlUx8C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Incremental validation of XML documents",
            "Publication year": 2004,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/1042046.1042050",
            "Abstract": "We investigate the incremental validation of XML documents with respect to DTDs, specialized DTDs, and XML Schemas, under updates consisting of element tag renamings, insertions, and deletions. DTDs are modeled as extended context-free grammars. \"Specialized DTDs\" allow the decoupling of element types from element tags. XML Schemas are abstracted as specialized DTDs with limitations on the type assignment. For DTDs and XML Schemas, we exhibit an O(m log n) incremental validation algorithm using an auxiliary structure of size O(n), where n is the size of the document and m the number of updates. The algorithm does not handle the incremental validation of XML Schema wrt renaming of internal nodes, which is handled by the specialized DTDs incremental validation algorithm. For specialized DTDs, we provide an O(m log2 n) incremental algorithm, again using an auxiliary structure of size O(n \u2026",
            "Abstract entirety": 0,
            "Author pub id": "81cvn3sAAAAJ:kNdYIx-mwKoC",
            "Publisher": "ACM"
        },
        {
            "Title": "Efficient LCA based keyword search in XML data",
            "Publication year": 2008,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/1353343.1353408",
            "Abstract": "Keyword search in XML documents based on the notion of lowest common ancestors (LCAs) and modifications of it has recently gained research interest [10, 14, 22]. In this paper we propose an efficient algorithm called Indexed Stack to find answers to keyword queries based on XRank's semantics to LCA [10]. The complexity of the Indexed Stack algorithm is O (kd| S 1| log| S|) where k is the number of keywords in the query, d is the depth of the tree and| S 1|(| S|) is the occurrence of the least (most) frequent keyword in the query. In comparison, the best worst case complexity of the core algorithms in [10] is O (kd| S|). We analytically and experimentally evaluate the Indexed Stack algorithm and the two core algorithms in [10]. The results show that the Indexed Stack algorithm outperforms in terms of both CPU and I/O costs other algorithms by orders of magnitude when the query contains at least one low frequency \u2026",
            "Abstract entirety": 0,
            "Author pub id": "81cvn3sAAAAJ:MXK_kJrjxJIC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Structured materialized views for XML queries",
            "Publication year": 2007,
            "Publication url": "https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.79.8571&rep=rep1&type=pdf",
            "Abstract": "The performance of XML database queries can be greatly enhanced by rewriting them using materialized views. We study the problem of rewriting a query using materialized views, where both the query and the views are described by a tree pattern language, appropriately extended to capture a large XQuery subset. The pattern language features optional nodes and nesting, allowing to capture the data needs of nested XQueries. The language also allows describing storage features such as structural identifiers, which enlarge the space of rewritings. We study pattern containment and equivalent rewriting under the constraints expressed in a structural summary, whose enhanced form also entails integrity constraints. Our approach is implemented in the ULoad [7] prototype and we present a performance analysis.",
            "Abstract entirety": 1,
            "Author pub id": "81cvn3sAAAAJ:M3ejUd6NZC8C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Indexes on non-materialized views",
            "Publication year": 2021,
            "Publication url": "https://patents.google.com/patent/US11036708B2/en",
            "Abstract": "A database management system receives a request to create an index for a virtual view of a database table. In response to the request, the database management system identifies relationships between the columns of the virtual view and columns of the database table. The database management system generates an index on the database table, where columns are included in the generated index based on the identified relationships and the definition of the virtual view. Queries of the virtual view are assisted by the generated index of the underlying table.",
            "Abstract entirety": 1,
            "Author pub id": "81cvn3sAAAAJ:anf4URPfarAC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Objectrank: a system for authority-based search on databases",
            "Publication year": 2006,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/1142473.1142593",
            "Abstract": "We present ObjectRank demo system that performs authority-based keyword search on bibliographic databases. We also provide Inverse ObjectRank as a keyword-specific specificity metric and other calibration parameters such as Global ObjectRank. Users can specify various combinations of calibration values to control the behavior of the demo. Finally, we propose a methodology that enables us to extend query results using the ontology graph.",
            "Abstract entirety": 1,
            "Author pub id": "81cvn3sAAAAJ:IWHjjKOFINEC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Algebra-based extraction of tree patterns in XQuery",
            "Publication year": 2006,
            "Publication url": "https://hal.inria.fr/inria-00001147/",
            "Abstract": "Query processing performance in XML databases can be greatly enhanced by the usage of materialized views whose content has been stored in the database. This requires a method for identifying query subexpressions matching the views, a process known as view-based query rewriting. This process is quite complex for relational databases, and all the more daunting on XML databases. Current XML materialized view proposals are based on tree patterns, since query navigation is conceptually close to such patterns. However, the existing algorithms for extracting tree patterns from XQuery do not detect patterns {\\em across nested query blocks}. Thus, complex, useful tree pattern views may be missed by the rewriting algorithm. We present a novel tree pattern extraction algorithm from XQuery queries, able to identify larger patterns than previous methods. Our algorithm has been implemented in the ULoad XML database prototype. We study its performance, and the overall benefits of our tree pattern identification approch.",
            "Abstract entirety": 1,
            "Author pub id": "81cvn3sAAAAJ:fQNAKQ3IYiAC",
            "Publisher": "Unknown"
        },
        {
            "Title": "I2T: an information integration testbed for digital government",
            "Publication year": 2004,
            "Publication url": "https://www.researchgate.net/profile/Chaitan-Baru/publication/220268020_I2T_Information_Integration_Testbed_for_Digital_Government/links/53f9eb640cf20a45496ab2a5/I2T-Information-Integration-Testbed-for-Digital-Government.pdf",
            "Abstract": "The broad goal of the I2T project was to develop XML-based data mediation technology for integrating geospatial and statistical data, which is of great interest to a number of statistical and other government agencies. The research participants included the San Diego Supercomputer Center and Computer Science Department at the University of California, San Diego, and the Inter-University Consortium for Political and Social Science Research (ICPSR) at the University of Michigan. The initial agencies that were identified as potential beneficiaries of this research included the Bureau of Labor Statistics (BLS) and Census Bureau. The role of agencies was identified as providing not only the application drivers but also advice and feedback. Interactions with agencies were primarily via meetings held at in Washington or at San Diego Supercomputer Center. During the course of this project, there were also interactions and collaborations with other NSF Digital Government projects such as the Iowa State project on field data collection (Sara Nusser, PI) and data integration and the University of Maine project on spatial metadata (Peggy Agouris, PI). Indeed, these collaborations also eventually led to a funded joint NSF ITR project on geospatial data grids (GeoGrid), involving SDSC, Iowa State and Maine.The research goals of this project were to develop wrapper/mediator-based systems for Web-based integration of distributed databases, and to develop innovative query interfaces for statistical and GIS data integration. Some of the outcomes of this research include development of XML-based query language and query processing techniques \u2026",
            "Abstract entirety": 0,
            "Author pub id": "81cvn3sAAAAJ:M05iB0D1s5AC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Forward: Data-centric UIs using declarative templates that efficiently wrap third-party JavaScript components",
            "Publication year": 2014,
            "Publication url": "https://dl.acm.org/doi/abs/10.14778/2733004.2733052",
            "Abstract": "While Ajax programming and the plethora of JavaScript component libraries enable high-quality Uls in web applications, integrating them with page data is laborious and error-prone as a developer has to handcode incremental modifications with trigger-based programming and manual coordination of data dependencies. The FORWARD web framework simplifies the development of Ajax applications through declarative, state-based templates. This declarative, data-centric approach is characterized by the principle of logical/physical independence, which the database community has often deployed successfully. It enables FORWARD to leverage database techniques, such as incremental view maintenance, updatable views, capability-based component wrappers and cost-based optimization to automate efficient live visualizations. We demonstrate an end-to-end system implementation, including a web-based IDE \u2026",
            "Abstract entirety": 0,
            "Author pub id": "81cvn3sAAAAJ:kzcrU_BdoSEC",
            "Publisher": "VLDB Endowment"
        },
        {
            "Title": "Fast in-memory SQL analytics on relationships between entities",
            "Publication year": 2016,
            "Publication url": "https://scholar.google.com/scholar?cluster=625217416762142567&hl=en&oi=scholarr",
            "Abstract": "In this paper, we study relationship queries on graph databases with binary relationship. A relationship query is a graph reachability query bounded on primary-keys and foreign-keys with aggregation on single output attribute. Both row stores and column stores miss key opportunities towards the efficient execution of relationship queries, making them unacceptably slow in real-world OLAP scenarios.We present the FastR in-memory analytics engine that utilizes a new form of bottom-up fully pipelined query processing execution strategy. The plans run on a novel data organization that combines salient features of column-based organization, indexing and compression. Furthermore, FastR compiles its query plans into query-aware executable C++ source codes. Besides achieving runtime efficiency, FastR also reduces main memory requirements because, unlike column databases, FastR selectively allows more dense forms of compression including heavy-weighted compressions, which do not support random access. In our experiments, we used FastR to accelerate queries for two OLAP dashboards in the biomedical field. The first dashboard runs queries on the PubMed dataset and the second one on the SemMedDB dataset. FastR outperforms Postgres by 2-4 orders of magnitude and MonetDB by 1-3 orders of magnitude, when all of them are running on RAM. Our experiments dissect the FastR advantage between (i) the novel FastR execution strategy and associated data structures and (ii) the use of compiled code. We also provide an analysis and experiments illustrating space savings due to appropriate use of compression methods. Finally \u2026",
            "Abstract entirety": 0,
            "Author pub id": "81cvn3sAAAAJ:VLnqNzywnoUC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Integrated Querying of SQL database data and S3 data in Amazon Redshift.",
            "Publication year": 2018,
            "Publication url": "http://sites.computer.org/debull/A18june/A18JUN-CD.pdf#page=84",
            "Abstract": "Amazon Redshift features integrated, in-place access to data residing in a relational database and to data residing in the Amazon S3 object storage. In this paper we discuss associated query planning and processing aspects. Redshift plays the role of the integration query processor, in addition to the usual processor of queries over Redshift tables. In particular, during query execution, every compute node of a Redshift cluster issues (sub) queries over S3 objects, employing a novel multi-tenant (sub) query execution layer, called Amazon Redshift Spectrum, and merges/joins the results in an streaming and parallel fashion. The Spectrum layer offers massive scalability, with independent scaling of storage and computation. Redshifts optimizer determines how to minimize the amount of data scanned by Spectrum, the amount of data communicated to Redshift and the number of Spectrum nodes to be used. In particular \u2026",
            "Abstract entirety": 0,
            "Author pub id": "81cvn3sAAAAJ:i2xiXl-TujoC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Discover: Keyword search in relational databases",
            "Publication year": 2002,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/B9781558608696500652",
            "Abstract": "DISCOVER operates on relational databases and facilitates information discovery on them by allowing its user to issue keyword queries without any knowledge of the database schema or of SQL. DISCOVER returns qualified joining networks of tuples, that is, sets of tuples that are associated because they join on their primary and foreign keys and collectively contain all the keywords of the query. DISCOVER proceeds in two steps. First, the Candidate Network Generator generates all candidate networks of relations, that is, join expressions that generate the joining networks of tuples. Second, the Plan Generator builds plans for the efficient evaluation of the set of candidate networks, exploiting the opportunities to reuse common sub expressions of the candidate networks. Keyword search is the most popular information discovery method because the user does not need to know either a query \u2026",
            "Abstract entirety": 0,
            "Author pub id": "81cvn3sAAAAJ:9yKSN-GCB0IC",
            "Publisher": "Morgan Kaufmann"
        },
        {
            "Title": "Optimal access to database and web application data by distributed query processing",
            "Publication year": 2013,
            "Publication url": "https://www.researchgate.net/profile/Michalis-Petropoulos-2/publication/267386340_Optimal_access_to_database_and_web_application_data_by_distributed_query_processing/links/54b6952e0cf2bd04be32235b/Optimal-access-to-database-and-web-application-data-by-distributed-query-processing.pdf",
            "Abstract": "Web applications require simple, integrated access to persistent data from SQL databases, data obtained from services and transient web application data stored in the page, session or request. The FORWARD system leverages the database field\u2019s extensive knowledge on distributed query processing, OQL optimization and semistructured query optimization and extends it to enable efficient integrated access to a unified virtual database that includes both persistent and transient data. Furthermore, FORWARD enables web application pages as rendered views over the unified application state. The paper studies the resulting distributed query processing problem, which enables FORWARD to automatically optimize data access. It extends prior query processing work in order to tune distributed query processing to the problem of persistent/transient data access. It introduces (i) novel query plan operators that are tuned to integrating relatively small transient data with large persistent data and accommodate the page\u2019s nesting and variability, and (ii) a novel query planning algorithm that minimizes the number of queries issued to relational databases when it is beneficial to do so. We compare against popular data access frameworks involving Object-Relational-Mappers. We provide experiments showing that FORWARD avoids their inefficiencies. We also compare against recent extensions thereof.",
            "Abstract entirety": 1,
            "Author pub id": "81cvn3sAAAAJ:u9iWguZQMMsC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Incremental and Approximate Computations for Accelerating Deep CNN Inference",
            "Publication year": 2020,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/3397461",
            "Abstract": "Deep learning now offers state-of-the-art accuracy for many prediction tasks. A form of deep learning called deep convolutional neural networks (CNNs) are especially popular on image, video, and time series data. Due to its high computational cost, CNN inference is often a bottleneck in analytics tasks on such data. Thus, a lot of work in the computer architecture, systems, and compilers communities study how to make CNN inference faster. In this work, we show that by elevating the abstraction level and re-imagining CNN inference as queries, we can bring to bear database-style query optimization techniques to improve CNN inference efficiency. We focus on tasks that perform CNN inference repeatedly on inputs that are only slightly different. We identify two popular CNN tasks with this behavior: occlusion-based explanations (OBE) and object recognition in videos (ORV). OBE is a popular method for \u201cexplaining \u2026",
            "Abstract entirety": 0,
            "Author pub id": "81cvn3sAAAAJ:_FM0Bhl9EiAC",
            "Publisher": "ACM"
        },
        {
            "Title": "XQuery midflight: Emerging database-oriented paradigms and a classification of research advances",
            "Publication year": 2005,
            "Publication url": "https://pdfs.semanticscholar.org/eee3/58a16ac930322f87dd4347750d14522fc377.pdf",
            "Abstract": "XQuery midflight: Emerging Database-Oriented Paradigms and a Classification of Research \nAdvances Page 1 1 XQuery midflight: Emerging Database-Oriented Paradigms and a \nClassification of Research Advances Ioana Manolescu INRIA, France Yannis \nPapakonstantinou UCSD, USA April 5, 2005 Page 2 2 Outline Tuple-based evaluation of \nXQuery XQDMA: an abstraction of the XQuery data model Unified tuple-based algebra \nRelated work Page 3 3 Tuple-based Evaluation of XQuery Page 4 4 Database Research \nMeets XQuery Processing Database research has succeeded on querying large data \nvolumes Tuple-based algebras have been key ingredient Relational, OQL Algebraic cost-based \noptimization Set-at-a-time query processing primitives (eg join) Several tuple-based \nalgebras for XQuery similar, yet different PRIMARY GOAL: Formal definition of a unifying \ntuple-based algebra for processing XQuery in 5 (\u2026",
            "Abstract entirety": 0,
            "Author pub id": "81cvn3sAAAAJ:YFjsv_pBGBYC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Inconsistency resolution in online databases",
            "Publication year": 2010,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/5447743/",
            "Abstract": "Shared online databases allow community members to collaboratively maintain knowledge. Collaborative editing though inevitably leads to inconsistencies as different members enter erroneous data or conflicting opinions. Ideally community members should be able to see and resolve these inconsistencies in a collaborative fashion. However most current online databases do not support inconsistency resolution. Instead they try to by-pass the problem by either ignoring inconsistencies and treating data as if they were not conflicting or by requiring inconsistencies to be resolved outside the system. To address this limitation, we propose Ricolla; an online database system that, by treating inconsistencies as first-class citizens, supports a natural workflow for the management of conflicting data. The system captures inconsistencies (so that community members can easily inspect them) and remains fully functional in \u2026",
            "Abstract entirety": 0,
            "Author pub id": "81cvn3sAAAAJ:f2IySw72cVMC",
            "Publisher": "IEEE"
        },
        {
            "Title": "The SQL-based all-declarative FORWARD web application development framework.",
            "Publication year": 2011,
            "Publication url": "http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.224.3196&rep=rep1&type=pdf",
            "Abstract": "The vast majority of database-driven web applications perform, at a logical level, fundamentally simple INSERT/UPDATE/DELETE commands. In response to a user action on the browser, the web application executes a program that transitions the old state to a new state. The state is primarily persistent and often captured in a single database. Additional state, which is transient, is maintained in the session (eg, the identity of the currently logged-in user, her shopping cart, etc.) and the pages. The programs perform a series of simple SQL queries and updates, and decide the next step using simple if-then-else conditions over the state. The changes made on the transient state, though technically not expressed in SQL, are also computationally as simple as basic SQL updates. Despite their fundamental simplicity, creating web applications takes a disproportionate amount of time, which is expended in mundane data integration and coordination across the three layers of the application:(a) the visual layer on the browser,(b) the application logic layer on the server, and (c) the data layer in the database. Challenge 1: Language heterogeneities. Each layer uses different and heterogeneous languages. The visual layer is coded in HTML/JavaScript; the application logic layer utilizes Java (or some other language, such as PHP); and the data layer utilizes SQL. Even for pure server-side/pure HTML-based applications, the heterogeneities cause impedance mismatch between the layers. They are resolved by mundane code that translates the SQL data into Java objects and then into HTML. When the front end issues a\u2217 Supported by NSF awards IIS \u2026",
            "Abstract entirety": 0,
            "Author pub id": "81cvn3sAAAAJ:HoB7MX3m0LUC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Efficient approximate query answering over sensor data with deterministic error guarantees",
            "Publication year": 2017,
            "Publication url": "https://arxiv.org/abs/1707.01414",
            "Abstract": "With the recent proliferation of sensor data, there is an increasing need for the efficient evaluation of analytical queries over multiple sensor datasets. The magnitude of such datasets makes exact query answering infeasible, leading researchers into the development of approximate query answering approaches. However, existing approximate query answering algorithms are not suited for the efficient processing of queries over sensor data, as they exhibit at least one of the following shortcomings: (a) They do not provide deterministic error guarantees, resorting to weaker probabilistic error guarantees that are in many cases not acceptable, (b) they allow queries only over a single dataset, thus not supporting the multitude of queries over multiple datasets that appear in practice, such as correlation or cross-correlation and (c) they support relational data in general and thus miss speedup opportunities created by the special nature of sensor data, which are not random but follow a typically smooth underlying phenomenon. To address these problems, we propose PlatoDB; a system that exploits the nature of sensor data to compress them and provide efficient processing of queries over multiple sensor datasets, while providing deterministic error guarantees. PlatoDB achieves the above through a novel architecture that (a) at data import time pre-processes each dataset, creating for it an intermediate hierarchical data structure that provides a hierarchy of summarizations of the dataset together with appropriate error measures and (b) at query processing time leverages the pre-computed data structures to compute an approximate answer and \u2026",
            "Abstract entirety": 0,
            "Author pub id": "81cvn3sAAAAJ:MLfJN-KU85MC",
            "Publisher": "Unknown"
        },
        {
            "Title": "XML tuple algebra",
            "Publication year": 2009,
            "Publication url": "https://hal.inria.fr/inria-00431395/",
            "Abstract": "XML data management requires an algebraic approach. In this work, we describe a unified algebraic approach for modeling computations described by XML queries expressed in an specific, expressive XQuery subset.",
            "Abstract entirety": 1,
            "Author pub id": "81cvn3sAAAAJ:GnPB-g6toBAC",
            "Publisher": "Springer"
        },
        {
            "Title": "Created computed universe",
            "Publication year": 2015,
            "Publication url": "https://dl.acm.org/doi/pdf/10.1145/2667217",
            "Abstract": "Computing crosses cosmology and makes the case for agnosticism.",
            "Abstract entirety": 1,
            "Author pub id": "81cvn3sAAAAJ:evX43VCCuoAC",
            "Publisher": "ACM"
        },
        {
            "Title": "BBQ: A visual interface for integrated browsing and querying of XML",
            "Publication year": 2000,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-0-387-35504-7_18",
            "Abstract": "In this paper we present BBQ (Blended Browsing and Querying), a graphic user interface for seamlessly browsing and querying XML data sources. BBQ displays the structure of multiple data sources using a paradigm that resembles drilling-down in Windows\u2019 directory structures. BBQ allows queries incorporating one or more of the sources. Queries are constructed in a query-by-example (QBE) manner, where DTDs play the role of schema. The queries are arbitrary conjunctive queries with GROUPBY, and their results can be subsequently used and refined. To support query refinement, BBQ introduces virtual result views: standalone virtual data sources that (i) are constructed by user queries, from elements in other data sources, and (ii) can be used in subsequent queries as first-class data sources themselves. Furthermore, BBQ allows users to query data sources with loose or incomplete schema, and can \u2026",
            "Abstract entirety": 0,
            "Author pub id": "81cvn3sAAAAJ:8k81kl-MbHgC",
            "Publisher": "Springer, Boston, MA"
        },
        {
            "Title": "PREFER: A system for the efficient execution of multi-parametric ranked queries",
            "Publication year": 2001,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/376284.375690",
            "Abstract": "Users often need to optimize the selection of objects by appropriately weighting the importance of multiple object attributes. Such optimization problems appear often in operations' research and applied mathematics as well as everyday life; e.g., a buyer may select a home as a weighted function of a number of attributes like its distance from office, its price, its area, etc.We capture such queries in our definition of preference queries that use a weight function over a relation's attributes to derive a score for each tuple. Database systems cannot efficiently produce the top results of a preference query because they need to evaluate the weight function over all tuples of the relation. PREFER answers preference queries efficiently by using materialized views that have been pre-processed and stored.We first show how the result of a preference query can be produced in a pipelined fashion using a materialized view. Then \u2026",
            "Abstract entirety": 0,
            "Author pub id": "81cvn3sAAAAJ:WF5omc3nYNoC",
            "Publisher": "ACM"
        },
        {
            "Title": "XML queries and algebra in the Enosys integration platform",
            "Publication year": 2003,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S0169023X02001416",
            "Abstract": "We describe the Enosys XML integration platform, focusing on the query language, algebra, and architecture of its query processor. The platform enables the development of eBusiness applications in customer relationship management, e-commerce, supply chain management, and decision support. These applications often require that data be integrated dynamically from multiple information sources. The Enosys platform allows one to build (virtual and/or materialized) integrated XML views of multiple sources, using XML queries as view definitions. During run-time, the application issues XML queries against the views. Queries and views are translated into the XCQL algebra and are combined into a single algebra expression/plan. Query plan composition and query plan decomposition challenges are faced in this process. Finally, the query processor lazily evaluates the result, using an appropriate adaptation of \u2026",
            "Abstract entirety": 0,
            "Author pub id": "81cvn3sAAAAJ:hFOr9nPyWt4C",
            "Publisher": "North-Holland"
        },
        {
            "Title": "Navigation-driven evaluation of virtual mediated views",
            "Publication year": 2000,
            "Publication url": "http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.15.9350",
            "Abstract": "The MIX mediator systems incorporates a novel framework for navigation-driven evaluation of virtual mediated views. Its architecture allows the on-demand computation of views and query results as the user navigates them. The evaluation scheme minimizes superfluous source access through the use of lazy mediators that translate incoming client navigations on virtual XML views into navigations on lower level mediators or wrapped sources. The proposed demand-driven approach is inevitable for handling up-to-date mediated views of large Web sources or query results. The non-materialization of the query answer is transparent to the client application since clients can navigate the query answer using a subset of the standard DOM API for XML documents. We elaborate on query evaluation in such a framework and show how algebraic plans can be implemented as trees of lazy mediators. Finally, we present a new buffering technique that can mediate between the fine granularity of DOM navigations and the coarse granularity of real world sources.",
            "Abstract entirety": 1,
            "Author pub id": "81cvn3sAAAAJ:ClCfbGk0d_YC",
            "Publisher": "Unknown"
        },
        {
            "Title": "An experimental study of bitmap compression vs. inverted list compression",
            "Publication year": 2017,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/3035918.3064007",
            "Abstract": "Bitmap compression has been studied extensively in the database area and many efficient compression schemes were proposed, eg, BBC, WAH, EWAH, and Roaring. Inverted list compression is also a well-studied topic in the information retrieval community and many inverted list compression algorithms were developed as well, eg, VB, PforDelta, GroupVB, Simple8b, and SIMDPforDelta. We observe that they essentially solve the same problem, ie, how to store a collection of sorted integers with as few as possible bits and support query processing as fast as possible. Due to historical reasons, bitmap compression and inverted list compression were developed as two separated lines of research in the database area and information retrieval area. Thus, a natural question is: Which one is better between bitmap compression and inverted list compression?",
            "Abstract entirety": 1,
            "Author pub id": "81cvn3sAAAAJ:tYavs44e6CUC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Dynamically adjusting performance of materialized view maintenance",
            "Publication year": 2021,
            "Publication url": "https://patents.google.com/patent/US20210165789A1/en",
            "Abstract": "The maintenance of a materialized view created and managed by a materialized view management platform may be dynamically adjusted. The performance of updates to a materialized view are monitored to trigger different events to make adjustments to the performance of subsequent updates. The materialized view management platform can adequately scale to handle changes to data sources as inputs to the maintenance of the materialized view, as well as make other adjustments handle various changes in the capability of the target data store to receive updates to the materialized view (eg, target data store outages).",
            "Abstract entirety": 1,
            "Author pub id": "81cvn3sAAAAJ:umqufdRvDiIC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Hippogriffdb: Balancing i/o and gpu bandwidth in big data analytics",
            "Publication year": 2016,
            "Publication url": "https://dl.acm.org/doi/abs/10.14778/3007328.3007331",
            "Abstract": "As data sets grow and conventional processor performance scaling slows, data analytics move towards heterogeneous architectures that incorporate hardware accelerators (notably GPUs) to continue scaling performance. However, existing GPU-based databases fail to deal with big data applications efficiently: their execution model suffers from scalability limitations on GPUs whose memory capacity is limited; existing systems fail to consider the discrepancy between fast GPUs and slow storage, which can counteract the benefit of GPU accelerators.In this paper, we propose HippogriffDB, an efficient, scalable GPU-accelerated OLAP system. It tackles the bandwidth discrepancy using compression and an optimized data transfer path. HippogriffDB stores tables in a compressed format and uses the GPU for decompression, trading GPU cycles for the improved I/O bandwidth. To improve the data transfer efficiency \u2026",
            "Abstract entirety": 0,
            "Author pub id": "81cvn3sAAAAJ:URolC5Kub84C",
            "Publisher": "VLDB Endowment"
        },
        {
            "Title": "Branch-and-bound processing of ranked queries",
            "Publication year": 2007,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S0306437905001225",
            "Abstract": "Despite the importance of ranked queries in numerous applications involving multi-criteria decision making, they are not efficiently supported by traditional database systems. In this paper, we propose a simple yet powerful technique for processing such queries based on multi-dimensional access methods and branch-and-bound search. The advantages of the proposed methodology are: (i) it is space efficient, requiring only a single index on the given relation (storing each tuple at most once), (ii) it achieves significant (i.e., orders of magnitude) performance gains with respect to the current state-of-the-art, (iii) it can efficiently handle data updates, and (iv) it is applicable to other important variations of ranked search (including the support for non-monotone preference functions), at no extra space overhead. We confirm the superiority of the proposed methods with a detailed experimental study.",
            "Abstract entirety": 1,
            "Author pub id": "81cvn3sAAAAJ:L8Ckcad2t8MC",
            "Publisher": "Pergamon"
        },
        {
            "Title": "The NEXT Logical Framework for XQuery.",
            "Publication year": 2004,
            "Publication url": "http://www.vldb.org/conf/2004/RS4P5.PDF",
            "Abstract": "Classical logical optimization techniques rely on a logical semantics of the query language. The adaptation of these techniques to XQuery is precluded by its definition as a functional language with operational semantics. We introduce Nested XML Tableaux which enable a logical foundation for XQuery semantics and provide the logical plan optimization framework of our XQuery processor. As a proof of concept, we develop and evaluate a minimization algorithm for removing redundant navigation within and across nested subqueries. The rich XQuery features create key challenges that fundamentally extend the prior work on the problems of minimizing conjunctive and tree pattern queries.",
            "Abstract entirety": 1,
            "Author pub id": "81cvn3sAAAAJ:_axFR9aDTf0C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Authority-based keyword search in databases",
            "Publication year": 2008,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/1331904.1331905",
            "Abstract": "Our system applies authority-based ranking to keyword search in databases modeled as labeled graphs. Three ranking factors are used: the relevance to the query, the specificity and the importance of the result. All factors are handled using authority-flow techniques that exploit the link-structure of the data graph, in contrast to traditional Information Retrieval. We address the performance challenges in computing the authority flows in databases by using precomputation and exploiting the database schema if present. We conducted user surveys and performance experiments on multiple real and synthetic datasets, to assess the semantic meaningfulness and performance of our system.",
            "Abstract entirety": 1,
            "Author pub id": "81cvn3sAAAAJ:QIV2ME_5wuYC",
            "Publisher": "ACM"
        },
        {
            "Title": "Efficient keyword search for smallest LCAs in XML databases",
            "Publication year": 2005,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/1066157.1066217",
            "Abstract": "Keyword search is a proven, user-friendly way to query HTML documents in the World Wide Web. We propose keyword search in XML documents, modeled as labeled trees, and describe corresponding efficient algorithms. The proposed keyword search returns the set of smallest trees containing all keywords, where a tree is designated as\" smallest\" if it contains no tree that also contains all keywords. Our core contribution, the Indexed Lookup Eager algorithm, exploits key properties of smallest trees in order to outperform prior algorithms by orders of magnitude when the query contains keywords with significantly different frequencies. The Scan Eager variant is tuned for the case where the keywords have similar frequencies. We analytically and experimentally evaluate two variants of the Eager algorithm, along with the Stack algorithm [13]. We also present the XKSearch system, which utilizes the Indexed Lookup \u2026",
            "Abstract entirety": 0,
            "Author pub id": "81cvn3sAAAAJ:UeHWp8X0CEIC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Algebra-based identification of tree patterns in XQuery",
            "Publication year": 2006,
            "Publication url": "https://link.springer.com/chapter/10.1007/11766254_2",
            "Abstract": "Query processing performance in XML databases can be greatly enhanced by the usage of materialized views whose content has been stored in the database. This requires a method for identifying query subexpressions matching the views, a process known as view-based query rewriting. This process is quite complex for relational databases, and all the more daunting on XML databases.Current XML materialized view proposals are based on tree patterns, since query navigation is conceptually close to such patterns. However, the existing algorithms for extracting tree patterns from XQuery do not detect patterns across nested query blocks. Thus, complex, useful tree pattern views may be missed by the rewriting algorithm. We present a novel tree pattern extraction algorithm from XQuery queries, able to identify larger patterns than previous methods. Our algorithm has been implemented in an XML \u2026",
            "Abstract entirety": 0,
            "Author pub id": "81cvn3sAAAAJ:e5wmG9Sq2KIC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "The magazine archive includes every article published in Communications of the ACM for over the past 50 years.",
            "Publication year": 2014,
            "Publication url": "https://cacm.acm.org/magazines/2014/7/176204-big-data-and-its-technical-challenges/fulltext",
            "Abstract": "In a broad range of application areas, data is being collected at an unprecedented scale. Decisions that previously were based on guesswork, or on painstakingly handcrafted models of reality, can now be made using data-driven mathematical models. Such Big Data analysis now drives nearly every aspect of society, including mobile services, retail, manufacturing, financial services, life sciences, and physical sciences.",
            "Abstract entirety": 1,
            "Author pub id": "81cvn3sAAAAJ:WZBGuue-350C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Efficient IR-style keyword search over relational databases",
            "Publication year": 2003,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/B978012722442850080X",
            "Abstract": "This chapter presents a system for efficient information retrieval (IR) -style keyword search over relational databases. A query in the model is simply a list of keywords and does not need to specify any relation or attribute names. The answer to such a query consists of a rank of \u201ctuple trees,\u201d which potentially include tuples from multiple relations that are combined via joins. To rank tuple trees, this chapter introduces a ranking function that leverages and extends the ability of modern relational database systems to provide keyword search on individual text attributes and rank tuples accordingly. In particular, the ranking function appropriately combines the relational database management systems (RDBMS) provided scores of individual attributes and tuples. The chapter introduces several top-k query-processing algorithms whose relative strengths depend, for example, on whether queries have \u2026",
            "Abstract entirety": 0,
            "Author pub id": "81cvn3sAAAAJ:qjMakFHDy7sC",
            "Publisher": "Morgan Kaufmann"
        },
        {
            "Title": "In-depth Survey of MVVM Web Application Frameworks",
            "Publication year": 2016,
            "Publication url": "https://dbucsd.github.io/paperpdfs/2016_4.pdf",
            "Abstract": "Frameworks that adopt the Model-View-Controller (MVC) design pattern have been extensively used in the web community for the development of fully-fledged web applications. Such frameworks enable efficient incremental updates on the application\u2019s state and visual layer, but they usually enforce the extended use of imperative logic in order to accomplish this effect. As an application is extended with additional functionality, the development process soon becomes extremely arduous and error-prone. This has lead to the emergence of Model-View-ViewModel (MVVM) and Web Component libraries that achieve higher developer productivity by keeping the required source code minimal and well-organized. Such frameworks can also provide additional mechanisms that automatically maintain the application state and the respective visual layer in sync, thus alleviating the application developer from this task. On the downside such mechanisms can negatively impact the performance of a given application and cause noticeable irregularities to the user experience. This research exam surveys MVVM and Web Component libraries that constitute the state-of-the-art in the web community. It also provides accurate definitions of the modules that compose an MVVM and a Component library and contains detailed description of the internal workings of each individual framework. Furthermore, this survey focuses on the mechanisms that are employed by MVVM and Component libraries to propagate changes from the application state to the respective part of the visual layer and describes the advantages and disadvantages of each individual mechanism \u2026",
            "Abstract entirety": 0,
            "Author pub id": "81cvn3sAAAAJ:ILKRHgRFtOwC",
            "Publisher": "Technical report of UCSDSE, University of California, San Diego"
        },
        {
            "Title": "Plato: approximate analytics over compressed time series with tight deterministic error guarantees",
            "Publication year": 2018,
            "Publication url": "https://arxiv.org/abs/1808.04876",
            "Abstract": "Plato provides fast approximate analytics on time series, by precomputing and storing compressed time series. Plato's key novelty is the delivery of tight deterministic error guarantees for time series analytics. Plato evaluates any time series expression composed by the linear algebra operators over vectors, along with arithmetic operators. This large scope of possible expressions includes common use cases such as correlation and cross-correlation expressions. Each time series is segmented either by fixed-length segmentation or by (a usually more effective) variable-length segmentation. Each segment is compressed by an estimation/compression function that approximates the actual values and is coming from a user-chosen function family, as taught by many prior works. The novelty is that Plato associates to each segment 1 to 3 (depending on the case) precomputed error measures and, using them, Plato computes tight deterministic error guarantees for analytics over the compressions. Importantly, some compression families lead to much better deterministic error guarantees. This work identifies two broad estimation function family groups (Vector Space (VS) and Linear Scalable Family (LSF)), which lead to theoretically and practically high-quality guarantees, even for expressions (eg correlation) that combine multiple time series that have been independently compressed and may, thus, use misaligned segmentations. The theoretical aspect of \"high quality\" is crisply captured by the Amplitude Independence (AI) property: An AI guarantee does not depend on the amplitude of the involved time series, even when we combine multiple time \u2026",
            "Abstract entirety": 0,
            "Author pub id": "81cvn3sAAAAJ:9pM33mqn1YgC",
            "Publisher": "Unknown"
        },
        {
            "Title": "A transducer-based XML query processor",
            "Publication year": 2002,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/B9781558608696500287",
            "Abstract": "The XML Stream Machine (XSM) system is a novel XQuery processing paradigm that is tuned to the efficient processing of sequentially accessed XML data (streams). The system compiles a given XQuery into an XSM, which is an XML stream transducer, that is, an abstract device that takes as input one or more XML data streams and produces one or more output streams, potentially using internal buffers. It presents a systematic way to translate XQueries into efficient XSMs. First, the XQuery is translated into a network of XSMs that correspond to the basic operators of the XQuery language and exchange streams. The network is reduced to a single XSM by repeated application of an XSM composition operation that is optimized to reduce the number of tests and actions that the XSM performs as well as the number of intermediate buffers that it uses. Finally, the optimized XSM is compiled into a C \u2026",
            "Abstract entirety": 0,
            "Author pub id": "81cvn3sAAAAJ:_FxGoFyzp5QC",
            "Publisher": "Morgan Kaufmann"
        },
        {
            "Title": "Challenges and opportunities with big data",
            "Publication year": 2012,
            "Publication url": "https://scholar.google.com/scholar?cluster=6908889725431555609&hl=en&oi=scholarr",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "81cvn3sAAAAJ:Ug5p-4gJ2f0C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Query Optimization for Faster Deep CNN Explanations",
            "Publication year": 2020,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/3422648.3422663",
            "Abstract": "Deep Convolutional Neural Networks (CNNs) now match human accuracy in many image prediction tasks, resulting in a growing adoption in e-commerce, radiology, and other domains. Naturally, \"explaining\" CNN predictions is a key concern for many users. Since the internal workings of CNNs are unintuitive for most users, occlusion-based explanations (OBE) are popular for understanding which parts of an image matter most for a prediction. One occludes a region of the image using a patch and moves it around to produce a heatmap of changes to the prediction probability. This approach is computationally expensive due to the large number of re-inference requests produced, which wastes time and raises resource costs. We tackle this issue by casting the OBE task as a new instance of the classical incremental view maintenance problem. We create a novel and comprehensive algebraic framework for \u2026",
            "Abstract entirety": 0,
            "Author pub id": "81cvn3sAAAAJ:DUooU5lO8OsC",
            "Publisher": "ACM"
        },
        {
            "Title": "An intelligent topic map-based approach to detecting and resolving conflicts for multi-resource knowledge fusion",
            "Publication year": 2009,
            "Publication url": "https://ci.nii.ac.jp/naid/10027641253/",
            "Abstract": "CiNii \u8ad6\u6587 - An intelligent topic map-based approach to detecting and resolving conflicts for \nmulti-resource knowledge fusion CiNii \u56fd\u7acb\u60c5\u5831\u5b66\u7814\u7a76\u6240 \u5b66\u8853\u60c5\u5831\u30ca\u30d3\u30b2\u30fc\u30bf[\u30b5\u30a4\u30cb\u30a3] \u65e5\u672c\u306e\n\u8ad6\u6587\u3092\u3055\u304c\u3059 \u5927\u5b66\u56f3\u66f8\u9928\u306e\u672c\u3092\u3055\u304c\u3059 \u65e5\u672c\u306e\u535a\u58eb\u8ad6\u6587\u3092\u3055\u304c\u3059 \u65b0\u898f\u767b\u9332 \u30ed\u30b0\u30a4\u30f3 English \u691c\u7d22 \n\u3059\u3079\u3066 \u672c\u6587\u3042\u308a \u3059\u3079\u3066 \u672c\u6587\u3042\u308a \u9589\u3058\u308b \u30bf\u30a4\u30c8\u30eb \u8457\u8005\u540d \u8457\u8005ID \u8457\u8005\u6240\u5c5e \u520a\u884c\u7269\u540d ISSN \u5dfb\u53f7\u30da\u30fc\u30b8 \n\u51fa\u7248\u8005 \u53c2\u8003\u6587\u732e \u51fa\u7248\u5e74 \u5e74\u304b\u3089 \u5e74\u307e\u3067 \u691c\u7d22 \u691c\u7d22 \u691c\u7d22 CiNii\u7a93\u53e3\u696d\u52d9\u306e\u518d\u958b\u306b\u3064\u3044\u3066 An intelligent \ntopic map-based approach to detecting and resolving conflicts for multi-resource knowledge \nfusion LU H. \u88ab\u5f15\u7528\u6587\u732e: 1\u4ef6 \u8457\u8005 LU H. \u53ce\u9332\u520a\u884c\u7269 Information Technology Journal \nInformation Technology Journal 8(8), 1242-1248, 2009 \u88ab\u5f15\u7528\u6587\u732e: 1\u4ef6\u4e2d 1-1\u4ef6\u3092 \u8868\u793a 1 Visual \nKnowledge Structure Reasoning with Intelligent Topic Map LU Huimin , FENG Boqin , CHEN \nXi IEICE transactions on information and systems 93(10), 2805-2812, 2010-10-01 \u53c2\u8003\u6587\u732e34/\u2026",
            "Abstract entirety": 0,
            "Author pub id": "81cvn3sAAAAJ:e_rmSamDkqQC",
            "Publisher": "Unknown"
        },
        {
            "Title": "An unified tuple-based algebra for XQuery",
            "Publication year": 2005,
            "Publication url": "https://abiteboul.com/gemoReports/GemoReport-434.pdf",
            "Abstract": "X &\u00a9 I a m98 5 s E (\u00a4 5 f# 2E F 0 3G 4 ((D 9e\u00a5 GF r)(\u00a4 1 0 o d 6 C# 6 r# IH#(\u00a4 u F d\u00a4 f (\u00a4 9\u00a4 f F 6 r 6 6 (\u00a4 f 6 f 1s ( HQ P (5 r 6 (\u00a4 f 6 r (\u00a4 R% D ph 8 6",
            "Abstract entirety": 1,
            "Author pub id": "81cvn3sAAAAJ:NMxIlDl6LWMC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Context-sensitive ranking for document retrieval",
            "Publication year": 2011,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/1989323.1989403",
            "Abstract": "We study the problem of context-sensitive ranking for document retrieval, where a context is defined as a sub-collection of documents, and is specified by queries provided by domain-interested users. The motivation of context-sensitive search is that the ranking of the same keyword query generally depends on the context. The reason is that the underlying keyword statistics differ significantly from one context to another. The query evaluation challenge is the computation of keyword statistics at runtime, which involves expensive online aggregations. We appropriately leverage and extend materialized view research in order to deliver algorithms and data structures that evaluate context-sensitive queries efficiently. Specifically, a number of views are selected and materialized, each corresponding to one or more large contexts. Materialized views are used at query time to compute statistics which are used to compute \u2026",
            "Abstract entirety": 0,
            "Author pub id": "81cvn3sAAAAJ:u_35RYKgDlwC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Combining Databases and Signal Processing in Plato.",
            "Publication year": 2015,
            "Publication url": "http://cseweb.ucsd.edu/~ikatsis/publications/cidr15.pdf",
            "Abstract": "Sensors generate large amounts of spatiotemporal data that have to be stored and analyzed. However, spatiotemporal data still lack the equivalent of a DBMS that would allow their declarative analysis. We argue that the reason for this is that DBMSs have been built with the assumption that the stored data are the ground truth. This is not the case with sensor measurements, which are merely incomplete and inaccurate samples of the ground truth. Based on this observation, we present Plato; an extensible DBMS for spatiotemporal sensor data that leverages signal processing algorithms to infer from the measurements the underlying ground truth in the form of statistical models. These models are then used to answer queries over the data. By operating on the model instead of the raw data, Plato achieves significant data compression and corresponding query processing speedup. Moreover, by employing models that separate the signal from the noise, Plato produces query results of higher quality than even the original measurements.",
            "Abstract entirety": 1,
            "Author pub id": "81cvn3sAAAAJ:NJ774b8OgUMC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Hypothetical queries in an olap environment",
            "Publication year": 2000,
            "Publication url": "https://www.researchgate.net/profile/Thanos_Papadimitriou/publication/3845932_Optimization_of_Hypothetical_Queries_in_an_OLAP_Environment/links/5461c9d70cf2c1a63bffbebe.pdf",
            "Abstract": "Analysts and decision makers use what if analysis to assess the effects of hypotheti cal scenarios. What if analysis is currently supported by spreadsheets and ad hoc OLAP tools. Unfortunately, the former lack seam less integration with the data and the lat ter lack flexibility and performance appropri ate for OLAP applications. To tackle these problems we developed the Sesame system, which models an hypothetical scenario as a list of hypothetical modifications on the ware house views and fact data. We provide formal scenario syntax and semantics, which extend view update semantics for accomodating the special requirements of OLAP. We focus on query algebra operators suitable for perform ing spreadsheet style computations. Then we present SesameVs optimizer and its corner stone substitution and rewriting mechanisms. Substitution enables lazy evaluation of the hy pothetical updates. The substitution module delivers orders of magnitude optimizations in cooperation with the rewriter that uses knowl edge of arithmetic, relational, financial and other operators. Finally we discuss the chal lenges that the size of the scenario specifica tions and the arbitrary nature of the operators pose to the rewriter. We present a rewriter that employs the? minterms and? packed forests techniques to quickly produce plans. eThis work was supported by the NSF-IRI 9712239 grant, UCSD startup funds, the Onassis Foundation, and equipment donations from Intel Corp.Permission to copy without fee all or part of this material is granted provided that the copies are not made or distributed for direct commercial advantage, the VLDB copyright notice and the title of \u2026",
            "Abstract entirety": 0,
            "Author pub id": "81cvn3sAAAAJ:4DMP91E08xMC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Navigation-Driven Evaluation",
            "Publication year": 2000,
            "Publication url": "https://scholar.google.com/scholar?cluster=1716331830548348471&hl=en&oi=scholarr",
            "Abstract": "The MIX mediator systems incorporates a novel framework for navigation-driven evaluation of virtual mediated views. Its architec-ture allows the on-demand computation of views and query results as the user navigates them. The evaluation scheme minimizes superfluous source access through the use of lazy mediators that translate incoming client navigations on virtual XML views into navigations on lower level mediators or wrapped sources. The proposed demand-driven approach is inevitable for handling up-to-date mediated views of large Web sources or query results. The non-materialization of the query answer is transparent to the client application since clients can navigate the query answer using a subset of the standard DOM API for XML documents. We elaborate on query evaluation in such a framework and show how algebraic plans can be implemented as trees of lazy mediators. Finally, we present a new buffering technique that can mediate between the fine granularity of DOM navigations and the coarse granularity of real world sources. This drastically reduces communication overhead and also simplifies wrapper development. An implementation of the system is available on the Web.",
            "Abstract entirety": 1,
            "Author pub id": "81cvn3sAAAAJ:sNmaIFBj_lkC",
            "Publisher": "Springer-Verlag"
        },
        {
            "Title": "KAML: A flexible, high-performance key-value SSD",
            "Publication year": 2017,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/7920840/",
            "Abstract": "Modern solid state drives (SSDs) unnecessarily confine host programs to the conventional block I/O interface, leading to suboptimal performance and resource under-utilization. Recent attempts to replace or extend this interface with a key-value-oriented interface and/or built-in support for transactions offer some improvements, but the details of their implementations make them a poor match for many applications. This paper presents the key-addressable, multi-log SSD (KAML), an SSD with a key-value interface that uses a novel multi-log architecture and stores data as variable-sized records rather than fixed-sized sectors. Exposing a key-value interface allows applications to remove a layer of indirection between application-level keys (e.g., database record IDs or file inode numbers) and data stored in the SSD. KAML also provides native transaction support tuned to support fine-grained locking, achieving \u2026",
            "Abstract entirety": 0,
            "Author pub id": "81cvn3sAAAAJ:TIZ-Mc8IlK0C",
            "Publisher": "IEEE"
        },
        {
            "Title": "Exporting and interactively querying web service-accessed sources: The CLIDE system",
            "Publication year": 2007,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/1292609.1292612",
            "Abstract": "The CLIDE System assists the owners of sources that participate in Web service-based data publishing systems to publish a restricted set of parameterized queries over the schema of their sources and package them as WSDL services. The sources may be relational databases, which naturally have a schema, or ad hoc information/application systems whereas the owner publishes a virtual schema. CLIDE allows information clients to pose queries over the published schema and utilizes prior work on answering queries using views to answer queries that can be processed by combining and processing the results of one or more Web service calls. These queries are called feasible. Contrary to prior work, where infeasible queries are rejected without an explanatory feedback, leading the user into a frustrating trial-and-error cycle, CLIDE features a query formulation interface, which extends the QBE-like query builder \u2026",
            "Abstract entirety": 0,
            "Author pub id": "81cvn3sAAAAJ:isC4tDSrTZIC",
            "Publisher": "ACM"
        },
        {
            "Title": "Ssd in-storage computing for search engines",
            "Publication year": 2016,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/7565739/",
            "Abstract": "SSD-based in-storage computing (called \u201dSmart SSDs\u201d) allows application-specific codes to execute inside SSDs to exploit the high internal bandwidth and energy-efficient processors. As a result, Smart SSDs have been successfully deployed in many industry settings, e.g., Samsung, IBM, Teradata, and Oracle. Moreover, researchers have also demonstrated their potential opportunities in database systems, data mining, and big data processing. However, it remains unknown whether search engine systems can benefit from Smart SSDs. This work takes a first step to answer this question. The major research issue is what search engine query processing operations can be cost-effectively offloaded to SSDs. For this, we carefully identified the five most commonly used search engine operations that could potentially benefit from Smart SSDs: intersection, ranked intersection, ranked union, difference, and ranked \u2026",
            "Abstract entirety": 0,
            "Author pub id": "81cvn3sAAAAJ:g3aElNc5_aQC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Competitor analysis and its defenses in the e-marketplace",
            "Publication year": 2005,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/1076211.1076213",
            "Abstract": "A firm's presence on the Internet opens a valuable channel for its competitors to collect and analyze its business information---to the firm's competitive disadvantage---unless it devises a defensive strategy.",
            "Abstract entirety": 1,
            "Author pub id": "81cvn3sAAAAJ:uJ-U7cs_P_0C",
            "Publisher": "ACM"
        },
        {
            "Title": "The SQL++ query language: Configurable, unifying and semi-structured",
            "Publication year": 2014,
            "Publication url": "https://ui.adsabs.harvard.edu/abs/2014arXiv1405.3631W/abstract",
            "Abstract": "NoSQL databases support semi-structured data, typically modeled as JSON. They also provide limited (but expanding) query languages. Their idiomatic, non-SQL language constructs, the many variations, and the lack of formal semantics inhibit deep understanding of the query languages, and also impede progress towards clean, powerful, declarative query languages. This paper specifies the syntax and semantics of SQL++, which is applicable to both JSON native stores and SQL databases. The SQL++ semi-structured data model is a superset of both JSON and the SQL data model. SQL++ offers powerful computational capabilities for processing semi-structured data akin to prior non-relational query languages, notably OQL and XQuery. Yet, SQL++ is SQL backwards compatible and is generalized towards JSON by introducing only a small number of query language extensions to SQL. Recognizing that a query \u2026",
            "Abstract entirety": 0,
            "Author pub id": "81cvn3sAAAAJ:4fGpz3EwCPoC",
            "Publisher": "Unknown"
        },
        {
            "Title": "QURSED: querying and reporting semistructured data",
            "Publication year": 2002,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/564691.564714",
            "Abstract": "QURSED enables the development of web-based query forms and reports (QFRs) that query and report semistructured XML data, ie, data that are characterized by nesting, irregularities and structural variance. The query aspects of a QFR are captured by its query set specification, which formally encodes multiple parameterized condition fragments and can describe large numbers of queries. The run-time component of QURSED produces XQuery-compliant queries by synthesizing fragments from the query set specification that have been activated during the interaction of the end-user with the QFR. The design-time component of QURSED, called QURSED Editor, semi-automates the development of the query set specification and its association with the visual components of the QFR by translating visual actions into appropriate query set specifications. We describe QURSED and illustrate how it accommodates the \u2026",
            "Abstract entirety": 0,
            "Author pub id": "81cvn3sAAAAJ:aqlVkmm33-oC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Big data and its technical challenges",
            "Publication year": 2014,
            "Publication url": "https://dl.acm.org/doi/fullHtml/10.1145/2611567",
            "Abstract": "Exploring the inherent technical challenges in realizing the potential of Big Data.",
            "Abstract entirety": 1,
            "Author pub id": "81cvn3sAAAAJ:Fu2w8maKXqMC",
            "Publisher": "ACM"
        },
        {
            "Title": "Fast in-memory SQL analytics on typed graphs",
            "Publication year": 2016,
            "Publication url": "https://dl.acm.org/doi/abs/10.14778/3021924.3021941",
            "Abstract": "We study a class of graph analytics SQL queries, which we call relationship queries. These queries involving aggregation, join, semijoin, intersection and selection are a wide superset of fixed-length graph reachability queries and of tree pattern queries. We present real-world OLAP scenarios, where efficient relationship queries are needed. However, row stores, column stores and graph databases are unacceptably slow in such OLAP scenarios.We propose a GQ-Fast database, which is an indexed database that roughly corresponds to efficient encoding of annotated adjacency lists that combines salient features of column-based organization, indexing and compression. GQ-Fast uses a bottom-up fully pipelined query execution model, which enables (a) aggressive compression (e.g., compressed bitmaps and Huffman) and (b) avoids intermediate results that consist of row IDs (which are typical in column \u2026",
            "Abstract entirety": 0,
            "Author pub id": "81cvn3sAAAAJ:Z5m8FVwuT1cC",
            "Publisher": "VLDB Endowment"
        }
    ]
}]