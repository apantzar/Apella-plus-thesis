[{
    "name": "\u0395\u03bc\u03bc\u03b1\u03bd\u03bf\u03c5\u03ae\u03bb \u039b\u03bf\u03c5\u03c1\u03ac\u03ba\u03b7\u03c2",
    "romanize name": "Emmanouil Lourakis",
    "School-Department": "\u0399\u03bd\u03c3\u03c4\u03b9\u03c4\u03bf\u03cd\u03c4\u03bf \u03a0\u03bb\u03b7\u03c1\u03bf\u03c6\u03bf\u03c1\u03b9\u03ba\u03ae\u03c2",
    "University": "forth",
    "Rank": "\u0394\u03b9\u03b5\u03c5\u03b8\u03c5\u03bd\u03c4\u03ae\u03c2 \u0395\u03c1\u03b5\u03c5\u03bd\u03ce\u03bd",
    "Apella_id": 18073,
    "Scholar name": "Manolis Lourakis",
    "Scholar id": "4YYxk1IAAAAJ",
    "Affiliation": "Researcher, Foundation for Research and Technology - Hellas, Greece  (ORCID iD: 0000-0003-4596-5773)",
    "Citedby": 6017,
    "Interests": [
        "Computer Vision",
        "Robot Vision"
    ],
    "Scholar url": "https://scholar.google.com/citations?user=4YYxk1IAAAAJ&hl=en",
    "Publications": [
        {
            "Title": "High-performance vision-based navigation on SoC FPGA for spacecraft proximity operations",
            "Publication year": 2020,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/8648530/",
            "Abstract": "Future autonomous spacecraft rendezvous with uncooperative or unprepared objects will be enabled by vision-based navigation, which imposes great computational challenges. Targeting short duration missions in low Earth orbit, this paper develops high-performance avionics supporting custom computer vision algorithms of increased complexity for satellite pose tracking. At algorithmic level, we track 6D pose by rendering a depth image from an object mesh model and robustly matching edges detected in the depth and intensity images. At system level, we devise an architecture to exploit the structure of commercial system-on-chip FPGAs, i.e., Zynq7000, and the benefits of tightly coupling VHDL accelerators with CPU-based functions. At implementation level, we employ our custom HW/SW co-design methodology and an elaborate combination of digital circuit design techniques to optimize and map efficiently all \u2026",
            "Abstract entirety": 0,
            "Author pub id": "4YYxk1IAAAAJ:sSrBHYA8nusC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Plane metric rectification from a single view of multiple coplanar circles",
            "Publication year": 2009,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/5413978/",
            "Abstract": "Metric rectification has important applications to topics such as single-view metrology, camera calibration, optical character recognition and texture extraction or synthesis. This paper proposes a method for estimating the rectification homography of a world plane that pertains to a single view containing the images of at least two circles in general position. The method does not presuppose that the circles radii, the camera's intrinsics or the plane's vanishing line are known and can simultaneously accommodate multiple circles. Comparative experimental results demonstrate the approach's efficacy.",
            "Abstract entirety": 1,
            "Author pub id": "4YYxk1IAAAAJ:mVmsd5A6BfQC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Supporting the Wellness at Work and Productivity of Ageing Employees in Industrial Environments: The sustAGE Project",
            "Publication year": 2019,
            "Publication url": "https://scholar.google.com/scholar?cluster=15267751758183565234&hl=en&oi=scholarr",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "4YYxk1IAAAAJ:VOx2b1Wkg3QC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Camera matchmoving in unprepared, unknown environments",
            "Publication year": 2005,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/1467589/",
            "Abstract": "Camera matchmoving is an application involving synthesis of real scenes and artificial objects, in which the goal is to insert computer-generated graphical 3D objects into live-action footage depicting unmodeled, arbitrary scenes. This work addresses the problem of tracking the 3D motion of a camera in space, using only the images it acquires while moving freely in unmodeled, arbitrary environments. A novel feature-based method for camera tracking has been developed, intended to facilitate tracking in online, time-critical applications such as video see-through augmented reality and vision-based control. In contrast to several existing techniques, which are designed to operate in a batch, offline mode, assuming that the whole video sequence to be tracked is available before tracking commences, our method operates on images incrementally, as they are being acquired.",
            "Abstract entirety": 1,
            "Author pub id": "4YYxk1IAAAAJ:QIV2ME_5wuYC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Estimating the Jacobian of the singular value decomposition: Theory and applications",
            "Publication year": 2000,
            "Publication url": "https://link.springer.com/chapter/10.1007/3-540-45054-8_36",
            "Abstract": "The Singular Value Decomposition (SVD) of a matrix is a linear algebra tool that has been successfully applied to a wide variety of domains. The present paper is concerned with the problem of estimating the Jacobian of the SVD components of a matrix with respect to the matrix itself. An exact analytic technique is developed that facilitates the estimation of the Jacobian using calculations based on simple linear algebra. Knowledge of the Jacobian of the SVD is very useful in certain applications involving multivariate regression or the computation of the uncertainty related to estimates obtained through the SVD. The usefulness and generality of the proposed technique is demonstrated by applying it to the estimation of the uncertainty for three different vision problems, namely self-calibration, epipole computation and rigid motion estimation.",
            "Abstract entirety": 1,
            "Author pub id": "4YYxk1IAAAAJ:IjCSPb-OGe4C",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "Vision-based camera motion recovery for augmented reality",
            "Publication year": 2004,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/1309266/",
            "Abstract": "We address the problem of tracking the 3D position and orientation of a camera, using the images it acquires while moving freely in unmodeled, arbitrary environments. This task has a broad spectrum of useful applications in domains such as augmented reality and video post production. Most of the existing methods for vision-based camera tracking are designed to operate in a batch, off-line mode, assuming that the whole video sequence to be tracked is available before tracking commences. Typically, such methods operate noncausally, processing video frames backwards and forwards in time as they see fit. Furthermore, they resort to optimization in very high dimensional spaces, a process that is computationally intensive. For these reasons, batch methods are inapplicable to tracking in online, time-critical applications such as video see-through augmented reality. This paper puts forward a novel feature-based \u2026",
            "Abstract entirety": 0,
            "Author pub id": "4YYxk1IAAAAJ:LkGwnXOMwfcC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Correspondence-free pose estimation for 3D objects from noisy depth data",
            "Publication year": 2018,
            "Publication url": "https://link.springer.com/article/10.1007/s00371-016-1326-9",
            "Abstract": "Estimating the pose of objects from depth data is a problem of considerable practical importance for many vision applications. This paper presents an approach for accurate and efficient 3D pose estimation from noisy 2.5D depth images obtained from a consumer depth sensor. Initialized with a coarsely accurate pose, the proposed approach applies a hypothesize-and-test scheme that combines stochastic optimization and graphics-based rendering to refine the supplied initial pose, so that it accurately accounts for a sensed depth image. Pose refinement employs particle swarm optimization to minimize an objective function that quantifies the misalignment between the acquired depth image and a rendered one that is synthesized from a hypothesized pose with the aid of an object mesh model. No explicit correspondences between the depth data and the model need to be established, whereas pose \u2026",
            "Abstract entirety": 0,
            "Author pub id": "4YYxk1IAAAAJ:uWQEDVKXjbEC",
            "Publisher": "Springer Berlin Heidelberg"
        },
        {
            "Title": "A Linear Approach to Absolute Pose Estimation for Light Fields",
            "Publication year": 2020,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/9320357/",
            "Abstract": "This paper presents the first absolute pose estimation approach tailored to Light Field cameras. It builds on the observation that the ratio between the disparity arising in different sub-aperture images and their corresponding baseline is constant. Hence, we augment the 2D pixel coordinates with the corresponding normalised disparity to obtain the Light Field feature. This new representation reduces the effect of noise by aggregating multiple projections and allows for linear estimation of the absolute pose of a Light Field camera using the well-known Direct Linear Transformation algorithm. We evaluate the resulting absolute pose estimates with extensive simulations and experiments involving real Light Field datasets, demonstrating the competitive performance of our linear approach. Furthermore, we integrate our approach in a state-of-the-art Light Field Structure from Motion pipeline and demonstrate accurate multi \u2026",
            "Abstract entirety": 0,
            "Author pub id": "4YYxk1IAAAAJ:olpn-zPbct0C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Horizon matching for localizing unordered panoramic images",
            "Publication year": 2010,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S1077314209000472",
            "Abstract": "There is currently an abundance of vision algorithms which, provided with a sequence of images that have been acquired from sufficiently close successive 3D locations, are capable of determining the relative positions of the viewpoints from which the images have been captured. However, very few of these algorithms can cope with unordered image sets. This paper presents an efficient method for recovering the position and orientation parameters corresponding to the viewpoints of a set of panoramic images for which no a priori order information is available, along with certain structure information regarding the imaged environment. The proposed approach assumes that all images have been acquired from a constant height above a planar ground and operates sequentially, employing the Levenshtein distance to deduce the spatial proximity of image viewpoints and thus determine the order in which images \u2026",
            "Abstract entirety": 0,
            "Author pub id": "4YYxk1IAAAAJ:iH-uZ7U-co4C",
            "Publisher": "Academic Press"
        },
        {
            "Title": "Efficient, causal camera tracking in unprepared environments",
            "Publication year": 2005,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S1077314205000202",
            "Abstract": "This paper addresses the problem of tracking the 3D pose of a camera in space, using the images it acquires while moving freely in unmodeled, arbitrary environments. A novel feature-based approach for camera tracking is proposed, intended to facilitate tracking in on-line, time-critical applications such as video see-through augmented reality. In contrast to several existing methods which are designed to operate in a batch, off-line mode, assuming that the whole video sequence to be tracked is available before tracking commences, the proposed method operates on images incrementally. At its core lies a feature-based 3D plane tracking technique, which permits the estimation of the homographies induced by a virtual 3D plane between successive image pairs. Knowledge of these homographies allows the corresponding projection matrices encoding camera motion to be expressed in a common projective frame \u2026",
            "Abstract entirety": 0,
            "Author pub id": "4YYxk1IAAAAJ:W7OEmFMy1HYC",
            "Publisher": "Academic Press"
        },
        {
            "Title": "Reality Capturing and Modeling with Visual and Spatial Sensing",
            "Publication year": 2009,
            "Publication url": "http://gnosis.library.ucy.ac.cy/handle/7/45675",
            "Abstract": "Reality Capturing and Modeling with Visual and Spatial Sensing Toggle navigation English \n\u0395\u03bb\u03bb\u03b7\u03bd\u03b9\u03ba\u03ac English English \u0395\u03bb\u03bb\u03b7\u03bd\u03b9\u03ba\u03ac Login Toggle navigation View Item Home \u0394\u03b7\u03bc\u03bf\u03c3\u03b9\u03b5\u03cd\u03c3\u03b5\u03b9\u03c2 \u03a0\u039a \n/ UCY Publications 007 \u03a0\u03bf\u03bb\u03c5\u03c4\u03b5\u03c7\u03bd\u03b9\u03ba\u03ae \u03a3\u03c7\u03bf\u03bb\u03ae / Faculty of Engineering \u03a4\u03bc\u03ae\u03bc\u03b1 \u03a0\u03bf\u03bb\u03b9\u03c4\u03b9\u03ba\u03ce\u03bd \n\u039c\u03b7\u03c7\u03b1\u03bd\u03b9\u03ba\u03ce\u03bd \u03ba\u03b1\u03b9 \u039c\u03b7\u03c7\u03b1\u03bd\u03b9\u03ba\u03ce\u03bd \u03a0\u03b5\u03c1\u03b9\u03b2\u03ac\u03bb\u03bb\u03bf\u03bd\u03c4\u03bf\u03c2 / Department of Civil and Environmental Engineering \nView Item Home \u0394\u03b7\u03bc\u03bf\u03c3\u03b9\u03b5\u03cd\u03c3\u03b5\u03b9\u03c2 \u03a0\u039a / UCY Publications 007 \u03a0\u03bf\u03bb\u03c5\u03c4\u03b5\u03c7\u03bd\u03b9\u03ba\u03ae \u03a3\u03c7\u03bf\u03bb\u03ae / Faculty of \nEngineering \u03a4\u03bc\u03ae\u03bc\u03b1 \u03a0\u03bf\u03bb\u03b9\u03c4\u03b9\u03ba\u03ce\u03bd \u039c\u03b7\u03c7\u03b1\u03bd\u03b9\u03ba\u03ce\u03bd \u03ba\u03b1\u03b9 \u039c\u03b7\u03c7\u03b1\u03bd\u03b9\u03ba\u03ce\u03bd \u03a0\u03b5\u03c1\u03b9\u03b2\u03ac\u03bb\u03bb\u03bf\u03bd\u03c4\u03bf\u03c2 / Department of Civil \nand Environmental Engineering View Item Conference Object Reality Capturing and Modeling \nwith Visual and Spatial Sensing Thumbnail Date 2009 Author Makhmalbaf, Atefe Brilakis, \nIoannis Teizer, Jochen Lourakis, Manolis Sacks, Rafael ORCID logo Christodoulou, Symeon E. \nSavarese, Silvio Source Construction Industry Institute [CII 2009] Google Scholar check full ://.\u2026",
            "Abstract entirety": 0,
            "Author pub id": "4YYxk1IAAAAJ:GnPB-g6toBAC",
            "Publisher": "Unknown"
        },
        {
            "Title": "HW/SW codesign and FPGA acceleration of visual odometry algorithms for rover navigation on Mars",
            "Publication year": 2015,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/7147824/",
            "Abstract": "Future Mars exploration missions rely heavily on high-mobility autonomous rovers equipped with sophisticated scientific instruments and possessing advanced navigational capabilities. Increasing their navigation velocity and localization accuracy is essential for enabling these rovers to explore large areas on Mars. Contemporary Mars rovers move slowly, partially due to the long execution time of complex computer vision algorithms running on their slow space-grade CPUs. This paper exploits the advent of high-performance space-grade field-programmable gate arrays (FPGAs) to accelerate the navigation of future rovers. Specifically, it focuses on visual odometry (VO) and performs HW/SW codesign to achieve one order of magnitude faster execution and improved accuracy. Conforming to the specifications of the European Space Agency, we build a proof-of-concept system on an HW/SW platform with \u2026",
            "Abstract entirety": 0,
            "Author pub id": "4YYxk1IAAAAJ:P5F9QuxV20EC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Feature transfer and matching in disparate stereo views through the use of plane homographies",
            "Publication year": 2003,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/1177157/",
            "Abstract": "Many vision tasks rely upon the identification of sets of corresponding features among different images. This paper presents a method that, given some corresponding features in two stereo images, matches them with features extracted from a second stereo pair captured from a distant viewpoint. The proposed method is based on the assumption that the viewed scene contains two planar surfaces and exploits geometric constraints that are imposed by the existence of these planes to first transfer and then match image features between the two stereo pairs. The resulting scheme handles point and line features in a unified manner and is capable of successfully matching features extracted from stereo pairs that are acquired from considerably different viewpoints. Experimental results are presented, which demonstrate that the performance of the proposed method compares favorably to that of epipolar and tensor \u2026",
            "Abstract entirety": 0,
            "Author pub id": "4YYxk1IAAAAJ:WF5omc3nYNoC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Localizing unordered panoramic images using the Levenshtein distance",
            "Publication year": 2007,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/4409200/",
            "Abstract": "This paper proposes a feature-based method for recovering the relative positions of the viewpoints of a set of panoramic images for which no a priori order information is available, along with certain structure information regarding the imaged environment. The proposed approach operates incrementally, employing the Levenshtein distance to deduce the spatial proximity of image viewpoints and thus determine the order in which images should be processed. The Levenshtein distance also provides matches between images, from which their underlying environment points can be recovered. Recovered points that are visible in multiple views permit the localization of more views which in turn allow the recovery of more points. The process repeats until all views have been localized. Periodic refinement of the reconstruction with the aid of bundle adjustment, distributes the reconstruction errors among images. The \u2026",
            "Abstract entirety": 0,
            "Author pub id": "4YYxk1IAAAAJ:fPk4N6BV_jEC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Satellite Visual Tracking for Proximity Operations in Space",
            "Publication year": 2017,
            "Publication url": "http://users.ics.forth.gr/~lourakis/publ/2017_astra.pdf",
            "Abstract": "Determining the pose of orbiting satellites is a fundamental prerequisite for supporting autonomous proximity operations in space. This work presents a model-based 3D tracking algorithm based on edges. The proposed tracker maintains a pose hypothesis that is propagated from frame to frame, using it first to render a depth image and then refining it according to partial matches established between depth and intensity edges. Edge matching relies on fast, local linear searches along the depth gradient direction. The tracker does not require any preprocessing of the 3D model nor does it make any assumptions regarding its characteristics, as is often the case for other approaches based on edges. It is also robust to parts of the tracked satellite being out of view, occluded, shadowed or visually undetected. Experimental results evaluating the accuracy of the tracker and comparing it against established techniques are also included.",
            "Abstract entirety": 1,
            "Author pub id": "4YYxk1IAAAAJ:WbkHhVStYXYC",
            "Publisher": "Unknown"
        },
        {
            "Title": "3D pose refinement using rendering and texture-based matching",
            "Publication year": 2014,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-319-11331-9_80",
            "Abstract": "This paper presents a method for accurately determining the pose of Lambertian rigid objects present in an image. An initial pose estimate computed with the aid of local point features is ameliorated by considering all visible object texture. This is achieved by combining a textured mesh model of the object with a graphics renderer to synthesize an image of the object as would be captured by the camera at a particular pose. A rendered image is compared against the acquired one with the aid of a visual dissimilarity score involving cross-correlation. Population-based stochastic optimization is used to efficiently search the pose space and minimize the dissimilarity between rendered images corresponding to candidate poses and the acquired image. The method is demonstrated with the aid of real and synthetic images.",
            "Abstract entirety": 1,
            "Author pub id": "4YYxk1IAAAAJ:_xSYboBqXhAC",
            "Publisher": "Springer, Cham"
        },
        {
            "Title": "Vision-based interpretation of hand gestures for remote control of a computer mouse",
            "Publication year": 2006,
            "Publication url": "https://link.springer.com/chapter/10.1007/11754336_5",
            "Abstract": "This paper presents a vision-based interface for controlling a computer mouse via 2D and 3D hand gestures. The proposed interface builds upon our previous work that permits the detection and tracking of multiple hands that can move freely in the field of view of a potentially moving camera system. Dependable hand tracking, combined with fingertip detection, facilitates the definition of simple and, therefore, robustly interpretable vocabularies of hand gestures that are subsequently used to enable a human operator convey control information to a computer system. Two such vocabularies are defined, implemented and validated. The first one depends only on 2D hand tracking results while the second also makes use of 3D information. As confirmed by several experiments, the proposed interface achieves accurate mouse positioning, smooth cursor movement and reliable recognition of gestures activating \u2026",
            "Abstract entirety": 0,
            "Author pub id": "4YYxk1IAAAAJ:UeHWp8X0CEIC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "A Globally Optimal Method for the PnP Problem with MRP Rotation Parameterization",
            "Publication year": 2021,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/9412405/",
            "Abstract": "The perspective-n-point (PnP) problem is of fundamental importance in computer vision. A global optimality condition for PnP that is independent of a particular rotation parameterization was recently developed by Nakano. This paper puts forward a direct least squares, algebraic PnP solution that extends Nakano's work by combining his optimality condition with the modified Rodrigues parameters (MRPs) for parameterizing rotation. The result is a system of polynomials that is solved using the Gr\u00f6bner basis approach. An MRP vector has twice the rotational range of the classical Rodrigues (i.e., Cayley) vector used by Nakano to represent rotation. The proposed solution provides strong guarantees that the full rotation singularity associated with MRPs is avoided. Furthermore, detailed experiments provide evidence that our solution attains accuracy that is indistinguishable from Nakano's Cayley-based method with a \u2026",
            "Abstract entirety": 0,
            "Author pub id": "4YYxk1IAAAAJ:t6usbXjVLHcC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Real-time tracking of multiple skin-colored objects with a possibly moving camera",
            "Publication year": 2004,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-540-24672-5_29",
            "Abstract": "This paper presents a method for tracking multiple skin-colored objects in images acquired by a possibly moving camera. The proposed method encompasses a collection of techniques that enable the modeling and detection of skin-colored objects as well as their temporal association in image sequences. Skin-colored objects are detected with a Bayesian classifier which is bootstrapped with a small set of training data. Then, an off-line iterative training procedure is employed to refine the classifier using additional training images. On-line adaptation of skin-color probabilities is used to enable the classifier to cope with illumination changes. Tracking over time is realized through a novel technique which can handle multiple skin-colored objects. Such objects may move in complex trajectories and occlude each other in the field of view of a possibly moving camera. Moreover, the number of tracked objects may \u2026",
            "Abstract entirety": 0,
            "Author pub id": "4YYxk1IAAAAJ:d1gkVwhDpl0C",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "T-LESS: An RGB-D dataset for 6D pose estimation of texture-less objects",
            "Publication year": 2017,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/7926686/",
            "Abstract": "We introduce T-LESS, a new public dataset for estimating the 6D pose, i.e. translation and rotation, of texture-less rigid objects. The dataset features thirty industry-relevant objects with no significant texture and no discriminative color or reflectance properties. The objects exhibit symmetries and mutual similarities in shape and/or size. Compared to other datasets, a unique property is that some of the objects are parts of others. The dataset includes training and test images that were captured with three synchronized sensors, specifically a structured-light and a time-of-flight RGB-D sensor and a high-resolution RGB camera. There are approximately 39K training and 10K test images from each sensor. Additionally, two types of 3D models are provided for each object, i.e. a manually created CAD model and a semi-automatically reconstructed one. Training images depict individual objects against a black background \u2026",
            "Abstract entirety": 0,
            "Author pub id": "4YYxk1IAAAAJ:p2g8aNsByqUC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Bundle adjustment gone public",
            "Publication year": 2011,
            "Publication url": "Unknown",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "4YYxk1IAAAAJ:hC7cP41nSMkC",
            "Publisher": "Slides from PRCV Colloquium Prague Oct. 13th"
        },
        {
            "Title": "Camera self-calibration using the singular value decomposition of the fundamental matrix",
            "Publication year": 2000,
            "Publication url": "https://www.researchgate.net/profile/Manolis-Lourakis/publication/2441156_Camera_Self-Calibration_Using_the_Singular_Value_Decomposition_of_the_Fundamental_Matrix/links/5d8b21c992851c33e938c474/Camera-Self-Calibration-Using-the-Singular-Value-Decomposition-of-the-Fundamental-Matrix.pdf",
            "Abstract": "This paper deals with a fundamental problem in motion and stereo analysis, namely that of determining the camera intrinsic calibration parameters. A novel method is proposed that follows the autocalibration paradigm, according to which calibration is achieved not with the aid of a calibration pattern but by observing a number of image features in a set of successive images. The proposed method relies upon the Singular Value Decomposition of the fundamental matrix, which leads to a particularly simple form of the Kruppa equations. In contrast to the classical formulation that supplies an overdetermined system of constraints, the derivation proposed here provides a straightforward answer to the problem of determining which constraints to employ among the set of available ones. Moreover, the derivation is a purely algebraic one, without a need for resorting to the somewhat non-intuitive geometric concept of the absolute conic. Apart from the fundamental matrix, no other quantities that can be extracted from it (eg the epipoles) are needed for the derivation. Experimental results demonstrate the effectiveness of the proposed method in accurately estimating the intrinsic calibration matrices for several image sequences.",
            "Abstract entirety": 1,
            "Author pub id": "4YYxk1IAAAAJ:eJXPG6dFmWUC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Accurate Constraint-Based Modeling From A Single Perspective View",
            "Publication year": 2007,
            "Publication url": "http://www.inf.ufrgs.br/cgi2007/cd_cgi/papers/lourakis.pdf",
            "Abstract": "Recovery of a 3D model from a single image is possible provided that adequate geometric knowledge about the imaged scene is a priori available. This prior knowledge is essential for disambiguating among the infinitely many 3D reconstructions that are compatible with a given 2D image. In practice, single view reconstruction methods employ geometric knowledge in the form of constraints such as coplanarity, parallelism, perpendicularity, etc, that are assumed to be supplied by a user based on his/her interpretation of the scene. Most of the existing methods, however, produce reconstructions that only approximately satisfy the supplied geometric constraints. This paper puts forward a single view reconstruction method which produces reconstructions that accurately satisfy all specified geometric constraints. This is achieved by first obtaining a preliminary reconstruction and then refining it in an extendable, constrained minimization framework. Sample experimental results demonstrate the approach.",
            "Abstract entirety": 1,
            "Author pub id": "4YYxk1IAAAAJ:JV2RwH3_ST0C",
            "Publisher": "Petropolis"
        },
        {
            "Title": "A Consistently Fast and Globally Optimal Solution to the Perspective-n-Point Problem",
            "Publication year": 2020,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-030-58452-8_28",
            "Abstract": "An approach for estimating the pose of a camera given a set of 3D points and their corresponding 2D image projections is presented. It formulates the problem as a non-linear quadratic program and identifies regions in the parameter space that contain unique minima with guarantees that at least one of them will be the global minimum. Each regional minimum is computed with a sequential quadratic programming scheme. These premises result in an algorithm that always determines the global minima of the perspective-n-point problem for any number of input correspondences, regardless of possible coplanar arrangements of the imaged 3D points. For its implementation, the algorithm merely requires ordinary operations available in any standard off-the-shelf linear algebra library. Comparative evaluation demonstrates that the algorithm achieves state-of-the-art results at a consistently low computational cost.",
            "Abstract entirety": 1,
            "Author pub id": "4YYxk1IAAAAJ:5ugPr518TE4C",
            "Publisher": "Springer"
        },
        {
            "Title": "Planetary rover absolute localization by combining visual odometry with orbital image measurements",
            "Publication year": 2015,
            "Publication url": "http://robotics.estec.esa.int/ASTRA/Astra2015/Papers/Session%208B/98867_Lourakis.pdf",
            "Abstract": "Visual Odometry (VO) has established itself as an important localization technology for planetary exploration rovers, being capable of yielding location estimates with small error over medium-sized trajectories. However, due to VO\u2019s incremental mode of operation, the estimation error accumulates over time, resulting in considerable drift for long trajectories. This paper proposes a global localization method that counters VO drift by matching boulders extracted from overhead and ground images of a planet and using them periodically to re-localize the rover and refine VO estimates. The performance of the method is evaluated with the aid of overhead imagery of different resolutions. Experimental results demonstrate that a very terse representation, consisting of approximate boulder locations only, suffices for bringing significant accuracy improvements to VO over long traverses.",
            "Abstract entirety": 1,
            "Author pub id": "4YYxk1IAAAAJ:1sJd4Hv_s6UC",
            "Publisher": "Unknown"
        },
        {
            "Title": "High-performance embedded computing in space: Evaluation of platforms for vision-based navigation",
            "Publication year": 2018,
            "Publication url": "https://arc.aiaa.org/doi/abs/10.2514/1.I010555",
            "Abstract": "Vision-based navigation has become increasingly important in a variety of space applications for enhancing autonomy and dependability. Future missions, such as active debris removal for remediating the low Earth orbit environment, will rely on novel high-performance avionics to support advanced image processing algorithms with substantial workloads. However, when designing new avionics architectures, constraints relating to the use of electronics in space present great challenges, further exacerbated by the need for significantly faster processing compared to conventional space-grade central processing units. With the long-term goal of designing high-performance embedded computers for space, in this paper, an extended study and tradeoff analysis of a diverse set of computing platforms and architectures (i.e., central processing units, multicore digital signal processors, graphics processing units, and field \u2026",
            "Abstract entirety": 0,
            "Author pub id": "4YYxk1IAAAAJ:l7t_Zn2s7bgC",
            "Publisher": "American Institute of Aeronautics and Astronautics"
        },
        {
            "Title": "Matching disparate views of planar surfaces using projective invariants",
            "Publication year": 2000,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S0262885699000712",
            "Abstract": "Feature matching is a prerequisite to a wide variety of vision tasks. This paper presents a method that addresses the problem of matching two views of coplanar points and lines in a unified manner. The views to be matched are assumed to have been acquired from disparate, i.e. very different viewpoints. By employing a randomized search strategy combined with the two-line two-point projective invariant, the proposed method is able to derive small sets of possibly matching points and lines. These candidate matches are then verified by recovering the associated plane homography, which is further used to predict more matches. The resulting scheme is capable of successfully matching features extracted from views that differ considerably, even in the presence of large numbers of outlying features. Experimental results from the application of the method to indoor and aerial images indicate its effectiveness and \u2026",
            "Abstract entirety": 0,
            "Author pub id": "4YYxk1IAAAAJ:Tyk-4Ss8FVUC",
            "Publisher": "Elsevier"
        },
        {
            "Title": "The design and implementation of a generic sparse bundle adjustment software package based on the Levenberg-Marquardt algorithm",
            "Publication year": 2004,
            "Publication url": "https://www.ics.forth.gr/~argyros/mypapers/2004_08_tr340_forth_sba.pdf",
            "Abstract": "Bundle Adjustment (BA) is almost invariably used as the last step of every featurebased multiview structure and motion estimation algorithm; see, for example,[10, 3, 6, 21, 27]. BA was originally conceived in the field of photogrammetry [24] and has increasingly been used by vision researchers during the last decade. An excellent overview of its application to vision-based reconstruction is given in [25]. BA is a technique for simultaneously refining the 3D structure and viewing parameters (ie camera pose and possibly intrinsic calibration and radial distortion), to obtain a reconstruction which is optimal under certain assumptions regarding the noise pertaining to the observed image features [25]: If the image error is zero-mean Gaussian, then BA is the Maximum Likelihood Estimator. Its name refers to the\" bundles\" of light rays originating from each 3D feature and converging on each camera centre, which are adjusted optimally with respect to both structure and viewing parameters. BA amounts to minimizing the reprojection error between the observed and predicted image points, which is expressed as the sum of squares of a number of nonlinear real-valued functions. Thus, the minimization is achieved using non-linear least squares algorithms [4, 18], of which the Levenberg-Marquardt (LM) has proven to be the most successful due to its use of an effective damping strategy that lends it the ability to converge promptly from a wide range of initial guesses [11]. By iteratively linearizing the function to be minimized in the neighborhood of the current estimate, the LM algorithm involves the solution of linear systems known as the normal equations \u2026",
            "Abstract entirety": 0,
            "Author pub id": "4YYxk1IAAAAJ:u5HHmVD_uO8C",
            "Publisher": "Technical Report 340, Institute of Computer Science-FORTH, Heraklion, Crete, Greece"
        },
        {
            "Title": "Robust and efficient event detection for the monitoring of automated processes",
            "Publication year": 2006,
            "Publication url": "https://digital-library.theiet.org/content/conferences/10.1049/cp_20060573",
            "Abstract": "We present a new approach for the detection of events in image sequences. Our method relies on a number of logical sensors that can be defined over specific regions of interest in the viewed scene. These sensors measure time varying image properties that can be attributed to primitive events of interest. Thus, the logical sensors can be viewed as a means to transform image data to a set of symbols that can assist event detection and activities interpretation. On top of these elementary sensors, temporal and logical aggregation mechanisms are used to define hierarchies of progressively more complex sensors, able to detect events having more complex semantics. Finally, scenario verification mechanisms are employed to achieve process monitoring, by checking whether events occur according to a predetermined order. The proposed framework has been tested and validated in an application involving \u2026",
            "Abstract entirety": 0,
            "Author pub id": "4YYxk1IAAAAJ:7PzlFSSx8tAC",
            "Publisher": "IET Digital Library"
        },
        {
            "Title": "Automated Generation of Parametric BIMs based on Hybrid Video and Laser Scanning Data",
            "Publication year": 2009,
            "Publication url": "https://www.researchgate.net/profile/Ioannis-Brilakis/publication/269691272_Automated_Generation_of_Parametric_BIMs_based_on_Hybrid_Video_and_Laser_Scanning_Data/links/5645eb5108ae9f9c13e7246e/Automated-Generation-of-Parametric-BIMs-based-on-Hybrid-Video-and-Laser-Scanning-Data.pdf",
            "Abstract": "Only very few constructed facilities today have a complete record of as-built information. With growing use of Building Information Modelling, as-built records are improving, but it is estimated that more than a century will pass before guidelines that require as-built data modelling will be implemented for the majority of constructed facilities. This will still not address the stock of existing buildings. A technical solution for scanning buildings and compiling Building Information Models is needed. However, this is a multidisciplinary problem, requiring expertise in scanning, computer vision and videogrammetry, machine learning, and parametric object modelling. This paper outlines the technical approach adopted by a consortium of researchers that gathered to tackle the ambitious goal of automating as-built modelling. The top level framework of the proposed solution is presented, and each process, input and output is explained, along with the steps needed to validate them.",
            "Abstract entirety": 1,
            "Author pub id": "4YYxk1IAAAAJ:BqipwSGYUEgC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Article 2 (30 pages)-SBA: A Software Package for Generic Sparse Bundle Adjustment",
            "Publication year": 2010,
            "Publication url": "https://scholar.google.com/scholar?cluster=8029803019930097544&hl=en&oi=scholarr",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "4YYxk1IAAAAJ:B3FOqHPlNUQC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Large-scale, metric structure from motion for unordered light fields",
            "Publication year": 2019,
            "Publication url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Nousias_Large-Scale_Metric_Structure_From_Motion_for_Unordered_Light_Fields_CVPR_2019_paper.html",
            "Abstract": "This paper presents a large scale, metric Structure from Motion (SfM) pipeline for generalised cameras with overlapping fields-of-view, and demonstrates it using Light Field (LF) images. We build on recent developments in algorithms for absolute and relative pose recovery for generalised cameras and couple them with multi-view triangulation in a robust framework that advances the state-of-the-art on 3D reconstruction from LFs in several ways. First, our framework can recover the scale of a scene. Second, it is concerned with unordered sets of LF images, meticulously determining the order in which images should be considered. Third, it can scale to datasets with hundreds of LF images. Finally, it recovers 3D scene structure while abstaining from triangulating using very small baselines. Our approach outperforms the state-of-the-art, as demonstrated by real-world experiments with variable size datasets.",
            "Abstract entirety": 1,
            "Author pub id": "4YYxk1IAAAAJ:LPZeul_q3PIC",
            "Publisher": "Unknown"
        },
        {
            "Title": "The design and implementation of a generic sparse bundle adjustment software package based on the levenberg-marquardt algorithm (Technical Report 340). Institute of Computer Science-FORTH, Heraklion, Crete, Greece",
            "Publication year": 2004,
            "Publication url": "https://scholar.google.com/scholar?cluster=12223049909236900845&hl=en&oi=scholarr",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "4YYxk1IAAAAJ:V3AGJWp-ZtQC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Recover: photorealistic 3D reconstruction of perspective paintings and pictures",
            "Publication year": 2007,
            "Publication url": "http://users.ics.forth.gr/~lourakis/publ/2007_eva.pdf",
            "Abstract": "This paper presents developments concerning RECOVER, a co-operative project funded by the Commission of the European Union. Within RECOVER, techniques that facilitate the semi-automatic reconstruction of scenes depicted in perspective paintings and images are being explored. Starting with a single perspective picture, these techniques rely on a limited amount of interactive user input to recover a 3D textured graphical model corresponding to the depicted scene. Such 3D models can serve as the digital content for real-time virtual reality applications which improve the accessibility and visibility of cultural resources. Moreover, they can be employed in applications such as video games, 3D photography, digital visualization, art history study, visual metrology, forensics, etc.",
            "Abstract entirety": 1,
            "Author pub id": "4YYxk1IAAAAJ:r0BpntZqJG4C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Efficient absolute orientation revisited",
            "Publication year": 2018,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/8594296/",
            "Abstract": "Absolute orientation estimation is the determination of the similarity transformation between two sets of corresponding 3D points, a task arising frequently in computer vision and robotics. We have recently proposed an absolute orientation algorithm based on the Fast Optimal Attitude Matrix (FOAM) algorithm from astronautics and demonstrated that it is more efficient computationally compared to widely-used approaches involving costly eigenand singular-value matrix decompositions. In this work, we compare our FOAM-based solution with several more algorithms derived from attitude estimation techniques and show that further computational savings are possible by employing an algorithm grounded on the Optimal Linear Attitude Estimator (OLAE) method.",
            "Abstract entirety": 1,
            "Author pub id": "4YYxk1IAAAAJ:4fKUyHm3Qg0C",
            "Publisher": "IEEE"
        },
        {
            "Title": "Efficient 3D camera matchmoving using markerless, segmentation-free plane tracking",
            "Publication year": 2003,
            "Publication url": "https://ics.forth.gr/cvrl/publications/tech_reports/2003_09_tr324_forth_camera_tracking.pdf",
            "Abstract": "Camera matchmoving is an application involving synthesis of real scenes and artificial objects, in which the goal is to insert computer-generated graphical 3D objects into live-action footage depicting unmodeled, arbitrary scenes. Graphical objects should be inserted in a way so that they appear to move as if they were a part of the real scene. Seamless, convincing insertion of graphical objects calls for accurate 3D camera motion tracking (ie pose estimation), stable enough over extended sequences so as to avoid the problems of jitter and drift in the location and appearance of objects with respect to the real scene. Additionally, the placement of the objects with respect to the real scene often requires the availability of some 3D geometry information; for instance, accurate 3D reconstruction of a few guiding control points is in most cases sufficient. Matchmoving finds several important applications in augmented reality as well as virtual studio shooting and the creation of special effects in the post-production/filmmaking industry [40]. To provide the versatility required by such applications, very demanding camera tracking requirements, both in terms of accuracy and speed, are imposed [4].Optical and electromechanical camera tracking are technologies that have successfully proven themselves in applications such as live TV broadcasting [41]. Nevertheless, apart from suffering from range limitations, such technologies call for special modifications of the environment that render them inapplicable for tracking in unprepared, unstructured scenes, large scale environments or archive footage. Being non-intrusive, passive and capable of covering large \u2026",
            "Abstract entirety": 0,
            "Author pub id": "4YYxk1IAAAAJ:M3ejUd6NZC8C",
            "Publisher": "Unknown"
        },
        {
            "Title": "An efficient solution to absolute orientation",
            "Publication year": 2016,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/7900229/",
            "Abstract": "The absolute orientation problem arises often in vision and robotics. Despite that robust algorithmic solutions exist for quite some time, they all rely on matrix factorizations such as eigen or singular value decomposition. These factorizations are relatively expensive to compute, therefore might become a performance bottleneck when absolute orientation needs to be repeatedly computed on low-end hardware. The issue is exacerbated by implementations relying on standard numerical software libraries like LAPACK, since the linear algebra factorization routines they include are optimized for large matrices and thus are not the most efficient choice for small ones. Based on an attitude estimation algorithm originating from astronautics, this paper proposes a direct, factorization-free solution to the absolute orientation problem that is both computationally efficient and numerically accurate. Results from an experimental \u2026",
            "Abstract entirety": 0,
            "Author pub id": "4YYxk1IAAAAJ:u9iWguZQMMsC",
            "Publisher": "IEEE"
        },
        {
            "Title": "3D object pose refinement in range images",
            "Publication year": 2015,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-319-20904-3_25",
            "Abstract": "Estimating the pose of objects from range data is a problem of considerable practical importance for many vision applications. This paper presents an approach for accurate and efficient 3D pose estimation from 2.5D range images. Initialized with an approximate pose estimate, the proposed approach refines it so that it accurately accounts for an acquired range image. This is achieved by using a hypothesize-and-test scheme that combines Particle Swarm Optimization (PSO) and graphics-based rendering to minimize a cost function of object pose that quantifies the misalignment between the acquired and a hypothesized, rendered range image. Extensive experimental results demonstrate the superior performance of the approach compared to the Iterative Closest Point (ICP) algorithm that is commonly used for pose refinement.",
            "Abstract entirety": 1,
            "Author pub id": "4YYxk1IAAAAJ:CHSYGLWDkRkC",
            "Publisher": "Springer, Cham"
        },
        {
            "Title": "levmar: Levenberg-marquardt nonlinear least squares algorithms in C/C++.[web page] http://www. ics. forth. gr/~ lourakis/levmar",
            "Publication year": 2004,
            "Publication url": "https://scholar.google.com/scholar?cluster=10575738628371810720&hl=en&oi=scholarr",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "4YYxk1IAAAAJ:xtRiw3GOFMkC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Model-based pose estimation for rigid objects",
            "Publication year": 2013,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-642-39402-7_9",
            "Abstract": "Determining the pose of objects appearing in images is a problem encountered often in several practical applications. The most effective strategy for dealing with this challenge is to proceed according to the model-based paradigm, which involves building 3D models of objects and then determining object poses by fitting their models to new images with the aid of detected features. This paper proposes a model-based approach for estimating the full pose of known objects from natural point features. The method employs a projective imaging model and incorporates reliable automatic mechanisms for pose initialization and convergence. Furthermore, it is extendable to multiple cameras without the need to perform multi-view matching and relies on sparse structure from motion techniques for the construction of object models offline. Experimental results demonstrate its accuracy and robustness.",
            "Abstract entirety": 1,
            "Author pub id": "4YYxk1IAAAAJ:SeFeTyx0c_EC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "sba: A generic sparse bundle adjustment C/C++ package based on the Levenberg-Marquardt algorithm",
            "Publication year": 2008,
            "Publication url": "https://scholar.google.com/scholar?cluster=8740668433474445161&hl=en&oi=scholarr",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "4YYxk1IAAAAJ:5nxA0vEk-isC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Pose Estimation of a Moving Camera with Low-cost, multi-GNSS Devices",
            "Publication year": 2020,
            "Publication url": "https://www.researchgate.net/profile/Christos-Pikridas/amp",
            "Abstract": "Without additional prior information, the pose of a camera estimated with computer vision techniques is expressed in a local coordinate frame attached to the camera\u2019s initial location. Albeit sufficient in many cases, such an arbitrary representation is not convenient for employment in certain applications and has to be transformed to a coordinate system external to the camera before further use. Assuming a camera that is firmly mounted on a moving platform, this paper describes a method for continuously tracking the pose of that camera in a projected coordinate system. By combining exterior orientation from a known target with incremental pose changes inferred from accurate multi-GNSS positioning, the full 6 DoF pose of the camera is updated with low processing overhead and without requiring the continuous visual tracking of ground control points. Experimental results of applying the proposed method to a moving vehicle and a mobile port crane are reported, demonstrating its efficacy and potential.",
            "Abstract entirety": 1,
            "Author pub id": "4YYxk1IAAAAJ:kRWSkSYxWN8C",
            "Publisher": "https://www.int-arch-photogramm-remote-sens-spatial-inf-sci.net/XLIII-B2-2020/55/2020/"
        },
        {
            "Title": "Tracking skin-colored objects in real-time",
            "Publication year": 2005,
            "Publication url": "https://books.google.com/books?hl=en&lr=&id=JNEn23UyHuAC&oi=fnd&pg=PA77&dq=info:LONBKna64JIJ:scholar.google.com&ots=yov_9g7itc&sig=8Ai5_i534CHLynKkheAF4xLpoH8",
            "Abstract": "Locating and tracking objects of interest in a temporal sequence of images constitutes an essential building block of many vision systems. In particular, techniques for effectively and efficiently tracking the human body, either in part or as a whole, have received considerable attention in the context of applications such as face, gesture and gait recognition, markerless human motion capture, behavior and action interpretation, perceptual user interfaces, intelligent surveillance, etc. In such settings, vision-based tracking needs to provide answers to the following fundamental questions. First, how is a human modeled and how are instances of the employed model detected in an image? Second, how are instances of the detected model associated temporally in sequences of images?Being a complex, non-rigid structure with many degrees of freedom, the human body is intricate to model. This is reflected on the models that have been employed in the literature for human tracking, whose type and complexity vary dramatically (Gavrila, 1999; DeCarlo & Metaxas, 2000; Delamarre & Faugeras, 2001; Pl\u00e4nkers & Fua, 2001), depending heavily on the requirements of the application domain under consideration. For example, tracking people in an indoors environment in the context of a surveillance application has completely different modeling requirements compared to tracking the fingers of a hand for sign language interpretation. Many visual cues like color, shading, edges, texture, motion, depth and their combinations have been employed as the basis for modeling of human body parts. Among those, skin color is very effective towards detecting the \u2026",
            "Abstract entirety": 0,
            "Author pub id": "4YYxk1IAAAAJ:Se3iqnhoufwC",
            "Publisher": "Advanced Robotic Systems International"
        },
        {
            "Title": "Model-based visual tracking of orbiting satellites using edges",
            "Publication year": 2017,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/8206228/",
            "Abstract": "Estimating the pose of orbiting satellites is a key prerequisite for supporting autonomous proximity operations in space. This work presents a monocular 3D tracking algorithm that tracks edges with the aid of an arbitrary 3D mesh model assumed to capture a satellite's shape. The proposed tracker propagates a pose hypothesis between successive frames, using it first to render a depth image and then refining it according to partial matches established between depth and intensity edges. Edge matching relies on fast, local 1D searches along the depth gradient direction. The tracker does not require any pre-processing of the 3D model nor does it make any assumptions regarding its characteristics, as is often the case for other approaches. It is also robust to parts of the tracked satellite being out of view, occluded, shadowed or visually undetected. Experimental results evaluating the accuracy of the tracker and \u2026",
            "Abstract entirety": 0,
            "Author pub id": "4YYxk1IAAAAJ:738O_yMBCRsC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Markerless Visual Tracking of a Container Crane Spreader",
            "Publication year": 2021,
            "Publication url": "https://openaccess.thecvf.com/content/ICCV2021W/CVinHRC/html/Lourakis_Markerless_Visual_Tracking_of_a_Container_Crane_Spreader_ICCVW_2021_paper.html",
            "Abstract": "Crane systems play a crucial role in container transport logistics. This paper presents an approach for visually tracking the position and orientation in 3D space of a container crane spreader. An initial pose estimate is first employed to render a 3D triangle mesh model of the spreader as a wireframe with hidden lines removed. The initial pose is then refined so that the visible lines of the wireframe match the straight line segments detected in an input image. Line segment matching relies on fast, local one-dimensional searches along a segment's normal direction. Matched line segments yield constraints on the spreader motion which are processed with robust parameter estimation techniques that safeguard against outliers stemming from mismatches. The tracker automatically determines the visibility of segments, without making limiting assumptions regarding the spreader's 3D mesh model. It is also robust to parts of the tracked spreader being out of view, occluded, shadowed or simply undetected. Experimental results demonstrating the tracker's performance are additionally included.",
            "Abstract entirety": 1,
            "Author pub id": "4YYxk1IAAAAJ:AXPGKjj_ei8C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Enforcing Scene Constraints in Single View Reconstruction.",
            "Publication year": 2007,
            "Publication url": "https://diglib.eg.org/xmlui/bitstream/handle/10.2312/egs.20071030.045-048/045-048.pdf?sequence=1",
            "Abstract": "Three-dimensional reconstruction from a single view is an under-constrained process that relies critically upon the availability of prior knowledge about the imaged scene. This knowledge is assumed to be supplied by a user in the form of geometric constraints such as coplanarity, parallelism, perpendicularity, etc, based on his/her interpretation of the scene. In the presence of noise, however, most of the existing methods yield reconstructions that only approximately satisfy the supplied geometric constraints. This paper proposes a novel single view reconstruction method that provides reconstructions which exactly satisfy all user-supplied constraints. This is achieved by first obtaining a preliminary reconstruction and then refining it in an extendable, constrained optimization framework.",
            "Abstract entirety": 1,
            "Author pub id": "4YYxk1IAAAAJ:dhFuZR0502QC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Toward automated generation of parametric BIMs based on hybrid video and laser scanning data",
            "Publication year": 2010,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S1474034610000509",
            "Abstract": "Only very few constructed facilities today have a complete record of as-built information. Despite the growing use of Building Information Modelling and the improvement in as-built records, several more years will be required before guidelines that require as-built data modelling will be implemented for the majority of constructed facilities, and this will still not address the stock of existing buildings. A technical solution for scanning buildings and compiling Building Information Models is needed. However, this is a multidisciplinary problem, requiring expertise in scanning, computer vision and videogrammetry, machine learning, and parametric object modelling. This paper outlines the technical approach proposed by a consortium of researchers that has gathered to tackle the ambitious goal of automating as-built modelling as far as possible. The top level framework of the proposed solution is presented, and each \u2026",
            "Abstract entirety": 0,
            "Author pub id": "4YYxk1IAAAAJ:4DMP91E08xMC",
            "Publisher": "Elsevier"
        },
        {
            "Title": "Modified Rodrigues parameters: an efficient representation of orientation in 3D vision and graphics",
            "Publication year": 2018,
            "Publication url": "https://link.springer.com/article/10.1007/s10851-017-0765-x",
            "Abstract": "Modified Rodrigues parameters (MRPs) are triplets in  bijectively and rationally mapped to quaternions through stereographic projection. We present here a compelling case for MRPs as a minimal degree-of-freedom parameterization of orientation through novel solutions to prominent problems in the fields of 3D vision and computer graphics. In our primary contribution, we show that the derivatives of a unit quaternion in terms of its MRPs are simple polynomial expressions of its scalar and vector part. Furthermore, we show that updates to unit quaternions from perturbations in parameter space can be computed without explicitly invoking the parameters in the computations. Based on the former, we introduce a novel approach for designing orientation splines by configuring their back-projections in 3D space. Finally, in the general topic of nonlinear optimization for geometric vision, we run performance \u2026",
            "Abstract entirety": 0,
            "Author pub id": "4YYxk1IAAAAJ:K3LRdlH-MEoC",
            "Publisher": "Springer US"
        },
        {
            "Title": "Using geometric constraints for matching disparate stereo views of 3D scenes containing planes",
            "Publication year": 2000,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/905366/",
            "Abstract": "Several vision tasks rely upon the availability of sets of corresponding features among images. This paper presents a method which, given some corresponding features in two stereo images, addresses the problem of matching them with features extracted from a second stereo pair captured from a distant viewpoint. The proposed method is based on the assumption that the viewed scene contains two planar surfaces and exploits geometric constraints that are imposed by the existence of these planes to predict the location of image features in the second stereo pair. The resulting scheme handles point and line features in a unified manner and is capable of successfully matching features extracted from stereo pairs acquired from considerably different viewpoints. Experimental results from a prototype implementation demonstrate the effectiveness of the approach.",
            "Abstract entirety": 1,
            "Author pub id": "4YYxk1IAAAAJ:YOwf2qJgpHMC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Binocular hand tracking and reconstruction based on 2D shape matching",
            "Publication year": 2006,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/1698869/",
            "Abstract": "This paper presents a method for real-time 3D hand tracking in images acquired by a calibrated, possibly moving stereoscopic rig. The proposed method consists of a collection of techniques that enable the modeling and detection of hands, their temporal association in image sequences, the establishment of hand correspondences between stereo images and the 3D reconstruction of their contours. Building upon our previous research on color-based, 2D skin-color tracking, the 3D hand tracker is developed through the coupling of the results of two 2D skin-color trackers that run independently on the two video streams acquired by a stereoscopic system. The proposed method runs in real time on a conventional Pentium 4 processor when operating on 320times240 images. Representative experimental results are also presented",
            "Abstract entirety": 1,
            "Author pub id": "4YYxk1IAAAAJ:_kc_bZDykSQC",
            "Publisher": "IEEE"
        },
        {
            "Title": "levmar: Levenberg-Marquardt nonlinear least squares algorithms in C/C++",
            "Publication year": 2004,
            "Publication url": "https://ci.nii.ac.jp/naid/10018472159/",
            "Abstract": "CiNii \u8ad6\u6587 - levmar : Levenberg-Marquardt nonlinear least squares algorithms in C/C++ CiNii \n\u56fd\u7acb\u60c5\u5831\u5b66\u7814\u7a76\u6240 \u5b66\u8853\u60c5\u5831\u30ca\u30d3\u30b2\u30fc\u30bf[\u30b5\u30a4\u30cb\u30a3] \u65e5\u672c\u306e\u8ad6\u6587\u3092\u3055\u304c\u3059 \u5927\u5b66\u56f3\u66f8\u9928\u306e\u672c\u3092\u3055\u304c\u3059 \n\u65e5\u672c\u306e\u535a\u58eb\u8ad6\u6587\u3092\u3055\u304c\u3059 \u65b0\u898f\u767b\u9332 \u30ed\u30b0\u30a4\u30f3 English \u691c\u7d22 \u3059\u3079\u3066 \u672c\u6587\u3042\u308a \u3059\u3079\u3066 \u672c\u6587\u3042\u308a \u9589\u3058\u308b \n\u30bf\u30a4\u30c8\u30eb \u8457\u8005\u540d \u8457\u8005ID \u8457\u8005\u6240\u5c5e \u520a\u884c\u7269\u540d ISSN \u5dfb\u53f7\u30da\u30fc\u30b8 \u51fa\u7248\u8005 \u53c2\u8003\u6587\u732e \u51fa\u7248\u5e74 \u5e74\u304b\u3089 \u5e74\n\u307e\u3067 \u691c\u7d22 \u691c\u7d22 \u691c\u7d22 CiNii\u7a93\u53e3\u696d\u52d9\u306e\u518d\u958b\u306b\u3064\u3044\u3066 levmar : Levenberg-Marquardt nonlinear \nleast squares algorithms in C/C++ LOURAKIS MIA \u88ab\u5f15\u7528\u6587\u732e: 1\u4ef6 \u8457\u8005 LOURAKIS MIA \u53ce\u9332\n\u520a\u884c\u7269 http://www.ics.forth.gr/\u301clourakis/levmar/ http://www.ics.forth.gr/\u301clourakis/levmar/, 2004 \n\u88ab\u5f15\u7528\u6587\u732e: 1\u4ef6\u4e2d 1-1\u4ef6\u3092 \u8868\u793a 1 \u8868\u60c5\u5909\u52d5\u3092\u8a31\u5bb9\u3057\u305f\u5b9f\u6642\u9593\u982d\u90e8\u59ff\u52e2\u63a8\u5b9a\u306e\u305f\u3081\u306e\u500b\u4eba\u9593\u304a\u3088\u3073\n\u500b\u4eba\u5185\u5909\u52d5\u306b\u5bfe\u3059\u308b\u9854\u5f62\u72b6\u63a8\u5b9a \u83c5\u91ce \u88d5\u4ecb , \u4f50\u85e4 \u6d0b\u4e00 \u60c5\u5831\u51e6\u7406\u5b66\u4f1a\u7814\u7a76\u5831\u544a. CVIM, [\u30b3\u30f3\u30d4\u30e5\u30fc\u30bf\n\u30d3\u30b8\u30e7\u30f3\u3068\u30a4\u30e1\u30fc\u30b8\u30e1\u30c7\u30a3\u30a2] 156, 179-186, 2006-11-09 \u53c2\u8003\u6587\u732e15\u4ef6 Tweet \u5404\u7a2e\u30b3\u30fc\u30c9 NII\u8ad6\u6587ID() \u2026",
            "Abstract entirety": 0,
            "Author pub id": "4YYxk1IAAAAJ:9yKSN-GCB0IC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Camera self-calibration using the Kruppa equations and the SVD of the fundamental matrix: The case of varying intrinsic parameters",
            "Publication year": 2000,
            "Publication url": "https://hal.inria.fr/inria-00072742/",
            "Abstract": "Estimation of the camera intrinsic calibration parameters is a prerequisite to a wide variety of vision tasks related to motion and stereo analysis. A major breakthrough related to the intrinsic calibration problem was the introduction in the early nineties of the autocalibration paradigm, according to which calibration is achieved not with the aid of a calibration pattern but by observing a number of image features in a set of successive images. Until recently, however, most research efforts have been focused on applying the autocalibration paradigm to estimating constant intrinsic calibration parameters. Therefore, such approaches are inapplicable to cases where the intrinsic parameters undergo continuous changes due to focusing and/or zooming. In this paper, our previous work for autocalibration in the case of constant camera intrinsic parameters is extended and a novel autocalibration method capable of handling variable intrinsic parameters is proposed. The method relies upon the Singular Value Decomposition of the fundamental matrix, which leads to a particularly simple form of the Kruppa equations. In contrast to the classical formulation that yields an over-determined system of constraints, a purely algebraic derivation is proposed here which provides a straightforward answer to the problem of determining which constraints to employ among the set of available ones. Additionally, the new formulation does not employ the epipoles, which are known to be difficult to estimate accurately. The intrinsic calibration parameters are recovered from the developed constraints through a nonlinear minimization scheme that explicitly takes into consideration \u2026",
            "Abstract entirety": 0,
            "Author pub id": "4YYxk1IAAAAJ:_FxGoFyzp5QC",
            "Publisher": "INRIA"
        },
        {
            "Title": "Countering drift in Visual Odometry for planetary rovers by registering boulders in ground and orbital images",
            "Publication year": 2015,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/7353362/",
            "Abstract": "Visual Odometry (VO) is a proven technology for planetary exploration rovers, facilitating their localization with a small error over medium-sized trajectories. However, due to VO's incremental mode of operation, its estimation error accumulates over time, resulting in considerable drift for long trajectories. This paper proposes a global localization method that counters VO drift by matching boulders extracted from overhead and ground images and using them periodically to relocalize the rover and refine VO estimates. The performance of the proposed method is evaluated with the aid of overhead imagery of different resolutions. Experimental results demonstrate that a very terse representation, consisting of approximate boulder locations only, suffices for significantly improving the accuracy of VO over long traverses.",
            "Abstract entirety": 1,
            "Author pub id": "4YYxk1IAAAAJ:dshw04ExmUIC",
            "Publisher": "IEEE"
        },
        {
            "Title": "\u0391utomated Generation of Parametric BIMs based on Hybrid Video and Laser Scanning Data",
            "Publication year": 2009,
            "Publication url": "http://gnosis.library.ucy.ac.cy/handle/7/45228",
            "Abstract": "\u0391utomated Generation of Parametric BIMs based on Hybrid Video and Laser Scanning \nData Toggle navigation English \u0395\u03bb\u03bb\u03b7\u03bd\u03b9\u03ba\u03ac English English \u0395\u03bb\u03bb\u03b7\u03bd\u03b9\u03ba\u03ac Login Toggle \nnavigation View Item Home \u0394\u03b7\u03bc\u03bf\u03c3\u03b9\u03b5\u03cd\u03c3\u03b5\u03b9\u03c2 \u03a0\u039a / UCY Publications 007 \u03a0\u03bf\u03bb\u03c5\u03c4\u03b5\u03c7\u03bd\u03b9\u03ba\u03ae \u03a3\u03c7\u03bf\u03bb\u03ae / \nFaculty of Engineering \u03a4\u03bc\u03ae\u03bc\u03b1 \u03a0\u03bf\u03bb\u03b9\u03c4\u03b9\u03ba\u03ce\u03bd \u039c\u03b7\u03c7\u03b1\u03bd\u03b9\u03ba\u03ce\u03bd \u03ba\u03b1\u03b9 \u039c\u03b7\u03c7\u03b1\u03bd\u03b9\u03ba\u03ce\u03bd \u03a0\u03b5\u03c1\u03b9\u03b2\u03ac\u03bb\u03bb\u03bf\u03bd\u03c4\u03bf\u03c2 / \nDepartment of Civil and Environmental Engineering View Item Home \u0394\u03b7\u03bc\u03bf\u03c3\u03b9\u03b5\u03cd\u03c3\u03b5\u03b9\u03c2 \u03a0\u039a / \nUCY Publications 007 \u03a0\u03bf\u03bb\u03c5\u03c4\u03b5\u03c7\u03bd\u03b9\u03ba\u03ae \u03a3\u03c7\u03bf\u03bb\u03ae / Faculty of Engineering \u03a4\u03bc\u03ae\u03bc\u03b1 \u03a0\u03bf\u03bb\u03b9\u03c4\u03b9\u03ba\u03ce\u03bd \n\u039c\u03b7\u03c7\u03b1\u03bd\u03b9\u03ba\u03ce\u03bd \u03ba\u03b1\u03b9 \u039c\u03b7\u03c7\u03b1\u03bd\u03b9\u03ba\u03ce\u03bd \u03a0\u03b5\u03c1\u03b9\u03b2\u03ac\u03bb\u03bb\u03bf\u03bd\u03c4\u03bf\u03c2 / Department of Civil and Environmental \nEngineering View Item Conference Object \u0391utomated Generation of Parametric BIMs based \non Hybrid Video and Laser Scanning Data Thumbnail Date 2009 Author Brilakis, Ioannis \nLourakis, Manolis Sacks, Rafael Savarese, Silvio ORCID logo Christodoulou, Symeon E. \nTeizer, Jochen Makhmalbaf, Atefe Source European in \u2026",
            "Abstract entirety": 0,
            "Author pub id": "4YYxk1IAAAAJ:5Ul4iDaHHb8C",
            "Publisher": "Unknown"
        },
        {
            "Title": "SPARTAN: Vision-based Autonomous Navigation System for Fast Traversal Planetary Rovers",
            "Publication year": 2018,
            "Publication url": "http://users.ics.forth.gr/~zabulis/2018_isairas.pdf",
            "Abstract": "Autonomous navigation of planetary exploration rovers has become a key element to attain mission success, as it can significantly improve the length of daily traverses, particularly when driving in unknown areas away from the lander. Future missions, such as the Mars Sample Return or the Lunar Polar Sample Return, already demand longer and faster traversals compared to past missions to maximize their scientific return and reduce operational costs and risks. Autonomous navigation is usually based on computer vision due to the passive mode of operation, simple hardware, small form factor and low power consumption of camera sensors. Computer vision nevertheless entails a rather high computational burden which puts a strain on the limited computational resources available onboard these rovers. This paper describes SPARTAN, an optimized, hardware embedded vision system for autonomous navigation of planetary rovers that meets the high demands of future missions requiring large and fast traversals.",
            "Abstract entirety": 1,
            "Author pub id": "4YYxk1IAAAAJ:vRqMK49ujn8C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Biosensors and  Internet of Things in smart healthcare applications: challenges  and  opportunities",
            "Publication year": 2019,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/B9780128153697000021",
            "Abstract": "The use of health and well-being monitoring technologies has been steadily increasing and such systems can now be found in smart homes, age-friendly workplaces, public spaces, and elsewhere. These monitoring technologies employ a wide variety of off-the-shelf smart sensors and medical devices to support functional, physiological, and behavioral monitoring and to address social interaction aspects of daily life. These systems focus either on specific health-related conditions or on supporting the more general aims of comfort, well-being, and quality of life. However, there remain several technological (interoperability, expandability, etc.) and societal (cost, privacy, etc.) challenges to be addressed before smart biosensor systems are widely adopted.Motivated by the above, this chapter highlights the challenges and opportunities surrounding the application of smart biosensors in healthcare and presents three \u2026",
            "Abstract entirety": 0,
            "Author pub id": "4YYxk1IAAAAJ:fQNAKQ3IYiAC",
            "Publisher": "Elsevier"
        },
        {
            "Title": "Refining single view calibration with the aid of metric scene properties",
            "Publication year": 2007,
            "Publication url": "http://publications.ics.forth.gr/_publications/wscg07.pdf",
            "Abstract": "Intrinsic camera calibration using a single image is possible provided that certain geometric objects such as orthogonal vanishing points and metric homographies can be estimated from the image and give rise to adequate constraints on the sought calibration parameters. In doing so, however, any additional metric information that might be available for the imaged scene is not always straightforward to accommodate. This paper puts forward a method for incorporating into the calibration procedure metric scene information expressed in the form of known segment 3D angles, equal but unknown 3D angles and known 3D length ratios. Assuming the availability of an initial calibration estimate, the proposed method refines the former by numerically minimizing an error term corresponding to the discrepancy between the scene\u2019s known metric properties and the values measured with the aid of the calibration estimate. Sample experimental results demonstrate the improvements in the intrinsic calibration estimates that are achieved by the proposed method.",
            "Abstract entirety": 1,
            "Author pub id": "4YYxk1IAAAAJ:ldfaerwXgEUC",
            "Publisher": "V\u00e1clav Skala-UNION Agency"
        },
        {
            "Title": "A brief description of the Levenberg-Marquardt algorithm implemented by levmar",
            "Publication year": 2005,
            "Publication url": "https://users.ics.forth.gr/~lourakis/levmar/levmar.pdf",
            "Abstract": "The Levenberg-Marquardt (LM) algorithm is an iterative technique that locates the minimum of a function that is expressed as the sum of squares of nonlinear functions. It has become a standard technique for nonlinear least-squares problems and can be thought of as a combination of steepest descent and the Gauss-Newton method. This document briefly describes the mathematics behind levmar, a free LM C/C++ implementation that can be found at http://www. ics. forth. gr/lourakis/levmar.",
            "Abstract entirety": 1,
            "Author pub id": "4YYxk1IAAAAJ:qjMakFHDy7sC",
            "Publisher": "Unknown"
        },
        {
            "Title": "SBA: A software package for generic sparse bundle adjustment",
            "Publication year": 2009,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/1486525.1486527",
            "Abstract": "Bundle adjustment constitutes a large, nonlinear least-squares problem that is often solved as the last step of feature-based structure and motion estimation computer vision algorithms to obtain optimal estimates. Due to the very large number of parameters involved, a general purpose least-squares algorithm incurs high computational and memory storage costs when applied to bundle adjustment. Fortunately, the lack of interaction among certain subgroups of parameters results in the corresponding Jacobian being sparse, a fact that can be exploited to achieve considerable computational savings. This article presents sba, a publicly available C/C++ software package for realizing generic bundle adjustment with high efficiency and flexibility regarding parameterization.",
            "Abstract entirety": 1,
            "Author pub id": "4YYxk1IAAAAJ:u-x6o8ySG0sC",
            "Publisher": "ACM"
        },
        {
            "Title": "FORTH-ICS/TR-324 September 2003",
            "Publication year": 2003,
            "Publication url": "https://scholar.google.com/scholar?cluster=17942027658769235838&hl=en&oi=scholarr",
            "Abstract": "Camera matchmoving is an application involving synthesis of real scenes and artificial objects, in which the goal is to insert computer-generated graphical 3D objects into live-action footage depicting unmodeled, arbitrary scenes. Graphical objects should be inserted in a way so that they appear to move as if they were a part of the real scene. Seamless, convincing insertion of graphical objects calls for accurate 3D camera motion tracking (ie pose estimation), stable enough over extended sequences so as to avoid the problems of jitter and drift in the location and appearance of objects with respect to the real scene. Additionally, the placement of the objects with respect to the real scene often requires the availability of some 3D geometry information; for instance, accurate 3D reconstruction of a few guiding control points is in most cases sufficient. Matchmoving finds several important applications in augmented reality \u2026",
            "Abstract entirety": 0,
            "Author pub id": "4YYxk1IAAAAJ:M3NEmzRMIkIC",
            "Publisher": "Unknown"
        },
        {
            "Title": "The design and implementation of a generic sparse bundle adjustment software package based on the LM algorithm",
            "Publication year": 2004,
            "Publication url": "https://scholar.google.com/scholar?cluster=16794463694272861988&hl=en&oi=scholarr",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "4YYxk1IAAAAJ:1qzjygNMrQYC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Three-dimensional tracking of multiple skin-colored regions by a moving stereoscopic system",
            "Publication year": 2004,
            "Publication url": "https://www.osapublishing.org/abstract.cfm?uri=AO-43-2-366",
            "Abstract": "A system that performs three-dimensional (3D) tracking of multiple skin-colored regions (SCRs) in images acquired by a calibrated, possibly moving stereoscopic rig is described. The system consists of a collection of techniques that permit the modeling and detection of SCRs, the determination of their temporal association in monocular image sequences, the establishment of their correspondence between stereo images, and the extraction of their 3D positions in a world-centered coordinate system. The development of these techniques has been motivated by the need for robust, near-real-time tracking performance. SCRs are detected by use of a Bayesian classifier that is trained with the aid of a novel technique. More specifically, the classifier is bootstrapped with a small set of training data. Then, as new images are being processed, an iterative training procedure is employed to refine the classifier. Furthermore, a \u2026",
            "Abstract entirety": 0,
            "Author pub id": "4YYxk1IAAAAJ:UebtZRa9Y70C",
            "Publisher": "Optical Society of America"
        },
        {
            "Title": "SPARTAN/SEXTANT/COMPASS: advancing space rover vision via reconfigurable platforms",
            "Publication year": 2015,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-319-16214-0_44",
            "Abstract": "Targeting enhanced navigational speed and autonomy for the space exploration rovers, researchers are gradually turning to reconfigurable computing and FPGAs. High-density space-grade FPGAs will enable the acceleration of high-complexity computer vision algorithms for improving the localization and mapping functions of the future Mars rovers. In the projects SPARTAN/SEXTANT/COMPASS of the European Space Agency, we study the potential use of FPGAs for implementing a variety of stereo correspondence, feature extraction, and visual odometry algorithms, all with distinct cost-performance tradeoffs. The most efficient of the developed accelerators will assist the slow space-grade CPU in completing the visual tasks of the rover faster, by one order of magnitude, and thus, will allow the future missions to visit larger areas on Mars. Our work bases on a custom HW/SW co-design methodology \u2026",
            "Abstract entirety": 0,
            "Author pub id": "4YYxk1IAAAAJ:abG-DnoFyZgC",
            "Publisher": "Springer, Cham"
        },
        {
            "Title": "Egomotion estimation using quadruples of collinear image points",
            "Publication year": 2000,
            "Publication url": "https://link.springer.com/chapter/10.1007/3-540-45053-X_53",
            "Abstract": "This paper considers a fundamental problem in visual motion perception, namely the problem of egomotion estimation based on visual input. Many of the existing techniques for solving this problem rely on restrictive assumptions regarding the observer\u2019s motion or even the scene structure. Moreover, they often resort to searching the high dimensional space of possible solutions, a strategy which might be inefficient in terms of computational complexity and exhibit convergence problems if the search is initiated far away from the correct solution. In this work, a novel linear constraint that involves quantities that depend on the egomotion parameters is developed. The constraint is defined in terms of the optical flow vectors pertaining to four collinear image points and is applicable regardless of the egomotion or the scene structure. In addition, it is exact in the sense that no approximations are made for deriving it \u2026",
            "Abstract entirety": 0,
            "Author pub id": "4YYxk1IAAAAJ:qxL8FJ1GzNcC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "Chaining planar homographies for fast and reliable 3d plane tracking",
            "Publication year": 2006,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/1698960/",
            "Abstract": "This paper addresses the problem of tracking a 3D plane over a sequence of images acquired by a free moving camera, a task that is of central importance to a wide variety of vision tasks. A feature-based method is proposed which given a triplet of consecutive images and a plane homography between the first two of them, estimates the homography induced by the same plane between the second and third images, without requiring the plane to be segmented from the rest of the scene. Thus, the proposed method operates by \"chaining\" (i.e. propagating) across frames the image-to-image homographies due to some 3D plane. The chaining operation represents projective space using a \"plane + parallax\" decomposition, which permits the combination of constraints arising from all available point matches, regardless of whether they actually lie on the tracked 3D plane or not. Experimental results are also provided",
            "Abstract entirety": 1,
            "Author pub id": "4YYxk1IAAAAJ:Wp0gIr-vW9MC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Accurate scale factor estimation in 3D reconstruction",
            "Publication year": 2013,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-642-40261-6_60",
            "Abstract": "A well-known ambiguity in monocular structure from motion estimation is that 3D reconstruction is possible up to a similarity transformation, i.e. an isometry composed with isotropic scaling. To raise this ambiguity, it is commonly suggested to manually measure an absolute distance in the environment and then use it to scale a reconstruction accordingly. In practice, however, it is often the case that such a measurement cannot be performed with sufficient accuracy, compromising certain uses of a 3D reconstruction that require the acquisition of true Euclidean measurements. This paper studies three alternative techniques for obtaining estimates of the scale pertaining to a reconstruction and compares them experimentally with the aid of real and synthetic data.",
            "Abstract entirety": 1,
            "Author pub id": "4YYxk1IAAAAJ:ZHo1McVdvXMC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "Automated as-built 3D reconstruction of civil infrastructure using computer vision: Achievements, opportunities, and challenges",
            "Publication year": 2015,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S1474034615000245",
            "Abstract": "Image-based 3D reconstruction of civil infrastructure is an emerging topic that is gaining significant interest both in the scientific and commercial sectors of the construction industry. Reliable computer vision-based algorithms have become available over the last decade and they can now be applied to solve real-life problems in uncontrolled environments. While a large number of such algorithms have been developed by the computer vision and photogrammetry communities, relatively little work has been done to study their performance in the context of infrastructure. This paper aims to analyze the state-of-the-art in image-based 3D reconstruction and categorize existing algorithms according to different metrics that are important for the given purpose. An ideal solution is portrayed to show what the ultimate goal is. This will be followed by identifying gaps in knowledge and highlighting future research topics that could \u2026",
            "Abstract entirety": 0,
            "Author pub id": "4YYxk1IAAAAJ:b0M2c_1WBrUC",
            "Publisher": "Elsevier"
        },
        {
            "Title": "Tracking of human hands and faces through probabilistic fusion of multiple visual cues",
            "Publication year": 2008,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-540-79547-6_4",
            "Abstract": "This paper presents a new approach for real time detection and tracking of human hands and faces in image sequences. The proposed method builds upon our previous research on color-based tracking and extends it towards building a system capable of distinguishing between human hands, faces and other skin-colored regions in the image background. To achieve these goals, the proposed approach allows the utilization of additional information cues including motion information given by means of a background subtraction algorithm, and top-down information regarding the formed image segments such as their spatial location, velocity and shape. All information cues are combined under a probabilistic framework which furnishes the proposed approach with the ability to cope with uncertainty due to noise. The proposed approach runs in real time on a standard, personal computer. The presented \u2026",
            "Abstract entirety": 0,
            "Author pub id": "4YYxk1IAAAAJ:ULOm3_A8WrAC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "Sparse non-linear least squares optimization for geometric vision",
            "Publication year": 2010,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-642-15552-9_4",
            "Abstract": "Several estimation problems in vision involve the minimization of cumulative geometric error using non-linear least-squares fitting. Typically, this error is characterized by the lack of interdependence among certain subgroups of the parameters to be estimated, which leads to minimization problems possessing a sparse structure. Taking advantage of this sparseness during minimization is known to achieve enormous computational savings. Nevertheless, since the underlying sparsity pattern is problem-dependent, its exploitation for a particular estimation problem requires non-trivial implementation effort, which often discourages its pursuance in practice. Based on recent developments in sparse linear solvers, this paper provides an overview of sparseLM, a general-purpose software package for sparse non-linear least squares that can exhibit arbitrary sparseness and presents results from its application to \u2026",
            "Abstract entirety": 0,
            "Author pub id": "4YYxk1IAAAAJ:9ZlFYXVOiuMC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "Project HIPNOS: Case study of high performance avionics for active debris removal in space",
            "Publication year": 2017,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/7987544/",
            "Abstract": "The Clean Space initiative of the European Space Agency (ESA) seeks to decrease the environmental impact of space programmes by focusing, among others, on Active Debris Removal (ADR) and eDeorbit. In this direction, one of the main challenges is to autonomously track and approach a big non-cooperative satellite such as ENVISAT. To achieve the high level of autonomy required in this phase of the ADR mission, vision based navigation will guide a chaser spacecraft in real-time based on high-definition images acquired and processed on-board at high frame-rates. The increased complexity of these computer vision algorithms mandates the development and use of high performance avionics to provide one order of magnitude faster execution than today's conventional space-grade processors. In the context of ESA's project HIPNOS (HIgh Performance avionics solutioN for advanced and complex GNC \u2026",
            "Abstract entirety": 0,
            "Author pub id": "4YYxk1IAAAAJ:Tiz5es2fbqcC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Enriching Pictorial Cultural Content with 3D Models",
            "Publication year": 2007,
            "Publication url": "https://www.torrossa.com/gs/resourceProxy?an=2299577&publisher=FF3888",
            "Abstract": "This paper presents an approach for enriching culture-related pictorial content with 3D models obtained through semi-automatic reconstruction techniques. Starting with a single perspective picture, these techniques rely on a limited amount of interactive user input to recover a 3D textured graphical model corresponding to the depicted scene. Such 3D models constitute geometric scene descriptions and can serve as the digital content for interactive multimedia applications which improve the accessibility and visibility of cultural resources. Moreover, they can be reused in applications such as virtual reality, video games, 3D photography, digital visualization, visual metrology, art history study, etc.",
            "Abstract entirety": 1,
            "Author pub id": "4YYxk1IAAAAJ:bFI3QPDXJZMC",
            "Publisher": "Firenze University Press"
        },
        {
            "Title": "Detection of physical strain and fatigue in industrial environments using visual and non-visual sensors",
            "Publication year": 2021,
            "Publication url": "https://www.researchgate.net/profile/Konstantinos-Papoutsakis/publication/351838538_Detection_of_physical_strain_and_fatigue_in_industrial_environments_using_visual_and_non-visual_sensors/links/60acb20092851ca9dce23226/Detection-of-physical-strain-and-fatigue-in-industrial-environments-using-visual-and-non-visual-sensors.pdf",
            "Abstract": "sustAGE is an ongoing project, developing an Internet of Things ecosystem, including smartphones, smartwatches, environmental sensors and cameras to support elderly workers in industrial environments, such a car manufacturing factory. In this context, we briefly describe non-obtrusive method for assessing the physical strain of workers using visual data and a method for detecting worker fatigue using heart rate data. The results of both methods are utilized by the recommendation system developed in sustAGE to support preventive actions towards work-related musculo-skeletal dis-orders and mental fatigue and to promote occupational safety.",
            "Abstract entirety": 1,
            "Author pub id": "4YYxk1IAAAAJ:Mojj43d5GZwC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Tracking multiple colored blobs with a moving camera",
            "Publication year": 2005,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/1467577/",
            "Abstract": "This paper concerns a method for tracking multiple blobs exhibiting certain color distributions in images acquired by a possibly moving camera. The method encompasses a collection of techniques that enable modeling and detecting the blobs possessing the desired color distribution(s), as well as inferring their temporal association across image sequences. Appropriately colored blobs are detected with a Bayesian classifier, which is bootstrapped with a small set of training data. Then, an online iterative training procedure is employed to refine the classifier using additional training images. Online adaptation of color probabilities is used to enable the classifier to cope with illumination changes. Tracking over time is realized through a novel technique, which can handle multiple colored blobs. Such blobs may move in complex trajectories and occlude each other in the field of view of a possibly moving camera, while \u2026",
            "Abstract entirety": 0,
            "Author pub id": "4YYxk1IAAAAJ:MXK_kJrjxJIC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Is Levenberg-Marquardt the most efficient optimization algorithm for implementing bundle adjustment?",
            "Publication year": 2005,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/1544898/",
            "Abstract": "In order to obtain optimal 3D structure and viewing parameter estimates, bundle adjustment is often used as the last step of feature-based structure and motion estimation algorithms. Bundle adjustment involves the formulation of a large scale, yet sparse minimization problem, which is traditionally solved using a sparse variant of the Levenberg-Marquardt optimization algorithm that avoids storing and operating on zero entries. This paper argues that considerable computational benefits can be gained by substituting the sparse Levenberg-Marquardt algorithm in the implementation of bundle adjustment with a sparse variant of Powell's dog leg non-linear least squares technique. Detailed comparative experimental results provide strong evidence supporting this claim",
            "Abstract entirety": 1,
            "Author pub id": "4YYxk1IAAAAJ:u_35RYKgDlwC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Parallel Robust Absolute Orientation on FPGA for Vision and Robotics",
            "Publication year": 2018,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/8617856/",
            "Abstract": "The performance of absolute orientation, a computationally intensive process, plays a key role in a plethora of computer vision and robotics applications. This paper focuses on accelerating the execution of a robust algorithm based on Horn's quaternion solution and presents a HW architecture as well as its FPGA implementation. The proposed design approach relies on the specifics of the algorithm to develop each of its architectural parts by using either low-level Hardware Description Language (HDL) or High Level Synthesis (HLS) descriptions, significantly improving both the design and the time required for development. Combining HDL and HLS described parts leads to an architecture design that exploits parallelism, improves HW utilization and enhances the efficiency of calculations by customizing complicated arithmetic operations. Our implementations on Kintex 7 XC7K325T achieve 61x total speedup \u2026",
            "Abstract entirety": 0,
            "Author pub id": "4YYxk1IAAAAJ:tS2w5q8j5-wC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Detecting Planes In An Uncalibrated Image Pair",
            "Publication year": 2002,
            "Publication url": "https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.673.161&rep=rep1&type=pdf",
            "Abstract": "Plane detection is a prerequisite to a wide variety of vision tasks. This paper proposes a novel method that exploits results from projective geometry to automatically detect planes using two images. Using a set of point and line features that have been matched between images, the method exploits the fact that every pair of a 3D line and a 3D point defines a plane and utilizes an iterative voting scheme for identifying coplanar subsets of the employed feature set. The method does not require camera calibration, circumvents the 3D reconstruction problem, is robust to the existence of mismatched features and is applicable either to stereo or motion sequence images. Sample results from the application of the proposed method to real imagery are also provided.",
            "Abstract entirety": 1,
            "Author pub id": "4YYxk1IAAAAJ:Y0pCki6q_DkC",
            "Publisher": "Unknown"
        },
        {
            "Title": "levmar: Levenberg-marquardt nonlinear least squares algorithms in C/C++(2004)",
            "Publication year": 2009,
            "Publication url": "https://scholar.google.com/scholar?cluster=17316126016522727317&hl=en&oi=scholarr",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "4YYxk1IAAAAJ:kNdYIx-mwKoC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Single-and multi-FPGA acceleration of dense stereo vision for planetary rovers",
            "Publication year": 2019,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/3312743",
            "Abstract": "Increased mobile autonomy is a vital requisite for future planetary exploration rovers. Stereo vision is a key enabling technology in this regard, as it can passively reconstruct in three dimensions the surroundings of a rover and facilitate the selection of science targets and the planning of safe routes. Nonetheless, accurate dense stereo algorithms are computationally demanding. When executed on the low-performance, radiation-hardened CPUs typically installed on rovers, slow stereo processing severely limits the driving speed and hence the science that can be conducted in situ. Aiming to decrease execution time while increasing the accuracy of stereo vision embedded in future rovers, this article proposes HW/SW co-design and acceleration on resource-constrained, space-grade FPGAs. In a top-down approach, we develop a stereo algorithm based on the space sweep paradigm, design its parallel HW \u2026",
            "Abstract entirety": 0,
            "Author pub id": "4YYxk1IAAAAJ:geHnlv5EZngC",
            "Publisher": "ACM"
        },
        {
            "Title": "Evolutionary quasi-random search for hand articulations tracking",
            "Publication year": 2014,
            "Publication url": "http://openaccess.thecvf.com/content_cvpr_2014/html/Oikonomidis_Evolutionary_Quasi-random_Search_2014_CVPR_paper.html",
            "Abstract": "We present a new method for tracking the 3D position, global orientation and full articulation of human hands. Following recent advances in model-based, hypothesize-and-test methods, the high-dimensional parameter space of hand configurations is explored with a novel evolutionary optimization technique specifically tailored to the problem. The proposed method capitalizes on the fact that samples from quasi-random sequences such as the Sobol have low discrepancy and exhibit a more uniform coverage of the sampled space compared to random samples obtained from the uniform distribution. The method has been tested for the problems of tracking the articulation of a single hand (27D parameter space) and two hands (54D space). Extensive experiments have been carried out with synthetic and real data, in comparison with state of the art methods. The quantitative evaluation shows that for cases of limited computational resources, the new approach achieves a speed-up of four (single hand tracking) and eight (two hands tracking) without compromising tracking accuracy. Interestingly, the proposed method is preferable compared to the state of the art either in the case of limited computational resources or in the case of more complex (ie, higher dimensional) problems, thus improving the applicability of the method in a number of application domains.",
            "Abstract entirety": 1,
            "Author pub id": "4YYxk1IAAAAJ:pyW8ca7W8N0C",
            "Publisher": "Unknown"
        },
        {
            "Title": "A system for geometrically constrained single view reconstruction",
            "Publication year": 2008,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-540-79547-6_19",
            "Abstract": "This paper presents an overview of a system for recovering 3D models corresponding to scenes for which only a single perspective image is available. The system encompasses a versatile set of semi-automatic single view reconstruction techniques and couples them with limited interactive user input in order to reconstruct textured 3D graphical models corresponding to the imaged input scenes. Such 3D models can serve as the digital content for supporting interactive multimedia and virtual reality applications. Furthermore, they can support novel applications in areas such as video games, 3D photography, visual metrology, computer-assisted study of art and crime scene reconstruction, etc.",
            "Abstract entirety": 1,
            "Author pub id": "4YYxk1IAAAAJ:maZDTaKrznsC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "A graph-based approach to corner matching using mutual information as a local similarity measure",
            "Publication year": 2004,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/1334386/",
            "Abstract": "Corner matching constitutes a fundamental vision problem that serves as a building block of several important applications. The common approach to dealing with this problem starts by ranking potential matches according to their affinity, which is assessed with the aid of window-based intensity similarity measures. Then, actual matches are established by optimizing global criteria involving all potential matches. This paper puts forward a novel approach for solving the corner matching problem that uses mutual information as a window similarity measure, combined with graph matching techniques for determining a matching of corners that is globally optimal. Experimental results illustrate the effectiveness of the approach.",
            "Abstract entirety": 1,
            "Author pub id": "4YYxk1IAAAAJ:hqOjcs7Dif8C",
            "Publisher": "IEEE"
        },
        {
            "Title": "Using constraint lines for estimating egomotion",
            "Publication year": 2000,
            "Publication url": "https://www.ics.forth.gr/~lourakis/publ/2000_accv_egomotion.pdf",
            "Abstract": "This paper considers the problem of estimating egomotion using visual input, which constitutes a fundamental problem in visual motion analysis. Many of the existing techniques for solving this problem rely on restrictive assumptions regarding the observer\u2019s motion or even the scene structure. In this work, a novel method for egomotion estimation is proposed. The method relies on the observation that optical flow vectors at pairs of points lying on lines through the FOE, exhibit particular geometric properties. Such lines containing the FOE are identified using a robust criterion and the FOE is then located at their point of intersection. The method requires simple computations and employs linear models. Simulations employing synthetic velocity fields as well as experiments with real image sequences demonstrate the performance of the proposed method under varying noise levels and camera motions.",
            "Abstract entirety": 1,
            "Author pub id": "4YYxk1IAAAAJ:aqlVkmm33-oC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Smart sensor based vision system for automated processes",
            "Publication year": 2007,
            "Publication url": "http://old.sztaki.hu/~viharos/homepage/Publications/2007/2007_INTSAR/MultiSens_Viharos_Web.pdf",
            "Abstract": "A new approach is proposed for vision-based sensing and processing for process control and monitoring of automated processes. The proposed approach relies on a number of binary logical sensors defined over specific regions of interest in the viewed scene. On top of these elementary sensors, temporal and logical aggregation mechanisms realize hierarchies of compound logical functions, able to detect complex events. Finally, scenario verification mechanisms are employed to monitor the occurrence order and timing of expected and actual events. The proposed framework has been tested and validated in an application involving monitoring of automated processes, demonstrating that the proposed approach provides a promising concept of vision-based event detection. The described framework is being implemented on the Bi-i standalone cellular vision system which has the potential of replacing several conventional sensors used for process control and fault detection in automation.",
            "Abstract entirety": 1,
            "Author pub id": "4YYxk1IAAAAJ:M05iB0D1s5AC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Detection and fine 3D pose estimation of texture-less objects in RGB-D images",
            "Publication year": 2015,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/7354005/",
            "Abstract": "Despite their ubiquitous presence, texture-less objects present significant challenges to contemporary visual object detection and localization algorithms. This paper proposes a practical method for the detection and accurate 3D localization of multiple texture-less and rigid objects depicted in RGB-D images. The detection procedure adopts the sliding window paradigm, with an efficient cascade-style evaluation of each window location. A simple pre-filtering is performed first, rapidly rejecting most locations. For each remaining location, a set of candidate templates (i.e. trained object views) is identified with a voting procedure based on hashing, which makes the method's computational complexity largely unaffected by the total number of known objects. The candidate templates are then verified by matching feature points in different modalities. Finally, the approximate object pose associated with each detected \u2026",
            "Abstract entirety": 0,
            "Author pub id": "4YYxk1IAAAAJ:KxtntwgDAa4C",
            "Publisher": "IEEE"
        },
        {
            "Title": "Autonomous Visual Navigation for Planetary Exploration Rovers",
            "Publication year": 2013,
            "Publication url": "https://ics.forth.gr/~zabulis/esa_2811305.pdf",
            "Abstract": "SPARTAN (SPAring Robotics Technologies for Autonomous Navigation) and its extension SEXTANT (Spartan EXTension Activity-Not Tendered) are two robotic exploration technology development activities funded by the European Space Agency (ESA). They target the development of computer vision algorithms for visual navigation that will be suitable for use by Martian rovers. This paper summarizes our on-going efforts in the context of SEXTANT for developing dependable and efficient solutions for two key ingredients of visual navigation, namely terrain mapping and localization.",
            "Abstract entirety": 1,
            "Author pub id": "4YYxk1IAAAAJ:rO6llkc54NcC",
            "Publisher": "European Space Agency"
        },
        {
            "Title": "Fast trifocal tensor estimation using virtual parallax",
            "Publication year": 2005,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/1529999/",
            "Abstract": "We present a computationally efficient method for estimating the trifocal tensor corresponding to three images acquired by a freely moving camera. The proposed method represents projective space through a \"plane + parallax\" decomposition and employs a novel technique for estimating the homographies induced by a virtual 3D plane between successive image pairs. Knowledge of these homographies allows the corresponding camera projection matrices to be expressed in a common projective frame and, therefore, to be recovered directly. The trifocal tensor can then be recovered in a straightforward manner from the estimated projection matrices. Sample experimental results demonstrate that the method performs considerably faster compared to a state of the art method, without a serious loss in accuracy.",
            "Abstract entirety": 1,
            "Author pub id": "4YYxk1IAAAAJ:4TOpqqG69KYC",
            "Publisher": "IEEE"
        }
    ]
}]