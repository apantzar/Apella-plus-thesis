[{
    "name": "\u039c\u03b1\u03c1\u03af\u03b1 \u03a7\u03b1\u03bb\u03ba\u03af\u03b4\u03b7",
    "romanize name": "Maria Chalkidi",
    "School-Department": "\u03a8\u03b7\u03c6\u03b9\u03b1\u03ba\u03ce\u03bd \u03a3\u03c5\u03c3\u03c4\u03b7\u03bc\u03ac\u03c4\u03c9\u03bd",
    "University": "unipi",
    "Rank": "\u0391\u03bd\u03b1\u03c0\u03bb\u03b7\u03c1\u03c9\u03c4\u03ae\u03c2 \u039a\u03b1\u03b8\u03b7\u03b3\u03b7\u03c4\u03ae\u03c2",
    "Apella_id": 2891,
    "Scholar name": "M Halkidi",
    "Scholar id": "FknZ1Q8AAAAJ",
    "Affiliation": "University of Piraeus",
    "Citedby": 6885,
    "Interests": [
        "Data Mining",
        "machine learning",
        "recommender systems",
        "distributed systems",
        "data privacy"
    ],
    "Scholar url": "https://scholar.google.com/citations?user=FknZ1Q8AAAAJ&hl=en",
    "Publications": [
        {
            "Title": "Organizing web documents into thematic subsets using an ontology",
            "Publication year": 2003,
            "Publication url": "https://www.academia.edu/download/30700906/NVVH02-TechReport.pdf",
            "Abstract": "The volume and diversity of documents in the WWW, and the fact that these documents are connected to each other by links that bear important semantics generate requirements for effective organization of web content. This would enable effective browsing and searching. Both tasks are based on similarity between documents at the semantic level. In this context we propose a novel similarity measure between web documents, characterized by their incoming links, that can be used in conjunction with a clustering algorithm to discover groups of web documents on the same topic. Assuming each document is characterized by a sets of terms of an ontology, the similarity measure can compute a collective similarity between sets of terms seen as a whole, rather than between terms that would be independent. The similarity measure is embedded in different clustering algorithms and is extensively evaluated against real web document collections classified by human experts, in order to prove its efficiency.",
            "Abstract entirety": 1,
            "Author pub id": "FknZ1Q8AAAAJ:_FxGoFyzp5QC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Clustering validity assessment using multi representatives",
            "Publication year": 2002,
            "Publication url": "https://www.researchgate.net/profile/Maria-Halkidi/publication/241328314_Clustering_validity_assessment_using_multi_representatives/links/00b7d537c5d52e0754000000/Clustering-validity-assessment-using-multi-representatives.pdf",
            "Abstract": "Clustering is a mostly unsupervised procedure and the majority of the clustering algorithms depend on certain assumptions in order to define the subgroups present in a data set. Moreover, they may behave in a different way depending on the features of the data set and their input parameters values. Therefore, in most applications the resulting clustering scheme requires some sort of evaluation as regards its validity. In this paper a new validity index, CDbw, is defined based on well-known clustering criteria enabling: i. the finding of the optimal input parameters\u2019 values for a clustering algorithm that results in the optimal partitioning of a data set, ii. the selection of the algorithm that provides the optimal partitioning of a data set. CDbw puts emphasis on the geometric features of clusters, handling efficiently arbitrary shaped clusters. It achieves this by representing each cluster by a certain fixed number of clusters rather than a single center point. Our experimental results confirm the reliability of our index showing that it performs favorably in all cases selecting independently of clustering algorithm the scheme that best fits the data under consideration.",
            "Abstract entirety": 1,
            "Author pub id": "FknZ1Q8AAAAJ:zYLM7Y9cAGgC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Npclu: An approach for clustering spatially extended objects",
            "Publication year": 2008,
            "Publication url": "https://content.iospress.com/articles/intelligent-data-analysis/ida00349",
            "Abstract": "The majority of clustering algorithms deal with collections of data that can be represented as sets of points in the multidimensional Euclidean space. There is a large variety of application domains, such as spatiotemporal databases, medical applications and others, which produce datasets of non-point objects (ie objects that occupy a specific hyperspace). Traditional clustering algorithms are mainly based on statistical properties of data and therefore are not able to efficiently partition sets of spatially extended objects.",
            "Abstract entirety": 1,
            "Author pub id": "FknZ1Q8AAAAJ:UebtZRa9Y70C",
            "Publisher": "IOS Press"
        },
        {
            "Title": "Quality scheme assessment in the clustering process",
            "Publication year": 2000,
            "Publication url": "https://link.springer.com/chapter/10.1007/3-540-45372-5_26",
            "Abstract": "Clustering is mostly an unsupervised procedure and most of the clustering algorithms depend on assumptions and initial guesses in order to define the subgroups presented in a data set. As a consequence, in most applications the final clusters require some sort of evaluation. The evaluation procedure has to tackle difficult problems, which can be qualitatively expressed as: i. quality of clusters, ii. the degree with which a clustering scheme fits a specific data set, iii. the optimal number of clusters in a partitioning. In this paper we present a scheme for finding the optimal partitioning of a data set during the clustering process regardless of the clustering algorithm used. More specifically, we present an approach for evaluation of clustering schemes (partitions) so as to find the best number of clusters, which occurs in a specific data set. A clustering algorithm produces different partitions for different values of the \u2026",
            "Abstract entirety": 0,
            "Author pub id": "FknZ1Q8AAAAJ:2osOgNQ5qMEC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "DsUniPi: An SVM-based approach for sentiment analysis of figurative language on Twitter",
            "Publication year": 2015,
            "Publication url": "https://www.aclweb.org/anthology/S15-2120.pdf",
            "Abstract": "The DsUniPi team participated in the SemEval 2015 Task# 11: Sentiment Analysis of Figurative Language in Twitter. The proposed approach employs syntactical and morphological features, which indicate sentiment polarity in both figurative and non-figurative tweets. These features were combined with others that indicate presence of figurative language in order to predict a fine-grained sentiment score. The method is supervised and makes use of structured knowledge resources, such as Senti-WordNet sentiment lexicon for assigning sentiment score to words and WordNet for calculating word similarity. We have experimented with different classification algorithms (Na\u00efve Bayes, Decision trees, and SVM), and the best results were achieved by an SVM classifier with linear kernel.",
            "Abstract entirety": 1,
            "Author pub id": "FknZ1Q8AAAAJ:TFP_iSt0sucC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Clustering validity assessment: Finding the optimal partitioning of a data set",
            "Publication year": 2001,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/989517/",
            "Abstract": "Clustering is a mostly unsupervised procedure and the majority of clustering algorithms depend on certain assumptions in order to define the subgroups present in a data set. As a consequence, in most applications the resulting clustering scheme requires some sort of evaluation regarding its validity. In this paper we present a clustering validity procedure, which evaluates the results of clustering algorithms on data sets. We define a validity index, S Dbw, based on well-defined clustering criteria enabling the selection of optimal input parameter values for a clustering algorithm that result in the best partitioning of a data set. We evaluate the reliability of our index both theoretically and experimentally, considering three representative clustering algorithms run on synthetic and real data sets. We also carried out an evaluation study to compare S Dbw performance with other known validity indices. Our approach \u2026",
            "Abstract entirety": 0,
            "Author pub id": "FknZ1Q8AAAAJ:9yKSN-GCB0IC",
            "Publisher": "IEEE"
        },
        {
            "Title": "QGraph: A Quality Assessment Index for Graph Clustering",
            "Publication year": 2019,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-030-15719-7_9",
            "Abstract": "In this work, we aim to study the cluster validity problem for graph data. We present a new validity index that evaluates structural characteristics of graphs in order to select the clusters that best represent the communities in a graph. Since the work of defining what constitutes cluster in a graph is rather difficult, we exploit concepts of graph theory in order to evaluate the cohesiveness and separation of nodes. More specifically, we use the concept of degeneracy, and graph density to evaluate the connectivity of nodes in and between clusters. The effectiveness of our approach is experimentally evaluated using real-world data collections.",
            "Abstract entirety": 1,
            "Author pub id": "FknZ1Q8AAAAJ:NMxIlDl6LWMC",
            "Publisher": "Springer, Cham"
        },
        {
            "Title": "Scalable and real-time sentiment analysis of twitter data",
            "Publication year": 2016,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/7836769/",
            "Abstract": "In this paper, we present a system for scalable and real-time sentiment analysis of Twitter data. The proposed system relies on feature extraction from tweets, using both morphological features and semantic information. For the sentiment analysis task, we adopt a supervised learning approach, where we train various classifiers based on the extracted features. Finally, we present the design and implementation of a real-time system architecture in Storm, which contains the feature extraction and classification tasks, and scales well with respect to input data size and data arrival rate. By means of an experimental evaluation, we demonstrate the merits of the proposed system, both in terms of classification accuracy as well as scalability and performance.",
            "Abstract entirety": 1,
            "Author pub id": "FknZ1Q8AAAAJ:M3NEmzRMIkIC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Cluster validity methods: part I",
            "Publication year": 2002,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/565117.565124",
            "Abstract": "Clustering is an unsupervised process since there are no predefined classes and no examples that would indicate grouping properties in the data set. The majority of the clustering algorithms behave differently depending on the features of the data set and the initial assumptions for defining groups. Therefore, in most applications the resulting clustering scheme requires some sort of evaluation as regards its validity. Evaluating and assessing the results of a clustering algorithm is the main subject of cluster validity. In this paper we present a review of the clustering validity and methods. More specifically, Part I of the paper discusses the cluster validity approaches based on external and internal criteria.",
            "Abstract entirety": 1,
            "Author pub id": "FknZ1Q8AAAAJ:u-x6o8ySG0sC",
            "Publisher": "ACM"
        },
        {
            "Title": "Measurement aggregation and routing techniques for energy-efficient estimation in wireless sensor networks",
            "Publication year": 2010,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/5518812/",
            "Abstract": "Wireless sensor networks are fundamentally different from other wireless networks due to energy constraints and spatial correlation among sensor measurements. Mechanisms that efficiently compress and transport sensor data in the network are needed. We consider the problem of maximizing lifetime of wireless sensor networks that are entitled with the task of estimating an unknown parameter or process and thus need to adhere to estimation error specifications. We investigate optimal endogenous sensor measurement rate control, in-network data aggregation and routing for achieving the goal above. Sensors take measurements and aggregate incoming data from neighbors in a single outgoing flow by applying appropriate aggregation weights. By doing so, they control the variance of outgoing flow. Each sensor controls its measurement rate and aggregation weights, and aggregated measurement data are \u2026",
            "Abstract entirety": 0,
            "Author pub id": "FknZ1Q8AAAAJ:KlAtU1dfN6UC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Data mining: Concepts and techniques",
            "Publication year": 2001,
            "Publication url": "https://www.researchgate.net/profile/Petra-Perner/publication/220633275_Data_Mining_-_Concepts_and_Techniques/links/55910ed708ae1e1f9bae4892/Data-Mining-Concepts-and-Techniques.pdf",
            "Abstract": "Knowledge Discovery And Data Mining in Database Page 1 Data Mining: Concepts and \nTechniques \u2014 Tutorial \u2014 M. Vazirgiannis, M. Halkidi {mvazirg, mhalk}@aueb.gr Dept. of \nInformatics, Athens Univ. of Economics & Bussiness, Athens, Greece http://www.db-net.aueb.gr \nPage 2 23.8.02 M.Vazirgiannis & M. Halkidi, HELDiNET 10/2000 A Brief History of Data Mining \nSociety \u27a2 1989 IJCAI Workshop on Knowledge Discovery in Databases (PiatetskyShapiro) \u2713 \nKnowledge Discovery in Databases (G. Piatetsky-Shapiro and W. Frawley, 1991) \u27a2 1991-1994 \nWorkshops on Knowledge Discovery in Databases \u2713 Advances in Knowledge Discovery and \nData Mining (U. Fayyad, G. Piatetsky-Shapiro, P. Smyth, and R. Uthurusamy, 1996) \u27a2 \n1995-1998 International Conferences on Knowledge Discovery in Databases and Data Mining \n(KDD\u201995-98) \u2713 Journal of Data Mining and Knowledge Discovery (1997) \u27a2 1998 ACM , \u20191999-\u2026",
            "Abstract entirety": 0,
            "Author pub id": "FknZ1Q8AAAAJ:MXK_kJrjxJIC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Data Mining Process",
            "Publication year": 2003,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-1-4471-0031-7_2",
            "Abstract": "The knowledge discovery from large data repositories has been accepted as a key research issue in the field of databases, machine learning, and statistics, as well as an important opportunity for innovation in business. Various applications, such as data warehousing and on-line services via the Internet, invoke different data mining techniques in order to achieve better understanding of customers\u2019 behavior and thus to improve the quality of provided services achieving their business advantage.",
            "Abstract entirety": 1,
            "Author pub id": "FknZ1Q8AAAAJ:j3f4tGmQtD8C",
            "Publisher": "Springer, London"
        },
        {
            "Title": "A semi-supervised incremental clustering algorithm for streaming data",
            "Publication year": 2012,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-642-30217-6_48",
            "Abstract": "Nowadays many applications need to deal with evolving data streams. In this work, we propose an incremental clustering approach for the exploitation of user constraints on data streams. Conventional constraints do not make sense on streaming data, so we extend the classic notion of constraint set into a constraint stream. We propose methods for using the constraint stream as data items are forgotten or new items arrive. Also we present an on-line clustering approach for the cost-based enforcement of the constraints during cluster adaptation on evolving data streams. Our method introduces the concept of multi-clusters (m-clusters) to capture arbitrarily shaped clusters. An m-cluster consists of multiple dense overlapping regions, named s-clusters, each of which can be efficiently represented by a single point. Also it proposes the definition of outliers clusters in order to handle outliers while it provides \u2026",
            "Abstract entirety": 0,
            "Author pub id": "FknZ1Q8AAAAJ:qUcmZB5y_30C",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "Distributed energy-efficient estimation in spatially correlated wireless sensor networks",
            "Publication year": 2014,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S014036641400098X",
            "Abstract": "We study the problem of maximizing lifetime in sensor networks that are deployed for estimating an unknown parameter or process. Sensors take measurements and transport them in multi-hop fashion to a fusion center (FC) for Maximum Likelihood (ML) estimation of this process. A prime distinguishing feature of wireless sensor networks is the spatial correlation among measurements of nearby sensors. We investigate the way spatial correlation shapes the tradeoff between estimation quality and energy efficiency, according to which more measurement data improve estimation quality, but they are more energy-costly to transport. If the effect of spatial correlation is understood, then a given estimation quality can be achieved with minimum data redundancy and energy consumption. We study the dynamic control of the sensor sampling rates and the routes to the FC. Sensor attributes such as spatial correlation \u2026",
            "Abstract entirety": 0,
            "Author pub id": "FknZ1Q8AAAAJ:r0BpntZqJG4C",
            "Publisher": "Elsevier"
        },
        {
            "Title": "THESUS, a closer view on web content management enhanced with link semantics",
            "Publication year": 2004,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/1294890/",
            "Abstract": "With the unstoppable growth of the world wide Web, the great success of Web search engines, such as Google and AltaVista, users now turn to the Web whenever looking for information. However, many users are neophytes when it comes to computer science, yet they are often specialists of a certain domain. These users would like to add more semantics to guide their search through world wide Web material, whereas currently most search features are based on raw lexical content. We show how the use of the incoming links of a page can be used efficiently to classify a page in a concise manner. This enhances the browsing and querying of Web pages. We focus on the tools needed in order to manage the links and their semantics. We further process these links using a hierarchy of concepts, akin to an ontology, and a thesaurus. This work is demonstrated by an prototype system, called THESUS, that organizes \u2026",
            "Abstract entirety": 0,
            "Author pub id": "FknZ1Q8AAAAJ:Y0pCki6q_DkC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Recent Advances on Pattern Representation and",
            "Publication year": 2003,
            "Publication url": "http://www.db-net.aueb.gr/gbt/publications/PANDA_TR-2003-04.pdf",
            "Abstract": "Data intensive applications produce complex information that is posing requirements for novel Database Management Systems (DBMSs). Such information is characterized by its huge volume of data and by its diversity and complexity, since the data processing methods such as pattern recognition, data mining and knowledge extraction result in knowledge artifacts like clusters, association rules, decision trees and others. These artifacts, called patterns, need to be stored and retrieved effectively and efficiently. In this paper, we review the concept of patterns and their applicability in several research domains and we define the knowledge domain related to the PANDA project. We examine the different types of patterns that are extracted from a data set, in order to gather the necessary requirements for the definition of a pattern model. This model will constitute the heart of the Pattern Base Management System that will be designed.",
            "Abstract entirety": 1,
            "Author pub id": "FknZ1Q8AAAAJ:QIV2ME_5wuYC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Quality classifiers for open source software repositories",
            "Publication year": 2009,
            "Publication url": "https://arxiv.org/abs/0904.4708",
            "Abstract": "Open Source Software (OSS) often relies on large repositories, like SourceForge, for initial incubation. The OSS repositories offer a large variety of meta-data providing interesting information about projects and their success. In this paper we propose a data mining approach for training classifiers on the OSS meta-data provided by such data repositories. The classifiers learn to predict the successful continuation of an OSS project. The `successfulness' of projects is defined in terms of the classifier confidence with which it predicts that they could be ported in popular OSS projects (such as FreeBSD, Gentoo Portage).",
            "Abstract entirety": 1,
            "Author pub id": "FknZ1Q8AAAAJ:kNdYIx-mwKoC",
            "Publisher": "Unknown"
        },
        {
            "Title": "A game theoretic framework for data privacy preservation in recommender systems",
            "Publication year": 2011,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-642-23780-5_50",
            "Abstract": "We address the fundamental tradeoff between privacy preservation and high-quality recommendation stemming from a third party. Multiple users submit their ratings to a third party about items they have viewed. The third party aggregates the ratings and generates personalized recommendations for each user. The quality of recommendations for each user depends on submitted rating profiles from all users, including the user to which the recommendation is destined. Each user would like to declare a rating profile so as to preserve data privacy as much as possible, while not causing deterioration in the quality of the recommendation he would get, compared to the one he would get if he revealed his true private profile.We employ game theory to model and study the interaction of users and we derive conditions and expressions for the Nash Equilibrium Point (NEP). This consists of the rating strategy \u2026",
            "Abstract entirety": 0,
            "Author pub id": "FknZ1Q8AAAAJ:M3ejUd6NZC8C",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "Optimization of Multi-stakeholder Recommender Systems for Diversity and Coverage",
            "Publication year": 2021,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-030-79150-6_55",
            "Abstract": "Multi-stakeholder recommender systems (RSs) are a major paradigm shift from current RSs because recommendations affect not only item consumers (end-users) but also item providers (owners). They also motivate the need for new performance metrics beyond recommendation quality that explicitly affect the latter. In this work, we introduce a framework for optimizing multi-stakeholder RSs under constraints on diversity and coverage. Our goal is to make recommendations to end-users while treating each item provider equally, by ensuring sufficient user base coverage and diverse profiles of users to which items are recommended. Namely, items of each provider should be recommended to a certain number of users that are also diverse enough in their preferences. The optimization objective is that the total average rating of recommended items is as close as possible to that of a baseline RS. The problem \u2026",
            "Abstract entirety": 0,
            "Author pub id": "FknZ1Q8AAAAJ:RGFaLdJalmkC",
            "Publisher": "Springer, Cham"
        },
        {
            "Title": "Towards a logical model for patterns",
            "Publication year": 2003,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-540-39648-2_9",
            "Abstract": "Nowadays, the vast volume of collected digital data obliges us to employ processing methods like pattern recognition and data mining in order to reduce the complexity of data management. In this paper, we present the architecture and the logical foundations for the management of the produced knowledge artifacts, which we call patterns. To this end, we first introduce the concept of Pattern-Base Management System; then, we provide the logical foundations of a general framework based on the notions of pattern types and pattern classes, which stand for the intensional and extensional description of pattern instances, respectively. The framework is general and extensible enough to cover a broad range of real-world patterns, each of which is characterized by its structure, the related underlying data, an expression that carries the semantics of the pattern, and measurements of how successful the \u2026",
            "Abstract entirety": 0,
            "Author pub id": "FknZ1Q8AAAAJ:IjCSPb-OGe4C",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "A Survey on Pattern Application Domains and Pattern",
            "Publication year": 2003,
            "Publication url": "https://www.academia.edu/download/46273924/PANDA_TR-2003-01.pdf",
            "Abstract": "Data intensive applications produce complex information that is posing requirements for novel Database Management Systems (DBMSs). Such information is characterized by its huge volume of data and by its diversity and complexity, since the data processing methods such as pattern recognition, data mining and knowledge extraction result in knowledge artifacts like clusters, association rules, decision trees and others. These artifacts that we call patterns need to be stored and retrieved efficiently. In order to accomplish this we have to express them within a formalism and a language.In this report we review the concept of patterns and their applicability in several research domains related with the proposed work and we define the knowledge domain related with the PANDA project. It is important to interrelate these domains in order to be able to define the problem in comprehensive and complete way and come up with requirements on how a management system for patterns should be.",
            "Abstract entirety": 1,
            "Author pub id": "FknZ1Q8AAAAJ:7PzlFSSx8tAC",
            "Publisher": "Unknown"
        },
        {
            "Title": "A density-based cluster validity approach using multi-representatives",
            "Publication year": 2008,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S0167865508000020",
            "Abstract": "Although the goal of clustering is intuitively compelling and its notion arises in many fields, it is difficult to define a unified approach to address the clustering problem and thus diverse clustering algorithms abound in the research community. These algorithms, under different clustering assumptions, often lead to qualitatively different results. As a consequence the results of clustering algorithms (i.e., data set partitionings) need to be evaluated as regards their validity based on widely accepted criteria.In this paper a cluster validity index, CDbw, is proposed which assesses the compactness and separation of clusters defined by a clustering algorithm. The cluster validity index, given a data set and a set of clustering algorithms, enables (i) the selection of the input parameter values that lead an algorithm to the best possible partitioning of the data set, and (ii) the selection of the algorithm that provides the best partitioning \u2026",
            "Abstract entirety": 0,
            "Author pub id": "FknZ1Q8AAAAJ:eQOLeE2rZwMC",
            "Publisher": "North-Holland"
        },
        {
            "Title": "A framework for semi-supervised learning based on subjective and objective clustering criteria",
            "Publication year": 2005,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/1565745/",
            "Abstract": "In this paper, we propose a semi-supervised framework for learning a weighted Euclidean subspace, where the best clustering can be achieved. Our approach capitalizes on user-constraints and the quality of intermediate clustering results in terms of its structural properties. It uses the clustering algorithm and the validity measure as parameters.",
            "Abstract entirety": 1,
            "Author pub id": "FknZ1Q8AAAAJ:Tyk-4Ss8FVUC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Thesus: Organising web document collections based on semantics and clustering",
            "Publication year": 2002,
            "Publication url": "https://abiteboul.com/gemoReports/GemoReport-230.ps",
            "Abstract": "The requirements for effective search and management of the WWW content are stronger than ever. Document retrieval in the WWW is problematic with regards to three aspects: i. Not taking adequately into account link semantics for characterizing documents ii. Basing document similarity on binary",
            "Abstract entirety": 1,
            "Author pub id": "FknZ1Q8AAAAJ:W7OEmFMy1HYC",
            "Publisher": "Technical Report"
        },
        {
            "Title": "UMiner: A Data mining system handling uncertainty and quality",
            "Publication year": 2002,
            "Publication url": "https://link.springer.com/chapter/10.1007/3-540-45876-X_55",
            "Abstract": "In this paper we present UMiner, a new data mining system, which improves the quality of the data analysis results, handles uncertainty in the clustering & classification process and improves reasoning and decisionmaking.",
            "Abstract entirety": 1,
            "Author pub id": "FknZ1Q8AAAAJ:9ZlFYXVOiuMC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "Clustering validity checking methods",
            "Publication year": 2002,
            "Publication url": "https://scholar.google.com/scholar?cluster=16364442047713882218&hl=en&oi=scholarr",
            "Abstract": "Clustering results validation is an important topic in the context of pattern recognition. We review approaches and systems in this context. In the first part of this paper we presented clustering validity checking approaches based on internal and external criteria. In the second, current part, we present a review of clustering validity approaches based on relative criteria. Also we discuss the results of an experimental study based on widely known validity indices. Finally the paper illustrates the issues that are under-addressed by the recent approaches and proposes the research directions in the field.",
            "Abstract entirety": 1,
            "Author pub id": "FknZ1Q8AAAAJ:-f6ydRqryjwC",
            "Publisher": "Unknown"
        },
        {
            "Title": "A clustering framework based on subjective and objective validity criteria",
            "Publication year": 2008,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/1324172.1324176",
            "Abstract": "Clustering, as an unsupervised learning process is a challenging problem, especially in cases of high-dimensional datasets. Clustering result quality can benefit from user constraints and objective validity assessment. In this article, we propose a semisupervised framework for learning the weighted Euclidean subspace, where the best clustering can be achieved. Our approach capitalizes on: (i) user constraints; and (ii) the quality of intermediate clustering results in terms of their structural properties. The proposed framework uses the clustering algorithm and the validity measure as its parameters. We develop and discuss algorithms for learning and tuning the weights of contributing dimensions and defining the \u201cbest\u201d clustering obtained by satisfying user constraints. Experimental results on benchmark datasets demonstrate the superiority of the proposed approach in terms of improved clustering accuracy.",
            "Abstract entirety": 1,
            "Author pub id": "FknZ1Q8AAAAJ:YsMSGLbcyi4C",
            "Publisher": "ACM"
        },
        {
            "Title": "Difrec: A social-diffusion-aware recommender system",
            "Publication year": 2015,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/2806416.2806559",
            "Abstract": "Recommender systems used in current online social platforms make recommendations by only considering how relevant an item is to a specific user but they ignore the fact that, thanks to mechanisms like sharing or re-posting across the underlying social network, an item recommended to a user i propagates through the network and can reach another user j without needing to be explicitly recommended to j too. Overlooking this fact may lead to an inefficient use of the limited recommendation slots. These slots can instead be exploited more profitably by avoiding unnecessary duplicates and recommending other equally relevant items.",
            "Abstract entirety": 1,
            "Author pub id": "FknZ1Q8AAAAJ:isC4tDSrTZIC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Quality Assessment and Uncertainty Handling in Data Mining Process.",
            "Publication year": 2000,
            "Publication url": "https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.33.7885&rep=rep1&type=pdf",
            "Abstract": "The KDD process aims at the discovery and extraction of \u201cuseful\u201d knowledge (such as interesting patterns, classification, rules etc) from large data repositories. A widely recognized requirement is that the patterns discovered must be valid and ultimately comprehensible (ie, to be easily understood by analysts). Another requirement that is under-addressed in KDD process is the reveal and the handling of uncertainty in the main data mining processes of clustering, classification and association rules extraction.",
            "Abstract entirety": 1,
            "Author pub id": "FknZ1Q8AAAAJ:LkGwnXOMwfcC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Clustering algorithms and validity measures",
            "Publication year": 2001,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/938534/",
            "Abstract": "Clustering aims at discovering groups and identifying interesting distributions and patterns in data sets. Researchers have extensively studied clustering since it arises in many application domains in engineering and social sciences. In the last years the availability of huge transactional and experimental data sets and the arising requirements for data mining created needs for clustering algorithms that scale and can be applied in diverse domains. The paper surveys clustering methods and approaches available in the literature in a comparative way. It also presents the basic concepts, principles and assumptions upon which the clustering algorithms are based. Another important issue is the validity of the clustering schemes resulting from applying algorithms. This is also related to the inherent features of the data set under concern. We review and compare clustering validity measures available in the literature \u2026",
            "Abstract entirety": 0,
            "Author pub id": "FknZ1Q8AAAAJ:qjMakFHDy7sC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Managing uncertainty and quality in the classification process",
            "Publication year": 2002,
            "Publication url": "https://link.springer.com/chapter/10.1007/3-540-46014-4_25",
            "Abstract": "An important open issue in KDD research is the reveal and the handling of uncertainty. The popular classification approaches do not take into account this feature while they do not exploit properly the significant amount of information included in the results of classification process (i.e., classification scheme), though it will be useful in decision-making. In this paper we present a framework that maintains uncertainty throughout the classification process by maintaining the classification belief and moreover enables assignment of an item to multiple classes with a different belief. Decision support tools are provided for decisions related to: i. relative importance of classes in a data set (i.e., \u201cyoung vs. old customers\u201d), ii. relative importance of classes across data sets iii. the information content of different data sets. Finally we provide a mechanism for evaluating classification schemes and select the scheme that best \u2026",
            "Abstract entirety": 0,
            "Author pub id": "FknZ1Q8AAAAJ:roLk4NBRz8UC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "THESUS: Organizing Web document collections based on link semantics",
            "Publication year": 2003,
            "Publication url": "https://link.springer.com/article/10.1007/s00778-003-0100-6",
            "Abstract": "The requirements for effective search and management of the WWW are stronger than ever. Currently Web documents are classified based on their content not taking into account the fact that these documents are connected to each other by links. We claim that a page\u2019s classification is enriched by the detection of its incoming links\u2019 semantics. This would enable effective browsing and enhance the validity of search results in the WWW context. Another aspect that is underaddressed and strictly related to the tasks of browsing and searching is the similarity of documents at the semantic level. The above observations lead us to the adoption of a hierarchy of concepts (ontology) and a thesaurus to exploit links and provide a better characterization of Web documents. The enhancement of document characterization makes operations such as clustering and labeling very interesting. To this end, we devised a \u2026",
            "Abstract entirety": 0,
            "Author pub id": "FknZ1Q8AAAAJ:UeHWp8X0CEIC",
            "Publisher": "Springer-Verlag"
        },
        {
            "Title": "Method-independent indices for cluster validation and estimating the number of clusters",
            "Publication year": 2015,
            "Publication url": "https://www.taylorfrancis.com/chapters/edit/10.1201/b19706-35/method-independent-indices-cluster-validation-estimating-number-clusters-maria-halkidi-michalis-vazirgiannis-christian-hennig",
            "Abstract": ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 595 26.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 596 26.2 Euclidean and Dissimilarity-Based Indices for Crisp Partitions . . . . . . . . . . . . . 59826.2.1 Within/Between Clusters Sum of Squares-Based Criteria . . . . . . . . . . . 599 26.2.2 The Davies-Bouldin Index . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 602 26.2.3 The Dunn Family of Indices . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 602 26.2.4 Hubert\u2019s 0 and Related Indices . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 603 26.2.5 The Average Silhouette Width Criterion . . . . . . . . . . . . . . . . . . . . . . . . 604 26.2.6 The CDbw-Index . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 605 26.2.7 A Clustering Validation Index Based on Nearest Neighbors . . . . . . . . . 607 26.2.8 Specialized Indices . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 608 26.2.9 A Data Example \u2026",
            "Abstract entirety": 0,
            "Author pub id": "FknZ1Q8AAAAJ:blknAaTinKkC",
            "Publisher": "Chapman and Hall/CRC"
        },
        {
            "Title": "Motivating Pattern Management",
            "Publication year": 2003,
            "Publication url": "http://isl.cs.unipi.gr/people/ntoutsi/papers/03.TR02.pdf#page=3",
            "Abstract": "As the amount of data produced by data processing systems increases, it has become clear that users of decision support systems do not want massive volumes of data, but are more interested in informative patterns buried within data. The patterns that emerge from data intensive applications have to be stored in a way so that they can be queried effectively and efficiently. Thus, we need to create pattern repositories where the knowledge artefacts known as patterns will reside, as primitive data reside in Data Base Management Systems (DBMSs). In this paper we present some representative pattern application domains that call for integrated and efficient pattern base support, along with the corresponding types of the patterns they produce. We also motivate research towards a pattern base management system by abstracting common features of patterns and management requirements",
            "Abstract entirety": 1,
            "Author pub id": "FknZ1Q8AAAAJ:4TOpqqG69KYC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Efficient and fair item coverage in recommender systems",
            "Publication year": 2018,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/8511997/",
            "Abstract": "We study the design of recommender systems under the constraint of item coverage. An item is covered if it is recommended at least to a certain number of users. This situation arises in settings where the items to be recommended stem from different entities such as owners, producers or advertisers with whom the recommendation engine has come into agreement about item promotion through recommendation, in exchange for some payment. It is therefore important to issue recommendations with breadth, in the sense that each item reaches a sufficiently large portion of the user base through recommendation. This constraint drastically changes the recommendation problem since now the lists of items to be recommended to different users become coupled. We formulate and study the recommendation problem under the item coverage constraint, with the goal of minimizing the cost of deviation from a nominal \u2026",
            "Abstract entirety": 0,
            "Author pub id": "FknZ1Q8AAAAJ:hMod-77fHWUC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Clustering validity checking methods: Part II",
            "Publication year": 2002,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/601858.601862",
            "Abstract": "Clustering results validation is an important topic in the context of pattern recognition. We review approaches and systems in this context. In the first part of this paper we presented clustering validity checking approaches based on internal and external criteria. In the second, current part, we present a review of clustering validity approaches based on relative criteria. Also we discuss the results of an experimental study based on widely known validity indices. Finally the paper illustrates the issues that are under-addressed by the recent approaches and proposes the research directions in the field.",
            "Abstract entirety": 1,
            "Author pub id": "FknZ1Q8AAAAJ:d1gkVwhDpl0C",
            "Publisher": "ACM"
        },
        {
            "Title": "Discovering representative skyline points over distributed data",
            "Publication year": 2012,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-642-31235-9_9",
            "Abstract": "Skyline queries help users make intelligent decisions over complex data. The main shortcoming of skyline queries is that the cardinality of the result set is not known a-priori. To overcome this limitation, the representative skyline query has been proposed, which retrieves a fixed set of k skyline points that best describe all skyline points. Even though the representative skyline has been studied before in centralized environments, this is the first paper that addresses efficient computation of the representative skyline in distributed systems. The distributed nature of the environment makes the task of discovering truly representative skyline points even more challenging. In this paper, we propose a novel framework for discovering the representative skyline over distributed data sources. Our experimental study demonstrates the efficiency and effectiveness of our framework.",
            "Abstract entirety": 1,
            "Author pub id": "FknZ1Q8AAAAJ:hC7cP41nSMkC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "Uncertainty Handling in Data Mining",
            "Publication year": 2003,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-1-4471-0031-7_4",
            "Abstract": "The KDD process aims at searching for interesting patterns in large real-world data sets. The representation of the extracted knowledge may have various forms, depending on the specific data mining technique used, such as classification, association rules, clustering, etc.",
            "Abstract entirety": 1,
            "Author pub id": "FknZ1Q8AAAAJ:iH-uZ7U-co4C",
            "Publisher": "Springer, London"
        },
        {
            "Title": "Evaluating the validity of clustering results based on density criteria and multi-representatives",
            "Publication year": 2001,
            "Publication url": "http://www.db-net.aueb.gr/files/tkde-0021-0104.pdf",
            "Abstract": "Although the goal of clustering is intuitively compelling and its notion arises in many fields, it has been difficult to define a unified approach to address the clustering problem and thus diverse clustering approaches abound in the research community. These approaches are based on different clustering principles and assumptions and they often lead to qualitatively different results. As a consequence the results of clustering algorithms (ie data set partitionings) need to be evaluated as regards their validity based on widely accepted criteria. In this paper a cluster validity index, CDbw, is introduced which assesses compactness and separation of the partitions generated by a clustering algorithm. The cluster validity index, given a data set and a set of clustering algorithms, enables: i) the selection of the input parameter values that lead an algorithm to the best possible partitioning of the data set, and ii) the selection of the algorithm that provides the optimal partitioning of the data set. CDbw handles efficiently arbitrarily shaped clusters by representing each cluster with a number of points rather than by a single representative point. The properties of the validity index are theoretically justified. A full implementation and experimental results confirm the reliability of the validity index showing also that its performance compares favorably to that of several others.",
            "Abstract entirety": 1,
            "Author pub id": "FknZ1Q8AAAAJ:YOwf2qJgpHMC",
            "Publisher": "Greece"
        },
        {
            "Title": "DFC: A Density-based Fuzzy Clustering Algorithm",
            "Publication year": 2005,
            "Publication url": "https://scholar.google.com/scholar?cluster=14452347512655783955&hl=en&oi=scholarr",
            "Abstract": "The majority of clustering algorithms assign each object to exactly one cluster, assuming that the boundaries of a cluster are strictly defined. However, this approach does not always correspond to the real-world applications since the boundaries among clusters can be fuzzy, in the sense that an object can be assigned to more than one cluster. Thus, fuzzy clustering arises as a commonly used conceptual and algorithmic framework for data analysis and unsupervised pattern recognition. In this paper we present a new non-crisp clustering algorithm, DFC, which based on density notion of clusters, discovers arbitrarily shaped clusters. Furthermore, it takes into account the uncertainty in the clustering process so that the objects are assigned to potentially more than one cluster with some degree of belief. The experimental study with various datasets shows that DFC combines efficiently geometrical and uncertainty \u2026",
            "Abstract entirety": 0,
            "Author pub id": "FknZ1Q8AAAAJ:ZeXyd9-uunAC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Uncertainty handling in the data mining process with fuzzy logic",
            "Publication year": 2000,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/838692/",
            "Abstract": "The KDD process aims at searching for interesting instances of patterns in data sets. It is widely accepted that the patterns must be comprehensible. One of the aspects that are under-addressed in the KDD process is the handling of uncertainty in the process of clustering, classification and association rules extraction. In this paper we present a classification framework for relational databases so as to support uncertainty in terms of natural language queries and assessments. More specifically, we present a classification scheme of non-categorical attributes into lexically defined categories based on fuzzy logic and provides decision support facilities based on related information measures.",
            "Abstract entirety": 1,
            "Author pub id": "FknZ1Q8AAAAJ:WF5omc3nYNoC",
            "Publisher": "IEEE"
        },
        {
            "Title": "A survey on pattern application domains and pattern management approaches",
            "Publication year": 2003,
            "Publication url": "http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.200.6106",
            "Abstract": "CiteSeerX \u2014 A Survey on Pattern Application Domains and Pattern Management Approaches \nDocuments Authors Tables Log in Sign up MetaCart DMCA Donate CiteSeerX logo \nDocuments: Advanced Search Include Citations Authors: Advanced Search Include Citations \nTables: DMCA A Survey on Pattern Application Domains and Pattern Management \nApproaches (2003) Cached Download as a PDF Download Links [dke.cti.gr] [www.db-net.aueb.gr] \n[www.idi.ntnu.no] [www.idi.ntnu.no] Save to List Add to Collection Correct Errors Monitor \nChanges by Author(s) M. Vazirgiannis , M. Halkidi , G. Tsatsaronis , E. Vrachnos , D. Keim (konstanz \n, P. Xeros , Y. Theodoridis (cti , A. Pikrakis , S. Theodoridis (uoa , M. Vazirgiannis , M. Halkidi , \nG. Tsatsaronis , E. Vrachnos , D. Keim , P. Xeros , Y. Theodoridis , A. Pikrakis , S. Theodoridis \nSummary Citations Active Bibliography Co-citation Clustered Documents Version History by of -\u2026",
            "Abstract entirety": 0,
            "Author pub id": "FknZ1Q8AAAAJ:Se3iqnhoufwC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Hierarchial Clustering.",
            "Publication year": 2009,
            "Publication url": "https://scholar.google.com/scholar?cluster=999462866726066315&hl=en&oi=scholarr",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "FknZ1Q8AAAAJ:TQgYirikUcIC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Auctioning data for learning",
            "Publication year": 2015,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/7395737/",
            "Abstract": "In this paper we advocate that market mechanisms inspired by economics in conjunction with intelligent data selection is the key to fulfilling learning tasks in the presence of big data subject to privacy concerns of users. We design a market of private data that are gathered towards building a classifier. Each data owner has a private cost that quantifies his discomfort for providing data to the learner. Also, at each stage of the learning process, each data owner is characterized by a utility score, which expresses the utility of his data for the learner. The learner initiates a call for buying data, and interested owners respond by declaring their costs. The learner computes the utility score of each data owner. It then selects one owner to buy data from and associated payment. For the goals of minimizing the expected privacy cost of users and of minimizing the expected payment by the learner, we propose a variation of a \u2026",
            "Abstract entirety": 0,
            "Author pub id": "FknZ1Q8AAAAJ:k_IJM867U9cC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Uncertainty handling and quality assessment in data mining",
            "Publication year": 2003,
            "Publication url": "https://books.google.com/books?hl=en&lr=&id=Y6wYLPzQkq8C&oi=fnd&pg=PA3&dq=info:oOGeTbRMqWYJ:scholar.google.com&ots=b_6rZlqjUC&sig=XR-LDLg3KCkcQ3OvppIYG07F0IM",
            "Abstract": "Uncertainty Handling and Quality Assessment in Data Mining provides an introduction to the application of these concepts in Knowledge Discovery and Data Mining. It reviews the state-of-the-art in uncertainty handling and discusses a framework for unveiling and handling uncertainty. Coverage of quality assessment begins with an introduction to cluster analysis and a comparison of the methods and approaches that may be used. The techniques and algorithms involved in other essential data mining tasks, such as classification and extraction of association rules, are also discussed together with a review of the quality criteria and techniques for evaluating the data mining results. This book presents a general framework for assessing quality and handling uncertainty which is based on tested concepts and theories. This framework forms the basis of an implementation tool,'Uminer'which is introduced to the reader for the first time. This tool supports the key data mining tasks while enhancing the traditional processes for handling uncertainty and assessing quality. Aimed at IT professionals involved with data mining and knowledge discovery, the work is supported with case studies from epidemiology and telecommunications that illustrate how the tool works in'real world'data mining projects. The book would also be of interest to final year undergraduates or post-graduate students looking at: databases, algorithms, artificial intelligence and information systems particularly with regard to uncertainty and quality assessment.",
            "Abstract entirety": 1,
            "Author pub id": "FknZ1Q8AAAAJ:IWHjjKOFINEC",
            "Publisher": "Springer Science & Business Media"
        },
        {
            "Title": "Online clustering of distributed streaming data using belief propagation techniques",
            "Publication year": 2011,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/6068441/",
            "Abstract": "Extraction of patterns out of streaming data that are generated from geographically dispersed devices is a major challenge in data mining. The sequential, distributed fashion in which data become available to the decision maker, together with the fact that the decision maker needs to rely only on recently received data due to storage and communication constraints, render the objective of keeping track of data evolution a nontrivial one. We consider a set of distributed nodes that communicate directly with a central location. We address the problem of clustering distributed streaming data through a two-level clustering approach. We adopt belief propagation techniques to perform stream clustering at both levels. At the node level, a batch of data arrives at each time slot, and the goal is to maintain a set of salient data (local exemplars) at each time slot, which best represents the data received up to that slot. At each \u2026",
            "Abstract entirety": 0,
            "Author pub id": "FknZ1Q8AAAAJ:qxL8FJ1GzNcC",
            "Publisher": "IEEE"
        },
        {
            "Title": "NPClu: A Methodology for Clustering Non-point Objects",
            "Publication year": 2002,
            "Publication url": "https://www.researchgate.net/profile/Maria-Halkidi/publication/251639021_NPClu_A_Methodology_for_Clustering_Nonpoint_Objects/links/00b7d537c5d5225ede000000/NPClu-A-Methodology-for-Clustering-Nonpoint-Objects.pdf",
            "Abstract": "Clustering is an important task in managing voluminous data so as to identify significant groups in an underlying data set and extract \u201cinteresting\u201d knowledge from it. Since it is widely recognized as a major tool in a number of applications in many fields (business and science), a number of clustering techniques and algorithms have been proposed and are available in literature. The vast majority of algorithms have only considered point objects, though in many cases we have to handle sets of extended objects such as rectangles. In this paper we present an approach for nonpoint clustering. The main idea is to represent objects (approximated by their minimum bounding rectangles-MBRs) by their vertices. Then a well-defined clustering algorithm can be applied on the set of vertices while a refinement step follows to identify the final clusters of objects. We compare the performance of our approach with the naive solution of representing objects by their MBR centers. Our approach results in better partitioning in all studies. We also theoretically show that it will always perform at least as well as the case of considering the MBR centers.",
            "Abstract entirety": 1,
            "Author pub id": "FknZ1Q8AAAAJ:Wp0gIr-vW9MC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Quality assessment approaches in data mining",
            "Publication year": 2009,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-0-387-09823-4_31",
            "Abstract": "The Data Mining process encompasses many different specific techniques and algorithms that can be used to analyze the data and derive the discovered knowledge. An important problem regarding the results of the Data Mining process is the development of efficient indicators of assessing the quality of the results of the analysis. This, the quality assessment problem, is a cornerstone issue of the whole process because: i) The analyzed data may hide interesting patterns that the Data Mining methods are called to reveal. Due to the size of the data, the requirement for automatically evaluating the validity of the extracted patterns is stronger than ever.ii)A number of algorithms and techniques have been proposed which under different assumptions can lead to different results. iii)The number of patterns generated during the Data Mining process is very large but only a few of these patterns are likely to be \u2026",
            "Abstract entirety": 0,
            "Author pub id": "FknZ1Q8AAAAJ:5nxA0vEk-isC",
            "Publisher": "Springer, Boston, MA"
        },
        {
            "Title": "Recommender systems with selfish users",
            "Publication year": 2020,
            "Publication url": "https://link.springer.com/article/10.1007/s10115-020-01460-5",
            "Abstract": "Recommender systems are a fundamental component of contemporary social-media platforms and require feedback submitted from users in order to fulfill their goal. On the other hand, the raise of advocacy about user-controlled data repositories supports the selective submission of data by user through intelligent software agents residing at the user end. These agents are endowed with the task of protecting user privacy by applying a \u201csoft filter\u201d on personal data provided to the system. In this work, we pose the question: \u201chow should the software agent control the user feedback submitted to a recommender system in a way that is most privacy preserving, while the user still enjoys most of the benefits of the recommender system?\u201d. We consider a set of such agents, each of which aims to protect the privacy of its serving user by submitting to the recommender system server a version of her real rating profile. The fact \u2026",
            "Abstract entirety": 0,
            "Author pub id": "FknZ1Q8AAAAJ:ns9cj8rnVeAC",
            "Publisher": "Springer London"
        },
        {
            "Title": "Efficient online state tracking using sensor networks",
            "Publication year": 2006,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/1630560/",
            "Abstract": "Sensor networks are being deployed for tracking events of interest in many environmental or monitoring applications. Because of their distributed nature of operation, a challenging issue is how to accurately identify the aggregate state of the phenomenon that is being observed. This work presents an online mechanism for efficiently determining the overall network status, employing distributed operations that minimize the communication costs. Experiments on real data, suggest that the proposed metholology can be a viable solution for real world systems.",
            "Abstract entirety": 1,
            "Author pub id": "FknZ1Q8AAAAJ:ufrVoPGSRksC",
            "Publisher": "IEEE"
        },
        {
            "Title": "On clustering validation techniques",
            "Publication year": 2001,
            "Publication url": "https://link.springer.com/article/10.1023/a:1012801612483",
            "Abstract": "Cluster analysis aims at identifying groups of similar objects and, therefore helps to discover distribution of patterns and interesting correlations in large data sets. It has been subject of wide research since it arises in many application domains in engineering, business and social sciences. Especially, in the last years the availability of huge transactional and experimental data sets and the arising requirements for data mining created needs for clustering algorithms that scale and can be applied in diverse domains.This paper introduces the fundamental concepts of clustering while it surveys the widely known clustering algorithms in a comparative way. Moreover, it addresses an important issue of clustering process regarding the quality assessment of the clustering results. This is also related to the inherent features of the data set under concern. A review of clustering validity measures and \u2026",
            "Abstract entirety": 0,
            "Author pub id": "FknZ1Q8AAAAJ:u5HHmVD_uO8C",
            "Publisher": "Kluwer Academic Publishers"
        },
        {
            "Title": "UMiner: A Data Mining System Handling Uncertainty and Quality",
            "Publication year": 2003,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-1-4471-0031-7_5",
            "Abstract": "The explosive growth of data collections in the science and business applications and the need to analyze and extract useful knowledge from this data leads to a new generation of tools and techniques grouped under the term data mining [FU96]. Their objective is to deal with volumes of data and automate the data mining and knowledge discovery from large data repositories. The majorities of data mining systems produce a particular enumeration of patterns over data sets accomplishing a limited set of tasks, such as clustering, classification and rules extraction [BL96, FPSU96]. However, there are some aspects in the data mining process that are under-addressed by the current approaches in database and data mining applications. These aspects are:                     i)                                          the revealing and handling of uncertainty in the context of data mining tasks. In traditional data \u2026 the revealing and handling of uncertainty in the context of data mining tasks. In traditional data \u2026",
            "Abstract entirety": 0,
            "Author pub id": "FknZ1Q8AAAAJ:4JMBOYKVnBMC",
            "Publisher": "Springer, London"
        },
        {
            "Title": "Data mining in software engineering",
            "Publication year": 2011,
            "Publication url": "https://content.iospress.com/articles/intelligent-data-analysis/ida00475",
            "Abstract": "The increased availability of data created as part of the software development process allows us to apply novel analysis techniques on the data and use the results to guide the process's optimization. In this paper we describe various data sources and discuss the principles and techniques of data mining as applied on software engineering data. Data that can be mined is generated by most parts of the development process: requirements elicitation, development analysis, testing, debugging, and maintenance. Based on this classification we survey the mining approaches that have been used and categorize them according to the corresponding parts of the development process and the task they assist. Thus the survey provides researchers with a concise overview of data mining techniques applied to software engineering data, and aids practitioners on the selection of appropriate data mining techniques for their work.",
            "Abstract entirety": 1,
            "Author pub id": "FknZ1Q8AAAAJ:0EnyYjriUFMC",
            "Publisher": "IOS Press"
        },
        {
            "Title": "Lifetime maximization in wireless sensor networks with an estimation mission",
            "Publication year": 2009,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/5425294/",
            "Abstract": "We study the problem of maximum lifetime in wireless sensor networks that are entitled with the task of estimating an unknown parameter or process. Sensors take measurements and transfer them in multi-hop fashion to a fusion center (FC) for Maximum Likelihood (ML) estimation. To engineer the network for lifetime maximization while adhering to estimation error specifications, the number of measurements by each sensor per unit of time (namely, sensor measurement rate) and the routes to the FC are controlled. Sensor spatial correlation, measurement accuracies, link qualities and energy reserves affect sensor measurement rates and the routes to the FC, and, in turn, measurement rates and sensor characteristics impact estimation error. We show that the problem can be decomposed into separate optimization problems where each sensor autonomously takes its measurement rate and routing decisions, and \u2026",
            "Abstract entirety": 0,
            "Author pub id": "FknZ1Q8AAAAJ:8k81kl-MbHgC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Resilient and energy efficient tracking in sensor networks",
            "Publication year": 2006,
            "Publication url": "https://www.inderscienceonline.com/doi/abs/10.1504/IJWMC.2006.012468",
            "Abstract": "We present a new distributed mechanism for tracking moving objects with a network of sensors. To track such objects efficiently and accurately, we need techniques that allow the cooperation of many sensors, and the real-time exchange of data in the presence of possible failures and within the constraints of the system. Our mechanism provides efficient set-up and cooperation of the sensors within the network, while providing fault tolerant characteristics through replication. We provide an algorithm for predicting, with high probability, the future location of an object based on past observations by many sensors. We empirically evaluate the efficiency and accuracy of our approach.",
            "Abstract entirety": 1,
            "Author pub id": "FknZ1Q8AAAAJ:hqOjcs7Dif8C",
            "Publisher": "Inderscience Publishers"
        },
        {
            "Title": "Quality Assessment in Data Mining",
            "Publication year": 2003,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-1-4471-0031-7_3",
            "Abstract": " Data Mining is mainly concerned with methodologies for extracting patterns from large data repositories. There are many data mining methods which accomplishing a limited set of tasks produces a particular enumeration of patterns over data sets. The main tasks of data mining which have already been discussed in previous sections are: i) Clustering, ii) Classification, iii) Association Rule Extraction, iv) Time Series, v) Regression, and vi) Summarization.",
            "Abstract entirety": 1,
            "Author pub id": "FknZ1Q8AAAAJ:RHpTSmoSYBkC",
            "Publisher": "Springer, London"
        },
        {
            "Title": "Construction de classes de documents web",
            "Publication year": 2003,
            "Publication url": "https://abiteboul.com/gemoReports/GemoReport-304.pdf",
            "Abstract": "In this paper, we introduce a novel similarity measure between documents, such as web documents, that can be characterized by a small set of concepts, that each belong to a hierarchy (ontology). We use this measure with a slightly modified DB-SCAN clustering algorithm in order to construct clusters of semantically related documents. We also give experimental results that illustrate the quality of our approach.",
            "Abstract entirety": 1,
            "Author pub id": "FknZ1Q8AAAAJ:3fE2CSJIrl8C",
            "Publisher": "Unknown"
        }
    ]
}]