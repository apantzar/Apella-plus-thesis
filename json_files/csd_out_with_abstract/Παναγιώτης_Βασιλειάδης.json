[{
    "name": "\u03a0\u03b1\u03bd\u03b1\u03b3\u03b9\u03ce\u03c4\u03b7\u03c2 \u0392\u03b1\u03c3\u03b9\u03bb\u03b5\u03b9\u03ac\u03b4\u03b7\u03c2",
    "romanize name": "Panagiotis Vasileiadis",
    "School-Department": "\u039c\u03b7\u03c7 \u0397\u03bb\u03b5\u03ba\u03c4\u03c1\u03bf\u03bd\u03b9\u03ba\u03ce\u03bd \u03a5\u03c0\u03bf\u03bb\u03bf\u03b3\u03b9\u03c3\u03c4\u03ce\u03bd \u03ba\u03b1\u03b9 \u03a0\u03bb\u03b7\u03c1\u03bf\u03c6\u03bf\u03c1\u03b9\u03ba\u03ae\u03c2",
    "University": "uoi",
    "Rank": "\u039a\u03b1\u03b8\u03b7\u03b3\u03b7\u03c4\u03ae\u03c2",
    "Apella_id": 10082,
    "Scholar name": "Panos Vassiliadis",
    "Scholar id": "B_Zd1P8AAAAJ",
    "Affiliation": "Dept. of Comp. Science and Eng., Univ. of Ioannina",
    "Citedby": 8359,
    "Interests": [
        "Data Management",
        "Schema Evolution",
        "Data Warehousing",
        "ETL",
        "OLAP"
    ],
    "Scholar url": "https://scholar.google.com/citations?user=B_Zd1P8AAAAJ&hl=en",
    "Publications": [
        {
            "Title": "And the Tool Created a GUI That was Impure and Without Form: Anti-Patterns in Automatically Generated GUIs",
            "Publication year": 2018,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/3282308.3282333",
            "Abstract": "A basic prerequisite for any daily development task is to understand the source code that we are working with. To this end, the source code should be clean. Usually, it is up to us, the developers, to keep the source code clean. However, often there are parts of the code that are automatically generated. A typical such case are Graphical User Interfaces (GUIs) created via a GUI builder, ie, a tool that allows the developer to design the GUI by combining graphical control elements, offered in a palette. In this paper, we investigate the quality of the code that is generated by GUI builders. To assist tool-smiths in developing better GUI builders, we report anti-patterns concerning naming, documentation, design and implementation issues, observed in a study that involves four popular GUI builders for Java. The reported anti-patterns can further assist GUI developers/designers in selecting appropriate tools.",
            "Abstract entirety": 1,
            "Author pub id": "B_Zd1P8AAAAJ:tuHXwOkdijsC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Beyond roll-up\u2019s and drill-down\u2019s: An intentional analytics model to reinvent OLAP",
            "Publication year": 2019,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S0306437918303016",
            "Abstract": "This paper structures a novel vision for OLAPby fundamentally redefining several of the pillars on which OLAP has been based for the last 20 years. We redefine OLAP queries, in order to move to higher degrees of abstraction from roll-up\u2019s and drill-down\u2019s, and we propose a set of novel intentional OLAP operators, namely, describe, assess, explain, predict, and suggest, which express the user\u2019s need for results. We fundamentally redefine what a query answer is, and escape from the constraint that the answer is a set of tuples; on the contrary, we complement the set of tuples with models (typically, but not exclusively, results of data mining algorithms over the involved data) that concisely represent the internal structure or correlations of the data. Due to the diverse nature of the involved models, we come up (for the first time ever, to the best of our knowledge) with a unifying framework for them, that places its pillars \u2026",
            "Abstract entirety": 0,
            "Author pub id": "B_Zd1P8AAAAJ:MLfJN-KU85MC",
            "Publisher": "Pergamon"
        },
        {
            "Title": "Schema evolution for databases and data warehouses",
            "Publication year": 2015,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-319-39243-1_1",
            "Abstract": "Like all software systems, databases are subject to evolution as time passes. The impact of this evolution is tremendous as every change to the schema of a database affects the syntactic correctness and the semantic validity of all the surrounding applications and de facto necessitates their maintenance in order to remove errors from their source code. This survey provides a walk-through on different approaches to the problem of handling database and data warehouse schema evolution. The areas covered include (a) published case studies with statistical information on database evolution, (b) techniques for managing schema and view evolution, (c) techniques pertaining to the area of data warehouses, and, (d) prospects for future research.",
            "Abstract entirety": 1,
            "Author pub id": "B_Zd1P8AAAAJ:z_wVstp3MssC",
            "Publisher": "Springer, Cham"
        },
        {
            "Title": "Timely provisioning of mobile services in critical pervasive environments",
            "Publication year": 2005,
            "Publication url": "https://link.springer.com/chapter/10.1007/11575771_54",
            "Abstract": "Timeliness in conventional real-time systems is addressed by employing well-known scheduling techniques that guarantee the execution of a number of tasks within certain deadlines. However, these classical scheduling techniques do not take into account basic features that characterize today\u2019s critical pervasive computing environments.In this paper, we revisit the issue of timeliness in the context of pervasive computing environments. We propose a middleware service that addresses the timely provisioning of services, while taking into account both the mobility of the entities that constitute pervasive computing environments and the existence of multiple alternative entities, providing semantically compatible services. Specifically, we model the overall behavior of mobile entities in terms of the entities\u2019 lifetime. The lifetime of an entity is the duration for which the entity is present and available to \u2026",
            "Abstract entirety": 0,
            "Author pub id": "B_Zd1P8AAAAJ:blknAaTinKkC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "Scheduling strategies for efficient ETL execution",
            "Publication year": 2013,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S0306437912001561",
            "Abstract": "Extract-transform-load (ETL) workflows model the population of enterprise data warehouses with information gathered from a large variety of heterogeneous data sources. ETL workflows are complex design structures that run under strict performance requirements and their optimization is crucial for satisfying business objectives. In this paper, we deal with the problem of scheduling the execution of ETL activities (a.k.a. transformations, tasks, operations), with the goal of minimizing ETL execution time and allocated memory. We investigate the effects of four scheduling policies on different flow structures and configurations and experimentally show that the use of different scheduling policies may improve ETL performance in terms of memory consumption and execution time. First, we examine a simple, fair scheduling policy. Then, we study the pros and cons of two other policies: the first opts for emptying the largest \u2026",
            "Abstract entirety": 0,
            "Author pub id": "B_Zd1P8AAAAJ:D_sINldO8mEC",
            "Publisher": "Pergamon"
        },
        {
            "Title": "Extraction of Embedded Queries via Static Analysis of Host Code",
            "Publication year": 2017,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-319-59536-8_32",
            "Abstract": "Correctly identifying the embedded queries within the source code of an information system is a significant aid to developers and administrators, as it can facilitate the visualization of a map of the information system, the identification of areas affected by schema evolution, code migration, and the planning of the joint maintenance of code and data. In this paper, we provide a solution to the problem of identifying the location and semantics of embedded queries with a generic, language-independent method that identifies the embedded queries of a data-intensive ecosystem, regardless of the programming style and the host language, and represents them in a universal, also language-independent manner that facilitates the aforementioned maintenance, evolution and migration tasks with minimal user effort and significant effectiveness.",
            "Abstract entirety": 1,
            "Author pub id": "B_Zd1P8AAAAJ:epqYDVWIO7EC",
            "Publisher": "Springer, Cham"
        },
        {
            "Title": "Distributed Objects and Applications (DOA) 2005 International Conference-Mobility-Timely Provisioning of Mobile Services in Critical Pervasive Environments",
            "Publication year": 2005,
            "Publication url": "https://scholar.google.com/scholar?cluster=10592178997610001169&hl=en&oi=scholarr",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "B_Zd1P8AAAAJ:NhqRSupF_l8C",
            "Publisher": "Berlin: Springer-Verlag, 1973-"
        },
        {
            "Title": "ETL queues for active data warehousing",
            "Publication year": 2005,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/1077501.1077509",
            "Abstract": "Traditionally, the refreshment of data warehouses has been performed in an off-line fashion. Active Data Warehousing refers to a new trend where data warehouses are updated as frequently as possible, to accommodate the high demands of users for fresh data. In this paper, we propose a framework for the implementation of active data warehousing, with the following goals:(a) minimal changes in the software configuration of the source,(b) minimal overhead for the source due to the active nature of data propagation,(c) the possibility of smoothly regulating the overall configuration of the environment in a principled way. In our framework, we have implemented ETL activities over queue networks and employ queue theory for the prediction of the performance and the tuning of the operation of the overall refreshment process. Due to the performance overheads incurred, we explore different architectural choices for \u2026",
            "Abstract entirety": 0,
            "Author pub id": "B_Zd1P8AAAAJ:0EnyYjriUFMC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Benchmarking ETL workflows",
            "Publication year": 2009,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-642-10424-4_15",
            "Abstract": "Extraction\u2013Transform\u2013Load (ETL) processes comprise complex data workflows, which are responsible for the maintenance of a Data Warehouse. A plethora of ETL tools is currently available constituting a multi-million dollar market. Each ETL tool uses its own technique for the design and implementation of an ETL workflow, making the task of assessing ETL tools extremely difficult. In this paper, we identify common characteristics of ETL workflows in an effort of proposing a unified evaluation method for ETL. We also identify the main points of interest in designing, implementing, and maintaining ETL workflows. Finally, we propose a principled organization of test suites based on the TPC-H schema for the problem of experimenting with ETL workflows.",
            "Abstract entirety": 1,
            "Author pub id": "B_Zd1P8AAAAJ:e5wmG9Sq2KIC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "Similarity measures for multidimensional data",
            "Publication year": 2011,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/5767869/",
            "Abstract": "How similar are two data-cubes? In other words, the question under consideration is: given two sets of points in a multidimensional hierarchical space, what is the distance value between them? In this paper we explore various distance functions that can be used over multidimensional hierarchical spaces. We organize the discussed functions with respect to the properties of the dimension hierarchies, levels and values. In order to discover which distance functions are more suitable and meaningful to the users, we conducted two user study analysis. The first user study analysis concerns the most preferred distance function between two values of a dimension. The findings of this user study indicate that the functions that seem to fit better the user needs are characterized by the tendency to consider as closest to a point in a multidimensional space, points with the smallest shortest path with respect to the same \u2026",
            "Abstract entirety": 0,
            "Author pub id": "B_Zd1P8AAAAJ:KxtntwgDAa4C",
            "Publisher": "IEEE"
        },
        {
            "Title": "Hiding Design-Decisions in Service-Oriented Software via Service Abstraction Recovery",
            "Publication year": 2010,
            "Publication url": "https://hal.inria.fr/inria-00491349/",
            "Abstract": "In this paper, we propose an approach for the recovery of service abstractions out of sets of available services that play the role of alternative design-decisions, which can be used in a service-oriented application. A service abstraction provides a uniform interface that hides dierences in the interfaces of alternative services and consequently allows reducing the coupling between the application and the services. To this end, we formally define the notion of service abstraction and propose a hierarchical clustering algorithm that incrementally recovers a hierarchy of service abstractions out of a given set of alternative design-decisions/services. Finally, we evaluate the proposed algorithm with real-world sets of services and report on our findings.",
            "Abstract entirety": 1,
            "Author pub id": "B_Zd1P8AAAAJ:RYcK_YlVTxYC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Sequential greedy approximation for certain convex optimization problems",
            "Publication year": 2003,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/1184144/",
            "Abstract": "A greedy algorithm for a class of convex optimization problems is presented. The algorithm is motivated from function approximation using a sparse combination of basis functions as well as some of its variants. We derive a bound on the rate of approximate minimization for this algorithm, and present examples of its application. Our analysis generalizes a number of earlier studies.",
            "Abstract entirety": 1,
            "Author pub id": "B_Zd1P8AAAAJ:HbR8gkJAVGIC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Quality-Driven Data Warehouse Design",
            "Publication year": 2003,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-662-05153-5_8",
            "Abstract": "This final chapter links the metadata framework presented in Chap. 7 with the algorithms presented in earlier chapters to describe a systematic solution to incorporate quality aspects into design problems encountered in data warehousing. This solution, developed in the DWQ project, will be illustrated through an example. Then, one missing building block not yet covered in earlier chapters \u2014 the optimization of view materialization \u2014 will be discussed with an outlook on current challenges and extensions to data warehousing.",
            "Abstract entirety": 1,
            "Author pub id": "B_Zd1P8AAAAJ:mvPsJ3kp5DgC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "Cross-layer routing for peer database querying over mobile ad hoc networks",
            "Publication year": 2012,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S1389128611003707",
            "Abstract": "The widespread of mobile ad hoc networking calls for a careful design of network functions in order to meet the application requirements and economize on the limited resources. In this paper we address the problem of distributing query messages among peers in mobile ad hoc networks. We assume that peers are organized in classes. Each peer possesses a local database and can answer queries posed by other peers. Each peer can also pose queries to all the peers belonging to a certain class or classes. Contrary to traditional p2p lookup queries, we are interested in collecting answers from as many peers as possible. We propose a query routing protocol, called CL-QF, which is based on a novel cross-layer design. The purpose of this design is to incorporate application layer specifics (e.g., class information) into the network layer in order to reduce transmissions therefore economize on resources. CL-QF \u2026",
            "Abstract entirety": 0,
            "Author pub id": "B_Zd1P8AAAAJ:4OULZ7Gr8RgC",
            "Publisher": "Elsevier"
        },
        {
            "Title": "Supporting streaming updates in an active data warehouse",
            "Publication year": 2007,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/4221696/",
            "Abstract": "Active data warehousing has emerged as an alternative to conventional warehousing practices in order to meet the high demand of applications for up-to-date information. In a nutshell, an active warehouse is refreshed on-line and thus achieves a higher consistency between the stored information and the latest data updates. The need for on-line warehouse refreshment introduces several challenges in the implementation of data warehouse transformations, with respect to their execution time and their overhead to the warehouse processes. In this paper, we focus on a frequently encountered operation in this context, namely, the join of a fast stream S of source updates with a disk-based relation R, under the constraint of limited memory. This operation lies at the core of several common transformations, such as, surrogate key assignment, duplicate detection or identification of newly inserted tuples. We propose a \u2026",
            "Abstract entirety": 0,
            "Author pub id": "B_Zd1P8AAAAJ:UebtZRa9Y70C",
            "Publisher": "IEEE"
        },
        {
            "Title": "On relaxing contextual preference queries",
            "Publication year": 2007,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/4417168/",
            "Abstract": "Personalization systems exploit preferences for providing users with only relevant data from the huge volume of information that is currently available. We consider preferences that dependent on context, such as the location of the user. We model context as a set of attributes, each taking values from hierarchical domains. Often, the context of the query may be too specific to match any of the given preferences. In this paper, we consider possible expansions of the query context produced by relaxing one or more of its context attributes. A hierarchical attribute may be relaxed upwards by replacing its value by a more general one, downwards by replacing its value by a set of more specific values or sideways by replacing its value by sibling values in the hierarchy. We present an algorithm based on a prefix-based representation of context for identifying the preferences whose context matches the relaxed context of the \u2026",
            "Abstract entirety": 0,
            "Author pub id": "B_Zd1P8AAAAJ:r0BpntZqJG4C",
            "Publisher": "IEEE"
        },
        {
            "Title": "Towards a conceptual model for data narratives",
            "Publication year": 2020,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-030-62522-1_19",
            "Abstract": "Data narration is the activity of producing stories supported by facts extracted from data analysis, possibly using interactive visualizations. In spite of the increasing interest in data narration in several communities (e.g. journalism, business, e-government), there is no consensual definition of data narrative, let alone a conceptual or logical model of it. In this paper, we propose a conceptual model of data narrative for exploratory data analysis. It is based on four layers that reflect the transition from raw data to the visual rendering of the data story: factual, intentional, structural and presentational. This model aims to support the entire lifecycle of building a data narrative, starting from an intentional goal: fetch and explore data, bring out highlights, derive important messages, structure the plot of the data narrative, and render it in a visual manner. Our contributions include a description of the model and its instantiation for \u2026",
            "Abstract entirety": 0,
            "Author pub id": "B_Zd1P8AAAAJ:86PQX7AUzd4C",
            "Publisher": "Springer, Cham"
        },
        {
            "Title": "Data warehouse metadata encyclopedia of database systems",
            "Publication year": 2009,
            "Publication url": "http://62.217.125.140/jspui/handle/123456789/26769",
            "Abstract": "Repository of UOI \"Olympias\": Data warehouse metadata encyclopedia of database \nsystems Skip navigation Home Browse Communities & Collections Browse Items by: Issue \nDate Author Title Subject Item Type Advanced Search Help About DSpace Sign on to: My \nDSpace Receive email updates Edit Profile Saved Searches Favorites Repository of UOI \"Olympias\" \n1.Repository of OAI 2.\u0391\u03a0\u039f\u0398\u0395\u03a4\u0397\u03a1\u0399\u039f \"\u039f\u039b\u03a5\u039c\u03a0\u0399\u0391\u03a3\" 3.\u03a3\u03c7\u03bf\u03bb\u03ae \u0398\u03b5\u03c4\u03b9\u03ba\u03ce\u03bd \u0395\u03c0\u03b9\u03c3\u03c4\u03b7\u03bc\u03ce\u03bd 4.\u03a4\u03bc\u03ae\u03bc\u03b1 \n\u039c\u03b7\u03c7\u03b1\u03bd\u03b9\u03ba\u03ce\u03bd \u0397\u03bb\u03b5\u03ba\u03c4\u03c1\u03bf\u03bd\u03b9\u03ba\u03ce\u03bd \u03a5\u03c0\u03bf\u03bb\u03bf\u03b3\u03b9\u03c3\u03c4\u03ce\u03bd \u03ba\u03b1\u03b9 \u03a0\u03bb\u03b7\u03c1\u03bf\u03c6\u03bf\u03c1\u03b9\u03ba\u03ae\u03c2 5.\u039c\u03bf\u03bd\u03bf\u03b3\u03c1\u03b1\u03c6\u03af\u03b5\u03c2 ( \u039a\u03bb\u03b5\u03b9\u03c3\u03c4\u03ad\u03c2) \n\u0395\u03bb\u03bb\u03b7\u03bd\u03b9\u03ba\u03ac English Please use this identifier to cite or link to this item: https://olympias.lib.uoi.gr/jspui/handle/123456789/26769 \nInstitution and School/Department of submitter: \u03a0\u03b1\u03bd\u03b5\u03c0\u03b9\u03c3\u03c4\u03ae\u03bc\u03b9\u03bf \u0399\u03c9\u03b1\u03bd\u03bd\u03af\u03bd\u03c9\u03bd. \u03a3\u03c7\u03bf\u03bb\u03ae \u0398\u03b5\u03c4\u03b9\u03ba\u03ce\u03bd \n\u0395\u03c0\u03b9\u03c3\u03c4\u03b7\u03bc\u03ce\u03bd. \u03a4\u03bc\u03ae\u03bc\u03b1 \u039c\u03b7\u03c7\u03b1\u03bd\u03b9\u03ba\u03ce\u03bd \u0397/\u03a5 & \u03a0\u03bb\u03b7\u03c1\u03bf\u03c6\u03bf\u03c1\u03b9\u03ba\u03ae\u03c2 Keywords: - URI: https://olympias.lib.uoi.gr/jspui/handle/123456789/26769 \nPublisher: Springer Book name: - Appears : : \u2026",
            "Abstract entirety": 0,
            "Author pub id": "B_Zd1P8AAAAJ:AvfA0Oy_GE0C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Contribution \u00e0 la d\u00e9finition d\u2019une m\u00e9thodologie et d\u2019un outil de mod\u00e9lisation et de mesure de la performance des services publics.",
            "Publication year": 2011,
            "Publication url": "https://www.academia.edu/download/52085547/_Badja-Contribution.pdf",
            "Abstract": "Les organismes de service public doivent relever de nouveaux d\u00e9fis parmi lesquels la satisfaction de leurs partenaires de mani\u00e8re efficiente. Pour r\u00e9pondre \u00e0 de telles exigences, ces organismes doivent d\u00e9finir une strat\u00e9gie de gestion des services et mettre en place un syst\u00e8me de mesure de performance permettant d\u2019appr\u00e9cier les r\u00e9sultats obtenus.De par leur nature, les organismes de service public sont concern\u00e9s par les probl\u00e9matiques inh\u00e9rentes aux services (une d\u00e9finition parfois floue, des difficult\u00e9s \u00e0 mod\u00e9liser et \u00e0 contr\u00f4ler l\u2019activit\u00e9 de service, une interaction forte avec l\u2019usager qui rend le service difficile \u00e0 \u00e9valuer, etc.) en plus d\u2019\u00eatre soumis \u00e0 la loi organique relative aux lois de finance. Il en r\u00e9sulte une complexit\u00e9 d\u2019analyse et de compr\u00e9hension de ce que sont les services publics et des moyens permettant de les rationaliser.",
            "Abstract entirety": 1,
            "Author pub id": "B_Zd1P8AAAAJ:abG-DnoFyZgC",
            "Publisher": "Unknown"
        },
        {
            "Title": "In-situ visual exploration over big raw data",
            "Publication year": 2021,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S0306437920300910",
            "Abstract": "Data exploration and visual analytics systems are of great importance in Open Science scenarios, where less tech-savvy researchers wish to access and visually explore big raw data files (eg, json, csv) generated by scientific experiments using commodity hardware and without being overwhelmed in the tedious processes of data loading, indexing and query optimization. In this paper, we present our work for enabling efficient query processing on large raw data files for interactive visual exploration scenarios and analytics. We introduce a framework, named RawVis, built on top of a lightweight in-memory tile-based index, VALINOR, that is constructed on-the-fly given the first user query over a raw file and progressively adapted based on the user interaction. We evaluate the performance of a prototype implementation compared to three other alternatives and show that our method outperforms in terms of response \u2026",
            "Abstract entirety": 0,
            "Author pub id": "B_Zd1P8AAAAJ:ClCfbGk0d_YC",
            "Publisher": "Pergamon"
        },
        {
            "Title": "Gulliver in the land of data warehousing: practical experiences and observations of a researcher.",
            "Publication year": 2000,
            "Publication url": "http://www.cse.uoi.gr/~pvassil/publications/2000_DMDW/dmdw00.pdf",
            "Abstract": "The gap between researchers and practitioners is widely discussed in the IT community. The purpose of this paper is towards showing the issues which occupy both research and practice, and the extent to which these issues have any overlap, in the field of data warehousing. To achieve this goal we first present the current status and tendencies in data warehouse research. Then we list several practical problems as they appear in the relevant literature, based also on our personal experience. Finally, we try to give the relationship of research and practice into a unified big picture.",
            "Abstract entirety": 1,
            "Author pub id": "B_Zd1P8AAAAJ:zYLM7Y9cAGgC",
            "Publisher": "Unknown"
        },
        {
            "Title": "RawVis: Visual Exploration over Raw Data",
            "Publication year": 2018,
            "Publication url": "https://link.springer.com/content/pdf/10.1007/978-3-319-98398-1.pdf#page=68",
            "Abstract": "Data exploration and visual analytics systems are of great importance in Open Science scenarios, where less tech-savvy researchers wish to access and visually explore big raw data files (eg, json, csv) generated by scientific experiments using commodity hardware and without being overwhelmed in the tedious processes of data loading, indexing and query optimization. In this work, we present our work for enabling efficient query processing on raw data files for interactive visual exploration scenarios. We introduce a framework, named RawVis, built on top of a lightweight in-memory tile-based index, VALINOR, that is constructed on-the-fly given the first user query over a raw file and adapted based on the user interaction. We evaluate the performance of prototype implementation compared to three other alternatives and show that our method outperforms in terms of response time, disk accesses and memory \u2026",
            "Abstract entirety": 0,
            "Author pub id": "B_Zd1P8AAAAJ:b1wdh0AR-JQC",
            "Publisher": "Springer"
        },
        {
            "Title": "Architecture for pattern-base management systems",
            "Publication year": 2003,
            "Publication url": "http://infolab.cs.unipi.gr/people/ntoutsi/papers/03.TR02.pdf#page=23",
            "Abstract": "In many modern applications we have to deal with huge volumes of data. Many techniques have been developed on how to extract knowledge, statistical usually, from them, especially in the context of data mining. The results of such operations are abstract and compact representations of the original data, which we namepatterns. Still, these patterns have to be further elaborated to be used in an effective way. In this paper we present the architecture of a Pattern Base Management System that can be used to efficiently store, and query patterns. We present its logical structure and we comment on the criteria of whether the existing systems for storing and manipulating data can cover the special user requirements that patterns impose.",
            "Abstract entirety": 1,
            "Author pub id": "B_Zd1P8AAAAJ:vRqMK49ujn8C",
            "Publisher": "Unknown"
        },
        {
            "Title": "On the logical modeling of ETL processes",
            "Publication year": 2002,
            "Publication url": "https://link.springer.com/chapter/10.1007/3-540-47961-9_67",
            "Abstract": "Extraction-Transformation-Loading (ETL) tools are pieces of software responsible for the extraction of data from several sources, their cleansing, customization and insertion into a data warehouse. Research has only recently dealt with the above problem and provided few models, tools and techniques to address the issues around the ETL environment [1,2,3,5]. In this paper, we present a logical model for ETL processes. The proposed model is characterized by several templates, representing frequently used ETL activities along with their semantics and their interconnection. In the full version of the paper [4] we present more details on the aforementioned issues and complement them with results on the characterization of the content of the involved data stores after the execution of an ETL scenario and impact-analysis results in the presence of changes.",
            "Abstract entirety": 1,
            "Author pub id": "B_Zd1P8AAAAJ:ULOm3_A8WrAC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "Modeling and language support for the management of pattern-bases",
            "Publication year": 2007,
            "Publication url": "https://docs.lib.purdue.edu/ccpubs/300/",
            "Abstract": "Information overloading is today a serious concern that may hinder the potential of modern web-based information systems. A promising approach to deal with this problem is represented by knowledge extraction methods able to produce artifacts (also called patterns) that concisely represent data. Patterns are usually quite heterogeneous and voluminous. So far, little emphasis has been posed on developing an overall integrated environment for uniformly representing and querying different types of patterns. In this paper we consider the larger problem of modeling, storing, and querying patterns, in a database-like setting and use a Pattern-Base Management System (PBMS) for this purpose. Specifically,(a) we formally define the logical foundations for the global setting of pattern management through a model that covers data, patterns, and their intermediate mappings;(b) we present a formalism for pattern specification along with safety restrictions; and (c) we introduce predicates for comparing patterns and query operators",
            "Abstract entirety": 1,
            "Author pub id": "B_Zd1P8AAAAJ:SP6oXDckpogC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Language Extensions for the Automation of Database Schema Evolution.",
            "Publication year": 2008,
            "Publication url": "https://www.cs.uoi.gr/~pvassil/publications/2008_ICEIS/ICEIS_2008.pdf",
            "Abstract": "2Department of Computer Science, University of Ioannina, Ioannina, Greece {pvassil, fpechliv, kostazz}@ cs. uoi. gr 3IBM Almaden Research Center, San Jose, California, USA asimits@ us. ibm. com",
            "Abstract entirety": 1,
            "Author pub id": "B_Zd1P8AAAAJ:TQgYirikUcIC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Automating the adaptation of evolving data-intensive ecosystems",
            "Publication year": 2013,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-642-41924-9_17",
            "Abstract": "Data-intensive ecosystems are conglomerations of data repositories surrounded by applications that depend on them for their operation. To support the graceful evolution of the ecosystem\u2019s components we annotate them with policies for their response to evolutionary events. In this paper, we provide a method for the adaptation of ecosystems based on three algorithms that (i) assess the impact of a change, (ii) compute the need of different variants of an ecosystem\u2019s components, depending on policy conflicts, and (iii) rewrite the modules to adapt to the change.",
            "Abstract entirety": 1,
            "Author pub id": "B_Zd1P8AAAAJ:eMMeJKvmdy0C",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "Schema evolution and foreign keys: a study on usage, heartbeat of change and relationship of foreign keys to table activity",
            "Publication year": 2019,
            "Publication url": "https://link.springer.com/article/10.1007/s00607-019-00702-x",
            "Abstract": "In this paper, we study the evolution of foreign keys in the context of schema evolution for relational databases. Specifically, we study the schema histories of a six free, open-source databases that contain foreign keys. Our findings verify previous results that schemata grow in the long run in terms of tables. To our surprise, we discovered that foreign keys appear to be fairly scarce in the projects that we have studied and they do not necessarily grow in sync with table growth. In fact, we have observed different \u201ccultures\u201d for the handling of foreign keys, ranging from treating foreign keys as an indispensable part of the schema, in full sync with the growth of tables, to the unexpected extreme of treating foreign keys as an optional add-on that twice resulted in their full removal from the schema of the database. Apart from the behavior of entire schemata, we have also studied the behavior of individual tables. We \u2026",
            "Abstract entirety": 0,
            "Author pub id": "B_Zd1P8AAAAJ:LI9QrySNdTsC",
            "Publisher": "Springer Vienna"
        },
        {
            "Title": "Navigating through the Archipelago of Refactorings",
            "Publication year": 2015,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/2786805.2803203",
            "Abstract": "The essence of refactoring is to improve software quality via the systematic combination of primitive refactorings. Yet, there are way too many refactorings. Choosing which refactorings to use, how to combine them and how to integrate them in more complex evolution tasks is really hard. Our vision is to provide the developer with a\" trip advisor\" for the archipelago of refactorings. The core idea of our approach is the map of the archipelago of refactorings, which identies the basic relations that guide the systematic and eective combination of refactorings. Based on the map, the trip advisor makes suggestions that allow the developer to decide how to start, assess the possible alternatives, have a clear picture of what has to be done before, during and after the refactorings and assess the possible implications.",
            "Abstract entirety": 1,
            "Author pub id": "B_Zd1P8AAAAJ:hkOj_22Ku90C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Extraction-transformation-loading processes",
            "Publication year": 2005,
            "Publication url": "https://www.igi-global.com/chapter/extraction-transformation-loading-processes/11153",
            "Abstract": "A data warehouse (DW) is a collection of technologies aimed at enabling the knowledge worker (executive, manager, analyst, etc.) to make better and faster decisions. The architecture of a DW exhibits various layers of data in which data from one layer are derived from data of the lower layer (see Figure 1). The operational databases, also called data sources, form the starting layer. They may consist of structured data stored in open database and legacy systems, or even in files. The central layer of the architecture is the global DW. The global DW keeps a historical record of data that result from the transformation, integration, and aggregation of detailed data found in the data sources. An auxiliary area of volatile data, data staging area (DSA) is employed for the purpose of data transformation, reconciliation, and cleaning. The next layer of data involves client warehouses, which contain highly aggregated data \u2026",
            "Abstract entirety": 0,
            "Author pub id": "B_Zd1P8AAAAJ:YFjsv_pBGBYC",
            "Publisher": "IGI Global"
        },
        {
            "Title": "A Framework for the Design of ETL Scenarios",
            "Publication year": 2003,
            "Publication url": "https://link.springer.com/chapter/10.1007/3-540-45017-3_35",
            "Abstract": "Extraction-Transformation-Loading (ETL) tools are pieces of software responsible for the extraction of data from several sources, their cleansing, customization and insertion into a data warehouse. In this paper, we delve into the logical design of ETL scenarios. We describe a framework for the declarative specification of ETL scenarios with two main characteristics: genericity and customization. Moreover, we present a palette of several templates, representing frequently used ETL activities along with their semantics and their interconnection. Finally, we discuss implementation issues and we present a graphical tool, ARKTOS II that facilitates the design of ETL scenarios, based on our model.",
            "Abstract entirety": 1,
            "Author pub id": "B_Zd1P8AAAAJ:Se3iqnhoufwC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "Adding context to preferences",
            "Publication year": 2007,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/4221733/",
            "Abstract": "To handle the overwhelming amount of information currently available, personalization systems allow users to specify the information that interests them through preferences. Most often, users have different preferences depending on context. In this paper, we introduce a model for expressing such contextual preferences. Context is modeled as a set of multidimensional attributes. We formulate the context resolution problem as the problem of (a) identifying those preferences that qualify to encompass the context state of a query and (b) selecting the most appropriate among them. We also propose an algorithm for context resolution that uses a data structure, called the profile tree, that indexes preferences based on their associated context. Finally, we evaluate our approach from two perspectives: usability and performance.",
            "Abstract entirety": 1,
            "Author pub id": "B_Zd1P8AAAAJ:WF5omc3nYNoC",
            "Publisher": "IEEE"
        },
        {
            "Title": "schedule-Aware transactions for Ambient Intelligence environments",
            "Publication year": 2010,
            "Publication url": "https://www.igi-global.com/article/schedule-aware-transactions-ambient-intelligence/47177",
            "Abstract": "In this paper, the authors investigate the concept of designing user-centric transaction protocols toward achieving dependable coordination in AmI environments. As a proof-of-concept, this paper presents a protocol that takes into account the schedules of roaming users, which move from one AmI environment to another, avoiding abnormal termination of transactions when users leave an environment for a short time and return later. The authors compare the proposed schedule-aware protocol against a schedule-agnostic one. Findings show that the use of user-centric information in such situations is quite beneficial.",
            "Abstract entirety": 1,
            "Author pub id": "B_Zd1P8AAAAJ:xtRiw3GOFMkC",
            "Publisher": "IGI Global"
        },
        {
            "Title": "Modelling and Optimisation Issues",
            "Publication year": 2003,
            "Publication url": "https://books.google.com/books?hl=en&lr=&id=0f5pCQAAQBAJ&oi=fnd&pg=PA482&dq=info:nZvsnBGRbsMJ:scholar.google.com&ots=SObUF85fRG&sig=vmZjq5c3hDA6nNnqaKLsCZ587Co",
            "Abstract": "It is commonly agreed that multidimensional data cubes form the basic logical data model for OLAP applications. Still, there seems to be no agreement on a common model for cubes. In this paper we propose a logical model for cubes based on the key observation that a cube is not a self-existing entity, but rather a view over an underlying data set. We accompany our model with syntactic characterisations for the problem of cube usability. To this end, we have developed algorithms to check whether (a) the marginal conditions of two cubes are appropriate for a rewriting, in the presence of aggregation hierarchies and (b) an implication exists between two selection conditions that involve different levels of aggregation of the same dimension hierarchy. Finally, we present a rewriting algorithm for the cube usability problem.",
            "Abstract entirety": 1,
            "Author pub id": "B_Zd1P8AAAAJ:ZuybSZzF8UAC",
            "Publisher": "Springer"
        },
        {
            "Title": "State-space optimization of ETL workflows",
            "Publication year": 2005,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/1501823/",
            "Abstract": "Extraction-transformation-loading (ETL) tools are pieces of software responsible for the extraction of data from several sources, their cleansing, customization, and insertion into a data warehouse. In this paper, we derive into the logical optimization of ETL processes, modeling it as a state-space search problem. We consider each ETL workflow as a state and fabricate the state space through a set of correct state transitions. Moreover, we provide an exhaustive and two heuristic algorithms toward the minimization of the execution cost of an ETL workflow. The heuristic algorithm with greedy characteristics significantly outperforms the other two algorithms for a large set of experimental cases.",
            "Abstract entirety": 1,
            "Author pub id": "B_Zd1P8AAAAJ:roLk4NBRz8UC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Data mapping diagrams for data warehouse design with UML",
            "Publication year": 2004,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-540-30464-7_16",
            "Abstract": "In Data Warehouse (DW) scenarios, ETL (Extraction, Transformation, Loading) processes are responsible for the extraction of data from heterogeneous operational data sources, their transformation (conversion, cleaning, normalization, etc.) and their loading into the DW. In this paper, we present a framework for the design of the DW back-stage (and the respective ETL processes) based on the key observation that this task fundamentally involves dealing with the specificities of information at very low levels of granularity including transformation rules at the attribute level. Specifically, we present a disciplined framework for the modeling of the relationships between sources and targets in different levels of granularity (including coarse mappings at the database and table levels to detailed inter-attribute mappings at the attribute level). In order to accomplish this goal, we extend UML (Unified Modeling \u2026",
            "Abstract entirety": 0,
            "Author pub id": "B_Zd1P8AAAAJ:W7OEmFMy1HYC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "MDM: governing evolution in big data ecosystems",
            "Publication year": 2018,
            "Publication url": "https://upcommons.upc.edu/handle/2117/128004",
            "Abstract": "On-demand integration of multiple data sources is a critical requirement in many Big Data settings. This has been coined as the data variety challenge, which refers to the complexity of dealing with an heterogeneous set of data sources to enable their integrated analysis. In Big Data settings, data sources are commonly represented by external REST APIs, which provide data in their original format and continously apply changes in their structure (i.e., schema). Thus, data analysts face the challenge to integrate such multiple sources, and then continuosly adapt their analytical processes to changes in the schema. To address this challenges, in this paper, we present the Metadata Management System, shortly MDM, a tool that supports data stewards and analysts to manage the integration and analysis of multiple heterogeneous sources under schema evolution. MDM adopts a vocabulary-based integration-oriented ontology to conceptualize the domain of interest and relies on local-as-view mappings to link it with the sources. MDM provides user-friendly mechanisms to manage the ontology and mappings. Finally, a query rewriting algorithm ensures that queries posed to the ontology are correctly resolved to the sources in the presence of multiple schema versions, a transparent process to data analysts. On-site, we will showcase using real-world examples how MDM facilitates the management of multiple evolving data sources and enables its integrated analysis.",
            "Abstract entirety": 1,
            "Author pub id": "B_Zd1P8AAAAJ:hMsQuOkrut0C",
            "Publisher": "OpenProceedings"
        },
        {
            "Title": "Policy-regulated management of ETL evolution",
            "Publication year": 2009,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-642-03098-7_6",
            "Abstract": "In this paper, we discuss the problem of performing impact prediction for changes that occur in the schema/structure of the data warehouse sources. We abstract Extract-Transform-Load (ETL) activities as queries and sequences of views. ETL activities and its sources are uniformly modeled as a graph that is annotated with policies for the management of evolution events. Given a change at an element of the graph, our method detects the parts of the graph that are affected by this change and highlights the way they are tuned to respond to it. For many cases of ETL source evolution, we present rules so that both syntactical and semantic correctness of activities are retained. Finally, we experiment with the evaluation of our approach over real-world ETL workflows used in the Greek public sector.",
            "Abstract entirety": 1,
            "Author pub id": "B_Zd1P8AAAAJ:ZeXyd9-uunAC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "Keep calm and wait for the spike! insights on the evolution of Amazon services",
            "Publication year": 2016,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-319-39696-5_27",
            "Abstract": "Web services are black box dependency magnets. Hence, studying how they evolve is both important and challenging. In this paper, we focus on one of the most successful stories of the service-oriented paradigm in industry, i.e., the Amazon services. We perform a principled empirical study, that detects evolution patterns and regularities, based on Lehman\u2019s laws of software evolution. Our findings indicate that service evolution comes with spikes of change, followed by calm periods where the service is internally enhanced. Although spikes come with unpredictable volume, developers can count in the near certainty of the calm periods following them to allow their absorption. As deletions rarely occur, both the complexity and the exported functionality of a service increase over time (in fact, predictably). Based on the above findings, we provide recommendations that can be used by the developers of Web \u2026",
            "Abstract entirety": 0,
            "Author pub id": "B_Zd1P8AAAAJ:j8SEvjWlNXcC",
            "Publisher": "Springer, Cham"
        },
        {
            "Title": "Management of the evolution of database-centric information systems",
            "Publication year": 2007,
            "Publication url": "https://www.researchgate.net/profile/George-Papastefanatos/publication/250797099_Management_of_the_Evolution_of_Database-Centric_Information_Systems/links/0deec5294adb5be4b8000000/Management-of-the-Evolution-of-Database-Centric-Information-Systems.pdf",
            "Abstract": "Assume a database surrounded by a large variety of applications depending on it. For example, data entry or query forms are used by hundreds of users updating or querying information and complex workflows that operate in the enterprise frequently pose queries to the database. What happens if we delete a popular attribute from a relation in the database? Typically, all applications accessing this attribute will crash. Take for example, the case in Figure 1, where we use an Architecture-graph-like sketch representation of two relations (WORKS and EMP) and a query Q1. Observe the attribute EMP. Emp#, which is the Primary Key (PK) of relation EMP. Its role is such that it participates as (1) a grouper in the group-by query Q1,(2) a part of join condition between relations EMP and WORKS,(3) a part of the result of Q1, while, at the same time,(4) it is also part of a foreign key in the database. Clearly, the impact of deleting this attribute is significantly higher for the structure of the database and its surrounding applications, than, eg, attribute WORKS. Hours. At the same, if for some reason we would like to alter the primary key of relation EMP, this would incur even higher reconstruction costs of the database (both due to the presence of query Q1 and the foreign key among relations WORKS and EMP).",
            "Abstract entirety": 1,
            "Author pub id": "B_Zd1P8AAAAJ:isC4tDSrTZIC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Efficient answering of set containment queries for skewed item distributions",
            "Publication year": 2011,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/1951365.1951394",
            "Abstract": "In this paper we address the problem of efficiently evaluating containment (ie, subset, equality, and superset) queries over set-valued data. We propose a novel indexing scheme, the Ordered Inverted File (OIF) which, differently from the state-of-the-art, indexes set-valued attributes in an ordered fashion. We introduce query processing algorithms that practically treat containment queries as range queries over the ordered postings lists of OIF and exploit this ordering to quickly prune unnecessary page accesses. OIF is simple to implement and our experiments on both real and synthetic data show that it greatly outperforms the current state-of-the-art methods for all three classes of containment queries.",
            "Abstract entirety": 1,
            "Author pub id": "B_Zd1P8AAAAJ:ldfaerwXgEUC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Hecataeus: A what-if analysis tool for database schema evolution",
            "Publication year": 2008,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/4493341/",
            "Abstract": "Databases are continuously evolving environments, where design constructs are added, removed or updated rather often. Small changes in the database configurations might impact a large number of applications and data stores around the system: queries and data entry forms can be invalidated, application programs might crash. HECATAEUS is a tool, which represents the database schema along with its dependent workload, mainly queries and views, as a uniform directed graph. The tool enables the user to create hypothetical evolution events and examine their impact over the overall graph as well as to define rules so that both syntactical and semantic correctness of the affected workload is retained.",
            "Abstract entirety": 1,
            "Author pub id": "B_Zd1P8AAAAJ:iH-uZ7U-co4C",
            "Publisher": "IEEE"
        },
        {
            "Title": "CHOReOS Middleware Specification (D3. 1)",
            "Publication year": 2011,
            "Publication url": "https://hal.inria.fr/hal-00664253/",
            "Abstract": "This deliverable specifies the main concepts of the CHOReOS middleware architecture. Starting from the Future Internet (FI) challenges for scalability, heterogeneity, mobility, awareness, and adaptation that have been investigated in prior work done in WP1, we introduce the aforementioned concepts to deal with the requirements derived from the FI challenges. In particular, we propose an extensible and scalable service discovery approach for the organization and discovery of services that relies on multiple service discovery protocols. Moreover, we introduce an extensible and scalable approach, based on the service bus paradigm, for service access that features the integration and adaptation of multiple interaction protocols. Furthermore, we propose solutions that enable the execution of FI service compositions that range from compositions of choreographed services, developed according to the CHOReOS development process, to massive compositions of things. Finally, we detail the Cloud & Grid middleware facilities that support the overall middleware and the choreographies that are built on it, via a unified API that provides access to multiple cloud infrastructures (e.g., Amazon EC2, HP Open Cirrus, private clouds).",
            "Abstract entirety": 1,
            "Author pub id": "B_Zd1P8AAAAJ:b0M2c_1WBrUC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Service selection for happy users: making user-intuitive quality abstractions",
            "Publication year": 2012,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/2393596.2393632",
            "Abstract": "The state of the art service search engines allow the users to pick the services they need, based on the quality properties, offered by these services. To this end, the users should interact with the search engines based on the quality models that are imposed by the engines. This is a significant restriction towards making the service-oriented paradigm attractive to the general public. In this paper, we propose an approach that allows a user to specify his perception of quality in terms of a simple, user-defined quality model. The proposed approach automatically maps the user-defined quality model to the search engine's quality model. This mapping forms the basis for ordering, grouping and, in general manipulating, the results of the user's service discovery requests.",
            "Abstract entirety": 1,
            "Author pub id": "B_Zd1P8AAAAJ:geHnlv5EZngC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Policy regulated management of ETL evolution",
            "Publication year": 2009,
            "Publication url": "http://olympias.lib.uoi.gr/jspui/handle/123456789/11028",
            "Abstract": "Repository of UOI \"Olympias\": Policy regulated management of ETL evolution Skip navigation Home \nBrowse Communities & Collections Browse Items by: Issue Date Author Title Subject Item Type \nAdvanced Search Help About DSpace Sign on to: My DSpace Receive email updates Edit Profile \nSaved Searches Favorites Repository of UOI \"Olympias\" 1.Repository of OAI 2.\u0391\u03a0\u039f\u0398\u0395\u03a4\u0397\u03a1\u0399\u039f \n\"\u039f\u039b\u03a5\u039c\u03a0\u0399\u0391\u03a3\" 3.\u03a3\u03c7\u03bf\u03bb\u03ae \u0398\u03b5\u03c4\u03b9\u03ba\u03ce\u03bd \u0395\u03c0\u03b9\u03c3\u03c4\u03b7\u03bc\u03ce\u03bd 4.\u03a4\u03bc\u03ae\u03bc\u03b1 \u039c\u03b7\u03c7\u03b1\u03bd\u03b9\u03ba\u03ce\u03bd \u0397\u03bb\u03b5\u03ba\u03c4\u03c1\u03bf\u03bd\u03b9\u03ba\u03ce\u03bd \u03a5\u03c0\u03bf\u03bb\u03bf\u03b3\u03b9\u03c3\u03c4\u03ce\u03bd \u03ba\u03b1\u03b9 \n\u03a0\u03bb\u03b7\u03c1\u03bf\u03c6\u03bf\u03c1\u03b9\u03ba\u03ae\u03c2 5.\u0386\u03c1\u03b8\u03c1\u03b1 \u03c3\u03b5 \u03b5\u03c0\u03b9\u03c3\u03c4\u03b7\u03bc\u03bf\u03bd\u03b9\u03ba\u03ac \u03c0\u03b5\u03c1\u03b9\u03bf\u03b4\u03b9\u03ba\u03ac ( \u0391\u03bd\u03bf\u03b9\u03ba\u03c4\u03ac) \u0395\u03bb\u03bb\u03b7\u03bd\u03b9\u03ba\u03ac English Please use this \nidentifier to cite or link to this item: https://olympias.lib.uoi.gr/jspui/handle/123456789/11028 \nInstitution and School/Department of submitter: \u03a0\u03b1\u03bd\u03b5\u03c0\u03b9\u03c3\u03c4\u03ae\u03bc\u03b9\u03bf \u0399\u03c9\u03b1\u03bd\u03bd\u03af\u03bd\u03c9\u03bd. \u03a3\u03c7\u03bf\u03bb\u03ae \u0398\u03b5\u03c4\u03b9\u03ba\u03ce\u03bd \n\u0395\u03c0\u03b9\u03c3\u03c4\u03b7\u03bc\u03ce\u03bd. \u03a4\u03bc\u03ae\u03bc\u03b1 \u039c\u03b7\u03c7\u03b1\u03bd\u03b9\u03ba\u03ce\u03bd \u0397\u03bb\u03b5\u03ba\u03c4\u03c1\u03bf\u03bd\u03b9\u03ba\u03ce\u03bd \u03a5\u03c0\u03bf\u03bb\u03bf\u03b3\u03b9\u03c3\u03c4\u03ce\u03bd \u03ba\u03b1\u03b9 \u03a0\u03bb\u03b7\u03c1\u03bf\u03c6\u03bf\u03c1\u03b9\u03ba\u03ae\u03c2 URI: \nhttps://olympias.lib.uoi.gr/jspui/handle/123456789/11028 Publisher: Springer in : \u03c3\u03b5 -\u2026",
            "Abstract entirety": 0,
            "Author pub id": "B_Zd1P8AAAAJ:ZfRJV9d4-WMC",
            "Publisher": "Unknown"
        },
        {
            "Title": "The Traveling Analyst Problem: Definition and preliminary study",
            "Publication year": 2020,
            "Publication url": "https://hal.archives-ouvertes.fr/hal-03001208/",
            "Abstract": "This paper introduces the Traveling Analyst Problem (TAP), an original strongly NP-hard problem where an automated algorithm assists an analyst to explore a dataset, by suggesting the most interesting and coherent set of queries that are estimated to be completed under a time constraint. We motivate the problem, study its complexity, propose a simple heuristic under simplifying assumptions for approximating it, and run preliminary tests to observe the behavior of this heuristic.",
            "Abstract entirety": 1,
            "Author pub id": "B_Zd1P8AAAAJ:0N-VGjzr574C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Towards a benefit-based optimizer for Interactive Data Analysis",
            "Publication year": 2019,
            "Publication url": "https://hal.archives-ouvertes.fr/hal-02375855/",
            "Abstract": "This vision paper introduces several ideas around the optimization of Interactive Data Analysis (IDA) tasks. With an eye on traditional query optimization (QO) in Relational DataBase Management Systems (RDBMS), we suggest that IDA tasks should be specified through high-level statements and optimized globally , particularly by maximizing the number and significance of insights that can be automatically collected for the task. We envision an architecture for IDA and propose in the context of IDA what corresponds to statistics, cost model and execution plan pruning strategy in relational systems. We give elements pertaining to the feasibility of the vision and draw perspectives.",
            "Abstract entirety": 1,
            "Author pub id": "B_Zd1P8AAAAJ:M7yex6snE4oC",
            "Publisher": "Unknown"
        },
        {
            "Title": "The NTUA viewpoint on the logical model of a PBMS",
            "Publication year": 2002,
            "Publication url": "https://scholar.google.com/scholar?cluster=7697513073494456141&hl=en&oi=scholarr",
            "Abstract": "The purpose of this document is to present our point of view on the logical model for the Pattern-Based Management System (PBMS). In this section, we will provide a framework that describes the way we believe patterns are collected, organized and defined in the PBMS.",
            "Abstract entirety": 1,
            "Author pub id": "B_Zd1P8AAAAJ:yD5IFk8b50cC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Modelling and optimisation issues for multidimensional databases",
            "Publication year": 2000,
            "Publication url": "https://link.springer.com/chapter/10.1007/3-540-45140-4_32",
            "Abstract": "It is commonly agreed that multidimensional data cubes form the basic logical data model for OLAP applications. Still, there seems to be no agreement on a common model for cubes. In this paper we propose a logical model for cubes based on the key observation that a cube is not a self-existing entity, but rather a view over an underlying data set. We accompany our model with syntactic characterisations for the problem of cube usability. To this end, we have developed algorithms to check whether (a) the marginal conditions of two cubes are appropriate for a rewriting, in the presence of aggregation hierarchies and (b) an implication exists between two selection conditions that involve different levels of aggregation of the same dimension hierarchy. Finally, we present a rewriting algorithm for the cube usability problem.",
            "Abstract entirety": 1,
            "Author pub id": "B_Zd1P8AAAAJ:5nxA0vEk-isC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "RawVis: A System for Efficient In-situ Visual Analytics",
            "Publication year": 2021,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/3448016.3452764",
            "Abstract": "In-situ processing has received a great deal of attention in recent years. In in-situ scenarios, big raw data files which do not fit in main memory, must be efficiently handled on-the-fly using commodity hardware, without the overhead of a preprocessing phase or the loading of data into a database system. This paper presents RawVis, an open source data visualization system for in-situ visual exploration and analytics over big raw data. RawVis implements novel indexing schemes and adaptive processing techniques allowing users to perform efficient visual and analytics operations directly over the data files. RawVis provides real-time interaction, reporting low response time, over large data files, using commodity hardware.",
            "Abstract entirety": 1,
            "Author pub id": "B_Zd1P8AAAAJ:4fGpz3EwCPoC",
            "Publisher": "Unknown"
        },
        {
            "Title": "A combination of trie-trees and inverted files for the indexing of set-valued attributes",
            "Publication year": 2006,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/1183614.1183718",
            "Abstract": "Set-valued attributes frequently occur in contexts like market-basked analysis and stock market trends. Late research literature has mainly focused on set containment joins and data mining without considering simple queries on set valued attributes. In this paper we address superset, subset and equality queries and we propose a novel indexing scheme for answering them on set-valued attributes. The proposed index superimposes a trie-tree on top of an inverted file that indexes a relation with set-valued data. We show that we can efficiently answer the aforementioned queries by indexing only a subset of the most frequent of the items that occur in the indexed relation. Finally, we show through extensive experiments that our approach outperforms the state of the art mechanisms and scales gracefully as database size grows.",
            "Abstract entirety": 1,
            "Author pub id": "B_Zd1P8AAAAJ:L8Ckcad2t8MC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Architecture for pattern base management systems",
            "Publication year": 2003,
            "Publication url": "https://scholar.google.com/scholar?cluster=15152731040745417280&hl=en&oi=scholarr",
            "Abstract": "Inmany modern applications we have todeal withhuge volumes of data. Many techniqueshavebeen developedon how to extract knowledge, statistical usually, from them, especially in thecontext of datamining. The results of such operations are abstract andcompact representations of the original data, which wename patterns. Still, these patternshave to be further elaborated to be used in an effective way. In this paper we present the architecture of a Pattern Base Management System that can be used to efficiently store, and query patterns. Wepresent its logical structureand we comment on the criteria of whether the existing systems for storing and manipulating data can cover the special user requirements that patterns impose.",
            "Abstract entirety": 1,
            "Author pub id": "B_Zd1P8AAAAJ:k8Z6L05lTy4C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Fitness workout for fat interfaces: Be slim, clean, and flexible",
            "Publication year": 2015,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/7332507/",
            "Abstract": "A class that provides a fat interface violates the interface segregation principle, which states that the clients of the class should not be coupled with methods that they do not need. Coping with this problem involves extracting interfaces that satisfy the needs of the clients. In this paper, we envision an interface extraction method that serves a combination of four principles: (1) fitness, as the extracted interfaces have to fit the needs of the clients, (2) clarity, as the interfaces should not be cluttered with duplicated methods declarations due to the clients' similar needs, (3) flexibility, as it should be easy to maintain the extracted interfaces to cope with client changes, without affecting parts of the software that are not concerned by the changes, and (4) practicality, as the interface extraction should account for practical issues like the number of extracted interfaces, domain/developer specific constraints on what to include in the \u2026",
            "Abstract entirety": 0,
            "Author pub id": "B_Zd1P8AAAAJ:dQ2og3OwTAUC",
            "Publisher": "IEEE"
        },
        {
            "Title": "A Methodology for the Conceptual Modeling of ETL Processes.",
            "Publication year": 2003,
            "Publication url": "http://ftp.informatik.rwth-aachen.de/Publications/CEUR-WS/Vol-75/files/DSE_04.pdf",
            "Abstract": "Extraction-Transformation-Loading (ETL) tools are pieces of software responsible for the extraction of data from several sources, their cleansing, customization and insertion into a data warehouse. In this paper, we propose a methodology for the earliest stages of the data warehouse design, with the goal of tracing the analysis of the structure and content of the existing data sources and their intentional mapping to the common conceptual data warehouse model. The methodology comprises a set of steps that can be summarized as follows:(a) identification of the proper data stores;(b) candidates and active candidates for the involved data stores;(c) attribute mapping between the providers and the consumers, and (d) annotation of the diagram with runtime constraints.",
            "Abstract entirety": 1,
            "Author pub id": "B_Zd1P8AAAAJ:KlAtU1dfN6UC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Graph-based modeling of ETL activities with multi-level transformations and updates",
            "Publication year": 2005,
            "Publication url": "https://link.springer.com/chapter/10.1007/11546849_5",
            "Abstract": "Extract-Transform-Load (ETL) workflows are data centric workflows responsible for transferring, cleaning, and loading data from their respective sources to the warehouse. In this paper, we build upon existing graph-based modeling techniques that treat ETL workflows as graphs by (a) extending the activity semantics to incorporate negation, aggregation and self-joins, (b) complementing querying semantics with insertions, deletions and updates, and (c) transforming the graph to allow zoom-in/out at multiple levels of abstraction (i.e., passing from the detailed description of the graph at the attribute level to more compact variants involving programs, relations and queries and vice-versa).",
            "Abstract entirety": 1,
            "Author pub id": "B_Zd1P8AAAAJ:QIV2ME_5wuYC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "Integrated CHOReOS middleware-Enabling large-scale, QoS-aware adaptive choreographies",
            "Publication year": 2013,
            "Publication url": "https://hal.inria.fr/hal-00912882/",
            "Abstract": "This document describes the final implementation and the evaluation of the CHOReOS middleware. Evaluation is achieved both via the use of the middleware on CHOReOS use-cases and via synthetic experiments and simulation. The conclusion was that the implementation of the CHOReOS middleware has achieved a good level of maturity for an open source project and it is ready to be used in real-world, complex choreographies.",
            "Abstract entirety": 1,
            "Author pub id": "B_Zd1P8AAAAJ:VL0QpB8kHFEC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Model-driven dependability analysis of webservices",
            "Publication year": 2004,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-540-30469-2_48",
            "Abstract": "This paper focuses on the development of a principled methodology for the dependability analysis of composite Web services. The first step of the methodology involves a UML representation for the architecture specification of composite Web services. The proposed representation is built upon BPEL and introduces necessary extensions to support the second step of the methodology, which comprises the specification of properties, characterizing the failure behavior of the elements that constitute the composite Web services. The automated mapping of this extended UML model to Block Diagrams and Markov models is introduced as the third step of the methodology. A comparative analysis of the aforementioned dependability analysis techniques in terms of precision and complexity is also performed.",
            "Abstract entirety": 1,
            "Author pub id": "B_Zd1P8AAAAJ:8k81kl-MbHgC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "Design of the Eratosthenes OLAP server",
            "Publication year": 2003,
            "Publication url": "http://olympias.lib.uoi.gr/jspui/handle/123456789/10779",
            "Abstract": "Repository of UOI \"Olympias\": Design of the Eratosthenes OLAP server Skip navigation \nHome Browse Communities & Collections Browse Items by: Issue Date Author Title Subject \nItem Type Advanced Search Help About DSpace Sign on to: My DSpace Receive email \nupdates Edit Profile Saved Searches Favorites Repository of UOI \"Olympias\" 1.Repository \nof OAI 2.\u0391\u03a0\u039f\u0398\u0395\u03a4\u0397\u03a1\u0399\u039f \"\u039f\u039b\u03a5\u039c\u03a0\u0399\u0391\u03a3\" 3.\u03a3\u03c7\u03bf\u03bb\u03ae \u0398\u03b5\u03c4\u03b9\u03ba\u03ce\u03bd \u0395\u03c0\u03b9\u03c3\u03c4\u03b7\u03bc\u03ce\u03bd 4.\u03a4\u03bc\u03ae\u03bc\u03b1 \u039c\u03b7\u03c7\u03b1\u03bd\u03b9\u03ba\u03ce\u03bd \n\u0397\u03bb\u03b5\u03ba\u03c4\u03c1\u03bf\u03bd\u03b9\u03ba\u03ce\u03bd \u03a5\u03c0\u03bf\u03bb\u03bf\u03b3\u03b9\u03c3\u03c4\u03ce\u03bd \u03ba\u03b1\u03b9 \u03a0\u03bb\u03b7\u03c1\u03bf\u03c6\u03bf\u03c1\u03b9\u03ba\u03ae\u03c2 5.\u0386\u03c1\u03b8\u03c1\u03b1 \u03c3\u03b5 \u03b5\u03c0\u03b9\u03c3\u03c4\u03b7\u03bc\u03bf\u03bd\u03b9\u03ba\u03ac \u03c0\u03b5\u03c1\u03b9\u03bf\u03b4\u03b9\u03ba\u03ac ( \u0391\u03bd\u03bf\u03b9\u03ba\u03c4\u03ac) \n\u0395\u03bb\u03bb\u03b7\u03bd\u03b9\u03ba\u03ac English Please use this identifier to cite or link to this item: https://olympias.lib.uoi.gr/jspui/handle/123456789/10779 \nInstitution and School/Department of submitter: \u03a0\u03b1\u03bd\u03b5\u03c0\u03b9\u03c3\u03c4\u03ae\u03bc\u03b9\u03bf \u0399\u03c9\u03b1\u03bd\u03bd\u03af\u03bd\u03c9\u03bd. \u03a3\u03c7\u03bf\u03bb\u03ae \u0398\u03b5\u03c4\u03b9\u03ba\u03ce\u03bd \n\u0395\u03c0\u03b9\u03c3\u03c4\u03b7\u03bc\u03ce\u03bd. \u03a4\u03bc\u03ae\u03bc\u03b1 \u039c\u03b7\u03c7\u03b1\u03bd\u03b9\u03ba\u03ce\u03bd \u0397\u03bb\u03b5\u03ba\u03c4\u03c1\u03bf\u03bd\u03b9\u03ba\u03ce\u03bd \u03a5\u03c0\u03bf\u03bb\u03bf\u03b3\u03b9\u03c3\u03c4\u03ce\u03bd \u03ba\u03b1\u03b9 \u03a0\u03bb\u03b7\u03c1\u03bf\u03c6\u03bf\u03c1\u03b9\u03ba\u03ae\u03c2 URI: https://olympias.lib.uoi.gr/jspui/handle/123456789/10779 \nPublisher: Springer Verlag in : \u03c3\u03b5 \u2026",
            "Abstract entirety": 0,
            "Author pub id": "B_Zd1P8AAAAJ:fEOibwPWpKIC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Mobile web services for context-aware pervasive environments",
            "Publication year": 2005,
            "Publication url": "https://www.researchgate.net/profile/Valerie-Issarny/publication/265022761_Mobile_Web_Services_for_Context-Aware_Pervasive_Environments/links/544e68010cf2bca5ce90b268/Mobile-Web-Services-for-Context-Aware-Pervasive-Environments.pdf",
            "Abstract": "In this paper we propose CoWSAMI, a service-oriented middleware that aims at supporting context-awareness in pervasive computing environments. To this end, we rely on the standard Web services architectural style to handle the architectural heterogeneity of available context sources. CoWSAMI balances the trend between the resource limitations of available context sources and the resource requirements introduced by the aforementioned standard, by employing WSAMI, a lightweight middleware infrastructure for the development of mobile Web services. CoWSAMI provides a dynamic and highly scalable service discovery mechanism that deals with the increased behavioral mobility of available context sources. CoWSAMI further handles the behavioral heterogeneity of available context sources through a mechanism that gathers contextual information while adapting its proper behavior to the interfaces of context sources. Finally, CoWSAMI allows querying for contextual information with respect to the aforementioned organization, though a classical SQL-based interface.",
            "Abstract entirety": 1,
            "Author pub id": "B_Zd1P8AAAAJ:RGFaLdJalmkC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Advances in Conceptual Modeling: ER 2012 Workshops CMS, ECDM-NoCoDA, MODIC, MORE-BI, RIGIM, SeCoGIS, WISM, Florence, Italy, October 15-18, 2012, Proceedings",
            "Publication year": 2012,
            "Publication url": "https://books.google.com/books?hl=en&lr=&id=bYu5BQAAQBAJ&oi=fnd&pg=PR2&dq=info:FpilHI9aMJcJ:scholar.google.com&ots=pM9GYsjS4w&sig=4SWD8DhBDCMpuTOkYHdAPk65VtM",
            "Abstract": "This book constitutes the refereed proceedings of workshops, held at the 31st International Conference on Conceptual Modeling, ER 2012, in Florence, Italy in October 2012. The 32 revised papers presented together with 6 demonstrations were carefully reviewed and selected from 84 submissions. The papers are organized in sections on the workshops CMS 2012, EDCM-NoCoDa, MODIC, MORE-BI, RIGIM, SeCoGIS and WISM. The workshops cover different conceptual modeling topics, from requirements, goal and service modeling, to evolution and change management, to non-conventional data access, and they span a wide range of domains including Web information systems, geographical information systems, business intelligence, data-intensive computing.",
            "Abstract entirety": 1,
            "Author pub id": "B_Zd1P8AAAAJ:5ugPr518TE4C",
            "Publisher": "Springer"
        },
        {
            "Title": "CHOReOS State of the Art, Baseline, and Beyond (D1. 1)",
            "Publication year": 2011,
            "Publication url": "https://hal.inria.fr/hal-00662510/",
            "Abstract": "The D1.1 deliverable clarifies baseline, progress, and state of the art that CHOReOS will address. For each of the first four CHOReOS work packages, WP1 to WP4, this deliverable gives a precise definition of the state of the art, an indication of the envisaged progress beyond the state of the art by CHOReOS and the baseline for its research.",
            "Abstract entirety": 1,
            "Author pub id": "B_Zd1P8AAAAJ:fPk4N6BV_jEC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Accelerating Web service workflow execution via intelligent allocation of services to servers",
            "Publication year": 2010,
            "Publication url": "https://www.igi-global.com/article/journal-database-management-jdm/47420",
            "Abstract": "The appropriate deployment of web service operations at the service provider site plays a critical role in the efficient provision of services to clients. In this paper, the authors assume that a service provider has several servers over which web service operations can be deployed. Given a workflow of web services and the topology of the servers, the most efficient mapping of operations to servers must then be discovered. Efficiency is measured in terms of two cost functions that concern the execution time of the workflow and the fairness of the load distribution among the servers. The authors study different topologies for the workflow structure and the server connectivity and propose a suite of greedy algorithms for each combination.",
            "Abstract entirety": 1,
            "Author pub id": "B_Zd1P8AAAAJ:OU6Ihb5iCvQC",
            "Publisher": "IGI Global"
        },
        {
            "Title": "Deciding the physical implementation of ETL workflows",
            "Publication year": 2007,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/1317331.1317341",
            "Abstract": "In this paper, we deal with the problem of determining the best possible physical implementation of an ETL workflow, given its logical-level description and an appropriate cost model as inputs. We formulate the problem as a state-space problem and provide a suitable solution for this task. We further extend this technique by intentionally introducing sorter activities in the workflow in order to search for alternative physical implementations with lower cost. We experimentally assess our method based on a principled organization of test suites.",
            "Abstract entirety": 1,
            "Author pub id": "B_Zd1P8AAAAJ:Zph67rFs4hoC",
            "Publisher": "Unknown"
        },
        {
            "Title": "ARKTOS: towards the modeling, design, control and execution of ETL processes",
            "Publication year": 2001,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S0306437901000394",
            "Abstract": "Extraction-Transformation-loading (ETL) tools are pieces of software responsible for the extraction of data from several sources, their cleansing, customization and insertion into a data warehouse. Literature and personal experience have guided us to conclude that the problems concerning the ETL tools are primarily problems of complexity, usability and price. To deal with these problems we provide a uniform metamodel for ETL processes, covering the aspects of data warehouse architecture, activity modeling, contingency treatment and quality management. The ETL tool we have developed, namely Arktos, is capable of modeling and executing practical ETL scenarios by providing explicit primitives for the capturing of common tasks. Arktos provides three ways to describe an ETL scenario: a graphical point-and-click front end and two declarative languages: XADL (an XML variant), which is more verbose and easy \u2026",
            "Abstract entirety": 0,
            "Author pub id": "B_Zd1P8AAAAJ:UeHWp8X0CEIC",
            "Publisher": "Pergamon"
        },
        {
            "Title": "Adaptive Indexing for In-situ Visual Exploration and Analytics.",
            "Publication year": 2021,
            "Publication url": "https://www.nbikakis.com/papers/RawVis_Adaptive_Indexing_for_In-situ_Visual_Exploration_and_Analytics_DOLAP2021.pdf",
            "Abstract": "In-situ processing has received a great deal of attention in recent years. In in-situ scenarios, big raw data files which do not fit in main memory, must be efficiently handled using commodity hardware, without the overhead of a preprocessing phase or the loading of data into a database. In this work, we present an adaptive indexing scheme that enables efficient visual exploration and analytics over big raw data files. Beyond visual exploration and statistics, the scheme enables categorical-based analytics using group-by and filter operations. The proposed scheme combines a tile-based structure that offers efficient exploratory operations over the 2D space, with a tree-based structure that organizes a tile\u2019s objects based on their categorical values, enabling efficient visual analytics and the support of advanced visualization methods. The index resides in main memory and is built progressively as the user explores parts of the raw file, whereas its structure and level of granularity are adjusted to the user\u2019s exploration areas and type of analysis. We conduct experiments using real and synthetic datasets, and demonstrate that the proposed approach, is in most cases more than 40\u00d7 faster compared to the existing solutions, and performs around 3 orders of magnitude less I/O operations.",
            "Abstract entirety": 1,
            "Author pub id": "B_Zd1P8AAAAJ:kh2fBNsKQNwC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Near real time ETL",
            "Publication year": 2008,
            "Publication url": "https://books.google.com/books?hl=en&lr=&id=x22qorWzur4C&oi=fnd&pg=PA19&dq=info:hcaCMXIoEssJ:scholar.google.com&ots=RLIXRELgN9&sig=NoO9opjMYLK31XxRyV9fKOmEG-Y",
            "Abstract": "Near real time ETL deviates from the traditional conception of data warehouse refreshment, which is performed off-line in a batch mode, and adopts the strategy of propagating changes that take place in the sources towards the data warehouse to the extent that both the sources and the warehouse can sustain the incurred workload. In this article, we review the state of the art for both conventional and near real time ETL, we discuss the background, the architecture, and the technical issues that arise in the area of near real time ETL, and we pinpoint interesting research challenges for future work.",
            "Abstract entirety": 1,
            "Author pub id": "B_Zd1P8AAAAJ:JQOojiI6XY0C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Cross-layer networking for peer databases over wireless ad-hoc communities",
            "Publication year": 2007,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/4289241/",
            "Abstract": "In this paper we address the problem of efficiently distributing query messages among peers in a wireless ad hoc network. We assume that peers are organized in classes. Each peer possesses a local database and can answer queries posed by other peers. Each peer can also pose queries to all the peers belonging to a certain class and/or within a certain range of distance in the network. Contrary to traditional p2p lookup queries, we are interested in collecting answers from as many peers as possible. To efficiently serve this purpose, we take advantage of routing and application layer specifics (e.g., class information, network distance) to avoid flooding and at the same time preserve compatibility with traditional routing and transport mechanisms.",
            "Abstract entirety": 1,
            "Author pub id": "B_Zd1P8AAAAJ:NMxIlDl6LWMC",
            "Publisher": "IEEE"
        },
        {
            "Title": "A study on the effect of a table\u2019s involvement in foreign keys to its schema evolution",
            "Publication year": 2020,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-030-62522-1_34",
            "Abstract": "In this paper, we study the evolution of tables in a schema with respect to the structure of the foreign keys to which tables are related. We organize a hierarchy of topological complexity for the structure of foreign keys, based on a modeling of schemata as graphs, where tables are classified in increasing order of complexity as: isolated (not involved in foreign keys), source (with outgoing foreign keys only), lookup (with incoming foreign keys only) and internal (with both kinds). Our study reveals that this hierarchy reflects also the update behavior of tables: topologically simple tables are more likely to have a life with few or zero schema updates, whereas, topologically complex tables are more likely to undergo high numbers of updates. Early versions of the database attract the large majority of births of complex tables, as opposed to the simple ones, demonstrating a pattern of reducing the introduction of complex \u2026",
            "Abstract entirety": 0,
            "Author pub id": "B_Zd1P8AAAAJ:5qfkUJPXOUwC",
            "Publisher": "Springer, Cham"
        },
        {
            "Title": "ARKTOS: A tool for data cleaning and transformation in data warehouse environments",
            "Publication year": 2000,
            "Publication url": "https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.32.7286&rep=rep1&type=pdf#page=44",
            "Abstract": "Extraction-Transformation-Loading (ETL) and Data Cleaning tools are pieces of software responsible for the extraction of data from several sources, their cleaning, customization and insertion into a data warehouse. To deal with the complexity and efficiency of the transformation and cleaning tasks we have developed a tool, namely ARKTOS, capable of modeling and executing practical scenarios, by providing explicit primitives for the capturing of common tasks. ARKTOS provides three ways to describe such a scenario, including a graphical point-and-click front end and two declarative languages: XADL (an XML variant), which is more verbose and easy to read and SADL (an SQL-like language) which has a quite compact syntax and is, thus, easier for authoring.",
            "Abstract entirety": 1,
            "Author pub id": "B_Zd1P8AAAAJ:kNdYIx-mwKoC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Efficient Computation of Containment and Complementarity in RDF Data Cubes.",
            "Publication year": 2016,
            "Publication url": "https://www.cs.uoi.gr/~pvassil/publications/2016_EDBT/EDBT_2016.pdf",
            "Abstract": "Multidimensional data are published in the web of data under common directives, such as the Resource Description Framework (RDF). The increasing volume and diversity of these data pose the challenge of finding relations between them in a most efficient and accurate way, by taking into advantage their overlapping schemes. In this paper we define two types of relationships between multidimensional RDF data, and we propose algorithms for efficient and scalable computation of these relationships. Specifically, we define the notions of containment and complementarity between points in multidimensional dataspaces, as different aspects of relatedness, and we propose a baseline method for computing them, as well as two alternative methods that target speed and scalability. We provide an experimental evaluation over real-world and synthetic datasets and we compare our approach to a SPARQL-based and a rule-based alternative, which prove to be inefficient for increasing input sizes.",
            "Abstract entirety": 1,
            "Author pub id": "B_Zd1P8AAAAJ:kzcrU_BdoSEC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Gravitating to rigidity: Patterns of schema evolution\u2013and its absence\u2013in the lives of tables",
            "Publication year": 2017,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S030643791630120X",
            "Abstract": "Like all software maintenance, schema evolution is a process that can severely impact the lifecycle of a data-intensive software projects, as schema updates can drive depending applications crushing or delivering incorrect data to end users. In this paper, we study the schema evolution of eight databases that are part of larger open source projects, publicly available through open source repositories. In particular, the focus of our research was the understanding of which tables evolve and how. We report on our observations and patterns on how evolution related properties, like the possibility of deletion, or the amount of updates that a table undergoes, are related to observable table properties like the number of attributes or the time of birth of a table.A study of the update profile of tables, indicates that they are mostly rigid (without any updates to their schema at all) or quiet (with few updates), especially in databases \u2026",
            "Abstract entirety": 0,
            "Author pub id": "B_Zd1P8AAAAJ:0KyAp5RtaNEC",
            "Publisher": "Pergamon"
        },
        {
            "Title": "Contextual Database Preferences.",
            "Publication year": 2011,
            "Publication url": "http://cs.uoi.gr/~pvassil/publications/2011_DEB/DEB_2011.pdf",
            "Abstract": "As both the volume of data and the diversity of users accessing them increase, user preferences offer a useful means towards improving the relevance of the query results to the information needs of the specific user posing the query. In this article, we focus on enhancing preferences with context. Context may express conditions on situations external to the database or related to the data stored in the database. We outline models for expressing both types of preferences. Then, given a user query and its surrounding context, we consider the problem of selecting related preferences to personalize the query.",
            "Abstract entirety": 1,
            "Author pub id": "B_Zd1P8AAAAJ:2P1L_qKh6hAC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Rule-based Management of Schema Changes at ETL sources",
            "Publication year": 2009,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-642-12082-4_8",
            "Abstract": "In this paper, we visit the problem of the management of inconsistencies emerging on ETL processes as results of evolution operations occurring at their sources. We abstract Extract-Transform-Load (ETL) activities as queries and sequences of views. ETL activities and its sources are uniformly modeled as a graph that is annotated with rules for the management of evolution events. Given a change at an element of the graph, our framework detects the parts of the graph that are affected by this change and highlights the way they are tuned to respond to it. We then present the system architecture of a tool called Hecataeus that implements the main concepts of the proposed framework.",
            "Abstract entirety": 1,
            "Author pub id": "B_Zd1P8AAAAJ:ns9cj8rnVeAC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "Meshing streaming updates with persistent data in an active data warehouse",
            "Publication year": 2008,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/4441713/",
            "Abstract": "Active data warehousing has emerged as an alternative to conventional warehousing practices in order to meet the high demand of applications for up-to-date information. In a nutshell, an active warehouse is refreshed online and thus achieves a higher consistency between the stored information and the latest data updates. The need for online warehouse refreshment introduces several challenges in the implementation of data warehouse transformations, with respect to their execution time and their overhead to the warehouse processes. In this paper, we focus on a frequently encountered operation in this context, namely, the join of a fast stream 5\" of source updates with a disk-based relation R, under the constraint of limited memory. This operation lies at the core of several common transformations such as surrogate key assignment, duplicate detection, or identification of newly inserted tuples. We propose a \u2026",
            "Abstract entirety": 0,
            "Author pub id": "B_Zd1P8AAAAJ:YOwf2qJgpHMC",
            "Publisher": "IEEE"
        },
        {
            "Title": "A framework for learning cell interestingness from cube explorations",
            "Publication year": 2019,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-030-28730-6_26",
            "Abstract": "In this paper, we discuss the problem of organizing the different ways of computing the interestingness of a particular cell derived from a cube in the context of a hierarchical, multidimensional space. We start from an in-depth study of the interestingness aspects in the study of human behavior and include in our survey the approaches taken by computer-science efforts in the area of data mining and user recommendations. We move on to structure interestingness along different fundamental, high level aspects, and, due to their high-level nature, we also move towards much more concrete data-oriented definitions of interestingness aspects.",
            "Abstract entirety": 1,
            "Author pub id": "B_Zd1P8AAAAJ:e_rmSamDkqQC",
            "Publisher": "Springer, Cham"
        },
        {
            "Title": "Architecture and Quality in Data Warehouses",
            "Publication year": 2013,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-642-36926-1_13",
            "Abstract": "Most database researchers have studied data warehouses (DW) in their role as buffers of materialized views, mediating between updateintensive OLTP systems and query-intensive decision support. This neglects the organizational role of data warehousing as a means of centralized information flow control. As a consequence, a large number of quality aspects relevant for data warehousing cannot be expressed with the current DW meta models. This paper makes two contributions towards solving these problems. Firstly, we enrich the meta data about DW architectures by explicit enterprise models. Secondly, many very different mathematical techniques for measuring or optimizing certain aspects of DW quality are being developed. We adapt the Goal-Question-Metric approach from software quality management to a meta data management environment in order to link these special techniques to a generic \u2026",
            "Abstract entirety": 0,
            "Author pub id": "B_Zd1P8AAAAJ:_B80troHkn4C",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "Towards a logical model for patterns",
            "Publication year": 2003,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-540-39648-2_9",
            "Abstract": "Nowadays, the vast volume of collected digital data obliges us to employ processing methods like pattern recognition and data mining in order to reduce the complexity of data management. In this paper, we present the architecture and the logical foundations for the management of the produced knowledge artifacts, which we call patterns. To this end, we first introduce the concept of Pattern-Base Management System; then, we provide the logical foundations of a general framework based on the notions of pattern types and pattern classes, which stand for the intensional and extensional description of pattern instances, respectively. The framework is general and extensible enough to cover a broad range of real-world patterns, each of which is characterized by its structure, the related underlying data, an expression that carries the semantics of the pattern, and measurements of how successful the \u2026",
            "Abstract entirety": 0,
            "Author pub id": "B_Zd1P8AAAAJ:eQOLeE2rZwMC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "Modeling and storing context-aware preferences",
            "Publication year": 2006,
            "Publication url": "https://link.springer.com/chapter/10.1007/11827252_12",
            "Abstract": "Today, the overwhelming volume of information that is available to an increasingly wider spectrum of users creates the need for personalization. In this paper, we consider a database system that supports context-aware preference queries, that is, preference queries whose result depends on the context at the time of their submission. We use data cubes to store the associations between context-dependent preferences and database relations and OLAP techniques for processing context-aware queries, thus allowing the manipulation of the captured context data at different levels of abstractions. To improve query performance, we use an auxiliary data structure, called context tree, which indexes the results of previously computed preference-aware queries based on their associated context. We show how these cached results can be used to process both exact and approximate context-aware preference queries.",
            "Abstract entirety": 1,
            "Author pub id": "B_Zd1P8AAAAJ:4TOpqqG69KYC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "Data Warehouse Refreshment",
            "Publication year": 2003,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-662-05153-5_4",
            "Abstract": "The central problem addressed in this chapter is the refreshment of a data warehouse in order to reflect the changes that have occurred in the sources from which the data warehouse is defined. The possibility of having \u201cfresh data\u201d in a warehouse is a key factor for success in business applications. In many activities, such as in retail, business applications rely on the proper refreshment of their warehouses. For instance, Jahnke [Jahn96] mentions the case of WalMart, the world\u2019s most successful retailer. Many of WalMart\u2019s large volume suppliers, such as Procter & Gamble, have direct access to the WalMart data warehouse, so they deliver goods to specific stores as needed. WalMart pays such companies for their products only when they are sold. Procter & Gamble ships 40% of its items in this way, eliminating paperwork and sale calls on both sides. It is essential for the supplier to use fresh data in order to \u2026",
            "Abstract entirety": 0,
            "Author pub id": "B_Zd1P8AAAAJ:kRWSkSYxWN8C",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "Cohesion-driven decomposition of service interfaces without access to source code",
            "Publication year": 2014,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/6763104/",
            "Abstract": "Software cohesion concerns the degree to which the elements of a module belong together. Cohesive software is easier to understand, test and maintain. In the context of service-oriented development, cohesion refers to the degree to which the operations of a service interface belong together. In the state of the art, software cohesion is improved based on refactoring methods that rely on information, extracted from the software implementation. This is a main limitation towards using these methods in the case of web services: web services do not expose their implementation; instead all that they export is the web service interface specification. To deal with this problem, we propose an approach that enables the cohesion-driven decomposition of service interfaces, without information on how the services are implemented. Our approach progressively decomposes a given service interface into more cohesive interfaces \u2026",
            "Abstract entirety": 0,
            "Author pub id": "B_Zd1P8AAAAJ:Y5dfb0dijaUC",
            "Publisher": "IEEE"
        },
        {
            "Title": "HAL Id: inria-00583780",
            "Publication year": 2011,
            "Publication url": "https://hal.inria.fr/inria-00583780/PDF/icse11_2nier-p101-athanasopoulos.pdf",
            "Abstract": "Several lines of research rely on the concept of service abstractions to enable the organization, the composition and the adaptation of services. However, what is still missing, is a systematic approach for extracting service abstractions out of the vast amount of services that are available all over the Web. To deal with this issue, we propose an approach for mining service abstractions, based on an agglomerative clustering algorithm. Our experimental findings suggest that the approach is promising and can serve as a basis for future research.",
            "Abstract entirety": 1,
            "Author pub id": "B_Zd1P8AAAAJ:XoXfffV-tXoC",
            "Publisher": "Unknown"
        },
        {
            "Title": "A presentation model & non-traditional visualization for OLAP",
            "Publication year": 2005,
            "Publication url": "https://www.igi-global.com/article/international-journal-data-warehousing-mining/1746",
            "Abstract": "Data visualization is one of the major issues of database research. OLAP a decision support technology, is clearly in the center of this effort. Thus far, visualization has not been incorporated in the abstraction levels of DBMS architecture (conceptual, logical, physical); neither has it been formally treated in this context. In this paper we start by reconsidering the separation of the aforementioned abstraction levels to take visualization into consideration. Then, we present the Cube Presentation Model (CPM), a novel presentational model for OLAP screens. The proposal lies on the fundamental idea of separating the logical part of a data cube computation from the presentational part of the client tool. Then, CPM can be naturally mapped on the Table Lens, which is an advanced visualization technique from the Human-Computer Interaction area, particularly tailored for cross-tab reports. Based on the particularities of \u2026",
            "Abstract entirety": 0,
            "Author pub id": "B_Zd1P8AAAAJ:M3ejUd6NZC8C",
            "Publisher": "IGI Global"
        },
        {
            "Title": "Source Integration",
            "Publication year": 2003,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-662-05153-5_3",
            "Abstract": "According to [Inmo96], integration is the most important aspect of a data warehouse. When data passes from the application-oriented operational environment to the data warehouse, possible inconsistencies and redundancies should be resolved, so that the warehouse is able to provide an integrated and reconciled view of data of the organization.",
            "Abstract entirety": 1,
            "Author pub id": "B_Zd1P8AAAAJ:J-pR_7NvFogC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "Modeling and optimization of extraction-transformation-loading (ETL) processes in data warehouse environments",
            "Publication year": 2004,
            "Publication url": "http://www.dbnet.ece.ntua.gr/pubs/uploads/PHD-2004-2.pdf",
            "Abstract": "This chapter highlights the background of the dissertation and outlines its structure. In Section 1.1 we briefly present a high-level architecture of a data warehouse and we exhibit its main layers. In Section 1.2 we introduce the Extract\u2013Transform\u2013Load (ETL) processes, the general subject of this work. In Section 1.3, we sketch our approach for modeling ETL processes, and formulate our main objectives. An overview of the structure and contributions of the dissertation is given in Section 1.4.",
            "Abstract entirety": 1,
            "Author pub id": "B_Zd1P8AAAAJ:uc_IGeMz5qoC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Query management over ad-hoc communities of web services",
            "Publication year": 2005,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/1506419/",
            "Abstract": "In this paper, we present CONSERV - a middleware infrastructure for the development of virtual databases in pervasive computing environments. CONSERV provides an SQL front-end for posing and processing queries on information provided by ad-hoc communities of Web services hosted by peers that arbitrarily join and leave the system. The cornerstone of the proposed infrastructure is the fact that we replace the traditional treatment of databases as persistent collections of records by the assumption that a database relation is a collection of records dynamically compiled from such ad-hoc sets of peers. Each peer offers data to the relations through a workflow of Web services. Another aspect of our approach is that we confine query processing over specific sets of peers that we call communities. Communities are defined based on the current context of the peer initiating each query. Since our infrastructure \u2026",
            "Abstract entirety": 0,
            "Author pub id": "B_Zd1P8AAAAJ:BqipwSGYUEgC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Data warehouse process management",
            "Publication year": 2001,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S0306437901000187",
            "Abstract": "Previous research has provided metadata models that enable the capturing of the static components of a data warehouse architecture, along with information on different quality factors over these components. This paper complements this work with the modeling of the dynamic parts of the data warehouse. The proposed metamodel of data warehouse operational processes is capable of modeling complex activities, their interrelationships, and the relationship of activities with data sources and execution details. Moreover, the metamodel complements the existing architecture and quality models in a coherent fashion, resulting in a full framework for quality-oriented data warehouse management, capable of supporting the design, administration and especially evolution of a data warehouse. Finally, we exploit our framework to revert the widespread belief that data warehouses can be treated as collections of \u2026",
            "Abstract entirety": 0,
            "Author pub id": "B_Zd1P8AAAAJ:Tyk-4Ss8FVUC",
            "Publisher": "Pergamon"
        },
        {
            "Title": "Data provenance in ETL scenarios",
            "Publication year": 2007,
            "Publication url": "http://cs.uoi.gr/~pvassil/publications/2007_PrOPr/PrOPr_2007.pdf",
            "Abstract": "Data in large organizations are typically distributed in several heterogeneous sources, organized and stored under different naming conventions, structures, and formats. For supporting the functionality of On-Line Analytical Processing (OLAP) applications and Decision Support Systems (DSS), Data Warehouses (DW) are employed to integrate the data and provide a uniform infrastructure for querying, reporting, mining, and other advanced analysis techniques. The process of populating the DW with data stemming from the operational sources, in a way that the schema and business requirements of the DW are met, is referred to as Extract-Transform-Load (ETL) process. Typically, such processes are handled by ETL tools, which are pieces of software responsible for the extraction of data from several sources, their cleansing, customization, and insertion into a DW. However, even though the term ETL is traditionally related to data warehousing, it may be used in a wider sense to refer to any process of exchanging and transforming data between data stores. For example, ETL is the core functionality of a recently emerging type of web applications, called mashups, where information is extracted from various web sites, and it is appropriately transformed and integrated before presented to the final user.",
            "Abstract entirety": 1,
            "Author pub id": "B_Zd1P8AAAAJ:u_35RYKgDlwC",
            "Publisher": "Unknown"
        },
        {
            "Title": "User-Centric Transactions for Ambient Intelligence Environments",
            "Publication year": 2008,
            "Publication url": "https://hal.inria.fr/inria-00312742/",
            "Abstract": "In this paper we investigate the concept of designing user-centric transaction protocols towards achieving dependable coordination in AmI environments. As a proof-of-concept, we propose a protocol that takes into account the schedules of roaming users that move from one AmI environment to another, to avoid abnormal terminations of transactions when the users leave an environment for short, only to return later. We compare the proposed schedule-aware protocol against a schedule-agnostic one. Our findings show that the use of user-centric information in such situations is quite beneficial.",
            "Abstract entirety": 1,
            "Author pub id": "B_Zd1P8AAAAJ:zA6iFVUQeVQC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Trading privacy for information loss in the blink of an eye",
            "Publication year": 2012,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-642-31235-9_38",
            "Abstract": "The publishing of data with privacy guarantees is a task typically performed by a data curator who is expected to provide guarantees for the data he publishes in quantitative fashion, via a privacy criterion (e.g., k-anonymity, l-diversity). The anonymization of data is typically performed off-line. In this paper, we provide algorithmic tools that facilitate the negotiation for the anonymization scheme of a data set in user time. Our method takes as input a set of user constraints for (i) suppression, (ii) generalization and (iii) a privacy criterion (k-anonymity, l-diversity) and returns (a) either an anonymization scheme that fulfils these constraints or, (b) three approximations to the user request based on the idea of keeping the two of the three values of the user input fixed and finding the closest possible approximation for the third parameter. The proposed algorithm involves precomputing suitable histograms for all the \u2026",
            "Abstract entirety": 0,
            "Author pub id": "B_Zd1P8AAAAJ:f2IySw72cVMC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "A method for the mapping of conceptual designs to logical blueprints for ETL processes",
            "Publication year": 2008,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S0167923606002065",
            "Abstract": "Extraction\u2013Transformation\u2013Loading (ETL) tools are pieces of software responsible for the extraction of data from several sources, their cleansing, customization and insertion into a data warehouse. In previous work, we presented a modeling framework for ETL processes comprised of a conceptual model that concretely deals with the early stages of a data warehouse project, and a logical model that deals with the definition of data-centric workflows. In this paper, we describe the mapping of the conceptual model to the logical model. First, we identify how conceptual entities are mapped to logical entities. Next, we determine the execution order in the logical workflow using information adapted from the conceptual model. Finally, we provide a method for the transition from the conceptual model to the logical model.",
            "Abstract entirety": 1,
            "Author pub id": "B_Zd1P8AAAAJ:3fE2CSJIrl8C",
            "Publisher": "North-Holland"
        },
        {
            "Title": "Preference Networks for the Combination of Qualitative and Quantitative Preferences",
            "Publication year": 2010,
            "Publication url": "http://www.cse.uoi.gr/~pvassil/publications/on_going/WQP.pdf",
            "Abstract": "Preference management in databases is handled via profiles that allow the ranking of the tuples of a query\u2019s answer. A profile is a set of expressions, typically over the attributes of a relation. Preference management and profiles typically come in two flavors:(a) quantitative preferences, that assign a score to a profile\u2019s expressions and subsequently to each tuple that satisfies an expression, and (b) qualitative preferences which state a precedence relationship between two expressions and subsequently result in expressing when a tuple is preferred over another. Related literature has elaborated each of the above categories in isolation only. In this paper, we present a method to map quantitative to qualitative preferences and vice versa. We map profiles of both kinds to graphs called preference networks that formally capture the precedence relationship of a profile\u2019s expressions for both of the above categories. To fully support the management of preferences via preference networks we introduce weighted qualitative preferences that annotate the precedence relationship with a degree of preference (ie, be able to say\u2019I prefer IM to JP a lot\u2019). We provide methods to map qualitative to quantitative profiles as well as different ways to consolidate two profiles in one.",
            "Abstract entirety": 1,
            "Author pub id": "B_Zd1P8AAAAJ:_xSYboBqXhAC",
            "Publisher": "Unknown"
        },
        {
            "Title": "The three-step refactoring detector pattern",
            "Publication year": 2019,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/3361149.3361168",
            "Abstract": "Developing a tool that provides support for different refactorings, through a set of refactoring detectors which identify opportunities for source code improvements, is not easy. Our experience in developing such a tool for refactoring object-oriented software revealed the Three-Step Refactoring Detector pattern. The main idea behind the pattern is to develop an extensible hierarchy of refactoring detectors, with respect to a general three-step refactoring detection process. The proposed pattern facilitates the expansion of the hierarchy with new refactoring detectors and enables the reuse of existing refactoring detectors, provided by third party developers. Concerning maintainability, the pattern promotes the development of simple, clean and technology independent refactoring detectors. We have used the pattern for the development of 11 different refactoring detectors in the context of our tool. The pattern has not been \u2026",
            "Abstract entirety": 0,
            "Author pub id": "B_Zd1P8AAAAJ:-FonjvnnhkoC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Concept based design of data warehouses: The DWQ demonstrators",
            "Publication year": 2000,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/342009.336570",
            "Abstract": "The ESPRIT Project DWQ (Foundations of Data Warehouse Quality) aimed at improving the quality of DW design and operation through systematic enrichment of the semantic foundations of data warehousing. Logic-based knowledge representation and reasoning techniques were developed to control accuracy, consistency, and completeness via advanced conceptual modeling techniques for source integration, data reconciliation, and multi-dimensional aggregation. This is complemented by quantitative optimization techniques for view materialization, optimizing timeliness and responsiveness without losing the semantic advantages from the conceptual approach. At the operational level, query rewriting and materialization refreshment algorithms exploit the knowledge developed at design time. The demonstration shows the interplay of these tools under a shared metadata repository, based on an example \u2026",
            "Abstract entirety": 0,
            "Author pub id": "B_Zd1P8AAAAJ:MXK_kJrjxJIC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Profiles of Schema Evolution in Free Open Source Software Projects",
            "Publication year": 2021,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/9458666/",
            "Abstract": "In this paper, we present the findings of a large study of the evolution of the schema of 195 Free Open Source Software projects. We identify families of evolutionary behaviors, or taxa, in FOSS projects. A large percentage of the projects demonstrate very few, if any, actions of schema evolution. Two other taxa involve the evolution via focused actions, with either a single focused maintenance action, or a large percentage of evolution activity grouped in no more than a couple interventions. Schema evolution also involves moderate, and active evolution, with very different volumes of updates to the schema. To the best of our knowledge, this is the first study of this kind in the area of schema evolution, both in terms of presenting profiles of how schemata evolve, and, in terms of the dataset magnitude and the generalizability of the findings.",
            "Abstract entirety": 1,
            "Author pub id": "B_Zd1P8AAAAJ:_FM0Bhl9EiAC",
            "Publisher": "IEEE"
        },
        {
            "Title": "What-if analysis for data warehouse evolution",
            "Publication year": 2007,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-540-74553-2_3",
            "Abstract": "In this paper, we deal with the problem of performing what-if analysis for changes that occur in the schema/structure of the data warehouse sources. We abstract software modules, queries, reports and views as (sequences of) queries in SQL enriched with functions. Queries and relations are uniformly modeled as a graph that is annotated with policies for the management of evolution events. Given a change at an element of the graph, our method detects the parts of the graph that are affected by this change and indicates the way they are tuned to respond to it.",
            "Abstract entirety": 1,
            "Author pub id": "B_Zd1P8AAAAJ:mVmsd5A6BfQC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "Schema Evolution for Relational Databases.",
            "Publication year": 2016,
            "Publication url": "https://scholar.google.com/scholar?cluster=18087376788695957502&hl=en&oi=scholarr",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "B_Zd1P8AAAAJ:L7CI7m0gUJcC",
            "Publisher": "Unknown"
        },
        {
            "Title": "View usability and safety for the answering of top-k queries via materialized views",
            "Publication year": 2009,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/1651291.1651308",
            "Abstract": "In this paper, we investigate the problem of answering top-k queries via materialized views. We provide theoretical guarantees for the adequacy of a view to answer a top-k query, along with algorithmic techniques to compute the query via a view when this is possible. We explore the problem of answering a query via a combination of more than one view and show that it is impossible to improve our theoretical guarantees for the answering of a query via a combination of views. Finally, we experimentally assess our approach for its effectiveness and efficiency.",
            "Abstract entirety": 1,
            "Author pub id": "B_Zd1P8AAAAJ:k_IJM867U9cC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Hierarchical Property Set Merging for SPARQL Query Optimization.",
            "Publication year": 2020,
            "Publication url": "http://ceur-ws.org/Vol-2572/paper13.pdf",
            "Abstract": "Characteristic sets (CS) organize RDF triples based on the set of properties associated with their subject nodes. This concept was recently used in indexing techniques, as it can capture the implicit schema of RDF data. While most CS-based approaches yield significant improvements in space and query performance, they fail to perform well when answering complex query workloads in the presence of schema heterogeneity, ie, when the number of CSs becomes very large, resulting in a highly partitioned data organization. In this paper, we address this problem by introducing a novel technique, for merging CSs based on their hierarchical structure. Our method employs a lattice to capture the hierarchical relationships between CSs, identifies dense CSs and merges dense CSs with their ancestors, thus reducing the size of the CSs as well as the links between them. We implemented our algorithm on top of a relational backbone, where each merged CS is stored in a relational table, and we performed an extensive experimental study to evaluate the performance and impact of merging to the storage and querying of RDF datasets, indicating significant improvements.",
            "Abstract entirety": 1,
            "Author pub id": "B_Zd1P8AAAAJ:FPJr55Dyh1AC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Advanced visualization for OLAP",
            "Publication year": 2003,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/956060.956063",
            "Abstract": "Data visualization is one of the big issues of database research. OLAP as a decision support technology is highly related to the developments of data visualization area. In this paper we demonstrate how the Cube Presentation Model (CPM), a novel presentational model for OLAP screens, can be naturally mapped on the Table Lens, which is an advanced visualization technique from the Human-Computer Interaction area, particularly tailored for cross-tab reports. We consider how the user interacts with an OLAP screen and based on the particularities of Table Lens, we propose an automated proactive users support. Finally, we discuss the necessity and the applicability of advanced visualization techniques in the presence of recent technological developments.",
            "Abstract entirety": 1,
            "Author pub id": "B_Zd1P8AAAAJ:LkGwnXOMwfcC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Adaptive Query Formulation to Handle Database Evolution.",
            "Publication year": 2006,
            "Publication url": "http://www.dbnet.ece.ntua.gr/~gpapas/Publications/AdaptiveQueryEvolution-Extended.pdf",
            "Abstract": "Databases are continuously evolving environments, where design constructs are added, removed or updated quite often. Research has extensively dealt with the problem of database evolution. Nevertheless, problems arise with existing queries, mainly due to the fact that in most cases, their role as integral parts of the environment is not given the proper attention. Furthermore, the queries are not designed to handle database evolution. In this paper, we first introduce a graph-based model that uniformly captures relations, views, constraints and queries. For several cases of database evolution we present rules so that both syntactical and semantic correctness of queries are retained. To this end, we also extend the query formulation capabilities by annotating SQL queries with information concerning the semantically aware adaptation of a query in the presence of changes in the underlying database.",
            "Abstract entirety": 1,
            "Author pub id": "B_Zd1P8AAAAJ:_Qo2XoVZTnwC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Metadata and data warehouse quality",
            "Publication year": 2003,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-662-05153-5_7",
            "Abstract": "In the traditional view, data warehouses provide large-scale caches of historic data. They sit between (a) information sources gained externally or through online transaction processing systems (OLTP) and (b) decision support or data mining queries following the vision of online analytic processing (OLAP). Three main arguments have been put forward in favor of this caching approach:                   1.                                      Performance and safety considerations. The concurrency control methods of most DBMS do not react well to a mix of short update transactions (as in OLTP) and OLAP queries that typically search a large portion of the database. Moreover, the OLTP systems are often critical for the operation of the organization and must not be in danger of corruption by other applications.                   2.                                      Logical interpretability problems \u2026 Performance and safety considerations. The concurrency control methods of most DBMS do not react well to a mix of short update transactions (as in OLTP) and OLAP queries that typically search a large portion of the database. Moreover, the OLTP systems are often critical for the operation of the organization and must not be in danger of corruption by other applications. Logical interpretability problems \u2026",
            "Abstract entirety": 0,
            "Author pub id": "B_Zd1P8AAAAJ:JV2RwH3_ST0C",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "Mining service abstractions: NIER track",
            "Publication year": 2011,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/6032558/",
            "Abstract": "Several lines of research rely on the concept of service abstractions to enable the organization, the composition and the adaptation of services. However, what is still missing, is a systematic approach for extracting service abstractions out of the vast amount of services that are available all over the Web. To deal with this issue, we propose an approach for mining service abstractions, based on an agglomerative clustering algorithm. Our experimental findings suggest that the approach is promising and can serve as a basis for future research.",
            "Abstract entirety": 1,
            "Author pub id": "B_Zd1P8AAAAJ:M3NEmzRMIkIC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Open-source databases: Within, outside, or beyond lehman\u2019s laws of software evolution?",
            "Publication year": 2014,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-319-07881-6_26",
            "Abstract": "Lehman\u2019s laws of software evolution is a well-established set of observations (matured during the last forty years) on how the typical software systems evolve. However, the applicability of these laws on databases has not been studied so far. To this end, we have performed a thorough, large-scale study on the evolution of databases that are part of larger open source projects, publicly available through open source repositories, and report on the validity of the laws on the grounds of properties like size, growth, and amount of change per version.",
            "Abstract entirety": 1,
            "Author pub id": "B_Zd1P8AAAAJ:JoZmwDi-zQgC",
            "Publisher": "Springer, Cham"
        },
        {
            "Title": "Survival in schema evolution: putting the lives of survivor and dead tables in counterpoint",
            "Publication year": 2017,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-319-59536-8_21",
            "Abstract": "How can we plan development over an evolving schema? In this paper, we study the history of the schema of eight open source software projects that include relational databases and extract patterns related to the survival or death of their tables. Our findings are mostly summarized by a pattern, which we call \u201celectrolysis pattern\u201d due to its diagrammatic representation, stating that dead and survivor tables live quite different lives: tables typically die shortly after birth, with short durations and mostly no updates, whereas survivors mostly live quiet lives with few updates \u2013 except for a small group of tables with high update ratios that are characterized by high durations and survival. Based on our findings, we recommend that development over newborn tables should be restrained, and wherever possible, encapsulated by views to buffer both infant mortality and high update rate of hyperactive tables. Once a \u2026",
            "Abstract entirety": 0,
            "Author pub id": "B_Zd1P8AAAAJ:vDijr-p_gm4C",
            "Publisher": "Springer, Cham"
        },
        {
            "Title": "CineCubes: cubes as movie stars with little effort",
            "Publication year": 2013,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/2513190.2513191",
            "Abstract": "In this paper we investigate how we can exploit the existence of a star schema in order to answer user OLAP queries with CineCube movies. Our method, implemented in an actual system, includes the following steps. The user submits a query over an underlying star schema. Taking this query as input, the system comes up with a set of queries complementing the information content of the original query, and executes them. Then, the system visualizes the query results and accompanies this presentation with a text commenting on the result highlights. Moreover, via a text-to-speech conversion the system automatically produces audio for the constructed text. Each combination of visualization, text and audio practically constitutes a cube movie, which is wrapped as a PowerPoint presentation and returned to the user.",
            "Abstract entirety": 1,
            "Author pub id": "B_Zd1P8AAAAJ:tkaPQYYpVKoC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Design of the ERATOSTHENES OLAP Server",
            "Publication year": 2001,
            "Publication url": "https://link.springer.com/chapter/10.1007/3-540-38076-0_3",
            "Abstract": "On-Line Analytical Processing (OLAP) is a trend in database technology, based on the multidimensional view of data and is an indispensable component of the so-called business intelligence technology. The systems that realize this technology are called OLAP servers and are among the most high-priced products in software industry today [24]. The aim of this paper is twofold: (a) to describe the core levels of an OLAP system\u2019s architecture and to present design choices and reasoning for each one of them,an d (b) to present the specific design decisions that we made for a prototype under development at NTUA, ERATOSTHENES. The paper describes in detail the most important decisions taken regarding the basic layers of the server component of ERATOSTHENES.",
            "Abstract entirety": 1,
            "Author pub id": "B_Zd1P8AAAAJ:maZDTaKrznsC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "Erratum to: Service-oriented middleware for the Future Internet: state of the art and research directions",
            "Publication year": 2011,
            "Publication url": "https://scholar.google.com/scholar?cluster=11655709339794054854&hl=en&oi=scholarr",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "B_Zd1P8AAAAJ:nrtMV_XWKgEC",
            "Publisher": "Springer Science and Media"
        },
        {
            "Title": "Advantages of UML for Multidimensional Modeling.",
            "Publication year": 2004,
            "Publication url": "https://www.researchgate.net/profile/Sergio-Lujan-Mora/publication/220711403_Advantages_of_UML_for_Multidimensional_Modeling/links/5ae1cd2c0f7e9b285948aa03/Advantages-of-UML-for-Multidimensional-Modeling.pdf",
            "Abstract": "In the last few years, various approaches for the multidimensional (MD) modeling have been presented. However, none of them has been widely accepted as a standard. In this paper, we summarize the advantages of using object orientation for MD modeling. Furthermore, we use the UML, a standard visual modeling language, for modeling every aspect of MD systems. We show how our approach resolves elegantly some important problems of the MD modeling, such as multistar models, shared hierarchy levels, and heterogeneous dimensions. We believe that our approach, based on the popular UML, can be successfully used for MD modeling and can represent most of frequent MD modeling problems at the conceptual level.",
            "Abstract entirety": 1,
            "Author pub id": "B_Zd1P8AAAAJ:HDshCWvjkbEC",
            "Publisher": "Unknown"
        },
        {
            "Title": "The road to highlights is paved with good intentions: Envisioning a paradigm shift in OLAP modeling",
            "Publication year": 2018,
            "Publication url": "https://hal.archives-ouvertes.fr/hal-01888222/",
            "Abstract": "In this vision paper we structure a vision for the Business Intelligence of the near future in terms of a model with novel concepts and operators. We envision systems where the end-user requests information at a very high level, expressed as his intention to discover information, and the system transforms this request to the concrete execution of algorithms in order to compute, visualize and comment data and important highlights among them as an answer to the information request made by the end-user.",
            "Abstract entirety": 1,
            "Author pub id": "B_Zd1P8AAAAJ:EYYDruWGBe4C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Computing and managing cardinal direction relations",
            "Publication year": 2005,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/1524962/",
            "Abstract": "Qualitative spatial reasoning forms an important part of the commonsense reasoning required for building intelligent geographical information systems (GIS). Previous research has come up with models to capture cardinal direction relations for typical GIS data. In this paper, we target the problem of efficiently computing the cardinal direction relations between regions that are composed of sets of polygons and present two algorithms for this task. The first of the proposed algorithms is purely qualitative and computes, in linear time, the cardinal direction relations between the input regions. The second has a quantitative aspect and computes, also in linear time, the cardinal direction relations with percentages between the input regions. Our experimental evaluation indicates that the proposed algorithms outperform existing methodologies. The algorithms have been implemented and embedded in an actual system \u2026",
            "Abstract entirety": 0,
            "Author pub id": "B_Zd1P8AAAAJ:aqlVkmm33-oC",
            "Publisher": "IEEE"
        },
        {
            "Title": "KNOWLEDGE AND DATA ENGINEERING",
            "Publication year": 2005,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/1524959/",
            "Abstract": "[Front cover] Page 1 IEEE TRANSA CTIONS ON KNO WLEDGE AND D A T A \nENGINEERING V ol. 17, No. 12, December 2005 IEEE TRANSACTIONS ON KNOWLEDGE \nAND DATA ENGINEERING A publication of the IEEE Computer Society VOLUME 17 \nNUMBER 12 ITKEEH (ISSN 1041-4347) REGULAR PAPERS Databases and Data \nModeling Storing XML (with XSD) in SQL Databases: Interplay of Logical and Physical \nDesigns S. Chaudhuri, Z. Chen, K. Shim, and Y. Wu ...................................................................................................................... \nComputing and Managing Cardinal Direction Relations S. Skiadopoulos, C. Giannoukos, N. \nSarkas, P. Vassiliadis, T. Sellis, and M. Koubarakis.................................................. Data Mining \nDocument Clustering Using Locality Preserving Indexing D. Cai, X. He, and J. Han .................................................................................................................................................. \nSTAVIES: A System for from Web \u2026",
            "Abstract entirety": 0,
            "Author pub id": "B_Zd1P8AAAAJ:tS2w5q8j5-wC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Proceedings of the 5th International Workshop on Design and Management of Data Warehouses (DMDW 2003)",
            "Publication year": 2003,
            "Publication url": "https://www.narcis.nl/publication/RecordID/oai:tilburguniversity.edu:publications%2F0a147f53-b664-48ff-ab04-25b448ce55a4",
            "Abstract": "Proceedings of the 5th International Workshop on Design and Management... (2003) | www.narcis.nl \nKNAW KNAW Narcis Back to search results Tilburg University Publication Proceedings of the 5th \nInternational Workshop on Design and Management... (2003) Pagina-navigatie: Main Save \npublication Save as MODS Export to Mendeley Save as EndNote Export to RefWorks Title \nProceedings of the 5th International Workshop on Design and Management of Data Warehouses \n(DMDW 2003) Series CEUR Workshop Proceedings Author Lenz, HJ; Vassiliadis, P.; Jeusfeld, \nMA; Staudt, M. Publisher Research Group: Information Management Date issued 2003 Access \nRestricted Access Language English Type Book Publisher CEUR Publication \nhttps://research.tilburguniversity.edu/en/publications/0a147... Persistent Identifier \nurn:nbn:nl:ui:12-180231 Metadata XML Source Tilburg University Go to Website Navigation: about \u2026",
            "Abstract entirety": 0,
            "Author pub id": "B_Zd1P8AAAAJ:3s1wT3WcHBgC",
            "Publisher": "CEUR"
        },
        {
            "Title": "Hurtownie danych",
            "Publication year": 2003,
            "Publication url": "https://scholar.google.com/scholar?cluster=212262621560313492&hl=en&oi=scholarr",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "B_Zd1P8AAAAJ:kz9GbA2Ns4gC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Tuning the top-k view update process",
            "Publication year": 2007,
            "Publication url": "https://www.cs.uoi.gr/~pvassil/publications/2007_MPREF/MPref_2007.pdf",
            "Abstract": "In this paper we handle the problem of maintaining materialized top-k views in the presence of high deletion rates. We provide a principled method that complements the inefficiency of the state of the art independently of the statistical properties of the data and the characteristics of the update streams.",
            "Abstract entirety": 1,
            "Author pub id": "B_Zd1P8AAAAJ:GnPB-g6toBAC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Growing up with stability: how open-source relational databases evolve",
            "Publication year": 2015,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S0306437915000691",
            "Abstract": "Like all software systems, databases are subject to evolution as time passes. The impact of this evolution can be vast as a change to the schema of a database can affect the syntactic correctness and the semantic validity of all the surrounding applications. In this paper, we have performed a thorough, large-scale study on the evolution of databases that are part of larger open source projects, publicly available through open source repositories. Lehman\u05f3s laws of software evolution, a well-established set of observations on how the typical software systems evolve (matured during the last forty years), has served as our guide towards providing insights on the mechanisms that govern schema evolution. Much like software systems, we found that schemata expand over time, under a stabilization mechanism that constraints uncontrolled expansion with perfective maintenance. At the same time, unlike typical software \u2026",
            "Abstract entirety": 0,
            "Author pub id": "B_Zd1P8AAAAJ:N5tVd3kTz84C",
            "Publisher": "Pergamon"
        },
        {
            "Title": "A context\u2010aware preference database system",
            "Publication year": 2007,
            "Publication url": "https://www.emerald.com/insight/content/doi/10.1108/17427370710863158/full/html",
            "Abstract": "A context\u2010aware system is a system that uses context to provide relevant information or services to its users. While there has been a variety of context middleware infrastructures and context\u2010aware applications, little work has been done on integrating context into database management systems. The purpose of this paper is to consider a preference database system that supports context\u2010aware queries, that is, queries whose results depend on the context at the time of their submission.The paper proposes using data cubes to store the dependencies between context\u2010dependent preferences and database relations and on\u2010line analytical processing techniques for processing context\u2010aware queries. This allows for the manipulation of the captured context data at various levels of abstraction, for instance, in the case of a context parameter representing location, preferences \u2026",
            "Abstract entirety": 0,
            "Author pub id": "B_Zd1P8AAAAJ:mB3voiENLucC",
            "Publisher": "Emerald Group Publishing Limited"
        },
        {
            "Title": "Data warehouse refreshment",
            "Publication year": 2006,
            "Publication url": "http://olympias.lib.uoi.gr/jspui/handle/123456789/26770",
            "Abstract": "Repository of UOI \"Olympias\": Data warehouse refreshment Skip navigation Home Browse \nCommunities & Collections Browse Items by: Issue Date Author Title Subject Item Type \nAdvanced Search Help About DSpace Sign on to: My DSpace Receive email updates Edit \nProfile Saved Searches Favorites Repository of UOI \"Olympias\" 1.Repository of OAI 2.\u0391\u03a0\u039f\u0398\u0395\u03a4\u0397\u03a1\u0399\u039f \n\"\u039f\u039b\u03a5\u039c\u03a0\u0399\u0391\u03a3\" 3.\u03a3\u03c7\u03bf\u03bb\u03ae \u0398\u03b5\u03c4\u03b9\u03ba\u03ce\u03bd \u0395\u03c0\u03b9\u03c3\u03c4\u03b7\u03bc\u03ce\u03bd 4.\u03a4\u03bc\u03ae\u03bc\u03b1 \u039c\u03b7\u03c7\u03b1\u03bd\u03b9\u03ba\u03ce\u03bd \u0397\u03bb\u03b5\u03ba\u03c4\u03c1\u03bf\u03bd\u03b9\u03ba\u03ce\u03bd \u03a5\u03c0\u03bf\u03bb\u03bf\u03b3\u03b9\u03c3\u03c4\u03ce\u03bd \n\u03ba\u03b1\u03b9 \u03a0\u03bb\u03b7\u03c1\u03bf\u03c6\u03bf\u03c1\u03b9\u03ba\u03ae\u03c2 5.\u039c\u03bf\u03bd\u03bf\u03b3\u03c1\u03b1\u03c6\u03af\u03b5\u03c2 ( \u039a\u03bb\u03b5\u03b9\u03c3\u03c4\u03ad\u03c2) \u0395\u03bb\u03bb\u03b7\u03bd\u03b9\u03ba\u03ac English Please use this identifier to \ncite or link to this item: https://olympias.lib.uoi.gr/jspui/handle/123456789/26770 Institution \nand School/Department of submitter: \u03a0\u03b1\u03bd\u03b5\u03c0\u03b9\u03c3\u03c4\u03ae\u03bc\u03b9\u03bf \u0399\u03c9\u03b1\u03bd\u03bd\u03af\u03bd\u03c9\u03bd. \u03a3\u03c7\u03bf\u03bb\u03ae \u0398\u03b5\u03c4\u03b9\u03ba\u03ce\u03bd \u0395\u03c0\u03b9\u03c3\u03c4\u03b7\u03bc\u03ce\u03bd. \n\u03a4\u03bc\u03ae\u03bc\u03b1 \u039c\u03b7\u03c7\u03b1\u03bd\u03b9\u03ba\u03ce\u03bd \u0397/\u03a5 & \u03a0\u03bb\u03b7\u03c1\u03bf\u03c6\u03bf\u03c1\u03b9\u03ba\u03ae\u03c2 Keywords: - URI: https://olympias.lib.uoi.gr/jspui/handle/123456789/26770 \nPublisher: IGI Global Book name: Data Warehouses and OLAP Appears in : ( \u2026",
            "Abstract entirety": 0,
            "Author pub id": "B_Zd1P8AAAAJ:7T2F9Uy0os0C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Assess Queries for Interactive Analysis of Data Cubes.",
            "Publication year": 2021,
            "Publication url": "http://cs.uoi.gr/~pvassil/publications/2021_EDBT/EDBT_2021_ASSESS.pdf",
            "Abstract": "Assessment is the process of comparing the actual to the expected behavior of a business phenomenon and judging the outcome of the comparison. In this paper we propose assess, a novel querying operator that supports assessment based on the results of a query on a data cube. This operator requires (1) the specification of an OLAP query over a measure of a data cube, to define the target cube to be assessed;(2) the specification of a reference cube of comparison (benchmark), which represents the expected performance of the measure;(3) the specification of how to perform the comparison between the target cube and the benchmark, and (4) a labeling function that classifies the result of this comparison using a set of labels. After introducing an SQL-like syntax for our operator, we formally define its semantics in terms of a set of logical operators. To support the computation of assess we propose a basic plan as well as some optimization strategies, then we experimentally evaluate their performance using a prototype.",
            "Abstract entirety": 1,
            "Author pub id": "B_Zd1P8AAAAJ:9pM33mqn1YgC",
            "Publisher": "Unknown"
        },
        {
            "Title": "CoWSAMI: Interface-aware context gathering in ambient intelligence environments",
            "Publication year": 2008,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S1574119207000740",
            "Abstract": "In this paper we present CoWSAMI, a middleware infrastructure that enables context awareness in open ambient intelligence environments, consisting of mobile users and context sources that become dynamically available as the users move from one location to another. A central requirement in such dynamic scenarios is to be able to integrate new context sources and users at run-time. CoWSAMI exploits a novel approach towards this goal. The proposed approach is based on utilizing Web services as interfaces to context sources and dynamically updatable relational views for storing, aggregating and interpreting context. Context rules are employed to provide mappings that specify how to populate context relations, with respect to the different context sources that become dynamically available. An underlying context sources discovery mechanism is utilized to maintain context information up to date as context \u2026",
            "Abstract entirety": 0,
            "Author pub id": "B_Zd1P8AAAAJ:4DMP91E08xMC",
            "Publisher": "Elsevier"
        },
        {
            "Title": "Data Warehousing and OLAP",
            "Publication year": 2008,
            "Publication url": "https://pascal-francis.inist.fr/vibad/index.php?action=getRecordDetail&idt=20259249",
            "Abstract": "Sauf mention contraire ci-dessus, le contenu de cette notice bibliographique peut \u00eatre utilis\u00e9 dans le cadre d\u2019une licence CC BY 4.0 Inist-CNRS/Unless otherwise stated above, the content of this bibliographic record may be used under a CC BY 4.0 licence by Inist-CNRS/A menos que se haya se\u00f1alado antes, el contenido de este registro bibliogr\u00e1fico puede ser utilizado al amparo de una licencia CC BY 4.0 Inist-CNRS",
            "Abstract entirety": 1,
            "Author pub id": "B_Zd1P8AAAAJ:TIZ-Mc8IlK0C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Propagating evolution events in data-centric software artifacts",
            "Publication year": 2011,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/5767629/",
            "Abstract": "The success and wellbeing of large organizations rely on the smooth functionality and operability of their software. Such qualities are largely affected by evolution events and changes, like software upgrades. In this paper, we are dealing with handling evolution events in data management systems. We consider a data-centric ecosystem that captures relational tables, views and queries (the latter are seeing as software modules that are either internal to the database, e.g., stored procedures, or external software applications that access the database). We also consider policies dictating the response of a software module to a possible event. We investigate the impact of such events to the database and present a graph-based mechanism to control event propagation. We show that our mechanism terminates and that every database construct is annotated with a single status, regardless of the sequence of messages \u2026",
            "Abstract entirety": 0,
            "Author pub id": "B_Zd1P8AAAAJ:hMod-77fHWUC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Report on the 8th International Workshop on Quality in Databases (QDB10)",
            "Publication year": 2012,
            "Publication url": "https://dl.acm.org/doi/pdf/10.1145/2094114.2094128",
            "Abstract": "The eighth international workshop on Quality in Database was held in Singapore, on September 13th, 2010 and co-located with the 36th Conference on Very Large DataBase (VLDB). The main objective of the workshop was to address the challenge to detect data anomalies and assess, monitor, improve, and maintain the quality of information. The workshop attracted 12 submissions from Asia, Australia, Europe, and the United States, out of which the Program Committee finally accepted 9 full papers. The accepted papers focused on important issues especially related to Data Quality assessment, Entity Matching, and Information Overloading.",
            "Abstract entirety": 1,
            "Author pub id": "B_Zd1P8AAAAJ:dshw04ExmUIC",
            "Publisher": "ACM"
        },
        {
            "Title": "A survey of extract\u2013transform\u2013load technology",
            "Publication year": 2009,
            "Publication url": "https://www.igi-global.com/article/survey-extract-transform-load-technology/3894",
            "Abstract": "The software processes that facilitate the original loading and the periodic refreshment of the data warehouse contents are commonly known as Extraction-Transformation-Loading (ETL) processes. The intention of this survey is to present the research work in the field of ETL technology in a structured way. To this end, we organize the coverage of the field as follows:(a) first, we cover the conceptual and logical modeling of ETL processes, along with some design methods,(b) we visit each stage of the ETL triplet, and examine problems that fall within each of these stages,(c) we discuss problems that pertain to the entirety of an ETL process, and,(d) we review some research prototypes of academic origin.",
            "Abstract entirety": 1,
            "Author pub id": "B_Zd1P8AAAAJ:hC7cP41nSMkC",
            "Publisher": "IGI Global"
        },
        {
            "Title": "Design patterns for relational databases",
            "Publication year": 2009,
            "Publication url": "https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.184.3476&rep=rep1&type=pdf",
            "Abstract": "A design artifact at the logical level comprises abstract mathematical symbol structures to hide implementation details from the designer [Kolp01, Mylo98]. Logical models are the bridge between the requirements-oriented, subjective, highly intuitive conceptual models and the concrete, physical-level models that represent the way things are actually implemented in the system. This property provides a reasonable compromise between formality, intuition and implementation and makes the logical models the fundamental blueprints of the software architecture of an information system. In the world of databases, the fundamental design artifacts at the logical level are the database schemata. A database schema is the platform over which (a) applications are developed and (b) tuning of the physical structure of the database is performed. In other words, logical schemata are the most important design artifact for the full lifecycle of a database-centric information system. Why patterns? Patterns constitute a principled way of teaching, designing and documenting software systems [GHJV95]. Moreover, patterns allow us to evaluate the quality of a design by measuring the compliance of a logical schema to a set of underlying patterns. Given a well-founded theory of database patterns, the less deviations a schema has from the theory, the less is the risk of maintenance traps, since the improvisations that a designer makes are minimized. In this paper, we provide a discussion of a template structure for database-related patterns. We make the following assumptions:(i) we are primarily interested in patterns concerning relational databases (on top of which, object \u2026",
            "Abstract entirety": 0,
            "Author pub id": "B_Zd1P8AAAAJ:vV6vV6tmYwMC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Multidimensional data models and aggregation",
            "Publication year": 2000,
            "Publication url": "https://link.springer.com/content/pdf/10.1007/978-3-662-04138-3_5.pdf",
            "Abstract": "This chapter is devoted to the modeling of multidimensional information in the context of data warehousing and knowledge representation, with a particular emphasis on the operation of aggregation.",
            "Abstract entirety": 1,
            "Author pub id": "B_Zd1P8AAAAJ:BrmTIyaxlBUC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "Supporting the Generation of Data Narratives.",
            "Publication year": 2020,
            "Publication url": "http://ceur-ws.org/Vol-2716/paper16.pdf",
            "Abstract": "Data narration has received increasing interest in several communities while lacking models and tools for handling, building and structuring data narratives. We present a simple prototype for supporting data narrative, based on a conceptual model defined in [4]. It guides a data narrator from scratch: fetch and explore data, abstract important messages based on an intentional goal, structure the contents of the data story, and render it in a visual manner. This prototype is implemented in Java as a web application using Spring, d3. js, JFreeChart and Apache PDFBox.",
            "Abstract entirety": 1,
            "Author pub id": "B_Zd1P8AAAAJ:PVjk1bu6vJQC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Visual Maps for Data-Intensive Ecosystems",
            "Publication year": 2014,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-319-12206-9_32",
            "Abstract": "Data-intensive ecosystems are conglomerations of one or more databases along with software applications that are built on top of them. This paper proposes a set of methods for providing visual maps of data-intensive ecosystems. We model the ecosystem as a graph, with modules (tables and queries embedded in the applications) as nodes and data provision relationships as edges. We cluster the modules of the ecosystem in order to further highlight their interdependencies and reduce visual clutter. We employ three alternative, novel, circular graph drawing methods for creating a visual map of the graph.",
            "Abstract entirety": 1,
            "Author pub id": "B_Zd1P8AAAAJ:SdhP9T11ey4C",
            "Publisher": "Springer, Cham"
        },
        {
            "Title": "CPM: A Cube Presentation Model for",
            "Publication year": 2003,
            "Publication url": "http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.60.8747",
            "Abstract": "On-Line Analytical Processing (OLAP) is a trend in database technology, based on the multidimensional view of data. In this paper we introduce the Cube Presentation Model (CPM), a presentational model for OLAP data which, to the best of our knowledge, is the only formal presentational model for OLAP found in the literature until today. First, our proposal extends a previous logical model for cubes, to handle more complex cases. Then, we present a novel presentational model for OLAP screens, intuitively based on the geometrical representation of a cube and its human perception in the space. Moreover, we show how the logical and the presentational models are integrated smoothly. Finally, we describe how typical OLAP operations can be easily mapped to the CPM.",
            "Abstract entirety": 1,
            "Author pub id": "B_Zd1P8AAAAJ:lSLTfruPkqcC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Schema evolution survival guide for tables: Avoid rigid childhood and you\u2019re en route to a quiet life",
            "Publication year": 2017,
            "Publication url": "https://link.springer.com/article/10.1007/s13740-017-0083-x",
            "Abstract": "In this paper, we study the factors that relate to the survival of a table in the context of schema evolution in open-source software. We study the history of the schema of eight open-source software projects that include relational databases and extract patterns related to the survival or death of their tables. Our study shows that the probability of a table with a wide schema (i.e., a large number of attributes) being removed is systematically lower than average. Activity and duration are related to survival too. Rigid tables, without any change to their schema, are more likely to be removed than tables that sustain changes. Durations of dead and survival tables demonstrate a mirror image: dead tables\u2019 durations are mostly short, whereas survivor tables gravitate toward higher durations. Our findings are mostly summarized by a pattern, which we call electrolysis pattern, due to its diagrammatic representation, stating \u2026",
            "Abstract entirety": 0,
            "Author pub id": "B_Zd1P8AAAAJ:4MWp96NkSFoC",
            "Publisher": "Springer Berlin Heidelberg"
        },
        {
            "Title": "Data warehouse architecture and quality: impact and open challenges",
            "Publication year": 2013,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-642-36926-1_14",
            "Abstract": "The CAiSE 98 paper \u201cArchitecture and Quality in Data Warehouses\u201d and its expanded journal version [17] was the first to add a Zachman-like [35] explicit conceptual enterprise modeling perspective to the architecture of data warehouses. Until then, data warehouses were just seen as collections of \u2013 typically multidimensional and historized \u2013 materialized views on relational tables, without consideration of modeling of the (business) concepts underlying their structure. The paper pointed out that this additional conceptual perspective was not just necessary for a truly semantic data integration but also a prerequisite for bringing the then very active data warehouse movement together with another topic of quickly growing importance, that of data quality.",
            "Abstract entirety": 1,
            "Author pub id": "B_Zd1P8AAAAJ:AXPGKjj_ei8C",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "Computational methods and optimizations for containment and complementarity in web data cubes",
            "Publication year": 2018,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S030643791730488X",
            "Abstract": "The increasing availability of diverse multidimensional data on the web has led to the creation and adoption of common vocabularies and practices that facilitate sharing, aggregating and reusing data from remote origins. One prominent example in the Web of Data is the RDF Data Cube vocabulary, which has recently attracted great attention from the industrial, government and academic sectors as the de facto representational model for publishing open multidimensional data. As a result, different datasets share terms from common code lists and hierarchies, this way creating an implicit relatedness between independent sources. Identifying and analyzing relationships between disparate data sources is a major prerequisite for enabling traditional business analytics at the web scale. However, discovery of instance-level relationships between datasets becomes a computationally costly procedure, as typically all \u2026",
            "Abstract entirety": 0,
            "Author pub id": "B_Zd1P8AAAAJ:ILKRHgRFtOwC",
            "Publisher": "Pergamon"
        },
        {
            "Title": "CPM: A cube presentation model for OLAP",
            "Publication year": 2003,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-540-45228-7_2",
            "Abstract": "On-Line Analytical Processing (OLAP) is a trend in database technology, based on the multidimensional view of data. In this paper we introduce the Cube Presentation Model (CPM), a presentational model for OLAP data which, to the best of our knowledge, is the only formal presentational model for OLAP found in the literature until today. First, our proposal extends a previous logical model for cubes, to handle more complex cases. Then, we present a novel presentational model for OLAP screens, intuitively based on the geometrical representation of a cube and its human perception in the space. Moreover, we show how the logical and the presentational models are integrated smoothly. Finally, we describe how typical OLAP operations can be easily mapped to the CPM.",
            "Abstract entirety": 1,
            "Author pub id": "B_Zd1P8AAAAJ:Wp0gIr-vW9MC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "Efficient Deployment of Web Service Workflows",
            "Publication year": 2007,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/4401012/",
            "Abstract": "The appropriate deployment of Web service operations at the service provider site plays a critical role in the efficient provision of services to clients. In this paper, we assume that a service provider has several servers over which web service operations can be deployed. Then, given a workflow of Web services and the topology of the servers, the most efficient mopping of operations to servers must be discovered. Efficiency is measured in terms of two cost functions that concern the execution lime of the workflow and the fairness of the load distribution among the servers. We study different topologies for the workflow structure and the server connectivity and propose a suite of greedy algorithms for each combination.",
            "Abstract entirety": 1,
            "Author pub id": "B_Zd1P8AAAAJ:nb7KW1ujOQ8C",
            "Publisher": "IEEE"
        },
        {
            "Title": "Computing and handling cardinal direction information",
            "Publication year": 2004,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-540-24741-8_20",
            "Abstract": "Qualitative spatial reasoning forms an important part of the commonsense reasoning required for building intelligent Geographical Information Systems (GIS). Previous research has come up with models to capture cardinal direction relations for typical GIS data. In this paper, we target the problem of efficiently computing the cardinal direction relations between regions that are composed of sets of polygons and present the first two algorithms for this task. The first of the proposed algorithms is purely qualitative and computes, in linear time, the cardinal direction relations between the input regions. The second has a quantitative aspect and computes, also in linear time, the cardinal direction relations with percentages between the input regions. The algorithms have been implemented and embedded in an actual system, CarDirect, that allows the user to annotate regions of interest in an image or a map \u2026",
            "Abstract entirety": 0,
            "Author pub id": "B_Zd1P8AAAAJ:-f6ydRqryjwC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "Service oriented middleware for the future Internet state of the art and research directions",
            "Publication year": 2011,
            "Publication url": "http://olympias.lib.uoi.gr/jspui/handle/123456789/11081",
            "Abstract": "Repository of UOI \"Olympias\": Service oriented middleware for the future Internet state of the \nart and research directions Skip navigation Home Browse Communities & Collections Browse \nItems by: Issue Date Author Title Subject Item Type Advanced Search Help About DSpace Sign \non to: My DSpace Receive email updates Edit Profile Saved Searches Favorites Repository of \nUOI \"Olympias\" 1.Repository of OAI 2.\u0391\u03a0\u039f\u0398\u0395\u03a4\u0397\u03a1\u0399\u039f \"\u039f\u039b\u03a5\u039c\u03a0\u0399\u0391\u03a3\" 3.\u03a3\u03c7\u03bf\u03bb\u03ae \u0398\u03b5\u03c4\u03b9\u03ba\u03ce\u03bd \u0395\u03c0\u03b9\u03c3\u03c4\u03b7\u03bc\u03ce\u03bd \n4.\u03a4\u03bc\u03ae\u03bc\u03b1 \u039c\u03b7\u03c7\u03b1\u03bd\u03b9\u03ba\u03ce\u03bd \u0397\u03bb\u03b5\u03ba\u03c4\u03c1\u03bf\u03bd\u03b9\u03ba\u03ce\u03bd \u03a5\u03c0\u03bf\u03bb\u03bf\u03b3\u03b9\u03c3\u03c4\u03ce\u03bd \u03ba\u03b1\u03b9 \u03a0\u03bb\u03b7\u03c1\u03bf\u03c6\u03bf\u03c1\u03b9\u03ba\u03ae\u03c2 5.\u0386\u03c1\u03b8\u03c1\u03b1 \u03c3\u03b5 \u03b5\u03c0\u03b9\u03c3\u03c4\u03b7\u03bc\u03bf\u03bd\u03b9\u03ba\u03ac \n\u03c0\u03b5\u03c1\u03b9\u03bf\u03b4\u03b9\u03ba\u03ac ( \u0391\u03bd\u03bf\u03b9\u03ba\u03c4\u03ac) \u0395\u03bb\u03bb\u03b7\u03bd\u03b9\u03ba\u03ac English Please use this identifier to cite or link to this item: \nhttps://olympias.lib.uoi.gr/jspui/handle/123456789/11081 Institution and School/Department of \nsubmitter: \u03a0\u03b1\u03bd\u03b5\u03c0\u03b9\u03c3\u03c4\u03ae\u03bc\u03b9\u03bf \u0399\u03c9\u03b1\u03bd\u03bd\u03af\u03bd\u03c9\u03bd. \u03a3\u03c7\u03bf\u03bb\u03ae \u0398\u03b5\u03c4\u03b9\u03ba\u03ce\u03bd \u0395\u03c0\u03b9\u03c3\u03c4\u03b7\u03bc\u03ce\u03bd. \u03a4\u03bc\u03ae\u03bc\u03b1 \u039c\u03b7\u03c7\u03b1\u03bd\u03b9\u03ba\u03ce\u03bd \n\u0397\u03bb\u03b5\u03ba\u03c4\u03c1\u03bf\u03bd\u03b9\u03ba\u03ce\u03bd \u03a5\u03c0\u03bf\u03bb\u03bf\u03b3\u03b9\u03c3\u03c4\u03ce\u03bd \u03ba\u03b1\u03b9 \u03a0\u03bb\u03b7\u03c1\u03bf\u03c6\u03bf\u03c1\u03b9\u03ba\u03ae\u03c2 Keywords: Future Internet,,Service-oriented ,,-: :\u2026",
            "Abstract entirety": 0,
            "Author pub id": "B_Zd1P8AAAAJ:_Re3VWB3Y0AC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Guest editors' introduction: special issue on the CAiSE 2003 conference",
            "Publication year": 2005,
            "Publication url": "https://dl.acm.org/doi/abs/10.5555/1090339.1090340",
            "Abstract": "Guest editors' introduction: special issue on the CAiSE 2003 conference: Information Systems: \nVol 30, No 7 ACM Digital Library home ACM home Google, Inc. (search) Advanced Search \nBrowse About Sign in Register Advanced Search Journals Magazines Proceedings Books \nSIGs Conferences People More Search ACM Digital Library SearchSearch Advanced Search \nInformation Systems Periodical Home Latest Issue Archive Authors Affiliations Award Winners \nMore HomeBrowse by TitlePeriodicalsInformation SystemsVol. , No. Guest editors' introduction: \nspecial issue on the CAiSE 2003 conference article Guest editors' introduction: special issue \non the CAiSE 2003 conference Share on Authors: J. Eder Departement of Informatics system, \nAlps Adria University, Klagenfurt, Austria Departement of Informatics system, Alps Adria \nUniversity, Klagenfurt, Austria View Profile , M. Missikoff Istituto di Analisi dei Sistemi ed , , .\u2026",
            "Abstract entirety": 0,
            "Author pub id": "B_Zd1P8AAAAJ:a0OBvERweLwC",
            "Publisher": "Elsevier Science Ltd."
        },
        {
            "Title": "ERATOSTHENES: Design and Architecture of an OLAP System",
            "Publication year": 2001,
            "Publication url": "http://www.dblab.ece.ntua.gr/pubs/uploads/TR-2001-10.pdf",
            "Abstract": "On-Line Analytical Processing (OLAP) is a trend in database technology, based on the multidimensional view of data. The aim of this paper is twofold:(a) to list general problems and solutions applicable to the design of any OLAP system and (b) to present the specific design decisions that we made for a prototype under development at NTUA, which we call ERATOSTHENES. The paper addresses requirements and design issues for all three models involved in an OLAP system: the presentational, logical and physical model. It also discusses in detail the architecture and the major components of ERATOSTHENES.",
            "Abstract entirety": 1,
            "Author pub id": "B_Zd1P8AAAAJ:g5m5HwL7SMYC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Towards a benchmark for etl workflows",
            "Publication year": 2007,
            "Publication url": "http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.94.8508",
            "Abstract": "Extraction\u2013Transform\u2013Load (ETL) processes comprise complex data workflows, which are responsible for the maintenance of a Data Warehouse. Their practical importance is denoted by the fact that a plethora of ETL tools currently constitutes a multi-million dollars market. However, each one of them follows a different design and modeling technique and internal language. So far, the research community has not agreed upon the basic characteristics of ETL tools. Hence, there is a necessity for a unified way to assess ETL workflows. In this paper, we investigate the main characteristics and peculiarities of ETL processes and we propose a principled organization of test suites for the problem of experimenting with ETL scenarios. 1.",
            "Abstract entirety": 1,
            "Author pub id": "B_Zd1P8AAAAJ:qxL8FJ1GzNcC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Fundamentals of data warehouses",
            "Publication year": 2002,
            "Publication url": "https://books.google.com/books?hl=en&lr=&id=95Rg5K516mYC&oi=fnd&pg=PA1&dq=info:ew8q_j2dP7kJ:scholar.google.com&ots=GaowNM7i0c&sig=nwL7nu2jbf4fzgWpJ1xZV5yaTTs",
            "Abstract": "Data warehouses have captured the attention of practitioners and researchers alike. But the design and optimization of data warehouses remains an art rather than a science. This book presents the first comparative review of the state of the art and best current practice of data warehouses. It covers source and data integration, multidimensional aggregation, query optimization, update propagation, metadata management, quality assessment, and design optimization. Also, based on results of the European Data Warehouse Quality project, it offers a conceptual framework by which the architecture and quality of data warehouse efforts can be assessed and improved using enriched metadata management combined with advanced techniques from databases, business modeling, and artificial intelligence. For researchers and database professionals in academia and industry, the book offers an excellent introduction to the issues of quality and metadata usage in the context of data warehouses.",
            "Abstract entirety": 1,
            "Author pub id": "B_Zd1P8AAAAJ:u5HHmVD_uO8C",
            "Publisher": "Springer Science & Business Media"
        },
        {
            "Title": "Developing mobile commerce applications",
            "Publication year": 2008,
            "Publication url": "https://www.igi-global.com/article/developing-mobile-commerce-applications/3506",
            "Abstract": "In this article, we deal with context-aware query processing in ad-hoc peer-to-peer networks. Each peer in such an environment has a database over which users execute queries. This database involves (a) relations which are locally stored and (b) virtual relations, all the tuples of which are collected from peers that are present in the network at the time when a query is posed. The objective of our work is to perform query processing in such an environment and, to this end, we start with a formal definition of the system model. Next, we formally define SQLP, an extension of SQL that covers the termination of queries, the failure of individual peers and the semantic characteristics of the peers of such a network. Moreover, we present a query execution algorithm as well as the formal definition of all the operators that take place in a query execution plan.",
            "Abstract entirety": 1,
            "Author pub id": "B_Zd1P8AAAAJ:D03iK_w7-QYC",
            "Publisher": "IGI Global"
        },
        {
            "Title": "Graph-driven Federated Data Management",
            "Publication year": 2021,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/9422168/",
            "Abstract": "Modern data analysis applications, require the ability to provide on-demand integration of data sources while offering a flexible and user-friendly query interface. Traditional techniques for answering queries using views, focused on a rather static setting, fail to address such requirements. To overcome these issues, we propose a fully-fledged data integration approach based on graph-based constructs. The extensibility of graphs allows us to extend the traditional framework for data integration with view definitions. Furthermore, we also propose a query language based on subgraphs. We tackle query answering via a query rewriting algorithm based on well-known algorithms for answering queries using views. We experimentally show that the proposed method yields good performance and does not introduce a significant overhead.",
            "Abstract entirety": 1,
            "Author pub id": "B_Zd1P8AAAAJ:GtLg2Ama23sC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Near real time ETL",
            "Publication year": 2009,
            "Publication url": "https://link.springer.com/content/pdf/10.1007/978-0-387-87431-9_2.pdf",
            "Abstract": "Near real time ETL deviates from the traditional conception of data warehouse refreshment, which is performed off-line in a batch mode, and adopts the strategy of propagating changes that take place in the sources towards the data warehouse to the extent that both the sources and the warehouse can sustain the incurred workload. In this article, we review the state of the art for both conventional and near real time ETL, we discuss the background, the architecture, and the technical issues that arise in the area of near real time ETL, and we pinpoint interesting research challenges for future work.",
            "Abstract entirety": 1,
            "Author pub id": "B_Zd1P8AAAAJ:IWHjjKOFINEC",
            "Publisher": "Springer, Boston, MA"
        },
        {
            "Title": "RADAR: Radial applications' depiction around relations for data-centric ecosystems",
            "Publication year": 2011,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/5767648/",
            "Abstract": "A data-centric ecosystem is the configuration of a central database along with all the applications that operate on top of it and are (a) dependent upon the database for performing their task appropriately and (b) closely related in terms of coding to the database. This paper presents first results towards addressing the issue of visualization of such a data-centric ecosystem in a reference \u201cmap\u201d. We map SQL queries and relations to a graph and present alternative algorithms for the visualization of the graph. First we start with a barycenter-based method that puts all queries in a line and all relations in a parallel line, in a way that closely put nodes are the ones that are most similar (within the same line) and closely related (across lines). Then, we move on to extend it with a variant that involves multiple lines for the queries. Finally, we present our main algorithm Concentric Radial, for placing queries and relations in \u2026",
            "Abstract entirety": 0,
            "Author pub id": "B_Zd1P8AAAAJ:dfsIfKJdRG4C",
            "Publisher": "IEEE"
        },
        {
            "Title": "\u0394\u03b9\u03ac\u03b4\u03bf\u03c3\u03b7 \u0391\u03bb\u03bb\u03b1\u03b3\u03ce\u03bd \u03a3\u03b5 \u03a0\u03bb\u03b7\u03c1\u03bf\u03c6\u03bf\u03c1\u03b9\u03b1\u03ba\u03ac \u039f\u03b9\u03ba\u03bf\u03c3\u03c5\u03c3\u03c4\u03ae\u03bc\u03b1\u03c4\u03b1",
            "Publication year": 2012,
            "Publication url": "https://scholar.google.com/scholar?cluster=15349199609960397938&hl=en&oi=scholarr",
            "Abstract": "The repository \u00abATHENA\u00bb is an Open Access Institutional Repository that collects, gathers, and freely disseminates the research outputs created by the members of the \u00abATHENA\u00bb Research Center. The aim of the \u00abATHENA\u00bb repository is to promote knowledge by supporting the research life-cycle. For this reason, it is based on international standards to ensure sustainability of the research outputs which derived from the scientific and the social challenges.",
            "Abstract entirety": 1,
            "Author pub id": "B_Zd1P8AAAAJ:rmuvC79q63oC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Advances in data warehousing",
            "Publication year": 2006,
            "Publication url": "https://scholar.google.com/scholar?cluster=13037692015748788627&hl=en&oi=scholarr",
            "Abstract": "not available.",
            "Abstract entirety": 1,
            "Author pub id": "B_Zd1P8AAAAJ:uWQEDVKXjbEC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Blueprints and measures for ETL workflows",
            "Publication year": 2005,
            "Publication url": "https://link.springer.com/chapter/10.1007/11568322_25",
            "Abstract": "Extract-Transform-Load (ETL) workflows are data centric workflows responsible for transferring, cleaning, and loading data from their respective sources to the warehouse. Previous research has identified graph-based techniques that construct the blueprints for the structure of such workflows. In this paper, we extend existing results by explicitly incorporating the internal semantics of each activity in the workflow graph. Apart from the value that blueprints have per se, we exploit our modeling to introduce rigorous techniques for the measurement of ETL workflows. To this end, we build upon an existing formal framework for software quality metrics and formally prove how our quality measures fit within this framework.",
            "Abstract entirety": 1,
            "Author pub id": "B_Zd1P8AAAAJ:9ZlFYXVOiuMC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "How is life for a table in an evolving relational schema? Birth, death and everything in between",
            "Publication year": 2015,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-319-25264-3_34",
            "Abstract": "In this paper, we study the version history of eight databases that are part of larger open source projects, and report on our observations on how evolution-related properties, like the possibility of deletion, or the amount of updates that a table undergoes, are related to observable table properties like the number of attributes or the time of birth of a table. Our findings indicate that (i) most tables live quiet lives; (ii) few top-changers adhere to a profile of long duration, early birth, medium schema size at birth; (iii) tables with large schemata or long duration are quite unlikely to be removed, and, (iv) early periods of the database life demonstrate a higher level of evolutionary activity compared to later ones.",
            "Abstract entirety": 1,
            "Author pub id": "B_Zd1P8AAAAJ:PR6Y55bgFSsC",
            "Publisher": "Springer, Cham"
        },
        {
            "Title": "Do People Use Naming Conventions in SQL Programming?",
            "Publication year": 2020,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-030-38919-2_35",
            "Abstract": "In this paper, we investigate the usage of naming conventions in SQL programming. To this end, we define a reference style, consisting of naming conventions that have been proposed in the literature. Then, we perform an empirical study that involves the database schemas of 21 open source projects. In our study, we evaluate the adherence of the names that are used in the schemas to the reference style. Moreover, we study how the adherence of the names to the reference style evolves, during the lifetime of the schemas. Our study reveals that many conventions are followed in all schemas. The adherence to these conventions is typically stable, during the lifetime of the schemas. However, there are also conventions that are partially followed, or even not followed. Over time, the adherence of the schemas to these conventions may improve, decay or remain stable.",
            "Abstract entirety": 1,
            "Author pub id": "B_Zd1P8AAAAJ:foquWX3nUaYC",
            "Publisher": "Springer, Cham"
        },
        {
            "Title": "Design and Management of Data Warehouses 2003",
            "Publication year": 2003,
            "Publication url": "http://ceur-ws.org/Vol-77/",
            "Abstract": "CEUR-WS.org/Vol-77 [CEUR Workshop Proceedings] Vol-77 \u00a9 2003 for the individual papers \nby the papers' authors. Copying permitted for private and scientific purposes. Re-publication of \nmaterial on this page requires permission by the copyright owners. Design and Management of \nData Warehouses 2003 Proceedings of the 5th Intl. Workshop DMDW'2003, Berlin, Germany, \nSeptember 8, 2003 Edited by Hans-J. Lenz , Freie Univ. Berlin, Germany Panos Vassiliadis, \nUniv. of Ioannina, Greece Manfred Jeusfeld, Tilburg Univ., The Netherlands Martin Staudt \nUniv. of Applied Sciences Solothurn, Switzerland DMDW'2003 was held in conjunction with \nthe 29th International Conference on Very Large DataBases (VLDB'03). Foreword Keynote \naddress Open problems in data warehousing: eight years later Stefano Rizzi Research \npapers A Comprehensive Method for Data Warehouse Design Sergio Lujan-Mora and Juan . I\u2026",
            "Abstract entirety": 0,
            "Author pub id": "B_Zd1P8AAAAJ:8AbLer7MMksC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Modelling and analysing reliable service oriented processes",
            "Publication year": 2008,
            "Publication url": "http://olympias.lib.uoi.gr/jspui/handle/123456789/10997",
            "Abstract": "Repository of UOI \"Olympias\": Modelling and analysing reliable service oriented processes Skip \nnavigation Home Browse Communities & Collections Browse Items by: Issue Date Author Title \nSubject Item Type Advanced Search Help About DSpace Sign on to: My DSpace Receive email \nupdates Edit Profile Saved Searches Favorites Repository of UOI \"Olympias\" 1.Repository of OAI \n2.\u0391\u03a0\u039f\u0398\u0395\u03a4\u0397\u03a1\u0399\u039f \"\u039f\u039b\u03a5\u039c\u03a0\u0399\u0391\u03a3\" 3.\u03a3\u03c7\u03bf\u03bb\u03ae \u0398\u03b5\u03c4\u03b9\u03ba\u03ce\u03bd \u0395\u03c0\u03b9\u03c3\u03c4\u03b7\u03bc\u03ce\u03bd 4.\u03a4\u03bc\u03ae\u03bc\u03b1 \u039c\u03b7\u03c7\u03b1\u03bd\u03b9\u03ba\u03ce\u03bd \u0397\u03bb\u03b5\u03ba\u03c4\u03c1\u03bf\u03bd\u03b9\u03ba\u03ce\u03bd \n\u03a5\u03c0\u03bf\u03bb\u03bf\u03b3\u03b9\u03c3\u03c4\u03ce\u03bd \u03ba\u03b1\u03b9 \u03a0\u03bb\u03b7\u03c1\u03bf\u03c6\u03bf\u03c1\u03b9\u03ba\u03ae\u03c2 5.\u0386\u03c1\u03b8\u03c1\u03b1 \u03c3\u03b5 \u03b5\u03c0\u03b9\u03c3\u03c4\u03b7\u03bc\u03bf\u03bd\u03b9\u03ba\u03ac \u03c0\u03b5\u03c1\u03b9\u03bf\u03b4\u03b9\u03ba\u03ac ( \u0391\u03bd\u03bf\u03b9\u03ba\u03c4\u03ac) \u0395\u03bb\u03bb\u03b7\u03bd\u03b9\u03ba\u03ac English \nPlease use this identifier to cite or link to this item: \nhttps://olympias.lib.uoi.gr/jspui/handle/123456789/10997 Institution and School/Department of \nsubmitter: \u03a0\u03b1\u03bd\u03b5\u03c0\u03b9\u03c3\u03c4\u03ae\u03bc\u03b9\u03bf \u0399\u03c9\u03b1\u03bd\u03bd\u03af\u03bd\u03c9\u03bd. \u03a3\u03c7\u03bf\u03bb\u03ae \u0398\u03b5\u03c4\u03b9\u03ba\u03ce\u03bd \u0395\u03c0\u03b9\u03c3\u03c4\u03b7\u03bc\u03ce\u03bd. \u03a4\u03bc\u03ae\u03bc\u03b1 \u039c\u03b7\u03c7\u03b1\u03bd\u03b9\u03ba\u03ce\u03bd \u0397\u03bb\u03b5\u03ba\u03c4\u03c1\u03bf\u03bd\u03b9\u03ba\u03ce\u03bd \n\u03a5\u03c0\u03bf\u03bb\u03bf\u03b3\u03b9\u03c3\u03c4\u03ce\u03bd \u03ba\u03b1\u03b9 \u03a0\u03bb\u03b7\u03c1\u03bf\u03c6\u03bf\u03c1\u03b9\u03ba\u03ae\u03c2 Keywords: composite web services,BPEL,reliability \u2026",
            "Abstract entirety": 0,
            "Author pub id": "B_Zd1P8AAAAJ:35r97b3x0nAC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Data Warehouse Metadata.",
            "Publication year": 2009,
            "Publication url": "https://scholar.google.com/scholar?cluster=3825086071181190193&hl=en&oi=scholarr",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "B_Zd1P8AAAAJ:HE397vMXCloC",
            "Publisher": "Unknown"
        },
        {
            "Title": "A model for data warehouse operational processes",
            "Publication year": 2000,
            "Publication url": "https://link.springer.com/chapter/10.1007/3-540-45140-4_30",
            "Abstract": "Previous research has provided metadata models that enable the capturing of the static components of a Data Warehouse (DW) architecture, along with information on different quality factors over these components. This paper complements this work with the modeling of the dynamic parts of the DW, i.e., with a metamodel for DW operational processes. The proposed metamodel is capable of modeling complex activities, their interrelationships, and the relationship of activities with data sources and execution details. Finally, the metamodel complements proposed architecture and quality models in a coherent fashion, resulting in a full framework for DW metamodeling, capable of supporting the design, administration and evolution of a DW. We have implemented this metamodel using the language Telos and the metadata repository system ConceptBase.",
            "Abstract entirety": 1,
            "Author pub id": "B_Zd1P8AAAAJ:qUcmZB5y_30C",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "\u0391\u03c5\u03c4\u03bf\u03bc\u03b1\u03c4\u03bf\u03c0\u03bf\u03af\u03b7\u03c3\u03b7 \u03c4\u03b7\u03c2 \u03a0\u03c1\u03bf\u03c3\u03b1\u03c1\u03bc\u03bf\u03b3\u03ae\u03c2 \u0395\u03be\u03b5\u03bb\u03b9\u03c3\u03c3\u03cc\u03bc\u03b5\u03bd\u03c9\u03bd \u039f\u03b9\u03ba\u03bf\u03c3\u03c5\u03c3\u03c4\u03b7\u03bc\u03ac\u03c4\u03c9\u03bd \u0394\u03b5\u03b4\u03bf\u03bc\u03ad\u03bd\u03c9\u03bd",
            "Publication year": 2014,
            "Publication url": "https://scholar.google.com/scholar?cluster=1565249247242392440&hl=en&oi=scholarr",
            "Abstract": "The repository \u00abATHENA\u00bb is an Open Access Institutional Repository that collects, gathers, and freely disseminates the research outputs created by the members of the \u00abATHENA\u00bb Research Center. The aim of the \u00abATHENA\u00bb repository is to promote knowledge by supporting the research life-cycle. For this reason, it is based on international standards to ensure sustainability of the research outputs which derived from the scientific and the social challenges.",
            "Abstract entirety": 1,
            "Author pub id": "B_Zd1P8AAAAJ:_axFR9aDTf0C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Final CHOReOS Architectural Style and its Relation with the CHOReOS Development Process and IDRE",
            "Publication year": 2013,
            "Publication url": "https://hal.inria.fr/hal-00912869/",
            "Abstract": "This is Part b of Deliverable D1.4, which specifies the final CHOReOS architectural style, that is, the types of components, connectors, and configurations that are composed within the Future Internet of services, as enabled by the CHOReOS technologies developed in WP2 to WP4 and integrated in the WP5 IDRE. The definition of the CHOReOS architectural style is especially guided by the objective of meeting the challenges posed by the Future Internet, i.e.: (i) the ultra large base of services and of consumers, (ii) the high heterogeneity of the services that get composed, from the ones offered by tiny things to the ones hosted on powerful cloud computing infrastructures, (iii) the increasing predominance of mobile consumers and services, which take over the original fixed Inter- net, and (iv) the required awareness of, and related adaptation to, the continuous environmental changes. Another critical challenge posed by the Future Internet is that of security, trust and privacy. However, the study of technologies dedicated to enforcing security, privacy and trust is beyond the scope of the CHOReOS project; instead, state of the art technologies and possibly latest results from projects focused on security solutions are built upon for the development of CHOReOS use cases -if and when needed-. The CHOReOS architectural style that is presented in this deliverable refines the definition of the early style introduced in Deliverable D1.3. Key features of the CHOReOS architectural elements are as follows: (1) The CHOReOS service-based components are technology agnostic and allow for the abstraction of the large diversity of Future Internet services, and \u2026",
            "Abstract entirety": 0,
            "Author pub id": "B_Zd1P8AAAAJ:LjlpjdlvIbIC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Schema evolution and foreign keys: birth, eviction, change and absence",
            "Publication year": 2017,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-319-69904-2_9",
            "Abstract": "In this paper, we focus on the study of the evolution of foreign keys in the broader context of schema evolution for relational databases. Specifically, we study the schema histories of a six free, open-source databases that contained foreign keys. Our findings concerning the growth of tables verify previous results that schemata grow in the long run in terms of tables. Moreover, we have come to several surprising, new findings in terms of foreign keys. Foreign keys appear to be fairly scarce in the projects that we have studied and they do not necessarily grow in sync with table growth. In fact, we have observed different cultures for the handling of foreign keys, ranging from treating foreign keys as an indispensable part of the schema, in full sync with the growth of tables, to the unexpected extreme of treating foreign keys as an optional add-on that twice resulted in their full removal from the schema of the database.",
            "Abstract entirety": 1,
            "Author pub id": "B_Zd1P8AAAAJ:Z5m8FVwuT1cC",
            "Publisher": "Springer, Cham"
        },
        {
            "Title": "RawVis: visual exploration over raw data",
            "Publication year": 2018,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-319-98398-1_4",
            "Abstract": "Data exploration and visual analytics systems are of great importance in Open Science scenarios, where less tech-savvy researchers wish to access and visually explore big raw data files (e.g., json, csv) generated by scientific experiments using commodity hardware and without being overwhelmed in the tedious processes of data loading, indexing and query optimization. In this work, we present our work for enabling efficient query processing on raw data files for interactive visual exploration scenarios. We introduce a framework, named RawVis, built on top of a lightweight in-memory tile-based index, VALINOR, that is constructed on-the-fly given the first user query over a raw file and adapted based on the user interaction. We evaluate the performance of prototype implementation compared to three other alternatives and show that our method outperforms in terms of response time, disk accesses and \u2026",
            "Abstract entirety": 0,
            "Author pub id": "B_Zd1P8AAAAJ:kuK5TVdYjLIC",
            "Publisher": "Springer, Cham"
        },
        {
            "Title": "A context aware preference database system",
            "Publication year": 2007,
            "Publication url": "http://olympias.lib.uoi.gr/jspui/handle/123456789/10963",
            "Abstract": "Repository of UOI \"Olympias\": A context aware preference database system Skip navigation \nHome Browse Communities & Collections Browse Items by: Issue Date Author Title Subject \nItem Type Advanced Search Help About DSpace Sign on to: My DSpace Receive email \nupdates Edit Profile Saved Searches Favorites Repository of UOI \"Olympias\" 1.Repository \nof OAI 2.\u0391\u03a0\u039f\u0398\u0395\u03a4\u0397\u03a1\u0399\u039f \"\u039f\u039b\u03a5\u039c\u03a0\u0399\u0391\u03a3\" 3.\u03a3\u03c7\u03bf\u03bb\u03ae \u0398\u03b5\u03c4\u03b9\u03ba\u03ce\u03bd \u0395\u03c0\u03b9\u03c3\u03c4\u03b7\u03bc\u03ce\u03bd 4.\u03a4\u03bc\u03ae\u03bc\u03b1 \u039c\u03b7\u03c7\u03b1\u03bd\u03b9\u03ba\u03ce\u03bd \n\u0397\u03bb\u03b5\u03ba\u03c4\u03c1\u03bf\u03bd\u03b9\u03ba\u03ce\u03bd \u03a5\u03c0\u03bf\u03bb\u03bf\u03b3\u03b9\u03c3\u03c4\u03ce\u03bd \u03ba\u03b1\u03b9 \u03a0\u03bb\u03b7\u03c1\u03bf\u03c6\u03bf\u03c1\u03b9\u03ba\u03ae\u03c2 5.\u0386\u03c1\u03b8\u03c1\u03b1 \u03c3\u03b5 \u03b5\u03c0\u03b9\u03c3\u03c4\u03b7\u03bc\u03bf\u03bd\u03b9\u03ba\u03ac \u03c0\u03b5\u03c1\u03b9\u03bf\u03b4\u03b9\u03ba\u03ac ( \u0391\u03bd\u03bf\u03b9\u03ba\u03c4\u03ac) \n\u0395\u03bb\u03bb\u03b7\u03bd\u03b9\u03ba\u03ac English Please use this identifier to cite or link to this item: https://olympias.lib.uoi.gr/jspui/handle/123456789/10963 \nInstitution and School/Department of submitter: \u03a0\u03b1\u03bd\u03b5\u03c0\u03b9\u03c3\u03c4\u03ae\u03bc\u03b9\u03bf \u0399\u03c9\u03b1\u03bd\u03bd\u03af\u03bd\u03c9\u03bd. \u03a3\u03c7\u03bf\u03bb\u03ae \u0398\u03b5\u03c4\u03b9\u03ba\u03ce\u03bd \n\u0395\u03c0\u03b9\u03c3\u03c4\u03b7\u03bc\u03ce\u03bd. \u03a4\u03bc\u03ae\u03bc\u03b1 \u039c\u03b7\u03c7\u03b1\u03bd\u03b9\u03ba\u03ce\u03bd \u0397\u03bb\u03b5\u03ba\u03c4\u03c1\u03bf\u03bd\u03b9\u03ba\u03ce\u03bd \u03a5\u03c0\u03bf\u03bb\u03bf\u03b3\u03b9\u03c3\u03c4\u03ce\u03bd \u03ba\u03b1\u03b9 \u03a0\u03bb\u03b7\u03c1\u03bf\u03c6\u03bf\u03c1\u03b9\u03ba\u03ae\u03c2 URI: https://olympias.lib.uoi.gr/jspui/handle/123456789/10963 \nPublisher: Emerald Group in \u2026",
            "Abstract entirety": 0,
            "Author pub id": "B_Zd1P8AAAAJ:-_dYPAW6P2MC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Modeling and language support for the management of pattern-bases",
            "Publication year": 2007,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S0169023X0600187X",
            "Abstract": "Information overloading is today a serious concern that may hinder the potential of modern web-based information systems. A promising approach to deal with this problem is represented by knowledge extraction methods able to produce artifacts (also called patterns) that concisely represent data. Patterns are usually quite heterogeneous and voluminous. So far, little emphasis has been posed on developing an overall integrated environment for uniformly representing and querying different types of patterns. In this paper we consider the larger problem of modeling, storing, and querying patterns, in a database-like setting and use a Pattern-Base Management System (PBMS) for this purpose. Specifically, (a) we formally define the logical foundations for the global setting of pattern management through a model that covers data, patterns, and their intermediate mappings; (b) we present a formalism for pattern \u2026",
            "Abstract entirety": 0,
            "Author pub id": "B_Zd1P8AAAAJ:_kc_bZDykSQC",
            "Publisher": "North-Holland"
        },
        {
            "Title": "Conceptual modeling for ETL processes",
            "Publication year": 2002,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/583890.583893",
            "Abstract": "Extraction-Transformation-Loading (ETL) tools are pieces of software responsible for the extraction of data from several sources, their cleansing, customization and insertion into a data warehouse. In this paper, we focus on the problem of the definition of ETL activities and provide formal foundations for their conceptual representation. The proposed conceptual model is (a) customized for the tracing of inter-attribute relationships and the respective ETL activities in the early stages of a data warehouse project;(b) enriched with a'palette'of a set of frequently used ETL activities, like the assignment of surrogate keys, the check for null values, etc; and (c) constructed in a customizable and extensible manner, so that the designer can enrich it with his own re-occurring patterns for ETL activities.",
            "Abstract entirety": 1,
            "Author pub id": "B_Zd1P8AAAAJ:d1gkVwhDpl0C",
            "Publisher": "Unknown"
        },
        {
            "Title": "HECATAEUS: Regulating schema evolution",
            "Publication year": 2010,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/5447778/",
            "Abstract": "HECATAEUS is an open-source software tool for enabling impact prediction, what-if analysis, and regulation of relational database schema evolution. We follow a graph theoretic approach and represent database schemas and database constructs, like queries and views, as graphs. Our tool enables the user to create hypothetical evolution events and examine their impact over the overall graph before these are actually enforced on it. It also allows definition of rules for regulating the impact of evolution via (a) default values for all the nodes of the graph and (b) simple annotations for nodes deviating from the default behavior. Finally, HECATAEUS includes a metric suite for evaluating the impact of evolution events and detecting crucial and vulnerable parts of the system.",
            "Abstract entirety": 1,
            "Author pub id": "B_Zd1P8AAAAJ:TFP_iSt0sucC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Design metrics for data warehouse evolution",
            "Publication year": 2008,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-540-87877-3_32",
            "Abstract": "During data warehouse design, the designer frequently encounters the problem of choosing among different alternatives for the same design construct. The behavior of the chosen design in the presence of evolution events is an important parameter for this choice. This paper proposes metrics to assess the quality of the warehouse design from the viewpoint of evolution. We employ a graph-based model to uniformly abstract relations and software modules, like queries, views, reports, and ETL activities. We annotate the warehouse graph with policies for the management of evolution events. The proposed metrics are based on graph-theoretic properties of the warehouse graph to assess the sensi tivity of the graph to a set of possible events. We evaluate our metrics with experiments over alternative configurations of the same warehouse schema.",
            "Abstract entirety": 1,
            "Author pub id": "B_Zd1P8AAAAJ:RHpTSmoSYBkC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "Towards quality-oriented data warehouse usage and evolution",
            "Publication year": 2000,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S0306437900000119",
            "Abstract": "As a decision support information system, a data warehouse must provide high level quality of data and services. In the DWQ project (Foundations of Data Warehouse Quality), we have proposed how semantically rich meta-information of a data warehouse can be stored in a metadata repository. This static representation of the various perspectives of data warehouse components and their linkage to quality factors is complemented by an operational methodology on how to use these quality factors and achieve the quality goals of the users. This approach is an extension of the Goal-Question-Metric (GQM) approach, based on the idea that a quality goal is operationally defined over a concrete set of questions, i.e., algorithmic steps. The proposed approach covers the full lifecycle of the data warehouse, allows capturing the interrelationships between different quality factors and helps the interested user to organize \u2026",
            "Abstract entirety": 0,
            "Author pub id": "B_Zd1P8AAAAJ:Y0pCki6q_DkC",
            "Publisher": "Pergamon"
        },
        {
            "Title": "A manifesto for pattern bases",
            "Publication year": 2003,
            "Publication url": "https://www.researchgate.net/profile/Stefano-Rizzi-2/publication/237807375_A_Manifesto_for_Pattern_Bases/links/543bb2b90cf2d6698be31404/A-Manifesto-for-Pattern-Bases.pdf",
            "Abstract": "A major challenge for the database discipline in the 21st century is the efficient manipulation of huge volumes of data along with the extraction and management of useful knowledge from these data sets. Nowadays, sophisticated data processing tools, based on data mining, pattern recognition and other knowledge extraction techniques, produce knowledge artifacts that represent large parts of underlying data sets in a concise and meaningful way (eg, association rules, frequent parts of signals, etc.). In this paper, we will refer to these knowledge artifacts as patterns. We envision pattern repositories, which we call Pattern Base Management Systems (PBMSs), for treating patterns as persistent objects that deserve effective and efficient storing, processing, and querying. Architectural considerations along with functionality requirements for a PBMS are also presented.",
            "Abstract entirety": 1,
            "Author pub id": "B_Zd1P8AAAAJ:hFOr9nPyWt4C",
            "Publisher": "PANDA Technical Report TR-2003-03"
        },
        {
            "Title": "Extraction, Transformation, and Loading.",
            "Publication year": 2009,
            "Publication url": "http://www.cs.uoi.gr/~pvassil/downloads/ETL/SHORT_DESCR/08SpringerEncyclopedia_draft.pdf",
            "Abstract": "DEFINITION Extraction, Transformation, and Loading (ETL) processes are responsible for the operations taking place in the back stage of a data warehouse architecture. In a high level description of an ETL process, first, the data are extracted from the source datastores, which can be in a relational and/or a semi-structured format. In typical cases, the source datastores can be On-Line Transactional Processing (OLTP) or legacy systems, files under any format, web pages, various kinds of documents (eg, spreadsheets and text documents) or even data coming in a streaming fashion. Typically, only the data that are different from the previous execution of an ETL process (newly inserted, updated, and deleted information) should be extracted from the sources. After this phase, the extracted data are propagated to a special-purpose area of the warehouse, called Data Staging Area (DSA), where their transformation, homogenization, and cleansing take place. The most frequently used transformations include filters and checks to ensure that the data propagated to the warehouse respect business rules and integrity constraints, as well as schema transformations that ensure that data fit the target data warehouse schema. Finally, the data are loaded to the central data warehouse (DW) and all its counterparts (eg, data marts and views). In a traditional data warehouse setting, the ETL process periodically refreshes the data warehouse during idle or low-load, periods of its operation (eg, every night) and has a specific time-window to complete. Nowadays, business necessities and demands require near real-time data warehouse refreshment and significant \u2026",
            "Abstract entirety": 0,
            "Author pub id": "B_Zd1P8AAAAJ:4JMBOYKVnBMC",
            "Publisher": "Unknown"
        },
        {
            "Title": "KNOWLEDGE AND DATA ENGINEERING",
            "Publication year": 2005,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/1501814/",
            "Abstract": "[Front cover] Page 1 IEEE TRANSA CTIONS ON KNO WLEDGE AND D A T A \nENGINEERING V ol. 17, No. 10, October 2005 IEEE TRANSACTIONS ON KNOWLEDGE \nAND DATA ENGINEERING A publication of the IEEE Computer Society VOLUME 17 \nNUMBER 10 ITKEEH (ISSN 1041-4347) REGULAR PAPERS Data Mining On Combining \nClassifer Mass Functions for Text Categorization DA Bell, JW Guan, and Y. Bi .......................................................................................................................................... \nContinuous Similarity-Based Queries on Streaming Time Series L. Gao and XS Wang ...................................................................................................................................................... \nUsing One-Class and Two-Class SVMs for Multiclass Image Annotation K.-S. Goh, EY \nChang, and B. Li ...................................................................................................................................... \nFast Algorithms for Frequent Itemset Mining Using FP-Trees G. Grahne and J. ...\u2026",
            "Abstract entirety": 0,
            "Author pub id": "B_Zd1P8AAAAJ:pyW8ca7W8N0C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Data warehouse practice: An overview",
            "Publication year": 2000,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-662-04138-3_1",
            "Abstract": "Since the beginning of data warehousing in the early 1990s, an informal consensus has been reached concerning the major terms and components involved in data warehousing. In this chapter, we first explain the main terms and components. Data warehouse vendors are pursuing different strategies in supporting this basic framework. We review a few of the major product families and show in the next chapter a brief survey of the basic problem areas data warehouse practice and research is faced with today. These issues are then treated in more depth in the remainder of this book.",
            "Abstract entirety": 1,
            "Author pub id": "B_Zd1P8AAAAJ:Ri6SYOTghG4C",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "CineCubes: Aiding data workers gain insights from OLAP queries",
            "Publication year": 2015,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S0306437914001938",
            "Abstract": "In this paper we demonstrate that it is possible to enrich query answering with a short data movie that gives insights to the original results of an OLAP query. Our method, implemented in an actual system, CineCubes, includes the following steps. The user submits a query over an underlying star schema. Taking this query as input, the system comes up with a set of queries complementing the information content of the original query, and executes them. For each of the query results, we execute a set of highlight extraction algorithms that identify interesting patterns and values in the data of the results. Then, the system visualizes the query results and accompanies this presentation with a text commenting on the result highlights. Moreover, via a text-to-speech conversion the system automatically produces audio for the constructed text. Each combination of visualization, text and audio practically constitutes a movie \u2026",
            "Abstract entirety": 0,
            "Author pub id": "B_Zd1P8AAAAJ:WqliGbK-hY8C",
            "Publisher": "Pergamon"
        },
        {
            "Title": "Recommending Trips in the Archipelago of Refactorings",
            "Publication year": 2020,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-030-38919-2_38",
            "Abstract": "The essence of refactoring is to improve source code quality, in a principled, behavior preserving, one step at the time, process. To this end, the developer has to figure out the refactoring steps, while working on a specific source code fragment. To facilitate this task, the documentation that explains each primitive refactoring typically provides guidelines and tips on how to combine it with further refactorings. However, the developer has to cope with many refactorings and lots of guidelines.To deal with this problem, we propose a graph-based model that formally specifies refactoring guidelines and tips in terms of nodes that correspond to refactorings and edges that denote part-of, instead-of and succession relations. We refer to this model as the Map of the Archipelago of Refactorings and we use it as the premise of the Refactoring Trip Advisor, a refactoring recommendation tool that facilitates the combination of \u2026",
            "Abstract entirety": 0,
            "Author pub id": "B_Zd1P8AAAAJ:q3CdL3IzO_QC",
            "Publisher": "Springer, Cham"
        },
        {
            "Title": "Fusion cubes: Towards self-service business intelligence",
            "Publication year": 2013,
            "Publication url": "https://www.igi-global.com/article/content/78287",
            "Abstract": "Self-service business intelligence is about enabling non-expert users to make well-informed decisions by enriching the decision process with situational data, ie, data that have a narrow focus on a specific business problem and, typically, a short lifespan for a small group of users. Often, these data are not owned and controlled by the decision maker; their search, extraction, integration, and storage for reuse or sharing should be accomplished by decision makers without any intervention by designers or programmers. The goal of this paper is to present the framework we envision to support self-service business intelligence and the related research challenges; the underlying core idea is the notion of fusion cubes, ie, multidimensional cubes that can be dynamically extended both in their schema and their instances, and in which situational data and metadata are associated with quality and provenance annotations.",
            "Abstract entirety": 1,
            "Author pub id": "B_Zd1P8AAAAJ:sSrBHYA8nusC",
            "Publisher": "IGI Global"
        },
        {
            "Title": "Report on the 5th international workshop on the design and management of data warehouses (DMDW'03)",
            "Publication year": 2003,
            "Publication url": "https://dl.acm.org/doi/pdf/10.1145/959060.959083",
            "Abstract": "This article reports on the 5th International Workshop on Design and Management of Data Warehouses (DMDW) held in conjunction with VLDB\u201903 in Berlin, Germany, on September 8th, 2003. A short summary on the papers and the discussions held during the workshop is given.Data Warehousing embraces technology and industrial practice to systematically integrate data from multiple distributed data sources and to use that data in annotated and aggregated form to support business decision-making and enterprise management. Although many database techniques have been revisited or newly developed in the context of data warehouses, such as view maintenance and OLAP, little attention has been paid to the design, management and high quality service of the management of a given enterprise. Little attention is also paid to aspects that are intrinsic to the functionality and usage of data warehouses, either in \u2026",
            "Abstract entirety": 0,
            "Author pub id": "B_Zd1P8AAAAJ:pqnbT2bcN3wC",
            "Publisher": "ACM"
        },
        {
            "Title": "Context-aware query processing in ad-hoc environments of peers",
            "Publication year": 2009,
            "Publication url": "https://www.igi-global.com/chapter/context-aware-query-processing-hoc/8008",
            "Abstract": "In this article, we deal with context-aware query processing in ad-hoc peer-to-peer networks. Each peer in such an environment has a database over which users execute queries. This database involves (a) relations which are locally stored and (b) virtual relations, all the tuples of which are collected from peers that are present in the network at the time when a query is posed. The objective of our work is to perform query processing in such an environment and, to this end, we start with a formal definition of the system model. Next, we formally define SQLP, an extension of SQL that covers the termination of queries, the failure of individual peers and the semantic characteristics of the peers of such a network. Moreover, we present a query execution algorithm as well as the formal definition of all the operators that take place in a query execution plan.",
            "Abstract entirety": 1,
            "Author pub id": "B_Zd1P8AAAAJ:J_g5lzvAfSwC",
            "Publisher": "IGI Global"
        },
        {
            "Title": "Context aware query processing in Ad-Hoc environments of peers",
            "Publication year": 2008,
            "Publication url": "https://olympias.lib.uoi.gr/jspui/bitstream/123456789/10996/1/Vassiliadis-2008-Context-Aware%20Query%20Processing%20in%20Ad-Hoc%20Environments%20of.pdf",
            "Abstract": "In this paper, we deal with context-aware query processing in ad-hoc peer-to-peer networks. Each peer in such an environment has a database over which users want to execute queries. This database involves (a) relations which are locally stored and (b) relations which are virtual or hybrid. In the case of virtual relations, all the tuples of the relation are collected from peers that are present in the network at the time when the query is posed. Hybrid relations involve both locally stored tuples and tuples collected from the network. The collaboration among peers is performed through web services. The integration of the external data, before they are locally collected to a peer's database is performed through a workflow of web service invocations. Summarizing the problem, due to the transitive nature of the extent of virtual relations, we cannot perform query processing in the traditional way, but rather, we have to involve contextaware query processing techniques that exploit the neighborhood of each peer and the web service infrastructure that deals with the heterogeneity of peers. To deal with the aforementioned problem we provide the following contributions. First, we formally define the system model. Next, we define SQLP, an extension of traditional SQL on the basis of contextual environment requirements that concern the termination of queries, the failure of individual peers and the semantic characteristics of the peers of the network. In addition, we precisely define the semantics of SQLP. We discuss issues of data integration, performed through workflows of web services. Moreover, we present a query execution algorithm as well as the formal \u2026",
            "Abstract entirety": 0,
            "Author pub id": "B_Zd1P8AAAAJ:2KloaMYe4IUC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Schema evolution and gravitation to rigidity: a tale of calmness in the lives of structured data",
            "Publication year": 2017,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-319-66854-3_2",
            "Abstract": "Evolving dependency magnets, i.e., software modules upon which a large number of other modules depend, is always a hard task. As Robert C. Martin has nicely summarized it (see                      http://www.oodesign.com/design-principles.html                                        ), fundamental problems of bad design that hinder evolution include immobility, i.e., difficulty in reuse, rigidity, i.e., the tendency for software to be difficult to change and fragility, i.e., the tendency of the software to break in many places every time it is changed. In such cases, developers are reluctant to evolve the software to avoid facing the impact of change. How are these fundamentals related to schema evolution? We know that changes in the schema of a database affect a large (and not necessarily traced) number of surrounding applications, without explicit identification of the impact. These affected applications can then suffer from syntactic \u2026",
            "Abstract entirety": 0,
            "Author pub id": "B_Zd1P8AAAAJ:BUYA1_V_uYcC",
            "Publisher": "Springer, Cham"
        },
        {
            "Title": "Metrics for the prediction of evolution impact in etl ecosystems: A case study",
            "Publication year": 2012,
            "Publication url": "https://link.springer.com/content/pdf/10.1007/s13740-012-0006-9.pdf",
            "Abstract": "The Extract-Transform-Load (ETL) flows are essential for the success of a data warehouse and the business intelligence and decision support mechanisms that are attached to it. During both the ETL design phase and the entire ETL lifecycle, the ETL architect needs to design and improve an ETL design in a way that satisfies both performance and correctness guarantees and often, she has to choose among various alternative designs. In this paper, we focus on ways to predict the maintenance effort of ETL workflows and we explore techniques for assessing the quality of ETL designs under the prism of evolution. We focus on a set of graph-theoretic metrics for the prediction of evolution impact and we investigate their fit into real-world ETL scenarios. We present our experimental findings and describe the lessons we learned working on real-world cases.",
            "Abstract entirety": 1,
            "Author pub id": "B_Zd1P8AAAAJ:4fKUyHm3Qg0C",
            "Publisher": "Springer-Verlag"
        },
        {
            "Title": "Data warehouse refreshment",
            "Publication year": 2007,
            "Publication url": "https://www.igi-global.com/chapter/data-warehouses-olap/7618",
            "Abstract": "In the early stages of a data warehouse project, the designers/administrators have to come up with a decision concerning the design and deployment of the back-stage architecture. The possible options are (a) the usage of a commercial ETL tool, or (b) the development of an in-house ETL prototype. Both cases have advantages and disadvantages. However, in both cases the design and modeling of the ETL workflows have the same characteristics. The scope of this chapter is to indicate the main challenges, issues, and problems concerning the manufacturing of ETL workflows, in order to assist the designers/administrators to decide which solution suits better to their data warehouse project and to help them construct an efficient, robust and evolvable ETL workflow that implements the refreshment of their warehouse.",
            "Abstract entirety": 1,
            "Author pub id": "B_Zd1P8AAAAJ:j3f4tGmQtD8C",
            "Publisher": "IGI Global"
        },
        {
            "Title": "Report on the International Workshop on Pattern Representation and Management (PaRMa'04)",
            "Publication year": 2005,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/1083784.1083799",
            "Abstract": "The increasing ability to quickly collect and cheaply store large volumes of data, and the need for extracting concise information to be efficiently manipulated and intuitively analyzed, are posing new requirements for Database Management Systems (DBMS) in both industrial and scientific applications. A common approach to deal with huge data volumes is to reduce the available information to knowledge artifacts (i.e., clusters, rules, etc.), hereafter called patterns, through data processing methods (pattern recognition, data mining, knowledge extraction). Patterns reduce the number and size of the original information to manageable size while preserving as much as possible its hidden / interesting content. In order to efficiently and effectively deal with patterns, academic groups and industrial consortiums have recently devoted efforts towards modeling, storage, retrieval, analysis and manipulation of patterns with \u2026",
            "Abstract entirety": 0,
            "Author pub id": "B_Zd1P8AAAAJ:ZHo1McVdvXMC",
            "Publisher": "ACM"
        },
        {
            "Title": "A taxonomy of ETL activities",
            "Publication year": 2009,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/1651291.1651297",
            "Abstract": "Extract-Transform-Load (ETL) activities are software modules responsible for populating a data warehouse with operational data, which have undergone a series of transformations on their way to the warehouse. The whole process is very complex and of signifi-cant importance for the design and maintenance of the data ware-house. A plethora of commercial ETL tools are already available in the market. However, each one of them follows a different ap-proach for the modeling of ETL activities; ie, of the building blocks of an ETL workflow. As a result, so far there is no standard or unified approach for describing such activities. In this paper, we are working towards the identification of generic properties that characterize ETL activities. In doing so, we follow a black-box approach and provide a taxonomy that characterizes ETL activities in terms of the relationship of their input to their output and provide a normal form \u2026",
            "Abstract entirety": 0,
            "Author pub id": "B_Zd1P8AAAAJ:dhFuZR0502QC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Data warehouse modeling and quality issues",
            "Publication year": 2000,
            "Publication url": "http://www.cs.uoi.gr/~pvassil/publications/PhD/pv_eng_phd.pdf",
            "Abstract": "Data warehouses can be defined as \u2018subject-oriented\u2019, integrated, time-varying, non-volatile collections of data that is used primarily in organizational decision making. Nowadays, data warehousing became an important strategy to integrate heterogeneous information sources in organizations, and to enable On-Line Analytic Processing (OLAP). Unfortunately, neither the accumulation, nor the storage process, seem to be completely credible. For example, it has been suggested in the literature that more than $2 billion of US federal loan money have been lost because of poor data quality at a single agency, that manufacturing companies spent over 25% of their sales on wasteful practices, a number which came up to 40% for service companies.The question that arises, then, is how to organize the design, administration and evolution choices in such a way that all the different, and sometimes opposing, quality user requirements can be simultaneously satisfied. To tackle this problem, this thesis contributes as follows: The first major result that we present is a general framework for the treatment of data warehouse metadata in a metadata repository. The framework requires the classification of metadata in at least two instantiation layers and three perspectives. The metamodel layer constitutes the schema of the metadata repository and the metadata layer the actual meta-information for a particular data warehouse. The perspectives are the well known conceptual, logical and physical perspectives from the field of database and information systems. We link this framework to a well-defined approach for the architecture of the data warehouse from the \u2026",
            "Abstract entirety": 0,
            "Author pub id": "B_Zd1P8AAAAJ:YsMSGLbcyi4C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Report on the 9th International Workshop on Data Warehousing and OLAP (DOLAP 2006)",
            "Publication year": 2007,
            "Publication url": "https://scholar.google.com/scholar?cluster=15346318870742701049&hl=en&oi=scholarr",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "B_Zd1P8AAAAJ:K3LRdlH-MEoC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Pattern management challenges",
            "Publication year": 2004,
            "Publication url": "http://kops.uni-konstanz.de/bitstream/handle/123456789/5480/panel.pdf?sequence=1",
            "Abstract": "The increasing opportunity of quickly collecting and cheaply storing large volumes of data, and the need for extracting concise information to be efficiently manipulated and intuitively analyzed, are posing new requirements for data management systems in both industrial and scientific applications. A usual approach to deal with such huge volume of data is to reduce the available data to knowledge artifacts (ie, clusters, rules, etc.), also called patterns, through data processing methods (pattern recognition, data mining, knowledge extraction) that reduce their number and size to make them manageable from humans while preserving as much as possible their hidden/interesting information. In order to efficiently and effectively deal with patterns, academic groups and industrial consortiums have devoted efforts towards the modeling, storage, retrieval, analysis and manipulation of patterns with results mainly in the area of standards, inductive databases and pattern-base management systems. Notably, two main lines of research have been pursued, by different research groups. The first line of research, focused around the notion of the Pattern-Base Management System (PBMS), has been pursued by the members of the European PANDA project [1]. In the PANDA approach, patterns are concise and rich in semantics representations of data. Patterns are differentiated from data: the former lie in the PBMS, where customized operations (eg, similarity checks) are to be applied, whereas the latter reside in traditional data stores. PANDA has come up with a generic model and languages for patterns [2, 3] as well as results for internal data representation in \u2026",
            "Abstract entirety": 0,
            "Author pub id": "B_Zd1P8AAAAJ:08ZZubdj9fEC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Maintenance of top-k materialized views",
            "Publication year": 2010,
            "Publication url": "https://link.springer.com/article/10.1007/s10619-009-7057-4",
            "Abstract": "In this paper we present results on the problem of maintaining materialized top-k views and provide results in two directions. The first problem we tackle concerns the maintenance of top-k views in the presence of high deletion rates. We provide a principled method that complements the inefficiency of the state of the art independently of the statistical properties of the data and the characteristics of the update streams. The second problem we have been concerned with has to do with the efficient maintenance of multiple top-k views in the presence of updates to their base relation. To this end, we provide theoretical guarantees for the nucleation (practically, inclusion) of a view with respect to another view and the reflection of this property to the management of updates. We also provide algorithmic results towards the maintenance of a large number of views, via their appropriate structuring in hierarchies of views.",
            "Abstract entirety": 1,
            "Author pub id": "B_Zd1P8AAAAJ:O3NaXMp0MMsC",
            "Publisher": "Springer US"
        },
        {
            "Title": "Query processing and optimization",
            "Publication year": 2003,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-662-05153-5_6",
            "Abstract": "The ultimate purpose of a data warehouse is to support queries by end users who want to analyze the available information for an organization. However, from a more abstract point of view, queries are not only processed at the data warehouse back end.",
            "Abstract entirety": 1,
            "Author pub id": "B_Zd1P8AAAAJ:1qzjygNMrQYC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "Modeling ETL activities as graphs.",
            "Publication year": 2002,
            "Publication url": "https://cs.uoi.gr/~pvassil/publications/2002_DMDW/VaSS02_graphs_long.pdf",
            "Abstract": "Extraction-Transformation-Loading (ETL) tools are pieces of software responsible for the extraction of data from several sources, their cleansing, customization and insertion into a data warehouse. In this paper, we focus on the logical design of the ETL scenario of a data warehouse. We define a formal logical model for ETL processes. The data stores, activities and their constituent parts are formally introduced. An ETL scenario is defined as the combination of ETL activities and data stores. Then, we show how this model is reduced to a graph, which we call the Architecture Graph. We model all the aforementioned entities as nodes and four different kinds of relationships (instance-of, part-of, regulator and provider relationships) as edges. Also, we provide simple graph transformations that reduce the complexity of the graph. Finally, in order to support the engineering of the design and the evolution of the warehouse, we introduce specific importance metrics, namely dependence and responsibility, to measure the degree to which entities are bound to each other.",
            "Abstract entirety": 1,
            "Author pub id": "B_Zd1P8AAAAJ:hqOjcs7Dif8C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Data Warehouse Research: Issues and Projects",
            "Publication year": 2000,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-662-04138-3_2",
            "Abstract": "In the previous chapter, we have given a broad-brush state of the practice in data warehousing. In this chapter, we look at more or less the same issues again, focusing, however, on problems rather than solutions. Each of the topics we address is covered in the following chapters. In Section 2.6, we briefly review some larger research projects which address more than one of the issues and will therefore be cited in several places throughout the book. Finally, Section 2.7 takes a critical overall look at this work and introduces the DWQ conceptual framework which takes the business perspective of data warehousing into account as well as the so far dominant technical aspects.",
            "Abstract entirety": 1,
            "Author pub id": "B_Zd1P8AAAAJ:q3oQSFYPqjQC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "Impact analysis and policy-conforming rewriting of evolving data-intensive ecosystems",
            "Publication year": 2015,
            "Publication url": "https://link.springer.com/article/10.1007/s13740-015-0050-3",
            "Abstract": "Data-intensive ecosystems are conglomerations of data repositories surrounded by applications that depend on them for their operation. In this paper, we address the problem of performing what-if analysis for the evolution of the database part of a data-intensive ecosystem, to identify what other parts of an ecosystem are affected by a potential change in the database schema, and how will the ecosystem look like once the change has been performed, while, at the same time, retaining the ability to regulate the flow of events. We model the ecosystem as a graph, uniformly covering relations, views, and queries as nodes and their internal structure and interdependencies as the edges of the graph. We provide a simple language to annotate the modules of the graph with policies for their response to evolutionary events to regulate the flow of events and their impact by (i) vetoing (\u201cblocking\u201d) the change in parts \u2026",
            "Abstract entirety": 0,
            "Author pub id": "B_Zd1P8AAAAJ:UHK10RUVsp4C",
            "Publisher": "Springer Berlin Heidelberg"
        },
        {
            "Title": "Optimizing ETL processes in data warehouses",
            "Publication year": 2005,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/1410172/",
            "Abstract": "Extraction-transformation-loading (ETL) tools are pieces of software responsible for the extraction of data from several sources, their cleansing, customization and insertion into a data warehouse. Usually, these processes must be completed in a certain time window; thus, it is necessary to optimize their execution time. In this paper, we delve into the logical optimization of ETL processes, modeling it as a state-space search problem. We consider each ETL workflow as a state and fabricate the state space through a set of correct state transitions. Moreover, we provide algorithms towards the minimization of the execution cost of an ETL workflow.",
            "Abstract entirety": 1,
            "Author pub id": "B_Zd1P8AAAAJ:qjMakFHDy7sC",
            "Publisher": "Ieee"
        },
        {
            "Title": "On Supporting Context-Aware Preferences in Relational Database Systems.",
            "Publication year": 2005,
            "Publication url": "http://cs.uoi.gr/~pvassil/publications/2005_MCMP/MCMP_2005.pdf",
            "Abstract": "A context-aware system is a system that uses context to provide relevant information or services to its users. While there has been a variety of context middleware infrastructures and context-aware applications, little work has been done in integrating context into database management systems. In this paper, we consider a preference system that facilitates context-aware OLAP queries, that is OLAP queries whose result depends on the context at the time of their submission. We propose using data cubes to store the dependencies between context and database relations and OLAP techniques for the manipulation of context-aware queries.",
            "Abstract entirety": 1,
            "Author pub id": "B_Zd1P8AAAAJ:7PzlFSSx8tAC",
            "Publisher": "Unknown"
        },
        {
            "Title": "CHOReOS dynamic development model definition (D2. 1)",
            "Publication year": 2011,
            "Publication url": "https://hal.inria.fr/hal-00664236/",
            "Abstract": "The Future Internet envisions a ubiquitous world where available services can be easily discovered and coordinated so as to fit users needs. Service choreographies will play a central role in this vision as an effective means to allow heterogeneous services to suitably collaborate. This deliverable defines the CHOReOS Dynamic Development Process Model by refining and completing the artefacts/ activities and the relationships among them already sketched into the DoW (under the WP2 description), and conceptualized by the the CHOReOS conceptual model [CHO11b]. The process model is an abstract and simplified description of what will be the actual CHOReOS software development process to be defined at M24. The process model describes the \"strategy\" to be used during the choreography life cycle from design, to development, to maintenance (and hence from static, to runtime, to evolution). The model is made up of activities, common to (almost) every process, but structured in a particular way (i.e., the \"CHOReOS way\"), hence distinguishing the CHOReOS development process from others.",
            "Abstract entirety": 1,
            "Author pub id": "B_Zd1P8AAAAJ:EUQCXRtRnyEC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Macro-level Scheduling of ETL Workflows",
            "Publication year": 2009,
            "Publication url": "http://cs.uoi.gr/~pvassil/publications/2011_QDB/QDB_2011.pdf",
            "Abstract": "Extract-Transform-Load (ETL) workflows (a) extract data from various sources,(b) transform, cleanse and homogenize these data, and (c) populate a target data store (eg, a data warehouse). Typically, such processes should terminate during strict time windows and thus, ETL workflow optimization is of significant interest. In this paper, we deal with the problem of scheduling the execution of ETL activities, with the goal of minimizing ETL execution time and allocated memory. Apart from a simple, fair scheduling policy we also experiment with two policies, the first aiming to empty the largest input queue of the workflow and the second to activate the activity with the maximum tuple consumption rate. We experimentally show that the use of different scheduling policies can improve ETL performance in terms of memory consumption and execution time.",
            "Abstract entirety": 1,
            "Author pub id": "B_Zd1P8AAAAJ:70eg2SAEIzsC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Service-oriented middleware for the future internet: state of the art and research directions",
            "Publication year": 2011,
            "Publication url": "https://link.springer.com/article/10.1007/s13174-011-0021-3",
            "Abstract": "Service-oriented computing is now acknowledged as a central paradigm for Internet computing, supported by tremendous research and technology development over the last 10 years. However, the evolution of the Internet, and in particular, the latest Future Internet vision, challenges the paradigm. Indeed, service-oriented computing has to face the ultra large scale and heterogeneity of the Future Internet, which are orders of magnitude higher than those of today\u2019s service-oriented systems. This article aims at contributing to this objective by identifying the key research directions to be followed in light of the latest state of the art. This article more specifically focuses on research challenges for service-oriented middleware design, therefore, investigating service description, discovery, access, and composition in the Future Internet of services.",
            "Abstract entirety": 1,
            "Author pub id": "B_Zd1P8AAAAJ:fQNAKQ3IYiAC",
            "Publisher": "SpringerOpen"
        },
        {
            "Title": "Relational schema optimization for RDF-based knowledge graphs",
            "Publication year": 2021,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S0306437921000223",
            "Abstract": "Characteristic sets (CS) organize RDF triples based on the set of properties associated with their subject nodes. This concept was recently used in indexing techniques, as it can capture the implicit schema of RDF data. While most CS-based approaches yield significant improvements in space and query performance, they fail to perform well when answering complex query workloads in the presence of schema heterogeneity, i.e., when the number of CSs becomes very large, resulting in a highly partitioned data organization. In this paper, we address this problem by introducing a novel technique, for merging CSs based on their hierarchical structure. Our method employs a lattice to capture the hierarchical relationships between CSs, identifies dense CSs and merges dense CSs with their ancestors. We have implemented our algorithm on top of a relational backbone, where each merged CS is stored in a relational \u2026",
            "Abstract entirety": 0,
            "Author pub id": "B_Zd1P8AAAAJ:bz8QjSJIRt4C",
            "Publisher": "Pergamon"
        },
        {
            "Title": "Modelling and analysing reliable service-oriented processes",
            "Publication year": 2008,
            "Publication url": "https://www.inderscienceonline.com/doi/abs/10.1504/IJBPIM.2008.023216",
            "Abstract": "This paper introduces principled methods for the reliability analysis of business processes that rely on web services. The input to the problem is the BPEL specification of a business process and the output is the prediction of the process's reliability. The first step to this end involves a method for the translation of the BPEL specification to its corresponding UML model. The second step of the reliability analysis involves a principled way for the annotation of the UML model with the necessary extensions for the specification of reliability properties that characterise the behaviour of the elements that constitute the process. The third step of the analysis comprises the systematic mapping of the extended UML model to block diagrams and Markov models which are subsequently used to compute the reliability of the process.",
            "Abstract entirety": 1,
            "Author pub id": "B_Zd1P8AAAAJ:WbkHhVStYXYC",
            "Publisher": "Inderscience Publishers"
        },
        {
            "Title": "An integration-oriented ontology to govern evolution in big data ecosystems",
            "Publication year": 2019,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S0306437917304660",
            "Abstract": "Big Data architectures allow to flexibly store and process heterogeneous data, from multiple sources, in their original format. The structure of those data, commonly supplied by means of REST APIs, is continuously evolving. Thus data analysts need to adapt their analytical processes after each API release. This gets more challenging when performing an integrated or historical analysis. To cope with such complexity, in this paper, we present the Big Data Integration ontology, the core construct to govern the data integration process under schema evolution by systematically annotating it with information regarding the schema of the sources. We present a query rewriting algorithm that, using the annotated ontology, converts queries posed over the ontology to queries over the sources. To cope with syntactic evolution in the sources, we present an algorithm that semi-automatically adapts the ontology upon new \u2026",
            "Abstract entirety": 0,
            "Author pub id": "B_Zd1P8AAAAJ:zLWjf1WUPmwC",
            "Publisher": "Pergamon"
        },
        {
            "Title": "Panel: Pattern management challenges",
            "Publication year": 2004,
            "Publication url": "http://ftp.informatik.rwth-aachen.de/Publications/CEUR-WS/Vol-96/10-panel.pdf",
            "Abstract": "The increasing opportunity of quickly collecting and cheaply storing large volumes of data, and the need for extracting concise information to be efficiently manipulated and intuitively analyzed, are posing new requirements for data management systems in both industrial and scientific applications. A usual approach to deal with such huge volume of data is to reduce the available data to knowledge artifacts (ie, clusters, rules, etc.), also called patterns, through data processing methods (pattern recognition, data mining, knowledge extraction) that reduce their number and size to make them manageable from humans while preserving as much as possible their hidden/interesting information. In order to efficiently and effectively deal with patterns, academic groups and industrial consortiums have devoted efforts towards the modeling, storage, retrieval, analysis and manipulation of patterns with results mainly in the area of standards, inductive databases and pattern-base management systems. Notably, two main lines of research have been pursued, by different research groups. The first line of research, focused around the notion of the Pattern-Base Management System (PBMS), has been pursued by the members of the European PANDA project [1]. In the PANDA approach, patterns are concise and rich in semantics representations of data. Patterns are differentiated from data: the former lie in the PBMS, where customized operations (eg, similarity checks) are to be applied, whereas the latter reside in traditional data stores. PANDA has come up with a generic model and languages for patterns [2, 3] as well as results for internal data representation in \u2026",
            "Abstract entirety": 0,
            "Author pub id": "B_Zd1P8AAAAJ:cFHS6HbyZ2cC",
            "Publisher": "Unknown"
        },
        {
            "Title": "A generic and customizable framework for the design of ETL scenarios",
            "Publication year": 2005,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S0306437904000985",
            "Abstract": "Extraction\u2013transformation\u2013loading (ETL) tools are pieces of software responsible for the extraction of data from several sources, their cleansing, customization and insertion into a data warehouse. In this paper, we delve into the logical design of ETL scenarios and provide a generic and customizable framework in order to support the DW designer in his task. First, we present a metamodel particularly customized for the definition of ETL activities. We follow a workflow-like approach, where the output of a certain activity can either be stored persistently or passed to a subsequent activity. Also, we employ a declarative database programming language, LDL, to define the semantics of each activity. The metamodel is generic enough to capture any possible ETL activity. Nevertheless, in the pursuit of higher reusability and flexibility, we specialize the set of our generic metamodel constructs with a palette of frequently used \u2026",
            "Abstract entirety": 0,
            "Author pub id": "B_Zd1P8AAAAJ:IjCSPb-OGe4C",
            "Publisher": "Pergamon"
        },
        {
            "Title": "Hecataeus: A Framework for Representing SQL Constructs as Graphs",
            "Publication year": 2005,
            "Publication url": "ftp://ceur-ws.org/pub/publications/CEUR-WS/Vol-363.zip",
            "Abstract": "Traditional modeling techniques typically focus on the static part of databases and ignore their dynamic part (eg, queries or data-centric workflows). In this paper, we first introduce and sketch a graph-based model that captures relations, views, constraints and queries. We then present HECATAEUS, a tool for implementing and visualizing the above framework.",
            "Abstract entirety": 1,
            "Author pub id": "B_Zd1P8AAAAJ:R3hNpaxXUhUC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Erratum to: Service-oriented middleware for the Future Internet: state of the art and research directions",
            "Publication year": 2011,
            "Publication url": "https://jisajournal.springeropen.com/track/pdf/10.1007/s13174-011-0029-8.pdf",
            "Abstract": "By using this website, you agree to our Terms and Conditions, California Privacy Statement, Privacy statement and Cookies policy. Manage cookies/Do not sell my data we use in the preference centre.",
            "Abstract entirety": 1,
            "Author pub id": "B_Zd1P8AAAAJ:PELIpwtuRlgC",
            "Publisher": "SpringerOpen"
        },
        {
            "Title": "Managing contextual preferences",
            "Publication year": 2011,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S0306437911000834",
            "Abstract": "To handle the overwhelming amount of information currently available, personalization systems allow users to specify through preferences which pieces of data interest them. Most often, users have different preferences depending on context. In this paper, we introduce a model for expressing such contextual preferences. Context is modeled using a set of hierarchical attributes, thus allowing context specification at various levels of detail. We formulate the context resolution problem as the problem of selecting appropriate preferences based on context for personalizing a query. We also propose algorithms for context resolution based on data structures that index preferences by exploiting the hierarchical nature of the context attributes. Finally, we evaluate our approach from two perspectives: usability and performance. Usability evaluates the overheads imposed on users for specifying context-dependent preferences \u2026",
            "Abstract entirety": 0,
            "Author pub id": "B_Zd1P8AAAAJ:bFI3QPDXJZMC",
            "Publisher": "Pergamon"
        }
    ]
}]