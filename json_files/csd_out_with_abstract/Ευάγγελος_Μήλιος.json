[{
    "name": "\u0395\u03c5\u03ac\u03b3\u03b3\u03b5\u03bb\u03bf\u03c2 \u039c\u03ae\u03bb\u03b9\u03bf\u03c2",
    "romanize name": "Evangelos Milios",
    "School-Department": " Computer Science",
    "University": "Dalhousie University",
    "Rank": "\u039a\u03b1\u03b8\u03b7\u03b3\u03b7\u03c4\u03ae\u03c2",
    "Apella_id": 2289,
    "Scholar name": "Evangelos Milios",
    "Scholar id": "ME8aQywAAAAJ",
    "Affiliation": "Professor of Computer Science, Dalhousie University",
    "Citedby": 13735,
    "Interests": [
        "Text mining",
        "social network analysis",
        "text visualization",
        "visual analytics"
    ],
    "Scholar url": "https://scholar.google.com/citations?user=ME8aQywAAAAJ&hl=en",
    "Publications": [
        {
            "Title": "How Document Properties Affect Document Relatedness Measures",
            "Publication year": 2014,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-642-54903-8_33",
            "Abstract": "We address the question of how document properties (word count, term frequency, cohesiveness, genre) affect the quality of unsupervised document relatedness measures (Google trigram model and vector space model). We use three genres of documents: aviation safety reports, medical equipment failure descriptions, and biodiversity heritage library text. Quality of document relatedness is assessed by the accuracy of a classification task using the kNN method. Experiments discover correlations between document property values and document relatedness quality, and we discuss how one approach may perform better depending on property values of the dataset.",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:NyGDZy8z5eUC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "Fast entropy based alert detection in super computer logs",
            "Publication year": 2010,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/5542621/",
            "Abstract": "The task of alert detection in event logs is very important in preventing or recovering from downtime events. The ability to do this automatically and accurately provides significant savings in the time and cost of downtime events. The Nodeinfo algorithm, which is currently in production use at Sandia National Laboratories, is an entropy based algorithm for alert detection in event logs. Automatic alert detection needs to be fast for it to be practical in a production environment. In this work we show that with Message Type Indexing (MTI) the computational effort required for alert detection can be reduced by up to 99%. This can be achieved without a drop in detection performance. Our proposed method has special significance because it provides a framework for alert detection which requires little or no human input, due to message type extraction required for MTI being carried out automatically using the Iterative \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ME8aQywAAAAJ:zA6iFVUQeVQC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Similarity-based support for text reuse in technical writing",
            "Publication year": 2015,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/2682571.2797068",
            "Abstract": "Technical writing in professional environments, such as user manual authoring for new products, is a task that relies heavily on reuse of content. Therefore, technical content is typically created following a strategy where modular units of text have references to each other. One of the main challenges faced by technical authors is to avoid duplicating existing content, as this adds unnecessary effort, generates undesirable inconsistencies, and dramatically increases maintenance and translation costs. However, there are few computational tools available to support this activity. This paper investigates the use of different similarity methods for the task of identification of reuse opportunities in technical writing. We evaluated our results using existing ground truth as well as feedback from technical authors. Finally, we also propose a tool that combines text similarity algorithms with interactive visualizations to aid authors in \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ME8aQywAAAAJ:7wO8s98CvbsC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Active stereo sound localization",
            "Publication year": 2003,
            "Publication url": "https://asa.scitation.org/doi/abs/10.1121/1.1518469",
            "Abstract": "Estimating the direction of arrival of sound in three-dimensional space is typically performed by generalized time-delay processing on a set of signals from a fixed array of omnidirectional microphones. This requires specialized multichannel A/D hardware, and careful arrangement of the microphones into an array. This work is motivated by the desire to instead only use standard two-channel audio A/D hardware and portable equipment. To estimate direction of arrival of persistent sound, the position of the microphones is made variable by mounting them on one or more computer-controlled pan-and-tilt units. In this paper, we describe the signal processing and control algorithm of a device with two omnidirectional microphones on a fixed baseline and two rotational degrees of freedom. Experimental results with real data are reported with both impulsive and speech sounds in an untreated, normally reverberant indoor \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ME8aQywAAAAJ:hC7cP41nSMkC",
            "Publisher": "Acoustical Society of America"
        },
        {
            "Title": "Acoustical Modeling Using a Russian Roulette Strategy",
            "Publication year": 2005,
            "Publication url": "http://www.aes.org/e-lib/online/browse.cfm?elib=13213",
            "Abstract": "A problem with ray-based acoustical modeling approaches is handling the potentially large number of interactions between a sound ray and any objects/surfaces it encounters. Typical solutions to modeling these interactions include emitting several\" new\" rays at each interaction point. Such solutions are computationally expensive except for simple environments. Rather than using such deterministic strategies, probabilistic techniques such as Russian Roulette can be applied instead. Russian Roulette ensures the path length of each acoustic ray is kept at a manageable size yet allows for paths of arbitrary size to be explored. Here we describe the application of Russian Roulette to acoustic modeling. Experimental results demonstrate the ability of Russian Roulette to provide a computationally reasonable solution to room acoustical modeling.",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:1yQoGdGgb4wC",
            "Publisher": "Audio Engineering Society"
        },
        {
            "Title": "Deep analysis of word sense disambiguation via semi-supervised learning and neural word representations",
            "Publication year": 2021,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S0020025521003273",
            "Abstract": "Word Sense Disambiguation (WSD) aims to determine the meaning of a word in context. Different approaches have been proposed in supervised and unsupervised domains. In most cases, supervised learning provides superior WSD performance. Since sense-annotated corpora can be difficult or time-consuming to obtain, which must be repeated for new domains, languages, and sense inventories, semi-supervised learning (SSL) methods, that combine a small amount of sense-annotated data, start to be pre-eminent. In SSL, graph-based methods are common, because they capture the relationships between terms using an undirected graph. This paper aims to investigate semi-supervised WSD by considering different graph-based SSL algorithms with features generated by word embeddings from Word2Vec, FastText, GloVe, BERT and ELECTRA models combined with parts-of-speech tags and word context \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ME8aQywAAAAJ:-6RzNnnwWf8C",
            "Publisher": "Elsevier"
        },
        {
            "Title": "A statistical model for topic segmentation and clustering",
            "Publication year": 2008,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-540-68825-9_27",
            "Abstract": "This paper presents a statistical model for discovering topical clusters of words in unstructured text. The model uses a hierarchical Bayesian structure and it is also able to identify segments of text which are topically coherent. The model is able to assign each segment to a particular topic and thus categorizes the corresponding document to potentially multiple topics. We present some initial results indicating that the word topics discovered by the proposed model are more consistent compared to other models. Our early experiments show that our model clustering performance compares well with other clustering models on a real text corpus, which do not provide topic segmentation. Segmentation performance of our model is also comparable to a recently proposed segmentation model which does not provide document clustering.",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:uWQEDVKXjbEC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "Robot map verification of a graph world",
            "Publication year": 2001,
            "Publication url": "https://link.springer.com/article/10.1023/A:1011688823715",
            "Abstract": "In the map verification problem, a robot is given a (possibly incorrect) map M of the world G with its position and orientation indicated on the map. The task is to find out whether this map, for the given robot position and its orientation in the map, is correct for the world G. We consider the world model of a graph G = (V G, E G) in which, for each vertex, edges incident to the vertex are ordered cyclically around that vertex. (This also holds for the map M = (V M, E M.) The robot can traverse edges and enumerate edges incident on the current vertex, but it cannot distinguish vertices (and edges) from each other. To solve the verification problem, the robot uses a portable edge marker, that it can put down at an edge of the graph world G and pick up later as needed. The robot can recognize the edge marker when it encounters it in the world G. By reducing the verification problem to an exploration problem, verification \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ME8aQywAAAAJ:nb7KW1ujOQ8C",
            "Publisher": "Kluwer Academic Publishers"
        },
        {
            "Title": "EmERGING TRENDS",
            "Publication year": 2021,
            "Publication url": "https://www.cambridge.org/core/journals/natural-language-engineering/article/nle-volume-27-issue-3-cover-and-back-matter/DFC12B2E334B940A83F2F83EC5A7BD82",
            "Abstract": "//static.cambridge.org/content/id/urn%3Acambridge.org%3Aid%3Aarticle%3AS1351324921000073/resource/name/firstPage-S1351324921000073a.jpg",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:c1e4I3QdEKYC",
            "Publisher": "Unknown"
        },
        {
            "Title": "What is in a rumour: Combined visual analysis of rumour flow and user activity",
            "Publication year": 2016,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/2949035.2949040",
            "Abstract": "Due to the rapid propagation of rumours in Online Social Networks (OSNs), identifying and understanding characteristic patterns, evolution and user behaviours behind this activity is essential. Yet, there are few tools that can support analysing rumours and activities of players in their propagation. In this paper we propose a visual analysis approach to explore rumour components and life cycles as well as their association with user actions. The approach is realized by the implementation of a prototype system, called RumourFlow. Our framework designs, adopts and implements multiple visualizations and modeling tools that are integrated to reveal rumour contents and participants' activity, both within a rumour and across different rumours. The approach supports analysts in drawing hypotheses regarding rumour propagation. This paper presents the various models, algorithms and visualizations employed for \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ME8aQywAAAAJ:DBa1UEJaJKAC",
            "Publisher": "Unknown"
        },
        {
            "Title": "A systematic study of document representation and dimension reduction for text clustering",
            "Publication year": 2006,
            "Publication url": "https://cdn.dal.ca/content/dam/dalhousie/pdf/faculty/computerscience/technical-reports/CS-2006-05.pdf",
            "Abstract": "Increasingly large text datasets and the high dimensionality associated with natural language create a great challenge in text mining. In this research, a systematic study is conducted, in which three Dimension Reduction Techniques (DRT) are applied on three different document representation methods in the context of the text clustering problem. Several standard benchmark datasets are used. The dimension reduction methods considered include independent component analysis (ICA), latent semantic indexing (LSI), and a technique based on Document Frequency (DF). These three methods are applied on three Document representation methods based on the vector space model; word, multi-word term, and character N-gram representations. Results are compared in terms of clustering performance, using the k-means clustering algorithm. Experiments show that ICA and LSI are clearly better than DF on all datasets. For word and N-gram representation, ICA generally gives better results compared with LSI. Experiments also show that the word representation gives better clustering results compared to term and N-gram representation. Finally, for the N-gram representation, it is shown that a profile length of 2000 is enough to capture the information and in most cases, a 4-gram representation gives better performance than 3-gram representation.",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:D03iK_w7-QYC",
            "Publisher": "Unknown"
        },
        {
            "Title": "An evaluation of machine learning techniques for enterprise spam filters",
            "Publication year": 2004,
            "Publication url": "https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.147.2559&rep=rep1&type=pdf",
            "Abstract": "This thesis studies the viability of enterprise spam lters that use machine learning algorithms to recognize spam. It introduces a scalable architecture for such lters, and a novel experimental methodology for evaluating their e ectiveness. Using this methodology, it overcomes the privacy barrier to evaluate three popular spam classication algorithms on complete sets of real email. The goal is to determine if these kinds of lters can be both e ective and e cient enough for practical deployment in large networks.Spam, sometimes more formally known as\\Unsolicited Commercial Email\"(UCE) or\\Unsolicited Bulk Email\"(UBE), has grown from being a minor nuisance into a global menace. Millions of email users world-wide waste untold thousands of hours every day sorting through incoming mailboxes cluttered with unwanted or even offensive messages. Meanwhile, the growth in network resources consumed by spam continues at an unsustainable rate. The spiraling direct and indirect costs of spam threaten the reliability and utility of the email infrastructure that has become so vital to the global economy.",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:bFI3QPDXJZMC",
            "Publisher": "Technical Report CS-2004-03, Dalhousie University"
        },
        {
            "Title": "Aqua: An amphibious autonomous robot",
            "Publication year": 2007,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/4069194/",
            "Abstract": "AQUA, an amphibious robot that swims via the motion of its legs rather than using thrusters and control surfaces for propulsion, can walk along the shore, swim along the surface in open water, or walk on the bottom of the ocean. The vehicle uses a variety of sensors to estimate its position with respect to local visual features and provide a global frame of reference",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:QIV2ME_5wuYC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Supervised Learning Rule Learning",
            "Publication year": 2007,
            "Publication url": "https://scholar.google.com/scholar?cluster=14663166161885587754&hl=en&oi=scholarr",
            "Abstract": "Given collection S with p+, p\u2212 the fraction of positive, negative instances, entropy is H (S)=\u2212 p+ logp+\u2212 p\u2212 logp\u2212 After splitting S with an attribute test, we get two subcollections St, Sf consisting of the instances for which test is true t or false f.",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:k8Z6L05lTy4C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Integrating Global Attention for Pairwise Text Comparison",
            "Publication year": 2018,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/3209280.3229119",
            "Abstract": "Attention guides computation to focus on important parts of the input data. For pairwise input, existing attention approaches tend to bias towards trivial repetitions (eg punctuations and stop words) between two texts, and thus failed to contribute reasonable guidance to model predictions. As a remedy, we suggest taking into account the corpus-level information via global-aware attention. In this paper, we propose an attention mechanism that makes use of intratext, inter-text and global contextual information. We undertake an ablation study on paraphrase identification, and demonstrate that the proposed attention mechanism can obviate the downsides of trivial repetitions and provide interpretable word weightings.",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:69ZgNCALVd0C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Multilevel Soft Co-Clustering",
            "Publication year": 2006,
            "Publication url": "https://scholar.google.com/scholar?cluster=12441824652331091995&hl=en&oi=scholarr",
            "Abstract": "Co-clustering, the simultaneous clustering of both dimensions of a matrix, is a new research area in machine learning. Existing coclustering algorithms such as information theoretical co-clustering and binary cross-association co-clustering has been shown to be effective in many clustering applications. However two often used aspects of traditional clustering, hierarchical clustering and soft clustering, does not exist in the co-clustering world. Building upon the foundations of binary cross-association co-clustering, this work proposed a new multi-level soft co-clustering algorithm appropriately called multi-level soft co-clustering. In addition to being a multi-level soft co-clustering algorithm, the soft co-clustering and the multi-level co-clustering are independent of each other, thus can be used independently for greater flexibility. Finally, we propose a set of experiments to evaluate the performance of the multi-level soft co \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ME8aQywAAAAJ:g3aElNc5_aQC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Agglomerative genetic algorithm for clustering in social networks",
            "Publication year": 2009,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/1569901.1570068",
            "Abstract": "Size and complexity of data repositories collaboratively created by Web users generate a need for new processing approaches. In this paper, we study the problem of detection of fine-grained communities of users in social networks, which can be defined as clustering with a large number of clusters. The practical size of social networks makes the traditional evolutionary based clustering approaches, which represent the entire clustering solution as one individual, hard to apply. We propose an Agglomerative Clustering Genetic Algorithm (ACGA): a population of clusters evolves from the initial state in which each cluster represents one user to a high quality clustering solution. Each step of the evolutionary process is performed locally, engaging only a small part of the social network limited to two clusters and their direct neighborhood. This makes the algorithm practically useful independently of the size of the network \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ME8aQywAAAAJ:cFHS6HbyZ2cC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Author verification using common n-gram profiles of text documents",
            "Publication year": 2014,
            "Publication url": "https://www.aclweb.org/anthology/C14-1038.pdf",
            "Abstract": "Authorship verification is the problem of answering the question whether or not a sample text document was written by a specific person, given a few other documents known to be authored by them. We propose a proximity based method for one-class classification that applies the Common N-Gram (CNG) dissimilarity measure. The CNG dissimilarity (Ke\u0161elj et al., 2003) is based on the differences in the frequencies of n-grams of tokens (characters, words) that are most common in the considered documents. Our method utilizes the pairs of most dissimilar documents among documents of known authorship. We evaluate various variants of the method in the setting of a single classifier or an ensemble of classifiers, on a multilingual authorship verification corpus of the PAN 2013 Author Identification evaluation framework. Our method yields competitive results when compared to the results achieved by the participants of the PAN 2013 competition on the entire set, as well as separately on two subsets\u2014English and Spanish ones\u2014out of the three language subsets of the corpus.",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:buQ7SEKw-1sC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Acoustical modeling using a Russian roulette strategy",
            "Publication year": 2005,
            "Publication url": "https://web.cs.dal.ca/~eem/res/pubs/pubs/billk-aesBarcelona-2005.pdf",
            "Abstract": "One of the problems with geometric (ray) based acoustical modeling approaches is handling the potentially large number of interactions between a propagating sound ray and objects/surfaces it may encounter. A sound ray incident on a surface may be absorbed, reflected both specularly and diffusely, be refracted and diffracted. Typical solutions to modeling such effects include emitting several \u201cnew\u201d rays at each interaction point. Such solutions are computationally expensive for all but very simple environments. Rather than using such deterministic strategies and following these generated rays until they leave the environment or become sufficiently reduced in power that they no longer contribute to the acoustical landscape, probabilistic techniques such as the Russian Roulette strategy can be applied instead. Russian Roulette ensures the path length of each acoustic ray is kept at a manageable size yet allows for paths of arbitrary size to be explored. Here we describe the application of a Russian Roulette approach to acoustic modeling. Experimental results are presented that demonstrate the ability of Russian Roulette to provide a computationally reasonable solution to room acoustical modeling.",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:a0OBvERweLwC",
            "Publisher": "Unknown"
        },
        {
            "Title": "An evolutionary algorithm for feature selective double clustering of text documents",
            "Publication year": 2013,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/6557603/",
            "Abstract": "We propose FSDC, an evolutionary algorithm for Feature Selective Double Clustering of text documents. We first cluster the terms existing in the document corpus. The term clusters are then fed into multiobjective genetic algorithms to prune non-informative terms and form sets of keyterms representing topics. Based on the topic keyterms found, representative documents for each topic are extracted. These documents are then used as seeds to cluster all documents in the dataset. FSDC is compared to some well-known co-clusterers on real text datasets. The experimental results show that our algorithm can outperform the competitors.",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:5MTHONV0fEkC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Interactive feature selection for document clustering",
            "Publication year": 2011,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/1982185.1982436",
            "Abstract": "Traditional document clustering techniques group similar documents without any user interaction. Although such methods minimize user effort, the clusters they generate are often not in accord with their users' conception of the document collection. In this paper we describe a new framework and experiments with it exploring how clustering might be improved by including user supervision at the level of selecting features that are used to distinguish between documents. Our features are based on the words that appear in documents (see \u00a7 4.1 for details.) We conjecture that clusters better matching user expectations can be generated with user input at the feature level. In order to verify our conjecture, we propose a novel iterative framework which involves users interactively selecting the features used to cluster documents. Unlike existing semi-supervised clustering, which asks users to label constraints between \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ME8aQywAAAAJ:eJXPG6dFmWUC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Assessing Causality Structures learned from Digital Text Media",
            "Publication year": 2020,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/3395027.3419594",
            "Abstract": "In this paper we describe a framework to uncover potential causal relations between event mentions from streaming text of news media. This framework relies on a dataset of manually labeled events to train a recurrent neural network for event detection. It then creates a time series of event clusters, where clusters are based on BERT contextual word embedding representations of the identified events. Using these time series dataset, we assess four methods based on Granger causality for inferring causal relations. Granger causality is a statistical concept of causality that is based on forecasting. It states that a cause occurs before the effect, and the cause produces unique changes in the effect, so past values of the cause help predict future values of the effect. The four analyzed methods are the pairwise Granger test, VAR (1), BigVar and SiMoNe. The framework is applied to the New York Times dataset, which \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ME8aQywAAAAJ:X9ykpCP0fEIC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Filtering for medical news items",
            "Publication year": 2002,
            "Publication url": "https://asistdl.onlinelibrary.wiley.com/doi/abs/10.1002/meet.1450390131",
            "Abstract": "In this paper we describe recent work toprovide a filtering service for readers interested in medically related news articles from online news sources. The first task is to filter out the nonmedical news articles. The remaining articles, the medically related ones, are then assigned MeSH headings for context and then categorized further by intended audience level (medical expert, medically knowledgeable, no particular medical background needed). The effectiveness goals include both accuracy and efficiency. That is, the process must be robust and efficient enough to scan significant data sets dynamically for the user at the same time as provide accurate results. Our primary effectiveness goal is to provide high accuracy at the medical/nonmedical filtering step. The secondary concern is the effectiveness of the subsequent grouping of the medical articles into reader groups with MeSH contexts for each paper. While it is \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ME8aQywAAAAJ:UxriW0iASnsC",
            "Publisher": "Wiley Subscription Services, Inc., A Wiley Company"
        },
        {
            "Title": "Investigating the properties of a social bookmarking and tagging network",
            "Publication year": 2012,
            "Publication url": "https://www.igi-global.com/chapter/exploring-advances-interdisciplinary-data-mining/61165",
            "Abstract": "Social networks and collaborative tagging systems are rapidly gaining popularity as a primary means for storing and sharing data among friends, family, colleagues, or perfect strangers as long as they have common interests. del. icio. us3 is a social network where people store and share their personal bookmarks. Most importantly, users tag their bookmarks for ease of information dissemination and later look up. However, it is the friendship links, that make del. icio. us a social network. They exist independently of the set of bookmarks that belong to the users and have no relation to the tags typically assigned to the bookmarks. To study the interaction among users, the strength of the existing links and their hidden meaning, we introduce implicit links in the network. These links connect only highly \u201csimilar\u201d users. Here, similarity can reflect different aspects of the user\u2019s profile that makes her similar to any other user \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ME8aQywAAAAJ:1qzjygNMrQYC",
            "Publisher": "IGI Global"
        },
        {
            "Title": "Auditory perception and spatial (3d) auditory systems",
            "Publication year": 2003,
            "Publication url": "https://www.eecs.yorku.ca/research/techreports/2003/CS-2003-07.pdf",
            "Abstract": "In order to enable the user of a virtual reality system to be fully immersed in the virtual environment, the user must be presented with believable sensory input. Although the majority of virtual environments place the emphasis on visual cues, replicating the complex interactions of sound within an environment will benefit the level of immersion and hence the user\u2019s sense of presence. Three dimensional (spatial) sound systems allow a listener to perceive the position of sound sources, and the effect of the interaction of sound sources with the acoustic structure of the environment. This paper reviews the relevant biological and technical literature relevant to the generation of accurate acoustic displays for virtual environments, beginning with an introduction to the process of auditory perception in humans. This paper then critically examines common methods and techniques that have been used in the past as well as methods and techniques which are currently being used to generate spatial sound. In the process of doing so, the limitations, drawbacks, advantages and disadvantages associated with these techniques are also presented.",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:j3f4tGmQtD8C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Exploratory visual analysis and interactive pattern extraction from semi-structured data",
            "Publication year": 2015,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/2812115",
            "Abstract": "Semi-structured documents are a common type of data containing free text in natural language (unstructured data) as well as additional information about the document, or meta-data, typically following a schema or controlled vocabulary (structured data). Simultaneous analysis of unstructured and structured data enables the discovery of hidden relationships that cannot be identified from either of these sources when analyzed independently of each other. In this work, we present a visual text analytics tool for semi-structured documents (ViTA-SSD), that aims to support the user in the exploration and finding of insightful patterns in a visual and interactive manner in a semi-structured collection of documents. It achieves this goal by presenting to the user a set of coordinated visualizations that allows the linking of the metadata with interactively generated clusters of documents in such a way that relevant patterns can be \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ME8aQywAAAAJ:MhiOAD_qIWkC",
            "Publisher": "ACM"
        },
        {
            "Title": "Introduction to Text Analytics Minitrack",
            "Publication year": 2014,
            "Publication url": "https://www.computer.org/csdl/proceedings-article/hicss/2014/2504b803/12OmNzBOhu3",
            "Abstract": "This paper seeks to explore the integration of spectrum and network resource management functionalities to the benefit of achieving higher performance and capacity gains in an International Mobile Telecommunications-Advanced (IMT-A) scenario. In particular, we investigate the allocation of users over two frequency bands (ie, 2 GHz and 5 GHz ones) for a single operator scenario. The same type of Radio Access Technology (RAT) is considered for both frequency bands. It is assumed that the operator considered in this work has gained access to the frequency pool with a certain portion of the available spectrum. The operator has access to a non-shared 2 GHz band and to part (or all) of the frequency pool band at 5 GHz. The performance gain is analyzed in terms of higher data throughput, reduced delay and lower blocking probability. The performance is heavily dependent on the channel quality for each user in \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ME8aQywAAAAJ:4X0JR2_MtJMC",
            "Publisher": "IEEE Computer Society"
        },
        {
            "Title": "Characterizing a social bookmarking and tagging network",
            "Publication year": 2008,
            "Publication url": "https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.218.7857&rep=rep1&type=pdf",
            "Abstract": "Social networks and collaborative tagging systems are rapidly gaining popularity as a primary means for storing and sharing data among friends, family, colleagues, or perfect strangers as long as they have common interests. del. icio. us 5 is a social network where people store and share their personal bookmarks. Most importantly, users tag their bookmarks for ease of information dissemination and later look up. However, it is the friendship links, that make delicious a social network. They exist independently of the set of bookmarks that belong to the users and have no relation to the tags typically assigned to the bookmarks. To study the interaction among users, the strength of the existing links and their hidden meaning, we introduce implicit links in the network. These links connect only highly \u201csimilar\u201d users. Here, similarity can reflect different aspects of the user\u2019s profile that makes her similar to any other user, such as number of shared bookmarks, or similarity of their tags clouds. We investigate the question whether friends have common interests, we gain additional insights on the strategies that users use to assign tags to their bookmarks, and we demonstrate that the graphs formed by implicit links have unique properties differing from binomial random graphs or random graphs with an expected power-law degree distribution.",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:P5F9QuxV20EC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Post-OCR Document Correction with large Ensembles of Character Sequence Models",
            "Publication year": 2021,
            "Publication url": "https://arxiv.org/abs/2109.06264",
            "Abstract": "In this paper, we propose a novel method based on character sequence-to-sequence models to correct documents already processed with Optical Character Recognition (OCR) systems. The main contribution of this paper is a set of strategies to accurately process strings much longer than the ones used to train the sequence model while being sample- and resource-efficient, supported by thorough experimentation. The strategy with the best performance involves splitting the input document in character n-grams and combining their individual corrections into the final output using a voting scheme that is equivalent to an ensemble of a large number of sequence models. We further investigate how to weigh the contributions from each one of the members of this ensemble. We test our method on nine languages of the ICDAR 2019 competition on post-OCR text correction and achieve a new state-of-the-art performance in five of them. Our code for post-OCR correction is shared at https://github.com/jarobyte91/post_ocr_correction.",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:Zh0EY9V9P6UC",
            "Publisher": "Unknown"
        },
        {
            "Title": "DalTREC 2005 Spam Track: Spam Filtering using N-gram-based Techniques",
            "Publication year": 2006,
            "Publication url": "https://vlado.ca/papers/DalTREC05spam.pdf",
            "Abstract": "We briefly describe DalTREC 2005 Spam submission. DalTREC is the TREC research project at Dalhousie University. Four packages were submitted and they resulted in a median performance. The results are interesting and may be seen positive in the light of simplicity of our approaches.",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:WbkHhVStYXYC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Nonuniform language in technical writing: Detection and correction",
            "Publication year": 2021,
            "Publication url": "https://www.cambridge.org/core/journals/natural-language-engineering/article/nonuniform-language-in-technical-writing-detection-and-correction/5D05C80A7B6BEB03165B649A07F453D9",
            "Abstract": "Technical writing in professional environments, such as user manual authoring, requires the use of uniform language. Nonuniform language refers to sentences in a technical document that are intended to have the same meaning within a similar context, but use different words or writing style. Addressing this nonuniformity problem requires the performance of two tasks. The first task, which we named nonuniform language detection (NLD), is detecting such sentences. We propose an NLD method that utilizes different similarity algorithms at lexical, syntactic, semantic and pragmatic levels. Different features are extracted and integrated by applying a machine learning classification method. The second task, which we named nonuniform language correction (NLC), is deciding which sentence among the detected ones is more appropriate for that context. To address this problem, we propose an NLC method that \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ME8aQywAAAAJ:qe6vwMD2xtsC",
            "Publisher": "Cambridge University Press"
        },
        {
            "Title": "Comparing Documents Clustering Using N-grams, Terms and Words",
            "Publication year": 2004,
            "Publication url": "https://scholar.google.com/scholar?cluster=1136973079179510988&hl=en&oi=scholarr",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:dfsIfKJdRG4C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Natural Search Queries\u2013a machine learning approach to a search interface for consumer-oriented databases.",
            "Publication year": 2007,
            "Publication url": "https://cdn.dal.ca/content/dam/dalhousie/pdf/faculty/computerscience/technical-reports/CS-2007-01.pdf",
            "Abstract": "Search in consumer-oriented databases is becoming increasingly important, as the computer becomes a commonly used tool. Such databases are at the heart of e-mail managers, flight booking, and other e-commerce systems. Key problems associated with such searches are the structure and interface of the search query. The traditional solution for these problems involves the use of a separate text field for each element of the query structure. However, the requirement to support ever increasing numbers of inexperienced users, who require an efficient and userfriendly interface, is not met by the traditional solution. We present Natural Search Queries (NSQ), a simple and intuitive approach to the search of structured information. Our solution combines the ideas of natural language database interfaces and operator based search; queries, in simplified and intuitive natural language, are entered into a single text field. It is a front-end search interface oriented towards the common user. Our aim is to allow as much freedom in formulating queries as possible, while interpreting such queries as accurately as possible, to automatically extract the elements of the query structure. In our project, we address the problem of e-mail databases, but the results may be applicable to other databases oriented towards consumer users. The report introduces the grammar of Natural Search Queries and probabilistic methods for recognizing the query structure (ie, parsing, and Hidden Markov Model). In addition, we demonstrate a complete implementation of a system for processing NSQs and presenting retrieved messages. Specific subproblems that were addressed \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ME8aQywAAAAJ:Ug5p-4gJ2f0C",
            "Publisher": "Unknown"
        },
        {
            "Title": "AQUA: an aquatic walking robot",
            "Publication year": 2004,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/1389962/",
            "Abstract": "This paper describes an underwater walking robotic system being developed under the name AQUA, the goals of the AQUA project, the overall hardware and software design, the basic hardware and sensor packages that have been developed, and some initial experiments. The robot is based on the RHex hexapod robot and uses a suite of sensing technologies, primarily based on computer vision and INS, to allow it to navigate and map clear shallow-water environments. The sensor-based navigation and mapping algorithms are based on the use of both artificial floating visual and acoustic landmarks as well as on naturally occurring underwater landmarks and trinocular stereo.",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:ufrVoPGSRksC",
            "Publisher": "IEEE"
        },
        {
            "Title": "An evaluation of entropy based approaches to alert detection in high performance cluster logs",
            "Publication year": 2010,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/5600405/",
            "Abstract": "Manual alert detection on modern high performance clusters (HPC) is cumbersome given their increasing complexity and size of their logs. The ability to automatically detect such alerts quickly and accurately with little or no human intervention is therefore desirable. The entropy-based approach of the Nodeinfo framework, which is in production use at Sandia National Laboratories, is one approach to automatic alert detection in HPC logs. In this work, we perform a comparative evaluation of three entropy based techniques, which are modifications to Nodeinfo. We evaluate these systems using three performance metrics, namely (i) Computational cost, (ii) detection accuracy, and (iii) false positive rate. Our results show that there is still room for improvement in entropy based approaches to the task of alert detection. We also show experimentally that it is possible to detect 100% of all alerts while maintaining an \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ME8aQywAAAAJ:OU6Ihb5iCvQC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Node similarity in the citation graph",
            "Publication year": 2007,
            "Publication url": "https://link.springer.com/article/10.1007/s10115-006-0023-9",
            "Abstract": "Published scientific articles are linked together into a graph, the citation graph, through their citations. This paper explores the notion of similarity based on connectivity alone, and proposes several algorithms to quantify it. Our metrics take advantage of the local neighborhoods of the nodes in the citation graph. Two variants of link-based similarity estimation between two nodes are described, one based on the separate local neighborhoods of the nodes, and another based on the joint local neighborhood expanded from both nodes at the same time. The algorithms are implemented and evaluated on a subgraph of the citation graph of computer science in a retrieval context. The results are compared with text-based similarity, and demonstrate the complementarity of link-based and text-based retrieval.",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:dhFuZR0502QC",
            "Publisher": "Springer-Verlag"
        },
        {
            "Title": "Second Workshop on Exploratory Search and Interactive Data Analytics (ESIDA)",
            "Publication year": 2018,
            "Publication url": "http://ceur-ws.org/Vol-2068/preface-esida.pdf",
            "Abstract": "This is the second edition of the Workshop on Exploratory Search and Interactive Data Analytics (ESIDA). This series of workshops emerged as a response to the growing interest in developing new methods and systems that allow users to interactively explore large volumes of data, such as documents, multimedia or specialised collections, such as biomedical datasets. There are various approaches to supporting users in this interactive environment ranging from the development of new algorithms through visualisation methods to analysing users\u2019 search patterns. The overarching goal of ESIDA is to bring together researchers working in areas that span across multiple facets of exploratory search and data analytics to discuss and outline research challenges for this novel area.",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:EPG8bYD4jVwC",
            "Publisher": "Unknown"
        },
        {
            "Title": "CAST: A context-aware story-teller for streaming social content",
            "Publication year": 2014,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/2661829.2661859",
            "Abstract": "Online social streams such as Twitter timelines, forum discussions and email threads have emerged as important channels for information propagation. Mining transient stories and their correlations implicit in social streams is a challenging task, since these streams are noisy and surge quickly. In this paper, we propose CAST, which is a context-aware story-teller that discovers new stories from social streams and tracks their structural context on the fly to build a vein of stories. More precisely, we model the social stream as a capillary network, and define stories by a new cohesive subgraph type called (k, d)-Core in the capillary network. We propose deterministic and randomized context search to support the iceberg query, which builds the story vein as social streams flow. We perform detailed experimental study on real Twitter streams and the results demonstrate the creativity and value of our approach.",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:jgBuDB5drN8C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Registration uncertainty for robot self-localization in 3D",
            "Publication year": 2005,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/1443170/",
            "Abstract": "Stereo camera is a very important sensor for mobile robot localization and mapping. Its consecutive images can be used to estimate the location of the robot with respect to its environment. This estimation will be fused with location estimates from other sensors for a globally optimal location estimate. In the data fusion context, it is important to compute the uncertainty of the stereo-based localization. In this paper, we propose an approach to obtain the uncertainty of localization when a correspondence-based method is used to estimate the robot pose. The computational complexity of this approach is O(n). Where n is the number of corresponding image points. Experimental results show that this approach is promising.",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:08ZZubdj9fEC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Link-based event detection in email communication networks",
            "Publication year": 2009,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/1529282.1529618",
            "Abstract": "People's email communications can be modeled as graphs with vertices representing email accounts and edges representing email communications. Email communication data usually comes in as continuous data stream. Event detection aims to identify abnormal email communications that serve as analogs of real-world events imposed upon the data stream. The goal is to understand the communications behaviors of the subjects. The contents of emails are often not available or protected by privacy, which makes linkage information the only resource we can rely on. We propose a link-based event detection method that clusters vertices with similar communication patterns together and then, considers deviations from each vertex's individual profile, as well as its cluster profile. Experiments show that this method performs well on both Enron and our own email datasets.",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:LPZeul_q3PIC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Twitter message recommendation based on user interest profiles",
            "Publication year": 2016,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/7752266/",
            "Abstract": "Twitter has become one of the most important platforms for gathering information, where users follow breaking news, track ongoing events and learn about their topics of interest. Considering the sheer volume of Twitter data and the ever-growing number of users, it is of great importance to have real-time systems that can monitor and recommend relevant and non-redundant tweets with respect to users' interests. In this paper, we propose a framework using language models as a basis for analyzing strategies and techniques for tweet recommendation based on user interest profiles. Results show that identifying named entities in profiles has a major impact on the accuracy of the recommender. We also performed a thorough comparison to investigate whether state-of-the-art semantic relatedness techniques have a positive impact on the precision of the recommended tweets. The TREC 2015 Microblog track dataset \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ME8aQywAAAAJ:-7ulzOJl1JYC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Selective Retrieval for Categorization of Semi-structured Web Resources",
            "Publication year": 2013,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-642-38457-8_11",
            "Abstract": "A typical on-line content directory contains factual information about entities (e.g., address of a company) together with entity categories (e.g., company\u2019s industries). The categories are a salient element of the system as they allow users to browse for entities of a chosen type. Assigning categories manually can be a challenging task, considering that an entity can belong to few out of hundreds of categories (e.g., all possible industry types). Instead we suggest to augment this process with an automatic categorization system that suggests categories based on the entity\u2019s home page. To improve the accuracy of results, the system follows links extracted from the home page and uses retrieved content to expand an entity\u2019s term profile. The profile is later used by a multi-label classification system to assign categories to the entity. The key element of the system is a link ranking module, which uses home page \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ME8aQywAAAAJ:F9fV5C73w3QC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "Multi-Objective GP Strategies for Topical Search Integrating Wikipedia Concepts",
            "Publication year": 2019,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/3342558.3345402",
            "Abstract": "Genetic Programming techniques have demonstrated great potential in dealing with the problem of query generation. This work explores different Multi-Objective Genetic Programming strategies for evolving a collection of topic-based Boolean queries. It compares three approaches to build topical Boolean queries: using terms, incorporating Wikipedia semantics (Wikipedia concepts) and a hybrid approach, using a combination of both terms and concepts. In addition, different fitness functions are combined giving rise to seven multi-objective schemes. In particular, we investigate the use of the proposed strategies in conjunction with novel fitness functions aimed at attaining high diversity based on the information-theoretic notion of entropy and Jaccard similarity. Experiments were completed using 25 topics from a dataset consisting of approximately 350,000 webpages classified into 448 topics. The results reveal that \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ME8aQywAAAAJ:Xl6nMSl579sC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Avatars d'un h\u00e9ros compos\u00e9: Bruno Brazil et le Commando Ca\u00efman",
            "Publication year": 2006,
            "Publication url": "https://dalspace.library.dal.ca/bitstream/handle/10222/28724/frigerio_v_belphegor_2006d_fr.pdf?sequence=1",
            "Abstract": "Dans le cadre de la bande dessin\u00e9e franco-belge, \u00e0 l'int\u00e9rieur de laquelle les figures de \u00abh\u00e9ros multiples\u00bb ne sont pas rares 1, la s\u00e9rie des aventures de Bruno Brazil et du Commando Ca\u00efman semble faire exception. Cette saga nous para\u00eet pouvoir se pr\u00eater ais\u00e9ment \u00e0 une discussion, sans grandes pr\u00e9tentions de g\u00e9n\u00e9ralisation, sur la nature et les qualit\u00e9s du h\u00e9ros de bandes dessin\u00e9es d'aventures et surtout sur les rapports qu'il entretient avec les divers personnages secondaires qui l'entourent.Publi\u00e9es initialement dans les pages de l'hebdomadaire Tintin \u00e0 partir de janvier 1967, les aventures de Bruno Brazil ont \u00e9t\u00e9 recueillies en 10 albums 2. La premi\u00e8re aventure de ce personnage, Le requin qui mourut deux fois, le voit seul en sc\u00e8ne \u00e0 la poursuite d'un criminel de guerre nazi, Schellemberg, et de son tr\u00e9sor cach\u00e9. En cette incarnation initiale, Brazil est pr\u00e9sent\u00e9 simplement comme un agent secret, sans plus. Son aspect athl\u00e9tique, ses costumes impeccables, sa chemise blanche et sa cravate toujours soigneusement nou\u00e9e le rapprochent suffisamment des grands arch\u00e9types de la cat\u00e9gorie, dont \u00e9videmment James Bond, pour qu'il devienne inutile de fournir au lecteur des renseignements biographiques qui n'ajouteraient rien au personnage. Fort, courageux, habile, intelligent, Brazil cumule les lieux communs et collectionne les qualit\u00e9s essentielles \u00e0 la progression et au d\u00e9veloppement d'une intrigue qui le porte plus qu'il ne la dirige. Il appara\u00eet, en son ind\u00e9finition fortement marqu\u00e9e par les traits caract\u00e9ristiques de sa profession, comme un simple actant \u00e0 qui une personnalit\u00e9 particuli\u00e8rement marqu\u00e9e ou individualis\u00e9e ne rendrait \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ME8aQywAAAAJ:3NQIlFlcGxIC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Eyes'n Ears: A System for Attentive Teleconferencing",
            "Publication year": 2001,
            "Publication url": "https://www.academia.edu/download/49895703/asaAtlanta.pdf",
            "Abstract": "Various teleconferencing systems exist, including systems intended for multiple speakers in a conference setting. In such a multiple-speaker setting, a speaker must be localized and tracked in both the video and audio domains. Although many fast, reliable and economical video trackers capable of tracking humans exist, there are very few compact, portable and economical audio localization systems. On the contrary, most available audio localization systems are expensive, non-portable and require extensive audio arrays requiring substantial computational processing. Under the Eyes\u2019n Ears project, a simple, economical and compact method of sound localization for use in a teleconferencing system is being investigated. This paper describes the current status of the Eyes \u2018n Ears project, and summarizes the hardware and software components that make up the system.",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:l7t_Zn2s7bgC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Multi-document summarization of scientific corpora",
            "Publication year": 2011,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/1982185.1982243",
            "Abstract": "In this paper, we investigated four approaches for scientific corpora summarization when only gold-standard keyterms available. MEAD with built-in default vocabulary, MEAD with corpus specific vocabulary extracted by Keyphrase Extraction Algorithm (KEA), LexRank (a state-of-the-art summarization algorithm based on random walk) and W3SS (summarization algorithm based on keyword density) are tested on two Computer Science research paper collections. We use a content evaluation method, pyramid method, instead of the well-known ROUGE metrics since there are no gold-standard summaries available for our data. Evaluations with pyramid method indicates that including a corpus specific vocabulary to the traditional summarization methods improves the performance but not significantly. On the other hand, visual inspection shows us that current content evaluation methods, which use only the gold \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ME8aQywAAAAJ:z_wVstp3MssC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Visual analysis of interactive document clustering streams",
            "Publication year": 2020,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/3399715.3399962",
            "Abstract": "Interactive clustering techniques play a key role by putting the user in the clustering loop, allowing her to interact with document group abstractions instead of full-length documents. It allows users to focus on corpus exploration as an incremental task. To explore Information Discovery's incremental aspect, this article proposes a visual component to depict clustering membership changes throughout a clustering iteration loop in both static and dynamic data sets. The visual component is evaluated with an expert user and with an experiment with data streams.",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:1tZ8xJnm2c8C",
            "Publisher": "Unknown"
        },
        {
            "Title": "On the positional uncertainty of multi-robot cooperative localization",
            "Publication year": 2002,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-94-017-2376-3_1",
            "Abstract": "This paper deals with terrain mapping and position estimation using multiple robots. Here we will discuss work where a larger group of robots can mutually estimate one another\u2019s position (in 2D or 3D) and uncertainty using a sample-based (particle filter) model of uncertainty. Our prior work has dealt with a pair of robots that estimate one another\u2019s position using visual tracking and coordinated motion and we extend these results and consider a richer set of sensing and motion options. In particular, we focus on issues related to confidence estimation for groups of more than two robots.",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:ruyezt5ZtCIC",
            "Publisher": "Springer, Dordrecht"
        },
        {
            "Title": "Personalized document clustering with dual supervision",
            "Publication year": 2012,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/2361354.2361393",
            "Abstract": "The potential for semi-supervised techniques to produce personalized clusters has not been explored. This is due to the fact that semi-supervised clustering algorithms used to be evaluated using oracles based on underlying class labels. Although using oracles allows clustering algorithms to be evaluated quickly and without labor intensive labeling, it has the key disadvantage that oracles always give the same answer for an assignment of a document or a feature. However, different human users might give different assignments of the same document and/or feature because of different but equally valid points of view. In this paper, we conduct a user study in which we ask participants (users) to group the same document collection into clusters according to their own understanding, which are then used to evaluate semi-supervised clustering algorithms for user personalization. Through our user study, we observe \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ME8aQywAAAAJ:IRz6iEL74y4C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Keysee: Supporting keyword search on evolving events in social streams",
            "Publication year": 2013,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/2487575.2487711",
            "Abstract": "Online social streams such as Twitter/Facebook timelines and forum discussions have emerged as prevalent channels for information dissemination. As these social streams surge quickly, information overload has become a huge problem. Existing keyword search engines on social streams like Twitter Search are not successful in overcoming the problem, because they merely return an overwhelming list of posts, with little aggregation or semantics. In this demo, we provide a new solution called\\keysee by grouping posts into events, and track the evolution patterns of events as new posts stream in and old posts fade out. Noise and redundancy problems are effectively addressed in our system. Our demo supports refined keyword query on evolving events by allowing users to specify the time span and designated evolution pattern. For each event result, we provide various analytic views such as frequency curves \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ME8aQywAAAAJ:nVrZBo8bIpAC",
            "Publisher": "Unknown"
        },
        {
            "Title": "A visual framework for clustering memes in social media",
            "Publication year": 2015,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/7403620/",
            "Abstract": "The spread of \"rumours\" in Online Social Networks (OSNs) has grown at an alarming rate. Consequently, there is an increasing need to improve understanding of the social and technological processes behind this trend. The first step in detecting rumours is to identify and extract memes, a unit of information that can be spread from person to person in OSNs. This paper proposes four similarity scores and two novel strategies to combine those similarity scores for detecting the spread of memes in OSNs, with the end goal of helping researchers as well as members of various OSNs to study the phenomenon. The two proposed strategies include: (1) automatically computing the similarity score weighting factors for four elements of a submission and (2) allowing users to engage in the clustering process and filter out outlier submissions, modify submission class labels, or assign different similarity score weight factors for \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ME8aQywAAAAJ:jU7OWUQzBzMC",
            "Publisher": "IEEE"
        },
        {
            "Title": "ALatex Tutorial",
            "Publication year": 2004,
            "Publication url": "https://web.cs.dal.ca/~eem/Research/Research/theses/LatexTutorial.pdf",
            "Abstract": "Let  be a subset of  and let  be a real-valued function on . The function  is said to be\\emph {continuous} on  if, for all  and for all , there exists some (which may depend on ) such that if  satisfies then",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:NJ774b8OgUMC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Graph Representation Learning in Document Wikification",
            "Publication year": 2021,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-030-86159-9_37",
            "Abstract": "Wikification (entity annotation) is a challenging task in Natural Language Processing (NLP). It is a method to automatically enrich a text with links to Wikipedia as a knowledge base. Wikification starts from detecting ambiguous mentions in the document, and later tries to disambiguate those mentions. In the core of the Wikification task, there is one other important NLP task: word representation. This paper proposes a new word representation for senses of a mention with Graph convolutional networks architecture. Senses are the possible meanings of one mention, based on the knowledge base. In our representation modeling, we used the context document and the first paragraph of each Wikipedia page to enhance our contextual representation. Using the nearest neighbor algorithm for disambiguating the mentions via our sense representations, we show the efficiency of our representations. The results of \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ME8aQywAAAAJ:4aZ_i-5WJEQC",
            "Publisher": "Springer, Cham"
        },
        {
            "Title": "Fourth Workshop on Exploratory Search and Interactive Data Analytics (ESIDA)",
            "Publication year": 2021,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/3397482.3450711",
            "Abstract": "This is the fourth edition of the Workshop on Exploratory Search and Interactive Data Analytics (ESIDA). This series of workshops emerged as a response to the growing interest in developing new methods and systems that allow users to interactively explore large volumes of data, such as documents, multimedia, or specialized collections, such as biomedical datasets. There are various approaches to supporting users in this interactive environment, ranging from developing new algorithms through visualization methods to analyzing users\u2019 search patterns. The overarching goal of ESIDA is to bring together researchers working in areas that span across multiple facets of exploratory search and data analytics to discuss and outline research challenges for this novel area.",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:A8cqit5AE6sC",
            "Publisher": "Unknown"
        },
        {
            "Title": "New towed-array shape-estimation scheme for real-time sonar systems",
            "Publication year": 2003,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/1240017/",
            "Abstract": "In real-time towed-array systems, performance degradation of array gain occurs when a line array that is not straight is assumed straight in the beamforming process. In this paper, a new method is proposed for array shape estimation. The novelty of this method is that it accounts for the variations in the tow ship's speed, which are typical during course alterations. The procedure consists of two steps. First, we solve for the tow-point induced motion in the time domain based on the constraints from the tow-point compass-sensor readings and from a discretized Paidoussis equation. At each time instance, the shape estimate is solved from a linear system of equations. We also show that this solution is equivalent to a previous frequency-domain solution while the new approach is much simpler. In the second step, we use the tail compass-sensor data to adjust the overall array shape. By noting that variations in the ship \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ME8aQywAAAAJ:YFjsv_pBGBYC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Document clustering with dual supervision through feature reweighting",
            "Publication year": 2016,
            "Publication url": "https://onlinelibrary.wiley.com/doi/abs/10.1111/coin.12064",
            "Abstract": "Traditional semi\u2010supervised clustering uses only limited user supervision in the form of instance seeds for clusters and pairwise instance constraints to aid unsupervised clustering. However, user supervision can also be provided in alternative forms for document clustering, such as labeling a feature by indicating whether it discriminates among clusters. This article thus fills this void by enhancing traditional semi\u2010supervised clustering with feature supervision, which asks the user to label discriminating features during defining (labeling) the instance seeds or pairwise instance constraints. Various types of semi\u2010supervised clustering algorithms were explored with feature supervision. Our experimental results on several real\u2010world data sets demonstrate that augmenting the instance\u2010level supervision with feature\u2010level supervision can significantly improve document clustering performance.",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:cK4Rrx0J3m0C",
            "Publisher": "Unknown"
        },
        {
            "Title": "An ensemble approach for text document clustering using Wikipedia concepts",
            "Publication year": 2014,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/2644866.2644868",
            "Abstract": "Most text clustering algorithms represent a corpus as a document-term matrix in the bag of words model. The feature values are computed based on term frequencies in documents and no semantic relatedness between terms is considered. Therefore, two semantically similar documents may sit in different clusters if they do not share any terms. One solution to this problem is to enrich the document representation using an external resource like Wikipedia. We propose a new way to integrate Wikipedia concepts in partitional text document clustering in this work. A text corpus is first represented as a document-term matrix and a document-concept matrix. Terms that exist in the corpus are then clustered based on the document-term representation. Given the term clusters, we propose two methods, one based on the document-term representation and the other one based on the document-concept representation, to find \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ME8aQywAAAAJ:ubry08Y2EpUC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Mining frequent generalized patterns for web personalization in the presence of taxonomies",
            "Publication year": 2010,
            "Publication url": "https://www.igi-global.com/article/mining-frequent-generalized-patterns-web/38954",
            "Abstract": "The Web is a continuously evolving environment, since its content is updated on a regular basis. As a result, the traditional usage-based approach to generate recommendations that takes as input the navigation paths recorded on the Web page level, is not as effective. Moreover, most of the content available online is either explicitly or implicitly characterized by a set of categories organized in a taxonomy, allowing the page-level navigation patterns to be generalized to a higher, aggregate level. In this direction, the authors present the Frequent Generalized Pattern (FGP) algorithm. FGP takes as input the transaction data and a hierarchy of categories and produces generalized association rules that contain transaction items and/or item categories. The results can be used to generate association rules and subsequently recommendations for the users. The algorithm can be applied to the log files of a typical Web site \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ME8aQywAAAAJ:WC9gN4BGCRcC",
            "Publisher": "IGI Global"
        },
        {
            "Title": "World wide web site summarization",
            "Publication year": 2004,
            "Publication url": "https://content.iospress.com/articles/web-intelligence-and-agent-systems-an-international-journal/wia00026",
            "Abstract": "Summaries of Web sites help Web users get an idea of the site contents without having to spend time browsing the sites. Currently, manually constructed summaries of Web sites by volunteer experts are available, such as the DMOZ Open Directory Project. This research is directed towards automating the Web site summarization task. To achieve this objective, an approach which applies machine learning and natural language processing techniques is developed to summarize a Web site automatically. The information content of the automatically generated summaries is compared, via a formal evaluation process involving human subjects, to DMOZ summaries, home page browsing and time-limited site browsing, for a number of academic and commercial Web sites. Statistical evaluation of the scores of the answers to a list of questions about the sites demonstrates that the automatically generated summaries \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ME8aQywAAAAJ:9ZlFYXVOiuMC",
            "Publisher": "IOS Press"
        },
        {
            "Title": "Vector embedding of wikipedia concepts and entities",
            "Publication year": 2017,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-319-59569-6_50",
            "Abstract": "Using deep learning for different machine learning tasks such as word embedding has recently gained a lot of researchers\u2019 attention. Word embedding is the task of mapping words or phrases to a low dimensional numerical vector. In this paper, we use deep learning to embed Wikipedia concepts and entities. The English version of Wikipedia contains more than five million pages, which suggest its capability to cover many English entities, phrases, and concepts. Each Wikipedia page is considered as a concept. Some concepts correspond to entities, such as a person\u2019s name, an organization or a place. Contrary to word embedding, Wikipedia concepts embedding is not ambiguous, so there are different vectors for concepts with similar surface form but different mentions. We proposed several approaches and evaluated their performance based on Concept Analogy and Concept Similarity tasks. The results \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ME8aQywAAAAJ:sszUF3NjhM4C",
            "Publisher": "Springer, Cham"
        },
        {
            "Title": "Document representation and dimension reduction for text clustering",
            "Publication year": 2007,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/4401066/",
            "Abstract": "Increasingly large text damsels and the high dimensionality associated with natural language create a great challenge in text mining, In this research, a systematic study is conducted. in which three different document representation methods for text are used, together with three Dimension Reduction Techniques (DRT), in the context of the text clustering problem. Several standard benchmark datasets are used. The three Document representation methods considered are based on the vector space model, and they include word, multi-word term, and character N-gram representations. The dimension reduction methods are. independent component analysis (ICA). latent semantic indexing (LSI), and a feature selection technique based on Document Frequency (DF). Results are compared in terms of clustering performance, using the k-means clustering algorithm. Experiments show that ICA and LSI are clearly belter \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ME8aQywAAAAJ:sSrBHYA8nusC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Information Retrieval by Semantic Similarity",
            "Publication year": 2006,
            "Publication url": "https://web.cs.dal.ca/~eem/cvWeb/pubs/Hliaoutakis-JSWIS.pdf",
            "Abstract": "Semantic Similarity relates to computing the similarity between conceptually similar but not necessarily lexically similar terms. Typically, semantic similarity is computed by mapping terms to an ontology and by examining their relationships in that ontology. We investigate approaches to computing the semantic similarity between natural language terms (using WordNet as the underlying reference ontology) and between medical terms (using the MeSH ontology of medical and biomedical terms). The most popular semantic similarity methods are implemented and evaluated using WordNet and MeSH. Building upon semantic similarity, we propose the Semantic Similarity based Retrieval Model (SSRM), a novel information retrieval method capable for discovering similarities between documents containing conceptually similar terms. The most effective semantic similarity method is implemented into SSRM. SSRM has been applied in retrieval on OHSUMED (a standard TREC collection available on the Web). The experimental results demonstrated promising performance improvements over classic information retrieval methods utilizing plain lexical matching (eg, Vector Space Model) and also over state-of-theart semantic similarity retrieval methods utilizing ontologies.",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:TIZ-Mc8IlK0C",
            "Publisher": "Unknown"
        },
        {
            "Title": "A framework for summarization of multi-topic Web sites.",
            "Publication year": 2007,
            "Publication url": "https://dalspace.library.dal.ca/bitstream/handle/10222/54977/NR31513.PDF?sequence=1",
            "Abstract": "In this chapter, we briefly describe the research problem, the motivation, and the approach. We aim to address the following two questions:",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:4vMrXwiscB8C",
            "Publisher": "Dalhousie University"
        },
        {
            "Title": "Augmenting GEM-encoded clinical practice guidelines with relevant best evidence autonomously retrieved from MEDLINE",
            "Publication year": 2005,
            "Publication url": "https://journals.sagepub.com/doi/abs/10.1177/1460458205050684",
            "Abstract": "Clinical practice guidelines (CPG) are instrumental in standardizing the quality                     and delivery of care across different practitioners, departments and                     institutions. Health practitioners will use current best evidence to validate or                     supplement their understanding of CPG. This study investigates the potential of                     supplementing computerized CPG with relevant best evidence sourced from reliable                     medical literature repositories. A web-enabled Best-evidence Retrieval and                     Delivery (BiRD) system facilitates autonomous retrieval of pertinent medical                     literature with respect to user-specified content from a GEM-encoded CPG. A                     multilevel literature search strategy categorizes the search towards predefined                     clinical query intentions, and subsequently filters insignificant medical terms.                     The resultant is a highly focused \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ME8aQywAAAAJ:SeFeTyx0c_EC",
            "Publisher": "Sage Publications"
        },
        {
            "Title": "Perspectives on Business Intelligence",
            "Publication year": 2013,
            "Publication url": "https://www.morganclaypool.com/doi/abs/10.2200/S00491ED1V01Y201303DTM034",
            "Abstract": " Download Free Sample  In the 1980s, traditional Business Intelligence (BI) systems focused on the delivery of reports that describe the state of business activities in the past, such as for questions like \"How did our sales perform during the last quarter?\" A decade later, there was a shift to more interactive content that presented how the business was performing at the present time, answering questions like \"How are we doing right now?\" Today the focus of BI users are looking into the future. \"Given what I did before and how I am currently doing this quarter, how will I do next quarter?\" Furthermore, fuelled by the demands of Big Data, BI systems are going through a time of incredible change. Predictive analytics, high volume data, unstructured data, social data, mobile, consumable analytics, and data visualization are all examples of demands and capabilities that have become critical within just the past few years \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ME8aQywAAAAJ:OP4eGU-M3BUC",
            "Publisher": "Morgan & Claypool Publishers"
        },
        {
            "Title": "Sonel mapping: a probabilistic acoustical modeling method",
            "Publication year": 2008,
            "Publication url": "https://journals.sagepub.com/doi/abs/10.1260/135101008786939973",
            "Abstract": "Sonel mapping is a Monte-Carlo-based acoustical modeling technique that approximates the acoustics of an environment while accounting for diffuse and specular reflections as well as diffraction effects. Through the use of a probabilistic Russian roulette strategy to determine the type of interaction between a sound and any objects/surfaces it may encounter, sonel mapping avoids excessively large running times in contrast to deterministic techniques. Sonel mapping approximates many of the subtle interaction effects required for realistic acoustical modeling yet due to its probabilistic nature, can be incorporated into interactive virtual environments where accuracy is often substituted for efficiency. Experimental results demonstrate the efficacy of the approach.",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:V3AGJWp-ZtQC",
            "Publisher": "SAGE Publications"
        },
        {
            "Title": "Shape matching with occlusion in image databases",
            "Publication year": 2001,
            "Publication url": "http://www.intelligence.tuc.gr/~petrakis/publications/dipemi01.pdf",
            "Abstract": "We propose an approach for matching deformed, occluded and unoccluded shapes using Dynamic Programming (DP). We distinguish among various cases of matching including cases where the shapes are scaled with respect to each other or cases where one shape matches the whole or only a part of the other shape. Our approach handles noise and shape distortions by allowing matching of merged sequences of consecutive small segments in a shape, with larger segments of another shape, while being invariant to translation, scale orientation and starting point selection. We demonstrate the superiority of our approach over traditional approaches to shape matching and retrieval based on Fourier descriptors and moments.",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:9vf0nzSNQJEC",
            "Publisher": "Unknown"
        },
        {
            "Title": "A systematic study on document representation and dimensionality reduction for text clustering",
            "Publication year": 2006,
            "Publication url": "http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.333.93&rep=rep1&type=pdf",
            "Abstract": "Increasingly large text datasets and the high dimensionality associated with natural language is a great challenge of text mining. In this research, a systematic study is conducted of application of three Dimension Reduction Techniques (DRT) on three different document representation methods in the context of the text clustering problem using several standard benchmark datasets. The dimensionality reduction methods considered include Independent Component Analysis (ICA), Latent Semantic Indexing (LSI) and one technique based on Document Frequency (DF). These three methods are applied on three Document representation methods based on the idea of Vector Space Model, namely word, term and N-Gram representations. Experiments with the k-means clustering algorithm show that ICA and LSI are clearly better than DF on all datasets. For word and N-Gram representation, ICA gives better results compared to LSI. Experiments also show that the word representation gives better clustering results compared to term and N-Gram representation. Finally, for N-Gram representation, it is shown that profile length equal to 2000 is",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:BUYA1_V_uYcC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Extracting message types from bluegene/l\u2019s logs",
            "Publication year": 2009,
            "Publication url": "https://www.cs.dal.ca/~makanju/publications/paper/wasl09.pdf",
            "Abstract": "In this paper we present the results on extracting message types from the BlueGene/L supercomputer logs using the IPLoM (Iterative Partitioning Log Mining) algorithm. Previous work using IPLoM indicates that IPLoM shows promise as message type extraction algorithm. We compared the results of IPLoM against manually produced message types produced on the BlueGene/L data. To provide a baseline of performance we also perform similar experiments using SLCT (Simple Log File Clustering Tool). The results show that IPLoM improves the performance of SLCT by finding the infrequent patterns in the data and is also able to achieve an F-Measure result of 91% based on micro-average classification accuracy.",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:u_35RYKgDlwC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Interactive document clustering revisited: A visual analytics approach",
            "Publication year": 2018,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/3172944.3172964",
            "Abstract": "Document clustering is an efficient way to get insight into large text collections. Due to the personalized nature of document clustering, even the best fully automatic algorithms cannot create clusters that accurately reflect the user\u00bb s perspectives. To incorporate the user\u00bb s perspective in the clustering process and, at the same time, effectively visualize document collections to enhance user's sense-making of data, we propose a novel visual analytics system for interactive document clustering. We built our system on top of clustering algorithms that can adapt to user's feedback. First, the initial clustering is created based on the user-defined number of clusters and the selected clustering algorithm. Second, the clustering result is visualized to the user. A collection of coordinated visualization modules and document projection is designed to guide the user towards a better insight into the document collection and clusters \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ME8aQywAAAAJ:An6A6Jpfc1oC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Storage and retrieval of system log events using a structured schema based on message type transformation",
            "Publication year": 2011,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/1982185.1982298",
            "Abstract": "Message types are semantic groupings of the free form messages in system log events. The message types that exist in a log file, if known, can be used in several log management and analysis tasks. In this work, we explore the use of message types as a schema definition for the storage and retrieval of messages in event logs. We show how message types can be used to impose structure on the unstructured content of event logs and how this structured representation can provide a usable index for searching the contents of the log file. As a side benefit, the structured representation that message types impose also leads to the removal of redundant information in the event logs that leads to space savings on disk.",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:SdhP9T11ey4C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Active neural learners for text with dual supervision",
            "Publication year": 2020,
            "Publication url": "https://link.springer.com/article/10.1007/s00521-019-04681-0",
            "Abstract": "Dual supervision for text classification and information retrieval, which involves training the machine with class labels augmented with text annotations that are indicative of the class, has been shown to provide significant improvements, both in and beyond active learning (AL) settings. Annotations in the simplest form are highlighted portions of the text that are indicative of the class. In this work, we aim to identify and realize the full potential of unsupervised pretrained word embeddings for text-related tasks in AL settings by training neural nets\u2014specifically, convolutional and recurrent neural nets\u2014through dual supervision. We propose an architecture-independent algorithm for training neural networks with human rationales for class assignments and show how unsupervised embeddings can be better leveraged in active learning settings using the said algorithm. The proposed solution involves the use of \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ME8aQywAAAAJ:SIv7DqKytYAC",
            "Publisher": "Springer London"
        },
        {
            "Title": "Workshop Innovative Internet Computing Systems-Characterizing the Citation Graph as a Self-Organizing Networked Information Space",
            "Publication year": 2002,
            "Publication url": "https://scholar.google.com/scholar?cluster=12808929310572594828&hl=en&oi=scholarr",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:tYavs44e6CUC",
            "Publisher": "Berlin: Springer-Verlag, 1973-"
        },
        {
            "Title": "Efficient computation of co-occurrence based word relatedness",
            "Publication year": 2015,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/2682571.2797088",
            "Abstract": "Measuring document relatedness using unsupervised co-occurrence based word relatedness methods is a processing-time and memory consuming task. This paper introduces the application of compact data structures for efficient computation of word relatedness based on corpus statistics. The data structure is used to efficiently lookup:(1) the corpus statistics for the Common Word Relatedness Approach,(2) the pairwise word relatedness for the Algorithm Specific Word Relatedness Approach. These two approaches significantly accelerate the processing time of word relatedness methods and reduce the space cost of storing co-occurrence statistics in memory, making text mining tasks like classification and clustering based on word relatedness practical.",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:WHdLCjDvYFkC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Dark fiber: Tracking critical Internet culture",
            "Publication year": 2004,
            "Publication url": "https://scholar.google.com/scholar?cluster=1837959740484785813&hl=en&oi=scholarr",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:rTD5ala9j4wC",
            "Publisher": "SAGE PUBLICATIONS INC"
        },
        {
            "Title": "Semi-supervised document clustering with dual supervision through seeding",
            "Publication year": 2012,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/2245276.2245306",
            "Abstract": "Semi-supervised clustering algorithms for general problems use a small amount of labeled instances or pairwise instance constraints to aid the unsupervised clustering. However, user supervision can also be provided in alternative forms for document clustering, such as labeling a feature by associating it with a document or a cluster. Besides labeled documents, this paper also explores labeled features to generate cluster seeds to seed the unsupervised clustering. In this paper, we present a unified framework in which one can use both labeled documents and features in terms of seeding clusters and refine this information using intermediate clusters. We introduce two methods of using labeled features to generate cluster seeds. Experimental results on several real-world data sets demonstrate that constraining the clustering by both documents and features seeding can significantly improve document clustering \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ME8aQywAAAAJ:PR6Y55bgFSsC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Interactive text document clustering using feature labeling",
            "Publication year": 2013,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/2494266.2494279",
            "Abstract": "We propose an interactive text document method, which is based on term labeling. The algorithm asks the user to cluster the top keyterms associated with document clusters iteratively. The keyterm clusters are used to guide the clustering method. Rather than using standard clustering algorithms, we propose a new text clusterer using term clusters. Terms that exist in a document corpus are clustered. Using a greedy approach, the term clusters are distilled in order to remove non-discriminative general terms. We then present a heuristic approach to extract seed documents associated with each distilled term cluster. These seeds are finally used to cluster all documents. We compared our interactive term labeling to a baseline interactive term selection algorithm on some real standard text datasets. The experiments show that with a comparable amount of user effort, our term labeling is more effective than the baseline \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ME8aQywAAAAJ:tH6gc1N1XXoC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Summarizing web sites automatically",
            "Publication year": 2003,
            "Publication url": "https://link.springer.com/chapter/10.1007/3-540-44886-1_22",
            "Abstract": "This research is directed towards automating the Web Site summarization task. To achieve this objective, an approach, which applies machine learning and natural language processing techniques, is employed. The automatically generated summaries are compared to manually constructed summaries from DMOZ Open Directory Project. The comparison is performed via a formal evaluation process involving human subjects. Statistical evaluation of the results demonstrates that the automatically generated summaries are as informative as human authored DMOZ summaries and significantly more informative than home page browsing or time limited site browsing.",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:vV6vV6tmYwMC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "Reddit temporal n-gram corpus and its applications on paraphrase and semantic similarity in social media using a topic-based latent semantic analysis",
            "Publication year": 2016,
            "Publication url": "https://www.aclweb.org/anthology/C16-1335.pdf",
            "Abstract": "This paper introduces a new large-scale n-gram corpus that is created specifically from social media text. Two distinguishing characteristics of this corpus are its monthly temporal attribute and that it is created from 1.65 billion comments of user-generated text in Reddit. The usefulness of this corpus is exemplified and evaluated by a novel Topic-based Latent Semantic Analysis (TLSA) algorithm. The experimental results show that unsupervised TLSA outperforms all the state-of-the-art unsupervised and semi-supervised methods in SEMEVAL 2015: paraphrase and semantic similarity in Twitter tasks.",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:w0F2JDEymm0C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Active learning for medical code assignment",
            "Publication year": 2021,
            "Publication url": "https://arxiv.org/abs/2104.05741",
            "Abstract": "Machine Learning (ML) is widely used to automatically extract meaningful information from Electronic Health Records (EHR) to support operational, clinical, and financial decision-making. However, ML models require a large number of annotated examples to provide satisfactory results, which is not possible in most healthcare scenarios due to the high cost of clinician-labeled data. Active Learning (AL) is a process of selecting the most informative instances to be labeled by an expert to further train a supervised algorithm. We demonstrate the effectiveness of AL in multi-label text classification in the clinical domain. In this context, we apply a set of well-known AL methods to help automatically assign ICD-9 codes on the MIMIC-III dataset. Our results show that the selection of informative instances provides satisfactory classification with a significantly reduced training set (8.3\\% of the total instances). We conclude that AL methods can significantly reduce the manual annotation cost while preserving model performance.",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:MIg0yeAD4ggC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Contextualized Knowledge Base Sense Embeddings in Word Sense Disambiguation",
            "Publication year": 2021,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-030-86159-9_12",
            "Abstract": "Contextualized sense embedding has been shown to carry useful semantic information to improve the final results of various Natural Language Processing tasks. However, it is still challenging to integrate them with the information of the knowledge base, which is one lack in current state-of-the-art representations. This integration is helpful in NLP tasks, specifically in the lexical ambiguity problem. In this paper, we present C-KASE (Contextualized-Knowledge base Aware Sense Embedding), a novel approach to producing sense embeddings for the lexical meanings within a lexical knowledge base. The novel difference of our representation is the integration of the knowledge base information and the input text. This representation lies in a space that is comparable to that of contextualized word vectors. C-KASE representations enable a simple 1-Nearest-Neighbour algorithm to perform as well as state-of \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ME8aQywAAAAJ:KWzIFqRkAKkC",
            "Publisher": "Springer, Cham"
        },
        {
            "Title": "Characterizing and mining the citation graph of the computer science literature",
            "Publication year": 2004,
            "Publication url": "https://link.springer.com/article/10.1007/s10115-003-0128-3",
            "Abstract": "Citation graphs representing a body of scientific literature convey measures of scholarly activity and productivity. In this work we present a study of the structure of the citation graph of the computer science literature. Using a web robot we built several topic-specific citation graphs and their union graph from the digital library ResearchIndex. After verifying that the degree distributions follow a power law, we applied a series of graph theoretical algorithms to elicit an aggregate picture of the citation graph in terms of its connectivity. We discovered the existence of a single large weakly-connected and a single large biconnected component, and confirmed the expected lack of a large strongly-connected component. The large components remained even after removing the strongest authority nodes or the strongest hub nodes, indicating that such tight connectivity is widespread and does not depend on a small \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ME8aQywAAAAJ:roLk4NBRz8UC",
            "Publisher": "Springer-Verlag"
        },
        {
            "Title": "Hierarchical Clustering in Medical Document Collections: the BIC-Means Method.",
            "Publication year": 2010,
            "Publication url": "http://www.dline.info/fpaper/jdim/v8i2/1.pdf",
            "Abstract": "Hierarchical clustering of text collections is a key problem in document management and retrieval. In partitional hierarchical clustering, which is more efficient than its agglomerative counterpart, the entire collection is split into clusters and the individual clusters are further split until a heuristicallymotivated termination criterion is met. In this paper, we define the BIC-means algorithm, which applies the Bayesian Information Criterion (BIC) as a domain independent termination criterion for partitional hierarchical clustering. We evaluate the effectiveness of BIC-means in clustering and retrieval on medical document collections and we propose a dynamic version of the BIC-Means algorithm for adapting an existing clustering solution to document additions.",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:yB1At4FlUx8C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Clinically significant information extraction from radiology reports",
            "Publication year": 2017,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/3103010.3103023",
            "Abstract": "Radiology reports are one of the most important medical documents that a diagnostician looks into, especially in the emergency context. They provide the emergency physicians with critical information regarding the condition of the patient and help the physicians take immediate action on urgent conditions. However, the reports are in the form of unstructured text, which makes them time consuming for humans to interpret. We have developed a machine learning system to (a) efficiently extract the clinically significant parts and their level of importance in radiology reports, and (b) to classifies the overall report into critical or non-critical categories which help doctors to identify potential high priority reports. As a starting point, the system uses anonymized chest X-RAY reports of adults and provides three levels of importance for medical phrases. We used the Conditional Random Field (CRF) model to identify clinically \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ME8aQywAAAAJ:3bvyWxjaHKcC",
            "Publisher": "Unknown"
        },
        {
            "Title": "BiRD: a strategy to autonomously supplement clinical practice guidelines with related clinical studies",
            "Publication year": 2005,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/1385521/",
            "Abstract": "In this paper we introduce a framework to supplement and tag computerized CPG with related best-evidence automatically sourced from on-line medical literature repositories. The idea is to provide CPG users with additional published evidence pertaining to the different sections of a CPG of their interest. We present a web-enabled Best-evidence Retrieval and Delivery (BiRD) system that autonomously retrieves pertinent medical literature with respect to user-specified content from a GEM-encoded CPG. This is achieved via a multi-level literature search strategy that uses the actual CPG content to autonomously generate a search query. The featured search strategy firstly categorizes the search query towards a priori defined clinical query subjects and secondly filters out insignificant medical terms from the search query. The technical architecture comprises existing medical language processing tools and \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ME8aQywAAAAJ:yD5IFk8b50cC",
            "Publisher": "IEEE"
        },
        {
            "Title": "A comparative study on key phrase extraction methods in automatic web site summarization",
            "Publication year": 2007,
            "Publication url": "https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.259.4842&rep=rep1&type=pdf",
            "Abstract": "Web Site Summarization is the process of automatically generating a concise and informative summary for a given Web site. It has gained more and more attention in recent years as effective summarization could lead to enhanced Web information retrieval systems such as searching for Web sites. Extraction-based approaches to Web site summarization rely on the extraction of the most significant sentences from the target Web site based on the density of a list of key phrases that best describe the entire Web site. In this work, we benchmark five alternative key phrase extraction methods, TFIDF, KEA, Keyword, Keyterm, and Mixture, in an automatic Web site summarization framework we previously developed. We investigate the performance of these underlying methods via a formal user study and demonstrate that Keyterm is the best choice for key phrase extraction while Mixture should be used to obtain key sentences. We also discuss why one method performs better than another and what could be done to further improve the summarization system.",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:mvPsJ3kp5DgC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Sonel mapping: A stochastic acoustical modeling system",
            "Publication year": 2006,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/1661302/",
            "Abstract": "Modeling the acoustics of an environment is a complex and challenging task. Here we describe the sonel mapping approach to acoustical rendering. Sonel mapping is a Monte-Carlo-based approach to modeling diffuse, specular, absorption and diffraction effects in an efficient manner. The approach models many of the subtle interaction effects required for realistic acoustical modeling, and the approach is computationally efficient allowing it to be used to acoustically model interactive virtual environments",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:pyW8ca7W8N0C",
            "Publisher": "IEEE"
        },
        {
            "Title": "Eyes'n ears: Face detection utilizing audio and video cues",
            "Publication year": 2001,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/938918/",
            "Abstract": "This work investigates the development of a robust and portable teleconferencing system utilizing both audio and video cues. An omnidirectional video sensor is used to provide a view of the entire visual hemisphere thereby providing multiple dynamic views of the participants. Regions of skin are detected using simple statistical methods, along with histogram color models for both skin and non-skin color classes. Skin regions belonging to the same person are grouped together. Using simple geometrical properties, the location of each person's face in the \"real world\" is estimated and provided to the audio system as a possible sound source direction. Beamforming and sound detection techniques with a small, compact microphone array allows the audio system to detect and attend to the speech of each participant, thereby reducing unwanted noise and sounds emanating from other locations. The results of \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ME8aQywAAAAJ:J-pR_7NvFogC",
            "Publisher": "IEEE"
        },
        {
            "Title": "System state discovery via information content clustering of system logs",
            "Publication year": 2011,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/6045954/",
            "Abstract": "Self-awareness is an important attribute for any system to have before it is capable of self-management. A system needs to have a continuous stream of real-time data to analyze to allow it be aware of its internal state. To this end, previous approaches have utilized system performance metrics and system log data to characterize system internal state. In using system logs to characterize system internal state, the computation of strongly correlated message types is necessary. In this work, we show that strongly correlated message types can be easily discovered without much computation. Our work explores a natural behaviour of system logs where system log data partitioned using source and time information contain correlated message types. We demonstrate how the groups of partitions, which contain correlated message types, can be found by clustering the partitions based on their entropy-based information \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ME8aQywAAAAJ:WA5NYHcadZ8C",
            "Publisher": "IEEE"
        },
        {
            "Title": "Tulip: Lightweight entity recognition and disambiguation using wikipedia-based topic centroids",
            "Publication year": 2014,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/2633211.2634351",
            "Abstract": "This article presents Tulip, an ERD system submitted to the ERD 2014: Entity Recognition and Disambiguation Challenge. The objective of the proposed system is to spot mentions of entities in a document and link the mentions to corresponding Freebase articles. To achieve it, Tulip prunes the set of entity candidates focusing on a core subset of related entities capturing the context of the document. The relationship strength is measured as a similarity to a topic centroid generated from entity features. Each entity is represented by an accurate and compact feature vector extracted from a category graph built based on information from 120 language versions of Wikipedia. Given the core set of accepted entities Tulip uses the Wikipedia-based feature vectors to extract more related entities from the document text. Tulip received the first prize in the long document track with F1 score of 0.74, which confirms the \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ME8aQywAAAAJ:wMgC3FpKEyYC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Semantic similarity methods in wordnet and their application to information retrieval on the web",
            "Publication year": 2005,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/1097047.1097051",
            "Abstract": "Semantic Similarity relates to computing the similarity between concepts which are not lexicographically similar. We investigate approaches to computing semantic similarity by mapping terms (concepts) to an ontology and by examining their relationships in that ontology. Some of the most popular semantic similarity methods are implemented and evaluated using WordNet as the underlying reference ontology. Building upon the idea of semantic similarity, a novel information retrieval method is also proposed. This method is capable of detecting similarities between documents containing semantically similar but not necessarily lexicographically similar terms. The proposed method has been evaluated in retrieval of images and documents on the Web. The experimental results demonstrated very promising performance improvements over state-of-the-art information retrieval methods.",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:Tyk-4Ss8FVUC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Atr-vis: Visual and interactive information retrieval for parliamentary discussions in twitter",
            "Publication year": 2018,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/3047010",
            "Abstract": "The worldwide adoption of Twitter turned it into one of the most popular platforms for content analysis as it serves as a gauge of the public\u2019s feeling and opinion on a variety of topics. This is particularly true of political discussions and lawmakers\u2019 actions and initiatives. Yet, one common but unrealistic assumption is that the data of interest for analysis is readily available in a comprehensive and accurate form. Data need to be retrieved, but due to the brevity and noisy nature of Twitter content, it is difficult to formulate user queries that match relevant posts that use different terminology without introducing a considerable volume of unwanted content. This problem is aggravated when the analysis must contemplate multiple and related topics of interest, for which comments are being concurrently posted. This article presents Active Tweet Retrieval Visualization (ATR-Vis), a user-driven visual approach for the retrieval of \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ME8aQywAAAAJ:uVUOdF_882EC",
            "Publisher": "ACM"
        },
        {
            "Title": "Link-based anomaly detection in communication networks",
            "Publication year": 2008,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/4740808/",
            "Abstract": "Communication networks, such as networks formed by phone calls and email communications, can be modeled as dynamic graphs with vertices representing agents and edges representing communications. Anomaly detection is to identify abnormal behaviour occurring in these networks. This is crucial for anti-terrorism, resource allocation and network management. The contents of the communications are often unavailable or protected by regulations or encryption, which makes linkage information the only type of data we can rely on in order to identify anomalies. In this paper, we propose a link-based anomaly detection method that considers deviations from individual patterns by taking into account the behaviour pattern of the cluster to which the individual belongs. Clusters can be formed by a standard clustering procedure or based on a specific attribute depending on the dataset. Experiments show that this \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ME8aQywAAAAJ:q3oQSFYPqjQC",
            "Publisher": "IEEE"
        },
        {
            "Title": "A Comparative Study on Key Phrase Extraction Surnmarization",
            "Publication year": 2007,
            "Publication url": "http://web.cs.dal.ca/~eem/res/pubs/pubs/Yongzheng-JDIM-2007.pdf",
            "Abstract": "Web Site Summarization is the process af automatically generating a concise and informative summary for a given Web site. It has gained more and more attention in recent Years as effective summarization could lead to enhanced Web information retrieval systems such as searching for Web sites. Extraction-based approaches to Web sife summarization rely on the extraction of the most significant sentences from the target Web site based on the density of a list of key phrases that best describe the entire Web site. In this wark, we benchmark five alternative key phrase extraction methods, TFIDF, KEA,",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:tuHXwOkdijsC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Message type extraction based alert detection in system logs",
            "Publication year": 2009,
            "Publication url": "https://cdn.dal.ca/content/dam/dalhousie/pdf/faculty/computerscience/technical-reports/CS-2009-08.pdf",
            "Abstract": "The task of alert detection in event logs, ie determining which events in the event log require action from an administrator, is very important in preventing or recovering from downtime events. The ability to do this automatically and accurately provides significant savings in time and cost of downtime events. In this work we combine message type extraction based alert detection with the entropy based approach of the Nodeinfo algorithm, which is in production use at Sandia National Laboratories, to significantly improve its performance. We show that with Message Type Indexing (MTI) and some modifications to the Nodeinfo framework, we can achieve an~ 99% reduction in the computational effort required for Nodeinfo and an F-Measure score of up to 100% in the identification of regions of the event log which contain alerts. Our work demonstrates a practical application of employing MTI on a real world data set using an alert detection framework that is currently in production use in a major government run national laboratory.",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:dshw04ExmUIC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Beyond term clusters: assigning Wikipedia concepts to scientific documents",
            "Publication year": 2013,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/2494266.2494297",
            "Abstract": "We propose a model for assigning Wikipedia Concepts as scientific category labels to scientific documents where their terms are first grouped together using the well-known topic modelling method, Latent Dirichlet Allocation (LDA) and then assigned to Wikipedia Concepts by wikification. We wikify the terms of the topic model of a document to extract related concepts from Wikipedia. We experiment on two different datasets: the abstracts of the documents from the ACM Digital Library and the full papers of the UvT Collection. The ACM dataset includes Computer Science publications whereas UvT includes scientific publications from a range of topics. Domain specific taxonomies are used for evaluation. Results show that our approach is able to assign Wikipedia Concepts to the scientific publications in an automated manner, removing any need for human supervision.",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:gKiMpY-AVTkC",
            "Publisher": "Unknown"
        },
        {
            "Title": "A Constraint-Based Approach for Signal Acquisition Control in Magnetic Resonance Imaging and Spectroscopy (MRI/MRS)",
            "Publication year": 2002,
            "Publication url": "https://cdn.dal.ca/content/dam/dalhousie/pdf/faculty/computerscience/technical-reports/CS-2003-02.pdf",
            "Abstract": "Magnetic resonance imaging technology is one of the most promising investigative and diagnostic methodologies in brain research and in clinical neurological practice. To acquire informative magnetic resonance signals, a variety of equipment parameters require identification. However, depending on which neuronal metabolites and brain tissues are of interest and on what types of clinical or research questions are being asked, the relation between equipment parameters is often complex. This complexity means that computerized tools that can design valid novel settings to control the activities of the magnet during data acquisition would be beneficial. The goal of the present research is to build such a tool using constraint satisfaction based on the constraints associated with different imaging protocols. A constraint-resolving program, which is generated automatically from the constraints provided by the user in text form, enumerates the value domains of the variables, enforces the constraints associated with each possible setting, and produces a complete set of all valid parameter settings for controlling the magnetic device during signal acquisition.",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:UHK10RUVsp4C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Detecting Ongoing Events Using Contextual Word and Sentence Embeddings",
            "Publication year": 2020,
            "Publication url": "https://arxiv.org/abs/2007.01379",
            "Abstract": "This paper introduces the Ongoing Event Detection (OED) task, which is a specific Event Detection task where the goal is to detect ongoing event mentions only, as opposed to historical, future, hypothetical, or other forms or events that are neither fresh nor current. Any application that needs to extract structured information about ongoing events from unstructured texts can take advantage of an OED system. The main contribution of this paper are the following: (1) it introduces the OED task along with a dataset manually labeled for the task; (2) it presents the design and implementation of an RNN model for the task that uses BERT embeddings to define contextual word and contextual sentence embeddings as attributes, which to the best of our knowledge were never used before for detecting ongoing events in news; (3) it presents an extensive empirical evaluation that includes (i) the exploration of different architectures and hyperparameters, (ii) an ablation test to study the impact of each attribute, and (iii) a comparison with a replication of a state-of-the-art model. The results offer several insights into the importance of contextual embeddings and indicate that the proposed approach is effective in the OED task, outperforming the baseline models.",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:AzKEL7Gb_04C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Dark Fiber: Tracking Internet Culture by Geert Lovink",
            "Publication year": 2004,
            "Publication url": "https://scholar.google.com/scholar?cluster=10182484124190584823&hl=en&oi=scholarr",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:kzcSZmkxUKAC",
            "Publisher": "DUKE UNIVERSITY PRESS"
        },
        {
            "Title": "Real time filtering of tweets using wikipedia concepts and google tri-gram semantic relatedness",
            "Publication year": 2015,
            "Publication url": "https://apps.dtic.mil/sti/citations/AD1004733",
            "Abstract": "This paper describes our participation in the mobile notification and email digest tasks in the TREC 2015 Mircoblog track. The tasks are about monitoring Twitter stream and retrieving relevant tweets to users interest profiles. Interest profiles contain the description of a topic that the user is interested in receiving relevant posts in real-time. Our proposed approach extracts Wikipedia concepts for profiles and tweets and applies a corpus-based word semantic relatedness method to assign tweets to their relevant profiles. This approach is also used to determine whether two tweets are semantically similar which in turn prevents the retrieval of redundant tweets.Descriptors:",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:mKu_rENv82IC",
            "Publisher": "Dalhousie University Halifax, NS Canada"
        },
        {
            "Title": "Interactive learning of alert signatures in high performance cluster system logs",
            "Publication year": 2012,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/6211882/",
            "Abstract": "The ability to automatically discover error conditions with little human input is a feature lacking in most modern computer systems and networks. However, with the ever increasing size and complexity of modern systems, such a feature will become a necessity in the not too distant future. Our work proposes a hybrid framework that allows High Performance Clusters (HPC) to detect error conditions in their logs. Through the use of anomaly detection, the system is able to detect portions of the log that are likely to contain errors (anomalies). Via visualization, human administrators can inspect these anomalies and assign labels to clusters that correlate with error conditions. The system can then learn a signature from the confirmed anomalies, which it uses to detect future occurrences of the error condition. Our evaluations show the system is able to generate simple and accurate signatures using very little data.",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:kz9GbA2Ns4gC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Time series classification for rumor detection",
            "Publication year": 2021,
            "Publication url": "https://digital-library.theiet.org/content/conferences/10.1049/icp.2021.1466",
            "Abstract": "The automatic detection of rumors in social networks has gained considerable attention from researchers and practitioners during the last decade, due to the consequences of the spread of disinformation in public opinion. Most of the existing methods make use of features extracted from conversational threads, user profiles, and structural information of the network. These features are difficult to capture in practice and are often only partially available during the spread of rumors. In this paper, we study an unexplored approach in rumor detection: time series classification (TSC). By modeling the problem using time series, we avoid using lexical or structural characteristics of the network. Instead, we use information that is simpler to capture, such as the volume of tweets and the number of followers and followees of the users involved in a story. In this way, the characterization of the story is not related to specific users \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ME8aQywAAAAJ:RuPIJ_LgqDgC",
            "Publisher": "IET Digital Library"
        },
        {
            "Title": "Proximity based one-class classification with Common N-Gram dissimilarity for authorship verification task",
            "Publication year": 2013,
            "Publication url": "https://projects.cs.dal.ca/visualtextanalytics/wp-content/uploads/_mediavault/2014/09/author_verification_general_2014-09.pdf",
            "Abstract": "Proximity based one-class classification with Common N-Gram dissimilarity for authorship \nverification task Page 1 Proximity based one-class classification with Common N-Gram \ndissimilarity for authorship verification task Magdalena Jankowska, Vlado Ke\u0161elj and Evangelos \nMilios Faculty of Computer Science, Dalhousie University September 2014 Page 2 Example \n\"The Cuckoo's Calling\u201c 2013 detective novel by Robert Galbraith Page 3 Example \"The \nCuckoo's Calling\u201c 2013 detective novel by Robert Galbraith Question by Sundays Times Was \n\u201cThe Cuckoo\u2019s Calling\u201d really written by JK Rowling? Peter Millican and Patrick Juola requested \n(independently) to answer this question through their algorithmic methods Results indicative of \nthe positive answer JK Rowling admitted that she is the author Page 4 \ud835\udc62 \ud835\udc68 Set of \u201cknown\u201d \ndocuments by a given author \u201cunknown\u201d document document of a questioned authorship Input: ,\u2026",
            "Abstract entirety": 0,
            "Author pub id": "ME8aQywAAAAJ:artPoR2Yc-kC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Focused crawling by learning HMM from user's topic-specific browsing",
            "Publication year": 2004,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/1410908/",
            "Abstract": "A focused crawler is designed to traverse the Web to gather documents on a specific topic. It is not an easy task to predict which links lead to good pages. In this paper, we present a new approach for prediction of the important links to relevant pages based on a learned user model. In particular, we first collect pages that a user visits during a learning session, where the user browses the Web and specifically marks which pages she is interested in. We then examine the semantic content of these pages to construct a concept graph, which is used to learn the dominant content and link structure leading to target pages using a Hidden Markov Model (HMM). Experiments show that with learned HMM from a user's browsing, the crawling performs better than Best-First strategy.",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:r0BpntZqJG4C",
            "Publisher": "IEEE"
        },
        {
            "Title": "f: Phrase Relatedness Function Using Overlapping Bi-gram Context",
            "Publication year": 2016,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-319-34111-8_19",
            "Abstract": "We present an unsupervised phrase relatedness function (f) that has been applied in a Semantic Textual Similarity system (TrWP) of SemEval-2015. The best run of TrWP was ranked 33 among 73 runs. f finds the relatedness strength between two phrases using overlapping bi-gram context extracted from the Google-n-gram corpus. The relatedness strength is the strength of association capturing how similar or dissimilar two phrases are. In order to find the relatedness strength, f applies a sum-ratio (SR) technique based on the statistics of the overlapping n-grams associated with two input phrases. The experimental result from f demonstrates improvement over existing phrase relatedness methods on two standard datasets of 216 phrase-pairs. f does not require any human annotated resource and is independent of the syntactic structure of phrases.",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:Ade32sEp0pkC",
            "Publisher": "Springer, Cham"
        },
        {
            "Title": "An offline\u2013online visual framework for clustering memes in social media",
            "Publication year": 2017,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-319-51367-6_1",
            "Abstract": "The amount of data generated in Online Social Networks (OSNs) is increasing every day. Extracting and understanding trending topics and events from the vast amount of data is an important area of research in OSNs. This paper proposes a novel clustering framework to detect the spread of memes in OSNs in real time. The Offline\u2013Online meme clustering framework exploits various similarity scores between different elements of Reddit submissions, two strategies to combine those scores based on Wikipedia concepts as an external knowledge, text semantic similarity and a modified version of Jaccard Coefficient. The two combination strategies include: (1) automatically computing the similarity score weighting factors for five elements of a submission and (2) allowing users to engage in the clustering process and filter out outlier submissions, modify submission class labels, or assign different similarity score \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ME8aQywAAAAJ:-95Q15plzcUC",
            "Publisher": "Springer, Cham"
        },
        {
            "Title": "Searching for logo and trademark images on the web",
            "Publication year": 2007,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/1282280.1282358",
            "Abstract": "This work shows that it is possible to exploit text and image content characteristics of logo and trademark images in Web pages for enhancing the performance of retrievals on the Web. Searching for important (authoritative) Web pages and images is a desirable feature of many Web search engines and is also taken into account. State-of-the-art methods for assigning higher ranking to important Web pages, over other Web pages satisfying the query selection criteria, are considered and evaluated. PicASHOW exploits this idea in retrieval of important images on the Web using link information alone. WPicASHOW (Weighted PicASHOW), is a weighted scheme for co-citation analysis incorporating within the link analysis method of PicASHOW the text and image content of the queries and of the Web pages. The experimental results demonstrate that Web search methods utilizing content information (or combination of \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ME8aQywAAAAJ:B3FOqHPlNUQC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Vision data registration for robot self-localization in 3D",
            "Publication year": 2005,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/1545433/",
            "Abstract": "We address the problem of globally consistent estimation of the trajectory of a robot arm moving in three dimensional space based on a sequence of binocular stereo images from a stereo camera mounted on the tip of the arm. Correspondence between 3D points from successive stereo camera positions is established through matching of 2D SIFT features in the images. We compare three different methods for solving this estimation problem, based on three distance measures between 3D points, Euclidean distance, Mahalanobis distance and a distance measure defined by a maximum likelihood formulation. Theoretical analysis and experimental results demonstrate that the maximum likelihood formulation is the most accurate. If the measurement error is guaranteed to be small, then Euclidean distance is the fastest, without significantly compromising accuracy, and therefore it is best for on-line robot navigation.",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:K3LRdlH-MEoC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Statistical learning for OCR error correction",
            "Publication year": 2018,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S0306457317307823",
            "Abstract": "Modern OCR engines incorporate some form of error correction, typically based on dictionaries. However, there are still residual errors that decrease performance of natural language processing algorithms applied to OCR text. In this paper, we present a statistical learning model for post-processing OCR errors, either in a fully automatic manner or followed by minimal user interaction to further reduce error rate. Our model employs web-scale corpora and integrates a rich set of linguistic features. Through an interdependent learning pipeline, our model produces and continuously refines the error detection and suggestion of candidate corrections. Evaluated on a historical biology book with complex error patterns, our model outperforms various baseline methods in the automatic mode and shows an even greater advantage when involving minimal user interaction. Quantitative analysis of each computational step \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ME8aQywAAAAJ:SGW5VrABaM0C",
            "Publisher": "Pergamon"
        },
        {
            "Title": "Robust learning intrusion detection for attacks on wireless networks",
            "Publication year": 2011,
            "Publication url": "https://content.iospress.com/articles/intelligent-data-analysis/ida00496",
            "Abstract": "We address the problem of evaluating the robustness of machine learning based detectors for deployment in real life networks. To this end, we employ Genetic Programming for evolving classifiers and Artificial Neural Networks as our machine learning paradigms under three different Denial-of-Service attacks at the Data Link layer (De-authentication, Authentication and Association attacks). We investigate their cross-platform robustness and cross-attack robustness. Cross-platform robustness is the ability to seamlessly port an Intrusion Detector trained on one network to another network with little or no change and without a drop in performance. Cross-attack robustness is the ability of a detector trained on one attack type to detect a different but similar attack on which it has not been trained. Our results show that the potential of a machine learning based detector can be significantly enhanced or limited by the \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ME8aQywAAAAJ:lmc2jWPfTJgC",
            "Publisher": "IOS Press"
        },
        {
            "Title": "Characterizing and Mining the Citation Graph of the Computer",
            "Publication year": 2001,
            "Publication url": "https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.18.298&rep=rep1&type=pdf",
            "Abstract": "Citation graphs representing a body of scientific literature convey measures of scholarly activity and productivity. In this work we present a study of the structure of the citation graph of computer science literature. Using a web robot we build several citation graphs from parts of the digital library fesearch lr\u0131dex. After verifying that the degree distributions follow a power law, we apply a series of graph theoretical algorith rns to elicit an aggregate picture of the citation graph in terms of its connectivity.",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:YlPif8NxrbYC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Automatic recognition of regions of intrinsically poor multiple alignment using machine learning",
            "Publication year": 2003,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/1227381/",
            "Abstract": "Phylogenetic analysis requires alignment of gene or protein sequences. Some regions of genes evolve fast and suffer numerous insertion and deletion events and cannot be aligned reliably with automatic alignment algorithms. Such regions of intrinsically uncertain alignment are currently detected and deleted manually before performing phylogenetic analysis. We present the results of a machine learning approach to detect regions of poor alignment automatically. We compare the results obtained from Naive Bayes (NB), C4.5 decision tree (C4.5) and support vector machine (SVM) approaches.",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:NhqRSupF_l8C",
            "Publisher": "IEEE"
        },
        {
            "Title": "Exploiting multiple features with memms for focused web crawling",
            "Publication year": 2008,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-540-69858-6_11",
            "Abstract": "Focused web crawling traverses the Web to collect documents on a specific topic. This is not an easy task, since focused crawlers need to identify the next most promising link to follow based on the topic and the content and links of previously crawled pages. In this paper, we present a framework based on Maximum Entropy Markov Models(MEMMs) for an enhanced focused web crawler to take advantage of richer representations of multiple features extracted from Web pages, such as anchor text and the keywords embedded in the link URL, to represent useful context. The key idea of our approach is to treat the focused web crawling problem as a sequential task and use a combination of content analysis and link structure to capture sequential patterns leading to targets. The experimental results showed that focused crawling using MEMMs is a very competitive crawler in general over Best-First crawling on \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ME8aQywAAAAJ:4fKUyHm3Qg0C",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "Navigation with IMU/GPS/digital compass with unscented Kalman filter",
            "Publication year": 2005,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/1626777/",
            "Abstract": "Autonomous vehicle navigation with standard IMU and differential GPS has been widely used for aviation and military applications. Our research interesting is focused on using some low-cost off-the-shelf sensors, such as strap-down IMU, inexpensive single GPS receiver. In this paper, we present an autonomous vehicle navigation method by integrating the measurements of IMU, GPS, and digital compass. Two steps are adopted to overcome the low precision of the sensors. The first is to establish sophisticated dynamics models which consider Earth self rotation, measurement bias, and system noise. The second is to use a sigma Kalman filter for the system state estimation, which has higher accuracy compared with the extended Kalman filter. The method was evaluated by experimenting on a land vehicle equipped with IMU, GPS, and digital compass.",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:Zph67rFs4hoC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Evangelos Milios (Draft Profile)",
            "Publication year": 2013,
            "Publication url": "https://scholar.google.com/scholar?cluster=1223445590488625403&hl=en&oi=scholarr",
            "Abstract": "Evangelos Milios received a diploma in Electrical Engineering from the National Technical University of Athens, Greece, in 1980 and Master's and Ph. D. degrees in Electrical Engineering and Computer Science from the Massachusetts Institute of Technology, Cambridge, Massachusetts, from where he graduated in 1986. While at MIT, he was a member of Digital Signal Processing group and he worked on acoustic signal interpretation problems at the MIT Lincoln Laboratory. After spending 5 years doing research on shape analysis and sensor-based mobile robotics in the Department of Computer Science, University of Toronto, he joined York University in 1991 as an Associate Professor. Since July of 1998 he has been with the Faculty of Computer Science, Dalhousie University, Halifax, Nova Scotia, where he is Professor and Killam Chair of Computer Science. He served as Director of the Graduate Program (1999-2002) and he is currently Associate Dean, Research. He is a Senior Member of the IEEE. He was a member of the ACM Dissertation Award committee (1990-1992), a member of the AAAI/SIGART Doctoral Consortium Committee (1997-2001) and he is co-editor-in-chief of the journal Computational Intelligence. He has published on the processing, interpretation and use of visual and range signals for landmark-based navigation and map construction in single-and multiagent robotics. His current research activity is centered on modelling and mining of content and link structure of Networked Information Spaces.",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:LPtt_HFRSbwC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Information retrieval by semantic similarity",
            "Publication year": 2006,
            "Publication url": "https://www.igi-global.com/article/information-retrieval-semantic-similarity/2824",
            "Abstract": "Semantic Similarity relates to computing the similarity between conceptually similar but not necessarily lexically similar terms. Typically, semantic similarity is computed by mapping terms to an ontology and by examining their relationships in that ontology. We investigate approaches to computing the semantic similarity between natural language terms (using WordNet as the underlying reference ontology) and between medical terms (using the MeSH ontology of medical and biomedical terms). The most popular semantic similarity methods are implemented and evaluated using WordNet and MeSH. Building upon semantic similarity, we propose the Semantic Similarity based Retrieval Model (SSRM), a novel information retrieval method capable for discovering similarities between documents containing conceptually similar terms. The most effective semantic similarity method is implemented into SSRM. SSRM has \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ME8aQywAAAAJ:Se3iqnhoufwC",
            "Publisher": "IGI Global"
        },
        {
            "Title": "Multi-robot collaboration for robust exploration",
            "Publication year": 2001,
            "Publication url": "https://link.springer.com/article/10.1023/A:1016636024246",
            "Abstract": "This paper presents a new sensing modality for multirobot exploration. The approach is based on using a pair of robots that observe each other, and act in concert to reduce odometry errors. We assume the robots can both directly sense nearby obstacles and see each other. The proposed approach improves the quality of the map by reducing the inaccuracies that occur over time from dead reckoning errors. Furthermore, by exploiting the ability of the robots to see each other, we can detect opaque obstacles in the environment independently of their surface reflectance properties. Two different algorithms, based on the size of the environment, are introduced, with a complexity analysis, and experimental results in simulation and with real robots.",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:qjMakFHDy7sC",
            "Publisher": "Kluwer Academic Publishers"
        },
        {
            "Title": "Self-organizing peer-to-peer networks for collaborative document tracking",
            "Publication year": 2009,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/1651274.1651287",
            "Abstract": "Given a set of peers with overlapping interests where each peer wishes to keep track of new documents that are relevant to their interests, we propose a self-organizing peer-to-peer document-tracking network based on common interest profiles. The goal of a document-tracking network is to disseminate new documents as they are published. Peers collaboratively share new documents of interest with other peers. There is no explicit profile exchange between peers and no global information available. We describe a strategy for peers to discover the existence of other peers and learn about their interests locally, based on information carried in the document metadata that propagates through the network. Peers are connected based on their observed common interests. We compare our proposed common interest strategy with a randomly connected network. The experimental results, based on simulated environment \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ME8aQywAAAAJ:_B80troHkn4C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Large-scale web page classification",
            "Publication year": 2014,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/6758827/",
            "Abstract": "This research investigates the design of a unified framework for the content-based classification of highly imbalanced hierarchical datasets, such as web directories. In an imbalanced dataset, the prior probability distribution of a category indicates the presence or absence of class imbalance. This may include the lack of positive training instances (rarity) or an overabundance of positive instances. We partitioned the subcategories of the Yahoo! web directory into five mutually exclusive groups based on the prior probability distribution. The best performing classification methods for a particular prior probability distribution were identified and used to design a content-based classification model for the complete (as of 2007) Yahoo! web directory of 639,671 categories and 4,140,629 web pages. The methodology was validated using a DMOZ subset of 17,217 categories and 130,594 web pages and we demonstrated \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ME8aQywAAAAJ:4xDN1ZYqzskC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Enhancement of Short Text Clustering by Iterative Classification",
            "Publication year": 2020,
            "Publication url": "https://books.google.com/books?hl=en&lr=&id=cSbsDwAAQBAJ&oi=fnd&pg=PA103&dq=info:N2FQ79sZ70QJ:scholar.google.com&ots=mERpUqH3Ed&sig=T1d81MZHHfK_f5ZQbZFry68gLuU",
            "Abstract": "Short text clustering is a challenging task due to the lack of signal contained in short texts. In this work, we propose iterative classification as a method to boost the clustering quality of short texts. The idea is to repeatedly reassign (classify) outliers to clusters until the cluster assignment stabilizes. The classifier used in each iteration is trained using the current set of cluster labels of the non-outliers; the input of the first iteration is the output of an arbitrary clustering algorithm. Thus, our method does not require any human-annotated labels for training. Our experimental results show that the proposed clustering enhancement method not only improves the clustering quality of different baseline clustering methods (eg, k-means, k-means--, and hierarchical clustering) but also outperforms the state-of-the-art short text clustering methods on several short text datasets by a statistically significant margin.",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:v6i8RKmR8ToC",
            "Publisher": "Springer Nature"
        },
        {
            "Title": "Interactive document clustering using iterative class-based feature selection",
            "Publication year": 2010,
            "Publication url": "https://www.academia.edu/download/40153090/Interactive_Document_Clustering_Using_It20151118-3537-6iwoo2.pdf",
            "Abstract": "Semi-supervised clustering has been found to improve clustering performance by using constraints between documents. Recent research in active learning indicates that feature identification, which takes much less user effort than document labeling, can improve classification performance. We aim to use this new finding to improve document clustering. We first propose an unsupervised clustering framework which involves an iterative updating of the feature set. Users are then invited to help update the feature set by identifying good features. Experiments on various datasets indicate that the performance of document clustering may improve significantly with some user input. In addition, the clustering performance increases initially and then stabilizes with more user effort. Feature reweighting, which gives higher weights to features confirmed by the users, can achieve better clustering performance with less user effort. Based on our experiments, several guidelines are suggested for applying the interactive framework.",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:t6usbXjVLHcC",
            "Publisher": "Technical report, CS-2010-04, Faculty of Computer Science, Dalhousie University, Canada"
        },
        {
            "Title": "Using Molecular Embeddings in QSAR Modeling: Does it Make a Difference?",
            "Publication year": 2021,
            "Publication url": "https://arxiv.org/abs/2104.02604",
            "Abstract": "Several novel algorithms for learning molecular representations have been proposed recently with the consolidation of deep learning in computer-aided drug design. Learned molecular embeddings allow attaining rich representations of the molecular structure and physical-chemical properties while overcoming several limitations of traditional molecular representations. Despite their theoretical benefits, it is not clear how molecular embeddings compare with each other and with traditional representations, which in turn hinders the process of choosing a suitable embedding algorithm for QSAR modeling. A reason for this lack of consensus is that a fair and thorough comparison of different approaches is not straightforward. To close this gap, we reproduced three unsupervised and two supervised molecular embedding techniques recently proposed in the literature. Through a thorough experimental setup, we compared the molecular representations of these five methods concerning their performance in QSAR scenarios using five different datasets with varying class imbalance levels. We also compared these representations to traditional molecular representations, namely molecular descriptors and fingerprints. Our results show that molecular embeddings did not significantly surpass baseline results obtained using traditional molecular representations. While supervised techniques yielded competitive results compared to those obtained by traditional molecular representations, unsupervised techniques did not match the baseline results. Our results motivate a discussion about the usefulness of molecular embeddings in QSAR modeling and their \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ME8aQywAAAAJ:z6xuaG2dYH0C",
            "Publisher": "Unknown"
        },
        {
            "Title": "IntelliSearch: Intelligent Search for Images and Text on the Web",
            "Publication year": 2006,
            "Publication url": "https://link.springer.com/chapter/10.1007/11867586_64",
            "Abstract": " IntelliSearch is a complete and fully automated information retrieval system for the Web. It supports fast and accurate responses to queries addressing text and images in Web pages by incorporating state-of-the-art text and Web link information indexing and rertieval methods in conjunction with efficient ranking of Web pages and images by importance (authority). Searching by semantic similarity for discovering information related to user\u2019s requests (but not explicitly specified in the queries) is a distinguishing feature of the system. IntelliSearch stores a crawl of the Web with more than 1,5 million Web pages with images and is accessible on the Internet. It offers an ideal test-bed for experimentation and training and serves as a framework for a realistic evaluation of many Web image retrieval methods.",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:XiSMed-E-HIC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "An evolutionary subspace clustering algorithm for high-dimensional data",
            "Publication year": 2012,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/2330784.2331011",
            "Abstract": "We present an algorithm for generating subspace clusterings of large data sets with many attributes. An evolutionary algorithm is used to form groups of relevant attributes. Those groups are replaced by their centroids, making it possible to cluster the objects in a much lower dimensional space. Preliminary experiments with scalable synthetic data sets suggest that the algorithm generates competitive clusterings while scaling quite well.",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:bz8QjSJIRt4C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Term-based clustering and summarization of web page collections",
            "Publication year": 2004,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-540-24840-8_5",
            "Abstract": "Effectively summarizing Web page collections becomes more and more critical as the amount of information continues to grow on the World Wide Web. A concise and meaningful summary of a Web page collection, which is generated automatically, can help Web users understand the essential topics and main contents covered in the collection quickly without spending much browsing time. However, automatically generating coherent summaries as good as human-authored summaries is a challenging task since Web page collections often contain diverse topics and contents. This research aims towards clustering of Web page collections using automatically extracted topical terms, and automatic summarization of the resulting clusters. We experiment with word- and term-based representations of Web documents and demonstrate that term-based clustering significantly outperforms word-based clustering \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ME8aQywAAAAJ:ns9cj8rnVeAC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "DalGTM at SemEval-2016 task 1: importance-aware compositional approach to short text similarity",
            "Publication year": 2016,
            "Publication url": "https://www.aclweb.org/anthology/S16-1118.pdf",
            "Abstract": "This paper describes our system submission to the SemEval 2016 English Semantic Textual Similarity (STS) shared task. The proposed system is based on the compositional text similarity model, which aggregates pairwise word similarities for computing the semantic similarity between texts. In addition, our system combines word importance and word similarity to build an importance-similarity matrix. Three different word similarity measures are used in our three submitted runs. The evaluation results show that taking into account context dependent word importance information improves performance. However, the performance of the system varies drastically between different evaluation subsets. The best of our submitted runs achieves rank 60th with weighted mean Pearson correlation to human judgements of 0.6892.",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:q-HalDI95KYC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Efficient Clustering of Short Text Streams using Online-Offline Clustering",
            "Publication year": 2021,
            "Publication url": "https://www.researchgate.net/profile/Md-Rashadul-Hasan-Rakib/publication/352413688_Efficient_Clustering_of_Short_Text_Streams_using_Online-Offline_Clustering/links/60c8f38d458515dcee92d5c3/Efficient-Clustering-of-Short-Text-Streams-using-Online-Offline-Clustering.pdf",
            "Abstract": "Short text stream clustering is an important but challenging task since massive amount of text is generated from different sources such as micro-blogging, question-answering, and social news aggregation websites. The two major challenges of clustering such massive amount of text is to cluster them within a reasonable amount of time and to achieve better clustering result. To overcome these two challenges, we propose an efficient short text stream clustering algorithm (called EStream) consisting of two modules: online and offline. The online module of EStream algorithm assigns a text to a cluster one by one as it arrives. To assign a text to a cluster it computes similarity between a text and a selected number of clusters instead of all clusters and thus significantly reduces the running time of the clustering of short text streams. EStream assigns a text to a cluster (new or existing) using the dynamically computed similarity thresholds. Thus EStream efficiently deals with the concept drift problem. The offline module of EStream algorithm enhances the distributions of texts in the clusters obtained by the online module so that the upcoming short texts can be assigned to the appropriate clusters.Experimental results demonstrate that EStream outperforms the state-of-the-art short text stream clustering methods (in terms of clustering result) by a statistically significant margin on several short text datasets. Moreover, the running time of EStream is several orders of magnitude faster than that of the state-of-the-art methods.",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:NxmKEeNBbOMC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Investigating event log analysis with minimum apriori information",
            "Publication year": 2013,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/6573118/",
            "Abstract": "This thesis proposes a hybrid log alert detection scheme, which incorporates anomaly detection and signature generation to accomplish its goal. Unlike previous work, minimum apriori knowledge of the system being analyzed is assumed. This assumption enhances the platform portability of the framework. The anomaly detection component works in a bottom-up manner on the contents of historical system log data to detect regions of the log, which contain anomalous (alert) behaviour. The identified anomalous regions (after inspection by a human administrator through a visualization system) are then passed to the signature generation component, which mines them for patterns. Consequently, future occurrences of the underlying alert in the anomalous log region, can be detected on a production system using the discovered patterns. The combination of anomaly detection and signature generation, which is novel \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ME8aQywAAAAJ:lvd772isFD0C",
            "Publisher": "IEEE"
        },
        {
            "Title": "TrWP: text relatedness using word and phrase relatedness",
            "Publication year": 2015,
            "Publication url": "https://www.aclweb.org/anthology/S15-2016.pdf",
            "Abstract": "Text is composed of words and phrases. In bag-of-word model, phrases in texts are split into words. This may discard the inner semantics of phrases which in turn may give inconsistent relatedness score between two texts. TrWP, the unsupervised text relatedness approach combines both word and phrase relatedness. The word relatedness is computed using an existing unsupervised co-occurrence based method. The phrase relatedness is computed using an unsupervised phrase relatedness function f that adopts Sum-Ratio technique based on the statistics in the Google ngram corpus of overlapping n-grams associated with the two input phrases. The second run of TrWP ranked 30th out of 73 runs in SemEval-2015 task2a (English STS).",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:PaBasH6fAo0C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Web mining and clustering",
            "Publication year": 2004,
            "Publication url": "https://scholar.google.com/scholar?cluster=211292182958921454&hl=en&oi=scholarr",
            "Abstract": "not available.",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:VL0QpB8kHFEC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Diffraction modeling for interactive virtual acoustical environments.",
            "Publication year": 2007,
            "Publication url": "https://www.scitepress.org/Papers/2007/20758/20758.pdf",
            "Abstract": "Since the dimensions of many of the objects/surfaces encountered in our daily lives are within an order of magnitude of the wavelength of audible sounds, diffraction is an elementary means of sound propagation. Despite its importance in the real-world, diffraction effects are often overlooked by acoustical modeling methods leading to a degredation in immersion or presence. This paper describes an acoustical diffraction method based on the Huygens-Fresnel principle. The method is simple and efficient allowing it to be incorporated in interactive acoustical environments including virtual environments. Experimental results are presented that illustrate the performance and effectiveness of the method and its conformance to theoretical diffraction models.",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:u9iWguZQMMsC",
            "Publisher": "Unknown"
        },
        {
            "Title": "A visual approach for interactive keyterm-based clustering",
            "Publication year": 2018,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/3181669",
            "Abstract": "The keyterm-based approach is arguably intuitive for users to direct text-clustering processes and adapt results to various applications in text analysis. Its way of markedly influencing the results, for instance, by expressing important terms in relevance order, requires little knowledge of the algorithm and has predictable effect, speeding up the task. This article first presents a text-clustering algorithm that can easily be extended into an interactive algorithm. We evaluate its performance against state-of-the-art clustering algorithms in unsupervised mode. Next, we propose three interactive versions of the algorithm based on keyterm labeling, document labeling, and hybrid labeling. We then demonstrate that keyterm labeling is more effective than document labeling in text clustering. Finally, we propose a visual approach to support the keyterm-based version of the algorithm. Visualizations are provided for the whole \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ME8aQywAAAAJ:5bg8sr1QxYwC",
            "Publisher": "ACM"
        },
        {
            "Title": "Modeling community question-answering archives",
            "Publication year": 2011,
            "Publication url": "https://web.cs.dal.ca/~eem/res/pubs/pubs/2011-Zolaktaf-NIPS.pdf",
            "Abstract": "Community Question Answering (CQA) services contain large archives of previously asked questions and their answers. We present a statistical topic model for modeling Question-Answering archives. The model explicitly captures relationships between questions and their answers by modeling topical dependencies. We show that the model achieves improved performance in retrieving the correct answer for a query question compared to the LDA model. Our model can also be used for automatic tagging of questions and answers. This is useful for providing topical browsing capabilities for legacy Q&A archives.",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:BwyfMAYsbu0C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Exploratory search and interactive data analytics",
            "Publication year": 2017,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/3030024.3040246",
            "Abstract": "In recent years there has been a growing interest in developing new methods and systems that allow users to interactively explore large volumes of data, such as document collections, multimedia collections or biomedical datasets. There are various approaches to support users in this interactive environment ranging from the development of new algorithms through visualisation methods to specialised interfaces. The overarching goal of this workshop is to bring together a group of researchers spanning across multiple facets of exploratory search and data analytics to discuss, and outline research challenges for this novel area.",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:ce2CqMG-AY4C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Relevance feedback methods for logo and trademark image retrieval on the Web",
            "Publication year": 2005,
            "Publication url": "http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.103.8598",
            "Abstract": "Relevance feedback is the state-of-the-art approach for adjusting query results to the needs of the users. This work extends the existing framework of image retrieval with relevance feedback on the Web by incorporating text and image content into the search and feedback process. Some of the most powerful relevance feedback methods are implemented and tested on a fully automated Web retrieval system with more than 250,000 logo and trademark images. This evaluation demonstrates that term re-weighting based on text and image content is the most effective approach.",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:yMeIxYmEMEAC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Adaptabilty of a GP Based IDS on Wireless Networks",
            "Publication year": 2008,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/4529352/",
            "Abstract": "Security and Intrusion detection in WiFi networks is currently an active area of research where WiFi specific Data Link layer attacks are an area of focus; particularly recent work has focused on producing machine learning based IDSs for these WiFi specific attacks. These proposed machine learning based IDSs come in addition to the already deployed signatures which are already in use in conventional intrusion detection systems like Snort-Wireless and Kismet. In this paper, we compare the detection capability of Snort-Wireless and a Genetic Programming (GP) based intrusion detector, based on the ability to adapt to modified attacks, ability to adapt to similar unknown attacks and infrastructure independent detection. Our results show that the GP based detection system is much more robust against modified attacks compared to Snort-Wireless. Moreover, by focusing on the method(s) used in feature preprocessing \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ME8aQywAAAAJ:PELIpwtuRlgC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Eyes and ears: Attentive teleconferencing utilizing audio and video cues",
            "Publication year": 2001,
            "Publication url": "https://asa.scitation.org/doi/abs/10.1121/1.4744878",
            "Abstract": "The multiple speaker teleconferencing systems currently available typically focus on a single speaker and provide limited, if any, automatic speaker tracking technologies. However, in a multiple\u2010speaker setting, speakers must be localized and tracked in both the video and audio domains. Although many fast and portable video trackers capable of locating and tracking humans exist, they employ conventional cameras thereby providing a narrow field of view. In addition, audio localization systems are expensive, nonportable, and computationally intensive. Furthermore, there have been very few attempts to combine both audio and visual systems. This work investigates the development of a simple, economical, and compact teleconferencing system utilizing both audio and video cues. An omni\u2010directional video sensor is used to provide a view of the entire visual hemisphere thereby providing multiple dynamic views \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ME8aQywAAAAJ:S16KYo8Pm5AC",
            "Publisher": "Acoustical Society of America"
        },
        {
            "Title": "Post-supervised template induction for dynamic Web sources",
            "Publication year": 2003,
            "Publication url": "https://link.springer.com/chapter/10.1007/3-540-44886-1_21",
            "Abstract": "Dynamic web sites commonly return information in the form of lists and tables. Although hand crafting an extraction program for a specific template is time-consuming but straightforward, it is desirable to automatically generate template extraction programs from examples of lists and tables in html documents. We describe a novel technique, Post-supervised Learning, which exploits unsupervised learning to avoid the need for training examples, while minimally involving the user to achieve high accuracy. We have developed unsupervised algorithms to extract the number of rows and adopted a dynamic programming algorithm for extracting columns. Our system, called TIDE (Template Induction for web Data Extraction), achieves high performance with minimal user input compared to fully supervised techniques.",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:epqYDVWIO7EC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "Finding expert users in community question answering",
            "Publication year": 2012,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/2187980.2188202",
            "Abstract": "Community Question Answering (CQA) websites provide a rapidly growing source of information in many areas. This rapid growth, while offering new opportunities, puts forward new challenges. In most CQA implementations there is little effort in directing new questions to the right group of experts. This means that experts are not provided with questions matching their expertise, and therefore new matching questions may be missed and not receive a proper answer. We focus on finding experts for a newly posted question. We investigate the suitability of two statistical topic models for solving this issue and compare these methods against more traditional Information Retrieval approaches. We show that for a dataset constructed from the Stackoverflow website, these topic models outperform other methods in retrieving a candidate set of best experts for a question. We also show that the Segmented Topic Model gives \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ME8aQywAAAAJ:86PQX7AUzd4C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Latent Dirichlet co-clustering",
            "Publication year": 2006,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/4053080/",
            "Abstract": "We present a generative model for simultaneously clustering documents and terms. Our model is a four-level hierarchical Bayesian model, in which each document is modeled as a random mixture of document topics , where each topic is a distribution over some segments of the text. Each of these segments in the document can be modeled as a mixture of word topics where each topic is a distribution over words. We present efficient approximate inference techniques based on Markov Chain Monte Carlo method and a moment-matching algorithm for empirical Bayes parameter estimation. We report results in document modeling, document and term clustering, comparing to other topic models, Clustering and Co-Clustering algorithms including latent Dirichlet allocation (LDA), model-based overlapping clustering (MOC), model-based overlapping co-clustering (MOCC) and information-theoretic co-clustering (ITCC).",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:aqlVkmm33-oC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Using unsupervised learning to guide resampling in imbalanced data sets",
            "Publication year": 2001,
            "Publication url": "http://proceedings.mlr.press/r3/nickerson01a.html",
            "Abstract": "The class imbalance problem causes a classifier to over-fit the data belonging to the class with the greatest number of training examples. The purpose of this paper is to argue that methods that equalize class membership are not as effective as possible when applied blindly and that improvements can be obtained by adjusting for the within-class imbalance. A guided resampling technique is proposed and tested within a simpler letter recognition domain and a more difficult text classification domain. A fast unsupervised clustering technique, Principal Direction Divisive Partitioning (PDDP), is used to determine the internal characteristics of each class. The performance improvement in categories that suffer from a large between-class imbalance (few positive examples) are shown to be improved when using the guided resampling method.",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:5nxA0vEk-isC",
            "Publisher": "PMLR"
        },
        {
            "Title": "Enhancement of Short Text Clustering by Iterative Classification",
            "Publication year": 2020,
            "Publication url": "https://ui.adsabs.harvard.edu/abs/2020arXiv200111631R/abstract",
            "Abstract": "Short text clustering is a challenging task due to the lack of signal contained in such short texts. In this work, we propose iterative classification as a method to bo ost the clustering quality (eg, accuracy) of short texts. Given a clustering of short texts obtained using an arbitrary clustering algorithm, iterative classification applies outlier removal to obtain outlier-free clusters. Then it trains a classification algorithm using the non-outliers based on their cluster distributions. Using the trained classification model, iterative classification reclassifies the outliers to obtain a new set of clusters. By repeating this several times, we obtain a much improved clustering of texts. Our experimental results show that the proposed clustering enhancement method not only improves the clustering quality of different clustering methods (eg, k-means, k-means--, and hierarchical clustering) but also outperforms the state-of-the-art short text \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ME8aQywAAAAJ:CYCckWUYoCcC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Dimensionality Reduction",
            "Publication year": 2009,
            "Publication url": "http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.205.7590&rep=rep1&type=pdf",
            "Abstract": "Dimensionality Reduction Page 1 Dimensionality Reduction Evangelos Milios Dalhousie Univ., \nFaculty of Computer Science October 6, 2009 Evangelos Milios (Dalhousie Univ.) \nDimensionality Reduction October 6, 2009 1 / 78 Page 2 Outline 1 Linear algebra review 2 \nPrincipal Components Analysis 3 Singular Value Decomposition 4 Factor Analysis 5 Latent \nSemantic Indexing 6 Independent Component Analysis 7 Random Projections, Multidimensional \nscaling, Fastmap Evangelos Milios (Dalhousie Univ.) Dimensionality Reduction October 6, 2009 \n2 / 78 Page 3 Vector space Review A vector space V over the set of real numbers as scalars R \nhas an addition and a scalar multiplication defined, with the following properties. 1. (v1 + v2) \n+ v3 = v1 + (v2 + v3) 2. There is a zero vector 0 in V 3. For each vector v, there is a \u2212v, such \nthat v + (\u2212v) = 0 4. v1 + v2 = v2 + v1 5. 1v = v for real number 1 6. r1(r2v)=(r1r2)v 7. (r1 + r2)v r\u2026",
            "Abstract entirety": 0,
            "Author pub id": "ME8aQywAAAAJ:jL-93Qbq4QoC",
            "Publisher": "Unknown"
        },
        {
            "Title": "A graph-based approach for positive and unlabeled learning",
            "Publication year": 2021,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S0020025521009130",
            "Abstract": "Positive and Unlabeled Learning (PUL) uses unlabeled documents and a few positive documents for retrieving a set of \u201cinterest\u201d documents from a text collection. Usually, PUL approaches are based on the vector space model. However, when dealing with semi-supervised learning for text classification or information retrieval, graph-based approaches have been proved to outperform vector space model-based approaches. So, in this article, a graph-based approach for PUL is proposed: Label Propagation for Positive and Unlabeled Learning (LP-PUL). The proposed framework consists of three steps:(i) building a similarity graph,(ii) identifying reliable negative documents, and (iii) performing label propagation to classify the remaining unlabeled documents as positive or negative. We carried out experiments to measure the impact of the different choices in each step of the proposed framework. We also \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ME8aQywAAAAJ:-uzm3Y7AvW0C",
            "Publisher": "Elsevier"
        },
        {
            "Title": "A visually guided swimming robot",
            "Publication year": 2005,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/1545231/",
            "Abstract": "We describe recent results obtained with AQUA, a mobile robot capable of swimming, walking and amphibious operation. Designed to rely primarily on visual sensors, the AQUA robot uses vision to navigate underwater using servo-based guidance, and also to obtain high-resolution range scans of its local environment. This paper describes some of the pragmatic and logistic obstacles encountered, and provides an overview of some of the basic capabilities of the vehicle and its associated sensors. Moreover, this paper presents the first ever amphibious transition from walking to swimming.",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:ULOm3_A8WrAC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Context-specific sentiment lexicon expansion via minimal user interaction",
            "Publication year": 2014,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/7294415/",
            "Abstract": "One of the important factors in the performance of sentiment analysis methods is having a comprehensive sentiment lexicon. However, since sentiment words have different polarities not only in different domains, but also in different contexts within the same domain, constructing such context-specific sentiment lexicons is not an easy task. The high costs of manually constructing such lexicons motivate researchers to create automatic methods for finding sentiment words and assigning their polarities. However, existing methods may encounter ambiguous cases with contradictory evidence which are hard to automatically resolve. To address this problem, we aim to engage the user in the process of polarity assignment and improve the quality of the generated lexicon via minimal user effort. A novel visualization is employed to present the results of the automatic algorithm, i.e., the extracted sentiment pairs along with \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ME8aQywAAAAJ:6yz0xqPARnAC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Topic\u2010based web site summarization",
            "Publication year": 2010,
            "Publication url": "https://www.emerald.com/insight/content/doi/10.1108/17440081011090220/full/html",
            "Abstract": "Summarization of an entire web site with diverse content may lead to a summary heavily biased towards the site's dominant topics. The purpose of this paper is to present a novel topic\u2010based framework to address this problem.A two\u2010stage framework is proposed. The first stage identifies the main topics covered in a web site via clustering and the second stage summarizes each topic separately. The proposed system is evaluated by a user study and compared with the single\u2010topic summarization approach.The user study demonstrates that the clustering\u2010summarization approach statistically significantly outperforms the plain summarization approach in the multi\u2010topic web site summarization task. Text\u2010based clustering based on selecting features with high variance over web pages is reliable; outgoing links are useful if a rich set of cross links is available \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ME8aQywAAAAJ:p__nRnzSRKYC",
            "Publisher": "Emerald Group Publishing Limited"
        },
        {
            "Title": "Relevance feedback methods for logo and trademark image retrieval on the web",
            "Publication year": 2006,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/1141277.1141532",
            "Abstract": "Relevance feedback is the state-of-the-art approach for adjusting query results to the needs of the users. This work extends the existing framework of image retrieval with relevance feedback on the Web by incorporating text and image content into the search and feedback process. Some of the most powerful relevance feedback methods are implemented and tested on a fully automated Web retrieval system with more than 250,000 logo and trademark images. This evaluation demonstrates that term re-weighting based on text and image content is the most effective approach.",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:HoB7MX3m0LUC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Spatio-temporal decomposition, clustering and identification for alert detection in system logs",
            "Publication year": 2012,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/2245276.2245395",
            "Abstract": "In this work, we propose an approach based on analyzing the spatio-temporal partitions of a system log, generated by supercomputers consisting of several nodes, for alert detection without employing semantic analysis. In this case,\" Spatial\" refers to the source of the log event and\" Temporal\" refers to the time the log event was reported. Our research shows that these spatio-temporal partitions can be clustered to separate normal activity from anomalous activity, with high accuracy. Therefore, our proposed method provides an effective alert detection mechanism.",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:tkaPQYYpVKoC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Non-uniform language detection in technical writing",
            "Publication year": 2016,
            "Publication url": "https://dalspace.library.dal.ca/handle/10222/71479",
            "Abstract": "Technical writing in professional environments, such as user manual authoring, requires uniform language. Non-uniform language detection is a novel task, which aims to guarantee the consistency for technical writing by detecting sentences in a document that are intended to have the same meaning within a similar context but use different words/writing style. This thesis proposes an approach that utilizes text similarity algorithms at lexical, syntactic, semantic and pragmatic levels. Different metrics are integrated by applying a machine learning classification method. We tested our method using smart phone user manuals, and compared the performance against the state-of-the-art methods in related area. The experiments demonstrate our approach is the most efficient solution to date.",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:1Ye0OR6EYb4C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Fast and simple deterministic seeding of KMeans for text document clustering",
            "Publication year": 2018,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-319-98932-7_7",
            "Abstract": "KMeans is one of the most popular document clustering algorithms. It is usually initialized by random seeds that can drastically impact the final algorithm performance. There exists many random or order-sensitive methods that try to properly initialize KMeans but their problem is that their result is non-deterministic and unrepeatable. Thus KMeans needs to be initialized several times to get a better result, which is a time-consuming operation. In this paper, we introduce a novel deterministic seeding method for KMeans that is specifically designed for text document clustering. Due to its simplicity, it is fast and can be scaled to large datasets. Experimental results on several real-world datasets demonstrate that the proposed method has overall better performance compared to several deterministic, random, or order-sensitive methods in terms of clustering quality and runtime.",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:QUX0mv85b1cC",
            "Publisher": "Springer, Cham"
        },
        {
            "Title": "Active information retrieval for linking Twitter posts with political debates",
            "Publication year": 2015,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/7424315/",
            "Abstract": "Users of microblogging social networks produce millions of short messages every day. Retrieving relevant information to a particular event from this sheer volume of data is not a trivial task. In this paper, we present a framework for the retrieval of Twitter posts that are relevant to a set of political debates. Our main contribution is the proposal of a set of strategies for involving the user in the retrieval process, so that by presenting to her meaningful posts to be labeled, the method achieves a noticeably higher accuracy. The correct retrieval or labeling could be provided by an external information source such as a domain expert, or simulated with an oracle. A key aspect of active retrieval methods is to request the labels of the instances that help improve the retrieval accuracy the most, while keeping the number of labeling requests to a minimum. The proposed strategies for selecting labeling requests make use of the \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ME8aQywAAAAJ:CdxZDUztZiMC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Post-Processing OCR Text using Web-Scale Corpora",
            "Publication year": 2017,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/3103010.3121032",
            "Abstract": "We introduce a (semi-) automatic OCR post-processing system that utilizes web-scale linguistic corpora in providing high-quality correction. This paper is a comprehensive system overview with the focus on the computational procedures, applied linguistic analysis, and processing optimization.",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:-nhnvRiOwuoC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Detection of daily living activities using a two-stage markov model",
            "Publication year": 2013,
            "Publication url": "https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.725.1978&rep=rep1&type=pdf",
            "Abstract": "A supervised statistical model for detecting the activities of daily living (ADL) from sensor data streams is proposed in this paper. This method works in two stages aiming at capturing temporal intra-and inter-activity relationships. In the first stage each activity is modeled separately by a Markov model where sensors correspond to states. By modeling each sensor as a state we capture the absolute and relational temporal features within the activities. A novel data segmentation approach is proposed for accurate inferencing at the first stage. To boost the accuracy, a second stage consisting of a Hidden Markov Model is added that serves two purposes. Firstly, it acts as a corrective stage, as it learns the probability of each activity being incorrectly inferred by the first stage, so that they can be corrected at the second stage. Secondly, it introduces inter-activity transition information to capture possible time-dependent relationships between two contiguous activities. We applied our method to three smart house datasets. Comparison of the results to other traditional approaches for ADL identification shows competitive or better performance. The paper also proposes a deployment of our methodology using an agent-based architecture.",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:nZcligLrVowC",
            "Publisher": "IOS Press"
        },
        {
            "Title": "A next generation entropy based framework for alert detection in system logs",
            "Publication year": 2011,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/5990587/",
            "Abstract": "Recent research efforts have highlighted the capability of entropy based approaches in the automatic discovery of alerts in system logs. In this work, we extend this research to present the evaluations of three entropy based approaches on new datasets not utilized in previous papers. We also extend the approach with the introduction of a Cluster Membership Anomaly score. This extension of the approach is intended to reduce the false positive rates required to detect all alerts. Previous work has shown that false positive rates required for the detection of all alerts for an entropy based approach could be very high. The results show that the Cluster Membership Anomaly score has value for the reduction of false positive rates.",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:tKAzc9rXhukC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Sonel mapping: Acoustic modeling utilizing an acoustic version of photon mapping",
            "Publication year": 2004,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/1391872/",
            "Abstract": "Acoustic modeling of even small simple environments is a complex, computationally expensive task. Sound, just as light, is itself a wave phenomenon. Although there are several key differences between light and sound there are also several similarities. Given the similarities which exist between sound and light, this work investigates the application of photon mapping (suitably modified), to model environmental acoustics. The resulting acoustic sonel mapping technique can be used to model acoustic environments while accounting for diffuse and specular acoustic reflections as well as refraction and diffraction effects.",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:L8Ckcad2t8MC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Capturing causality in communications graphs",
            "Publication year": 2007,
            "Publication url": "https://scholar.google.com/scholar?cluster=5071882632787705151&hl=en&oi=scholarr",
            "Abstract": "We analyze dynamic graphs formed from email data to identify high impact messages and look for evidence of implied causality for real life events. We introduce a new method for identifying anomalies or events from dynamic communication graphs. The method is robust to false alarms. Experiments show it is effective in identifying the formation of communities within communications networks.",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:ZzlSgRqYykMC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Probabilistic cooperative localization and mapping in practice",
            "Publication year": 2003,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/1241873/",
            "Abstract": "In this paper we present a probabilistic framework for the reduction in the uncertainty of a moving robot pose during exploration by using a second robot to assist. A Monte Carlo Simulation technique (specifically, a Particle Filter) is employed in order to model and reduce the accumulated odometric error. Furthermore, we study the requirements to obtain an accurate yet timely pose estimate. A team of two robots is employed to explore an indoor environment in this paper, although several aspects of the approach have been extended to larger groups. The concept behind our exploration strategy has been presented previously and is based on having one robot carry a sensor that acts as a \"robot tracker\" to estimate the position of the other robot. By suitable use of the tracker as an appropriate motion-control mechanism we can sweep areas of free space between the stationary and the moving robot and generate an \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ME8aQywAAAAJ:_FxGoFyzp5QC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Post-supervised template induction for information extraction from lists and tables in dynamic web sources",
            "Publication year": 2005,
            "Publication url": "https://link.springer.com/content/pdf/10.1007/s10844-005-0861-z.pdf",
            "Abstract": "Dynamic web sites commonly return information in the form of lists and tables. Although hand crafting an extraction program for a specific template is time-consuming but straightforward, it is desirable to automatically generate template extraction programs from examples of lists and tables in html documents. Supervised approaches have been shown to achieve high accuracy, but they require manual labelling of training examples, which is also time consuming. Fully unsupervised approaches, which extract rows and columns by detecting regularities in the data, cannot provide sufficient accuracy for practical domains. We describe a novel technique, Post-supervised Learning, which exploits unsupervised learning to avoid the need for training examples, while minimally involving the user to achieve high accuracy. We have developed unsupervised algorithms to extract the number of rows and adopted a \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ME8aQywAAAAJ:eflP2zaiRacC",
            "Publisher": "Kluwer Academic Publishers"
        },
        {
            "Title": "Enhancement of short text clustering by iterative classification",
            "Publication year": 2020,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-030-51310-8_10",
            "Abstract": "Short text clustering is a challenging task due to the lack of signal contained in short texts. In this work, we propose iterative classification as a method to boost the clustering quality of short texts. The idea is to repeatedly reassign (classify) outliers to clusters until the cluster assignment stabilizes. The classifier used in each iteration is trained using the current set of cluster labels of the non-outliers; the input of the first iteration is the output of an arbitrary clustering algorithm. Thus, our method does not require any human-annotated labels for training. Our experimental results show that the proposed clustering enhancement method not only improves the clustering quality of different baseline clustering methods (e.g., k-means, k-means--, and hierarchical clustering) but also outperforms the state-of-the-art short text clustering methods on several short text datasets by a statistically significant margin.",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:DyXnQzXoVgIC",
            "Publisher": "Springer, Cham"
        },
        {
            "Title": "Information retrieval in network administration",
            "Publication year": 2008,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/4519908/",
            "Abstract": "Network administration is a task that requires experience in relating symptoms of network problems with possible causes and corrective actions. We describe the design of a system and more specifically its information retrieval component, which aims to retrieve articles relevant to a given problem case from a collection of articles describing previously solved problems and their associated solutions. An article is described by a term vector. We present a methodology for defining the vocabulary and preliminary results for assessing the quality of expert-proposed modifications to the vocabulary. We obtain vocabulary-derived document classes from a self- organising map and assess vocabulary quality using the quality of classification into these classes.",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:Z5m8FVwuT1cC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Mobile agent perception",
            "Publication year": 2001,
            "Publication url": "https://elibrary.ru/item.asp?id=782267",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:hCrLmN-GePgC",
            "Publisher": "Elsevier Science Publishing Company, Inc."
        },
        {
            "Title": "Using HMM to learn user browsing patterns for focused Web crawling",
            "Publication year": 2006,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S0169023X06000309",
            "Abstract": "A focused crawler is designed to traverse the Web to gather documents on a specific topic. It can be used to build domain-specific Web search portals and online personalized search tools. To estimate the relevance of a newly seen URL, it must use information gleaned from previously crawled page sequences.In this paper, we present a new approach for prediction of the links leading to relevant pages based on a Hidden Markov Model (HMM). The system consists of three stages: user data collection, user modelling via sequential pattern learning, and focused crawling. In particular, we first collect the Web pages visited during a user browsing session. These pages are clustered, and the link structure among pages from different clusters is then used to learn page sequences that are likely to lead to target pages. The learning is performed using HMM. During crawling, the priority of links to follow is based on a \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ME8aQywAAAAJ:Wp0gIr-vW9MC",
            "Publisher": "North-Holland"
        },
        {
            "Title": "Probabilistic models for focused web crawling",
            "Publication year": 2012,
            "Publication url": "https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1467-8640.2012.00411.x",
            "Abstract": "A focused crawler is an efficient tool used to traverse the Web to gather documents on a specific topic. It can be used to build domain\u2010specific Web search portals and online personalized search tools. Focused crawlers can only use information obtained from previously crawled pages to estimate the relevance of a newly seen URL. Therefore, good performance depends on powerful modeling of context as well as the quality of the current observations. To address this challenge, we propose capturing sequential patterns along paths leading to targets based on probabilistic models. We model the process of crawling by a walk along an underlying chain of hidden states, defined by hop distance from target pages, from which the actual topics of the documents are observed. When a new document is seen, prediction amounts to estimating the distance of this document from a target. Within this framework, we propose \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ME8aQywAAAAJ:7PzlFSSx8tAC",
            "Publisher": "Blackwell Publishing Inc"
        },
        {
            "Title": "for Dynamic Web Sources",
            "Publication year": 2003,
            "Publication url": "https://scholar.google.com/scholar?cluster=4663487233328072528&hl=en&oi=scholarr",
            "Abstract": "Dynamic web sites commonly return information in the form of lists and tables. Although hand crafting an extraction program for a specific template is time-consuming but straightforward, it is desirable to automatically generate template extraction programs from examples of lists and tables in html documents. We describe a novel technique, Postsupervised Learning, which exploits unsupervised learning to avoid the need for training examples, while minimally involving the user to achieve high accuracy. We have developed unsupervised algorithms to extract the number of rows and adopted a dynamic programming algorithm for ex-tracting columns. Our system, called TIDE (Template Induction for web Data Extraction), achieves high performance with minimal user input compared to fully supervised techniques.",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:H_jBuBxbQIAC",
            "Publisher": "Springer"
        },
        {
            "Title": "A Lightweight Algorithm for Message Type Extraction in Event Logs",
            "Publication year": 2009,
            "Publication url": "https://cdn.dal.ca/content/dam/dalhousie/pdf/faculty/computerscience/technical-reports/CS-2009-07.pdf",
            "Abstract": "Message type or message cluster extraction is an important task in automatic application log analysis. When the message types that exist in a log file are defined, they form the basis for carrying out other automatic application log analysis tasks. In this paper we introduce a novel algorithm for carrying out this task. IPLoM, which stands for Iterative Partitioning Log Mining, works through a 4-step process. The first 3 steps hierarchically partition the event log into groups of event log messages or event clusters. In its 4th and final stage IPLoM produces a message type description or line format for each of the message clusters. IPLoM is able to find clusters in data irrespective of the frequency of its instances in the data, it scales gracefully in face of long message type patterns and produces message type descriptions at a level of abstraction which is preferred by a human observer. Evaluations show that IPLoM outperforms similar algorithms statistically significantly.",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:foquWX3nUaYC",
            "Publisher": "Unknown"
        },
        {
            "Title": "A multi-centrality index for graph-based keyword extraction",
            "Publication year": 2019,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S0306457319303267",
            "Abstract": "Keyword extraction aims to capture the main topics of a document and is an important step in natural language processing (NLP) applications. The use of different graph centrality measures has been proposed to extract automatic keywords. However, there is no consensus yet on how these measures compare in this task. Here, we present the multi-centrality index (MCI) approach, which aims to find the optimal combination of word rankings according to the selection of centrality measures. We analyze nine centrality measures (Betweenness, Clustering Coefficient, Closeness, Degree, Eccentricity, Eigenvector, K-Core, PageRank, Structural Holes) for identifying keywords in co-occurrence word-graphs representation of documents. We perform experiments on three datasets of documents and demonstrate that all individual centrality methods achieve similar statistical results, while the proposed MCI approach \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ME8aQywAAAAJ:Hck25ST_3aIC",
            "Publisher": "Pergamon"
        },
        {
            "Title": "Comparing and combining dimension reduction techniques for efficient text clustering",
            "Publication year": 2005,
            "Publication url": "https://www.researchgate.net/profile/Giovanni-Felici/publication/226795010_Feature_Selection_for_Data_Mining/links/53e413d70cf25d674e94b475/Feature-Selection-for-Data-Mining.pdf#page=22",
            "Abstract": "A great challenge of text mining arises from the increasingly large text datasets and the high dimensionality associated with natural language. In this research, a systematic study is conducted of six Dimension Reduction Techniques (DRT) in the context of the text clustering problem using three standard benchmark datasets. The methods considered include three feature transformation techiques, Independent Component Analysis (ICA), Latent Semantic Indexing (LSI), Random Projection (RP), and three feature selection techniques based on Document Frequency (DF), mean TfIdf (TI) and Term Frequency Variance (TfV). Experiments with the k-means clustering algorithm show that ICA and LSI are clearly superior to RP on all three datasets. Furthermore, it is shown that TI and TfV outperform DF for text clustering. Finally, experiments where a selection technique is followed by a transformation technique show that this combination can help substantially reduce the computational cost associated with the best transformation methods (ICA and LSI) while preserving clustering performance.",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:0EnyYjriUFMC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Evaluating visual analytics for text information retrieval",
            "Publication year": 2021,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/3472301.3484320",
            "Abstract": "Retrieving information from document collections is necessary in many contexts, for example, researchers wish to retrieve papers on a research topic, physicians search for patient records related to a certain condition, police investigators seek for relationships in criminal reports. Common to these scenarios are users in need of identifying relevant textual information in a document collection. The task is challenging, especially when users hope for a retrieval process that misses none or very few of the relevant documents. Visual Analytics (VA) approaches are often advocated to support document retrieval tasks. VA relies on integrating interactive visualizations and machine learning algorithms so that a domain expert can gradually steer a system into identifying the relevant documents. As an example, TRIVIR is a state-of-the-art system that allows exploring a corpus while providing feedback to a classifier that \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ME8aQywAAAAJ:hvmnpdAuIbkC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Ensembles of Proximity-Based One-Class Classifiers for Author Verification",
            "Publication year": 2014,
            "Publication url": "https://www.uni-weimar.de/medien/webis/events/pan-14/pan14-papers-final/pan14-authorship-verification/jankowska14-notebook.pdf",
            "Abstract": "We use ensembles of proximity based one-class classifiers for authorship verification task. The one-class classifiers compare, for each document of the known authorship, the dissimilarity between this document and the most dissimilar other document of this authorship to the dissimilarity between this document and the questioned document. As the dissimilarity measure between documents we use Common N-Gram dissimilarity based on character or word n-grams.",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:WAzi4Gm8nLoC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Corpus-based term relatedness graphs in tag recommendation",
            "Publication year": 2010,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-642-13059-5_3",
            "Abstract": "A key problem in text mining is the extraction of relations between terms. Hand-crafted lexical resources such as Wordnet have limitations when it comes to special text corpora. Distributional approaches to the problem of automatic construction of thesauri from large corpora have been proposed, making use of sophisticated Natural Language Processing techniques, which makes them language specific, and computationally intensive. We conjecture that in a number of applications, it is not necessary to determine the exact nature of term relations, but it is sufficient to capture and exploit the frequent co-occurrence of terms. Such an application is tag recommendation.Collaborative tagging systems are social data repositories, in which users manage web resources by assigning to them descriptive keywords (tags). An important element of collaborative tagging systems is the tag recommender, which \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ME8aQywAAAAJ:7T2F9Uy0os0C",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "Node Similarity in Networked Information Space",
            "Publication year": 2001,
            "Publication url": "https://www.researchgate.net/profile/Jeannette-Janssen/publication/2516984_Node_Similarity_in_Networked_Information_Spaces/links/54bc217b0cf253b50e2d162b/Node-Similarity-in-Networked-Information-Spaces.pdf",
            "Abstract": "Networked information spaces contain information entities, corresponding to nodes, which are connected by associations, corresponding to links in the network. Hxarn ples of networked information spaces are: the World Wide Web, where information entities are web pages, and associations are hyperlinks; the scientific literature, where information entities are articles and associations are references to other articles. Similarity between information entities in a net-worked information space can be defined not only based on the content of the information entities, but also based on the connectivity established by the associations present. This paper explores the definition of similarity based on connectivity only, and proposes several algorithms for this purpose. Our rnet rics take advar\u0131lage of the local neighborhoods of the nodes in the nel-worked informalion space.\" l'herefore, explicil, availability of the nel worked \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ME8aQywAAAAJ:4DMP91E08xMC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Data quality challenges in twitter content analysis for informing policy making in health care",
            "Publication year": 2018,
            "Publication url": "https://aisel.aisnet.org/hicss-51/da/big_data_and_analytics/3/",
            "Abstract": "Social media platforms and microblogs have become popular fora where the general public expresses opinions and concerns on a variety of matters. As a result, private and public organizations have been looking into ways for finding, understanding and communicating insights extracted from this massive amount of text-based interconnected data. There are, however, important difficulties associated with the noisiness and reliability of the content that hinder the analysis of the data. This paper reports the main challenges found in a real-world experience with social media used as a source of data to support policy making and assessment. We also propose a set of strategies for the precise retrieval of data, the profiling of social media users, and the involvement of policy makers in the analytical process.",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:ziOE8S1-AIUC",
            "Publisher": "Unknown"
        },
        {
            "Title": "High-performance computational framework for phrase relatedness",
            "Publication year": 2017,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/3103010.3121039",
            "Abstract": "TrWP is a text relatedness measure that computes semantic similarity between words and phrases utilizing aggregated statistics from the Google Web 1T 5-gram corpus. The phrase similarity computation in TrWP is costly in terms of both time and space, making the existing implementation of TrWP impractical for real-world usage. In this work, we present an in-memory computational framework for TrWP, which optimizes the corpus search using perfect hashing and minimizes the required memory cost using variable length encoding. Evaluated using the Google Web 1T 5-gram corpus, we demonstrate that the computational speed of our framework outperforms a file-based implementation by several orders of magnitude.",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:F2UWTTQJPOcC",
            "Publisher": "Unknown"
        },
        {
            "Title": "COVID-19 pandemic: identifying key issues using social media and natural language processing",
            "Publication year": 2020,
            "Publication url": "https://arxiv.org/abs/2008.10022",
            "Abstract": "The COVID-19 pandemic has affected people's lives in many ways. Social media data can reveal public perceptions and experience with respect to the pandemic, and also reveal factors that hamper or support efforts to curb global spread of the disease. In this paper, we analyzed COVID-19-related comments collected from six social media platforms using Natural Language Processing (NLP) techniques. We identified relevant opinionated keyphrases and their respective sentiment polarity (negative or positive) from over 1 million randomly selected comments, and then categorized them into broader themes using thematic analysis. Our results uncover 34 negative themes out of which 17 are economic, socio-political, educational, and political issues. 20 positive themes were also identified. We discuss the negative issues and suggest interventions to tackle them based on the positive themes and research evidence.",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:kJDgFkosVoMC",
            "Publisher": "Unknown"
        },
        {
            "Title": "A comparison of keyword-and keyterm-based methods for automatic web site summarization",
            "Publication year": 2004,
            "Publication url": "https://www.aaai.org/Papers/Workshops/2004/WS-04-01/WS04-01-003.pdf",
            "Abstract": "Automatic Web site summarization, which is based on keyword and key sentence extraction from narrative text, is an effective means of making the content of a Web site easily accessible to Web users. This work is directed towards summary generation based on multi-word terms extracted by the C-value/NC-value method. Keyterm-based summaries are compared with keyword-based summaries for a list of test Web sites. The evaluation indicates that keyterm-based summaries are significantly better than keyword-based summaries, which have previously been shown to be as informative as human-authored summaries.",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:EUQCXRtRnyEC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Algorithms and Models for the Web-Graph",
            "Publication year": 2008,
            "Publication url": "https://repository.vnu.edu.vn/handle/VNU_123/24490",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:qwy9JoKyICEC",
            "Publisher": "Springer"
        },
        {
            "Title": "Natural Search Queries for consumer-oriented databases.",
            "Publication year": 2007,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/4437939/",
            "Abstract": "Search in consumer-oriented databases is becoming increasingly important, as the computer becomes a commonly used tool. Such databases are at the heart of e-mail managers, flight booking, and other e-commerce systems. Key problems associated with such searches are the structure and interface of the search query. The traditional solution for these problems involves the use of a separate text field for each element of the query structure. However, the requirement to support ever increasing numbers of inexperienced users, who require an efficient and user-friendly interface, is not met by the traditional solution. We present natural search queries (NSQ), a simple and intuitive approach to the search of structured information. Our solution combines the ideas of natural language database interfaces and operator based search; queries, in simplified and intuitive natural language, are entered into a single text field \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ME8aQywAAAAJ:tzM49s52ZIMC",
            "Publisher": "IEEE"
        },
        {
            "Title": "CNG text classification for authorship profiling task",
            "Publication year": 2013,
            "Publication url": "http://ceur-ws.org/Vol-1179/CLEF2013wn-PAN-JankowskaEt2013b.pdf",
            "Abstract": "We describe our participation in the Author Profiling task of the PAN 2013 competition. The task objective is to determine the age and the gender of an author of a document. We applied the Common N-Gram (CNG) classifier (Ke\u0161elj et al., 2003) to this task. The CNG classifier uses a dissimilarity measure based on the differences in the frequencies of the character n-grams that are most common in the considered documents. To train the classifier, a class is represented by one class document created by concatenating the training documents belonging to the class. A sample document is labelled by the class with the minimum dissimilarity. For the six class classification (combinations of two possible gender labels and three possible age labels) we achieved the accuracy of 0.2814 on the English test dataset and 0.2592 on the Spanish test dataset. Our results are below the medians of the results of the competition participants.",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:vDZJ-YLwNdEC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Text similarity using google tri-grams",
            "Publication year": 2012,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-642-30353-1_29",
            "Abstract": "The purpose of this paper is to propose an unsupervised approach for measuring the similarity of texts that can compete with supervised approaches. Finding the inherent properties of similarity between texts using a corpus in the form of a word n-gram data set is competitive with other text similarity techniques in terms of performance and practicality. Experimental results on a standard data set show that the proposed unsupervised method outperforms the state-of-the-art supervised method and the improvement achieved is statistically significant at 0.05 level. The approach is language-independent; it can be applied to other languages as long as n-grams are available.",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:rmuvC79q63oC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "Automatic term extraction and document similarity in special text corpora",
            "Publication year": 2003,
            "Publication url": "http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.121.3239&rep=rep1&type=pdf",
            "Abstract": "This paper confirms that the performance of a state-of-the-art automatic term extraction method on a computer science corpus is similar to previously published performance data on a medical corpus. The extracted terms are then used to estimate the similarity of papers in the computer science corpus using the standard Vector Space Model. The precision of retrieval using a term-based representation is compared with that of a word-based representation, and a link-based similarity metric based on the overlap of the local neighborhoods of the papers in the citation graph. The term-based approach offers comparable performance to the word-based approach, but potentially with a much smaller vocabulary size.",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:kNdYIx-mwKoC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Combining semantic and term frequency similarities for text clustering",
            "Publication year": 2019,
            "Publication url": "https://link.springer.com/article/10.1007/s10115-018-1278-7",
            "Abstract": "A key challenge for document clustering consists in finding a proper similarity measure for text documents that enables the generation of cohesive groups. Measures based on the classic bag-of-words model take into account solely the presence (and frequency) of words in documents. In doing so, semantically similar documents which use different vocabularies may end up in different clusters. For this reason, semantic similarity measures that use external knowledge, such as word n-gram corpora or thesauri, have been proposed in the literature. In this paper, the Frequency Google Tri-gram Measure is proposed to assess similarity between documents based on the frequencies of terms in the compared documents as well as the Google n-gram corpus as an additional semantic similarity source. Clustering algorithms are applied to several real datasets in order to experimentally evaluate the quality of the \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ME8aQywAAAAJ:DrR-2ekChdkC",
            "Publisher": "Springer London"
        },
        {
            "Title": "MTLV: a library for building deep multi-task learning architectures",
            "Publication year": 2021,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/3469096.3474926",
            "Abstract": "Multi-Task Learning (MTL) for text classification takes advantage of the data to train a single shared model with multiple task-specific layers on multiple related classification tasks to improve its generalization performance. We choose pre-trained language models (BERT-family) as the shared part of this architecture. Although they have achieved noticeable performance in different downstream NLP tasks, their performance in an MTL setting for the biomedical domain is not thoroughly investigated. In this work, we investigate the performance of BERT-family models in different MTL settings with Open-I (radiology reports) and OHSUMED (PubMed abstracts) datasets. We introduce the MTLV (Multi-Task Learning Visualizer) library for building Multi-task learning-related architectures which use existing infrastructure (eg, Hugging Face Transformers and MLflow Tracking). Following previous work in computer vision, we \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ME8aQywAAAAJ:JP7YXuLIOvAC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Statistical analysis of dynamic graphs",
            "Publication year": 2006,
            "Publication url": "https://www.academia.edu/download/7904136/10.1.1.62.4469.pdf#page=93",
            "Abstract": "Communications between large numbers of individuals can be modeled as a dynamic graph. The graph is the integrated effect of the individuals acting autonomously. To identify and analyze communication patterns, we study dynamic graphs by examining the global behaviour of local, vertex-specific measures. In this paper, we introduce novel vertex-specific measures, and apply scan statistics to examine the global extremes of these measures. We apply our methods to a set of email data, and show that the different measures offer complementary views of the data.",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:5Ul4iDaHHb8C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Machine learning meets visualization for extracting insights from text data",
            "Publication year": 2016,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/2847557.2847560",
            "Abstract": "Historically, text mining methods have been enriched substantially by both statistical learning and symbolic AI. Different approaches have been extensively applied over the last 30 years to extract \"knowledge\" from text. However, in scenarios where the path from data to decisions is unclear, or where different users may be interested in different solutions, the involvement of the user or analyst in the text mining process becomes crucial. Visual Text Analytics aims at addressing these problems by incorporating concepts from Visual Analytics to text mining and natural language processing (Keim et. al, 2010).",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:XUvXOeBm_78C",
            "Publisher": "ACM"
        },
        {
            "Title": "Logview: Visualizing event log clusters",
            "Publication year": 2008,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/4641277/",
            "Abstract": "Event logs or log files form an essential part of any network management and administration setup. While log files are invaluable to a network administrator, the vast amount of data they sometimes contain can be overwhelming and can sometimes hinder rather than facilitate the tasks of a network administrator. For this reason several event clustering algorithms for log files have been proposed, one of which is the event clustering algorithm proposed by Risto Vaarandi, on which his simple log file clustering tool (SLCT) is based. The aim of this work is to develop a visualization tool that can be used to view log files based on the clusters produced by SLCT. The proposed visualization tool, which is called LogView, utilizes treemaps to visualize the hierarchical structure of the clusters produced by SLCT. Our results based on different application log files show that LogView can ease the summarization of vast amount of \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ME8aQywAAAAJ:mB3voiENLucC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Narrative text classification for automatic key phrase extraction in web document corpora",
            "Publication year": 2005,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/1097047.1097059",
            "Abstract": "Automatic key phrase extraction is a useful tool in many text related applications such as clustering and summarization. State-of-the-art methods are aimed towards extracting key phrases from traditional text such as technical papers. Application of these methods on Web documents, which often contain diverse and heterogeneous contents, is of particular interest and challenge in the information age. In this work, we investigate the significance of narrative text classification in the task of automatic key phrase extraction in Web document corpora. We benchmark three methods, TFIDF, KEA, and Keyterm, used to extract key phrases from all the plain text and from only the narrative text of Web pages. ANOVA tests are used to analyze the ranking data collected in a user study using quantitative measures of acceptable percentage and quality value. The evaluation shows that key phrases extracted from the narrative text \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ME8aQywAAAAJ:qUcmZB5y_30C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Subspace mapping of noisy text documents",
            "Publication year": 2011,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-642-21043-3_45",
            "Abstract": "Subspace mapping methods aim at projecting high-dimensional data into a subspace where a specific objective function is optimized. Such dimension reduction allows the removal of collinear and irrelevant variables for creating informative visualizations and task-related data spaces. These specific and generally de-noised subspaces spaces enable machine learning methods to work more efficiently. We present a new and general subspace mapping method, Correlative Matrix Mapping (CMM), and evaluate its abilities for category-driven text organization by assessing neighborhood preservation, class coherence, and classification. This approach is evaluated for the challenging task of processing short and noisy documents.",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:Mojj43d5GZwC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "Shape retrieval based on dynamic programming",
            "Publication year": 2000,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/817606/",
            "Abstract": "We propose a shape matching algorithm for deformed shapes based on dynamic programming. Our algorithm is capable of grouping together segments at finer scales in order to come up with appropriate correspondences with segments at coarser scales. We illustrate the effectiveness of our algorithm in retrieval of shapes by content on two different two-dimensional (2-D) datasets, one of static hand gesture shapes and another of marine life shapes. We also demonstrate the superiority of our approach over traditional approaches to shape matching and retrieval, such as Fourier descriptors and geometric and sequential moments. Our evaluation is based on human relevance judgments following a well-established methodology from the information retrieval field.",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:W7OEmFMy1HYC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Characterization of graphs using degree cores",
            "Publication year": 2006,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-540-78808-9_13",
            "Abstract": "Generative models are often used in modeling real world graphs such as the Web graph in order to better understand the processes through which these graphs are formed. In order to determine if a graph might have been generated by a given model one must compare the features of that graph with those generated by the model. We introduce the concept of a hierarchical degree core tree as a novel way of summarizing the structure of massive graphs. The degree core of level k is the unique subgraph of minimal degree k. Hierarchical degree core trees are representations of the subgraph relationships between the components of the degree core of the graph, ranging over all possible values of k. We extract features related to the graph\u2019s local structure from these hierarchical trees. Using these features, we compare four real world graphs (a web graph, a patent citation graph, a co-authorship graph and an \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ME8aQywAAAAJ:geHnlv5EZngC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "MiBio: A dataset for OCR post-processing evaluation",
            "Publication year": 2018,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S235234091830951X",
            "Abstract": "We introduce a dataset for OCR post-processing model evaluation. This dataset contains fully aligned OCR texts and the ground truth recognition texts of a English biodiversity book. To better used for benchmark evaluation, we extracted the following information in TSV files: 1) 2907 OCR-generated errors with position in the OCR texts and correction in the ground truth text, 2) ground truth word and sentence segmentation of the OCR texts. In this article, we detail the data preprocessing and provide quantitative data analysis.",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:mWEH9CqjF64C",
            "Publisher": "Elsevier"
        },
        {
            "Title": "A Visually Guided Swimming Robot. IEEE",
            "Publication year": 2005,
            "Publication url": "https://scholar.google.com/scholar?cluster=3408937836586876095&hl=en&oi=scholarr",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:j7_hQOaDUrUC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Collaborative exploration for the construction of visual maps",
            "Publication year": 2001,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/977157/",
            "Abstract": "We examine the problem of learning a visual map of the environment while maintaining an accurate pose estimate. Our approach is based on using two robots in a simple collaborative scheme. Without outside information, as a robot collects training images, its position estimate accumulates errors, thus corrupting its knowledge of the positions from which observations are taken. We address this problem by deploying a second robot to observe the first one as it explores, thereby establishing a virtual tether, and enabling an accurate estimate of the robot's position while it constructs the map. We refer to this process as cooperative localization. The images collected during this process are assembled into a representation that allows vision-based position estimation from a single image at a later date. In addition to developing a formalism and concept, we validate our results experimentally and present quantitative \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ME8aQywAAAAJ:ZeXyd9-uunAC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Vector space representation of concepts using wikipedia graph structure",
            "Publication year": 2017,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-319-59569-6_48",
            "Abstract": "We introduce a vector space representation of concepts using Wikipedia graph structure to calculate semantic relatedness. The proposed method starts from the neighborhood graph of a concept as the primary form and transfers this graph into a vector space to obtain the final representation. The proposed method achieves state of the art results on various relatedness datasets.Combining the vector space representation with standard coherence model, we show that the proposed relatedness method performs successfully in Word Sense Disambiguation (WSD). We then suggest a different formulation for coherence to demonstrate that, in a short enough sentence, there is one key entity that can help disambiguate every other entity. Using this finding, we provide a vector space based method that can outperform the standard coherence model in a significantly shorter computation time.",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:VN7nJs4JPk0C",
            "Publisher": "Springer, Cham"
        },
        {
            "Title": "Matching and retrieval of distorted and occluded shapes using dynamic programming",
            "Publication year": 2002,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/1046166/",
            "Abstract": "We propose an approach for matching distorted and possibly occluded shapes using dynamic programming (DP). We distinguish among various cases of matching such as cases where the shapes are scaled with respect to each other and cases where an open shape matches the whole or only a part of another open or closed shape. Our algorithm treats noise and shape distortions by allowing matching of merged sequences of consecutive small segments in a shape with larger segments of another shape, while being invariant to translation, scale, orientation, and starting point selection. We illustrate the effectiveness of our algorithm in retrieval of shapes on two data sets of two-dimensional open and closed shapes of marine life species. We demonstrate the superiority of our approach over traditional approaches to shape matching and retrieval based on Fourier descriptors and moments. We also compare our \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ME8aQywAAAAJ:IjCSPb-OGe4C",
            "Publisher": "IEEE"
        },
        {
            "Title": "Efficient parallelization of the google trigram method for document relatedness computation",
            "Publication year": 2015,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/7349900/",
            "Abstract": "Finding pair wise document relatedness plays an important role in a variety of Natural Language Processing problems. Google Trigram Method (GTM) is one of the corpus-based unsupervised method that can be used to capture word relatedness and document relatedness. It has been shown that it is possible to apply GTM to construct high quality document relatedness applications. However, there are challenges in implementing GTM for pair-wise document relatedness computation on a large volume of document set given its high computational complexity. This paper presents time and space efficient methods for the computation of pair-wise document relatedness using GTM. In order to improve the performance algorithmic engineering, data structure enhancement, and parallel computing methods are applied. Two parallel methods are discussed in this paper: shared memory multicore implementation and \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ME8aQywAAAAJ:L1USKYWJimsC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Interactive document clustering with feature supervision through reweighting",
            "Publication year": 2014,
            "Publication url": "https://content.iospress.com/articles/intelligent-data-analysis/ida00658",
            "Abstract": "Unsupervised document clustering groups documents into clusters without any user effort. However, the clusters produced are often found not in accord with user's perception of the document collection. In this paper we describe a novel framework and explore whether clustering performance can be improved by including user supervision at the feature level. Unlike existing semi-supervised clustering methods, which ask the user to label documents, this framework interactively asks the user to label features. The proposed method ranks all features based on the recent clusters using cluster-based feature selection and presents a list of highly ranked features to the user for labeling. The feature set for the next clustering iteration includes both features accepted by the user and other highly ranked features. The experimental results on several real datasets demonstrate that the feature set obtained using the new \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ME8aQywAAAAJ:CaZNVDsoPx4C",
            "Publisher": "IOS Press"
        },
        {
            "Title": "Adaptive visualization of text documents incorporating domain knowledge",
            "Publication year": 2010,
            "Publication url": "http://cseweb.ucsd.edu/~lvdmaaten/workshops/nips2010/papers/soto.pdf",
            "Abstract": "We present a method for visualizing text corpora that are assumed to contain labeled and unlabeled documents. Our method aims at learning data mappings of labeled documents including the terms that are most relevant for label discrimination. We can use this information to visualize mapped unlabeled documents as well. We also show how this method allows the inclusion of user\u2019s feedback. This feedback is supplied in an iterative process, so that the user can use the output of the method to provide its domain knowledge of the data. At the same time, this technique is well suited for providing a new low-dimensional space where traditional clustering or classification methods can be applied. Even though our approach is able to deal with document labels that are discrete classes, continuous values, or associated vectors, we confine the experiments of this article to labels that represent non-overlapped topics. This approach is evaluated using a set of short and noisy documents, which is considered as a challenging task in the text mining literature.",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:WqliGbK-hY8C",
            "Publisher": "Unknown"
        },
        {
            "Title": "A two-stage corrective markov model for activities of daily living detection",
            "Publication year": 2012,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-642-28783-1_21",
            "Abstract": "In this paper we propose a two-stage, supervised statistical model for detecting the activities of daily living (ADL) from sensor data streams. In the first stage each activity is modeled separately by a Markov model where sensors correspond to states. By modeling each sensor as a state we capture the absolute and relational temporal features of the atomic activities. A novel data segmentation approach is proposed for accurate inferencing at the first stage. To boost the accuracy, a second stage consisting of a Hidden Markov Model is added that serves two purposes. Firstly, it acts as a corrective stage, as it learns the probability of each activity being incorrectly inferred by the first stage, so that they can be corrected at the second stage. Secondly, it introduces inter-activity transition information to capture possible time-dependent relationships between two contiguous activities. We applied our method to three \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ME8aQywAAAAJ:vbGhcppDl1QC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "3D SLAM",
            "Publication year": 2007,
            "Publication url": "https://scholar.google.com/scholar?cluster=8622593845782003044&hl=en&oi=scholarr",
            "Abstract": "This paper presents a mobile robot simulation system which is developed for 3D SLAM experiment by multi-sensor fusion. Users could select sensors and there parameters, set working environments such as the number and position of landmarks, define a robot which will work in space, on land or in water, and design robot paths on the interface of the system. Then the system will start to navigate in the working area, measure the environment with its sensors, and implement SLAM algorithm based on the measurements. The robot trajectory and observed landmarks are rendered in any view point of the 3D space. Experiment results with 3D SLAM proved that the system is successful and convenient.In order to provide a convenient tool for evaluating 3D SLAM (Simultaneous Localization And Mapping) algorithms, a 3D simulation system (SLAM 3DSim) was developed, in which a robot equipped with sensors such as \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ME8aQywAAAAJ:zLWjf1WUPmwC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Audiovisual localization of multiple speakers in a video teleconferencing setting",
            "Publication year": 2003,
            "Publication url": "https://onlinelibrary.wiley.com/doi/abs/10.1002/ima.10045",
            "Abstract": "Attending to multiple speakers in a video teleconferencing setting is a complex task. From a visual point of view, multiple speakers can occur at different locations and present radically different appearances. From an audio point of view, multiple speakers may be speaking at the same time, and background noise may make it difficult to localize sound sources without some a priori estimate of the sound source locations. This article presents a novel sensor and corresponding sensing algorithms to address the task of attending, simultaneously, to multiple speakers for video teleconferencing. A panoramic visual sensor is used to capture a 360\u00b0 view of the speakers in the environment and from this view potential speakers are identified via a color histogram approach. A directional audio system based on beamforming is then used to confirm potential speakers and attend to them. Experimental evaluation of the sensor \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ME8aQywAAAAJ:_kc_bZDykSQC",
            "Publisher": "Wiley Subscription Services, Inc., A Wiley Company"
        },
        {
            "Title": "Neural Abstractive Unsupervised Summarization of Online News Discussions",
            "Publication year": 2021,
            "Publication url": "https://arxiv.org/abs/2106.03953",
            "Abstract": "Summarization has usually relied on gold standard summaries to train extractive or abstractive models. Social media brings a hurdle to summarization techniques since it requires addressing a multi-document multi-author approach. We address this challenging task by introducing a novel method that generates abstractive summaries of online news discussions. Our method extends a BERT-based architecture, including an attention encoding that fed comments' likes during the training stage. To train our model, we define a task which consists of reconstructing high impact comments based on popularity (likes). Accordingly, our model learns to summarize online discussions based on their most relevant comments. Our novel approach provides a summary that represents the most relevant aspects of a news item that users comment on, incorporating the social context as a source of information to summarize texts in online social networks. Our model is evaluated using ROUGE scores between the generated summary and each comment on the thread. Our model, including the social attention encoding, significantly outperforms both extractive and abstractive summarization methods based on such evaluation.",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:unp9ATQDT5gC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Comparing word relatedness measures based on Google n-grams-grams",
            "Publication year": 2012,
            "Publication url": "https://www.aclweb.org/anthology/C12-2049.pdf",
            "Abstract": "Estimating word relatedness is essential in natural language processing (NLP), and in many other related areas. Corpus-based word relatedness has its advantages over knowledge-based supervised measures. There are many corpus-based measures in the literature that can not be compared to each other as they use a different corpus. The purpose of this paper is to show how to evaluate different corpus-based measures of word relatedness by calculating them over a common corpus (ie, the Google n-grams) and then assessing their performance with respect to gold standard relatedness datasets. We evaluate six of these measures as a starting point, all of which are re-implemented using the Google n-gram corpus as their only resource, by comparing their performance in five different data sets. We also show how a word relatedness measure based on a web search engine can be implemented using the Google n-gram corpus.",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:sJsF-0ZLhtgC",
            "Publisher": "Unknown"
        },
        {
            "Title": "NetPal: A Dynamic Network Administration Knowledge Base",
            "Publication year": 2008,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/1463788.1463815",
            "Abstract": "Netpal is a web-based dynamic knowledge base system designed to assist network administrators in their troubleshooting tasks, in recalling and storing experience, and in identifying new failure cases and their symptoms. In the context of web hosting environments, Netpal summarises network data and and supports retrieval of relevant organisational experience for system administrators. The system design draws on a variety of domains including knowledge management, information retrieval, machine learning and network management. We describe the system architecture, user interface design, user software testing and future directions for development.",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:ILKRHgRFtOwC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Document clustering using character N-grams: a comparative evaluation with term-based and word-based clustering",
            "Publication year": 2005,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/1099554.1099665",
            "Abstract": "We propose a novel method for document clustering using character N-grams. In the traditional vector-space model, the documents are represented as vectors, in which each dimension corresponds to a word. We propose a document representation based on the most frequent character N-grams, with window size of up to 10 characters. We derive a new distance measure, which produces uniformly better results when compared to the word-based and term-based methods. The result becomes more significant in the light of the robustness of the N-gram method with no language-dependent preprocessing. Experiments on the performance of a clustering algorithm on a variety of test document corpora demonstrate that the N-gram representation with n= 3 outperforms both word and term representations. The comparison between word and term representations depends on the data set and the selected dimensionality.",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:maZDTaKrznsC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Modelling and mining of networked information spaces",
            "Publication year": 2006,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-540-78808-9_1",
            "Abstract": "In recent years, the emergence of the Web and the dramatic increase in computing, storage and networking capacity has given rise to the concept of networked information spaces. The prime example of a networked information space is the World Wide Web itself. The Web, in its pure form, is a set of hypertext documents, with links in one document pointing to another document.",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:LjlpjdlvIbIC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "A visual approach for interactive expertise finding and exploration",
            "Publication year": 2016,
            "Publication url": "https://projects.cs.dal.ca/visualtextanalytics/wp-content/uploads/2017/02/Visual_DDTA2016.pdf",
            "Abstract": "Members of knowledge-intensive organizations (eg universities) is publishing considerable amounts of unstructured and semi-structured textual data such as research papers, tutorials, technical reviews. This data is a comprehensive description of both the members\u2019 expertise and the organization\u2019s goals. Exploring this document collection helps the organization to find the appropriate skillsets and expertise to improve their business. As the size of this document collection increases, analyzing this data to gain an insight becomes quite challenging. One solution is applying a clustering and topic modeling technique to these documents in order to help the organization to quickly find its major direction in the past months. Even the best clustering approach is not completely satisfactory and may produce some unintuitive results. To tackle this problem we have designed an interactive document clustering and keyword mining system using visualization which can be utilized to find the skillsets of an organization. Keyterm-based interactive approaches are arguably very intuitive for the users to guide the text clustering process and adapt the clustering results to the various applications in the text analysis. To demonstrate the usefulness of the proposed system, we have conducted a case study on a collection of data belonging to the School of Law and we supported the exploration process of the School in identifying its research directions over the past thirty years.",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:O0nohqN1r9EC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Self-configuration fuzzy system for inverse kinematics of robot manipulators",
            "Publication year": 2006,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/4216772/",
            "Abstract": "Kinematics is the study of motion without regard to the forces that create it. Generally, kinematics for robot manipulators includes two problems, forward kinematics problem and inverse kinematics problem. Because of the complexity of inverse kinematics, it is difficult to find the solutions for it. This paper applies a self-configuration fuzzy system to finding the solutions for inverse kinematics of robot manipulators. In this paper, the problem of fuzzy approach for inverse kinematics is described first. Then a self-configuration fuzzy system is introduced. Based on a small group of given input-output pairs selected by covering its workspace, an initially simple fuzzy model for inverse kinematics is built, including some basic rules, the number and the parameters of membership functions. Then, by applying given input-output data pairs to this simple fuzzy model, approximating error can be calculated. Consequently, the optimum \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ME8aQywAAAAJ:_xSYboBqXhAC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Using google n-grams to expand word-emotion association lexicon",
            "Publication year": 2013,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-642-37256-8_12",
            "Abstract": "We present an approach to automatically generate a word-emotion lexicon based on a smaller human-annotated lexicon. To identify associated feelings of a target word (a word being considered for inclusion in the lexicon), our proposed approach uses the frequencies, counts or unique words around it within the trigrams from the Google n-gram corpus. The approach was tuned using as training lexicon, a subset of the National Research Council of Canada (NRC) word-emotion association lexicon, and applied to generate new lexicons of 18,000 words. We present six different lexicons generated by different ways using the frequencies, counts, or unique words extracted from the n-gram corpus. Finally, we evaluate our approach by testing each generated lexicon against a human-annotated lexicon to classify feelings from affective text, and demonstrate that the larger generated lexicons perform better than \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ME8aQywAAAAJ:fFSKOagxvKUC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "Word sense disambiguation: an evaluation study of semi-supervised approaches with word embeddings",
            "Publication year": 2020,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/9207225/",
            "Abstract": "Word Sense Disambiguation (WSD) is a well-known problem in the field of Natural Language Processing (NLP) related to automatically determining the most appropriate sense of words in context. Several machine learning-based approaches have been proposed to tackle the ambiguity of language, but the lack of labeled data to train supervised models made semi-supervised learning (SSL) appear as an attractive option. Furthermore, the use of word embeddings to enhance the results of NLP tasks was shown to be an efficient strategy. Thus, this paper aims at adapting semi-supervised algorithms for WSD using word embeddings from Word2Vec, FastText, and BERT models combined with part-of-speech tags as input. We conduct a systematic evaluation of four graph-based SSL models analyzing the influence of their hyperparameters on the results, as well as the distances to build the graphs, the percentages of \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ME8aQywAAAAJ:wE-fMHVdjMkC",
            "Publisher": "IEEE"
        },
        {
            "Title": "System behavior characterization via information content clustering of system logs",
            "Publication year": 2011,
            "Publication url": "https://cdn.dal.ca/content/dam/dalhousie/pdf/faculty/computerscience/technical-reports/CS-2011-02.pdf",
            "Abstract": "Self-awareness or the ability to be informed about system internal state is an important attribute for any system to have before it is capable of self-management. This is irrespective of which of the self-* properties of self-management in autonomic systems we choose to achieve. A system needs to have a continuous stream of real-time data to analyze to allow it be aware of its internal state. To this end, previous approaches have utilized system performance metrics and system log data as a means of characterizing system behaviour and internal state. In this work, we propose a scheme which utilizes the entropybased information content to group spatio-temporal partitions of system log data into conceptual clusters. We evaluate our method using cluster cohesion, cluster separation and cluster conceptual purity as metrics on High Performance Cluster (HPC) system log data. The results show that our proposed method not only produces well-formed clusters but also clusters that can mapped to different kinds of alert behavior with a high degree of confidence. These results provide evidence that clusters produced by the proposed method characterize the different behaviors of the system and hence capture information about internal state. Hence they have value for the enhancement of self-awareness. The ability to differentiate among types of behavior (both normal and abnormal) is also valuable for self-monitoring and fault detection as deviations from types of normal behavior could be indicative of a fault.",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:eq2jaN3J8jMC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Graph-based automatic consistent image mosaicking",
            "Publication year": 2004,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/1521840/",
            "Abstract": "Consistent image mosaicking is a potentially useful tool for robot navigation and map construction. This paper presents an automatic algorithm to generate consistent image mosaicking. During the robot processing, local optimization based on the related previous images is used for every newly added image on the baseline approach view. As soon as a loop is detected, a global optimization method is activated to generate a globally consistent image mosaicking. This method is very efficient in computation and storage saving",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:NMxIlDl6LWMC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Early detection of rumor veracity in social media",
            "Publication year": 2019,
            "Publication url": "https://scholarspace.manoa.hawaii.edu/handle/10125/59674",
            "Abstract": "Rumor spread has become a significant issue in online social networks (OSNs). To mitigate and limit the spread of rumors and its detrimental effects, analyzing, detecting and better understanding rumor dynamics is required. One of the critical steps of studying rumor spread is to identify the level of the rumor truthfulness in its early stage. Understanding and identifying the level of rumor truthfulness helps prevent its viral spread and minimizes the damage a rumor may cause. In this research, we aim to debunk rumors by analyzing, visualizing, and classifying the level of rumor truthfulness from a large number of users that actively engage in rumor spread. First, we create a dataset of rumors that belong to one of five categories: \"False\", \"Mostly False\", \"True\", \"Mostly True\", and \"Half True\". This dataset provides intrinsic characteristics of a rumor: topics, user's sentiment, network structural and content features. Second, we analyze and visualize the characteristics of each rumor category to better understand its features. Third, using theories from social science and psychology, we build a feature set to classify those rumors and identify their truthfulness. The evaluation results on our new dataset show that the approach could effectively detect the truth of rumors as early as seven days. The proposed approach could be used as a valuable tool for existing fact-checking websites, such as Snopes.com or Politifact.com, to detect the veracity of rumors in its early stage automatically and educate OSN users to have a well-informed decision-making process.",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:HJSXoJQnj-YC",
            "Publisher": "Unknown"
        },
        {
            "Title": "A Visually Guided Swimming Robot",
            "Publication year": 2005,
            "Publication url": "http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.61.498",
            "Abstract": "We describe recent results obtained with AQUA, a mobile robot capable of swimming, walking and amphibious operation. Designed to rely primarily on visual sensors, the AQUA robot uses vision to navigate underwater using servobased guidance, and also to obtain high-resolution range scans of its local environment. This paper describes some of the pragmatic and logistic obstacles encountered, and provides an overview of some of the basic capabilities of the vehicle and its associated sensors. Moreover, this paper presents the first ever amphibious transition from walking to swimming.",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:g5Ck-dwhA_QC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Active High-Recall Information Retrieval from Domain-Specific Text Corpora based on Query Documents",
            "Publication year": 2018,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/3209280.3209532",
            "Abstract": "In this paper, we propose a high recall active document retrieval system for a class of applications involving query documents, as opposed to key terms, and domain-specific document corpora. The output of the model is a list of documents retrieved based on the domain expert feedback collected during training. A modified version of Bag of Word (BoW) representation and a semantic ranking module, based on Google n-grams, are used in the model. The core of the system is a binary document classification model which is trained through a continuous active learning strategy. In general, finding or constructing training data for this type of problem is very difficult due to either confidentiality of the data, or the need for domain expert time to label data. Our experimental results on the retrieval of Call For Papers based on a manuscript demonstrate the efficacy of the system to address this application and its performance \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ME8aQywAAAAJ:TlpoogIpr_IC",
            "Publisher": "Unknown"
        },
        {
            "Title": "EulerianGrapher: Text Visualisation at the Level of Character N--grams based on Eulerian Graphs",
            "Publication year": 2017,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/3038462.3038472",
            "Abstract": "Network analysis has been applied widely in different domains, providing a unified language to describe disparate domains. In this paper we present an interactive visualisation of graph--based ranking measures of text character n--grams. The visualisation provides insights into overall characteristics of the observed text, and an interactive manipulation of different parameters used to adjust, filter or emphasize relevant n--grams in the graph.",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:RoXSNcbkSzsC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Graph-based exploration using multiple robots",
            "Publication year": 2000,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-4-431-67919-6_23",
            "Abstract": "We present an approach to multi-robot exploration of large environments. Our method is designed to be robust in the face of arbitrarily large odometry errors or objects with poor reflectance characteristics. The algorithm achieves its robustness by using a team of cooperating agents. The critical aspect of our method is the use of a vision system that sweeps areas of free space and generates a graph-based description of the environment. This graph is used to guide the exploration process and can also be used for subsequent tasks such as place recognition or path planning. As a result of the guidance provided by the dual graph of the triangulated environment, our system can guarantee complete exploration without any overlaps.We present an algorithmic solution, simulation results, as well as a cost analysis and experimental data. In this approach a pair of robots observe one another\u2019s behavior, thus \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ME8aQywAAAAJ:YOwf2qJgpHMC",
            "Publisher": "Springer, Tokyo"
        },
        {
            "Title": "Natural search pointers\u2014A query formulation method for structured information search",
            "Publication year": 2008,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/4581436/",
            "Abstract": "Despite a wide variety of new solutions, structured information search still has only one practical approach - form-based interface. A key limitation of this interface is poor handling of iterative search. While browsing the results users have to memorize all new search constraints, go back to the form, and enter them into the appropriate fields. To overcome this obstacle we created Natural Search Pointers -a structured information search interface, which formulates search queries based on information highlighted by a user while browsing the search results. NSP can be used as an extension of any standard form-based interface for consumer-oriented database search engines. Comparison of traditional form-based interface and its NSP extension shows that in iterative search tasks NSP makes finding information faster and more convenient.",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:ZuybSZzF8UAC",
            "Publisher": "IEEE"
        },
        {
            "Title": "SAVI: an actively controlled teleconferencing system",
            "Publication year": 2001,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S0262885600001074",
            "Abstract": "A Stereo Active Vision Interface (SAVI) is introduced which detects frontal faces in real world environments and performs particular active control tasks dependent on hand gestures given by the person the system attends to. The SAVI system is thought of as a smart user interface for teleconferencing, telemedicine, and distance learning applications.To reduce the search space in the visual scene the processing is started with the detection of connected skin colour regions applying a new radial scanline algorithm. Subsequently, in the most salient skin colour region facial features are searched for while the skin colour blob is actively kept in the centre of the visual field of the camera system. After a successful evaluation of the facial features the associated person is able to give control commands to the system. For this contribution only visual control commands are investigated but there is no limitation for voice or any \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ME8aQywAAAAJ:HDshCWvjkbEC",
            "Publisher": "Elsevier"
        },
        {
            "Title": "When was macbeth written? mapping book to time",
            "Publication year": 2015,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-319-18111-0_6",
            "Abstract": "We address the question of predicting the time when a book was written using the Google Books Ngram corpus. This prediction could be useful for authorship and plagiarism detection, identification of literary movements, and forensic document examination. We propose an unsupervised approach and compare this with four baseline measures on a dataset consisting of 36 books written between 1551 and 1969. The proposed approach could be applicable to other languages as long as corpora of those languages similar to the Google Books Ngram are available.",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:7Hz3ACDFbsoC",
            "Publisher": "Springer, Cham"
        },
        {
            "Title": "Multi-robot cooperative localization: a study of trade-offs between efficiency and accuracy",
            "Publication year": 2002,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/1041676/",
            "Abstract": "This paper examines the tradeoffs between different classes of sensing strategy and motion control strategy in the context of terrain mapping with multiple robots. We consider a larger group of robots that can mutually estimate one another's position (in 2D or 3D) and uncertainty using a sample-based (particle filter) model of uncertainty. Our prior work has dealt with a pair of robots that estimate one another's position using visual tracking and coordinated motion. Here we extend these results and consider a richer set of sensing and motion options. In particular, we focus on issues related to confidence estimation for groups of more than two robots.",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:YsMSGLbcyi4C",
            "Publisher": "IEEE"
        },
        {
            "Title": "A unified framework for document clustering with dual supervision",
            "Publication year": 2012,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/2340416.2340421",
            "Abstract": "Semi-supervised clustering algorithms for general problems use a small amount of labeled instances or pairwise instance constraints to aid the unsupervised clustering. However, user supervision can also be provided in alternative forms for document clustering, such as labeling a feature by associating it with a document or a cluster. Besides labeled documents, this paper also explores labeled features to generate cluster seeds to seed the unsupervised clustering. In this paper, we present a unified framework in which one can use both labeled documents and features in terms of seeding clusters and refine this information using intermediate clusters. We introduce two methods of using labeled features to generate cluster seeds. Experimental results on several real-world data sets demonstrate that constraining the clustering by both documents and features seeding can significantly improve document clustering \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ME8aQywAAAAJ:4fGpz3EwCPoC",
            "Publisher": "ACM"
        },
        {
            "Title": "Enriching the legacy literature with OCR corrections and text-mined semantic metadata",
            "Publication year": 2014,
            "Publication url": "https://mbgocs.mobot.org/index.php/tdwg/2014/paper/view/588/0",
            "Abstract": "The Biodiversity Heritage Library (BHL) holds the largest collection of digitised legacy literature on biodiversity. Accessible as an online, fully-featured digital library, BHL stores bibliographic metadata for digital objects, allowing its users to issue keyword-based searches over the entire collection. Furthermore, owing to the application of optical character recognition (OCR) technology on scanned items (eg, books, monographs, journals), textual content has been made available in machine-readable form, as well as automatically linked to taxonomic names in the Encyclopedia of Life (EOL). In the work presented herein, we report on our recent efforts aimed at the further advancement of the above-mentioned BHL functionalities. In terms of content rectification, the quality of available texts is being improved through the detection and correction of OCR-generated errors using an unsupervised statistical procedure \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ME8aQywAAAAJ:w1MjKQ0l0TYC",
            "Publisher": "Unknown"
        },
        {
            "Title": "HIDDEN IN SSL STREAMS USING MACHINE LEARNING",
            "Publication year": 2010,
            "Publication url": "https://scholar.google.com/scholar?cluster=4138760218037076278&hl=en&oi=scholarr",
            "Abstract": "Permission is herewith granted to Dalhousie University to circulate and to have copied for non-commercial purposes, at its discretion, the above title upon the request of individuals or institutions. Signature of Author The author reserves other publication rights, and neither the thesis nor extensive extracts from it may be printed or otherwise reproduced without the author\u2019s written permission. The author attests that permission has been obtained for the use of any copyrighted material appearing in the thesis (other than brief excerpts requiring only proper acknowledgement in scholarly writing) and that all such use is clearly acknowledged.",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:T_ojBgVMvoEC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Experiments in free-space triangulation using cooperative localization",
            "Publication year": 2003,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/1248901/",
            "Abstract": "This paper presents a first detailed case study of collaborative exploration of a substantial environment. We use a pair of cooperating robots to test multi-robot environment mapping algorithms based on triangulation of free space. The robots observe one another using a robot tracking sensor based on laser range sensing (LIDAR). The environment mapping itself is accomplished using sonar sensing. The results of this mapping are compared to those obtained using scanning laser range sensing and the scan matching algorithm. We show that with appropriate outlier rejection policies, the sonar-based map obtained using collaborative localization can be as good or, in fact, better than that obtained using what is typically considered to be a superior sensing technology.",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:e5wmG9Sq2KIC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Efficient Map Building for 3D SLAM",
            "Publication year": 2007,
            "Publication url": "https://scholar.google.com/scholar?cluster=15382452702753360229&hl=en&oi=scholarr",
            "Abstract": "There are many kinds of maps which could be used by autonomous mobile robot, such as occupancy grid map, stochastic feature map, topological map, and hierarchical map. In this paper, we are focused on the stochastic feature map. For vision-based robot navigation, there are huge numbers of features in the map if SIFT feature is applied, which will cause a heavy burden for some search operations and storage. A new algorithm has been designed to build an efficient map based-on set theory and clustering method. Simulation and experiment results are displayed.",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:-FonjvnnhkoC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Relative N-gram signatures: Document visualization at the level of character N-grams",
            "Publication year": 2012,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/6400484/",
            "Abstract": "The Common N-Gram (CNG) classifier is a text classification algorithm based on the comparison of frequencies of character n-grams (strings of characters of length n) that are the most common in the considered documents and classes of documents. We present a text analytic visualization system that employs the CNG approach for text classification and uses the differences in frequency values of common n-grams in order to visually compare documents at the sub-word level. The visualization method provides both an insight into n-gram characteristics of documents or classes of documents and a visual interpretation of the workings of the CNG classifier.",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:OcBU2YAGkTUC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Neural Abstractive Unsupervised Summarization of Online News Discussions",
            "Publication year": 2021,
            "Publication url": "https://ui.adsabs.harvard.edu/abs/2021arXiv210603953T/abstract",
            "Abstract": "Summarization has usually relied on gold standard summaries to train extractive or abstractive models. Social media brings a hurdle to summarization techniques since it requires addressing a multi-document multi-author approach. We address this challenging task by introducing a novel method that generates abstractive summaries of online news discussions. Our method extends a BERT-based architecture, including an attention encoding that fed comments' likes during the training stage. To train our model, we define a task which consists of reconstructing high impact comments based on popularity (likes). Accordingly, our model learns to summarize online discussions based on their most relevant comments. Our novel approach provides a summary that represents the most relevant aspects of a news item that users comment on, incorporating the social context as a source of information to summarize texts in \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ME8aQywAAAAJ:EsEWqaRxkBgC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Acoustic positioning using multiple microphone arrays",
            "Publication year": 2005,
            "Publication url": "https://asa.scitation.org/doi/abs/10.1121/1.1895005",
            "Abstract": "Passive acoustic techniques are presented to solve the localization problem of a sound source in three-dimensional space using off-the-shelf hardware. Multiple microphone arrays are employed, which operate independently, in estimating the direction of arrival of sound, or, equivalently, a direction vector from the array\u2019s geometric center towards the source. Direction vectors and array centers are communicated to a central processor, where the source is localized by finding the intersection of the direction lines defined by the direction vectors and the associated array centers. The performance of the method in the air is demonstrated experimentally and compared with a state-of-the-art method that requires centralized digitization of the signals from the microphones of all the arrays.",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:hFOr9nPyWt4C",
            "Publisher": "Acoustical Society of America"
        },
        {
            "Title": "Event evolution tracking from streaming social posts",
            "Publication year": 2013,
            "Publication url": "https://arxiv.org/abs/1311.5978",
            "Abstract": "Online social post streams such as Twitter timelines and forum discussions have emerged as important channels for information dissemination. They are noisy, informal, and surge quickly. Real life events, which may happen and evolve every minute, are perceived and circulated in post streams by social users. Intuitively, an event can be viewed as a dense cluster of posts with a life cycle sharing the same descriptive words. There are many previous works on event detection from social streams. However, there has been surprisingly little work on tracking the evolution patterns of events, e.g., birth/death, growth/decay, merge/split, which we address in this paper. To define a tracking scope, we use a sliding time window, where old posts disappear and new posts appear at each moment. Following that, we model a social post stream as an evolving network, where each social post is a node, and edges between posts are constructed when the post similarity is above a threshold. We propose a framework which summarizes the information in the stream within the current time window as a ``sketch graph'' composed of ``core'' posts. We develop incremental update algorithms to handle highly dynamic social streams and track event evolution patterns in real time. Moreover, we visualize events as word clouds to aid human perception. Our evaluation on a real data set consisting of 5.2 million posts demonstrates that our method can effectively track event dynamics in the whole life cycle from very large volumes of social streams on the fly.",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:Ak0FvsSvgGUC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Model-based overlapping co-clustering",
            "Publication year": 2006,
            "Publication url": "http://www.siam.org/meetings/sdm06/workproceed/Text%20Mining/shafiei16.pdf",
            "Abstract": "Co-clustering or simultaneous clustering of rows and columns of two-dimensional data matrices, is a data mining technique with various applications such as text clustering and microarray analysis. Most proposed co-clustering algorithms work on the data matrices with special assumptions and they also assume the existence of a number of mutually exclusive row and column clusters, but it is believed that such an ideal structure rarely exists in real data. In this paper, we propose an overlapping co-clustering model which is able to work with any regular exponential family distribution, and corresponding Bregman divergences, thereby making the model applicable to a wide variety of clustering distance functions. The algorithm using a generative model is able to discover overlapping co-clusters in the input data matrix. The necessary algorithms are provided for this model, and the effectiveness of the method is demonstrated through experiments on subsets of Reuters and MovieLens datasets compared to several other clustering methods.",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:blknAaTinKkC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Learning in efficient tag recommendation",
            "Publication year": 2010,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/1864708.1864741",
            "Abstract": "The objective of a tag recommendation system is to propose a set of tags for a resource to ease the tagging process done manually by a user. Tag recommendation is an interesting and well defined research problem. However, while solving it, it is easy to forget about its practical implications. We discuss the practical aspects of tag recommendation and propose a system that successfully addresses the problem of learning in tag recommendation, without sacrificing efficiency. Learning is realized in two aspects: adaptation to newly added posts and parameter tuning. The content of each added post is used to update the resource and user profiles as well as associations between tags. Parameter tuning allows the system to automatically adjust the way tag sources (eg, content related tags or user profile tags) are combined to match the characteristics of a specific collaborative tagging system. The evaluation on data \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ME8aQywAAAAJ:1sJd4Hv_s6UC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Virtual audio systems",
            "Publication year": 2008,
            "Publication url": "https://direct.mit.edu/pvar/article-abstract/17/6/527/18723",
            "Abstract": "To be immersed in a virtual environment, the user must be presented with plausible sensory input including auditory cues. A virtual (three-dimensional) audio display aims to allow the user to perceive the position of a sound source at an arbitrary position in three-dimensional space despite the fact that the generated sound may be emanating from a fixed number of loudspeakers at fixed positions in space or a pair of headphones. The foundation of virtual audio rests on the development of technology to present auditory signals to the listener's ears so that these signals are perceptually equivalent to those the listener would receive in the environment being simulated. This paper reviews the human perceptual and technical literature relevant to the modeling and generation of accurate audio displays for virtual environments. Approaches to acoustical environment simulation are summarized and the advantages \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ME8aQywAAAAJ:iH-uZ7U-co4C",
            "Publisher": "MIT Press"
        },
        {
            "Title": "Statistical analysis of dynamic communications graphs",
            "Publication year": 2006,
            "Publication url": "https://scholar.google.com/scholar?cluster=17283101527952928419&hl=en&oi=scholarr",
            "Abstract": "Communication networks can be modeled as dynamic graphs with time-varying edges. Real-life events may cause communications that are unusual in either volume or pattern. Given such a dynamic graph with embedded events, can we detect when and where those events occur? The answer to this question is crucial for counter terrorism, network surveillance and traffic management. Most event detection methods only focus on network-wide events. However, events associated with only a few individuals are more common and of significant interest, as well. In this project, we focus on events with only local impacts. We use three metrics to characterize people\u2019s communications from different viewpoints. Based on the variations of these metrics over time, we detect and discriminate local events. Experiments on email data from our Faculty show that these metrics are effective in identifying events, and the signals of \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ME8aQywAAAAJ:M7yex6snE4oC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Trivir: A visualization system to support document retrieval with high recall",
            "Publication year": 2019,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/3342558.3345401",
            "Abstract": "In this paper, we propose TRIVIR, a novel interactive visualization tool powered by an Information Retrieval (IR) engine that implements an active learning protocol to support IR with high recall. The system integrates multiple graphical views in order to assist the user identifying the relevant documents in a collection, including a content-based similarity map obtained with multidimensional projection techniques. Given representative documents as queries, users can interact with the views to label documents as relevant/not relevant, and this information is used to train a machine learning (ML) algorithm which suggests other potentially relevant documents on demand. TRIVIR offers two major advantages over existing visualization systems for IR. First, it merges the ML algorithm output into the visualization, while supporting several user interactions in order to enhance and speed up its convergence. Second, it tackles \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ME8aQywAAAAJ:aIdbFUkbNIkC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Efficient retrieval of deformed and occluded shapes",
            "Publication year": 2000,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/902866/",
            "Abstract": "We propose an approach for matching deformed and occluded shapes using dynamic programming. Our algorithms handle noise and shape distortions by allowing matching of merged sequences of consecutive small segments in a shape, with larger segments of another shape, while being invariant to translation, scale and orientation transformations of shapes. We illustrate the effectiveness of our algorithms in retrieval of shapes on two different two-dimensional datasets: one of static hand gesture shapes and another of marine life shapes.",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:BrmTIyaxlBUC",
            "Publisher": "IEEE"
        },
        {
            "Title": "A taxonomy of multirobot systems",
            "Publication year": 2002,
            "Publication url": "http://www.cim.mcgill.ca/ftp/mobile-robot/taxonomy-book.pdf",
            "Abstract": "A key difficulty in the design of multi-agent robotic systems is the size and complexity of the space of possible designs. In order to make principled design decisions, an understanding of the many possible system configurations is essential. In Dudek et al.[DJMW96] we presented a taxonomy that classifies multi-agent systems according to communication, computational and other capabilities. In this chapter we update the taxonomy developed in the early 1990's and place a number of recent multirobot systems within it.Task oriented behaviour by groups of agents is ubiquitous in nature. How and why should multiple mobile robots be used for a task? Although most mobile robotic systems involve a single robot operating alone in its environment, a number of researchers have considered the problems and potential advantages involved in having an environment inhabited by a group of robots which cooperate in order to complete some required task. For some specific robotic tasks, such as exploring an unknown planet [AB98], pushing objects [Par94b, MN\u00cb95, RDJ95], or cleaning up toxic waste [Par98], it has been suggested that rather than sending one very complex robot to perform the task it would more effective to send a number of",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:eQOLeE2rZwMC",
            "Publisher": "Natick, MA: AK Peters"
        },
        {
            "Title": "Relaxing Orthogonality Assumption in Conceptual Text Document Similarity",
            "Publication year": 2016,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/2960811.2960813",
            "Abstract": "By reflecting the degree of proximity or remoteness of documents, similarity measure plays the key role in text analytics. Traditional measures, eg cosine similarity, assume that documents are represented in an orthogonal space formed by words as dimensions.",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:6_hjMsCP8ZoC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Underwater robot localization using artificial visual landmarks",
            "Publication year": 2004,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/1521867/",
            "Abstract": "Accurate localization for underwater robot is a big challenge in the mobile robot community. We use acoustic and visual-based approaches to solve the problem. In this paper, we focuses on the artificial landmark visual-based localization. The robot carries the camera to localize its position by calculating the camera's viewpoint through looking at the landmarks. The position of landmarks is known in a world-centered coordinate system (WCCS). A method is presented in this paper to recover the camera's viewpoint with minimum three feature points and a single image from one camera. Two steps are used in this paper: first step is to calculate the feature points' 3D coordinates in a camera centered coordinate system (CCCS); second step is to obtain a closed-form solution through the geometric transformations to map the 3D points from CCCS to WCCS. The algorithm is robust and efficient. It uses the fewest feature \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ME8aQywAAAAJ:4OULZ7Gr8RgC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Virtual culture: Work and play on the internet",
            "Publication year": 2005,
            "Publication url": "http://web.cs.dal.ca/~eem/res/pubs/pubs/Tastsoglou_NetworkNetplay.pdf",
            "Abstract": "This book is a collection of articles on various aspects of the formation and functioning of virtual groups on the Internet. The Internet communication infrastructure enables communication among geographically dispersed groups of people. Although the underlying technology is recent, it is fairly well understood. However, the dramatic rise of Internet access in recent years has led to new conditions of communication, the sociological implications of which are not well understood, as there has simply not passed enough time to observe the use people make of the technology. The book reports on several projects which aimed at filling this gap. The intended audience of the book includes anyone interested in computer mediated communication, with emphasis on group communications, such as newsgroups (open to anyone at large), multi-user virtual worlds (MUDs), mailing lists (with a restricted set of participants). The book is very diverse in terms of methodologies used in the individual chapters. Some chapters are based on empirical research, using data collected from newsgroups or mailing lists (Jones, Witmer & al, Mabry, Berthold&al) and applying statistical tools to draw conclusions, others present technology for virtual cooperative interaction (Chen & Gaines, Doyle & Hayes-Roth), and yet others discuss frameworks for studying Internet-based communication (Voiskounsky). Statistical tools used range from classical hypothesis testing (Witmer & Katzman, Mabry), tabulation and classification of results (Jones) to sophisticated use of self-organizing artificial neural networks to study typicality of messages (Berthold & al).The book\u2019s main strength is \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ME8aQywAAAAJ:AvfA0Oy_GE0C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Algorithms and Models for the Web-Graph: Fourth International Workshop, WAW 2006, Banff, Canada, November 30-December 1, 2006, Revised Papers",
            "Publication year": 2008,
            "Publication url": "https://books.google.com/books?hl=en&lr=&id=ZNGpCAAAQBAJ&oi=fnd&pg=PP2&dq=info:V19_NnvYOfwJ:scholar.google.com&ots=8uCx2S-7a5&sig=HLGELXrx3HSwTNfyahfCqBgNT6Q",
            "Abstract": "This book contains the revised papers of the Fourth International Workshop on Algorithms and Models for the Web-Graph. It covers a wide range of topics in the study of the Web-graph such as algorithms, PageRank analysis and computational as well as clustering.",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:ODE9OILHJdcC",
            "Publisher": "Springer"
        },
        {
            "Title": "Do Important Words in Bag-of-Words Model of Text Relatedness Help?",
            "Publication year": 2015,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-319-24033-6_64",
            "Abstract": "We address the question of how Bag-of-Words (BoW) models of text relatedness can be improved by using important words in the text-pair instead of all the words. To find important words in a text, we use a new approach based on word relatedness. We use two text relatedness methods: Latent Semantic Analysis (LSA) and Google Trigram Model (GTM) on five different datasets where words in the text-pair are sorted based on importance. We compare the use of a small number of important words against the use of all the words in the texts, and we find that both LSA and GTM achieve better results on four of the data sets and the same result on the fifth dataset.",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:PYBJJbyH-FwC",
            "Publisher": "Springer, Cham"
        },
        {
            "Title": "Short text stream clustering via frequent word pairs and reassignment of outliers to clusters",
            "Publication year": 2020,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/3395027.3419589",
            "Abstract": "Short text stream clustering is an important but challenging task since massive amounts of text are generated from different social media. Given streams of texts, the proposed method clusters the streams of texts based on the frequently occurring word pairs (not necessarily consecutive) in texts. It detects outliers in the clusters and reassigns the outliers to appropriate clusters using the semantic similarity between the outliers and the clusters based on the dynamically computed similarity thresholds. Thus the proposed method efficiently deals with the concept drift problem. Experimental results demonstrate that the proposed approach outperforms the state-of-the-art short text stream clustering algorithms by a statistically significant margin on several short text datasets.",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:zdjWy_NXXwUC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Collaborative exploration for map construction",
            "Publication year": 2001,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/1013215/",
            "Abstract": "We consider the problem of map learning while maintaining ground-truth pose estimates. Map learning is important in tasks that require a model of the environment or some of its features. As a robot collects data, uncertainty about its position accumulates and corrupts its knowledge of the positions from which observations are taken. We address this problem by employing cooperative localization; that is, deploying a second robot to observe the other as it explores, thereby establishing a virtual tether, and enabling an accurate estimate of the robot's position while it constructs the map. The paper presents our approach to this problem in the context of learning a set of visual landmarks useful for pose estimation. In addition to developing a formalism and concept, we validate our results experimentally and present quantitative results demonstrating the performance of the method.",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:M3NEmzRMIkIC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Quantifying the role of the opinion lexicon in sentiment analysis\u2016",
            "Publication year": 2012,
            "Publication url": "https://scholar.google.com/scholar?cluster=5003155011582002815&hl=en&oi=scholarr",
            "Abstract": "A widespread approach to determine the sentiment of a text is to use a pre-established opinion lexicon that includes negative and positive lexical entities. However, it is not clear how the choice of this lexicon impacts the classifier performance. In this paper, a comparison of seven opinion lexicons on six sentiment datasets (movie reviews and tweets) is conducted. Results suggest that increasing the lexicon size by semantic expansion as well as assigning an interval value to the words of the opinion lexicon significantly increases the classification performance on short texts (eg tweets).",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:mNrWkgRL2YcC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Semantic analysis of documents workshop (SemADoc) extended abstract",
            "Publication year": 2014,
            "Publication url": "https://dl.acm.org/doi/pdf/10.1145/2644866.2644897",
            "Abstract": "A large number of document management problems would benefit from having the semantics of documents explicitly represented. However, manually assigning semantic descriptions to documents is labour intensive and error prone. At the same time, the manual generation of domain specific taxonomies is not only labour intensive, but it also needs to be repeated often as the domains themselves and their key concepts shift with time.In this workshop we focus on document content analysis and semantic enrichment to generate a layer of semantic description of documents that is useful for document management tasks, such as semantic information retrieval, conceptual organization and clustering of document collections for sense making, semantic expert profiling, and document recommender systems. The aim of the workshop is to bring together researchers and practitioners, and discuss different perspectives on \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ME8aQywAAAAJ:1lhNe0rCu4AC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Toward understanding how users respond to rumours in social media",
            "Publication year": 2016,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/7752326/",
            "Abstract": "As the spread of rumours has been increasing every day in online social networks (OSNs), it is important to analyze and understand this phenomenon. Damage caused by the spread of rumours is difficult to handle without a full understanding of the dynamics behind it. One of the central steps of understanding rumour spread is to analyze who spread rumours online, why, and how. In this research, we focus on the steps who and why by describing, implementing, and evaluating an approach that studies whether or not a group of users is actively involved in rumour discussions, and assesses rumour-spreading personality types in OSNs. We implement this general approach using Reddit data, and demonstrate its use by determining which users engage with a recurring rumour, and analyzing their comments using qualitative methods. We find that we can reliably classify users into one of three categories: (1 \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ME8aQywAAAAJ:jE2MZjpN3IcC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Shrack: Description and Performance Evaluation of a Peer-to-Peer System for Document Sharing and Tracking using Pull-Only Information Dissemination",
            "Publication year": 2007,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/4228389/",
            "Abstract": "Shrack is a peer-to-peer framework for document sharing and tracking. Shrack peers provide support to researchers in forming direct collaboration in autonomous sharing and keeping track of newly published documents based on their interests. We propose a pull-only information dissemination protocol for peers to distribute information about new documents among peers with similar interests. Each peer can use the disseminated information to build a local view of semantic overlay of peer interests in the network. Each peer can later use the semantic overlay to find new contact information about other peers with a particular interests, as well as search for documents archived by other peers. After presenting an overview architecture of the system and the dissemination protocol, we present the evaluation results of the system performance, based on a simulated environment. The results indicate that the Shrack \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ME8aQywAAAAJ:_Ybze24A_UAC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Enhancing semi-supervised document clustering with feature supervision",
            "Publication year": 2012,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/2245276.2245457",
            "Abstract": "Traditional semi-supervised clustering uses only limited user supervision in the form of labeled instances and pairwise instance constraints to aid unsupervised clustering. However, user supervision can also be provided in alternative forms for document clustering, such as labeling a feature by indicating whether it discriminates among clusters. This paper thus fills this void by enhancing traditional semi-supervised clustering with feature supervision which asks the user to label discriminating features during labeling the instance or pairwise instance constraints. Various types of semi-supervised clustering algorithms were explored with feature supervision. Our experimental results on several real-world datasets demonstrate that augmenting the instance-level supervision with feature-level supervision can significantly improve document clustering performance.",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:KUbvn5osdkgC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Sonification of range information for 3-D space perception",
            "Publication year": 2003,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/1261753/",
            "Abstract": "We present a device that allows three-dimensional (3-D) space perception by sonification of range information obtained via a point laser range sensor. The laser range sensor is worn by a blindfolded user, who scans space by pointing the laser beam in different directions. The resulting stream of range measurements is then converted to an auditory signal whose frequency or amplitude varies with the range. Our device differs from existing navigation aids for the visually impaired. Such devices use sonar ranging whose primary purpose is to detect obstacles for navigation, a task to which sonar is well suited due to its wide beam width. In contrast, the purpose of our device is to allow users to perceive the details of 3-D space that surrounds them, a task to which sonar is ill suited, due to artifacts generated by multiple reflections and due to its limited range. Preliminary trials demonstrate that the user is able to easily \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ME8aQywAAAAJ:f2IySw72cVMC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Unsupervised document summarization using pre-trained sentence embeddings and graph centrality",
            "Publication year": 2021,
            "Publication url": "https://www.aclweb.org/anthology/2021.sdp-1.14/",
            "Abstract": "This paper describes our submission for the LongSumm task in SDP 2021. We propose a method for incorporating sentence embeddings produced by deep language models into extractive summarization techniques based on graph centrality in an unsupervised manner. The proposed method is simple, fast, can summarize any kind of document of any size and can satisfy any length constraints for the summaries produced. The method offers competitive performance to more sophisticated supervised methods and can serve as a proxy for abstractive summarization techniques",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:__bU50VfleQC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Acoustical diffraction modeling utilizing the Huygens-Fresnel principle",
            "Publication year": 2005,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/1545649/",
            "Abstract": "This paper describes the application of the Huygens-Fresnel principle to acoustical diffraction modeling. A theoretical formulation of the optics-based Huygens-Fresnel principle is presented followed by a discussion regarding the modifications necessary to apply the Huygens-Fresnel principle to acoustical diffraction modeling. Experimental results indicate the method is capable of modeling acoustical diffraction phenomena in a simple and efficient manner, making it attractive for interactive virtual environments.",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:ldfaerwXgEUC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Improving short text clustering by similarity matrix sparsification",
            "Publication year": 2018,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/3209280.3229114",
            "Abstract": "Short text clustering is an important but challenging task. We investigate impact of similarity matrix sparsification on the performance of short text clustering. We show that two sparsification methods (the proposed Similarity Distribution based, and k-nearest neighbors) that aim to retain a prescribed number of similarity elements per text, improve hierarchical clustering quality of short texts for various text similarities. These methods using a word embedding based similarity yield competitive results with state-of-the-art methods for short text clustering especially for general domain, and are faster than the main state-of-the-art baseline.",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:SnGPuo6Feq8C",
            "Publisher": "Unknown"
        },
        {
            "Title": "MedSearch: A retrieval system for medical information based on semantic similarity",
            "Publication year": 2006,
            "Publication url": "https://link.springer.com/chapter/10.1007/11863878_56",
            "Abstract": " MedSearch is a complete retrieval system for Medline, the premier bibliographic database of the U.S. National Library of Medicine (NLM). MedSearch implements SSRM, a novel information retrieval method for discovering similarities between documents containing semantically similar but not necessarily lexically similar terms.",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:tOudhMTPpwUC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "Text clustering using one-mode projection of document-word bipartite graphs",
            "Publication year": 2013,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/2480362.2480539",
            "Abstract": "Many real life networks have an underlying bipartite structure based on which similarity between two nodes or data instances can be defined. For example, in the case of a document corpus, the similarity between a pair of documents can be assumed to arise from the words that co-occur in them, and this document-word co-occurrence relationship can be modeled as a bipartite graph. A document similarity graph can be obtained by taking a one-mode projection of the bipartite graph, which is a popular technique for studying similar networks which arise from bipartite structure. A graph-based clustering algorithm can then be applied to this projection graph to obtain clusters of documents. In this paper we study the use of one-mode projection of the document-word bipartite graph and the subsequent application of a modularity optimization algorithm to cluster the documents. In particular, we propose an alternative and \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ME8aQywAAAAJ:a3BOlSfXSfwC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Automatic website summarization by image content: a case study with logo and trademark images",
            "Publication year": 2008,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/4445672/",
            "Abstract": "Image-based abstraction (or summarization) of a Web site is the process of extracting the most characteristic (or important) images from it. The criteria for measuring the importance of images in Web sites are based on their frequency of occurrence, characteristics of their content and Web link information. As a case study, this work focuses on logo and trademark images. These are important characteristic signs of corporate Web sites or of products presented there. The proposed method incorporates machine learning for distinguishing logo and trademarks from images of other categories (e.g., landscapes, faces). Because the same logo or trademark may appear many times in various forms within the same Web site, duplicates are detected and only unique logo and trademark images are extracted. These images are then ranked by importance taking frequency of occurrence, image content and Web link information \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ME8aQywAAAAJ:p2g8aNsByqUC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Workshop on Algorithms and Models for the Web Graph",
            "Publication year": 2006,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-540-78808-9_2",
            "Abstract": "For barely a decade now the Web graph (the network formed by Web pages and their hyperlinks) has been the focus of scientific study. In that short a time, this study has made a significant impact on research in physics, computer science and mathematics. It has focussed the attention of the scientific community on all the different kinds of networks that have arisen through technology and human activity; some speak of a \u201cnew science of networks\u201d. It has brought the computational and deductive power of computer science to the study of the complex social networks formed by inter-human relationships. And, it has given birth to new branches of research in different areas of mathematics, most notably graph theory and probability.",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:PVjk1bu6vJQC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "Perception for Mobile Agents",
            "Publication year": 2000,
            "Publication url": "https://search.proquest.com/openview/94b1de11ae51a651015a219e3e8133f7/1?pq-origsite=gscholar&cbl=326361",
            "Abstract": "Building a Mobile Agent that safely operates in a real environment populated with people has occupied researchers for over 30 years and is still an open problem. The key problem in this endeavor is sensing. The world is constantly changing, plus the internal robot sensors accummulate errors, so the only way for a mobile agent to accomplish the task of moving from point A to point B is to refer its position to a world reference frame, either quantitatively (by maintaining global cartesian coordinates with respect to an accurate map) or quantitatively (by maintaining a description of its position and possible routes out of it). In reality, both modes need to be combined, as suggested in the spatial hierarchy of Kuipers.This special issue grew out of a \u201cWorkshop on the Perception of Mobile Agents\u201d held in conjunction with IEEE CVPR in 1998 in Santa Barbara. The workshop brought together a diverse group of researchers \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ME8aQywAAAAJ:fEOibwPWpKIC",
            "Publisher": "Springer Nature BV"
        },
        {
            "Title": "Domain-specific semantic relatedness from wikipedia structure: A case study in biomedical text",
            "Publication year": 2015,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-319-18111-0_26",
            "Abstract": "Wikipedia is becoming an important knowledge source in various domain specific applications based on concept representation. This introduces the need for concrete evaluation of Wikipedia as a foundation for computing semantic relatedness between concepts. While lexical resources like WordNet cover generic English well, they are weak in their coverage of domain specific terms and named entities, which is one of the strengths of Wikipedia. Furthermore, semantic relatedness methods that rely on the hierarchical structure of a lexical resource are not directly applicable to the Wikipedia link structure, which is not hierarchical and whose links do not capture well defined semantic relationships like hyponymy.In this paper we (1) Evaluate Wikipedia in a domain specific semantic relatedness task and demonstrate that Wikipedia based methods can be competitive with state of the art ontology \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ME8aQywAAAAJ:MpfHP-DdYjUC",
            "Publisher": "Springer, Cham"
        },
        {
            "Title": "Automatic Image Summarization of Large Corporate Web Sites",
            "Publication year": 2005,
            "Publication url": "https://scholar.google.com/scholar?cluster=4939865176314452121&hl=en&oi=scholarr",
            "Abstract": "Web image summarization is the process of extracting the most important or characteristic images from a Web site. This process is complementary to text summarization which works by extracting brief text summaries (eg, important phrases or sentences) from the Web sites. To the best of our knowledge, Web image summarization methods are not known to exist. This is exactly the problem this work is dealing with. The proposed method works by analyzing the content of the images stored in a Web-site taking also link information into account. Because there is no unique method for analyzing the content of every possible image type, this work focuses on logo and trademark images. These are important features of a Web site by themselves characterizing the identity of Corporate Web sites or of products presented in such Web sites. The method is based also on machine learning for distinguishing logo and trademarks \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ME8aQywAAAAJ:kzcrU_BdoSEC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Advances in Artificial Intelligence",
            "Publication year": 2015,
            "Publication url": "https://link.springer.com/content/pdf/10.1007/978-3-319-18356-5.pdf",
            "Abstract": "The 28th Canadian Conference on Artificial Intelligence (AI 2015) built on a long sequence of successful conferences, bringing together Canadian and international researchers, presenting and discussing original research. The conference was held in Halifax, Nova Scotia, Canada, during June 2\u20132, 2015, and was collocated with the 41st Graphics Interface Conference (GI 2015), and the 12th Conference on Computer and Robot Vision (CRV 2015).AI 2015 attracted 81 submissions from Canada and internationally. Each submission was reviewed in double-blind mode by at least three Program Committee members. For the conference and the proceedings 15 regular papers and 12 short papers were accepted, ie, 18.5% and 15% of the total number of submissions, respectively. Regular papers were allocated 16 pages in the proceedings, while short papers were allocated 8 pages. The proceedings include eight \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ME8aQywAAAAJ:nRpfm8aw39MC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Exploiting Multiple Features with MEMMs for Focused Crawling",
            "Publication year": 2008,
            "Publication url": "https://scholar.google.com/scholar?cluster=8232441608183392801&hl=en&oi=scholarr",
            "Abstract": "Focused web crawling traverses the Web to collect documents on a specific topic. This is not an easy task, since focused crawlers need to identify the next most promising link to follow based on the topic and the content and links of previously crawled pages. In this paper, we present a framework based on Maximum Entropy Markov Models (MEMMs) for an enhanced focused web crawler to take advantage of richer representations of multiple features extracted from Web pages, such as anchor text and the keywords embedded in the link URL, to represent useful context. The key idea of our approach is to treat the focused web crawling problem as a sequential task and use a combination of content analysis and link structure to capture sequential patterns leading to targets. The experimental results showed that focused crawling using MEMMs is a very competitive crawler in general over Best-First crawling on Web \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ME8aQywAAAAJ:0KyAp5RtaNEC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Clustering event logs using iterative partitioning",
            "Publication year": 2009,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/1557019.1557154",
            "Abstract": "The importance of event logs, as a source of information in systems and network management cannot be overemphasized. With the ever increasing size and complexity of today's event logs, the task of analyzing event logs has become cumbersome to carry out manually. For this reason recent research has focused on the automatic analysis of these log files. In this paper we present IPLoM (Iterative Partitioning Log Mining), a novel algorithm for the mining of clusters from event logs. Through a 3-Step hierarchical partitioning process IPLoM partitions log data into its respective clusters. In its 4th and final stage IPLoM produces cluster descriptions or line formats for each of the clusters produced. Unlike other similar algorithms IPLoM is not based on the Apriori algorithm and it is able to find clusters in data whether or not its instances appear frequently. Evaluations show that IPLoM outperforms the other algorithms \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ME8aQywAAAAJ:mVmsd5A6BfQC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Improving Event Detection using Contextual Word and Sentence Embeddings",
            "Publication year": 2020,
            "Publication url": "http://ir.cs.uns.edu.ar/publications/download/99.pdf",
            "Abstract": "The task of Event Detection (ED) is a subfield of Information Extraction (IE) that consists in recognizing event mentions in natural language texts. Several applications can take advantage of an ED system, including alert systems, text summarization, question-answering systems, and any system that needs to extract structured information about events from unstructured texts. ED is a complex task, which is hampered by two main challenges: the lack of a dataset large enough to train and test the developed models and the variety of event type definitions that exist in the literature. These problems make generalization hard to achieve, resulting in poor adaptation to different domains and targets. The main contribution of this paper is the design, implementation and evaluation of a recurrent neural network model for ED that combines several features. In particular, the paper makes the following contributions:(1) it uses BERT embeddings to define contextual word and contextual sentence embeddings as attributes, which to the best of our knowledge were never used before for the ED task;(2) the proposed model has the ability to use its first layer to learn good feature representations;(3) a new public dataset with a general definition of event;(4) an extensive empirical evaluation that includes (i) the exploration of different architectures and hyperparameters,(ii) an ablation test to study the impact of each attribute, and (iii) a comparison with a replication of a state-of-the-art model. The results offer several insights into the importance of contextual embeddings and indicate that the proposed approach is effective in the ED task, outperforming the baseline models.",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:27LrP4qxOz0C",
            "Publisher": "Unknown"
        },
        {
            "Title": "P-GTM: privacy-preserving google tri-gram method for semantic text similarity",
            "Publication year": 2014,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/2644866.2644882",
            "Abstract": "This paper presents P-GTM, a privacy-preserving text similarity algorithm that extends the Google Tri-gram Method (GTM). The Google Tri-gram Method is a high-performance unsupervised semantic text similarity method based on the use of context from the Google Web 1T n-gram dataset. P-GTM computes the semantic similarity between two input bag-of-words documents on public cloud hardware, without disclosing the documents' contents. Like the GTM, P-GTM requires the uni-gram and tri-gram lists from the Google Web 1T n-gram dataset as additional inputs. The need for these additional lists makes private computation of GTM text similarities a challenging problem. P-GTM uses a combination of pre-computation, encryption, and randomized preprocessing to enable private computation of text similarities using the GTM. We discuss the security of the algorithm and quantify its privacy using standard and real \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ME8aQywAAAAJ:ALROH1vI_8AC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Knowledge management in pediatric pain: Mapping on-line expert discussions to medical literature",
            "Publication year": 2004,
            "Publication url": "https://ebooks.iospress.nl/doi/10.3233/978-1-60750-949-3-3",
            "Abstract": "Clinical decision-making can be vastly improved with the availability of the right medical knowledge at the right time. This concept paper presents a knowledge management research program to (a) identify, capture and organize the tacit knowledge inherent within on-line problem-solving discussions between pediatric pain practitioners;(b) establish linkages between topic-specific pediatric pain discussions and corresponding published medical literature on children's pain available at PubMed\u2013ie linking tacit expert knowledge to explicit medical literature; and (c) make these knowledge resources available to pediatric pain practitioners via the WWW for timely access to various modalities of clinical knowledge.",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:kVjdVfd2voEC",
            "Publisher": "IOS Press"
        },
        {
            "Title": "Statistical learning for OCR text correction",
            "Publication year": 2016,
            "Publication url": "https://arxiv.org/abs/1611.06950",
            "Abstract": "The accuracy of Optical Character Recognition (OCR) is crucial to the success of subsequent applications used in text analyzing pipeline. Recent models of OCR post-processing significantly improve the quality of OCR-generated text, but are still prone to suggest correction candidates from limited observations while insufficiently accounting for the characteristics of OCR errors. In this paper, we show how to enlarge candidate suggestion space by using external corpus and integrating OCR-specific features in a regression approach to correct OCR-generated errors. The evaluation results show that our model can correct 61.5% of the OCR-errors (considering the top 1 suggestion) and 71.5% of the OCR-errors (considering the top 3 suggestions), for cases where the theoretical correction upper-bound is 78%.",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:KaMxkj08jr0C",
            "Publisher": "Unknown"
        },
        {
            "Title": "The impact of resource title on tags in collaborative tagging systems",
            "Publication year": 2010,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/1810617.1810648",
            "Abstract": "Collaborative tagging systems are popular tools for organization, sharing and retrieval of web resources. Their success is due to their freedom and simplicity of use. To post a resource, the user should only define a set of tags that would position the resource in the system's data structure--folksonomy. This data structure can serve as a rich source of information about relations between tags and concepts they represent. To make use of information collaboratively added to folksonomies, we need to understand how users make tagging decisions. Three factors that are believed to influence user tagging decisions are: the tags used by other users, the organization of user's personal repository and the knowledge model shared between users. In our work we examine the role of another potential factor--resource title. Despite all the advantages of tags, tagging is a tedious process. To minimize the effort, users are likely to \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ME8aQywAAAAJ:ZHo1McVdvXMC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Eyes'n ears face detection",
            "Publication year": 2001,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/958954/",
            "Abstract": "We present a robust and portable visual-based skin and face detection system developed for use in a multiple speaker teleconferencing system, employing both audio and video cues. An omni-directional video sensor is used to provide a view of the entire visual hemisphere, thereby allowing for multiple dynamic views of all the participants. Regions of skin are detected using simple statistical methods, along with histogram color models for both skin and non-skin color classes. Regions of skin belonging to the same person are grouped together, and using simple spatial properties, the position of each person's face is inferred. Preliminary results suggest the system is capable of detecting human faces present in an omni-directional image despite the poor resolution inherent with such an omni-directional sensor.",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:R3hNpaxXUhUC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Weighted link analysis for logo and trademark image retrieval on the Web",
            "Publication year": 2005,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/1517912/",
            "Abstract": "Image retrieval on the Web requires that important (authoritative) images satisfying the query selection criteria are assigned higher ranking over other relevant images. PicASHOW (Lempel and Soffer, 2002) achieves this goal using link information alone. This work proposes WPicASHOW (weighted PicASHOW), a weighted scheme for co-citation analysis that incorporates within the link analysis method of PicASHOW the text and image content of the queries and of the Web pages. WPicASHOW is implemented and integrated into a fully automated Web retrieval system for logo and trademark images.",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:JV2RwH3_ST0C",
            "Publisher": "IEEE"
        },
        {
            "Title": "Categorizing Online Harassment on Twitter.",
            "Publication year": 2019,
            "Publication url": "https://www.researchgate.net/profile/Samuel-Sousa-8/publication/335570031_Categorizing_Online_Harassment_on_Twitter/links/5d6dfe7c299bf1808d61c517/Categorizing-Online-Harassment-on-Twitter.pdf",
            "Abstract": "Harassment on social media is a hard problem to tackle since those platforms are virtual spaces in which people enjoy the liberty to express themselves with no restrictions. Furthermore, a large amount of users generating publications on online media like Twitter contributes to the hardness of controlling sexism and sexual harassment content, requesting robust methods of Machine Learning (ML) to be applied in this task. To do so, this work aims at comparing the performance of supervised ML algorithms to categorize online harassment in Twitter posts. We tested Logistic Regression, Gaussian Na\u0131ve Bayes, Decision Trees, Random Forest, Linear SVM, Gaussian SVM, Polynomial SVM, Multi-Layer Perceptron, and AdaBoost methods on the SIMAH Competition benchmark data, using TF-IDF vectors and Word2Vec embeddings as features. As results, we reached scores above 0.80% of accuracy for all the harassment types in the data. We also showed that, when using TFIDF vectors, Linear and Gaussian SVM are the best methods to predict harassment content, while Decision Trees and Random Forest better categorize physical and sexual harassment. Overall, by using TF-IDF vectors presented higher performance on these data, suggesting that the training corpus for Word2Vec influenced negatively on the classification task outcomes.",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:QsaTk4IG4EwC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Improving text relatedness by incorporating phrase relatedness with word relatedness",
            "Publication year": 2018,
            "Publication url": "https://onlinelibrary.wiley.com/doi/abs/10.1111/coin.12152",
            "Abstract": "Text is composed of words and phrases. In the bag\u2010of\u2010words model, phrases in text are split into words. This may discard the semantics of phrases, which, in turn, may give an inconsistent relatedness score between 2 texts. Our objective is to apply phrase relatedness in conjunction with word relatedness on the text relatedness task to improve text relatedness performance. We adopt 2 existing word relatedness measures based on Google n\u2010gram and Global Vectors for Word Representation, respectively, and incorporate them differently with an existing Google n\u2010gram\u2013based phrase relatedness method to compute text relatedness. The combination of Google n\u2010gram\u2013based word and phrase relatedness performs better than Google n\u2010gram\u2013based word relatedness alone, by achieving the higher weighted mean of Pearson's r, ie, 0.639 and 0.619, respectively, on the 14 data sets from the series of Semantic \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ME8aQywAAAAJ:mUJArPsKIAAC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Representation learning for sparse, high dimensional multi-label classification",
            "Publication year": 2012,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-642-32115-3_55",
            "Abstract": "In this article we describe the approach we applied for the JRS 2012 Data Mining Competition. The task of the competition was the multi-labelled classification of biomedical documents. Our method is motivated by recent work in the machine learning and computer vision communities that highlights the usefulness of feature learning for classification tasks. Our approach uses orthogonal matching persuit to learn a dictionary from PCA-transformed features. Binary relevance with logistic regression is applied to the encoded representations, leading to a fifth place performance in the competition. In order to show the suitability of our approach outside the competition task we also report a state-of-the-art classification performance on the multi-label ASRS dataset.",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:YohjEiUPhakC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "A graph-based topic extraction method enabling simple interactive customization",
            "Publication year": 2013,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/2494266.2494280",
            "Abstract": "It is often desirable to identify the concepts that are present in a corpus. A popular way to deal with this objective is to discover clusters of words or topics, for which many algorithms exist in the literature. Yet most of these methods lack the interpretability that would enable interaction with a user not familiar with their inner workings. The paper proposes a graph-based topic extraction algorithm, which can also be viewed as a soft-clustering of words present in a given corpus. Each topic, in the form of a set of words, represents an underlying concept in the corpus. The method allows easy interpretation of the clustering process, and hence enables the scope of user involvement at various steps. For a quantitative evaluation of the topics extracted, we use them as features to get a compact representation of documents for classification tasks. We compare the classification accuracy achieved by a reduced feature set \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ME8aQywAAAAJ:5icHVeHT4IsC",
            "Publisher": "Unknown"
        },
        {
            "Title": "of Proceedings: Proceedings of the ECAI 2008 Workshop on Mining Social Data (MSoDa)",
            "Publication year": 2008,
            "Publication url": "https://scholar.google.com/scholar?cluster=15669404948768554352&hl=en&oi=scholarr",
            "Abstract": "Social networks and collaborative tagging systems are rapidly gaining popularity as a primary means for storing and sharing data among friends, family, colleagues, or perfect strangers as long as they have common interests. del. icio. us is a social network where people store and share their personal bookmarks. Most importantly, users tag their bookmarks for ease of information dissemination and later look up. However, it is the friendship links, that make delicious a social network. They exist independently of the set of bookmarks that belong to the users and have no relation to the tags typically assigned to the bookmarks. To study the interaction among users, the strength of the existing links and their hidden meaning, we introduce implicit links in the network. These links connect only highly \u201csimilar\u201d users. Here, similarity can re\ufb02ect different aspects of the user\u2019s pro\ufb01le that makes her similar to any other user, such \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ME8aQywAAAAJ:PoWvk5oyLR8C",
            "Publisher": "IOS"
        },
        {
            "Title": "Supervised Learning",
            "Publication year": 2006,
            "Publication url": "https://scholar.google.com/scholar?cluster=13779674335299471773&hl=en&oi=scholarr",
            "Abstract": "&attribute outlook{sunny, overcast, rainy} &attribute temperature real &attribute humidity real &attribute windy TRUE, FALSE &attribute play yes, no data outlook temp hum windy play sunny, 85, 85, FALSE, no sunny, 80, 90, TRUE, no overcast, 83, 86, FALSE, yes rainy, 70, 96, FALSE, yes rainy, 68, 80, FALSE, yes rainy, 65, 70, TRUE, no overcast, 64, 65, TRUE, yes sunny, 72, 95, FALSE, no sunny, 69, 70, FALSE, yes rainy, 75, 80, FALSE, yes sunny, 75, 70, TRUE, yes overcast, 72, 90, TRUE, yes overcast, 81, 75, FALSE, yes rainy, 71, 91, TRUE, no",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:MLfJN-KU85MC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Incremental cluster evolution tracking from highly dynamic network data",
            "Publication year": 2014,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/6816635/",
            "Abstract": "Dynamic networks are commonly found in the current web age. In scenarios like social networks and social media, dynamic networks are noisy, are of large-scale and evolve quickly. In this paper, we focus on the cluster evolution tracking problem on highly dynamic networks, with clear application to event evolution tracking. There are several previous works on data stream clustering using a node-by-node approach for maintaining clusters. However, handling of bulk updates, i.e., a subgraph at a time, is critical for achieving acceptable performance over very large highly dynamic networks. We propose a subgraph-by-subgraph incremental tracking framework for cluster evolution in this paper. To effectively illustrate the techniques in our framework, we consider the event evolution tracking task in social streams as an application, where a social stream and an event are modeled as a dynamic post network and a \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ME8aQywAAAAJ:Bg7qf7VwUHIC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Book Review: Network, Netplay: Virtual Groups on the Internet",
            "Publication year": 2000,
            "Publication url": "https://journals.sagepub.com/doi/pdf/10.1177/089443930001800112",
            "Abstract": "The book is very diverse in terms of methodologies used in the individual chapters. Some chapters are based on empirical research, using data collected from newsgroups or mailing lists (Jones, Witmer, et al.; Mabry; Berthold, et al.); and applying statistical tools to draw conclusions, others present technology for virtual cooperative interaction (Chen & Gaines; Doyle & Hayes-Roth); and yet others discuss frameworks for studying Internet-based communication (Voiskounsky). Statistical tools used range from classical hypothesis testing (Witmer & Katzman; Mabry) and tabulation and classification of results (Jones) to sophisticated use of self-organizing artificial neural networks to study typicality of messages (Berthold, et al.).The book\u2019s main strength is that it brings together for the first time in a single volume a very diverse set of articles on social aspects of CMC. As such, it can serve as a reading in a graduate sociology \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ME8aQywAAAAJ:oNZyr7d5Mn4C",
            "Publisher": "Sage Publications"
        },
        {
            "Title": "Improving the performance of focused web crawlers",
            "Publication year": 2009,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S0169023X0900055X",
            "Abstract": "This work addresses issues related to the design and implementation of focused crawlers. Several variants of state-of-the-art crawlers relying on web page content and link information for estimating the relevance of web pages to a given topic are proposed. Particular emphasis is given to crawlers capable of learning not only the content of relevant pages (as classic crawlers do) but also paths leading to relevant pages. A novel learning crawler inspired by a previously proposed Hidden Markov Model (HMM) crawler is described as well. The crawlers have been implemented using the same baseline implementation (only the priority assignment function differs in each crawler) providing an unbiased evaluation framework for a comparative analysis of their performance. All crawlers achieve their maximum performance when a combination of web page content and (link) anchor text is used for assigning download \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ME8aQywAAAAJ:-f6ydRqryjwC",
            "Publisher": "North-Holland"
        },
        {
            "Title": "Filtering for medical news items using a machine learning approach.",
            "Publication year": 2002,
            "Publication url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2244368/",
            "Abstract": "We address the problem of filtering medical news articles for targeted audiences. The approach is based on terms and one of the difficulties is extracting a feature set appropriate for the domain. This paper addresses the medical news-filtering problem using a machine learning approach. We describe the application of two supervised machine learning techniques, Decision Trees and Na\u00efve Bayes, to automatically construct classifiers on the basis of a training set, in which news articles have been pre-classified by a medical expert and four other human readers. The goal is to classify the news articles into three groups: non-medical, medical intended for experts, and medical intended for other readers. While the general accuracy of the machine learning approach is around 78%, the accuracy of distinguishing non-medical articles from medical ones is shown to be 92%.",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:FAceZFleit8C",
            "Publisher": "American Medical Informatics Association"
        },
        {
            "Title": "Automatic document indexing in large medical collections",
            "Publication year": 2006,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/1183568.1183570",
            "Abstract": "Term extraction relates to extracting the most characteristic or important terms (words or phrases) in a document. This information is commonly used for improving the accuracy of document indexing and retrieval in large text collections. It also allows for faster and better understanding of the contents of a document collection without first browsing through the contents of its documents. This paper presents AMTE x an automatic term extraction method, specifically designed for the automatic indexing of documents in large medical collections such as MEDLINE, the premier bibliographic database of the US National Library of Medicine (NLM). AMTE x combines MeSH, the terminological thesaurus resource of NLM, with a well-established method for extraction of domain terms, the C/NC-value method. The performance evaluation of various AMTE x configurations in the indexing task is measured against the current state \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ME8aQywAAAAJ:J_g5lzvAfSwC",
            "Publisher": "Unknown"
        },
        {
            "Title": "A Visual Analytics Approach for Interactive Document Clustering",
            "Publication year": 2019,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/3241380",
            "Abstract": "Document clustering is a necessary step in various analytical and automated activities. When guided by the user, algorithms are tailored to imprint a perspective on the clustering process that reflects the user\u2019s understanding of the dataset. More than just allow for customized adjustment of the clusters, a visual analytics approach will provide tools for the user to draw new insights on the collection. While contributing his or her perspective, the user will also acquire a deeper understanding of the data set. To that effect, we propose a novel visual analytics system for interactive document clustering. We built our system on top of clustering algorithms that can adapt to user\u2019s feedback. In the proposed system, initial clustering is created based on the user-defined number of clusters and the selected clustering algorithm. A set of coordinated visualizations allow the examination of the dataset and the results of the clustering \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ME8aQywAAAAJ:LXmCCkuhhTsC",
            "Publisher": "ACM"
        },
        {
            "Title": "A lightweight algorithm for message type extraction in system application logs",
            "Publication year": 2011,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/5936060/",
            "Abstract": "Message type or message cluster extraction is an important task in the analysis of system logs in computer networks. Defining these message types automatically facilitates the automatic analysis of system logs. When the message types that exist in a log file are represented explicitly, they can form the basis for carrying out other automatic application log analysis tasks. In this paper, we introduce a novel algorithm for carrying out message type extraction from event log files. IPLoM, which stands for Iterative Partitioning Log Mining, works through a 4-step process. The first three steps hierarchically partition the event log into groups of event log messages or event clusters. In its fourth and final stage, IPLoM produces a message type description or line format for each of the message clusters. IPLoM is able to find clusters in data irrespective of the frequency of its instances in the data, it scales gracefully in the case of \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ME8aQywAAAAJ:VaXvl8Fpj5cC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Robotic neurosurgery and clinical applications",
            "Publication year": 2004,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/1384172/",
            "Abstract": "This paper presents robotic neurosurgery and clinical applications. Firstly, background, objective, motivation and distinct properties of this kind of surgical robots are introduced. Secondly, by analysing current main classifications for surgical robots, neurosurgical robots are divided into two groups, namely, neurosurgical robots anid tele-neurosurgical robots. Then, after the history of surgical robots is briefly reviewed, several prototypes of neurosurgical robots currently used in clinics are discussed in details. As a branch of surgical robots, the design issues about neurosurgical robots not only have the common part as surgical robots, but this field has its special issues, such as high complex image modeling and analysis, high accuracy, and high safety. Therefore, current research challenges are provided and consideratialn about tele-robotic neurosurgical design is put forward. Finally, this paper is concluded with \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ME8aQywAAAAJ:Tiz5es2fbqcC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Tag Sources for Recommendation in Collaborative Tagging Systems.",
            "Publication year": 2009,
            "Publication url": "https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.148.5334&rep=rep1&type=pdf",
            "Abstract": "Collaborative tagging systems are social data repositories, in which users manage resources using descriptive keywords (tags). An important element of collaborative tagging systems is the tag recommender, which proposes a set of tags to each newly posted resource. In this paper we discuss the potential role of three tag sources: resource content as well as resource and user profiles in the tag recommendation system. Our system compiles a set of resource specific tags, which includes tags related to the title and tags previously used to describe the same resource (resource profile). These tags are checked against user profile tags\u2013a rich, but imprecise source of information about user interests. The result is a set of tags related both to the resource and user. Depending on the character of processed posts this set can be an extension of the common tag recommendation sources, namely resource title and resource profile. The system was submitted to ECML PKDD Discovery Challenge 2009 for \u201ccontent-based\u201d and \u201cgraph-based\u201d recommendation tasks, in which it took the first and third place respectively.",
            "Abstract entirety": 1,
            "Author pub id": "ME8aQywAAAAJ:qxL8FJ1GzNcC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Characterizing the citation graph as a self-organizing networked information space",
            "Publication year": 2002,
            "Publication url": "https://link.springer.com/chapter/10.1007/3-540-48080-3_9",
            "Abstract": "Bodies of information available through the Internet, such as digital librarises and distributed file-sharing systems, often form a self-organizing networked information space, i.e. a collection of interconnected information entities generated incrementally over time by a large number of agents. The collection of electronically available research papers in Computer Science, linked by their citations, form a good example of such a space. In this work we present a study of the structure of the citation graph of computer science literature. Using a web robot we build several citation graphs from parts of the digital library ResearchIndex. After verifying that the degree distributions follow a power law, we apply a series of graph theoretical algorithms to elicit an aggregate picture of the citation graph in terms of its connectivity. The results expand our insight into the structure of self-organizing networked information spaces \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ME8aQywAAAAJ:M05iB0D1s5AC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "Efficient tag recommendation for real-life data",
            "Publication year": 2011,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/2036264.2036266",
            "Abstract": "Despite all of the advantages of tags as an easy and flexible information management approach, tagging is a cumbersome task. A set of descriptive tags has to be manually entered by users whenever they post a resource. This process can be simplified by the use of tag recommendation systems. Their objective is to suggest potentially useful tags to the user. We present a hybrid tag recommendation system together with a scalable, highly efficient system architecture. The system is able to utilize user feedback to tune its parameters to specific characteristics of the underlying tagging system and adapt the recommendation models to newly added content. The evaluation of the system on six real-life datasets demonstrated the system\u2019s ability to combine tags from various sources (e.g., resource content or tags previously used by the user) to achieve the best quality of recommended tags. It also confirmed the \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ME8aQywAAAAJ:AXPGKjj_ei8C",
            "Publisher": "ACM"
        }
    ]
}]