[{
    "name": "\u0394\u03b7\u03bc\u03ae\u03c4\u03c1\u03b9\u03bf\u03c2 \u039d\u03b9\u03ba\u03bf\u03bb\u03cc\u03c0\u03bf\u03c5\u03bb\u03bf\u03c2",
    "romanize name": "Dimitrios Nikolopoulos",
    "School-Department": "School of Electronics, Electrical Engineering and Computer Science",
    "University": "Virginia Polytechnic Inst.and State Univ.",
    "Rank": "\u039a\u03b1\u03b8\u03b7\u03b3\u03b7\u03c4\u03ae\u03c2",
    "Apella_id": 9012,
    "Scholar name": "Dimitrios S. Nikolopoulos",
    "Scholar id": "PkCuYUQAAAAJ",
    "Affiliation": "Virginia Tech",
    "Citedby": 5527,
    "Interests": [
        "High Performance Computing",
        "Runtime Systems",
        "Memory Systems"
    ],
    "Scholar url": "https://scholar.google.com/citations?user=PkCuYUQAAAAJ&hl=en",
    "Publications": [
        {
            "Title": "Methods and metrics for fair server assessment under real\u2010time financial workloads",
            "Publication year": 2016,
            "Publication url": "https://onlinelibrary.wiley.com/doi/abs/10.1002/cpe.3704",
            "Abstract": "We present a rigorous methodology and new metrics for fair comparison of server and microserver platforms. Deploying our methodology and metrics, we compare a microserver with ARM cores against two servers with \u00d786 cores running the same real\u2010time financial analytics workload. We define workload\u2010specific but platform\u2010independent performance metrics for platform comparison, targeting both datacenter operators and end users. Our methodology establishes that a server based on the Xeon Phi co\u2010processor delivers the highest performance and energy efficiency. However, by scaling out energy\u2010efficient microservers, we achieve competitive or better energy efficiency than a power\u2010equivalent server with two Sandy Bridge sockets, despite the microserver's slower cores. Using a new iso\u2010QoS metric, we find that the ARM microserver scales enough to meet market throughput demand, that is, a 100% QoS in \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:geHnlv5EZngC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Mixed-Precision Kernel Recursive Least Squares",
            "Publication year": 2020,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/9296554/",
            "Abstract": "Kernel recursive least squares (KRLS) is a widely used online machine learning algorithm for time series predictions. In this article, we present the mixed-precision KRLS, producing equivalent prediction accuracy to double-precision KRLS with a higher training throughput and a lower memory footprint. The mixed-precision KRLS applies single-precision arithmetic to the computation components being not only numerically resilient but also computationally intensive. Our mixed-precision KRLS demonstrates the 1.32, 1.15, 1.29, 1.09, and 1.08x training throughput improvements using 24.95%, 24.74%, 24.89%, 24.48%, and 24.20% less memory footprint without losing any prediction accuracy compared to double-precision KRLS for a 3-D nonlinear regression, a Lorenz chaotic time series, a Mackey-Glass chaotic time series, a sunspot number time series, and a sea surface temperature time series, respectively.",
            "Abstract entirety": 1,
            "Author pub id": "PkCuYUQAAAAJ:P5F9QuxV20EC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Using Docker Swarm with a user-centric decision-making framework for cloud application migration",
            "Publication year": 2017,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-319-94959-8_5",
            "Abstract": "Vendor lock-in is a major obstacle for cloud users in performing multi-cloud deployment or inter-cloud migration, due to the lack of standardization. Current research efforts tackling the inter-cloud migration problem are commonly technology-oriented with significant performance overheads. Moreover, current studies do not provide adequate support for decision making such as why and when inter-cloud migration should take place. We propose the architecture and the problem formulation of a Multi-objective dYnamic MIgratioN Decision makER (MyMinder) framework that assists cloud users in achieving a stable QoS performance in the post-deployment phase by helping decide on actions to be taken as well as providing support to achieve such actions. Additionally, we demonstrate the migration capability of MyMinder by proposing an Automated Triggering Algorithm (ATA), which uses existing Docker \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:35N4QoGY0k4C",
            "Publisher": "Springer, Cham"
        },
        {
            "Title": "Improving Java server performance with interruptlets",
            "Publication year": 2001,
            "Publication url": "https://link.springer.com/chapter/10.1007/3-540-45545-0_31",
            "Abstract": "With the widespread usage of the Internet, the need for high throughput servers has greatly increased. The Interruptlet system allows Java server application writers to register light-weight interrupt handling routines (written in C or Java). The underlying system architecture is designed to minimize redundant copies between protection domains and thread overhead involved in I/O handling in the JVM on Linux.",
            "Abstract entirety": 1,
            "Author pub id": "PkCuYUQAAAAJ:g3aElNc5_aQC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "Model-based, memory-centric performance and power optimization on numa multiprocessors",
            "Publication year": 2012,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/6402921/",
            "Abstract": "Non-Uniform Memory Access (NUMA) architectures are ubiquitous in HPC systems. NUMA along with other factors including socket layout, data placement, and memory contention significantly increase the search space to find an optimal mapping of applications to NUMA systems. This search space may be intractable for online optimization and challenging for efficient offline search. This paper presents DyNUMA, a framework for dynamic optimization of programs on NUMA architectures. DyNUMA uses simple, memory-centric, performance and energy models with non-linear terms to capture the complex and interacting effects of system layout, program concurrency, data placement, and memory controller contention. DyNUMA leverages an artificial neural network (ANN) with input, output, and intermediate layers that emulate program threads, memory controllers, processor cores, and their interactions. Using an \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:rO6llkc54NcC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Task-based parallel H. 264 video encoding for explicit communication architectures",
            "Publication year": 2011,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/6045464/",
            "Abstract": "Future multi-core processors will necessitate exploitation of fine-grain, architecture-independent parallelism from applications to utilize many cores with relatively small local memories. We use c264, an end-to-end H.264 video encoder for the Cell processor based on x264, to show that exploiting fine-grain parallelism remains challenging and requires significant advancement in runtime support. Our implementation of c264 achieves speedup between 4.7\u00d7 and 8.6\u00d7 on six synergistic processing elements (SPEs), compared to the serial version running on the power processing element (PPE). We find that the programming effort associated with efficient parallelization of c264 at fine granularity is highly non-trivial. Hand optimizations may improve performance significantly but are limited eventually by the code restructuring they require. We assess the complexity of exploiting fine-grain parallelism in realistic \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:gsN89kCJA0AC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Malleable memory mapping: User-level control of memory bounds for effective program adaptation",
            "Publication year": 2003,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/1213074/",
            "Abstract": "This paper presents a user-level runtime system which provides memory malleability to programs running on non-dedicated computational nodes. Memory malleability is analogous to processor malleability in the physical memory space. It lets a program shrink and expand its resident set size in response to runtime events, while preserving execution correctness. Malleability becomes relevant in the context of Grid computing, where loosely coupled distributed programs run on non-dedicated computational nodes with fluctuating CPU and memory loads. User-level malleable memory is proposed as a portable solution to obtain as much as possible out of the available physical memory of a computational node, without thrashing, and before reverting to coarse-grain load balancing via checkpointing and migration. Malleable memory mapping copes also with the unpredictable behavior of existing virtual memory \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:NhqRSupF_l8C",
            "Publisher": "IEEE"
        },
        {
            "Title": "An Energy-Efficient and Error-Resilient Server Ecosystem Exceeding Conservative Scaling Limits",
            "Publication year": 2016,
            "Publication url": "https://pure.qub.ac.uk/en/publications/an-energy-efficient-and-error-resilient-server-ecosystem-exceedin",
            "Abstract": "The explosive growth of Internet-connected devices will result in a flood of generated data, which will increase the demand for network bandwidth as well as compute power to process the generated data. Consequently, there is a need for more energy efficient servers to empower traditional centralized (Cloud) data-centers as well as emerging decentralized data-centers at the Edges of the Internet. In this paper, we present our approach, which aims at developing a new class of micro-servers\u2013the UniServer-that exceed the conservative energy and performance scaling boundaries by introducing novel mechanisms at all layers of the design stack. The main idea lies on the realization of the intrinsic hardware heterogeneity and the development of mechanisms that will automatically expose the unique varying capabilities of each hardware component and allow their operation at new extended operating points. Low overhead schemes are employed to monitor and predict the hardware behavior and report it to the system software, which is responsible for optimizing the system operation in terms of energy or performance, while guaranteeing non-disruptive operation under extended operating points. To efficiently manage any potential fault that may incur under extended margins, we aim at identifying critical/vulnerable software structures and developing low cost techniques for protecting them. This eventually, allows us to enhance the fault tolerance of the overall system software that is representative of any state of the art cloud data-center, since it adopts a virtualization environment as well as popular resource management packages. Our initial \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:0izLItjtcgwC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Intra-node memory safe gpu co-scheduling",
            "Publication year": 2017,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/8219713/",
            "Abstract": "GPUs in High-Performance Computing systems remain under-utilised due to the unavailability of schedulers that can safely schedule multiple applications to share the same GPU. The research reported in this paper is motivated to improve the utilisation of GPUs by proposing a framework, we refer to as schedGPU, to facilitate intra-node GPU co-scheduling such that a GPU can be safely shared among multiple applications by taking memory constraints into account. Two approaches, namely a client-server and a shared memory approach are explored. However, the shared memory approach is more suitable due to lower overheads when compared to the former approach. Four policies are proposed in schedGPU to handle applications that are waiting to access the GPU, two of which account for priorities. The feasibility of schedGPU is validated on three real-world applications. The key observation is that a \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:7PzlFSSx8tAC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Guest Editorial: Special Issue: Energy efficient computing with adaptive and heterogeneous architectures",
            "Publication year": 2015,
            "Publication url": "https://ietresearch.onlinelibrary.wiley.com/doi/abs/10.1049/iet-cdt.2014.0215",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "PkCuYUQAAAAJ:QYdC8u9Cj1oC",
            "Publisher": "The Institution of Engineering and Technology"
        },
        {
            "Title": "Energy-efficient hybrid DRAM/NVM main memory",
            "Publication year": 2015,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/7429336/",
            "Abstract": "DRAM consumes significant static energy both in active and idle state due to continuous leakage and refresh power. Various byte-addressable non-volatile memory (NVM) technologies promise near-zero static energy and persistence, however they suffer from increased latency and increased dynamic energy than DRAM. A hybrid main memory, containing both DRAM and NVM components, can provide both low energy and high performance although such organizations require that data is placed in the appropriate component. We propose a user-level software management methodology for a hybrid DRAM/NVM main memory system with an aim to reduce energy.",
            "Abstract entirety": 1,
            "Author pub id": "PkCuYUQAAAAJ:fFSKOagxvKUC",
            "Publisher": "IEEE"
        },
        {
            "Title": "New Approaches to Memory Reliability Management for Big Data Workloads",
            "Publication year": 2018,
            "Publication url": "https://pure.qub.ac.uk/en/publications/new-approaches-to-memory-reliability-management-for-big-data-work",
            "Abstract": "New Approaches to Memory Reliability Management for Big Data Workloads \u2014 Queen's \nUniversity Belfast Skip to main navigation Skip to search Skip to main content Queen's University \nBelfast Logo Help & FAQ Home Profiles Organisations Research output Projects Impact \nDatasets Activities Prizes Press / Media Student theses Facilities Search by expertise, name or \naffiliation New Approaches to Memory Reliability Management for Big Data Workloads Dimitrios \nNikolopoulos School of Electronics, Electrical Engineering and Computer Science Research \noutput: Contribution to conference \u203a Abstract Overview Original language English Publication \nstatus Published - 2018 Event SIAM Conference on Parallel Processing for Scientific Computing \n- Tokyo, Japan Duration: 07 Mar 2018 \u2192 \u2026 Conference Conference SIAM Conference \non Parallel Processing for Scientific Computing Abbreviated title SIAM PP Country Japan /\u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:2osOgNQ5qMEC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Fast dynamic binary rewriting to support thread migration in shared-isa asymmetric multicores",
            "Publication year": 2013,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/2446920.2446924",
            "Abstract": "Asymmetric multicore processors have demonstrated a strong potential for improving performance and energy-efficiency. Shared-ISA asymmetric multicore processors overcome programmability problems in disjoint-ISA systems and enhance single-ISA architectures with instruction based asymmetry. In such a design, processors share a common, baseline ISA and performance enhanced (PE) cores extend the baseline ISA with instructions that accelerate performance-critical operations. To exploit asymmetry, the scheduler should be able to migrate threads based on their acceleration potential.",
            "Abstract entirety": 1,
            "Author pub id": "PkCuYUQAAAAJ:Tyk-4Ss8FVUC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Power Log\u2019n\u2019Roll: Power-Efficient Localized Rollback for MPI Applications Using Message Logging Protocols",
            "Publication year": 2021,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/9524502/",
            "Abstract": "In fault tolerance for parallel and distributed systems, message logging protocols have played a prominent role in the last three decades. Such protocols enable local rollback to provide recovery from fail-stop errors. Global rollback techniques can be straightforward to implement but at times lead to slower recovery than local rollback. Local rollback is more complicated but can offer faster recovery times. In this work, we study the power and energy efficiency implications of global and local rollback. We propose a power-efficient version of local rollback to reduce power consumption for non-critical,  blocked  processes, using  Dynamic Voltage and Frequency Scaling  (DVFS) and  clock modulation  (CM). Our results for 3 different MPI codes on 2 parallel systems show that power-efficient local rollback reduces CPU energy waste up to 50% during the recovery phase, compared to existing global and local rollback \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:kw52XkFRtyQC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Runtime vs. Manual Data Distribution for Architecture-agnostic Shared-memory Programming Models",
            "Publication year": 2002,
            "Publication url": "https://scholar.google.com/scholar?cluster=11567784588642083426&hl=en&oi=scholarr",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "PkCuYUQAAAAJ:tzM49s52ZIMC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Modeling multigrain parallelism on heterogeneous multi-core processors: A case study of the Cell BE",
            "Publication year": 2008,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-540-77560-7_4",
            "Abstract": "Heterogeneous multi-core processors invest the most significant portion of their transistor budget in customized \u201caccelerator\u201d cores, while using a small number of conventional low-end cores for supplying computation to accelerators. To maximize performance on heterogeneous multi-core processors, programs need to expose multiple dimensions of parallelism simultaneously. Unfortunately, programming with multiple dimensions of parallelism is to date an ad hoc process, relying heavily on the intuition and skill of programmers. Formal techniques are needed to optimize multi-dimensional parallel program designs. We present a model of multi-dimensional parallel computation for steering the parallelization process on heterogeneous multi-core processors. The model predicts with high accuracy the execution time and scalability of a program using conventional processors and accelerators simultaneously \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:l7t_Zn2s7bgC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "VarSys Introduction: First International Workshop on Variability in Parallel and Distributed Systems",
            "Publication year": 2016,
            "Publication url": "https://pure.qub.ac.uk/en/publications/varsys-introduction-first-international-workshop-on-variability-i",
            "Abstract": "VarSys Introduction: First International Workshop on Variability in Parallel and Distributed \nSystems \u2014 Queen's University Belfast Skip to main navigation Skip to search Skip to main \ncontent Queen's University Belfast Logo Help & FAQ Home Profiles Organisations Research \noutput Projects Impact Datasets Activities Prizes Press / Media Student theses Facilities Search \nby expertise, name or affiliation VarSys Introduction: First International Workshop on Variability in \nParallel and Distributed Systems Kirk W. Cameron, Todd Gamblin, Dimitrios Nikolopoulos School \nof Electronics, Electrical Engineering and Computer Science High Performance and Distributed \nComputing Institute of Electronics, Communications & Information Technology Research \noutput: Chapter in Book/Report/Conference proceeding \u203a Foreword/postscript Overview \nProjects (1) Original language English Title of host publication IEEE International and of :/\u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:ODE9OILHJdcC",
            "Publisher": "IEEE Computer Society"
        },
        {
            "Title": "Evaluation of streaming aggregation on parallel hardware architectures",
            "Publication year": 2010,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/1827418.1827467",
            "Abstract": "We present a case study parallelizing streaming aggregation on three different parallel hardware architectures. Aggregation is a performance-critical operation for data summarization in stream computing, and is commonly found in sense-and-respond applications. Currently available commodity parallel hardware provides promise as accelerators for streaming aggregation. However, how streaming aggregation can map to the different parallel architectures is still an open question. Streaming aggregation is obviously data parallel, but in practice its performance relies more on efficient data movement than computation, as we will demonstrate. Furthermore, we used workloads such as stock market data, which introduces unique data distribution problems. The three parallel architectures we use in our study are an Intel Core 2 Quad processor, an Nvidia GTX 285 GPU and the IBM PowerXCell 8i, an enhanced version \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:aqlVkmm33-oC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Programming multiprocessors with explicitly managed memory hierarchies",
            "Publication year": 2009,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/5353458/",
            "Abstract": "A study of two applications programmed using three models of varying complexity reveals that implicit management of locality can produce code with performance comparable to code generated from explicit management of locality.",
            "Abstract entirety": 1,
            "Author pub id": "PkCuYUQAAAAJ:sNmaIFBj_lkC",
            "Publisher": "IEEE"
        },
        {
            "Title": "RAxML-CELL: Parallel phylogenetic tree construction on the Cell Broadband Engine",
            "Publication year": 2007,
            "Publication url": "https://scholar.google.com/scholar?cluster=5859188608316157227&hl=en&oi=scholarr",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "PkCuYUQAAAAJ:tH6gc1N1XXoC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Multigrain parallel delaunay mesh generation: challenges and opportunities for multithreaded architectures",
            "Publication year": 2005,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/1088149.1088198",
            "Abstract": "Given the importance of parallel mesh generation in large-scale scientific applications and the proliferation of multilevel SMT-based architectures, it is imperative to obtain insight on the interaction between meshing algorithms and these systems. We focus on Parallel Constrained Delaunay Mesh (PCDM) generation. We exploit coarse-grain parallelism at the subdomain level and fine-grain at the element level. This multigrain data parallel approach targets clusters built from low-end, commercially available SMTs. Our experimental evaluation shows that current SMTs are not capable of executing fine-grain parallelism in PCDM. However, experiments on a simulated SMT indicate that with modest hardware support it is possible to exploit fine-grain parallelism opportunities. The exploitation of fine-grain parallelism results to higher performance than a pure MPI implementation and closes the gap between the \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:SpbeaW3--B0C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Distributed region-based memory allocation and synchronization",
            "Publication year": 2014,
            "Publication url": "https://journals.sagepub.com/doi/abs/10.1177/1094342014552863",
            "Abstract": "We present DRASync, a region-based allocator that implements a global address space abstraction for MPI programs with pointer-based data structures. The main features of DRASync are: (a) it amortizes communication among nodes to allow efficient parallel allocation in a global address space; (b) it takes advantage of bulk deallocation and good locality with pointer-based data structures; (c) it supports ownership semantics of regions by nodes akin to reader\u2013writer locks, which makes for a high-level, intuitive synchronization tool in MPI programs, without sacrificing message-passing performance. We evaluate DRASync against a state-of-the-art distributed allocator and find that it produces comparable performance while offering a higher-level abstraction to programmers.",
            "Abstract entirety": 1,
            "Author pub id": "PkCuYUQAAAAJ:4fGpz3EwCPoC",
            "Publisher": "Sage Publications"
        },
        {
            "Title": "Design gene representations for emergent innovative design",
            "Publication year": 2019,
            "Publication url": "https://ebooks.iospress.nl/doi/10.3233/ATDE190068",
            "Abstract": "Looking to nature for inspiration, this work presents an alternative bottom-up engineering design system, which allows unpredicted-but-valuable designs to emerge with few constraints. A set of \u201cdesign genes\u201d have been developed which trigger and control the growth of a design within a CAD system through mechanisms such as copying and stretching. The single gene is structured as a one-dimensional array representation, which includes 6 elements: the attribute, the attribute\u2019s value or type, its active status, start and stop conditions, and dominance. A set of genes grouped together forms a \u201cdesign seed\u201d which contains all the necessary information to create the design. The design then emerges from the actions of the genes, which do not know anything about the final shape or form of the design. The growth is managed within a design environment which provides the external triggers and conditions needed to \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:VLnqNzywnoUC",
            "Publisher": "IOS Press"
        },
        {
            "Title": "Variation-aware pipelined cores through path shaping and dynamic cycle adjustment: Case study on a floating-point unit",
            "Publication year": 2018,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/3218603.3218617",
            "Abstract": "In this paper, we propose a framework for minimizing variation-induced timing failures in pipelined designs, while limiting any overhead incurred by conventional guardband based schemes. Our approach initially limits the long latency paths (LLPs) and isolates them in as few pipeline stages as possible by shaping the path distribution. Such a strategy, facilitates the adoption of a special unit that predicts the excitation of the isolated LLPs and dynamically allows an extra cycle for the completion of only these error-prone paths. Moreover, our framework performs post-layout dynamic timing analysis based on real operands that we extract from a variety of applications. This allows us to estimate the bit error rates under potential delay variations, while considering the dynamic data dependent path excitation. When applied to the implementation of an IEEE-754 compatible double precision floating-point unit (FPU) in a \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:Tiz5es2fbqcC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Fast load balance parallel graph analytics with an automatic graph data structure selection algorithm",
            "Publication year": 2020,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S0167739X19316590",
            "Abstract": "This paper investigates the performance of graph-structured analytics on large-scale shared memory systems. Graph analytics are highly demanding for efficient graph traversal due to large data set size and irregular data access patterns. In order to achieve efficient graph analytics, we consider and discuss the performance of three common types of graph data structures. Also, we demonstrate that load balance is to a large extent determined by the number of edges and number of unique vertices processed by each thread. Finally, we propose an automatic graph data structure selection algorithm and an efficient reordering as a pre-processing step to balance the number of vertices and edges together. Reordering algorithm also optimally balances edges and vertices for graphs with a power-law degree distribution and ensures an equal degree distribution across threads. The developed techniques are \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:kRWSkSYxWN8C",
            "Publisher": "North-Holland"
        },
        {
            "Title": "Accelerating Data Center Applications with Reconfigurable DataFlow Engines",
            "Publication year": 2016,
            "Publication url": "https://pure.qub.ac.uk/en/publications/accelerating-data-center-applications-with-reconfigurable-dataflo",
            "Abstract": "Energy-efficient, programmable accelerators are an important value proposition for pushing the limits on the computation capacity and density of future data centers. Integrating the accelerators in the software stacks of cloud-based data analytics frameworks is, however, an open issue. The goal of this work is to achieve seamless integration of accelerators in data analytics programming frameworks.",
            "Abstract entirety": 1,
            "Author pub id": "PkCuYUQAAAAJ:vRqMK49ujn8C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Scaling non-regular shared-memory codes by reusing custom loop schedules",
            "Publication year": 2003,
            "Publication url": "https://content.iospress.com/articles/scientific-programming/spr00131",
            "Abstract": "In this paper we explore the idea of customizing and reusing loop schedules to improve the scalability of non-regular numerical codes in shared-memory architectures with non-uniform memory access latency. The main objective is to implicitly setup affinity links between threads and data, by devising loop schedules that achieve balanced work distribution within irregular data spaces and reusing them as much as possible along the execution of the program for better memory access locality. This transformation provides a great deal of flexibility in optimizing locality, without compromising the simplicity of the shared-memory programming paradigm. In particular, the programmer does not need to explicitly distribute data between processors. The paper presents practical examples from real applications and experiments showing the efficiency of the approach.",
            "Abstract entirety": 1,
            "Author pub id": "PkCuYUQAAAAJ:zLWjf1WUPmwC",
            "Publisher": "IOS Press"
        },
        {
            "Title": "Energy-efficient in-memory data stores on hybrid memory hierarchies",
            "Publication year": 2015,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/2771937.2771940",
            "Abstract": "Increasingly large amounts of data are stored in main memory of data center servers. However, DRAM-based memory is an important consumer of energy and is unlikely to scale in the future. Various byte-addressable non-volatile memory (NVM) technologies promise high density and near-zero static energy, however they suffer from increased latency and increased dynamic energy consumption.",
            "Abstract entirety": 1,
            "Author pub id": "PkCuYUQAAAAJ:ruyezt5ZtCIC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Data collection framework: project deliverable D4. 1, revision 2",
            "Publication year": 2017,
            "Publication url": "https://oparu.uni-ulm.de/xmlui/handle/123456789/4362",
            "Abstract": "This deliverable will detail the requirements of the data collection framework to be deployed for the project. The requirements include the performance and energy indicators that the data collection framework is expected to log and analyse, the agreed data formats and the architecture of the data collection tool. The deliverable also discusses the available datasets from Flexiant and the University of ULM.",
            "Abstract entirety": 1,
            "Author pub id": "PkCuYUQAAAAJ:pqnbT2bcN3wC",
            "Publisher": "Universit\u00e4t Ulm"
        },
        {
            "Title": "Online strategies for high-performance power-aware thread execution on emerging multiprocessors",
            "Publication year": 2006,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/1639598/",
            "Abstract": "Granularity control is an effective means for trading power consumption with performance on dense shared memory multiprocessors, such as multi-SMT and multi-CMP systems. With granularity control, the number of threads used to execute an application, or part of an application, is changed, thereby also changing the amount of work done by each active thread. In this paper, we analyze the energy/performance trade-off of varying thread granularity in parallel benchmarks written for shared memory systems. We use physical experimentation on a real multi-SMT system and a power estimation model based on the die areas of processor components and component activity factors obtained from a hardware event monitor. We also present HPPATCH, a runtime algorithm for live tuning of thread granularity, which attempts to simultaneously reduce both execution time and processor power consumption",
            "Abstract entirety": 1,
            "Author pub id": "PkCuYUQAAAAJ:lmc2jWPfTJgC",
            "Publisher": "IEEE"
        },
        {
            "Title": "MyMinder: A User-centric Decision Making Framework for Intercloud Migration.",
            "Publication year": 2017,
            "Publication url": "https://www.researchgate.net/profile/Esha-Barlaskar/publication/317299552_MyMinder_A_User-centric_Decision_Making_Framework_for_Intercloud_Migration/links/5a9fb7fca6fdcc22e2cbe7a2/MyMinder-A-User-centric-Decision-Making-Framework-for-Intercloud-Migration.pdf",
            "Abstract": "Each cloud infrastructure-as-a-service (IaaS) provider offers its own set of virtual machine (VM) images and hypervisors. This creates a vendor lock-in problem when cloud users try to change cloud provider (CP). Although, recently a few user-side inter-cloud migration techniques have been proposed (eg nested virtualisation), these techniques do not provide dynamic cloud management facilities which could help users to decide whether or not to proceed with migration, when and where to migrate, etc. Such decision-making support in the post-deployment phase is crucial when the current CP\u2019s Quality of Service (QoS) degrades while other CPs offer better QoS or the same service at a lower price. To ensure that users\u2019 required QoS constraints are achieved, dynamic monitoring and management of the acquired cloud services are very important and should be integrated with the inter-cloud migration techniques. In this paper, we present the problem formulation and the architecture of a Multi-objective dYnamic MIgratioN Decision makER (MyMinder) framework that enables users to monitor and appropriately manage their deployed applications by providing decisions on whether to continue with the currently selected CP or to migrate to a different CP. The paper also discusses experimental results obtained when running a Spark linear regression application in Amazon EC2 and Microsoft Azure as an initial investigation to understand the motivating factors for live-migration of cloud applications across cloud providers in the post-deployment phase.",
            "Abstract entirety": 1,
            "Author pub id": "PkCuYUQAAAAJ:SeFeTyx0c_EC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Integrating multiple forms of multithreaded execution on multi-SMT systems: a study with scientific applications",
            "Publication year": 2005,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/1595796/",
            "Abstract": "Most scientific applications have high degrees of parallelism and thread-level parallel execution appears to be a natural choice for executing these applications on systems composed of SMT processors. Unfortunately, contention for shared resources limits the performance advantages of multithreading on current SMT processors, thus leading to marginal utilization of multiple hardware threads and even slowdown due to multithreading. We show, through a rigorous evaluation with hardware monitoring counters on a real multi-SMT system, that in traditionally scalable parallel applications conflicting resource requirements are - due to the high degree of resource sharing - accountable for deeply sub-optimal performance. Motivated by this observation, we investigate the use of alternative forms of multithreaded execution, including adaptive thread throttling and speculative runahead execution, to make better use of \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:cFHS6HbyZ2cC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Deployment and Use of Accelerators (DUAC 2021)",
            "Publication year": 2021,
            "Publication url": "https://pure.qub.ac.uk/en/publications/deployment-and-use-of-accelerators-duac-2021",
            "Abstract": "Deployment and Use of Accelerators (DUAC 2021) \u2014 Queen's University Belfast Skip to main \nnavigation Skip to search Skip to main content Queen's University Belfast Home Queen's \nUniversity Belfast Logo Help & FAQ Home Profiles Organisations Research output Projects \nImpact Datasets Activities Prizes Press / Media Student theses Facilities Search by expertise, \nname or affiliation Deployment and Use of Accelerators (DUAC 2021) Carlos Re\u00e3no, Dimitrios S. \nNikolopoulos Queen's University Belfast Research output: Chapter in Book/Report/Conference \nproceeding \u203a Other chapter contribution Overview Original language English Title of host \npublication ICPP Workshops '21: 50th International Conference on Parallel Processing Workshop \nPublisher ACM ISBN (Electronic) 978-1-4503-8441-4 DOIs https://doi.org/10.1145/3458744 \nPublication status Published - 09 Aug 2021 Event 50th International Conference on , /'\u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:MhiOAD_qIWkC",
            "Publisher": "ACM"
        },
        {
            "Title": "Scalable runtime support for data-intensive applications on the single-chip cloud computer",
            "Publication year": 2011,
            "Publication url": "https://books.google.com/books?hl=en&lr=&id=vBg-VbSbsz0C&oi=fnd&pg=PA25&dq=info:oyKg4HHPra4J:scholar.google.com&ots=HRUUe7-o9-&sig=EqXiHDFE72ndvkEMRq0jPAxj9T4",
            "Abstract": "Many-core processors, due to their complexity and diversity, necessitate high-productivity, domain-specific approaches to parallel programming. These approaches should hide architectural details and low-level parallelization constructs, while enabling scalability and performance portability. This paper presents a scalable implementation of MapReduce, a runtime system used widely by domain-specific languages for large-scale data processing, on the Intel SCC. We address the scalability bottlenecks of MapReduce with data partitioning, combining and sorting algorithms that we customize for the SCC network on-chip architecture. We achieve linear or superlinear speedups for representative MapReduce workloads with data sets that fit on a single SCC node. We also show that the SCC node outperforms the IBM Cell QS22 Blade, when the latter uses the fastest implementation of MapReduce available for the Cell processor.",
            "Abstract entirety": 1,
            "Author pub id": "PkCuYUQAAAAJ:yB1At4FlUx8C",
            "Publisher": "KIT Scientific Publishing"
        },
        {
            "Title": "ENORM: A framework for edge node resource management",
            "Publication year": 2017,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/8039523/",
            "Abstract": "Current computing techniques using the cloud as a centralised server will become untenable as billions of devices get connected to the Internet. This raises the need for fog computing, which leverages computing at the edge of the network on nodes, such as routers, base stations and switches, along with the cloud. However, to realise fog computing the challenge of managing edge nodes will need to be addressed. This paper is motivated to address the resource management challenge. We develop the first framework to manage edge nodes, namely the Edge NOde Resource Management (ENORM) framework. Mechanisms for provisioning and auto-scaling edge node resources are proposed. The feasibility of the framework is demonstrated on a Pok\u00e9Mon Go-like online game use-case. The benefits of using ENORM are observed by reduced application latency between 20%-80% and reduced data transfer and \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:HeT0ZceujKMC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Btl: A framework for measuring and modeling energy in memory hierarchies",
            "Publication year": 2012,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/6374782/",
            "Abstract": "Understanding the energy efficiency of computing systems is paramount. Although processors remain dominant energy consumers and the focal target of energy-aware optimization in computing systems, the memory subsystem dissipates substantial amounts of power, which at high densities may exceed50% of total system power. The failure of DRAM to keep up with increasing processor speeds, creates a two-pronged bottleneck for overall system energy efficiency. This paper presents a high-performance, autonomic power instrumentation setup to measure energy consumption in computing systems and accurately attribute energy to processors and components of the memory hierarchy. We provide a set of carefully engineered micro benchmarks that reveal the energy efficiency under different memory access patterns and stress the importance of minimizing costly data transfers that involve multiple levels of the \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:nrtMV_XWKgEC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Overcoming the scalability challenges of contagion simulations on Blue Waters",
            "Publication year": 2013,
            "Publication url": "https://scholar.google.com/scholar?cluster=12561249416908994074&hl=en&oi=scholarr",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "PkCuYUQAAAAJ:4X0JR2_MtJMC",
            "Publisher": "Technical Report 13-057, NDSSL, Virginia Bioinformatics Institute at Virginia Tech"
        },
        {
            "Title": "Scheduler-activated Dynamic Page Migration for Multiprogrammed DSM Multiprocessors",
            "Publication year": 2002,
            "Publication url": "https://scholar.google.com/scholar?cluster=11342413043328127138&hl=en&oi=scholarr",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "PkCuYUQAAAAJ:tKAzc9rXhukC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Using Computational Significance and Resilience in System Software Stacks.: Keynote Talk",
            "Publication year": 2016,
            "Publication url": "https://pure.qub.ac.uk/en/publications/using-computational-significance-and-resilience-in-system-softwar",
            "Abstract": "This talk explores how the runtime system and operating system can leverage metrics that express the significance and resilience of application components in order to reduce the energy footprint of parallel applications. We will explore in particular how software can tolerate and indeed exploit higher error rates in future processors and memory technologies that may operate outside their safe margins.",
            "Abstract entirety": 1,
            "Author pub id": "PkCuYUQAAAAJ:BUYA1_V_uYcC",
            "Publisher": "Unknown"
        },
        {
            "Title": "A scalable runtime for the ecoscale heterogeneous exascale hardware platform",
            "Publication year": 2016,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/2931088.2931090",
            "Abstract": "Exascale computation is the next target of high performance computing. In the push to create exascale computing platforms, simply increasing the number of hardware devices is not an acceptable option given the limitations of power consumption, heat dissipation, and programming models which are designed for current hardware platforms. Instead, new hardware technologies, coupled with improved programming abstractions and more autonomous runtime systems, are required to achieve this goal.",
            "Abstract entirety": 1,
            "Author pub id": "PkCuYUQAAAAJ:4OULZ7Gr8RgC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Proceedings of the 2nd International Workshop on Energy Efficient Supercomputing",
            "Publication year": 2014,
            "Publication url": "https://pure.qub.ac.uk/en/publications/proceedings-of-the-2nd-international-workshop-on-energy-efficient",
            "Abstract": "Proceedings of the 2nd International Workshop on Energy Efficient Supercomputing \u2014 Queen's \nUniversity Belfast Skip to main navigation Skip to search Skip to main content Queen's University \nBelfast Logo Help & FAQ Home Profiles Organisations Research output Projects Impact \nDatasets Activities Prizes Press / Media Student theses Facilities Search by expertise, name or \naffiliation Proceedings of the 2nd International Workshop on Energy Efficient Supercomputing \nKirk Cameron (Editor), Adolfy Hoisie (Editor), Darren Kerbyson (Editor), David Lowenthal \n(Editor), Dimitrios S. Nikolopoulos (Editor), Sudha Yalamanchili (Editor), Andres Marquez \n(Editor) School of Electronics, Electrical Engineering and Computer Science High Performance \nand Distributed Computing Research output: Book/Report \u203a Book Overview Original language \nEnglish Publisher Institute of Electrical and Electronics Engineers (IEEE) ISBN (Print) -\u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:FPJr55Dyh1AC",
            "Publisher": "Institute of Electrical and Electronics Engineers (IEEE)"
        },
        {
            "Title": "NUMA Machines and Clusters-A Study of Implicit Data Distribution Methods for OpenMP Using the SPEC Benchmarks",
            "Publication year": 2001,
            "Publication url": "https://scholar.google.com/scholar?cluster=3102594319767485569&hl=en&oi=scholarr",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "PkCuYUQAAAAJ:IWHjjKOFINEC",
            "Publisher": "Berlin: Springer-Verlag, 1973-"
        },
        {
            "Title": "Application-specific customization on many-core platforms: the VT-ASOS framework",
            "Publication year": 2007,
            "Publication url": "https://scholar.google.com/scholar?cluster=9644116873175900793&hl=en&oi=scholarr",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "PkCuYUQAAAAJ:LgRImbQfgY4C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Overcoming the scalability challenges of epidemic simulations on blue waters",
            "Publication year": 2014,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/6877307/",
            "Abstract": "Modeling dynamical systems represents an important application class covering a wide range of disciplines including but not limited to biology, chemistry, finance, national security, and health care. Such applications typically involve large-scale, irregular graph processing, which makes them difficult to scale due to the evolutionary nature of their workload, irregular communication and load imbalance. EpiSimdemics is such an application simulating epidemic diffusion in extremely large and realistic social contact networks. It implements a graph-based system that captures dynamics among co-evolving entities. This paper presents an implementation of EpiSimdemics in Charm++ that enables future research by social, biological and computational scientists at unprecedented data and system scales. We present new methods for application-specific processing of graph data and demonstrate the effectiveness of these \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:KlAtU1dfN6UC",
            "Publisher": "IEEE"
        },
        {
            "Title": "DMA-based prefetching for I/O-intensive workloads on the cell architecture",
            "Publication year": 2008,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/1366230.1366236",
            "Abstract": "Recent advent of the asymmetric multi-core processors such as Cell Broadband Engine (Cell/BE) has popularized the use of heterogeneous architectures. A growing body of research is exploring the use of such architectures, especially in High-End Computing, for supporting scientific applications. However, prior research has focused on use of the available Cell/BE operating systems and runtime environments for supporting compute-intensive jobs. Data and I/O intensive workloads have largely been ignored in this domain. In this paper, we take the first steps in supporting I/O intensive workloads on the Cell/BE and deriving guidelines for optimizing the execution of I/O workloads on heterogeneous architectures. We explore various performance enhancing techniques for such workloads on an actual Cell/BE system. Among the techniques we explore, an asynchronous prefetching-based approach, which uses the \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:mlAyqtXpCwEC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Comparing scalability prediction strategies on an SMP of CMPs",
            "Publication year": 2010,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-642-15277-1_14",
            "Abstract": "Diminishing performance returns and increasing power consumption of single-threaded processors have made chip multiprocessors (CMPs) an industry imperative. Unfortunately, poor software/hardware interaction and bottlenecks in shared hardware structures can prevent scaling to many cores. In fact, adding a core may harm performance and increase power consumption. Given these observations, we compare two approaches to predicting parallel application scalability: multiple linear regression and artificial neural networks (ANNs). We throttle concurrency to levels with higher predicted power/performance efficiency. We perform experiments on a state-of-the-art, dual-processor, quad-core platform, showing that both methodologies achieve high accuracy and identify energy-efficient concurrency levels in multithreaded scientific applications. The ANN approach has advantages, but the simpler \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:_kc_bZDykSQC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "Dram characterization under relaxed refresh period considering system level effects within a commodity server",
            "Publication year": 2018,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/8474184/",
            "Abstract": "Today's rapid generation of data and the increased need for higher memory capacity has triggered a lot of studies on aggressive scaling of refresh period, which is currently set according to rare worst case conditions. Such studies analysed in detail the data-dependent circuit level factors and indicated the need for online DRAM characterization due to the variable cell retention time. They have done so by executing few test data patterns on FPGAs under controlled temperatures by using thermal testbeds, which however cannot be available in the field. Moreover, the existing studies were not able to reveal any system level effects, which may be excited under the execution of workloads on real systems and directly or indirectly affect DRAM reliability. In this paper, we develop an experimental framework based on a state-of-the-art 64-bit ARM based server with Linux OS, in which we enabled the DRAM characterization \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:BrmTIyaxlBUC",
            "Publisher": "IEEE"
        },
        {
            "Title": "A multigrain Delaunay mesh generation method for multicore SMT-based architectures",
            "Publication year": 2009,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S0743731509000604",
            "Abstract": "Given the proliferation of layered, multicore- and SMT-based architectures, it is imperative to deploy and evaluate important, multi-level, scientific computing codes, such as meshing algorithms, on these systems. We focus on Parallel Constrained Delaunay Mesh (PCDM) generation. We exploit coarse-grain parallelism at the subdomain level, medium-grain at the cavity level and fine-grain at the element level. This multi-grain data parallel approach targets clusters built from commercially available SMTs and multicore processors. The exploitation of the coarser degree of granularity facilitates scalability both in terms of execution time and problem size on loosely-coupled clusters. The exploitation of medium-grain parallelism allows performance improvement at the single node level. Our experimental evaluation shows that the first generation of SMT cores is not capable of taking advantage of fine-grain parallelism in \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:JQOojiI6XY0C",
            "Publisher": "Academic Press"
        },
        {
            "Title": "Implementing efficient message logging protocols as MPI application extensions",
            "Publication year": 2019,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/3343211.3343219",
            "Abstract": "Message logging protocols are enablers of local rollback, a more efficient alternative to global rollback, for fault tolerant MPI applications. Until now, message logging MPI implementations have incurred the overheads of a redesign and redeployment of an MPI library, as well as continued performance penalties across various kernels. Successful research efforts for message logging implementations do exist, but not a single one of them can be easily deployed today by more than a few experts. In contrast, in this work we build efficient message logging capabilities on top of an MPI library with no message logging capabilities; we do so for two different send-deterministic HPC kernels, one with a global exchange pattern (CG), and one with a neighbour exchange pattern (LULESH). While our library of choice ULFM detects failure and recovers MPI communicators, we build on that to then restore the intra-and inter \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:J-pR_7NvFogC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Quantifying contention and balancing memory load on hardware DSM multiprocessors",
            "Publication year": 2003,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S0743731503001059",
            "Abstract": "This paper makes the following contributions: It proposes a new methodology for quantifying remote memory access contention on hardware DSM multiprocessors. The most valuable aspect of this methodology is that it assesses the overhead of contention on real parallel programs running on real hardware. The methodology uses as input the number of accesses from each node of the DSM to each page in memory. A trace of the memory accesses of the program obtained at runtime is used to compute a fairly accurate estimate of the fraction of execution time wasted due to contention. The paper presents also a new algorithm which detects potential hot spots in pages and balances memory load using dynamic page migration. The algorithm attacks indirectly the problem of contention by balancing the remote memory access latency across the nodes of the system. Experiments with five irregular parallel codes on a \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:e_rmSamDkqQC",
            "Publisher": "Academic Press"
        },
        {
            "Title": "Revealing DRAM Operating GuardBands through Workload-Aware Error Predictive Modeling",
            "Publication year": 2020,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/9239888/",
            "Abstract": "In this paper, we present a new technique for automatic scaling the DRAM refresh period under reduced supply voltage that minimizes the probability of failures. The main idea behind the proposed approach is that DRAM error behavior is workload-dependent and can be predicted based on particular program inherent features. We use a Machine Learning (ML) method to build a workload-aware DRAM error behavior model based on the program features which we extract from real workloads during our DRAM error characterization campaign. With such a model, we identify the marginal value of the DRAM refresh period under relaxed voltage for each DRAM module of a server that enable us to reduce the DRAM power. We implement a temperature-driven OS governor which automatically sets the module-specific marginal DRAM parameters discovered by the ML model. Our governor reduces the DRAM power by \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:bEWYMUwI8FkC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Student research poster: A scalable general purpose system for large-scale graph processing",
            "Publication year": 2016,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/7756793/",
            "Abstract": "Graph analytics is an important and computationally demanding class of data analytics. It is essential to balance scalability, ease-of-use and high performance in large scale graph analytics. As such, it is necessary to hide the complexity of parallelism, data distribution and memory locality behind an abstract interface [2].",
            "Abstract entirety": 1,
            "Author pub id": "PkCuYUQAAAAJ:IRz6iEL74y4C",
            "Publisher": "IEEE"
        },
        {
            "Title": "Integrated data collection and analysis frameworks: project deliverable D4. 4",
            "Publication year": 2017,
            "Publication url": "https://oparu.uni-ulm.de/xmlui/handle/123456789/4349",
            "Abstract": "CactoScale is a CACTOS component which provides monitoring and data analysis functionality. This deliverable presents the integration of the algorithmic data analysis framework and the data collection tool in a production-mode setup. For the setup we utilised the testbed provided by the industrial partner Flexiant and we examined CactoScale under the workload provided by DataPlay application from Playgen. In this deliverable we measure the performance of CactoScale when this is integrated with Flexiant Cloud Orchestrator (FCO) and the University of Ulm (UULM) testbeds under the impact of Playgen\u2019s enterprise application (DataPlay) workload. We assess the scaling capability of the monitoring framework by measuring the overall latency under increasing numbers of VMs on the platform\u2019s nodes. Furthermore, we assess any overhead induced by CactoScale on the integrated use case of Playgen when deployed on FCO. CactoScale also provides data analysis functionality to CACTOS. We demonstrate the performance of the analysis framework when integrated on the FCO-testbed and the UULM testbed. We use data collected from monitoring the deployed DataPlay application to perform correlation analysis using a Lightweight Anomaly Detection Tool (LADT). LADT utilises data correlation analysis to indicate any potential anomalies on a cloud compute node. To experiment on anomaly detection analysis we employ the DICE-fault-injection tool which allows fault injection on the Flexiant\u2019s platform. We use DataPlay\u2019s workload measurements to further estimate the scalability of the analytics tool by comparing the performance when \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:IaI1MmNe2tcC",
            "Publisher": "Universit\u00e4t Ulm"
        },
        {
            "Title": "Inference and declaration of independence: Impact on deterministic task parallelism",
            "Publication year": 2012,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/2370816.2370892",
            "Abstract": "We present a set of static techniques that reduce runtime overheads in task-parallel programs with implicit synchronization. We use a static dependence analysis to detect non-conflicting tasks and remove unnecessary runtime checks. We further reduce overheads by statically optimizing task creation and management of runtime metadata. We implemented these optimizations in SCOOP, a source-to-source compiler for such a programming model and runtime system. We evaluate SCOOP on 10 representative benchmarks and show that our approach can improve performance by 12% on average.",
            "Abstract entirety": 1,
            "Author pub id": "PkCuYUQAAAAJ:wbdj-CoPYUoC",
            "Publisher": "Unknown"
        },
        {
            "Title": "MESA: reducing cache conflicts by integrating static and run-time methods",
            "Publication year": 2006,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/1620803/",
            "Abstract": "The paper proposes MESA (Multicoloring with Embedded Skewed Associativity), a novel cache indexing scheme that integrates dynamic page coloring with static skewed associativity to reduce conflicts in L2/L3 caches with a small degree of associativity. MESA associates multiple cache pages (colors) with each virtual memory page and uses two-level skewed associativity, first to map a page to a different color in each bank of the cache, and then to disperse the lines of a page across the banks and within the colors of the page. MESA is a multi-grained cache indexing scheme that combines the best of two worlds, page coloring and skewed associativity. We also propose a novel cache management scheme based on page remapping, which uses cache miss imbalance between colors in each bank as the metric to track conflicts and trigger remapping. We evaluate MESA using 24 benchmarks from multiple \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:Aul-kAQHnToC",
            "Publisher": "IEEE"
        },
        {
            "Title": "smt-SPRINTS: Software Precomputation with Intelligent Streaming for Resource-Constrained SMTs",
            "Publication year": 2005,
            "Publication url": "https://link.springer.com/chapter/10.1007/11549468_78",
            "Abstract": "We present SPRINTS, a source-level speculative precomputation framework for scientific applications running on SMTs with two execution contexts. Our framework targets memory-bound applications and reduces memory latency by prefetching long streams of delinquent data accesses. A unique aspect of SPRINTS is that it requires neither hardware nor compiler support. It is based on partial cache simulation and a compression algorithm which can accurately summarize very long streams of cache misses. SPRINTS extracts patterns from the streams, which are in turn used to generate source-level, highly optimized precomputation code. SPRINTS achieves significant performance improvements over plain thread-level parallelization and indiscriminate precomputation based on code cloning. We demonstrate these improvements using two realistic scientific applications.",
            "Abstract entirety": 1,
            "Author pub id": "PkCuYUQAAAAJ:Ehil0879vHcC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "GPU virtualization and scheduling methods: A comprehensive survey",
            "Publication year": 2017,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/3068281",
            "Abstract": "The integration of graphics processing units (GPUs) on high-end compute nodes has established a new accelerator-based heterogeneous computing model, which now permeates high-performance computing. The same paradigm nevertheless has limited adoption in cloud computing or other large-scale distributed computing paradigms. Heterogeneous computing with GPUs can benefit the Cloud by reducing operational costs and improving resource and energy efficiency. However, such a paradigm shift would require effective methods for virtualizing GPUs, as well as other accelerators. In this survey article, we present an extensive and in-depth survey of GPU virtualization techniques and their scheduling methods. We review a wide range of virtualization techniques implemented at the GPU library, driver, and hardware levels. Furthermore, we review GPU scheduling methods that address performance and \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:dBIO0h50nwkC",
            "Publisher": "ACM"
        },
        {
            "Title": "Programming the Energy Efficiency of High Performance Computing Systems",
            "Publication year": 2013,
            "Publication url": "https://pure.qub.ac.uk/en/publications/programming-the-energy-efficiency-of-high-performance-computing-s",
            "Abstract": "Programming the Energy Efficiency of High Performance Computing Systems \u2014 Queen's \nUniversity Belfast Skip to main navigation Skip to search Skip to main content Queen's \nUniversity Belfast Logo Help & FAQ Home Profiles Organisations Research output Projects \nImpact Datasets Activities Prizes Press / Media Student theses Facilities Search by expertise, \nname or affiliation Programming the Energy Efficiency of High Performance Computing Systems \nDimitrios S. Nikolopoulos School of Electronics, Electrical Engineering and Computer Science \nHigh Performance and Distributed Computing Research output: Contribution to conference \u203a \nAbstract 159 Downloads (Pure) Overview Projects (1) Original language English Number of \npages 1 Publication status Published - Sep 2013 Event Fourth International Conference on \nEnergy-Aware High Performance Computing - Dresden, Germany Duration: 02 Sep 2013 \u2192 04 -/\u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:uWQEDVKXjbEC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Runtime support for adaptive power capping on heterogeneous socs",
            "Publication year": 2016,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/7818333/",
            "Abstract": "Power capping is a fundamental method for reducing the energy consumption of a wide range of modern computing environments, ranging from mobile embedded systems to datacentres. Unfortunately, maximising performance and system efficiency under static power caps remains challenging, while maximising performance under dynamic power caps has been largely unexplored. We present an adaptive power capping method that reduces the power consumption and maximizes the performance of heterogeneous SoCs for mobile and server platforms. Our technique combines power capping with coordinated DVFS, data partitioning and core allocations on a heterogeneous SoC with ARM processors and FPGA resources. We design our framework as a run-time system based on OpenMP and OpenCL to utilise the heterogeneous resources. We evaluate it through five data-parallel benchmarks on the Xilinx SoC \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:4vMrXwiscB8C",
            "Publisher": "IEEE"
        },
        {
            "Title": "Dimitrios S. Nikolopoulos, Constantine D. Polychronopoulos, Theodore S. Papatheodorou, Jes! us Labarta, and Eduard Ayguad! e. Scheduler-Activated Dynamic Page Migration for Multiprogrammed DSM Multiprocessors Ajay D. Kshemkalyani and Mukesh Singhal. Communication Patterns in Distributed Computations",
            "Publication year": 2002,
            "Publication url": "https://scholar.google.com/scholar?cluster=7078126760315164154&hl=en&oi=scholarr",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "PkCuYUQAAAAJ:BJbdYPG6LGMC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Mapping and Scheduling on Multi-core Processors using SMT Sol-vers",
            "Publication year": 2014,
            "Publication url": "https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.680.9372&rep=rep1&type=pdf",
            "Abstract": "In order to achieve performance gains in the software, computers have evolved to multi-core and many-core platforms abounding with multiple processor cores. However the problem of finding efficient ways to execute parallel software on these platform is hard. With a large number of processor cores available, the software must orchestrate the communication, synchronization along with the execution of the code. Communication corresponds to the transport of data between di\u21b5 erent processors, which either can be handled transparently by the hardware or explicitly managed by the software. Synchronization is a requirement of proper selection of start time of computations eg the condition for software tasks to begin execution only after all its dependencies are satisfied. Models which represent the algorithms in a structured and formal way expose the available parallelism. Deployment of the software algorithms represented by such models needs a specification of which processor to execute the tasks on (mapping) and when to execute them (scheduling). Mapping and scheduling is a hard combinatorial problem to solve with a huge design space containing exponential number of solutions. In addition, the solutions are evaluated according to di\u21b5 erent costs that need to be optimized, such as memory consumption, time to execute, static power consumption, resources used etc. Such a problem with multiple costs is called a multi-criteria optimization problem. The solution to this problem is not a unique single solution, but a set of incomparable solutions called Pareto solutions. In order to track multi-criteria problems, special algorithms are needed \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:eQOLeE2rZwMC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Scalo: Scalability-aware parallelism orchestration for multi-threaded workloads",
            "Publication year": 2017,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/3158643",
            "Abstract": "Shared memory machines continue to increase in scale by adding more parallelism through additional cores and complex memory hierarchies. Often, executing multiple applications concurrently, dividing among them hardware threads, provides greater efficiency rather than executing a single application with large thread counts. However, contention for shared resources can limit the improvement of concurrent application execution: orchestrating the number of threads used by each application and is essential.In this article, we contribute SCALO, a solution to orchestrate concurrent application execution to increase throughput. SCALO monitors co-executing applications at runtime to evaluate their scalability. Its optimizing thread allocator analyzes these scalability estimates to adapt the parallelism of each program. Unlike previous approaches, SCALO differs by including dynamic contention effects on scalability \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:LPZeul_q3PIC",
            "Publisher": "ACM"
        },
        {
            "Title": "A significance-driven programming framework for energy-constrained approximate computing",
            "Publication year": 2015,
            "Publication url": "https://dl.acm.org/doi/pdf/10.1145/2742854.2742857",
            "Abstract": "Approximate execution is a viable technique for energy-constrained environments, provided that applications have the mechanisms to produce outputs of the highest possible quality within the given energy budget.",
            "Abstract entirety": 1,
            "Author pub id": "PkCuYUQAAAAJ:p2g8aNsByqUC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Mini-symposium on energy and resilience in parallel programming",
            "Publication year": 2016,
            "Publication url": "https://pure.qub.ac.uk/en/publications/mini-symposium-on-energy-and-resilience-in-parallel-programming",
            "Abstract": "Mini-symposium on energy and resilience in parallel programming \u2014 Queen's University \nBelfast Skip to main navigation Skip to search Skip to main content Queen's University Belfast \nLogo Help & FAQ Home Profiles Organisations Research output Projects Impact Datasets \nActivities Prizes Press / Media Student theses Facilities Search by expertise, name or affiliation \nMini-symposium on energy and resilience in parallel programming Dimitrios S. Nikolopoulos, \nChristos D. Antonopoulos * * Corresponding author for this work Queen's University Belfast \nResearch output: Chapter in Book/Report/Conference proceeding \u203a Foreword/postscript \nOverview Original language English Title of host publication Parallel Computing Subtitle of host \npublication On the Road to Exascale Editors Frans Peters, Mark Parsons, Mark Sawyer, Hugh \nLeather, Gerhard R. Joubert Publisher Elsevier BV Number of pages 1 ISBN (Electronic) https\u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:ye4kPcJQO24C",
            "Publisher": "Elsevier BV"
        },
        {
            "Title": "Runtime and programming support for memory adaptation in scientific applications via local disk and remote memory",
            "Publication year": 2007,
            "Publication url": "https://link.springer.com/content/pdf/10.1007/s10723-007-9075-7.pdf",
            "Abstract": "The ever increasing memory demands of many scientific applications and the complexity of today\u2019s shared computational resources still require the occasional use of virtual memory, network memory, or even out-of-core implementations, with well known drawbacks in performance and usability. In Mills et al. (Adapting to memory pressure from within scientific applications on multiprogrammed COWS. In: International Parallel and Distributed Processing Symposium, IPDPS, Santa Fe, NM, 2004), we introduced a basic framework for a runtime, user-level library, MMlib, in which DRAM is treated as a dynamic size cache for large memory objects residing on local disk. Application developers can specify and access these objects through MMlib, enabling their application to execute optimally under variable memory availability, using as much DRAM as fluctuating memory levels will allow. In this paper, we first \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:mvPsJ3kp5DgC",
            "Publisher": "Kluwer Academic Publishers"
        },
        {
            "Title": "User-level dynamic page migration for multiprogrammed shared-memory multiprocessors",
            "Publication year": 2000,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/876083/",
            "Abstract": "This paper presents algorithms for improving the performance of parallel programs on multiprogrammed shared-memory NUMA multiprocessors, via the use of user-level dynamic page migration. The idea that drives the algorithms is that a page migration engine can perform accurate and timely page migrations in a multiprogrammed system if it can correlate page reference information with scheduling information obtained from the operating system. The necessary page migrations can be performed as a response to scheduling events that break the implicit association between threads and their memory affinity sets. We present two algorithms that use feedback from the kernel scheduler to aggressively migrate pages upon thread migrations. The first algorithm exploits the iterative nature of parallel programs, while the second targets generic codes without making assumptions on their structure. Performance \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:RGFaLdJalmkC",
            "Publisher": "IEEE"
        },
        {
            "Title": "The CACTOS vision of context-aware cloud topology optimization and simulation",
            "Publication year": 2014,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/7037644/",
            "Abstract": "Recent advances in hardware development coupled with the rapid adoption and broad applicability of cloud computing have introduced widespread heterogeneity in data centers, significantly complicating the management of cloud applications and data center resources. This paper presents the CACTOS approach to cloud infrastructure automation and optimization, which addresses heterogeneity through a combination of in-depth analysis of application behavior with insights from commercial cloud providers. The aim of the approach is threefold: to model applications and data center resources, to simulate applications and resources for planning and operation, and to optimize application deployment and resource use in an autonomic manner. The approach is based on case studies from the areas of business analytics, enterprise applications, and scientific computing.",
            "Abstract entirety": 1,
            "Author pub id": "PkCuYUQAAAAJ:hMod-77fHWUC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Designing accelerator-based distributed systems for high performance",
            "Publication year": 2010,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/5493481/",
            "Abstract": "Multi-core processors with accelerators are becoming commodity components for high-performance computing at scale. While accelerator-based processors have been studied in some detail, the design and management of clusters based on these processors have not received the same focus. In this paper, we present an exploration of four design and resource management alternatives, which can be used on large-scale asymmetric clusters with accelerators. Moreover, we adapt the popular MapReduce programming model to our proposed configurations. We enhance MapReduce with new dynamic data streaming and workload scheduling capabilities, which enable application writers to use asymmetric accelerator-based clusters without being concerned with the capabilities of individual components. We present an evaluation of the presented designs in a physical setting and show that our designs can provide \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:1sJd4Hv_s6UC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Scalable memory registration for high performance networks using helper threads",
            "Publication year": 2011,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/2016604.2016652",
            "Abstract": "Remote DMA (RDMA) enables high performance networks to reduce data copying between an application and the operating system (OS). However RDMA operations in some high performance networks require communication memory explicitly registered with the network adapter and pinned by the OS. Memory registration and pinning limits the flexibility of the memory system and reduces the amount of memory that user processes can allocate. These issues become more significant on multicore platforms, since registered memory demand grows linearly with the number of processor cores. In this paper we propose a new memory registration/deregistration strategy to reduce registered memory on multicore architectures for HPC applications. We hide the cost of dynamic memory management by offloading all dynamic memory registration and deregistration requests to a dedicated memory management helper \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:blknAaTinKkC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Efficient, Dynamic Multi-Task Execution on FPGA-Based Computing Systems",
            "Publication year": 2021,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/9502563/",
            "Abstract": "With growing Field Programmable Gate Array (FPGA) device sizes and their integration in environments enabling sharing of computing resources such as cloud and edge computing, there is a requirement to share the FPGA area between multiple tasks. The resource sharing typically involves partitioning the FPGA space into fix-sized slots. This results in suboptimal resource utilisation and relatively poor performance, particularly as the number of tasks increase. Using OpenCL\u2019s exploration capabilities, we employ clever clustering and custom, task-specific partitioning and mapping to create a novel, area sharing methodology where task resource requirements are more effectively managed. Using models with varying resource/throughput profiles, we select the most appropriate distribution based on the runtime, workload needs to enhance temporal compute density. The approach is enabled in the system stack by a \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:1taIhTC69MYC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Characterization of hpc workloads on an armv8 based server under relaxed dram refresh and thermal stress",
            "Publication year": 2018,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/3229631.3236091",
            "Abstract": "Improving energy efficiency of the memory subsystem becomes increasingly important for all digital systems due to the rapid growth of data. Many recent schemes have attempted to reduce the DRAM power by relaxing the refresh rate, which may negatively affect the DRAM reliability. To optimize the trade-offs between power and reliability, existing studies rely on experimental setups based on FPGAs and the use of few known data-patterns for exciting rare worst-case circuit reliability effects. However, by doing so, existing studies may be missing to capture the real DRAM behavior within a commodity server with a fully fledged OS.",
            "Abstract entirety": 1,
            "Author pub id": "PkCuYUQAAAAJ:fEOibwPWpKIC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Algorithm, software, and hardware optimizations for Delaunay mesh generation on simultaneous multithreaded architectures",
            "Publication year": 2009,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S0743731509000458",
            "Abstract": "This article focuses on the optimization of PCDM, a parallel, two-dimensional (2D) Delaunay mesh generation application, and its interaction with parallel architectures based on simultaneous multithreading (SMT) processors. We first present the step-by-step effect of a series of optimizations on performance. These optimizations improve the performance of PCDM by up to a factor of six. They target issues that very often limit the performance of scientific computing codes. We then evaluate the interaction of PCDM with a real SMT-based SMP system, using both high-level metrics, such as execution time, and low-level information from hardware performance counters.",
            "Abstract entirety": 1,
            "Author pub id": "PkCuYUQAAAAJ:5ugPr518TE4C",
            "Publisher": "Academic Press"
        },
        {
            "Title": "Fast and Energy-Efficient OLAP Data Management on Hybrid Main Memory Systems",
            "Publication year": 2019,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/8723105/",
            "Abstract": "This paper studies the problem of efficiently utilizing hybrid memory systems, consisting of both Dynamic Random Access Memory (DRAM) and novel Non-Volatile Memory (NVM) in database management systems (DBMS) for online analytical processing (OLAP) workloads. We present a methodology to determine the database operators that are responsible for most main memory accesses. Our analysis uses both cost models and empirical measurements. We develop heuristic decision procedures to allocate data in hybrid memory at the time that the data buffers are allocated, depending on the expected memory access frequency. We implement these heuristics in the MonetDB column-oriented database and demonstrate performance improvement and energy-efficiency as compared to state-of-the-art application-agnostic hybrid memory management techniques.",
            "Abstract entirety": 1,
            "Author pub id": "PkCuYUQAAAAJ:35r97b3x0nAC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Shared-Memory Multiprocessors\u201d",
            "Publication year": 2003,
            "Publication url": "https://books.google.com/books?hl=en&lr=&id=O1NqCQAAQBAJ&oi=fnd&pg=PA85&dq=info:hE-oCEXZHJwJ:scholar.google.com&ots=kFlUwlsn5M&sig=sSibbgPaLfkIt84_IjFXy_u3r4o",
            "Abstract": "We present the design and implementation of UPMLIB, a runtime system that provides transparent facilities for dynamically tuning the memory performance of OpenMP programs on scalable shared-memory multiprocessors with hardware cache-coherence. UPMLIB integrates information from the compiler and the operating system, to implement algorithms that perform accurate and timely page migrations. The algorithms and the associated mechanisms correlate memory reference information with the semantics of parallel programs and scheduling events that break the association between threads and data for which threads have memory affinity at runtime. Our experimental evidence shows that UPMLIB makes OpenMP programs immune to the page placement strategy of the operating system, thus obviating the need for introducing data placement directives in OpenMP. Furthermore, UPMlib provides solid improvements of throughput in multiprogrammed execution environments.",
            "Abstract entirety": 1,
            "Author pub id": "PkCuYUQAAAAJ:7T2F9Uy0os0C",
            "Publisher": "Springer"
        },
        {
            "Title": "Fast Analysis and Prediction in Large Scale Virtual Machines Resource Utilisation.",
            "Publication year": 2020,
            "Publication url": "https://www.researchgate.net/profile/Abdullahi-Abubakar-10/publication/340771957_Fast_Analysis_and_Prediction_in_Large_Scale_Virtual_Machines_Resource/links/5ff2e965299bf140886cdafd/Fast-Analysis-and-Prediction-in-Large-Scale-Virtual-Machines-Resource.pdf",
            "Abstract": "Most Cloud providers running Virtual Machines (VMs) have a constant goal of preventing downtime, increasing performance and power management among others. The most effective way to achieve these goals is to be proactive by predicting the behaviours of the VMs. Analysing VMs is important, as it can help cloud providers gain insights to understand the needs of their customers, predict their demands, and optimise the use of resources. To manage the resources in the cloud efficiently, and to ensure the performance of cloud services, it is crucial to predict the behaviour of VMs accurately. This will also help the cloud provider improve VM placement, scheduling, consolidation, power management, etc. In this paper, we propose a framework for fast analysis and prediction in large scale VM CPU utilisation. We use a novel approach both in terms of the algorithms employed for prediction and in terms of the tools used to run these algorithms with a large dataset to deliver a solid VM CPU utilisation predictor. We processed over two million VMs from Microsoft Azure VM traces and filter out the VMs with complete one month of data which amount to 28,858 VMs. The filtered VMs were subsequently used for prediction. Our Statistical analysis reveals that 94% of these VMs are predictable. Furthermore, we investigate the patterns and behaviours of those VMs and realised that most VMs have one or several spikes of which the majority are not seasonal. For all the 28,858 VMs analysed and forecasted, we accurately predicted 17,523 (61%) VMs based on their CPU. We use Apache Spark for parallel and distributed processing to achieve fast processing \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:LhH-TYMQEocC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Energy Efficient Computing using Computational Significance Abstractions: Keynote Talk at the UK-China Workshop on Shaping the Low Carbon Energy Future",
            "Publication year": 2016,
            "Publication url": "https://pure.qub.ac.uk/en/publications/energy-efficient-computing-using-computational-significance-abstr",
            "Abstract": "Energy Efficient Computing using Computational Significance Abstractions: Keynote Talk at the \nUK-China Workshop on Shaping the Low Carbon Energy Future \u2014 Queen's University Belfast \nSkip to main navigation Skip to search Skip to main content Queen's University Belfast Logo \nHelp & FAQ Home Profiles Organisations Research output Projects Impact Datasets Activities \nPrizes Press / Media Student theses Facilities Search by expertise, name or affiliation Energy \nEfficient Computing using Computational Significance Abstractions: Keynote Talk at the \nUK-China Workshop on Shaping the Low Carbon Energy Future Dimitrios Nikolopoulos School \nof Electronics, Electrical Engineering and Computer Science High Performance and Distributed \nComputing Institute of Electronics, Communications & Information Technology Research \noutput: Contribution to conference \u203a Other Overview Original language English status - \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:GFxP56DSvIMC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Parallel trace analysis: project deliverable D4. 3",
            "Publication year": 2017,
            "Publication url": "https://oparu.uni-ulm.de/xmlui/handle/123456789/4348",
            "Abstract": "CactoScale provides monitoring and data analysis functionality to CACTOS. This deliverable presents the framework and algorithms used by CactoScale for parallel trace analysis. We describe different CactoScale framework extensions which enable the implementation of parallel correlation analysis of system utilisation metric traces and cloud data logs. We also present the implementation of Lambda Architecture into CactoScale which parallelises several aspects of monitoring and exchanging information in CACTOS. CactoScale trace analysis tackles parallelism on various dimensions. We describe a hierarchical log analysis and anomaly detection framework. The anomaly detection utilises parallel data analysis frameworks such as Spark and mapreduce framework for parallel analysis of workload traces and system logs, coupled with HDFS for in-memory processing of the data. The trace analysis also involves the pre-processing of raw data logs for storage in HDFS. It allows executing anomaly detection algorithms hierarchically, both utilising the compute nodes in situ and the parallel HDFS monitoring facility. This is feasible by pairing the CactoScale agents with in situ analytics modules to cover the cases such as workload spike detection, but also to filter the data that flows to the database for post-processing. An in situ analytic module is a process designed to run locally in a node. This tactic provides the advantage of data locality. The data are pre-processed by the local node before being collected by a remote distributed service for further processing. In this way, the hierarchical design of data analysis allows for an additional level of real \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:WF5omc3nYNoC",
            "Publisher": "Universit\u00e4t Ulm"
        },
        {
            "Title": "A real time metabolomic profiling approach to detecting fish fraud using rapid evaporative ionisation mass spectrometry",
            "Publication year": 2017,
            "Publication url": "https://link.springer.com/article/10.1007/s11306-017-1291-y",
            "Abstract": "Fish fraud detection is mainly carried out using a genomic profiling approach requiring long and complex sample preparations and assay running times. Rapid evaporative ionisation mass spectrometry (REIMS) can circumvent these issues without sacrificing a loss in the quality of results.To demonstrate that REIMS can be used as a fast profiling technique capable of achieving accurate species identification without the need for any sample preparation. Additionally, we wanted to demonstrate that other aspects of fish fraud other than speciation are detectable using REIMS.478 samples of five different white fish species were subjected to REIMS analysis using an electrosurgical knife. Each sample was cut 8\u201312 times with each one lasting 3\u20135 s and chemometric models were generated \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:SP6oXDckpogC",
            "Publisher": "Springer US"
        },
        {
            "Title": "Scheduling asymmetric parallelism on a playstation3 cluster",
            "Publication year": 2008,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/4534213/",
            "Abstract": "Understanding the potential and implications of asymmetric multi-core processors for cluster computing is necessary, as these processors are rapidly becoming mainstream components in HPC environments. In this paper we evaluate a Linux cluster of Sony PlayStation3 consoles, using microbenchmarks and bioinformatics applications. We proceed to develop a model and scheduling techniques for effective execution of parallel applications on this low-cost, yet unconventional HPC platform based on the Cell/BE processor. We present an analytical formulation of layered parallelism for clusters of asymmetric multi-core multiprocessors and propose new co-scheduling heuristics for effectively executing MPI code with nested task and data parallelism on these systems. Our model has low execution time prediction error and is reliable in predicting optimal mappings of nested parallelism in MPI programs on the PS3 \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:M7yex6snE4oC",
            "Publisher": "IEEE"
        },
        {
            "Title": "PACMAN: A performance counters MANager for Intel hyperthreaded processors",
            "Publication year": 2006,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/1704008/",
            "Abstract": "Performance monitoring counters (PMCs) are registers within a processor which can be programmed to count the occurrences of particular processor events, such as L2 cache misses, stall cycles, etc. Due to the insight that they provide into the execution of an application on a given architecture, hardware performance counters are seeing increasing popularity in both the research and industrial communities. The difficulty stems from the sharing of the performance monitoring unit (PMU) between the two execution contexts on hyperthreaded Pentium 4 processors. Perfctr, the standard interface to Pentium 4 performance counters for Linux, overcomes this problem by disallowing the use of the second execution context on each processor when collecting events in per-thread mode. PAPI, being built on top of unaltered Perfctr, suffers from the same problems. Intel's VTune performance analyzer provides thread-local \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:i2xiXl-TujoC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Factory: An object-oriented parallel programming substrate for deep multiprocessors",
            "Publication year": 2005,
            "Publication url": "https://link.springer.com/chapter/10.1007/11557654_28",
            "Abstract": "Recent advances in processor technology such as Simultaneous Multithreading (SMT) and Chip Multiprocessing (CMP) enable parallel processing on a single die. These processors are used as building blocks of shared-memory multiprocessor systems, or clusters of multiprocessors. New programming languages and tools are necessary due to the complexities introduced by systems with multigrain, multilevel execution capabilities. This paper introduces Factory, an object-oriented parallel programming substrate which allows programmers to express multigrain parallelism, but alleviates them from having to manage it. Factory is written in C++ without introducing any extensions to the language. Because it leverages existing C++ constructs to express arbitrarily nested parallel computations, it is highly portable and does not require extra compiler support. Moreover, Factory offers programmability and \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:_FxGoFyzp5QC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "Modeling and Algorithms for Scalable and Energy Efficient Execution on Multicore Systems",
            "Publication year": 2013,
            "Publication url": "https://pure.qub.ac.uk/en/publications/modeling-and-algorithms-for-scalable-and-energy-efficient-executi",
            "Abstract": "Modeling and Algorithms for Scalable and Energy Efficient Execution on Multicore Systems \u2014 \nQueen's University Belfast Skip to main navigation Skip to search Skip to main content Queen's \nUniversity Belfast Logo Help & FAQ Home Profiles Organisations Research output Projects \nImpact Datasets Activities Prizes Press / Media Student theses Facilities Search by expertise, \nname or affiliation Modeling and Algorithms for Scalable and Energy Efficient Execution on \nMulticore Systems Dong Li, Dimitrios S. Nikolopoulos, Kirk W. Cameron School of Electronics, \nElectrical Engineering and Computer Science High Performance and Distributed Computing \nResearch output: Chapter in Book/Report/Conference proceeding \u203a Chapter (peer-reviewed) \nOverview Original language English Title of host publication Scalable Computing and \nCommunications: Theory and Practice Editors Samee U. Khan, Albert Y. Zomaya, Lizhe -157:\u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:HE397vMXCloC",
            "Publisher": "Wiley-Blackwell"
        },
        {
            "Title": "NanoStreams: Codesigned microservers for edge analytics in real time",
            "Publication year": 2016,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/7818346/",
            "Abstract": "NanoStreams explores the design, implementation, and system software stack of micro-servers aimed at processing data in-situ and in real time. These micro-servers can serve the emerging Edge computing ecosystem, namely the provisioning of advanced computational, storage, and networking capability near data sources to achieve both low latency event processing and high throughput analytical processing, before considering off-loading some of this processing to high-capacity data centres. Nano Streams explores a scale-out micro-server architecture that can achieve equivalent QoS to that of conventional rack-mounted servers for high-capacity data centres, but with dramatically reduced form factors and power consumption. To this end, Nano Streams introduces novel solutions in programmable & configurable hardware accelerators, as well as the system software stack used to access, share, and program \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:-FonjvnnhkoC",
            "Publisher": "IEEE"
        },
        {
            "Title": "A programming model and runtime system for significance-aware energy-efficient computing",
            "Publication year": 2015,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/2858788.2688546",
            "Abstract": " We introduce a task-based programming model and runtime system that exploit the observation that not all parts of a program are equally significant for the accuracy of the end-result, in order to trade off the quality of program outputs for increased energy-efficiency. This is done in a structured and flexible way, allowing for easy exploitation of different points in the quality/energy space, without adversely affecting application performance. The runtime system can apply a number of different policies to decide whether it will execute less-significant tasks accurately or approximately. The experimental evaluation indicates that our system can achieve an energy reduction of up to 83% compared with a fully accurate execution and up to 35% compared with an approximate version employing loop perforation. At the same time, our approach always results in graceful quality degradation. ",
            "Abstract entirety": 1,
            "Author pub id": "PkCuYUQAAAAJ:Fu2w8maKXqMC",
            "Publisher": "ACM"
        },
        {
            "Title": "Exploiting memory affinity in OpenMP through schedule reuse",
            "Publication year": 2001,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/563647.563657",
            "Abstract": "In this paper we explore the idea of reusing loop schedules to improve the scalability of numerical codes in shared-memory architectures with non-uniform memory access. The main objective is to implicitly construct affinity links between threads and data accesses and reuse them as much as possible along the execution of the program. These links are created through the definition and reuse of iteration schedules which are either defined statically by the user or created dynamically at run time. The paper does not include a formal proposal of OpenMP extensions but includes some experiments showing the usefulness of constructing affinity links in both regular and irregular codes.",
            "Abstract entirety": 1,
            "Author pub id": "PkCuYUQAAAAJ:uc_IGeMz5qoC",
            "Publisher": "ACM"
        },
        {
            "Title": "Experience with memory allocators for parallel mesh generation on multicore architectures",
            "Publication year": 2007,
            "Publication url": "http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.136.1305&rep=rep1&type=pdf",
            "Abstract": "Scalable and locality-aware multiprocessor memory allocators are critical for harnessing the potential of emerging multithreaded and multicore architectures. This paper evaluates two state-of-the-art generic multithreaded allocators designed for both scalability and locality, against custom allocators, written to optimize the multithreaded implementation of parallel mesh generation algorithms. We use three different algorithms in terms of communication/synchronization requirements. The implementations of all three algorithms are heavily dependent on dynamically allocated pointer-based data structures and all three use optimized internal memory allocators based on application-specific knowledge. For our study we used memory allocators which are implemented and evaluated on two real multiprocessors with a multi-SMT (quad Hyperthreaded Intel) and a multi-CMP/SMT (dual IBM Power5) organization. Our results indicate that properly engineered generic memory allocators can come close or sometimes exceed (in sequential allocation) the performance of custom multi-threaded allocators. These results suggest that in the near future we should be able to develop generic multi-threaded allocators that can adapt to application charac-",
            "Abstract entirety": 1,
            "Author pub id": "PkCuYUQAAAAJ:YohjEiUPhakC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Nanostreams: A microserver architecture for real-time analytics on fast data streams",
            "Publication year": 2017,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/8071017/",
            "Abstract": "Ever increasing power consumption has created great interest in energy-efficient microserver architectures but they lack the computational, networking, and storage power necessary to cope with real-time data analytics. We propose NanoStreams, an integrated architecture comprising an ARM-based microserver, coupled via a novel, low latency network interface, Nanowire, to an Analytics-on-Chip architecture implemented on Field Programmable Gate Array (FPGA) technology; the architecture comprises ARM cores for performing low latency transactional processing, integrated with programmable, energy efficient Nanocore processors for high-throughput streaming analytics. The paper outlines the complete system architecture, hardware level detail, compiler, network protocol, and programming environment. We present experiments from the financial services sector, comparing a state-of-the-art server based on \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:vbGhcppDl1QC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Realizing accelerated cost-effective distributed RAID",
            "Publication year": 2015,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-1-4939-2092-1_25",
            "Abstract": "The deluge of data from scientific instruments (SNS, LHC), experiments (DZero) and observations (SDSS) will soon surpass the ability of storage systems to store and retrieve data in a reliable and cost-effective manner. While the capacity, performance and the mean time to failure (MTTF) of a single disk has been improving, large-scale storage systems and parallel file systems (PFS) can comprise tens of thousands of drives, thus bringing down the overall mean time to data loss (MTTDL) of the entire system to unacceptably low levels. For example, the Lustre-based Spider PFS of the Jaguar supercomputer (No. 3 machine on the Top500 list) comprises 10,000+ disks. An exaflop machine in 2018 is projected to host hundreds of thousands of drives to support the desired I/O throughput.",
            "Abstract entirety": 1,
            "Author pub id": "PkCuYUQAAAAJ:PELIpwtuRlgC",
            "Publisher": "Springer, New York, NY"
        },
        {
            "Title": "Is data distribution necessary in OpenMP?",
            "Publication year": 2000,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/1592760/",
            "Abstract": "This paper investigates the performance implications of data placement in OpenMP programs running on modern ccNUMA multiprocessors. Data locality and minimization of the rate of remote memory accesses are critical for sustaining high performance on these systems. We show that due to the low remote-to-local memory access latency ratio of state-of-the-art ccNUMA architectures, reasonably balanced page placement schemes, such as round-robin or random distribution of pages incur modest performance losses. We also show that performance leaks stemming from suboptimal page placement schemes can be remedied with a smart user-level page migration engine. The main body of the paper describes how the OpenMP runtime environment can use page migration for implementing implicit data distribution and redistribution schemes without programmer intervention. Our experimental results support the \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:evX43VCCuoAC",
            "Publisher": "IEEE"
        },
        {
            "Title": "The Challenges and Opportunities of Micro-Servers in the HPC Ecosystem",
            "Publication year": 2014,
            "Publication url": "https://core.ac.uk/download/pdf/33581397.pdf",
            "Abstract": "5 ConclusionsD. Nikolopoulos (EEECS@ QUB) Micro-Servers in HPC, CCDSC\u201914 September 4, 2014 2/24",
            "Abstract entirety": 1,
            "Author pub id": "PkCuYUQAAAAJ:AvfA0Oy_GE0C",
            "Publisher": "Unknown"
        },
        {
            "Title": "MapReduce for the Single-Chip-Cloud Architecture",
            "Publication year": 2011,
            "Publication url": "https://tpapagian.github.io/files/acaces11.pdf",
            "Abstract": "Many-core processors, due to their complexity and diversity, will necessitate high-productivity, domain-specific approaches to parallel programming. These approaches should hide architectural details and low-level parallel programming constructs while enabling scalability and performance portability. This paper presents a scalable implementation of MapReduce, a runtime system used widely by domain-specific languages for large-scale data processing, on the Intel SCC. We address the scalability bottlenecks of MapReduce with data partitioning, combining and sorting algorithms that we customize for the SCC network on-chip architecture. We achieve linear or superlinear speedups for representative MapReduce workloads with data sets that fit on a single SCC node.",
            "Abstract entirety": 1,
            "Author pub id": "PkCuYUQAAAAJ:XvxMoLDsR5gC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Power modelling and capping for heterogeneous ARM/FPGA SoCs",
            "Publication year": 2014,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/7082782/",
            "Abstract": "Low-power processors and accelerators that were originally designed for the embedded systems market are emerging as building blocks for servers. Power capping has been actively explored as a technique to reduce the energy footprint of high-performance processors. The opportunities and limitations of power capping on the new low-power processor and accelerator ecosystem are less understood. This paper presents an efficient power capping and management infrastructure for heterogeneous SoCs based on hybrid ARM/FPGA designs. The infrastructure coordinates dynamic voltage and frequency scaling with task allocation on a customised Linux system for the Xilinx Zynq SoC. We present a compiler-assisted power model to guide voltage and frequency scaling, in conjunction with workload allocation between the ARM cores and the FPGA, under given power caps. The model achieves less than 5 \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:d1gkVwhDpl0C",
            "Publisher": "IEEE"
        },
        {
            "Title": "Feasibility of fog computing",
            "Publication year": 2020,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-030-43795-4_5",
            "Abstract": "As billions of devices get connected to the Internet, it will not be sustainable to use the cloud as a centralised server. The way forward is to decentralise computations away from the cloud towards the edge of the network closer to the user. This reduces the latency of communication between a user device and the cloud, and is the premise of \u2018fog computing\u2019. The aim of this chapter is to highlight the feasibility and the benefits in improving the Quality-of-Service by using fog computing. For an online game use-case, it was found that the average response time for a user is improved by 20% when using the edge of the network in comparison to using a cloud-only model. It was also observed that the volume of traffic between the edge and the cloud server is reduced by over 90% for the use-case. The preliminary results highlight the potential of fog computing in achieving a sustainable computing model and highlights the \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:z_wVstp3MssC",
            "Publisher": "Springer, Cham"
        },
        {
            "Title": "Rearchitecting mapreduce for heterogeneous multicore processors with explicitly managed memories",
            "Publication year": 2010,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/5599156/",
            "Abstract": "This paper presents a new design and an implementation of the runtime system of MapReduce for heterogeneous multicore processors with explicitly managed local memories. We advance the state of the art in runtime support for MapReduce using five instruments: (1) A new multi-threaded, event-driven controller for task instantiation, task scheduling, synchronization, and bulk-synchronous execution of MapReduce stages. The controller improves utilization of control efficient cores, minimizes control overhead in the runtime system, and overlaps task instantiation with task scheduling on compute-efficient cores. (2) An implicit partitioning scheme which eliminates redundant memory copies. (3) An adaptive memory management scheme which combines efficient memory preallocation for applications with statically known output volume with dynamic allocation using runahead tasks for applications with statically \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:KxtntwgDAa4C",
            "Publisher": "IEEE"
        },
        {
            "Title": "Minimization of timing failures in pipelined designs via path shaping and operand truncation",
            "Publication year": 2018,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/8474084/",
            "Abstract": "The continuous scaling of transistor sizes and the increased static and dynamic parametric variations render nanometer circuits more prone to timing failures. To protect circuits from such failures, typically designers adopt pessimistic timing margins, which are estimated statically under rare worst-case conditions. In this paper, we aim at minimizing the timing failures, while avoiding such pessimistic margins by proposing an approach that initially minimizes the number of long latency paths within each processor pipeline stage and con- straints them in as few stages as possible. Such an approach, not only reduces the timing failures, but also limits the potential error prone locations to only few pipeline registers/stages. To further reduce these failures, we exploit the path excitation dependence on data patterns and we truncate the bit-width of the operands in the few remaining long latency paths by setting a number of \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:4hFrxpcac9AC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Green building blocks-software stacks for energy-efficient clusters and data centers",
            "Publication year": 2009,
            "Publication url": "https://scholar.google.com/scholar?cluster=15405003238734804911&hl=en&oi=scholarr",
            "Abstract": "The Green Building Blocks (GBB) project is a joint effort between the Computer Architecture and VLSI Laboratory (CARV) of the Institute of Computer Science at the Foundation for Research and Technology\u2013Hellas (FORTH-ICS), and the Department of Computer Science at the Virginia Polytechnic Institute and State University (CS@ VT). GBB is a stacked assembly of device drivers, performance monitors, operating system and runtime modules, which interoperate to provide software capabilities for reducing the energy footprint of applications running on clusters and data centres, while sustaining performance near the maximum levels achievable with the hardware at hand.",
            "Abstract entirety": 1,
            "Author pub id": "PkCuYUQAAAAJ:kh2fBNsKQNwC",
            "Publisher": "Unknown"
        },
        {
            "Title": "On the use of GPUs in realizing cost-effective distributed RAID",
            "Publication year": 2012,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/6298207/",
            "Abstract": "The exponential growth in user and application data entails new means for providing fault tolerance and protection against data loss. High Performance Computing (HPC) storage systems, which are at the forefront of handling the data deluge, typically employ hardware RAID at the backend. However, such solutions are costly, do not ensure end-to-end data integrity, and can become a bottleneck during data reconstruction. In this paper, we design an innovative solution to achieve a flexible, fault-tolerant, and high-performance RAID-6 solution for a parallel file system (PFS). Our system utilizes low-cost, strategically placed GPUs - both on the client and server sides - to accelerate parity computation. In contrast to hardware-based approaches, we provide full control over the size, length and location of a RAID array on a per file basis, end-to-end data integrity checking, and parallelization of RAID array reconstruction \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:kzcrU_BdoSEC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Hyperqueues: Design and Implementation of Deterministic Concurrent Queues",
            "Publication year": 2019,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/3365660",
            "Abstract": "The hyperqueue is a programming abstraction for queues that results in deterministic and scale-free parallel programs. Hyperqueues extend the concept of Cilk++ hyperobjects to provide thread-local views on a shared data structure. While hyperobjects are organized around private local views, hyperqueues provide a shared view on a queue data structure. Hereby, hyperqueues guarantee determinism for programs using concurrent queues. We define the programming API and semantics of two instances of the hyperqueue concept. These hyperqueues differ in their API and the degree of concurrency that is extracted. We describe the implementation of the hyperqueues in a work-stealing scheduler and demonstrate scalable performance on pipeline-parallel benchmarks from PARSEC and StreamIt.",
            "Abstract entirety": 1,
            "Author pub id": "PkCuYUQAAAAJ:fPk4N6BV_jEC",
            "Publisher": "ACM"
        },
        {
            "Title": "Scaling non-regular shared-memory codes by reusing custom loop schedules.",
            "Publication year": 2003,
            "Publication url": "https://www.academia.edu/download/40500703/Scaling_Non-Regular_Shared-Memory_Codes_20151130-32690-ms9i77.pdf",
            "Abstract": "In this paper we explore the idea of customizing and reusing loop schedules to improve the scalability of non-regular numerical codes in shared\u2013memory architectures with non\u2013uniform memory access latency. The main objective is to implicitly setup affinity links between threads and data, by devising loop schedules that achieve balanced work distribution within irregular data spaces and reusing them as much as possible along the execution of the program for better memory access locality. This transformation provides a great deal of flexibility in optimizing locality, without compromising the simplicity of the shared-memory programming paradigm. In particular, the programmer does not need to explicitly distribute data between processors. The paper presents practical examples from real applications and experiments showing the efficiency of the approach.",
            "Abstract entirety": 1,
            "Author pub id": "PkCuYUQAAAAJ:3htObqc8RwsC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Tapas: Train-less accuracy predictor for architecture search",
            "Publication year": 2019,
            "Publication url": "https://ojs.aaai.org/index.php/AAAI/article/view/4282",
            "Abstract": "In recent years an increasing number of researchers and practitioners have been suggesting algorithms for large-scale neural network architecture search: genetic algorithms, reinforcement learning, learning curve extrapolation, and accuracy predictors. None of them, however, demonstrated highperformance without training new experiments in the presence of unseen datasets. We propose a new deep neural network accuracy predictor, that estimates in fractions of a second classification performance for unseen input datasets, without training. In contrast to previously proposed approaches, our prediction is not only calibrated on the topological network information, but also on the characterization of the dataset-difficulty which allows us to re-tune the prediction without any training. Our predictor achieves a performance which exceeds 100 networks per second on a single GPU, thus creating the opportunity to perform large-scale architecture search within a few minutes. We present results of two searches performed in 400 seconds on a single GPU. Our best discovered networks reach 93.67% accuracy for CIFAR-10 and 81.01% for CIFAR-100, verified by training. These networks are performance competitive with other automatically discovered state-of-the-art networks however we only needed a small fraction of the time to solution and computational resources.",
            "Abstract entirety": 1,
            "Author pub id": "PkCuYUQAAAAJ:OP4eGU-M3BUC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Brief Announcement: Energy Optimization of Memory Intensive Parallel Workloads",
            "Publication year": 2016,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/2935764.2935811",
            "Abstract": "Energy consumption is an important concern in modern multicore processors. The energy consumed during the execution of an application can be minimized by tuning the hardware state utilizing knobs such as frequency, voltage etc. The existing theoretical work on energy minimization using Global DVFS (Dynamic Voltage and Frequency Scaling), despite being thorough, ignores the energy consumed by the CPU on memory accesses and the dynamic energy consumed by the idle cores. This article presents an analytical energy-performance model for parallel workloads that accounts for the energy consumed by the CPU chip on memory accesses in addition to the energy consumed on CPU instructions. In addition, the model we present also accounts for the dynamic energy consumed by the idle cores. We present an analytical framework around our energy-performance model to predict the operating \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:uLbwQdceFCQC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Programming and Managing Resources on Accelerator-Enabled Clusters",
            "Publication year": 2017,
            "Publication url": "https://books.google.com/books?hl=en&lr=&id=z3vJDQAAQBAJ&oi=fnd&pg=PA407&dq=info:giIUkC3qZbIJ:scholar.google.com&ots=_Mp9D2ixw7&sig=nmvQWnM34FOoHuLcoasFm2nXMUo",
            "Abstract": "Computational accelerators are positive catalysts for high-end computing systems. Heterogeneous parallel architectures that integrate general-purpose processors with computational accelerators are rapidly being established on emerging systems as the sine qua non for high performance, energy efficiency and reliability. Acceleration through heterogeneity has been realized in several asymmetric multicore processors, where a fixed transistor budget is distributed between many simple, specialized tightly coupled cores and few complex, general-purpose cores. The specialized cores provide custom features that enable acceleration of computational kernels operating on vector data. These cores are controlled by the relatively few general-purpose cores, which run system services and manage off-chip communication. In addition to heterogeneous processors, it is now common for processor vendors to deliver teraflop-capable, single-chip multiprocessors by integrating many simple cores with single-instruction multiple data (SIMD) or single-instruction multiple threads",
            "Abstract entirety": 1,
            "Author pub id": "PkCuYUQAAAAJ:epqYDVWIO7EC",
            "Publisher": "John Wiley & Sons"
        },
        {
            "Title": "Topic 9-Parallel Programming: Models, Methods and Languages-Smt-SPRINTS: Software Precomputation with Intelligent Streaming for Resource-Constrained SMTs",
            "Publication year": 2005,
            "Publication url": "https://scholar.google.com/scholar?cluster=15136311078685732539&hl=en&oi=scholarr",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "PkCuYUQAAAAJ:ClCfbGk0d_YC",
            "Publisher": "Berlin: Springer-Verlag, 1973-"
        },
        {
            "Title": "Vt-asos: Holistic system software customization for many cores",
            "Publication year": 2008,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/4536390/",
            "Abstract": "VT-ASOS is a framework for holistic and continuous customization of system software on HPC systems. The framework leverages paravirtualization technology. VT-ASOS extends the Xen hypervisor with interfaces, mechanisms, and policies for supporting application-specific resource management schemes on many-core systems, while retaining the advantages of virtualization, including protection, performance isolation, and fault tolerance. We outline the VT-ASOS framework and present results from a preliminary prototype, which enables static customization of scheduler parameters and runtime adaptation of parallel virtual machines.",
            "Abstract entirety": 1,
            "Author pub id": "PkCuYUQAAAAJ:K3LRdlH-MEoC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Runtime support for memory adaptation in scientific applications via local disk and remote memory",
            "Publication year": 2006,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/1652149/",
            "Abstract": "The ever increasing memory demands of many scientific applications and the complexity of today's shared computational resources still require the occasional use of virtual memory, network memory, or even out-of-core implementations, with well known drawbacks in performance and usability. In this paper, we present a general framework, based on our earlier MML B prototype, that enables fully customizable, memory malleability in a wide variety of scientific applications. We provide several necessary enhancements to the environment sensing capabilities of MMLIB and introduce a remote memory capability, based on MPI communication of cached memory blocks between `compute nodes' and designated memory servers. We show experimental results from three important scientific applications that require the general MML B framework. Under constant memory pressure, we observe execution time \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:43bX7VzcjpAC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Graphgrind: Addressing load imbalance of graph partitioning",
            "Publication year": 2017,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/3079079.3079097",
            "Abstract": "We investigate how graph partitioning adversely affects the performance of graph analytics. We demonstrate that graph partitioning induces extra work during graph traversal and that graph partitions have markedly different connectivity than the original graph. By consequence, increasing the number of partitions reaches a tipping point after which overheads quickly dominate performance gains. Moreover, we show that the heuristic to balance CPU load between graph partitions by balancing the number of edges is inappropriate for a range of graph analyses. However, even when it is appropriate, it is sub-optimal due to the skewed degree distribution of social networks. Based on these observations, we propose GraphGrind, a new graph analytics system that addresses the limitations incurred by graph partitioning. We moreover propose a NUMA-aware extension to the Cilk programming language and obtain a \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:t6usbXjVLHcC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Evaluating asymmetric multicore systems-on-chip and the cost of fault tolerance using iso-metrics",
            "Publication year": 2015,
            "Publication url": "https://scholar.google.com/scholar?cluster=6527486706631614754&hl=en&oi=scholarr",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "PkCuYUQAAAAJ:kVjdVfd2voEC",
            "Publisher": "Unknown"
        },
        {
            "Title": "TwinPCG: Dual thread redundancy with forward recovery for preconditioned conjugate gradient methods",
            "Publication year": 2016,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/7776551/",
            "Abstract": "Even though iterative solvers like the Preconditioned Conjugate Gradient method (PCG) have been studied for over fifty years, fault tolerance for such solvers has seen much attention in recent years. For iterative solvers, two major reliable strategies of recovery exist: checkpoint-restart for backward recovery, or some type of redundancy technique for forward recovery. Efficient low-overhead redundancy techniques like algorithm-based fault tolerance for sparse matrix-vector products (SpMxV) have recently been proposed. These techniques add resilience with a good, but limited scope; state-of-the-art techniques correct at most 1 fault within a SpMxV. In this work, we study a more powerful resilience concept, which is redundant multithreading. It offers more generic and stronger recovery guarantees, including any soft faults in PCG iterations (among others covering SpMxV), but also requires more resources. We \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:Se3iqnhoufwC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Application-level energy awareness for openmp",
            "Publication year": 2015,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-319-24595-9_16",
            "Abstract": "Power, and consequently energy, has recently attained first-class system resource status, on par with conventional metrics such as CPU time. To reduce energy consumption, many hardware- and OS-level solutions have been investigated. However, application-level information - which can provide the system with valuable insights unattainable otherwise - was only considered in a handful of cases. We introduce OpenMPE, an extension to OpenMP designed for power management. OpenMP is the de-facto standard for programming parallel shared memory systems, but does not yet provide any support for power control. Our extension exposes (i) per-region multi-objective optimization hints and (ii) application-level adaptation parameters, in order to create energy-saving opportunities for the whole system stack. We have implemented OpenMPE support in a compiler and runtime system, and empirically \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:sSrBHYA8nusC",
            "Publisher": "Springer, Cham"
        },
        {
            "Title": "NanoStreams: A Hardware and Software Stack for Real-Time Analytics on Fast Data Streams",
            "Publication year": 2014,
            "Publication url": "https://pure.qub.ac.uk/en/publications/nanostreams-a-hardware-and-software-stack-for-real-time-analytics",
            "Abstract": "NanoStreams: A Hardware and Software Stack for Real-Time Analytics on Fast Data \nStreams \u2014 Queen's University Belfast Skip to main navigation Skip to search Skip to main \ncontent Queen's University Belfast Logo Help & FAQ Home Profiles Organisations \nResearch output Projects Impact Datasets Activities Prizes Press / Media Student theses \nFacilities Search by expertise, name or affiliation NanoStreams: A Hardware and Software \nStack for Real-Time Analytics on Fast Data Streams Dimitrios Nikolopoulos School of \nElectronics, Electrical Engineering and Computer Science High Performance and \nDistributed Computing Research output: Contribution to specialist publication \u203a Article \nOverview Original language English Volume 38 Specialist publication HiPEAC Info \nPublisher European Network of Excellence on High Performance and Embedded \nArchitectures and Compilation Publication status Published - Apr to ://'\u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:u-x6o8ySG0sC",
            "Publisher": "Unknown"
        },
        {
            "Title": "A case for user-level dynamic page migration",
            "Publication year": 2000,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/335231.335243",
            "Abstract": "This paper presents user-level dynamic page migration, a runtime technique which transparently enables parallel programs to tune their memory performance on distributed shared memory multiprocessors, with feedback obtained from dynamic monitoring of memory activity. Our technique exploits the iterative nature of parallel programs and information available to the program both at compile time and at runtime in order to improve the accuracy and the timeliness of page migrations, as well as amortize better the overhead, compared to page migration engines implemented in the operating system. We present an adaptive page migration algorithm based on a competitive and a predictive criterion. The competitive criterion is used to correct poor page placement decisions of the operating system, while the predictive criterion makes the algorithm responsive to scheduling events that necessitate immediate page \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:S16KYo8Pm5AC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Fine-grain OpenMP runtime support with explicit communication hardware primitives",
            "Publication year": 2011,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/5763299/",
            "Abstract": "We present a runtime system that uses the explicit on-chip communication mechanisms of the SARC multi-core architecture, to implement efficiently the OpenMP programming model and enable the exploitation of fine-grain parallelism in OpenMP programs. We explore the design space of implementation of OpenMP directives and runtime intrinsics, using a family of hardware primitives; remote stores, remote DMAs, hardware counters and hardware event queues with automatic responses, to support static and dynamic scheduling and data transfers in local memories. Using an FPGA prototype with four cores, we achieve OpenMP task creation latencies of 30-35 processor clock cycles, initiation of parallel contexts in 50 cycles and synchronization primitives in 65-210 cycles.",
            "Abstract entirety": 1,
            "Author pub id": "PkCuYUQAAAAJ:dfsIfKJdRG4C",
            "Publisher": "IEEE"
        },
        {
            "Title": "Energy efficiency through significance-based computing",
            "Publication year": 2014,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/6861903/",
            "Abstract": "An extension of approximate computing, significance-based computing exploits applications' inherent error resiliency and offers a new structural paradigm that strategically relaxes full computational precision to provide significant energy savings with minimal performance degradation.",
            "Abstract entirety": 1,
            "Author pub id": "PkCuYUQAAAAJ:olpn-zPbct0C",
            "Publisher": "IEEE"
        },
        {
            "Title": "DYVERSE: dynamic vertical scaling in multi-tenant edge environments",
            "Publication year": 2020,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S0167739X19312403",
            "Abstract": "Multi-tenancy in resource-constrained environments is a key challenge in Edge computing. In this paper, we develop \u2018DYVERSE: DYnamic VERtical Scaling in Edge\u2019 environments, which is the first light-weight and dynamic vertical scaling mechanism for managing resources allocated to applications for facilitating multi-tenancy in Edge environments. To enable dynamic vertical scaling, one static and three dynamic priority management approaches that are workload-aware, community-aware and system-aware, respectively are proposed. This research advocates that dynamic vertical scaling and priority management approaches reduce Service Level Objective (SLO) violation rates. An online-game and a face detection workload in a Cloud-Edge test-bed are used to validate the research. The merit of DYVERSE is that there is only a sub-second overhead per Edge server when 32 Edge servers are deployed on a \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:zA6iFVUQeVQC",
            "Publisher": "North-Holland"
        },
        {
            "Title": "A comparison of online and offline strategies for program adaptation",
            "Publication year": 2007,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/1233341.1233371",
            "Abstract": "Multithreaded programs executing on modern high-end computing systems have many potential avenues to adapt their execution to improve performance, energy consumption, or both. Program adaptation occurs anytime multiple execution modes are available to the application and one is selected based on information collected during program execution. As a result, some degree of online or offline analysis is required to come to a decision of how best to adapt and there are a variety of tradeoffs to consider when deciding which form of analysis to use, as the overheads they carry with them can vary widely in degree as well as type, as can their effectiveness.",
            "Abstract entirety": 1,
            "Author pub id": "PkCuYUQAAAAJ:8k81kl-MbHgC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Scaling irregular parallel codes with minimal programming effort",
            "Publication year": 2001,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/1592781/",
            "Abstract": "The long foreseen goal of parallel programming models is to scale parallel code without significant programming effort. Irregular parallel applications are a particularly challenging application domain for parallel programming models, since they require domain specific data distribution and load balancing algorithms. From a performance perspective, shared-memory models still fall short of scaling as well as message-passing models in irregular applications, although they require less coding effort. We present a simple runtime methodology for scaling irregular applications parallelized with the standard OpenMP interface. We claim that our parallelization methodology requires the minimum amount of effort from the programmer and prove experimentally that it is able to scale two highly irregular codes as well as MPI, with an order of magnitude less programming effort. This is probably the first time such a result is \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:VL0QpB8kHFEC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Epc: a power instrumentation controller for embedded applications",
            "Publication year": 2012,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/2318836.2318841",
            "Abstract": "In this work we propose and implement a real-time power monitor controller based on a simple 8-bit AVR controller and an analog Hall effect current sensor. Our setup imposes negligible degradation in the power efficiency, performance and the response time of the instrumented system. Those characteristics make it ideal for portable and battery critical applications. The use of an external controller enables the implementation of a function set for automated power measurement and energy accounting. In order to validate the correctness and the quality of our implementation we have used our setup to instrument a Linux Single Board Computer (SBC) based on an ARM micro-controller. During this instrumentation we have run various CPU and I/O intensive workloads that incur fast phase transitions.",
            "Abstract entirety": 1,
            "Author pub id": "PkCuYUQAAAAJ:ZeXyd9-uunAC",
            "Publisher": "ACM"
        },
        {
            "Title": "DARE: Data-Access Aware Refresh via spatial-temporal application resilience on commodity servers",
            "Publication year": 2018,
            "Publication url": "https://journals.sagepub.com/doi/abs/10.1177/1094342017718612",
            "Abstract": "Power consumption and reliability of memory components are two of the most important hurdles in realizing exascale systems. Dynamic random access memory (DRAM) scaling projections predict significant performance and power penalty due to the conventional use of pessimistic refresh periods catering for worst-case cell retention times. Recent approaches relax those pessimistic refresh rates only on ``strong'' cells, or build on application-specific error resilience for data placement. However, these approaches cannot reveal the full potential of a relaxed refresh paradigm shift, since they neglect additional application resilience properties related to the inherent functioning of DRAM. In this article, we elevate Refresh-by-Access as a first-class property of application resilience. We develop a complete, non-intrusive system stack, armed with low-cost Data-Access Aware Refresh (DARE) methods, to facilitate \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:XD-gHx7UXLsC",
            "Publisher": "SAGE Publications"
        },
        {
            "Title": "Scheduling dynamic parallelism on accelerators",
            "Publication year": 2009,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/1531743.1531769",
            "Abstract": "Resource management on accelerator based systems is complicated by the disjoint nature of the main CPU and accelerator, which involves separate memory hierarhcies, different degrees of parallelism, and relatively high cost of communicating between them. For applications with irregul parallelism, where work is dynamically created based on other computations, the accelerators may both consume and produce work. To maintain load balance, the accelerators hand work back to the CPU to be scheduled. In this paper we consider multiple approaches for such scheduling problems and use the Cell BE system to demonstrate the different schedulers and the trade-offs between them. Our evaluation is done with both microbenchmarks and two bioinformatics applications (PBPI and RAxML). Our baseline approach uses a standard Linux scheduler on the CPU, possibly with more than one process per CPU. We then \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:HtS1dXgVpQUC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Connecting the Dots between Parallel Programming and Energy",
            "Publication year": 2013,
            "Publication url": "https://pureadmin.qub.ac.uk/ws/files/11115853/pdp13_keynote_dsn.pdf",
            "Abstract": "Connecting the Dots between Parallel Programming and Energy Page 1 Connecting the \nDots between Parallel Programming and Energy Nikolopoulos, D. (2013). Connecting the \nDots between Parallel Programming and Energy. Abstract from PDP 2013 - The 21st \nEuromicro International Conference on Parallel, Distributed and Network-Based Computing, \nBelfast, United Kingdom. http://paraphrase-ict.eu/events/pdp-2013-the-21st-euromicro-international-conferenceon-parallel-distributed-and-network-based-computing \nQueen's University Belfast - Research Portal: Link to publication record in Queen's \nUniversity Belfast Research Portal Publisher rights \u00a9 2013 The Authors General rights \nCopyright for the publications made accessible via the Queen's University Belfast Research \nPortal is retained by the author(s) and / or other copyright owners and it is a condition of \naccessing these publications that users recognise by \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:BwyfMAYsbu0C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Tagged Procedure Calls (TPC): Efficient Runtime Support for Task-Based Parallelism on the Cell Processor",
            "Publication year": 2010,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-642-11515-8_23",
            "Abstract": "Increasing the number of cores in modern CPUs is the main trend for improving system performance. A central challenge is the runtime support that multi-core systems ought to use for sustaining high performance and scalability without increasing disproportionally the effort required by the programmer. In this work we present Tagged Procedure Calls (TPC), a runtime system for supporting task-based programming models on architectures that require explicit data access specification by the programmer. We present the design and implementation of TPC for the Cell processor and examine how the runtime system can support task management functions with on-chip communication only. Through minimizing off-chip transactions in the runtime, we achieve sub-microsecond task initiation latency and minimum null task initiation/completion latency of 385 ns. We evaluate TPC with several kernels and \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:Mojj43d5GZwC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "A taxonomy of task-based technologies for high-performance computing",
            "Publication year": 2017,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-319-78054-2_25",
            "Abstract": "Task-based programming models for shared memory \u2013 such as Cilk Plus and OpenMP 3 \u2013 are well established and documented. However, with the increase in heterogeneous, many-core and parallel systems, a number of research-driven projects have developed more diversified task-based support, employing various programming and runtime features. Unfortunately, despite the fact that dozens of different task-based systems exist today and are actively used for parallel and high-performance computing, no comprehensive overview or classification of task-based technologies for HPC exists.In this paper, we provide an initial task-focused taxonomy for HPC technologies, which covers both programming interfaces and runtime mechanisms. We demonstrate the usefulness of our taxonomy by classifying state-of-the-art task-based environments in use today.",
            "Abstract entirety": 1,
            "Author pub id": "PkCuYUQAAAAJ:XiVPGOgt02cC",
            "Publisher": "Springer, Cham"
        },
        {
            "Title": "A taxonomy of task-based parallel programming technologies for high-performance computing",
            "Publication year": 2018,
            "Publication url": "https://link.springer.com/article/10.1007/s11227-018-2238-4?platform=hootsuite",
            "Abstract": "Task-based programming models for shared memory\u2014such as Cilk Plus and OpenMP 3\u2014are well established and documented. However, with the increase in parallel, many-core, and heterogeneous systems, a number of research-driven projects have developed more diversified task-based support, employing various programming and runtime features. Unfortunately, despite the fact that dozens of different task-based systems exist today and are actively used for parallel and high-performance computing (HPC), no comprehensive overview or classification of task-based technologies for HPC exists. In this paper, we provide an initial task-focused taxonomy for HPC technologies, which covers both programming interfaces and runtime mechanisms. We demonstrate the usefulness of our taxonomy by classifying state-of-the-art task-based environments in use today.",
            "Abstract entirety": 1,
            "Author pub id": "PkCuYUQAAAAJ:maZDTaKrznsC",
            "Publisher": "Springer US"
        },
        {
            "Title": "Scaling Non-regular Shared-memory Codes by Reusing Custom Loop Schedules",
            "Publication year": 2003,
            "Publication url": "https://scholar.google.com/scholar?cluster=9616686775859679942&hl=en&oi=scholarr",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "PkCuYUQAAAAJ:dTyEYWd-f8wC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Realistic workload scheduling policies for taming the memory bandwidth bottleneck of smps",
            "Publication year": 2004,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-540-30474-6_33",
            "Abstract": "In this paper we reformulate the thread scheduling problem on multiprogrammed SMPs. Scheduling algorithms usually attempt to maximize performance of memory intensive applications by optimally exploiting the cache hierarchy. We present experimental results indicating that \u2013 contrary to the common belief \u2013 the extent of performance loss of memory-intensive, multiprogrammed workloads is disproportionate to the deterioration of cache performance caused by interference between threads. In previous work [1] we found that memory bandwidth saturation is often the actual bottleneck that determines the performance of multiprogrammed workloads. Therefore, we present and evaluate two realistic scheduling policies which treat memory bandwidth as a first-class resource. Their design methodology is general enough and can be applied to introduce bus bandwidth-awareness to conventional scheduling \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:W7OEmFMy1HYC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "Programming and Managing Resources on Accelerator\u2010Enabled Clusters",
            "Publication year": 2017,
            "Publication url": "https://onlinelibrary.wiley.com/doi/abs/10.1002/9781119332015.ch20",
            "Abstract": "This chapter explores system design alternatives for clusters with computational accelerators and capability\u2010aware task scheduling strategies for large\u2010scale data processing on accelerator\u2010enabled clusters. It presents an implementation and adaptation of the MapReduce programming model for asymmetric clusters. The asymmetry of resources on accelerator\u2010enabled clusters introduces imbalances in resource management and provisioning. Addressing those imbalances, while hiding the associated complexity from users, is key to achieving high performance and high productivity. While the potential of many\u2010core accelerators to catalyze high\u2010performance computing (HPC) systems and data centers is clear, attempting to integrate accelerators seamlessly in large\u2010scale computing installations raises challenges, with respect to resource management and programmability. Accelerators provide much \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:8xutWZnSdmoC",
            "Publisher": "John Wiley & Sons, Inc."
        },
        {
            "Title": "Workload-aware dram error prediction using machine learning",
            "Publication year": 2019,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/9041963/",
            "Abstract": "The aggressive scaling of technology may have helped to meet the growing demand for higher memory capacity and density, but has also made DRAM cells more prone to errors. Such a reality triggered a lot of interest in modeling DRAM behavior for either predicting the errors in advance or for adjusting DRAM circuit parameters to achieve a better tradeoff between energy efficiency and reliability. Existing modeling efforts may have studied the impact of few operating parameters and temperature on DRAM reliability using custom FPGAs setups, however they neglected the combined effect of workload-specific features that can be systematically investigated only on a real system. In this paper, we present the results of our study on workload-dependent DRAM error behavior within a real server considering various operating parameters, such as the refresh rate, voltage and temperature. We show that the rate of single \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:oNZyr7d5Mn4C",
            "Publisher": "IEEE"
        },
        {
            "Title": "On the design of online predictors for autonomic power-performance adaptation of multithreaded programs",
            "Publication year": 2006,
            "Publication url": "http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.118.5968&rep=rep1&type=pdf",
            "Abstract": "This paper investigates the design space for techniques that enable runtime, autonomic program adaptation for high-performance and low-power execution via event-driven performance prediction. The emerging multithreaded and multicore processor architectures enable applications to trade performance for reduced power consumption via regulating concurrency. At the same time however, power and performance adaptation opportunities for multithreaded programs in high-end computing environments are constrained by the fact that users are unwilling to compromise performance for saving power. Runtime systems that enable autonomous program adaptation are an appealing solution in the specific context, due to the challenges that arise in statically identifying the optimal energy-efficient operating points in each program, and the concerns of delegating the complexity of this task to end-users or application developers. System software needs to identify and exploit the power saving opportunities that arise due to the inability of code to effectively utilize all the available resources in the system, or the inability of the system to overcome scalability bottlenecks in parallel code. The techniques investigated in this paper fall into a broader class of methods that collect information about the performance of programs on-the-fly, as a program executes, and adapt the program in situ, after briefly analyzing the collected information. On-line performance predictors are well suited for rapid adaptation with limited input. They also overcome the limitations of techniques based on direct search of operating points. We explore the design of fast online \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:ML0RJ9NH7IQC",
            "Publisher": "Unknown"
        },
        {
            "Title": "BDDT-SCC: A Task-parallel Runtime for Non Cache-Coherent Multicores",
            "Publication year": 2016,
            "Publication url": "https://arxiv.org/abs/1606.04288",
            "Abstract": "This paper presents BDDT-SCC, a task-parallel runtime system for non cache-coherent multicore processors, implemented for the Intel Single-Chip Cloud Computer. The BDDT-SCC runtime includes a dynamic dependence analysis and automatic synchronization, and executes OpenMP-Ss tasks on a non cache-coherent architecture. We design a runtime that uses fast on-chip inter-core communication with small messages. At the same time, we use non coherent shared memory to avoid large core-to-core data transfers that would incur a high volume of unnecessary copying. We evaluate BDDT-SCC on a set of representative benchmarks, in terms of task granularity, locality, and communication. We find that memory locality and allocation plays a very important role in performance, as the architecture of the SCC memory controllers can create strong contention effects. We suggest patterns that improve memory locality and thus the performance of applications, and measure their impact.",
            "Abstract entirety": 1,
            "Author pub id": "PkCuYUQAAAAJ:YFjsv_pBGBYC",
            "Publisher": "Unknown"
        },
        {
            "Title": "On the virtualization of CUDA based GPU remoting on ARM and X86 machines in the GVirtuS framework",
            "Publication year": 2017,
            "Publication url": "https://link.springer.com/article/10.1007/s10766-016-0462-1",
            "Abstract": "The astonishing development of diverse and different hardware platforms is twofold: on one side, the challenge for the exascale performance for big data processing and management; on the other side, the mobile and embedded devices for data collection and human machine interaction. This drove to a highly hierarchical evolution of programming models. GVirtuS is the general virtualization system developed in 2009 and firstly introduced in 2010 enabling a completely transparent layer among GPUs and VMs. This paper shows the latest achievements and developments of GVirtuS, now supporting CUDA 6.5, memory management and scheduling. Thanks to the new and improved remoting capabilities, GVirtus now enables GPU sharing among physical and virtual machines based on x86 and ARM CPUs on local workstations, computing clusters and distributed cloud appliances.",
            "Abstract entirety": 1,
            "Author pub id": "PkCuYUQAAAAJ:abG-DnoFyZgC",
            "Publisher": "Springer US"
        },
        {
            "Title": "HpMC: An energy-aware management system of multi-level memory architectures",
            "Publication year": 2015,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/2818950.2818974",
            "Abstract": "DRAM technology faces density and power challenges to increase capacity because of limitations of physical cell design. To overcome these limitations, system designers are exploring alternative solutions that combine DRAM and emerging NVRAM technologies. Previous work on heterogeneous memories focuses, mainly, on two system designs: PCache, a hierarchical, inclusive memory system, and HRank, a flat, non-inclusive memory system. We demonstrate that neither of these designs can universally achieve high performance and energy efficiency across a suite of HPC workloads. In this work, we investigate the impact of a number of multi-level memory designs on the performance, power, and energy consumption of applications. To achieve this goal and overcome the limited number of available tools to study heterogeneous memories, we created HMsim, an infrastructure that enables n-level \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:FAceZFleit8C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Myrmics: Scalable, dependency-aware task scheduling on heterogeneous manycores",
            "Publication year": 2016,
            "Publication url": "https://arxiv.org/abs/1606.04282",
            "Abstract": "Task-based programming models have become very popular, as they offer an attractive solution to parallelize serial application code with task and data annotations. They usually depend on a runtime system that schedules the tasks to multiple cores in parallel while resolving any data hazards. However, existing runtime system implementations are not ready to scale well on emerging manycore processors, as they often rely on centralized structures and/or locks on shared structures in a cache-coherent memory. We propose design choices, policies and mechanisms to enhance runtime system scalability for single-chip processors with hundreds of cores. Based on these concepts, we create and evaluate Myrmics, a runtime system for a dependency-aware, task-based programming model on a heterogeneous hardware prototype platform that emulates a single-chip processor of 8 latency-optimized and 512 throughput-optimized CPUs. We find that Myrmics scales successfully to hundreds of cores. Compared to MPI versions of the same benchmarks with hand-tuned message passing, Myrmics achieves similar scalability with a 10-30% performance overhead, but with less programming effort. We analyze the scalability of the runtime system in detail and identify the key factors that contribute to it.",
            "Abstract entirety": 1,
            "Author pub id": "PkCuYUQAAAAJ:ZzlSgRqYykMC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Power and energy implications of the number of threads used on the intel xeon phi",
            "Publication year": 2015,
            "Publication url": "https://dialnet.unirioja.es/servlet/articulo?codigo=5307554",
            "Abstract": "Energy consumption has become an important area of research of late. With the advent of new manycore processors, situations have arisen where not all the processors need to be active to reach an optimal relation between performance and energy usage. In this paper, a study of the power and energy usage of a series of benchmarks, the PARSEC and the SPLASH-2X Benchmark Suites, on the Intel Xeon Phi for different threads configurations, is presented. To carry out this study, a tool was designed to monitor and record the power usage in real time during execution time and afterwards to compare the results of executions with different number of parallel threads.",
            "Abstract entirety": 1,
            "Author pub id": "PkCuYUQAAAAJ:M3ejUd6NZC8C",
            "Publisher": "Universidad de Granada"
        },
        {
            "Title": "UPMLIB: A runtime system for tuning the memory performance of openmp programs on scalable shared-memory multiprocessors",
            "Publication year": 2000,
            "Publication url": "https://link.springer.com/chapter/10.1007/3-540-40889-4_7",
            "Abstract": "We present the design and implementation of UPMLIB, a runtime system that provides transparent facilities for dynamically tuning the memory performance of OpenMP programs on scalable shared-memory multiprocessors with hardware cache-coherence. UPMLIB integrates information from the com- piler and the operating system, to implement algorithms that perform accurate and timely page migrations. The algorithms and the associated mechanisms cor- relate memory reference information with the semantics of parallel programs and scheduling events that break the association between threads and data for which threads have memory affinity at runtime. Our experimental evidence shows that UPMLIB makes OpenMP programs immune to the page placement strategy of the operating system, thus obviating the need for introducing data placement directives in OpenMP. Furthermore, UPMlib provides \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:_5tno0g5mFcC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "Set-top supercomputing: scalable software for scientific simulations on game consoles",
            "Publication year": 2008,
            "Publication url": "https://scholar.google.com/scholar?cluster=3169403824715077827&hl=en&oi=scholarr",
            "Abstract": "Exponential improvements in the performance of computer systems have brought supercomputing to the desks of users. A modern processor has the equivalent computing capacity of a massively parallel computer system from the last decade. The history of Top500, the list of the 500 most powerful computing systems on the planet, indicates that our 2008 laptops would have ranked in the Top500 most powerful computer systems ten to fifteen years ago.KS methods and preconditioners will be implemented on the parallel computer available at Dublin City University, and we propose a series of comparative stability, efficiency and scalability analyses of the parallel solver versus its serial version. The entire simulation process is illustrated in Figure 1.",
            "Abstract entirety": 1,
            "Author pub id": "PkCuYUQAAAAJ:qUcmZB5y_30C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Synthesizing Parallel Programming Models for Asymmetric Multi-core Systems",
            "Publication year": 2007,
            "Publication url": "https://www.eecis.udel.edu/~cavazos/cisc879-spring2008/papers/HPEC07.pdf",
            "Abstract": "Asymmetric multi-core processors integrating conventional with customized accelerator cores, have exhibited the potential to provide unprecedented performance for dataintensive applications. Although significant effort has been invested in parallel programming models that exploit a single form of parallelism, programming models that synthesize polymorphic parallelism and runtime systems that exploit multiple dimensions of concurrency and heterogeneity in parallel execution are rare. As a consequence, software developers lack both the programming abstractions and the methodologies for synthesizing programming models for polymorphic parallelism. This deficit may render software unable to exploit asymmetric multi-core processors, since polymorphic parallelism is essential to balance the supply of computation from conventional cores with the demand from accelerators [1]. Our research on runtime performance modeling and scheduling of dynamic polymorphic parallelism on the Cell Broadband Engine [1, 2, 3], derives a methodology for synthesizing polymorphic programming models for explicitly parallel programs on-the-fly. The proposed methodology off-loads the tasks of mapping algorithmic parallelism to the architecture and adapting parallel execution to the available resources from the programmer to the runtime environment. In addition to mapping and adaptation, the runtime environment performs a synthesis of execution, communication and synchronization schemes to balance parallel execution across the cores and the interconnection network of the processor. The runtime system leverages two complementary system software \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:O3NaXMp0MMsC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Recent Advances in the Message Passing Interface: 18th European MPI Users\u2019 Group Meeting, EuroMPI 2011, Santorini, Greece, September 18-21, 2011. Proceedings",
            "Publication year": 2011,
            "Publication url": "https://books.google.com/books?hl=en&lr=&id=I8FtaaxBjdkC&oi=fnd&pg=PR2&dq=info:3lNWqSzu8fQJ:scholar.google.com&ots=bdx4lCcNxk&sig=NYo8o1kASC-8tcj4bYWeGg3faX4",
            "Abstract": "This book constitutes the refereed proceedings of the 18th European MPI Users' Group Meeting on Recent Advances in the Message Passing Interface, EuroMPI 2011, held in Santorini, Greece, in September 2011. The 28 revised full papers presented together with 10 posters were carefully reviewed and selected from 66 submissions. Topics covered are communication; I/O; networking, and implementation issues and improvements; algorithms and tools; interaction with hardware; applications and performance evaluation; fault and tolerance.",
            "Abstract entirety": 1,
            "Author pub id": "PkCuYUQAAAAJ:wMgC3FpKEyYC",
            "Publisher": "Springer Science & Business Media"
        },
        {
            "Title": "On the energy-efficiency of byte-addressable non-volatile memory",
            "Publication year": 2014,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/6893025/",
            "Abstract": "Non-volatile memory (NVM) technology holds promise to replace SRAM and DRAM at various levels of the memory hierarchy. The interest in NVM is motivated by the difficulty faced in scaling DRAM beyond 22 nm and, long-term, lower cost per bit. While offering higher density and negligible static power (leakage and refresh), NVM suffers increased latency and energy per memory access. This paper develops energy and performance models of memory systems and applies them to understand the energy-efficiency of replacing or complementing DRAM with NVM. Our analysis focusses on the application of NVM in main memory. We demonstrate that NVM such as STT-RAM and RRAM is energy-efficient for memory sizes commonly employed in servers and high-end workstations, but PCM is not. Furthermore, the model is well suited to quickly evaluate the impact of changes to the model parameters, which may be \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:D03iK_w7-QYC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Cache-integrated network interfaces: Flexible on-chip communication and synchronization for large-scale CMPs",
            "Publication year": 2012,
            "Publication url": "https://link.springer.com/article/10.1007/s10766-011-0173-6",
            "Abstract": "Per-core scratchpad memories (or local stores) allow direct inter-core communication, with latency and energy advantages over coherent cache-based communication, especially as CMP architectures become more distributed. We have designed cache-integrated network interfaces, appropriate for scalable multicores, that combine the best of two worlds \u2013 the flexibility of caches and the efficiency of scratchpad memories: on-chip SRAM is configurably shared among caching, scratchpad, and virtualized network interface (NI) functions. This paper presents our architecture, which provides local and remote scratchpad access, to either individual words or multiword blocks through RDMA copy. Furthermore, we introduce event responses, as a technique that enables software configurable communication and synchronization primitives. We present three event response mechanisms that expose NI functionality to \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:HtEfBTGE9r8C",
            "Publisher": "Springer US"
        },
        {
            "Title": "Harmony: Heterogeneous-reliability memory and qos-aware energy management on virtualized servers",
            "Publication year": 2020,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/3373376.3378489",
            "Abstract": "The explosive growth of data increases the storage needs, especially within servers, making DRAM responsible for more than 40% of the total system power. Such a reality has made researchers focus on energy saving schemes that relax the pessimistic DRAM circuit parameters at the cost of potential faults. In an effort to limit the resultant risk of critical data disruption, new methods were introduced that split DRAM into domains with varying reliability and power. The benefits of such schemes may have been showcased on simulators but have neither been implemented on real systems with a complete software stack, nor have been combined with any energy-reliability OS management policies. In this paper, we are the first to implement and evaluate HaRMony, a heterogeneous-reliability memory framework, in conjunction with QoS-aware energy management policies on a server with a complete virtualization stack \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:-f6ydRqryjwC",
            "Publisher": "Unknown"
        },
        {
            "Title": "The architectural and operating system implications on the performance of synchronization on ccNUMA multiprocessors",
            "Publication year": 2001,
            "Publication url": "https://link.springer.com/article/10.1023/A:1011168003859",
            "Abstract": "This paper investigates the performance of synchronization algorithms on ccNUMA multiprocessors, from the perspectives of the architecture and the operating system. In contrast with previous related studies that emphasized the relative performance of synchronization algorithms, this paper takes a new approach by analyzing the sources of synchronization latency on ccNUMA architectures and how can this latency be reduced by leveraging hardware and software schemes in both dedicated and multiprogrammed execution environments. From the architectural perspective, the paper identifies the implications of directory-based cache coherence on the latency and scalability of synchronization instructions and examines if and how can simple hardware that accelerates these instructions be leveraged to reduce synchronization latency. From the operating system's perspective, the paper evaluates in a \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:IUKN3-7HHlwC",
            "Publisher": "Kluwer Academic Publishers-Plenum Publishers"
        },
        {
            "Title": "Code and Data Transformations to Address Garbage Collector Performance in Big Data Processing",
            "Publication year": 2018,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/8638146/",
            "Abstract": "Java, with its dynamic runtime environment and garbage collected GC memory management, is a very popular choice for big data processing engines. Its runtime provides convenient mechanisms to implement workload distribution without having to worry about direct memory allocation and deallocation. However, efficient memory usage is a recurring issue. In particular, our evaluation shows that garbage collection has huge drawbacks when handling a large number of data objects and more than 60% of execution time can be consumed by garbage collection. We present a set of unconventional strategies to counter this issue that rely on data layout transformations to drastically reduce the number of objects, and on changing the code structure to reduce the lifetime of objects. We encapsulate the implementation in Apache Spark making it transparent for software developers. Our preliminary results show an \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:TIZ-Mc8IlK0C",
            "Publisher": "IEEE"
        },
        {
            "Title": "Explicit communication and synchronization in SARC",
            "Publication year": 2010,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/5567092/",
            "Abstract": "A new network interface optimized for SARC supports synchronization and explicit communication and provides a robust mechanism for event responses. Full-system simulation of the authors' design achieved a 10- to 40-percent speed increase over traditional cache architectures on 64 cores, a two- to four-fold decrease in on-chip network traffic, and a three- to five-fold decrease in lock and barrier latency.",
            "Abstract entirety": 1,
            "Author pub id": "PkCuYUQAAAAJ:xtRiw3GOFMkC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Power Modelling for Heterogeneous Cloud-Edge Data Centers",
            "Publication year": 2017,
            "Publication url": "https://arxiv.org/abs/1710.10325",
            "Abstract": "Existing power modelling research focuses not on the method used for developing models but rather on the model itself. This paper aims to develop a method for deploying power models on emerging processors that will be used, for example, in cloud-edge data centers. Our research first develops a hardware counter selection method that appropriately selects counters most correlated to power on ARM and Intel processors. Then, we propose a two stage power model that works across multiple architectures. The key results are: (i) the automated hardware performance counter selection method achieves comparable selection to the manual selection methods reported in literature, and (ii) the two stage power model can predict dynamic power more accurately on both ARM and Intel processors when compared to classic power models.",
            "Abstract entirety": 1,
            "Author pub id": "PkCuYUQAAAAJ:70eg2SAEIzsC",
            "Publisher": "Unknown"
        },
        {
            "Title": "The transprecision computing paradigm: Concept, design, and applications",
            "Publication year": 2018,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/8342176/",
            "Abstract": "Guaranteed numerical precision of each elementary step in a complex computation has been the mainstay of traditional computing systems for many years. This era, fueled by Moore's law and the constant exponential improvement in computing efficiency, is at its twilight: from tiny nodes of the Internet-of-Things, to large HPC computing centers, sub-picoJoule/operation energy efficiency is essential for practical realizations. To overcome the power wall, a shift from traditional computing paradigms is now mandatory. In this paper we present the driving motivations, roadmap, and expected impact of the European project OPRECOMP. OPRECOMP aims to (i) develop the first complete transprecision computing framework, (ii) apply it to a wide range of hardware platforms, from the sub-milliWatt up to the MegaWatt range, and (iii) demonstrate impact in a wide range of computational domains, spanning IoT, Big Data \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:IjCSPb-OGe4C",
            "Publisher": "IEEE"
        },
        {
            "Title": "Dynamic tiling for effective use of shared caches on multithreaded processors",
            "Publication year": 2004,
            "Publication url": "https://www.inderscienceonline.com/doi/abs/10.1504/IJHPCN.2004.009265",
            "Abstract": "Simultaneous multithreaded (SMT) processors use data caches which are dynamically shared between threads. Depending on the processor workload, sharing the data cache may harm performance due to excessive cache conflicts. A way to overcome this problem is to physically partition the cache between threads. Unfortunately, partitioning the cache requires additional hardware and may lead to lower utilisation of the cache in certain workloads. It is therefore important to consider software mechanisms to implicitly partition the cache between threads by controlling the locations in the cache in which each thread can load data. This paper proposes standard program transformations for partitioning the shared data caches of SMT processors, if and only if there are conflicts between threads in the shared cache at runtime. We propose transformations based on dynamic tiling. The key idea is to use two tile sizes in \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:ILKRHgRFtOwC",
            "Publisher": "Inderscience Publishers"
        },
        {
            "Title": "Reliability-Aware System Software Support on ARM Microservers.",
            "Publication year": 2017,
            "Publication url": "https://pure.qub.ac.uk/en/publications/reliability-aware-system-software-support-on-arm-microservers",
            "Abstract": "Reliability-Aware System Software Support on ARM Microservers. \u2014 Queen's University \nBelfast Skip to main navigation Skip to search Skip to main content Queen's University \nBelfast Logo Help & FAQ Home Profiles Organisations Research output Projects Impact \nDatasets Activities Prizes Press / Media Student theses Facilities Search by expertise, name \nor affiliation Reliability-Aware System Software Support on ARM Microservers. \nAntonopoulos, C., S. Lallis, N. Bellas, D. Gizopoulos, and P. Lawthers , Georgios \nKarakonstantis, Dimitrios Nikolopoulos School of Electronics, Electrical Engineering and \nComputer Science Research output: Contribution to conference \u203a Abstract \u203a peer-review \nOverview Original language English Pages 1 Publication status Published - 2017 Event \nARM Research Summit - Cambridge, United Kingdom Duration: 11 Sep 2017 \u2192 13 Sep \n2017 https://developer.arm.com/research/summit ARM //'\u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:PoWvk5oyLR8C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Parallel Programming",
            "Publication year": 2013,
            "Publication url": "https://pure.qub.ac.uk/en/publications/parallel-programming",
            "Abstract": "Recent trends in computing systems, such as multi-core processors and cloud computing, expose tens to thousands of processors to the software. Software developers must respond by introducing parallelism in their software. To obtain highest performance, it is not only necessary to identify parallelism, but also to reason about synchronization between threads and the communication of data from one thread to another. This entry gives an overview on some of the most common abstractions that are used in parallel programming, namely explicit vs. implicit expression of parallelism and shared and distributed memory. Several parallel programming models are reviewed and categorized by means of these abstractions. The pros and cons of parallel programming models from the perspective of performance and programmability are discussed.",
            "Abstract entirety": 1,
            "Author pub id": "PkCuYUQAAAAJ:BqipwSGYUEgC",
            "Publisher": "Taylor and Francis"
        },
        {
            "Title": "Dynamic Program Stirring on Multiple Cores: How Hardware Performance Monitors Can Help Regulate Performance, Power, and Temperature Simultaneously",
            "Publication year": 2006,
            "Publication url": "https://www.academia.edu/download/30916856/FHPM06.pdf",
            "Abstract": "The utility of hardware performance monitors stems from the insight they provide into the interaction between software and hardware. It is this interaction that determines many interesting properties of an application\u2019s execution. Among these properties, of primary interest to our research are the IPC, as it determines the performance of an application; the instantaneous power consumption; and the temperature of various processor resources. In particular, we are interested in how these properties scale with the number, configuration, and frequency scale of execution cores on multicore platforms. Previous work has shown the potential for accurate prediction of power [3], performance and scalability on multiple cores [2], and temperature [1] using HPMs. We have focused on making predictions of the performance of a parallel application on a varying number of processors, processors cores, and core-level hardware threads. We exploit the iterative nature of parallel programs by recording event counts during an initial iteration of each program phase on a specific hardware configuration. We then make predictions by multiplying the event counts by coefficients that have been derived offline using regression. Two hurdles to accurate prediction are finding an effective performance model and selecting the correct sets of events. We have found effective solutions to these issues that allow for prediction accuracy approaching 90%. Our method of performance prediction allows an application to have access to predictions early at runtime, so an application can adapt itself to use the optimal configuration for the remainder of execution. Adapting to use fewer \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:M05iB0D1s5AC",
            "Publisher": "Unknown"
        },
        {
            "Title": "TwinCG: Dual Thread Redundancy with Forward Recovery for Conjugate Gradient Methods",
            "Publication year": 2016,
            "Publication url": "https://arxiv.org/abs/1605.04580",
            "Abstract": "Even though iterative solvers like the Conjugate Gradients method (CG) have been studied for over fifty years, fault tolerance for such solvers has seen much attention in recent years. For iterative solvers, two major reliable strategies of recovery exist: checkpoint-restart for backward recovery, or some type of redundancy technique for forward recovery. Important redundancy techniques like ABFT techniques for sparse matrix-vector products (SpMxV) have recently been proposed, which increase the resilience of CG methods. These techniques offer limited recovery options, and introduce a tolerable overhead. In this work, we study a more powerful resilience concept, which is redundant multithreading. It offers more generic and stronger recovery guarantees, including any soft faults in CG iterations (among others covering ABFT SpMxV), but also requires more resources. We carefully study this redundancy/efficiency conflict. We propose a fault tolerant CG method, called TwinCG, which introduces minimal wallclock time overhead, and significant advantages in detection and correction strategies. Our method uses Dual Modular Redundancy instead of the more expensive Triple Modular Redundancy; still, it retains the TMR advantages of fault correction. We describe, implement, and benchmark our iterative solver, and compare it in terms of efficiency and fault tolerance capabilities to state-of-the-art techniques. We find that before parallelization, TwinCG introduces around 5-6% runtime overhead compared to standard CG, and after parallelization efficiently uses BLAS. In the presence of faults, it reliably performs forward recovery for a range of \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:5nxA0vEk-isC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Refine: Realistic fault injection via compiler-based instrumentation for accuracy, portability and speed",
            "Publication year": 2017,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/3126908.3126972",
            "Abstract": "Compiler-based fault injection (FI) has become a popular technique for resilience studies to understand the impact of soft errors in supercomputing systems. Compiler-based FI frameworks inject faults at a high intermediate-representation level. However, they are less accurate than machine code, binary-level FI because they lack access to all dynamic instructions, thus they fail to mimic certain fault manifestations. In this paper, we study the limitations of current practices in compiler-based FI and how they impact the interpretation of results in resilience studies.",
            "Abstract entirety": 1,
            "Author pub id": "PkCuYUQAAAAJ:-_dYPAW6P2MC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Towards automated data-driven model creation for cloud computing simulation.",
            "Publication year": 2015,
            "Publication url": "https://pureadmin.qub.ac.uk/ws/portalfiles/portal/16422326/SIMUTOOLS_2015_FINAL3.pdf",
            "Abstract": "The increasing complexity and scale of cloud computing environments due to widespread data centre heterogeneity makes measurement-based evaluations highly difficult to achieve. Therefore the use of simulation tools to support decision making in cloud computing environments to cope with this problem is an increasing trend. However the data required in order to model cloud computing environments with an appropriate degree of accuracy is typically large, very difficult to collect without some form of automation, often not available in a suitable format and a time consuming process if done manually. In this research, an automated method for cloud computing topology definition, data collection and model creation activities is presented, within the context of a suite of tools that have been developed and integrated to support these activities.",
            "Abstract entirety": 1,
            "Author pub id": "PkCuYUQAAAAJ:tYavs44e6CUC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Software-managed energy-efficient hybrid DRAM/NVM main memory",
            "Publication year": 2015,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/2742854.2742886",
            "Abstract": "This paper evaluates the viability of user-level software management of a hybrid DRAM/NVM main memory system. We propose an operating system (OS) and programming interface to place data from within the user application. We present a profiling tool to help programmers decide on the placement of application data in hybrid memory systems. Cycle-accurate simulation of modified applications confirms that our approach is more energy-efficient than state-of-the-art hardware or OS approaches at equivalent performance. Moreover, our results are validated on several candidate NVM technologies and a wide set of 14 benchmarks.",
            "Abstract entirety": 1,
            "Author pub id": "PkCuYUQAAAAJ:KbBQZpvPDL4C",
            "Publisher": "Unknown"
        },
        {
            "Title": "A Runtime Framework for Optimizing Multi-Dimensional Array Accesses on Multi-core Processors",
            "Publication year": 2009,
            "Publication url": "https://www.researchgate.net/profile/Jae-Seung_Yeom/publication/228693301_A_Runtime_Framework_for_Optimizing_Multi-Dimensional_Array_Accesses_on_Multi-core_Processors/links/0912f5108708477f3f000000.pdf",
            "Abstract": "Scientific and numerical applications rely on multidimensional array data accessed in nested loops. These regular data access patterns can benefit from explicitly managed local memories, such as the local stores of the Cell processor. We present Strider, a runtime library framework which helps programming and optimization of multi-dimensional data accesses in nested loops, on multi-core processors with explicitly managed memory hierarchies. Strider automatically schedules strided data accesses based on a high-level description of loops and arrays provided by programmers. We present the design and implementation of Strider on Cell, followed by a preliminary performance evaluation of the framework. Our evaluation illustrates that Strider outperforms by significant margins existing parallel programming environments for multi-core processors with explicitly managed memory hierarchies.",
            "Abstract entirety": 1,
            "Author pub id": "PkCuYUQAAAAJ:Zph67rFs4hoC",
            "Publisher": "September"
        },
        {
            "Title": "A Tool to Schedule Parallel Applications on Multiprocessors: The NANOS CPU Manager",
            "Publication year": 2000,
            "Publication url": "https://link.springer.com/chapter/10.1007/3-540-39997-6_7",
            "Abstract": "Scheduling parallel applications on shared\u2013 memory multiprocessors is a di.cult task that requires a lot of tuning from application programmers, as well as operating system developers and system managers. In this paper, we present the characteristics related to kernel\u2013 level scheduling of the NANOS environment and the results we are achieving. The NANOS environment is designed and tuned speci.cally to achieve high performance in current shared\u2013 memory multiprocessors. Taking advantage of the wide and e.cient dialog established between applications and the NANOS environment, we are designing powerful scheduling policies. The information exchanged ranges from simply communicating the number of requested processors to providing information of the current speedup achieved by the applications. We have devised several scheduling policies that use this interface, such as Equipartition \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:kNdYIx-mwKoC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "Supporting I/O-Intensive Workloads on the Cell Architecture",
            "Publication year": 2008,
            "Publication url": "https://www.usenix.org/events/fast08/wips_posters/rafique-poster.pdf",
            "Abstract": "Recent advent of the asymmetric multi-core processors such as Cell Broadband Engine (Cell/BE) has popularized the use of heterogeneous architectures in High-End Computing. Data and I/O intensive workloads have largely been ignored in this domain. We take the first steps in supporting I/O intensive workloads on Cell and deriving some guidelines for optimizing the execution of I/O workloads on heterogeneous architectures. We explore various performance enhancing techniques for such workloads on an actual Cell/BE system. Among the techniques we explore, an asynchronous prefetching-based approach, which uses the PowerPC core of the Cell/BE for file prefetching and decentralized DMAs from the synergistic processing cores (SPE\u2019s), improves the performance for I/O workloads that include an encryption/decryption component by 30.2%, compared to I/O performed na\u0131vely from the SPE\u2019s.",
            "Abstract entirety": 1,
            "Author pub id": "PkCuYUQAAAAJ:g5m5HwL7SMYC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Computer Science researchers explore virtualization potential for high-end computing",
            "Publication year": 2007,
            "Publication url": "https://vtechworks.lib.vt.edu/handle/10919/59014",
            "Abstract": "Dimitrios Nikolopoulos, associate professor of computer science, and Godmar Back, assistant professor of computer science, both at Virginia Tech, have received a National Science Foundation (NSF) - Computer Science Research (CSR) grant of $300,000 for their Virtualization Technologies for Application-Specific Operating Systems (VT ASOS) project.",
            "Abstract entirety": 1,
            "Author pub id": "PkCuYUQAAAAJ:gKiMpY-AVTkC",
            "Publisher": "Virginia Tech. University Relations"
        },
        {
            "Title": "Topic 16: GPU and Accelerators Computing",
            "Publication year": 2012,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-642-32820-6_84",
            "Abstract": "Accelerator-based computing systems invest significant fractions of hardware real estate to execute critical computation with vastly higher efficiency than general-purpose CPUs. Amdahl\u2019s Law of the Multi-core Era suggests that such an heterogeneous approach to parallel computing is bound to deliver better scalability and power-efficiency than homogeneous system scaling. While General Purpose Graphics Processing Units (GPGPUs) have catalyzed research in this area, new ideas emerge to help us model, deconstruct and analyze the performance of accelerators, develop new standards for programming accelerators at a high level of abstraction, and port end-to-end applications on accelerator-based systems. Topic 16 provides a forum to discuss advances in all aspects of GPUand accelerator-based computing.",
            "Abstract entirety": 1,
            "Author pub id": "PkCuYUQAAAAJ:DUooU5lO8OsC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "Fast dynamic binary rewriting for flexible thread migration on shared-isa heterogeneous mpsocs",
            "Publication year": 2014,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/6893207/",
            "Abstract": "Heterogeneous MPSoCs where different types of cores share a baseline ISA but implement different operational accelerators combine programmability with flexible customization. They hold promise for high performance under power and area limitations. However, transparent binary execution and dynamic scheduling is hard on those platforms. The stateof-the-art approach for transparent accelerated execution is fault-and-migrate (FAM): when a thread executes an accelerating instruction unavailable on the host core, it is forcibly migrated to an accelerating core which implements the instruction natively. Unfortunately, this approach prohibits dynamic scheduling through flexible thread migration, which is essential to any asymmetric platform for efficient utilization of heterogeneous resources. We present two distinct binary-level techniques - Dynamic Binary Rewriting (DBR) and Dynamic Binary Translation (DBT \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:hMsQuOkrut0C",
            "Publisher": "IEEE"
        },
        {
            "Title": "AIR: Iterative refinement acceleration using arbitrary dynamic precision",
            "Publication year": 2020,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S0167819120300569",
            "Abstract": "The increased degree of concurrent operations by lower precision arithmetic enables high performance for iterative refinement. Most of related work present statically defined mixed precision arithmetic approaches, while adapting a level of arithmetic precision dynamically in a loop with one-bit granularity can further improve the performance. This paper presents Arbitrary Dynamic Precision Iterative Refinement algorithm (AIR) that minimizes the total significand bit-width to solve iterative refinement. AIR detects the number of cancellation bits dynamically per iteration and uses the information to provide the least sufficient significand bit-width for the next iteration. We prove that AIR is a backward stable algorithm and can bring up to 2\u2212 3\u00d7 speedups over a mixed precision iterative refinement depending on the characteristics of hardware. Our software demonstration shows that AIR requires only 83% of the significand \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:ufrVoPGSRksC",
            "Publisher": "North-Holland"
        },
        {
            "Title": "C Source Level Transformations & Optimizations for Task-Based Parallelism: Student Poster Session, 2011 International Symposium on Code Generation and Optimization (CGO)",
            "Publication year": 2011,
            "Publication url": "https://pure.qub.ac.uk/en/publications/c-source-level-transformations-amp-optimizations-for-task-based-p",
            "Abstract": "C Source Level Transformations & Optimizations for Task-Based Parallelism: Student Poster \nSession, 2011 International Symposium on Code Generation and Optimization (CGO) \u2014 \nQueen's University Belfast Skip to main navigation Skip to search Skip to main content Queen's \nUniversity Belfast Logo Help & FAQ Home Profiles Organisations Research output Projects \nImpact Datasets Activities Prizes Press / Media Student theses Facilities Search by expertise, \nname or affiliation C Source Level Transformations & Optimizations for Task-Based Parallelism: \nStudent Poster Session, 2011 International Symposium on Code Generation and Optimization \n(CGO) F. Zakkak, D. Chassapis, P. Pratikakis, Dimitrios Nikolopoulos, A. Bilas School of \nElectronics, Electrical Engineering and Computer Science Research output: Contribution to \nconference \u203a Poster \u203a peer-review Overview Original language English Number of pages 1 - , \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:WZBGuue-350C",
            "Publisher": "Unknown"
        },
        {
            "Title": "VEBO: a vertex-and edge-balanced ordering heuristic to load balance parallel graph processing",
            "Publication year": 2019,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/3293883.3295703",
            "Abstract": "This work proposes Vertex-and Edge-Balanced Ordering (VEBO): balance the number of edges and the number of unique destinations of those edges. VEBO balances edges and vertices for graphs with a power-law degree distribution, and ensures an equal degree distribution between partitions. Experimental evaluation on three shared-memory graph processing systems (Ligra, Polymer and GraphGrind) shows that VEBO achieves excellent load balance and improves performance by 1.09\u00d7 over Ligra, 1.41\u00d7 over Polymer and 1.65\u00d7 over GraphGrind, compared to their respective partitioning algorithms, averaged across 8 algorithms and 7 graphs. VEBO improves GraphGrind performance with a speedup of 2.9\u00d7 over Ligra on average.",
            "Abstract entirety": 1,
            "Author pub id": "PkCuYUQAAAAJ:GnPB-g6toBAC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Sustainable Computing: Informatics and Systems",
            "Publication year": 2014,
            "Publication url": "https://scholar.google.com/scholar?cluster=6401905670502560795&hl=en&oi=scholarr",
            "Abstract": "Article history: Received 19 April 2013",
            "Abstract entirety": 1,
            "Author pub id": "PkCuYUQAAAAJ:bFI3QPDXJZMC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Heterogeneous servers based on programmable cores and dataflow engines",
            "Publication year": 2017,
            "Publication url": "https://pure.qub.ac.uk/files/123397592/HiPEAC_ESCEC_2016.pdf",
            "Abstract": "The continuous growth of the internet, and the data volumes associated to it, put severe pressure on the computational, storage and networking resources available in today\u2019s data-centers. The stringent power budgets and the difficult expansion of current Internet communication infrastructures necessitates the design of new server architectures, programming models and run-time systems. In this paper, we present promising options in the design of energy-efficient servers based on programmable accelerators which can help push the limits on the computation of future data centers. We show that one of the proposed micro-server prototypes based on custom tiny cores can achieve 40% better energyefficiency than a standard Xeon Server, while dataflow engines can help speedup execution by up to 374x for various workloads.",
            "Abstract entirety": 1,
            "Author pub id": "PkCuYUQAAAAJ:OU6Ihb5iCvQC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Strider: Runtime support for optimizing strided data accesses on multi-cores with explicitly managed memories",
            "Publication year": 2010,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/5644876/",
            "Abstract": "Multi-core processors with explicitly-managed local memories provide advanced capabilities to optimize data caching and prefetching in software. Unfortunately, these capabilities are neither easily accessible to programmers, nor exploited to their maximum potential by current language, compiler, or runtime frameworks. We present Strider, a runtime framework for optimizing compilers on multi-core processors with software- managed memories. Strider transparently optimizes grouping, decomposition, and scheduling of explicit software-managed accesses to multi-dimensional arrays in nested loops, given a high- level specification of loops and their data access patterns. In particular, Strider contributes new methods to improve temporal locality, optimize the critical path of scheduling data transfers for multi-stride accesses in regular nested parallel loops, and distribute accesses between cores. The prototype of \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:LkGwnXOMwfcC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Incremental training of deep convolutional neural networks",
            "Publication year": 2018,
            "Publication url": "https://arxiv.org/abs/1803.10232",
            "Abstract": "We propose an incremental training method that partitions the original network into sub-networks, which are then gradually incorporated in the running network during the training process. To allow for a smooth dynamic growth of the network, we introduce a look-ahead initialization that outperforms the random initialization. We demonstrate that our incremental approach reaches the reference network baseline accuracy. Additionally, it allows to identify smaller partitions of the original state-of-the-art network, that deliver the same final accuracy, by using only a fraction of the global number of parameters. This allows for a potential speedup of the training time of several factors. We report training results on CIFAR-10 for ResNet and VGGNet.",
            "Abstract entirety": 1,
            "Author pub id": "PkCuYUQAAAAJ:r_AWSJRzSzQC",
            "Publisher": "Unknown"
        },
        {
            "Title": "A scalable and composable map-reduce system",
            "Publication year": 2016,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/7840854/",
            "Abstract": "This paper presents a novel map-reduce runtime system that is designed for scalability and for composition with other parallel software. We use a modified programming interface that expresses reduction operations over data containers as opposed to key-value pairs. This design choice admits higher efficiency as the programmer can select appropriate data structures. Our runtime targets shared memory systems, which are increasingly capable of performing data analytics on terabyte-sized data sets stored in-memory. Our map-reduce runtime is built over the Cilk programming language and outperforms Phoenix++, by 1.5x-4x for 5 out of 7 map-reduce benchmarks on 48 threads. These results arise from a combination of factors: (i) the reduction of framework overheads, including the elimination of repeated (de-)serialization of key-value pairs; (ii) the use of more appropriate intermediate data structures that \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:hCrLmN-GePgC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Adaptive scheduling under memory pressure on multiprogrammed clusters",
            "Publication year": 2002,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/1540437/",
            "Abstract": "This paper presents scheduling techniques that enable the adaptation of parallel programs to clustered computational farms with limited memory capacity. The purpose of the techniques is to coschedule communicating processes and prevent paging, using two cooperating extensions to the kernel scheduler. A paging prevention module enables memory-bound programs to adapt to memory short-age, by suspending their threads at well-defined execution points. The associated operating system interface provides a generic mechanism that enables programs to adapt in different ways, including application-specific forms of adaptation. At the same time, a dynamic coscheduling heuristic implemented in the kernel scheduler increases periodically the priority of communicating processes so that parallel jobs are eased through communication points. We show that when a parallel job competes with randomized \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:4DMP91E08xMC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Adapting to memory pressure from within scientific applications on multiprogrammed COWs",
            "Publication year": 2004,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/1303002/",
            "Abstract": "Summary form only given. Dismal performance often results when the memory requirements of a process exceed the physical memory available to it. Moreover, significant throughput reduction is experienced when this process is part of a synchronous parallel job on a nondedicated computational cluster. A possible solution is to develop programs that can dynamically adapt their memory usage according to the current availability of physical memory. We explore this idea on scientific computations that perform repetitive data accesses. Part of the program's data set is cached in resident memory, while the remainder that cannot fit is accessed in an \"out-of-core\" fashion from disk. The replacement policy can be user defined. This allows for a graceful degradation of performance as memory becomes scarce. To dynamically adjust its memory usage, the program must reliably answer whether there is a memory shortage \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:u_35RYKgDlwC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Edge-as-a-service: Towards distributed cloud architectures",
            "Publication year": 2017,
            "Publication url": "https://arxiv.org/abs/1710.10090",
            "Abstract": "We present an Edge-as-a-Service (EaaS) platform for realising distributed cloud architectures and integrating the edge of the network in the computing ecosystem. The EaaS platform is underpinned by (i) a lightweight discovery protocol that identifies edge nodes and make them publicly accessible in a computing environment, and (ii) a scalable resource provisioning mechanism for offloading workloads from the cloud on to the edge for servicing multiple user requests. We validate the feasibility of EaaS on an online game use-case to highlight the improvement in the QoS of the application hosted on our cloud-edge platform. On this platform we demonstrate (i) low overheads of less than 6%, (ii) reduced data traffic to the cloud by up to 95% and (iii) minimised application latency between 40%-60%.",
            "Abstract entirety": 1,
            "Author pub id": "PkCuYUQAAAAJ:mVmsd5A6BfQC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Userspace Hypervisor Data Characterization in Virtualized Environment",
            "Publication year": 2018,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/8644612/",
            "Abstract": "Memory-intensive applications have grown rapidly in order to adapt to the changing needs of businesses. Memory errors become even more concerning, since configuration at extended operating points makes hardware more susceptible to system failures. Some data structures may be more sensitive to errors and may cause system crashes more easily than others. A failure in a critical data structure can cause a complete system crash. In this paper, we propose a sensitivity characterization to the hypervisor structures. First, we implement an error-injection framework using Syscall ptrace. We profile both static and dynamic data structures through our framework. Then we provide the detailed analysis and data characterization to QEMU hypervisor. Finally, we discuss the checkpointing and selective mechanism in case the QEMU hypervisor crash.",
            "Abstract entirety": 1,
            "Author pub id": "PkCuYUQAAAAJ:1qzjygNMrQYC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Energy Efficiency in ARMv8-based Microservers by Hardware Margins Identification.",
            "Publication year": 2017,
            "Publication url": "https://pure.qub.ac.uk/en/publications/energy-efficiency-in-armv8-based-microservers-by-hardware-margins",
            "Abstract": "Energy Efficiency in ARMv8-based Microservers by Hardware Margins Identification. \u2014 Queen's \nUniversity Belfast Skip to main navigation Skip to search Skip to main content Queen's University \nBelfast Logo Help & FAQ Home Profiles Organisations Research output Projects Impact \nDatasets Activities Prizes Press / Media Student theses Facilities Search by expertise, name or \naffiliation Energy Efficiency in ARMv8-based Microservers by Hardware Margins Identification. \nD. Gizopoulos, Y. Sazeides, S. Das, P. Lawthers , Georgios Karakonstantis, Dimitrios \nNikolopoulos School of Electronics, Electrical Engineering and Computer Science Research \noutput: Contribution to conference \u203a Abstract \u203a peer-review Overview Original language English \nNumber of pages 1 Publication status Published - 2017 Event 2017 ARM Research Summit \n- Cambridge, United Kingdom Duration: 01 Sep 2017 \u2192 \u2026 Conference Conference 01//.\u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:2KloaMYe4IUC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Processors: The Challenge of Cooperation",
            "Publication year": 2009,
            "Publication url": "https://pure.qub.ac.uk/en/publications/processors-the-challenge-of-cooperation",
            "Abstract": "Processors: The Challenge of Cooperation \u2014 Queen's University Belfast Skip to main navigation \nSkip to search Skip to main content Queen's University Belfast Logo Help & FAQ Home Profiles \nOrganisations Research output Projects Impact Datasets Activities Prizes Press / Media \nStudent theses Facilities Search by expertise, name or affiliation Processors: The Challenge \nof Cooperation Manolis GH Katevenis, Dimitrios Nikolopoulos School of Electronics, Electrical \nEngineering and Computer Science Research output: Contribution to specialist publication \u203a \nArticle Overview Original language English Pages 26-28 Number of pages 3 Volume 71 \nSpecialist publication Economist Special Edition Publisher The Economist Newspaper Ltd. \nPublication status Published - Dec 2009 Bibliographical note Pagination / Size: 71, 26-28 Cite \nthis APA Author BIBTEX Harvard Standard RIS Vancouver Katevenis, MGH, & , D. (2009). : \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:L8Ckcad2t8MC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Designing effective memory allocators for multicore and multithreaded systems: A case study with irregular and adaptive applications",
            "Publication year": 2006,
            "Publication url": "https://scholar.google.com/scholar?cluster=5087320507273178293&hl=en&oi=scholarr",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "PkCuYUQAAAAJ:gVv57TyPmFsC",
            "Publisher": "Unknown"
        },
        {
            "Title": "COMPUTER SCIENCE RESEARCH MELISSES: Liquid Services for Scalable Multithreaded and Multicore Execution on Emerging Supercomputers",
            "Publication year": 2008,
            "Publication url": "https://www.osti.gov/servlets/purl/956344",
            "Abstract": "In this final report, we summarize the contributions made through support from the DOE ECPI award to research and training in advanced computing systems.",
            "Abstract entirety": 1,
            "Author pub id": "PkCuYUQAAAAJ:ns9cj8rnVeAC",
            "Publisher": "VIRGINIA POLYTECHNIC INSTITUTE AND STATE UNIVERSITY"
        },
        {
            "Title": "HPTA: A Library for High-Performance Text Analytics",
            "Publication year": 2016,
            "Publication url": "https://pure.qub.ac.uk/files/120164388/preprint.pdf",
            "Abstract": "One of the main targets of data analytics is unstructured data, which primarily involves textual data. High-performance processing of textual data is non-trivial. We present the HPTA library for high-performance text analytics. The library helps programmers to map textual data to a dense numeric representation, which can be handled more efficiently. HPTA encapsulates three performance optimizations:(i) efficient memory management for textual data,(ii) parallel computation on associative data structures that map text to values and (iii) optimization of the type of associative data structure depending on the program context. We demonstrate that HPTA outperforms popular frameworks for text analytics such as scikit-learn and Spark.",
            "Abstract entirety": 1,
            "Author pub id": "PkCuYUQAAAAJ:LjlpjdlvIbIC",
            "Publisher": "Unknown"
        },
        {
            "Title": "The trade-off between implicit and explicit data distribution in shared-memory programming paradigms",
            "Publication year": 2001,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/377792.377801",
            "Abstract": "This paper explores previously established and novel methods for scaling the performance of OpenMP on NUMA architectures. The spectrum of methods under investigation includes OS-level automatic page placement algorithms, dynamic page migrationd manual data distribution. The trade-off that these methods face lies between performance and programming effort. Automatic page placement algorithms are transparent to the programmer, but may compromise memory access locality. Dynamic page migration is also transparent, but requires careful engineering of online algorithms to be effective. Manual data distribution on the other requires substantial programming effort and architecture-specific extensions to OpenMP, but may localize memory accesses in a nearly optimal manner.",
            "Abstract entirety": 1,
            "Author pub id": "PkCuYUQAAAAJ:qjMakFHDy7sC",
            "Publisher": "Unknown"
        },
        {
            "Title": "LS-ADT: Lightweight and Scalable Anomaly Detection for Cloud Datacentres",
            "Publication year": 2015,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-319-29582-4_8",
            "Abstract": "Cloud data centres are implemented as large-scale clusters with demanding requirements for service performance, availability and cost of operation. As a result of scale and complexity, data centres typically exhibit large numbers of system anomalies resulting from operator error, resource over/under provisioning, hardware or software failures and security issus anomalies are inherently difficult to identify and resolve promptly via human inspection. Therefore, it is vital in a cloud system to have automatic system monitoring that detects potential anomalies and identifies their source. In this paper we present a lightweight anomaly detection tool for Cloud data centres which combines extended log analysis and rigorous correlation of system metrics, implemented by an efficient correlation algorithm which does not require training or complex infrastructure set up. The LADT algorithm is based on the premise that \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:6ZxmRoH8BuwC",
            "Publisher": "Springer, Cham"
        },
        {
            "Title": "Topic 1: Support Tools and Environments-(Introduction).: Euro-Par 2013 Parallel Processing-19th International Conference",
            "Publication year": 2013,
            "Publication url": "https://pure.qub.ac.uk/en/publications/topic-1-support-tools-and-environments-introduction-euro-par-2013",
            "Abstract": "Topic 1: Support Tools and Environments - (Introduction). Euro-Par 2013 Parallel Processing - \n19th International Conference \u2014 Queen's University Belfast Skip to main navigation Skip to \nsearch Skip to main content Queen's University Belfast Logo Help & FAQ Home Profiles \nOrganisations Research output Projects Impact Datasets Activities Prizes Press / Media Student \ntheses Facilities Search by expertise, name or affiliation Topic 1: Support Tools and \nEnvironments - (Introduction). Euro-Par 2013 Parallel Processing - 19th International Conference \nBronis de Supinski, Bettina Krammer, Karl Fuerlinger, Dimitrios Nikolopoulos, Jesus Labarta \nSchool of Electronics, Electrical Engineering and Computer Science High Performance and \nDistributed Computing Research output: Chapter in Book/Report/Conference proceeding \u203a \nForeword/postscript Overview Original language English Title of host publication Felix Wolf, Mohr(\u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:9vf0nzSNQJEC",
            "Publisher": "Springer"
        },
        {
            "Title": "The VINEYARD project: Versatile integrated accelerator-based heterogeneous data centres",
            "Publication year": 2016,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/7495121/",
            "Abstract": "Emerging applications like cloud computing and big data analytics have created the need for powerful centers hosting hundreds of thousands of servers. Currently, the data centers are based on general purpose processors that provide high flexibility but lacks the energy efficiency of customized accelerators. VINEYARD1 aims to develop novel servers based on programmable hardware accelerators. Furthermore, VINEYARD will develop an integrated framework for allowing end-users to seamlessly utilize these accelerators in heterogeneous computing systems by using typical data-center programming frameworks (i.e. Spark). VINEYARD will foster the expansion of the soft-IP cores industry, currently limited in the embedded systems, to the data center market. VINEYARD plans to demonstrate the advantages of its approach in three real use-cases a) a bio-informatics application for high-accuracy brain modeling, b \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:foquWX3nUaYC",
            "Publisher": "IEEE"
        },
        {
            "Title": "An energy-efficient and error-resilient server ecosystem exceeding conservative scaling limits",
            "Publication year": 2018,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/8342175/",
            "Abstract": "The explosive growth of Internet-connected devices will soon result in a flood of generated data, which will increase the demand for network bandwidth as well as compute power to process the generated data. Consequently, there is a need for more energy efficient servers to empower traditional centralized Cloud data-centers as well as emerging decentralized data-centers at the Edges of the Cloud. In this paper, we present our approach, which aims at developing a new class of micro-servers - the UniServer - that exceed the conservative energy and performance scaling boundaries by introducing novel mechanisms at all layers of the design stack. The main idea lies on the realization of the intrinsic hardware heterogeneity and the development of mechanisms that will automatically expose the unique varying capabilities of each hardware. Low overhead schemes are employed to monitor and predict the hardware \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:dQ2og3OwTAUC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Power capping: What works, what does not",
            "Publication year": 2015,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/7384335/",
            "Abstract": "Peak power consumption is the first order design constraint of data centers. Though peak power consumption is rarely, if ever, observed, the entire data center facility must prepare for it, leading to inefficient usage of its resources. The most prominent way for addressing this issue is to limit the power consumption of the data center IT facility far below its theoretical peak value. Many approaches have been proposed to achieve that, based on the same small set of enforcement mechanisms, but there has been no corresponding work on systematically examining the advantages and disadvantages of each such mechanism. In the absence of such a study, it is unclear what is the optimal mechanism for a given computing environment, which can lead to unnecessarily poor performance if an inappropriate scheme is used. This paper fills this gap by comparing for the first time five widely used power capping mechanisms \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:WJVC3Jt7v1AC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Keynote presentations",
            "Publication year": 2011,
            "Publication url": "http://130.203.136.60/viewdoc/summary?doi=10.1.1.233.657",
            "Abstract": "Welcome to the Fourth Workshop on Programmability Issues for Multi-Core Computers (MULTIPROG-2011). We are delighted to present a strong program composed of 10 high-quality papers selected out of 21 papers submitted. The program also included two keynote proesentations by Tim Mattson (Intel) and Dimitrios Nikolopoulos (U. of Crete and FORTH-ICS). As computer manufacturers are embarking on the multi-core roadmap, which promises a doubling of the number of processors on a chip every other year, the programming community is faced with a severe dilemma. Until now, software has been developed with a single processor in mind and it needs to be parallelized to take advantage of the new breed of multi-core computers. As a result, progress in how to easily harness the computing power of multi-core architectures is in great demand. This workshop brings together researchers interested in \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:uDGL6kOW6j0C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Foreword CLUSTER 2010",
            "Publication year": 2010,
            "Publication url": "https://pure.qub.ac.uk/en/publications/foreword-cluster-2010",
            "Abstract": "Foreword CLUSTER 2010 \u2014 Queen's University Belfast Skip to main navigation Skip to search \nSkip to main content Queen's University Belfast Logo Help & FAQ Home Profiles Organisations \nResearch output Projects Impact Datasets Activities Prizes Press / Media Student theses Facilities \nSearch by expertise, name or affiliation Foreword CLUSTER 2010 Dimitrios S. Nikolopoulos, \nRicardo Bianchini, Angelos Bilas Research output: Chapter in Book/Report/Conference \nproceeding \u203a Foreword/postscript Overview Original language English Title of host publication \nProceedings - 2010 IEEE International Conference on Cluster Computing, Cluster 2010 DOIs \nhttps://doi.org/10.1109/CLUSTER.Publication status Published - 02 Dec 2010 Externally \npublished Yes ASJC Scopus subject areas Software Hardware and Architecture Signal \nProcessing Access to Document 10.1109/CLUSTER.Cite this APA Author BIBTEX Harvard .\u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:YsMSGLbcyi4C",
            "Publisher": "Unknown"
        },
        {
            "Title": "On the viability of microservers for financial analytics",
            "Publication year": 2014,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/7016371/",
            "Abstract": "Energy consumption and total cost of ownership are daunting challenges for Datacenters, because they scale disproportionately with performance. Datacenters running financial analytics may incur extremely high operational costs in order to meet performance and latency requirements of their hosted applications. Recently, ARM-based microservers have emerged as a viable alternative to high-end servers, promising scalable performance via scale-out approaches and low energy consumption.In this paper, we investigate the viability of ARM-based microservers for option pricing, using the Monte Carlo and Binomial Tree kernels. We compare an ARM-based microserver against a state-of-the-art x86 server. We define application-related but platform-independent energy and performance metrics to compare those platforms fairly in the context of datacenters for financial analytics and give insight on the particular \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:bKqednn6t2AC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Significance-driven data truncation for preventing timing failures",
            "Publication year": 2019,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/8640064/",
            "Abstract": "The continuous scaling of transistor sizes and the increased parametric variations render nanometer circuits more prone to timing failures. To protect circuits from such failures, typically designers adopt pessimistic timing margins, which are estimated under rare worst-case conditions. In this paper, we present a technique that mitigates such pessimistic margins by minimizing the number of timing failures. In particular, we propose a method that minimizes the number of long latency paths within each processor pipeline stage and constrains them in as few stages as possible. Such a method allows us not only to reduce the timing failures but also to limit the potential error-prone locations to only a few pipeline stages. To further reduce these failures, we exploit the path excitation dependence on data patterns and truncate the bitwidth of the operands in the few remaining long latency paths by setting a number of less \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:ULOm3_A8WrAC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Error-resilient server ecosystems for edge and cloud datacenters",
            "Publication year": 2017,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/8220477/",
            "Abstract": "The explosive growth of Internet-connected devices that form the Internet of Things and the flood of data they yield require new energy-efficient and error-resilient hardware and software server stacks for next-generation cloud and edge datacenters.",
            "Abstract entirety": 1,
            "Author pub id": "PkCuYUQAAAAJ:roLk4NBRz8UC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Message from technical program Committee co-chairs",
            "Publication year": 2014,
            "Publication url": "https://pure.qub.ac.uk/en/publications/message-from-technical-program-committee-co-chairs",
            "Abstract": "Message from technical program Committee co-chairs \u2014 Queen's University Belfast Skip to \nmain navigation Skip to search Skip to main content Queen's University Belfast Logo Help & \nFAQ Home Profiles Organisations Research output Projects Impact Datasets Activities Prizes \nPress / Media Student theses Facilities Search by expertise, name or affiliation Message from \ntechnical program Committee co-chairs Kirk W. Cameron, Dimitrios S. Nikolopoulos School of \nElectronics, Electrical Engineering and Computer Science Research output: Contribution to \njournal \u203a Editorial \u203a peer-review Overview Original language English Article number 6846430 \nJournal Proceedings - 14th IEEE/ACM International Symposium on Cluster, Cloud, and Grid \nComputing, CCGrid 2014 DOIs https://doi.org/10.1109/CCGrid.Publication status Published \n- 01 Jan 2014 Event 14th IEEE/ACM International Symposium on Cluster, Cloud and Grid , \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:mB3voiENLucC",
            "Publisher": "Unknown"
        },
        {
            "Title": "A transparent runtime data distribution engine for OpenMP",
            "Publication year": 2000,
            "Publication url": "https://content.iospress.com/articles/scientific-programming/spr00057",
            "Abstract": "This paper makes two important contributions. First, the paper investigates the performance implications of data placement in OpenMP programs running on modern NUMA multiprocessors. Data locality and minimization of the rate of remote memory accesses are critical for sustaining high performance on these systems. We show that due to the low remote-to-local memory access latency ratio of contemporary NUMA architectures, reasonably balanced page placement schemes, such as round-robin or random distribution, incur modest performance losses. Second, the paper presents a transparent, user-level page migration engine with an ability to gain back any performance loss that stems from suboptimal placement of pages in iterative OpenMP programs. The main body of the paper describes how our OpenMP runtime environment uses page migration for implementing implicit data distribution and redistribution \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:cWzG1nlazyYC",
            "Publisher": "IOS Press"
        },
        {
            "Title": "Computer science faculty explore thermal-aware computing",
            "Publication year": 2007,
            "Publication url": "https://vtechworks.lib.vt.edu/handle/10919/59007",
            "Abstract": "Kirk Cameron and Dimitrios Nikolopoulos, associate professors of computer science in the College of Engineering at Virginia Tech, have earned a National Science Foundation (NSF) - Computer Science Research (CSR) award of $350,000 to help improve the reliability of computer systems' processors.",
            "Abstract entirety": 1,
            "Author pub id": "PkCuYUQAAAAJ:F1b5ZUV5XREC",
            "Publisher": "Virginia Tech. University Relations"
        },
        {
            "Title": "Supporting Cloud IaaS Users in Detecting Performance-based Violation for Streaming Applications",
            "Publication year": 2018,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/8498138/",
            "Abstract": "Cloud infrastructure-as-a-service (IaaS) users require stable performance for their applications so that the Quality of Service (QoS) constraints are satisfied. However, they generally experience performance variability, primarily due to multi-tenancy. Such variability may lead to QoS violations for the deployed applications. Existing cloud infrastructure solutions offered by cloud providers (CPs) do not have facilities to detect such violations. Hence, cloud users need to take responsibility for monitoring the performance of their applications in order to detect application-specific QoS violations. In this paper, we propose a novel algorithm for detecting QoS violation for media streaming applications. The algorithm compares the cumulative value of the expected streamed data against the cumulative value of the measured streamed data. Based on this comparison, the algorithm may raise QoS violation alarms. We evaluate the \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:YOwf2qJgpHMC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Effective cross-platform, multilevel parallelism via dynamic adaptive execution",
            "Publication year": 2002,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/1016495/",
            "Abstract": "This paper presents preliminary efforts to develop compilation and execution environments that achieve performance portability of multilevel parallelization on hierarchical architectures. Using the NAS parallel benchmarks, we first illustrate the lack of portable performance on stateof- the-art scalable parallel systems despite the use of two portable programming models, MPI and OpenMP. Then we present a dynamic compilation and execution framework that provides the desired portability through the use of program slices. These slices are used to select the optimal program decomposition on each architecture. Currently, our framework uses a simple incremental algorithm, which effectively identifies single or multi-level program decompositions that maximize performance. This algorithm can be used as a rule of thumb for automatic multilevel parallelization. The effectiveness of the approach is demonstrated on the \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:ZHo1McVdvXMC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Runtime support for integrating precomputation and thread-level parallelism on simultaneous multithreaded processors",
            "Publication year": 2004,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/1066650.1066667",
            "Abstract": "This paper presents runtime mechanisms that enable flexible use of speculative precomputation in conjunction with thread-level parallelism on SMT processors. The mechanisms were implemented and evaluated on a real multi-SMT system. So far, speculative precomputation and thread-level parallelism have been used disjunctively on SMT processors and no attempts have been made to compare and possibly combine these techniques for further optimization. We present runtime support mechanisms for coordinating precomputation with its sibling computation, so that precomputation is regulated to avoid cache pollution and sufficient runahead distance is allowed from the targeted computation. We also present a task queue mechanism to orchestrate precomputation and thread-level parallelism, so that they can be used conjunctively in the same program. The mechanisms are motivated by the observation that \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:eflP2zaiRacC",
            "Publisher": "Unknown"
        },
        {
            "Title": "FairGV: fair and fast GPU virtualization",
            "Publication year": 2017,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/7954729/",
            "Abstract": "Increasingly high performance computing (HPC) application developers are opting to use cloud resources due to higher availability. Virtualized GPUs would be an obvious and attractive option for HPC application developers using cloud hosting services. Unfortunately, existing GPU virtualization software is not ready to address fairness, utilization, and performance limitations associated with consolidating mixed HPC workloads. This paper presents FairGV, a radically redesigned GPU virtualization system that achieves system-wide weighted fair sharing and strong performance isolation in mixed workloads that use GPUs with variable degrees of intensity. To achieve its objectives, FairGV introduces a trap-less GPU processing architecture, a new fair queuing method integrated with work-conserving and GPU-centric coscheduling polices, and a collaborative scheduling method for non-preemptive GPUs. Our \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:4TOpqqG69KYC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Challenges and opportunities in edge computing",
            "Publication year": 2016,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/7796149/",
            "Abstract": "Many cloud-based applications employ a data centers as a central server to process data that is generated by edge devices, such as smartphones, tablets and wearables. This model places ever increasing demands on communication and computational infrastructure with inevitable adverse effect on Quality-of-Service and Experience. The concept of Edge Computing is predicated on moving some of this computational load towards the edge of the network to harness computational capabilities that are currently untapped in edge nodes, such as base stations, routers and switches. This position paper considers the challenges and opportunities that arise out of this new direction in the computing landscape.",
            "Abstract entirety": 1,
            "Author pub id": "PkCuYUQAAAAJ:anf4URPfarAC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Informing algorithms for efficient scheduling of synchronizing threads on multiprogrammed SMPs",
            "Publication year": 2001,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/952054/",
            "Abstract": "We present novel algorithms for efficient scheduling of synchronizing threads on multiprogrammed SMPs. The algorithms are based on intra-application priority control of synchronizing threads. We refer to such algorithms with the term \"informing algorithms\". Prerequisite for informing algorithms is the use of an efficient communication medium between the user- and kernel-level and the existence of in-kernel mechanisms that allow the applications to cooperate with the OS scheduler. The applications are given the opportunity to influence, in a non-intrusive manner, the scheduling decisions concerning their threads. We compare the performance of our informing algorithms with the performance of corresponding scheduler-oblivious algorithms under multiprogramming. We experimented on a small-scale, Intel x86-based SMP, running Linux, using both microbenchmarks and applications from the Splash-2 benchmark \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:Dip1O2bNi0gC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Exploring new search algorithms and hardware for phylogenetics: RAxML meets the IBM cell",
            "Publication year": 2007,
            "Publication url": "https://link.springer.com/article/10.1007/s11265-007-0067-4",
            "Abstract": "Phylogenetic inference is considered to be one of the grand challenges in Bioinformatics due to the immense computational requirements. RAxML is currently among the fastest and most accurate programs for phylogenetic tree inference under the Maximum Likelihood (ML) criterion. First, we introduce new tree search heuristics that accelerate RAxML by a factor of 2.43 while returning equally good trees. The performance of the new search algorithm has been assessed on 18 real-world datasets comprising 148 up to 4,843 DNA sequences. We then present the implementation, optimization, and evaluation of RAxML on the IBM Cell Broadband Engine. We address the problems and provide solutions pertaining to the optimization of floating point code, control flow, communication, and scheduling of multi-level parallelism on the Cell.",
            "Abstract entirety": 1,
            "Author pub id": "PkCuYUQAAAAJ:86PQX7AUzd4C",
            "Publisher": "Springer US"
        },
        {
            "Title": "Exploring Programming Models and Optimizations for the Cell Broadband Engine using RAxML",
            "Publication year": 2006,
            "Publication url": "https://www.researchgate.net/profile/Dimitrios-Nikolopoulos-3/publication/239866708_Exploring_Programming_Models_and_Optimizations_for_the_Cell_Broadband_Engine_using_RAxML/links/0deec534be0bdc6fb9000000/Exploring-Programming-Models-and-Optimizations-for-the-Cell-Broadband-Engine-using-RAxML.pdf",
            "Abstract": "Originally developed as a gaming processor for Sony PlayStation3, the Cell Broadband Engine opens new opportunities for running computationally intensive scientific applications more efficiently, thanks to characteristics such as multigrain task-level and data-level parallel execution and vast on-chip memory bandwidth. In the ideal case, the Cell is capable of achieving significant performance improvements over conventional processors. However, the potential of the Cell is unclear when the processor is used for applications that are not necessarily conforming to its architectural characteristics. Furthermore, the question of what is the best programming model for a processor like Cell remains open, with too many programming models and paradigms proposed, yet too few evaluated empirically or experimentally. In this work we present the port and optimization of RAxML, an application that computes large phylogenetic trees, on a real blade with Cell processors. We investigate two programming models that derive partially from the dominant programming models of conventional parallel machines, namely MPI and OpenMP, as well as an extensive set of Cell-specific optimizations. Using multilevel parallelization and several optimizations we have been able to improve the execution time of RAxML on the Cell by a factor of 5, a satisfactory result given that RAxML is an application with dynamically allocated data structures, complex control flow and extensive pointer arithmetic, all factors that present challenges for parallelization beyond the simple master-worker scheme. We also find that the Cells performs comparably or outperforms leading \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:bz8QjSJIRt4C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Topic 16: GPU and Accelerators Computing",
            "Publication year": 2012,
            "Publication url": "https://pure.qub.ac.uk/en/publications/topic-16-gpu-and-accelerators-computing",
            "Abstract": "Topic 16: GPU and Accelerators Computing \u2014 Queen's University Belfast Skip to main \nnavigation Skip to search Skip to main content Queen's University Belfast Logo Help & FAQ \nHome Profiles Organisations Research output Projects Impact Datasets Activities Prizes Press / \nMedia Student theses Facilities Search by expertise, name or affiliation Topic 16: GPU and \nAccelerators Computing Dimitrios Nikolopoulos School of Electronics, Electrical Engineering \nand Computer Science High Performance and Distributed Computing Research output: Chapter \nin Book/Report/Conference proceeding \u203a Foreword/postscript Overview Original language \nEnglish Title of host publication Euro-Par 2012 Parallel Processing - 18th International \nConference, Euro-Par 2012, Rhodes Island, Greece, August 27-31, 2012. Proceedings Place of \nPublication Rhodes, Greece Publisher Springer Pages 857-858 Number of pages 2 Volume () -3\u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:M3NEmzRMIkIC",
            "Publisher": "Springer"
        },
        {
            "Title": "DroidLight: Lightweight anomaly-based intrusion detection system for smartphone devices",
            "Publication year": 2020,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/3369740.3369796",
            "Abstract": "Smartphone malware attacks are increasing alongside the growth of smartphone applications in the market. Researchers have proposed techniques to detect malware attacks using various approaches, which broadly include signature and anomaly-based intrusion detection systems (IDSs). Anomaly-based IDSs usually require training machine learning models with datasets collected from running both benign and malware applications. This may result in low detection accuracy when detecting zero-day malwares, ie those not previously seen or recorded. In this paper, we propose DroidLight, a lightweight IDS which can detect zero-day malware efficiently and effectively. We designed an algorithm for DroidLight that is based on one class classification and probability distribution analysis. For each smartphone application, the classification model learns its normal CPU utilisation and network traffic pattern. The model \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:5awf1xo2G04C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Low-cost hardware infrastructure for runtime thread level energy accounting",
            "Publication year": 2016,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-319-30695-7_21",
            "Abstract": "The ever-growing need for energy efficient computation requires adequate support for energy-aware thread scheduling that offers insight into a systems behavior for improved application energy/performance optimizations. Runtime accurate monitoring of energy consumed by every component of a multi-core embedded system is an important feature to be considered for future designs. Although, important steps have been made in this direction, the problem of distributing energy consumption among threads executed on different cores for shared components remains an ongoing struggle. We aim at designing a generic low-cost and energy efficient hardware infrastructure which supports thread level energy accounting of hardware components in a multi-core system. The proposed infrastructure provides upper software layers with per thread and per component energy accounting API, similar with \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:PR6Y55bgFSsC",
            "Publisher": "Springer, Cham"
        },
        {
            "Title": "Iso-quality of service: Fairly ranking servers for real-time data analytics",
            "Publication year": 2015,
            "Publication url": "https://www.worldscientific.com/doi/abs/10.1142/S0129626415410042",
            "Abstract": "We present a mathematically rigorous iso-Quality-of-Service (QoS) metric which relates the achievable quality of service (QoS) for a real-time analytics service with workload specific and use case specific performance and output quality requirements to the energy cost of offering the service by different server architectures. Using a new iso-QoS evaluation methodology, we scale server resources to meet QoS targets and directly rank the servers in terms of their energy-efficiency and by extension cost of ownership. Our metric and method are platform-independent and enable fair comparison of datacenter compute servers with significant architectural diversity, including micro-servers. We deploy our metric and methodology to compare three servers running financial option pricing workloads on real-life market data. We find that server ranking is sensitive to data inputs and desired QoS level and that although scale-out \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:OTTXONDVkokC",
            "Publisher": "World Scientific Publishing Company"
        },
        {
            "Title": "VarSys Introduction",
            "Publication year": 2016,
            "Publication url": "https://www.computer.org/csdl/proceedings-article/ipdpsw/2016/3682b068/12OmNwl8GDW",
            "Abstract": "In this first iteration of the workshop, the focus of the organizers was on participation from a broad array of researchers interested in variability in parallel and distributed systems. Thus, the submission process and program committee were simplified to encourage submission of fresh, emergent ideas that may not be fully developed or explored. Submissions of 3-5 pages in length were encouraged and reviewed by the workshop organizers. This led to 10 submissions of which 5 were accepted for presentation at the workshop. Topics are diverse and include studies of variation in processors and virtualized operating systems as well as cloud and IoT related topics.We were also able to attract top researchers to present related work on variability at the inaugural VarSys workshop. Barry Rountree from Lawrence Livermore National Laboratory was selected as the keynote speaker. His research on processor variability at \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:yFnVuubrUp4C",
            "Publisher": "IEEE Computer Society"
        },
        {
            "Title": "RADS: Real-time anomaly detection system for cloud data centres",
            "Publication year": 2018,
            "Publication url": "https://arxiv.org/abs/1811.04481",
            "Abstract": "Cybersecurity attacks in Cloud data centres are increasing alongside the growth of the Cloud services market. Existing research proposes a number of anomaly detection systems for detecting such attacks. However, these systems encounter a number of challenges, specifically due to the unknown behaviour of the attacks and the occurrence of genuine Cloud workload spikes, which must be distinguished from attacks. In this paper, we discuss these challenges and investigate the issues with the existing Cloud anomaly detection approaches. Then, we propose a Real-time Anomaly Detection System (RADS) for Cloud data centres, which uses a one class classification algorithm and a window-based time series analysis to address the challenges. Specifically, RADS can detect VM-level anomalies occurring due to DDoS and cryptomining attacks. We evaluate the performance of RADS by running lab-based experiments and by using real-world Cloud workload traces. Evaluation results demonstrate that RADS can achieve 90-95% accuracy with a low false positive rate of 0-3%. The results further reveal that RADS experiences fewer false positives when using its window-based time series analysis in comparison to using state-of-the-art average or entropy based analysis.",
            "Abstract entirety": 1,
            "Author pub id": "PkCuYUQAAAAJ:_Re3VWB3Y0AC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Model-Based Hybrid MPI/OpenMP Power-Aware Computing: ACM/IEEE Supercomputing'2009: High-performance Computing, Networking, Storage and Analysis (SC)",
            "Publication year": 2009,
            "Publication url": "https://pure.qub.ac.uk/en/publications/model-based-hybrid-mpiopenmp-power-aware-computing-acmieee-superc",
            "Abstract": "Model-Based Hybrid MPI/OpenMP Power-Aware Computing: ACM/IEEE Supercomputing'2009: \nHigh-performance Computing, Networking, Storage and Analysis (SC): Poster Session \u2014 \nQueen's University Belfast Skip to main navigation Skip to search Skip to main content Queen's \nUniversity Belfast Logo Help & FAQ Home Profiles Organisations Research output Projects \nImpact Datasets Activities Prizes Press / Media Student theses Facilities Search by expertise, \nname or affiliation Model-Based Hybrid MPI/OpenMP Power-Aware Computing: ACM/IEEE \nSupercomputing'2009: High-performance Computing, Networking, Storage and Analysis (SC): \nPoster Session D. Li, K. Cameron, Dimitrios Nikolopoulos, M. Schulz, B. De Supinski School \nof Electronics, Electrical Engineering and Computer Science Research output: Contribution \nto conference \u203a Poster \u203a peer-review Overview Original language English Number of 1 - , \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:LI9QrySNdTsC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Safire: Scalable and accurate fault injection for parallel multithreaded applications",
            "Publication year": 2019,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/8820954/",
            "Abstract": "Soft errors threaten to disrupt supercomputing scaling. Fault injection is a key technique to understand the impact of faults on scientific applications. However, injecting faults in parallel applications has been prohibitively slow, inaccurate and hard to implement. In this paper, we present, the first fast and accurate fault injection framework for parallel, multi-threaded applications. uses novel compiler instrumentation and code generation techniques to achieve high accuracy and high speed. Using, we show that fault manifestations can be significantly different depending on whether they happen in the application itself or in the parallel runtime system. In our experimental evaluation on 15 HPC parallel programs, we show that is multiple factors faster and equally accurate in comparison with state-of-the-art dynamic binary instrumentation tools for fault injection.",
            "Abstract entirety": 1,
            "Author pub id": "PkCuYUQAAAAJ:hC7cP41nSMkC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Strategies for energy-efficient resource management of hybrid programming models",
            "Publication year": 2012,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/6171173/",
            "Abstract": "Many scientific applications are programmed using hybrid programming models that use both message passing and shared memory, due to the increasing prevalence of large-scale systems with multicore, multisocket nodes. Previous work has shown that energy efficiency can be improved using software-controlled execution schemes that consider both the programming model and the power-aware execution capabilities of the system. However, such approaches have focused on identifying optimal resource utilization for one programming model, either shared memory or message passing, in isolation. The potential solution space, thus the challenge, increases substantially when optimizing hybrid models since the possible resource configurations increase exponentially. Nonetheless, with the accelerating adoption of hybrid programming models, we increasingly need improved energy efficiency in hybrid parallel \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:9c2xU6iGI7YC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Alea: Fine-grain energy profiling with basic block sampling",
            "Publication year": 2015,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/7429297/",
            "Abstract": "Energy efficiency is an essential requirement for all contemporary computing systems. We thus need tools to measure the energy consumption of computing systems and to understand how workloads affect it. Significant recent research effort has targeted direct power measurements on production computing systems using on-board sensors or external instruments. These direct methods have in turn guided studies of software techniques to reduce energy consumption via workload allocation and scaling. Unfortunately, direct energymeasurementsarehamperedbythelowpowersampling frequency of power sensors. The coarse granularity of power sensing limits our understanding of how power is allocated in systems and our ability to optimize energy efficiency via workload allocation. We present ALEA, a tool to measure power and energy consumption at the granularity of basic blocks, using a probabilistic approach \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:NJ774b8OgUMC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Prefetching and cache management using task lifetimes",
            "Publication year": 2013,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/2464996.2465443",
            "Abstract": "Task-based dataflow programming models and runtimes emerge as promising candidates for programming multicore and manycore architectures. These programming models analyze dynamically task dependencies at runtime and schedule independent tasks concurrently to the processing elements. In such models, cache locality, which is critical for performance, becomes more challenging in the presence of fine-grain tasks, and in architectures with many simple cores.",
            "Abstract entirety": 1,
            "Author pub id": "PkCuYUQAAAAJ:OcBU2YAGkTUC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Parallel programming models for heterogeneous multicore architectures",
            "Publication year": 2010,
            "Publication url": "Unknown",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "PkCuYUQAAAAJ:HDshCWvjkbEC",
            "Publisher": "Unknown"
        },
        {
            "Title": "FPGA prototyping of emerging manycore architectures for parallel programming research using Formic boards",
            "Publication year": 2014,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S138376211400054X",
            "Abstract": "Performance evaluation of parallel software and architectural exploration of innovative hardware support face a common challenge with emerging manycore platforms: they are limited by the slow running time and the low accuracy of software simulators. Manycore FPGA prototypes are difficult to build, but they offer great rewards. Software running on such prototypes runs orders of magnitude faster than current simulators. Moreover, researchers gain significant architectural insight during the modeling process. We use the Formic FPGA prototyping board [1], which specifically targets scalable and cost-efficient multi-board prototyping, to build and test a 64-board model of a 512-core, MicroBlaze-based, non-coherent hardware prototype with a full network-on-chip in a 3D-mesh topology. We expand the hardware architecture to include the ARM Versatile Express platforms and build a 520-core heterogeneous prototype \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:_axFR9aDTf0C",
            "Publisher": "North-Holland"
        },
        {
            "Title": "Fast synchronization on scalable cache-coherent multiprocessors using hybrid primitives",
            "Publication year": 2000,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/846056/",
            "Abstract": "This paper presents a new methodology for implementing fast synchronization on scalable cache-coherent multiprocessors, through the use of hybrid primitives. Hybrid primitives leverage commodity hardware to speed-up the execution of the atomic remote Read-Modify-Write (RMW) instructions employed in synchronization algorithms to resolve contending processors, while exploiting the caches to reduce network traffic during the waiting and release phases of a synchronization primitive. We present a systematic methodology for transforming any synchronization primitive that uses RMW instructions into a hybrid one. We then provide experimental evidence on the effectiveness of using hybrid primitives in the implementation of spin locks, barriers and lock-free queues, in microbenchmarks and parallel applications on a SGI Origin 2000.",
            "Abstract entirety": 1,
            "Author pub id": "PkCuYUQAAAAJ:bnK-pcrLprsC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Access-aware DRAM failure-rate estimation under relaxed refresh operations",
            "Publication year": 2017,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/8344643/",
            "Abstract": "In recent years, there has been a growing interest on relaxing the pessimistic DRAM refresh rate due to the incurred power and throughput loss. Undeniably, a critical factor in determining the refresh rate relaxation that can be achieved lies on the degree of the DRAM error-rate deterioration that is incurred and on the amount of estimated errors that can be handled by system mitigation schemes which are mainly being evaluated in simulators. To estimate the DRAM faults under relaxed refresh, the majority of the existing works rely on estimated DRAM failure probability models using only the spatial distribution of the DRAM retention time across the memory cells. We observe that such failure models have neglected the intricate dependence on the memory accesses, which inherently refresh the accessed rows. In this paper, we propose that the intervals between consecutive accesses must also be considered during \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:8AbLer7MMksC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Computer science faculty earn IBM Faculty Awards",
            "Publication year": 2007,
            "Publication url": "https://vtechworks.lib.vt.edu/bitstream/handle/10919/58915/2007-462.html?sequence=1",
            "Abstract": "Three faculty members in Virginia Tech's Department of Computer Science, Kirk Cameron, Wu-Chun Feng, and Dimitrios Nikolopoulos, have received IBM Faculty Awards.",
            "Abstract entirety": 1,
            "Author pub id": "PkCuYUQAAAAJ:2tRrZ1ZAMYUC",
            "Publisher": "Virginia Tech. University Relations"
        },
        {
            "Title": "Runtime vs. manual data distribution for architecture-agnostic shared-memory programming models",
            "Publication year": 2002,
            "Publication url": "https://link.springer.com/article/10.1023/A:1019899812171",
            "Abstract": "This paper compares data distribution methodologies for scaling the performance of OpenMP on NUMA architectures. We investigate the performance of automatic page placement algorithms implemented in the operating system, runtime algorithms based on dynamic page migration, runtime algorithms based on loop scheduling transformations and manual data distribution. These techniques present the programmer with trade-offs between performance and programming effort. Automatic page placement algorithms are transparent to the programmer, but may compromise memory access locality. Dynamic page migration algorithms are also transparent, but require careful engineering and tuned implementations to be effective. Manual data distribution requires substantial programming effort and architecture-specific extensions to the API, but may localize memory accesses in a nearly optimal manner. Loop \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:JoZmwDi-zQgC",
            "Publisher": "Kluwer Academic Publishers-Plenum Publishers"
        },
        {
            "Title": "Exploiting Simultaneous Multithreading for Parallel Mesh Generation: A Multigrain Approach on Deep Multiprocessors: 13th International Meshing Roundtable (IMR)",
            "Publication year": 2004,
            "Publication url": "https://pure.qub.ac.uk/en/publications/exploiting-simultaneous-multithreading-for-parallel-mesh-generati",
            "Abstract": "Exploiting Simultaneous Multithreading for Parallel Mesh Generation: A Multigrain Approach \non Deep Multiprocessors: 13th International Meshing Roundtable (IMR) \u2014 Queen's University \nBelfast Skip to main navigation Skip to search Skip to main content Queen's University Belfast \nLogo Help & FAQ Home Profiles Organisations Research output Projects Impact Datasets \nActivities Prizes Press / Media Student theses Facilities Search by expertise, name or affiliation \nExploiting Simultaneous Multithreading for Parallel Mesh Generation: A Multigrain Approach \non Deep Multiprocessors: 13th International Meshing Roundtable (IMR) CD Antonopoulos, \nN. Chrisochoides, Dimitrios Nikolopoulos School of Electronics, Electrical Engineering and \nComputer Science Research output: Contribution to conference \u203a Poster \u203a peer-review 11 \nDownloads (Pure) Overview Original language English Publication status Published - Sep () (\u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:_B80troHkn4C",
            "Publisher": "Unknown"
        },
        {
            "Title": "To Program or Not To Program the Memory Hierarchy?: Keynote Talk. Proceedings of the 4th Workshop on Programmability Issues for Heterogeneous Multicores,(MULTIPROG)",
            "Publication year": 2011,
            "Publication url": "https://pure.qub.ac.uk/en/publications/to-program-or-not-to-program-the-memory-hierarchy-keynote-talk-pr",
            "Abstract": "To Program or Not To Program the Memory Hierarchy? Keynote Talk. Proceedings of the 4th \nWorkshop on Programmability Issues for Heterogeneous Multicores, (MULTIPROG) \u2014 Queen's \nUniversity Belfast Skip to main navigation Skip to search Skip to main content Queen's University \nBelfast Logo Help & FAQ Home Profiles Organisations Research output Projects Impact \nDatasets Activities Prizes Press / Media Student theses Facilities Search by expertise, name or \naffiliation To Program or Not To Program the Memory Hierarchy? Keynote Talk. Proceedings \nof the 4th Workshop on Programmability Issues for Heterogeneous Multicores, (MULTIPROG) \nDimitrios Nikolopoulos School of Electronics, Electrical Engineering and Computer Science \nResearch output: Contribution to conference \u203a Abstract Overview Original language English \nPublication status Published - Jan 2011 Event Proceedings of the 4th Workshop on , (/\u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:hFOr9nPyWt4C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Dynamic multigrain parallelization on the cell broadband engine",
            "Publication year": 2007,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/1229428.1229445",
            "Abstract": "This paper addresses the problem of orchestrating and scheduling parallelism at multiple levels of granularity on heterogeneous multicore processors. We present mechanisms and policies for adaptive exploitation and scheduling of layered parallelism on the Cell Broadband Engine. Our policies combine event-driven task scheduling with malleable loop-level parallelism, which is exploited from the runtime system whenever task-level parallelism leaves idle cores. We present a scheduler for applications with layered parallelism on Cell and investigate its performance with RAxML, an application which infers large phylogenetic trees, using the Maximum Likelihood (ML) method. Our experiments show that the Cell benefits significantly from dynamic methods that selectively exploit the layers of parallelism in the system, in response to workload fluctuation. Our scheduler out performs the MPI version of RAxML \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:CaZNVDsoPx4C",
            "Publisher": "Unknown"
        },
        {
            "Title": "ECOSCALE: Reconfigurable computing and runtime system for future exascale systems",
            "Publication year": 2016,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/7459398/",
            "Abstract": "In order to reach exascale performance, current HPC systems need to be improved. Simple hardware scaling is not a feasible solution due to the increasing utility costs and power consumption limitations. Apart from improvements in implementation technology, what is needed is to refine the HPC application development flow as well as the system architecture of future HPC systems. ECOSCALE tackles these challenges by proposing a scalable programming environment and architecture, aiming to substantially reduce energy consumption as well as data traffic and latency. ECOSCALE introduces a novel heterogeneous energy-efficient hierarchical architecture, as well as a hybrid many-core+OpenCL programming environment and runtime system. The ECOSCALE approach is hierarchical and is expected to scale well by partitioning the physical system into multiple independent Workers (i.e. compute nodes \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:EkHepimYqZsC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Dynamic binary rewriting and migration for shared-ISA asymmetric, multicore processors: summary",
            "Publication year": 2012,
            "Publication url": "https://dl.acm.org/doi/pdf/10.1145/2287076.2287096",
            "Abstract": "Asymmetric multicore processors have demonstrated strong potential for improving performance, power efficiency and area efficiency of computing systems [1, 2, 5, 6]. Disjoint ISA systems, such as AMD Fusion, ARM Tegra and the Cell broadband engine, are becoming widespread. Although disjoint-ISA systems have exhibited high performance, they are hard to program [6]. Single-ISA, performance heterogeneous systems [7, 10] are simpler to program, as the same code can run on any core in the system. However, that implies that certain threads will be unable to exploit performance enhancing features which are available on selected cores and exposed to the ISA, through specialized instructions. Shared-ISA asymmetric multicore architectures [9] provide programmability and code customization simultaneously. Shared-ISA architectures use a baseline ISA, which some performance enhanced (PE) cores extend \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:F9fV5C73w3QC",
            "Publisher": "Unknown"
        },
        {
            "Title": "HPTA: High-performance text analytics",
            "Publication year": 2016,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/7840632/",
            "Abstract": "One of the main targets of data analytics is unstructured data, which primarily involves textual data. High-performance processing of textual data is non-trivial. We present the HPTA library for high-performance text analytics. The library helps programmers to map textual data to a dense numeric representation, which can be handled more efficiently. HPTA encapsulates three performance optimizations: (i) efficient memory management for textual data, (ii) parallel computation on associative data structures that map text to values and (iii) optimization of the type of associative data structure depending on the program context. We demonstrate that HPTA outperforms popular frameworks for text analytics such as scikit-learn.",
            "Abstract entirety": 1,
            "Author pub id": "PkCuYUQAAAAJ:isC4tDSrTZIC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Dstress: Automatic synthesis of dram reliability stress viruses using genetic algorithms",
            "Publication year": 2020,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/9251864/",
            "Abstract": "Failures become inevitable in DRAM devices, which is a major obstacle for scaling down the density of cells in future DRAM technologies. These failures can be detected by specific DRAM tests that implement the data and memory access patterns having a strong impact on DRAM reliability. However, the design of such tests is very challenging, especially for testing DRAM devices in operation, due to an extremely large number of possible cell-to-cell interference effects and combinations of patterns inducing these effects.In this paper, we present a new framework for the synthesis of DRAM reliability stress viruses, DStress. This framework automatically searches for the data and memory access patterns that induce the worst-case DRAM error behavior regardless the internal DRAM design. The search engine of our framework is based on Genetic Algorithms (GA) and a programming tool that we use to specify the \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:zYLM7Y9cAGgC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Energy-efficient localised rollback via data flow analysis and frequency scaling",
            "Publication year": 2018,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/3236367.3236379",
            "Abstract": "Exascale systems will suffer failures hourly. HPC programmers rely mostly on application-level checkpoint and a global rollback to recover. In recent years, techniques reducing the number of rolling back processes have been implemented via message logging. However, the log-based approaches have weaknesses, such as being dependent on complex modifications within an MPI implementation, and the fact that a full restart may be required in the general case. To address the limitations of all log-based mechanisms, we return to checkpoint-only mechanisms, but advocate data flow rollback (DFR), a fundamentally different approach relying on analysis of the data flow of iterative codes, and the well-known concept of data flow graphs. We demonstrate the benefits of DFR for an MPI stencil code by localising rollback, and then reduce energy consumption by 10-12% on idling nodes via frequency scaling. We also \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:nb7KW1ujOQ8C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Power and Energy Implications of the Number of Threads Used on the Intel Xeon Phi. Multicore and GPU Programming",
            "Publication year": 2015,
            "Publication url": "https://scholar.google.com/scholar?cluster=1379935442906065199&hl=en&oi=scholarr",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "PkCuYUQAAAAJ:jgBuDB5drN8C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Scheduling Dynamic Parallelism on the Cell BE",
            "Publication year": 2009,
            "Publication url": "https://pure.qub.ac.uk/en/publications/scheduling-dynamic-parallelism-on-the-cell-be",
            "Abstract": "Scheduling Dynamic Parallelism on the Cell BE \u2014 Queen's University Belfast Skip to main \nnavigation Skip to search Skip to main content Queen's University Belfast Logo Help & FAQ Home \nProfiles Organisations Research output Projects Impact Datasets Activities Prizes Press / Media \nStudent theses Facilities Search by expertise, name or affiliation Scheduling Dynamic Parallelism \non the Cell BE Filip Blagojevic, Costin Iancu, Katherine A. Yelick, Dimitrios Nikolopoulos, \nBenjamin Rose, Matthew Curtis-Maury School of Electronics, Electrical Engineering and \nComputer Science Research output: Chapter in Book/Report/Conference proceeding \u203a \nConference contribution Overview Original language English Title of host publication Proceedings \nof the 15th Meeting of the IBM HPC Systems Scientific Computing User Group (SCICOMP) \nPlace of Publication Barcelona, Spain Number of pages 1 Publication status Published .\u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:nZcligLrVowC",
            "Publisher": "Unknown"
        },
        {
            "Title": "A Lightweight Tool for Anomaly Detection in Cloud Data Centres.",
            "Publication year": 2015,
            "Publication url": "https://pdfs.semanticscholar.org/14c6/7d04d990e4b47d0fbfb0472bdb8bd03cfc70.pdf",
            "Abstract": "Cloud data centres are critical business infrastructures and the fastest growing service providers. Detecting anomalies in Cloud data centre operation is vital. Given the vast complexity of the data centre system software stack, applications and workloads, anomaly detection is a challenging endeavour. Current tools for detecting anomalies often use machine learning techniques, application instance behaviours or system metrics distribution, which are complex to implement in Cloud computing environments as they require training, access to application-level data and complex processing. This paper presents LADT, a lightweight anomaly detection tool for Cloud data centres that uses rigorous correlation of system metrics, implemented by an efficient correlation algorithm without need for training or complex infrastructure set up. LADT is based on the hypothesis that, in an anomaly-free system, metrics from data centre host nodes and virtual machines (VMs) are strongly correlated. An anomaly is detected whenever correlation drops below a threshold value. We demonstrate and evaluate LADT using a Cloud environment, where it shows that the hosting node I/O operations per second (IOPS) are strongly correlated with the aggregated virtual machine IOPS, but this correlation vanishes when an application stresses the disk, indicating a node-level anomaly.",
            "Abstract entirety": 1,
            "Author pub id": "PkCuYUQAAAAJ:Y5dfb0dijaUC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Relaxing DRAM refresh rate through access pattern scheduling: A case study on stencil-based algorithms",
            "Publication year": 2017,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/8046197/",
            "Abstract": "The main memory in today's systems is based on DRAMs, which may offer low cost and high density storage for large amounts of data but it comes with a main drawback; DRAM cells need to be refreshed frequently for retaining the stored data. The refresh rate in modern DRAMs is set based on the worst-case retention time without considering access statistics, thereby resulting in very frequent refresh operations. Such high refresh rate leads eventually to large power and performance overheads, which are increasing with higher DRAM densities. However, such high refresh rates may not even required due to extremely low probability of the actual occurrence of the assumed worst-case scenarios, or due to the implicit refresh operation that occur during every memory access, a feature that has not been yet been studied in depth. In this paper, we enhance the state-of-the-art by systematically exploiting the implicit \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:tS2w5q8j5-wC",
            "Publisher": "IEEE"
        },
        {
            "Title": "The VINEYARD integrated framework for hardware accelerators in the cloud",
            "Publication year": 2018,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/3229631.3236093",
            "Abstract": "Emerging cloud applications like machine learning, AI and big data analytics required high performance computing systems that can sustain the increased amount of data processing without consuming excessive power. Towards this end, many cloud operators have started deploying hardware accelerators, like FPGAs, to increase the performance of computational intensive tasks but increasing the programming complexity to utilize these accelerators. VINEYARD has developed an efficient framework that allows the seamless deployment and utilization of hardware accelerators in the cloud without increasing the programming complexity and offering the flexibility of software packages. This paper presents the main components that have been developed in this framework such as the runtime system, the virtualization and the central accelerators\u00e2\u0102\u0179 repository. The proposed platform has been demonstrated into 2 \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:B3FOqHPlNUQC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Supporting mapreduce on large-scale asymmetric multi-core clusters",
            "Publication year": 2009,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/1531793.1531800",
            "Abstract": "Asymmetric multi-core processors (AMPs) with general-purpose and specialized cores packaged on the same chip, are emerging as a leading paradigm for high-end computing. A large body of existing research explores the use of standalone AMPs in computationally challenging and data-intensive applications. AMPs are rapidly deployed as high-performance accelerators on clusters. In these settings, scheduling, communication and I/O are managed by generalpurpose processors (GPPs), while computation is off-loaded to AMPs. Design space exploration for the configuration and software stack of hybrid clusters of AMPs and GPPs is an open problem. In this paper, we explore this design space in an implementation of the popular MapReduce programming model. Our contributions are: An exploration of various design alternatives for hybrid asymmetric clusters of AMPs and GPPs; the adoption of a streaming \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:2VqYfGB8ITEC",
            "Publisher": "ACM"
        },
        {
            "Title": "SmartMaaS: a framework for smart manufacturing-as-a-service",
            "Publication year": 2019,
            "Publication url": "https://books.google.com/books?hl=en&lr=&id=_WOwDwAAQBAJ&oi=fnd&pg=PA16&dq=info:WjjjyC-J8EYJ:scholar.google.com&ots=Nj2Nwp5fic&sig=qRxZblHI4LTA_5EY8ZX_-Y2kknQ",
            "Abstract": "With the advancement of information and communication technology, manufacturing organisations are adopting digital manufacturing more than ever before. This gives rise to cloud-based manufacturing through which manufacturers can sell their production capabilities as an on-demand service termed as Manufacturing-as-a-Service (MaaS), instead of selling pre-defined products. Existing MaaS providers (eg online 3D printing providers) offer manufacturing customised products. But, customers have more demanding needs, such as rapid turnaround time, quality product, innovative design, etc. To meet such requirements, a Smart Manufacturing-as-a-Service (SmartMaaS) framework has been developed. In order to deliver efficient products at optimal cost, SmartMaaS can take smart actions such as negotiating with manufacturing centres (eg 3D printers) with respect to their availability, turnaround time, manufacturing cost, etc. In this paper, SmartMaaS is introduced and demonstrated via a prototype that is capable of accepting customers\u2019 product request in the form of \u201cdesign genes\u201d and manufacturing 3D printed products through an actor-based system.",
            "Abstract entirety": 1,
            "Author pub id": "PkCuYUQAAAAJ:2P1L_qKh6hAC",
            "Publisher": "IOS Press"
        },
        {
            "Title": "BDDT: block-level dynamic dependence analysisfor deterministic task-based parallelism",
            "Publication year": 2012,
            "Publication url": "https://dl.acm.org/doi/pdf/10.1145/2145816.2145864",
            "Abstract": "Task-parallel programming models [1, 4, 6] offer a more abstract, more structured way for expressing parallelism compared to threads. In these systems the programmer describes the parts of the program that can be computed in parallel, and does not have to manually create and manage the threads of execution. Such models still require the programmer to manually find and enforce any ordering or memory dependencies among tasks, and also maintain the inherent nondeterminism found in threads, which makes them hard to test and debug, as some executions might not be easy to reproduce. Implicitly parallel models [2, 5, 7, 8] further extend task-parallel models with automatic inference of dependencies; the programmer annotates the program [2, 3, 5, 8]; the system then discovers parallelization and manage dependencies transparently. Dynamic dependence analysis can discover more parallelism than is \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:4fKUyHm3Qg0C",
            "Publisher": "Unknown"
        },
        {
            "Title": "A transparent operating system infrastructure for embedding adaptability to thread-based programming models",
            "Publication year": 2001,
            "Publication url": "https://link.springer.com/chapter/10.1007/3-540-44681-8_75",
            "Abstract": "Parallel programs executing on non-dedicated SMPs should be adaptive, that is, they should be able to execute on a dynamically varying environment without loss of efficiency. This paper defines a unified set of services, implemented at the operating system level, which can be used to embed adaptability in any thread-based programming paradigm. These services meet simultaneously three goals: they are highly efficient; they are orthogonal and transparent to the multithreading programming model and its API; and they are non-intrusive, that is, they do not compromise the native operating system\u2019s resource management policies. The paper presents an implementation and evaluation of these services in the Linux kernel, using two popular multithreading programming systems, namely OpenMP and Cilk. Our experiments show that using these services in a multiprogrammed SMP yields a throughput \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:9ZlFYXVOiuMC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "Hybrid address spaces: A methodology for implementing scalable high-level programming models on non-coherent many-core architectures",
            "Publication year": 2014,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S0164121214001496",
            "Abstract": "This paper introduces hybrid address spaces as a fundamental design methodology for implementing scalable runtime systems on many-core architectures without hardware support for cache coherence. We use hybrid address spaces for an implementation of MapReduce, a programming model for large-scale data processing, and the implementation of a remote memory access (RMA) model. Both implementations are available on the Intel SCC and are portable to similar architectures. We present the design and implementation of HyMR, a MapReduce runtime system whereby different stages and the synchronization operations between them alternate between a distributed memory address space and a shared memory address space, to improve performance and scalability. We compare HyMR to a reference implementation and we find that HyMR improves performance by a factor of 1.71\u00d7 over a set of \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:08ZZubdj9fEC",
            "Publisher": "Elsevier"
        },
        {
            "Title": "DOE ECPI AWARD DE-FG02-05ER25689 FINAL TECHNICAL REPORT",
            "Publication year": 2006,
            "Publication url": "https://www.osti.gov/servlets/purl/908411",
            "Abstract": "The research conducted until 08/14/06 has led to the implementation of the MELISSES continuous performance profiler. More specifically, we have designed, implemented, robustified and released PACMAN (available at http://www. cs. wm. edu/pacman), an implementation of our continuous profiler which provides accurate hardware event counters on a thread-local basis, at sub-microsecond granularity on Intel Hyperthreaded processors. PACMAN has been used to implement a number of performance and power-related optimizations for multithreaded codes running on layered parallel architectures. The first successful demonstration of MELISSES capabilities was a profile-driven parallelization scheme for multithreaded codes, in each parallel regions was parallelized individually using either speculative precomputation with helper threads, or non-speculative thread-level parallelization. Regions that exhibit ample instruction-level parallelism with low memory access rates are parallelized with conventional TLP methods, whereas regions with limited instruction-level parallelism and high memory access rates are not parallelized. They are executed instead with speculative precomputation, which preexecutes long-latency memory accesses. MELISSES assists in locating the critical memory accesses that are responsible for most of memory latency and are offloaded for precomputation on helper threads. Runtime mechanisms and schemes for combining TLP with speculative precomputation via the use of MELISSES were presented in publications [6]. Another relevant publication [8] addressed the problem of devising effective speculative \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:buQ7SEKw-1sC",
            "Publisher": "The College of William and Mary"
        },
        {
            "Title": "Analysis of dependence tracking algorithms for task dataflow execution",
            "Publication year": 2013,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/2541228.2555316",
            "Abstract": "Processor architectures has taken a turn toward many-core processors, which integrate multiple processing cores on a single chip to increase overall performance, and there are no signs that this trend will stop in the near future. Many-core processors are harder to program than multicore and single-core processors due to the need for writing parallel or concurrent programs with high degrees of parallelism. Moreover, many-cores have to operate in a mode of strong scaling because of memory bandwidth constraints. In strong scaling, increasingly finer-grain parallelism must be extracted in order to keep all processing cores busy.Task dataflow programming models have a high potential to simplify parallel programming because they alleviate the programmer from identifying precisely all intertask dependences when writing programs. Instead, the task dataflow runtime system detects and enforces intertask \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:NMxIlDl6LWMC",
            "Publisher": "ACM"
        },
        {
            "Title": "Dependency-Aware Rollback and Checkpoint-Restart for Distributed Task-Based Runtimes",
            "Publication year": 2017,
            "Publication url": "https://arxiv.org/abs/1705.10208",
            "Abstract": "With the increase in compute nodes in large compute platforms, a proportional increase in node failures will follow. Many application-based checkpoint/restart (C/R) techniques have been proposed for MPI applications to target the reduced mean time between failures. However, rollback as part of the recovery remains a dominant cost even in highly optimised MPI applications employing C/R techniques. Continuing execution past a checkpoint (that is, reducing rollback) is possible in message-passing runtimes, but extremely complex to design and implement. Our work focuses on task-based runtimes, where task dependencies are explicit and message passing is implicit. We see an opportunity for reducing rollback for such runtimes: we explore task dependencies in the rollback, which we call dependency-aware rollback. We also design a new C/R technique, which is influenced by recursive decomposition of tasks, and combine it with dependency-aware rollback. We expect the dependency-aware rollback to cancel and recompute less tasks in the presence of node failures. We describe, implement and validate the proposed protocol in a simulator, which confirms these expectations. In addition, we consistently observe faster overall execution time for dependency-aware rollback in the presence of faults, despite the fact that reduced task cancellation does not guarantee reduced overall execution time.",
            "Abstract entirety": 1,
            "Author pub id": "PkCuYUQAAAAJ:eMMeJKvmdy0C",
            "Publisher": "Unknown"
        },
        {
            "Title": "SCoRPiO: Significance Based Computing for Reliability and Power Optimization",
            "Publication year": 2016,
            "Publication url": "https://pure.qub.ac.uk/en/publications/scorpio-significance-based-computing-for-reliability-and-power-op",
            "Abstract": "SCoRPiO: Significance Based Computing for Reliability and Power Optimization \u2014 Queen's \nUniversity Belfast Skip to main navigation Skip to search Skip to main content Queen's University \nBelfast Logo Help & FAQ Home Profiles Organisations Research output Projects Impact \nDatasets Activities Prizes Press / Media Student theses Facilities Search by expertise, name \nor affiliation SCoRPiO: Significance Based Computing for Reliability and Power Optimization \nVassilis Vassiliadis, Konstantinos Parasyris, Christos D. Antonopoulos, Nikolaos Bellas, Jan \nRiehme, Dimitrios Nikolopoulos School of Electronics, Electrical Engineering and Computer \nScience Institute of Electronics, Communications & Information Technology Research output: \nContribution to conference \u203a Poster \u203a peer-review Overview Projects (1) Original language \nEnglish Number of pages 1 Publication status Accepted - 18 Mar 2016 Event 2016 on Code ((\u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:V3AGJWp-ZtQC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Adaptive scheduling under memory pressure on multiprogrammed SMPs",
            "Publication year": 2002,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/1015481/",
            "Abstract": "We present a simple scheduling strategy that copes with the adverse effects of paging on multiprogrammed SMPs. We consider open, multiuser SMP servers, typically found in academic or industrial environments. Our strategy incorporates four uniquely combined features. It is adaptive, in the sense that the programs themselves take scheduling actions upon detecting memory pressure; it is dynamic, since programs detect the likelihood of paging at runtime by communicating with the operating system through a lightweight interface; it is preventive, because it takes scheduling actions before paging occurs; and it is non-intrusive, because the local scheduling actions taken by a program do not affect adversely, but act to the benefit of other programs sharing the system. We present an efficient implementation of our strategy in Linux and show with a realistic production workload that it can improve the response time of \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:L7CI7m0gUJcC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Modeling Multigrain Parallelism on Heterogeneous Multi-core Processors",
            "Publication year": 2007,
            "Publication url": "https://vtechworks.lib.vt.edu/handle/10919/19802",
            "Abstract": "Heterogeneous multi-core processors integrate conventional processing cores with computational accelerators. To maximize performance on these systems, programs must exploit multiple dimensions of parallelism simultaneously, including task-level and data-level parallelism. Unfortunately, parallel program designs with multiple dimensions of parallelism today are ad hoc, resulting in performance that depends heavily on the intuition and skill of the programmer. Formal techniques are needed to optimize parallel program designs. We propose a parallel computational model for steering multi-grain parallelization in heterogeneous multi-core processors. Our model accurately predicts the execution time and scalability of a program using multiple conventional processors and accelerators.  The model reveals optimal degrees of multi-dimensional, task-level and data-level concurrency in parallel programs. We use the model to derive mappings of two full computational phylogenetics applications on multi-processors featuring the IBM Cell Broadband Engine.",
            "Abstract entirety": 1,
            "Author pub id": "PkCuYUQAAAAJ:CHSYGLWDkRkC",
            "Publisher": "Department of Computer Science, Virginia Polytechnic Institute & State University"
        },
        {
            "Title": "Leveraging transparent data distribution in OpenMP via user-level dynamic page migration",
            "Publication year": 2000,
            "Publication url": "https://link.springer.com/chapter/10.1007/3-540-39999-2_40",
            "Abstract": "This paper describes transparent mechanisms for emulating some of the data distribution facilities offered by traditional data-parallel programming models, such as High Performance Fortran, in OpenMP. The vehicle for implementing these facilities in OpenMP without modifying the programming model or exporting data distribution details to the programmer is user-level dynamic page migration [9], [10]. We have implemented a runtime system called UPMlib, which allows the compiler to inject into the application a smart user-level page migration engine. The page migration engine improves transparently the locality of memory references at the page level on behalf of the application. This engine can accurately and timely establish effective initial page placement schemes for OpenMP programs. Furthermore, it incorporates mechanisms for tuning page placement across phase changes in the application \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:RHpTSmoSYBkC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "Scheduling algorithms with bus bandwidth considerations for SMPs",
            "Publication year": 2003,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/1240622/",
            "Abstract": "The bus that connects processors to memory is known to be a major architectural bottleneck in SMPs. However, both software and scheduling policies for these systems generally focus on memory hierarchy optimizations and do not address the bus bandwidth limitations directly. We first present experimental results which indicate that bus saturation can cause an up to almost three-fold slowdown to applications. Motivated by these results, we introduce two scheduling policies that take into account the bus bandwidth consumption of applications. The necessary information is provided by performance monitoring counters which are present in all modern processors. Our algorithms organize jobs so that processes with high-bandwidth and low-bandwidth demands are co-scheduled to improve bus bandwidth utilization without saturating the bus. We found that our scheduler is effective with applications of varying \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:HIFyuExEbWQC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Hybrid MPI/OpenMP power-aware computing",
            "Publication year": 2010,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/5470463/",
            "Abstract": "Power-aware execution of parallel programs is now a primary concern in large-scale HPC environments. Prior research in this area has explored models and algorithms based on dynamic voltage and frequency scaling (DVFS) and dynamic concurrency throttling (DCT) to achieve power-aware execution of programs written in a single programming model, typically MPI or OpenMP. However, hybrid programming models combining MPI and OpenMP are growing in popularity as emerging large-scale systems have many nodes with several processors per node and multiple cores per process or. In th is paper we present and evaluate solutions for power-efficient execution of programs written in this hybrid model targeting large-scale distributed systems with multicore nodes. We use a new power-aware performance prediction model of hybrid MPI/OpenMP applications to derive a novel algorithm for power-efficient \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:NyGDZy8z5eUC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Exploiting significance of computations for energy-constrained approximate computing",
            "Publication year": 2016,
            "Publication url": "https://link.springer.com/article/10.1007/s10766-016-0409-6",
            "Abstract": "Approximate execution is a viable technique for environments with energy constraints, provided that applications are given the mechanisms to produce outputs of the highest possible quality within the available energy budget. This paper introduces a framework for energy-constrained execution with controlled and graceful quality loss. A simple programming model allows developers to structure the computation in different tasks, and to express the relative importance of these tasks for the quality of the end result. For non-significant tasks, the developer can also supply less costly, approximate versions. The target energy consumption for a given execution is specified when the application is launched. A significance-aware runtime system employs an application-specific analytical energy model to decide how many cores to use for the execution, the operating frequency for these cores, as well as the degree of \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:ipzZ9siozwsC",
            "Publisher": "Springer US"
        },
        {
            "Title": "On the potential of significance-driven execution for energy-aware HPC",
            "Publication year": 2015,
            "Publication url": "https://link.springer.com/article/10.1007%252Fs00450-014-0265-9",
            "Abstract": "Dynamic voltage and frequency scaling (DVFS) exhibits fundamental limitations as a method to reduce energy consumption in computing systems. In the HPC domain, where performance is of highest priority and codes are heavily optimized to minimize idle time, DVFS has limited opportunity to achieve substantial energy savings. This paper explores if operating processors near the transistor threshold voltage (NTV) is a better alternative to DVFS for breaking the power wall in HPC. NTV presents challenges, since it compromises both performance and reliability to reduce power consumption. We present a first of its kind study of a significance-driven execution paradigm that selectively uses NTV and algorithmic error tolerance to reduce energy consumption in performance-constrained HPC environments. Using an iterative algorithm as a use case, we present an adaptive execution scheme that switches \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:MLfJN-KU85MC",
            "Publisher": "Springer Berlin Heidelberg"
        },
        {
            "Title": "Supporting Data-Intensive Applications on Accelerator-Based Distributed Systems",
            "Publication year": 2009,
            "Publication url": "https://www.usenix.org/event/fast09/wips_posters/rafique_poster.pdf",
            "Abstract": "Problem Statement. Multi-core processors can now package several general-purpose processors (GPPs)(eg x86, PowerPC) and computational accelerators (eg SIMD processors and GPUs), yielding highly power-efficient and costefficient designs, with performance exceeding 100 Gflops. These asymmetric accelerator-based processors are rapidly becoming commodity components for high-performance computing, and this trend makes them a viable substitute of less cost-effective alternatives in large-scale clusters. However, the state of knowledge on the use of accelerator-based multi-core processors on large-scale clusters, specially for data-intensive applications, is limited. Current approaches for designing and programming on such clusters are either ad hoc or specific to an installation [1], thus posing several challenges when applied to general setups. First, the effects of alternative workload distributions between GPPs and accelerators are not well understood. Second, accelerators have limited capabilities for managing external system resources, such as communication and I/O devices, thus requiring support from GPPs and special consideration while designing the resource management software. Finally, suitable programming models that adapt to the varying capabilities of the accelerator-type components have not been developed, forcing application writers to micro-manage resources and use platform-specific programming techniques.Approach. We address these challenges by designing and evaluating alternative asymmetric, accelerator-based cluster configurations for supporting data-intensive applications. We characterize our \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:yMeIxYmEMEAC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Big data availability: Selective partial checkpointing for in-memory database queries",
            "Publication year": 2016,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/7840926/",
            "Abstract": "Fault tolerance is an important challenge for supporting critical big data analytic operations. Most existing solutions only provide fault tolerant data replication, requiring failed queries to be restarted. This approach is insufficient for long-running time-sensitive analytic queries, due to lost query progress. Several solutions provide intra-query fault tolerance. However, these focus on distributed or row-oriented databases and are not suitable for use with the column-oriented in-memory databases increasingly used for highperformance workloads. We propose a new approach for intra-query checkpointing that produces an optimal checkpoint solution for a fixed checkpointing budget to minimise overhead on in-memory column-oriented database clusters. We describe a modified architecture for fault tolerant query execution using this approach. We present a general model for the problem, in which an adversary is free to \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:WA5NYHcadZ8C",
            "Publisher": "IEEE"
        },
        {
            "Title": "Expediting assessments of database performance for streams of respiratory parameters",
            "Publication year": 2018,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S0010482518301410",
            "Abstract": "A new methodology is proposed to compare database performance for streams of patient respiratory data from patients in an intensive care unit. New metrics are proposed through which databases may be compared both for this and similar streaming applications in the domain of the Internet of Things. Studies are reported using simulated patient data for four freely available databases. The statistical technique of non-parametric bootstrapping is used to minimise the total running time of the tests. We report mean values and bias corrected and accelerated confidence intervals for each metric and use these to compare the databases. We find that, among the four databases tested, ScaleDB is an optimum database technology when handling between 200 and 800 patients in this application, while PostgreSQL performs best outside of this range. Comparing the non-parametric bootstrapping method to a complete set of \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:Ug5p-4gJ2f0C",
            "Publisher": "Pergamon"
        },
        {
            "Title": "Using Docker Swarm with a User-Centric Decision-Making Framework for Cloud Application Migration",
            "Publication year": 2018,
            "Publication url": "https://books.google.com/books?hl=en&lr=&id=zAFkDwAAQBAJ&oi=fnd&pg=PA81&dq=info:Zwezxcsi6I0J:scholar.google.com&ots=8I2cSqTvjs&sig=O9XwLdwm3ikL0qUDJl17Jt4E5rk",
            "Abstract": "Vendor lock-in is a major obstacle for cloud users in performing multi-cloud deployment or inter-cloud migration, due to the lack of standardization. Current research efforts tackling the inter-cloud migration problem are commonly technology-oriented with significant performance overheads. Moreover, current studies do not provide adequate support for decision making such as why and when inter-cloud migration should take place. We propose the architecture and the problem formulation of a Multi-objective dYnamic MIgratioN Decision makER (MyMinder) framework that assists cloud users in achieving a stable QoS performance in the post-deployment phase by helping decide on actions to be taken as well as providing support to achieve such actions. Additionally, we demonstrate the migration capability of MyMinder by proposing an Automated Triggering Algorithm (ATA), which uses existing Docker Swarm technology for application migration.",
            "Abstract entirety": 1,
            "Author pub id": "PkCuYUQAAAAJ:ZuybSZzF8UAC",
            "Publisher": "Springer"
        },
        {
            "Title": "A study of implicit data distribution methods for OpenMP using the SPEC benchmarks",
            "Publication year": 2001,
            "Publication url": "https://link.springer.com/chapter/10.1007/3-540-44587-0_11",
            "Abstract": "In contrast to the common belief that OpenMP requires data-parallel extensions to scale well on architectures with non-uniform memory access latency, recent work has shown that it is possible to develop OpenMP programs with good levels of memory access locality, without any extension of the OpenMP API. The vehicle for localizing memory accesses transparently to the programming model, is a runtime memory manager, which uses memory access tracing and dynamic page migration to implement automatic data distribution. This paper evaluates the effectiveness of using this runtime data distribution method in non embarrassingly parallel codes, such as the SPEC benchmarks. We investigate the extent up to which sophisticated management of physical memory in the runtime system can speedup programs for which the programmer has no knowledge of the memory access pattern. Our runtime \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:N5tVd3kTz84C",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "Cross Architectural Power Modelling",
            "Publication year": 2020,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/9139694/",
            "Abstract": "Existing power modelling research focuses on the model rather than the process for developing models. An automated power modelling process that can be deployed on different processors for developing power models with high accuracy is developed. For this, (i) an automated hardware performance counter selection method that selects counters best correlated to power on both ARM and Intel processors, (ii) a noise filter based on clustering that can reduce the mean error in power models, and (iii) a two stage power model that surmounts challenges in using existing power models across multiple architectures are proposed and developed. The key results are: (i) the automated hardware performance counter selection method achieves comparable selection to the manual method reported in the literature, (ii) the noise filter reduces the mean error in power models by up to 55%, and (iii) the two stage power model \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:eJXPG6dFmWUC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Cellmr: A framework for supporting mapreduce on asymmetric cell-based clusters",
            "Publication year": 2009,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/5161062/",
            "Abstract": "The use of asymmetric multi-core processors with on-chip computational accelerators is becoming common in a variety of environments ranging from scientific computing to enterprise applications. The focus of current research has been on making efficient use of individual systems, and porting applications to asymmetric processors. In this paper, we take the next step by investigating the use of multi-core-based systems, especially the popular Cell processor, in a cluster setting. We present CellMR, an efficient and scalable implementation of the MapReduce framework for asymmetric Cell-based clusters. The novelty of CellMR lies in its adoption of a streaming approach to supporting MapReduce, and its adaptive resource scheduling schemes: Instead of allocating workloads to the components once, CellMR slices the input into small work units and streams them to the asymmetric nodes for efficient processing \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:WqliGbK-hY8C",
            "Publisher": "IEEE"
        },
        {
            "Title": "Deterministic scale-free pipeline parallelism with hyperqueues",
            "Publication year": 2013,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/6877465/",
            "Abstract": "Ubiquitous parallel computing aims to make parallel programming accessible to a wide variety of programming areas using deterministic and scale-free programming models built on a task abstraction. However, it remains hard to reconcile these attributes with pipeline parallelism, where the number of pipeline stages is typically hard-coded in the program and defines the degree of parallelism. This paper introduces hyperqueues, a programming abstraction that enables the construction of deterministic and scale-free pipeline parallel programs. Hyperqueues extend the concept of Cilk++ hyperobjects to provide thread-local views on a shared data structure. While hyperobjects are organized around private local views, hyperqueues require shared concurrent views on the underlying data structure. We define the semantics of hyperqueues and describe their implementation in a work-stealing scheduler. We \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:RYcK_YlVTxYC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Power-capped DVFS and thread allocation with ANN models on modern NUMA systems",
            "Publication year": 2014,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/6974701/",
            "Abstract": "Power capping is an essential function for efficient power budgeting and cost management on modern server systems. Contemporary server processors operate under power caps by using dynamic voltage and frequency scaling (DVFS). However, these processors are often deployed in non-uniform memory access (NUMA) architectures, where thread allocation between cores may significantly affect performance and power consumption. This paper proposes a method which maximizes performance under power caps on NUMA systems by dynamically optimizing two knobs: DVFS and thread allocation. The method selects the optimal combination of the two knobs with models based on artificial neural network (ANN) that captures the nonlinear effect of thread allocation on performance. We implement the proposed method as a runtime system and evaluate it with twelve multithreaded benchmarks on a real AMD \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:5Ul4iDaHHb8C",
            "Publisher": "IEEE"
        },
        {
            "Title": "Shimmer: Implementing a heterogeneous-reliability dram framework on a commodity server",
            "Publication year": 2019,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/8613828/",
            "Abstract": "In this paper, we present the implementation of a heterogeneous-reliability DRAM framework, Shimmer, on a commodity server with a fully fledged OS. Shimmer enables splitting of DRAM into multiple domains with varying reliability and allocation of data depending on their criticality. Compared to existing studies which use simulators, we consider practical restrictions stemming from the real hardware and investigate methods to overcome them. In particular, we reveal that the implementation of the heterogeneous-reliability memory framework requires disabling of the hardware memory interleaving, which results in a significant degradation of the system performance. To overcome the induced performance loss, we develop a software-based interleaving. We evaluate the performance, power and energy of the server using 35 benchmarks across three memory configurations: the baseline configuration; with disabled \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:q3oQSFYPqjQC",
            "Publisher": "IEEE"
        },
        {
            "Title": "A Significance-Driven Programming Framework for Energy-Constrained Approximate Computing",
            "Publication year": 2015,
            "Publication url": "https://pureadmin.qub.ac.uk/ws/files/17173230/main.pdf",
            "Abstract": "Approximate execution is a viable technique for energy-constrained environments, provided that applications have the mechanisms to produce outputs of the highest possible quality within the given energy budget.We introduce a framework for energy-constrained execution with controlled and graceful quality loss. A simple programming model allows users to express the relative importance of computations for the quality of the end result, as well as minimum quality requirements. The significance-aware runtime system uses an application-specific analytical energy model to identify the degree of concurrency and approximation that maximizes quality while meeting user-specified energy constraints. Evaluation on a dual-socket 8-core server shows that the proposed framework predicts the optimal configuration with high accuracy, enabling energy-constrained executions that result in significantly higher quality compared to loop perforation, a compiler approximation technique.",
            "Abstract entirety": 1,
            "Author pub id": "PkCuYUQAAAAJ:yD5IFk8b50cC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Accelerating graph analytics by utilising the memory locality of graph partitioning",
            "Publication year": 2017,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/8025292/",
            "Abstract": "This paper investigates how to improve the memory locality of graph-structured analytics on large-scale shared memory systems. We demonstrate that a graph partitioning where all in-edges for a vertex are placed in the same partition improves memory locality. However, realising performance improvement through such graph partitioning poses several challenges and requires rethinking the classification of graph algorithms and preferred data structures. We introduce the notion of medium dense frontiers, a type of frontier that is sufficiently dense for a bitmap representation, yet benefits from an indexed graph layout. Using three types of frontiers, and three graph layout schemes optimized to each frontier type, we design an edge traversal algorithm that autonomously decides which type to use. The distinction of forward vs. backward graph traversal folds into this decision and need no longer be specified by the \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:0N-VGjzr574C",
            "Publisher": "IEEE"
        },
        {
            "Title": "Raxml-cell: Parallel phylogenetic tree inference on the cell broadband engine",
            "Publication year": 2007,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/4227995/",
            "Abstract": "Computational phylogeny is a challenging application even for the most powerful supercomputers. It is also an ideal candidate for benchmarking emerging multiprocessor architectures, because it exhibits fine- and coarse-grain parallelism at multiple levels. In this paper, we present the porting, optimization, and evaluation of RAxML on the cell broadband engine. RAxML is a provably efficient, hill climbing algorithm for computing phylogenetic trees, based on the maximum likelihood (ML) method. The cell broadband engine, a heterogeneous multi-core processor with SIMD accelerators which was initially marketed for set-top boxes, is currently being deployed on supercomputers and high-end server architectures. We present both conventional and unconventional, cell-specific optimizations for RAxML's search algorithm on a real cell multiprocessor. While exploring these optimizations, we present solutions to \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:kuK5TVdYjLIC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Operator and Workflow Optimization for High-Performance Analytics.",
            "Publication year": 2016,
            "Publication url": "https://core.ac.uk/download/pdf/33593436.pdf",
            "Abstract": "We make a case for studying the impact of intra-node parallelism on the performance of data analytics. We identify four performance optimizations that are enabled by an increasing number of processing cores on a chip. We discuss the performance impact of these opimizations on two analytics operators and we identify how these optimizations affect each another.",
            "Abstract entirety": 1,
            "Author pub id": "PkCuYUQAAAAJ:738O_yMBCRsC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Scheduling Algorithms with Bus",
            "Publication year": 2006,
            "Publication url": "Unknown",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "PkCuYUQAAAAJ:j7_hQOaDUrUC",
            "Publisher": "Wiley-Interscience"
        },
        {
            "Title": "A unified scheduler for recursive and task dataflow parallelism",
            "Publication year": 2011,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/6113783/",
            "Abstract": "Task dataflow languages simplify the specification of parallel programs by dynamically detecting and enforcing dependencies between tasks. These languages are, however, often restricted to a single level of parallelism. This language design is reflected in the runtime system, where a master thread explicitly generates a task graph and worker threads execute ready tasks and wake-up their dependents. Such an approach is incompatible with state-of-the-art schedulers such as the Cilk scheduler, that minimize the creation of idle tasks (work-first principle) and place all task creation and scheduling off the critical path. This paper proposes an extension to the Cilk scheduler in order to reconcile task dependencies with the work-first principle. We discuss the impact of task dependencies on the properties of the Cilk scheduler. Furthermore, we propose a low-overhead ticket-based technique for dependency tracking and \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:vDijr-p_gm4C",
            "Publisher": "IEEE"
        },
        {
            "Title": "Online power-performance adaptation of multithreaded programs using hardware event-based prediction",
            "Publication year": 2006,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/1183401.1183426",
            "Abstract": "With high-end systems featuring multicore/multithreaded processors and high component density, power-aware high-performance multithreading libraries become a critical element of the system software stack. Online power and performance adaptation of multithreaded code from within user-level runtime libraries is a relatively new and unexplored area of research. We present a user-level library framework for nearly optimal online adaptation of multithreaded codes for low-power, high-performance execution. Our framework operates by regulating concurrency and changing the processors/threads configuration as the program executes. It is innovative in that it uses fast, runtime performance prediction derived from hardware event-driven profiling, to select thread granularities that achieve nearly optimal energy-efficiency points. The use of predictors substantially reduces the runtime cost of granularity control and \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:1yQoGdGgb4wC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Achieving Multiprogramming Scalability of Parallel Programs on Intel SMP Platforms: Nanothreading in the Linux Kernel",
            "Publication year": 2000,
            "Publication url": "https://www.worldscientific.com/doi/abs/10.1142/9781848160170_0074",
            "Abstract": "This paper presents the design and implementation of a nanothreading interface in the kernel of the Linux operating system for Intel Architecture-based symmetric multiprocessors. The objective of the nanothreading interface is to achieve robust performance of multithreaded programs and increased throughput in multiprogrammed shared memory multiprocessors, where multiple parallel and sequential programs with diverge characteristics and resource requirements execute simultaneously. The interface lets a multithreading runtime system and the kernel exchange critical scheduling information through loads and stores in shared memory, in order to enable parallel programs to adapt to dynamically changing resources and minimize their idle time. The same interface enhances the capability of the kernel scheduler to allocate resources evenly between competing programs. We discuss the main design and \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:NaGl4SEjCO4C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Scheduler-activated dynamic page migration for multiprogrammed DSM multiprocessors",
            "Publication year": 2002,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S0743731501918179",
            "Abstract": "The performance of multiprogrammed shared-memory multiprocessors suffers often from scheduler interventions that neglect data locality. On cache-coherent distributed shared-memory (DSM) multiprocessors, such scheduler interventions tend to increase the rate of remote memory accesses. This paper presents a novel dynamic page migration algorithm that remedies this problem in iterative parallel programs. The purpose of the algorithm is the early detection of pages that will most likely be accessed remotely by threads associated with them via a thread-to-memory affinity relation. The key mechanism that enables timely identification of these pages is a communication interface between the page migration engine and the operating system scheduler. The algorithm improves previously proposed competitive page migration algorithms in many aspects, including accuracy, timeliness and cost amortization. Most \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:UHK10RUVsp4C",
            "Publisher": "Academic Press"
        },
        {
            "Title": "Code and data transformations for improving shared cache performance on SMT processors",
            "Publication year": 2003,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-540-39707-6_5",
            "Abstract": "Simultaneous multithreaded processors use shared on-chip caches, which yield better cost-performance ratios. Sharing a cache between simultaneously executing threads causes excessive conflict misses. This paper proposes software solutions for dynamically partitioning the shared cache of an SMT processor, via the use of three methods originating in the optimizing compilers literature: dynamic tiling, copying and block data layouts. The paper presents an algorithm that combines these transformations and two runtime mechanisms to detect cache sharing between threads and react to it at runtime. The first mechanism uses minimal kernel extensions and the second mechanism uses information collected from the processor hardware counters. Our experimental results show that for regular, perfect loop nests, these transformations are very effective in coping with shared caches. When the caches are \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:XiSMed-E-HIC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "The vineyard approach: Versatile, integrated, accelerator-based, heterogeneous data centres",
            "Publication year": 2016,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-319-30481-6_1",
            "Abstract": "Emerging web applications like cloud computing, Big Data and social networks have created the need for powerful centres hosting hundreds of thousands of servers. Currently, the data centres are based on general purpose processors that provide high flexibility buts lack the energy efficiency of customized accelerators. VINEYARD aims to develop an integrated platform for energy-efficient data centres based on new servers with novel, coarse-grain and fine-grain, programmable hardware accelerators. It will, also, build a high-level programming framework for allowing end-users to seamlessly utilize these accelerators in heterogeneous computing systems by employing typical data-centre programming frameworks (e.g. MapReduce, Storm, Spark, etc.). This programming framework will, further, allow the hardware accelerators to be swapped in and out of the heterogeneous infrastructure so as to offer high \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:edDO8Oi4QzsC",
            "Publisher": "Springer, Cham"
        },
        {
            "Title": "Critical path-based thread placement for NUMA systems",
            "Publication year": 2012,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/2381056.2381079",
            "Abstract": "Multicore multiprocessors use a Non Uniform Memory Architecture (NUMA) to improve their scalability. However, NUMA introduces performance penalties due to remote memory accesses. Without efficiently managing data layout and thread mapping to cores, scientific applications may suffer performance loss, even if they are optimized for NUMA. In this paper, we present algorithms and a runtime system that optimize the execution of OpenMP applications on NUMA architectures. By collecting information from hardware counters, the runtime system directs thread placement and reduces performance penalties by minimizing the critical path of OpenMP parallel regions. The runtime system uses a scalable algorithm that derives placement decisions with negligible overhead. We evaluate our algorithms and the runtime system with four NPB applications implemented in OpenMP. On average the algorithms achieve \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:_Ybze24A_UAC",
            "Publisher": "ACM"
        },
        {
            "Title": "TProf: An energy profiler for task-parallel programs",
            "Publication year": 2015,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S2210537914000390",
            "Abstract": "We present TProf, an energy profiling tool for OpenMP-like task-parallel programs. To compute the energy consumed by each task in a parallel application, TProf dynamically traces the parallel execution and uses a novel technique to estimate the per-task energy consumption. To achieve this estimation, TProf apportions the total processor energy among cores and overcomes the limitation of current works which would otherwise make parallel accounting impossible to achieve. We demonstrate the value of TProf by characterizing a set of task parallel programs, where we find that data locality, memory access patterns and task working sets are responsible for significant variance in energy consumption between seemingly homogeneous tasks. In addition, we identify opportunities for fine-grain energy optimization by applying per-task Dynamic Voltage and Frequency Scaling (DVFS).",
            "Abstract entirety": 1,
            "Author pub id": "PkCuYUQAAAAJ:e5wmG9Sq2KIC",
            "Publisher": "Elsevier"
        },
        {
            "Title": "Prediction models for multi-dimensional power-performance optimization on many cores",
            "Publication year": 2008,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/1454115.1454151",
            "Abstract": "Power has become a primary concern for HPC systems. Dynamic voltage and frequency scaling (DVFS) and dynamic concurrency throttling (DCT) are two software tools (or knobs) for reducing the dynamic power consumption of HPC systems. To date, few works have considered the synergistic integration of DVFS and DCT in performance-constrained systems, and, to the best of our knowledge, no prior research has developed application-aware simultaneous DVFS and DCT controllers in real systems and parallel programming frameworks. We present a multi-dimensional, online performance predictor, which we deploy to address the problem of simultaneous runtime optimization of DVFS and DCT on multi-core systems. We present results from an implementation of the predictor in a runtime library linked to the Intel OpenMP environment and running on an actual dual-processor quad-core system. We show that \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:j8SEvjWlNXcC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Using machine descriptors to select parallelization models and strategies on hierarchical systems",
            "Publication year": 2001,
            "Publication url": "https://core.ac.uk/download/pdf/10082841.pdf",
            "Abstract": "Copyright for the publications made accessible via the Queen's University Belfast Research Portal is retained by the author (s) and/or other copyright owners and it is a condition of accessing these publications that users recognise and abide by the legal requirements associated with these rights.",
            "Abstract entirety": 1,
            "Author pub id": "PkCuYUQAAAAJ:umqufdRvDiIC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Energy-efficient iterative refinement using dynamic precision",
            "Publication year": 2018,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/8395429/",
            "Abstract": "Mixed precision is a promising approach to save energy in iterative refinement algorithms since it obtains speed-up without necessitating additional cores and parallelization. However, conventional mixed precision methods utilize statically defined precision in a loop, thus hindering further speed-up and energy savings. We overcome this problem by proposing novel methods which allow iterative refinement to utilize variable precision arithmetic dynamically in a loop (i.e., a trans-precision approach). Our methods restructure a numeric algorithm dynamically according to runtime numeric behavior and remove unnecessary accuracy checks. We implemented our methods by extending one conventional mixed precision iterative refinement algorithm on an Intel Xeon E5-2650 2GHz core with MKL 2017 and XBLAS 1.0. Our dynamic precision approach demonstrates 2.0-2.6\u00d7 speed-up and 1.8-2.4\u00d7 energy savings \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:dhFuZR0502QC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Energy-Efficient Transprecision Techniques for Iterative Refinement",
            "Publication year": 2017,
            "Publication url": "https://pureadmin.qub.ac.uk/ws/portalfiles/portal/135660665/sc_poster_draft_final.pdf",
            "Abstract": "This paper presents transprecision techniques for iterative refinement, which utilize various precision arithmetic dynamically according to numeric properties of the algorithm and computational latencies depending on precisions. The transprecision techniques were plugged into a mixed precision iterative refinement on an Intel Xeon E5-2650 2GHz core with MKL 2017 and XBLAS 1.0. The transprecision techniques brought further 2.0-3.4 X speedups and 3.0-4.1 X energy reductions to a mixed precision iterative refinement when double precision solution accuracy was required for forward error and a matrix size was ranged from 4K to 32K.",
            "Abstract entirety": 1,
            "Author pub id": "PkCuYUQAAAAJ:rmuvC79q63oC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Myrmics: A scalable runtime system for global address spaces",
            "Publication year": 2013,
            "Publication url": "http://publications.ics.forth.gr/tech-reports/2013/2013.TR436_Myrmics_Scalable_Runtime_System_Global_Address_Spaces.pdf",
            "Abstract": "For the first decades of the semiconductor industry, processor chips had a single CPU core. Processor architecture evolved gradually to include many features that extracted instructionlevel parallelism from serial programs. Both the micro-architectural feature addition and the CPU performance scaling were feasible due to the technology scaling: each new technology node offered more chip area and faster transistors for a reduced price. After the first years of the 21st century, diminished returns of clock rate scaling and power challenges put an end to the single-core performance race [65]. While technology nodes still scale by Moore\u2019s law, the industry now exploits the exponential increase of transistors to integrate multiple CPU cores on a single processor, while the individual clock rates of each core remain constant at a few (2\u20134) GHz. To harness the increased aggregate performance of the multicore processors to run a single application faster, the programmer must use a parallel programming model so that parts of the application run on multiple CPU cores. Writing parallel applications efficiently is generally considered a very difficult problem [6]. The main challenges are that (i) the majority of software developers are experts on sequential programming, and many of them are not able to grasp the details of concurrent software and parallel hardware,(ii) compilers and operating system are large, unwieldy and resistant to change and thus slow to adopt efficient parallel concepts, and (iii) the multitude of new parallel programming languages makes it difficult to measure improvement, as researchers are often the ones deciding what they think would \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:sJsF-0ZLhtgC",
            "Publisher": "Unknown"
        },
        {
            "Title": "NanoStreams: Advancing the hardware and software stack for real-time analytics on fast data streams",
            "Publication year": 2014,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/7058143/",
            "Abstract": "NanoStreams is a consortium project funded by the European Commission under its FP7 programme and is a major effort to address the challenges of processing vast amounts of data in real-time, with a markedly lower carbon footprint than the state of the art. The project addresses both the energy challenge and the high-performance required by emerging applications in real-time streaming data analytics. NanoStreams achieves this goal by designing and building disruptive micro-server solutions incorporating real-silicon prototype micro-servers based on System-on-Chip and reconfigurable hardware technologies.",
            "Abstract entirety": 1,
            "Author pub id": "PkCuYUQAAAAJ:dshw04ExmUIC",
            "Publisher": "IEEE"
        },
        {
            "Title": "ALEA: A fine-grained energy profiling tool",
            "Publication year": 2017,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/3050436",
            "Abstract": "Energy efficiency is becoming increasingly important, yet few developers understand how source code changes affect the energy and power consumption of their programs. To enable them to achieve energy savings, we must associate energy consumption with software structures, especially at the fine-grained level of functions and loops. Most research in the field relies on direct power/energy measurements taken from on-board sensors or performance counters. However, this coarse granularity does not directly provide the needed fine-grained measurements. This article presents ALEA, a novel fine-grained energy profiling tool based on probabilistic analysis for fine-grained energy accounting. ALEA overcomes the limitations of coarse-grained power-sensing instruments to associate energy information effectively with source code at a fine-grained level. We demonstrate and validate that ALEA can perform \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:0KyAp5RtaNEC",
            "Publisher": "ACM"
        },
        {
            "Title": "DEFCON: generating and detecting failure-prone instruction sequences via stochastic search",
            "Publication year": 2020,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/9116363/",
            "Abstract": "The increased variability and adopted low supply voltages render nanometer devices prone to timing failures, which threaten the functionality of digital circuits. Recent schemes focused on developing instruction-aware failure prediction models and adapting voltage/frequency to avoid errors while saving energy. However, such schemes may be inaccurate when applied to pipelined cores since they consider only the currently executed instruction and the preceding one, thereby neglecting the impact of all the concurrently executing instructions on failure occurrence. In this paper, we first demonstrate that the order and type of instructions in sequences with a length equal to the pipeline depth affect significantly the failure rate. To overcome the practically impossible evaluation of the impact of all possible sequences on failures, we present DEFCON, a fully automated framework that stochastically searches for the most \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:NXb4pA-qfm4C",
            "Publisher": "IEEE"
        },
        {
            "Title": "Bio-inspired growth: introducing emergence into computational design",
            "Publication year": 2019,
            "Publication url": "https://ebooks.iospress.nl/volumearticle/52637",
            "Abstract": "In today\u2019s age of neural networks and brain study, creativity is being introduced into lifeless systems by modelling the concept of learning. Many believe the artificial intelligence that is leading technology will eventually do most of a designer\u2019s work. However, this artificial intelligence only results after long hours of training and is limited to the area within which it is trained. In nature, many systems can produce unpredictable solutions without the retention of information\u2013such as trees. Although computers cannot accurately model nature\u2019s growth mechanisms, it can be approximated with the concept of predictive non-determinism\u2013where what is not understood is treated as random\u2013and the rest of the system built around this. This paper lays out a four-tiered structure, inspired by growth principles seen in nature, for introducing emergence into the design system. The models presented are grown by random functions \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:b1wdh0AR-JQC",
            "Publisher": "IOS Press"
        },
        {
            "Title": "A comparison of programming models for multiprocessors with explicitly managed memory hierarchies",
            "Publication year": 2009,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/1504176.1504197",
            "Abstract": "On multiprocessors with explicitly managed memory hierarchies (EMM), software has the responsibility of moving data in and out of fast local memories. This task can be complex and error-prone even for expert programmers. Before we can allow compilers to handle this complexity for us, we must identify the abstractions that are general enough to allow us to write applications with reasonable effort, yet specific enough to exploit the vast on-chip memory bandwidth of EMM multi-processors. To this end, we compare two programming models against hand-tuned codes on the STI Cell, paying attention to programmability and performance. The first programming model, Sequoia, abstracts the memory hierarchy as private address spaces, each corresponding to a parallel task. The second, Cellgen, is a new framework which provides OpenMP-like semantics and the abstraction of a shared address space divided into \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:mNrWkgRL2YcC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Identifying energy-efficient concurrency levels using machine learning",
            "Publication year": 2007,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/4629274/",
            "Abstract": "Multicore microprocessors have been largely motivated by the diminishing returns in performance and the increased power consumption of single-threaded ILP microprocessors. With the industry already shifting from multicore to many-core microprocessors, software developers must extract more thread-level parallelism from applications. Unfortunately, low power-efficiency and diminishing returns in performance remain major obstacles with many cores. Poor interaction between software and hardware, and bottlenecks in shared hardware structures often prevent scaling to many cores, even in applications where a high degree of parallelism is potentially available. In some cases, throwing additional cores at a problem may actually harm performance and increase power consumption. Better use of otherwise limitedly beneficial cores by software components such as hypervisors and operating systems can improve \u2026",
            "Abstract entirety": 0,
            "Author pub id": "PkCuYUQAAAAJ:tuHXwOkdijsC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Energy Optimization of Parallel Programs on Unreliable Hardware",
            "Publication year": 2016,
            "Publication url": "https://core.ac.uk/download/pdf/33592017.pdf",
            "Abstract": "We present a work in progress report on the problem of minimizing the energy consumption of a parallel application on an unreliable hardware platform, specifically unreliable memory. In such a system, not all of the application data in memory is accurate at all the times. Allowing some inaccuracies in the data saves memory refresh power at the cost of increased inaccuracy which in many application domains can be dealt with algorithmic error resilience. We are building an analytical model to capture the CPU energy consumption of a parallel application with precedence constraints running on a system with unreliable memory. Using this model, we plan to provide a framework for analytically selecting CPU frequencies that minimize the overall CPU energy consumption of the application.",
            "Abstract entirety": 1,
            "Author pub id": "PkCuYUQAAAAJ:q3CdL3IzO_QC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Scalable locality-conscious multithreaded memory allocation",
            "Publication year": 2006,
            "Publication url": "Unknown",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "PkCuYUQAAAAJ:u9iWguZQMMsC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Performance and fault tolerance of preconditioned iterative solvers on low-power arm architectures",
            "Publication year": 2016,
            "Publication url": "https://ebooks.iospress.nl/volumearticle/42718",
            "Abstract": "As the complexity of computing systems grows, reliability and energy are two crucial challenges that will demand holistic solutions. In this paper, we investigate the interplay among concurrency, power dissipation, energy consumption and voltage-frequency scaling for a key numerical kernel for the solution of sparse linear systems. Concretely, we leverage a task-parallel implementation of the Conjugate Gradient method, equipped with an state-of-the-art preconditioner embedded in the ILUPACK software, and target a low-power multicore processor from ARM. In addition, we perform a theoretical analysis on the impact of a technique like Near Threshold Voltage Computing (NTVC) from the points of view of increased hardware concurrency and error rate.",
            "Abstract entirety": 1,
            "Author pub id": "PkCuYUQAAAAJ:xtoqd-5pKcoC",
            "Publisher": "IOS Press"
        }
    ]
}]