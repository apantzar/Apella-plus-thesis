[{
    "name": "\u0391\u03bd\u03c4\u03ce\u03bd\u03b9\u03bf\u03c2 \u0391\u03c1\u03b3\u03c5\u03c1\u03cc\u03c2 ",
    "romanize name": "Antonios Argyros ",
    "School-Department": "\u0395\u03c0\u03b9\u03c3\u03c4\u03ae\u03bc\u03b7\u03c2 \u03a5\u03c0\u03bf\u03bb\u03bf\u03b3\u03b9\u03c3\u03c4\u03ce\u03bd",
    "University": "uoc",
    "Rank": "\u039a\u03b1\u03b8\u03b7\u03b3\u03b7\u03c4\u03ae\u03c2",
    "Apella_id": 18605,
    "Scholar name": "Antonis Argyros",
    "Scholar id": "9OieklkAAAAJ",
    "Affiliation": "Computer Science Department, University of Crete (csd.uoc.gr) & ICS-FORTH (ics.forth.gr), Greece",
    "Citedby": 9005,
    "Interests": [
        "Computer Vision",
        "Robot Vision",
        "Human Computer Interaction",
        "Robotics"
    ],
    "Scholar url": "https://scholar.google.com/citations?user=9OieklkAAAAJ&hl=en",
    "Publications": [
        {
            "Title": "FaceGuard: A Wearable System To Avoid Face Touching",
            "Publication year": 2021,
            "Publication url": "https://www.frontiersin.org/articles/10.3389/frobt.2021.612392/full",
            "Abstract": "Most people touch their faces unconsciously, for instance to scratch an itch or to rest one\u2019s chin in their hands. To reduce the spread of the novel coronavirus (COVID-19), public health officials recommend against touching one\u2019s face, as the virus is transmitted through mucous membranes in the mouth, nose and eyes. Students, office workers, medical personnel and people on trains were found to touch their faces between 9 and 23 times per hour. This paper introduces FaceGuard, a system that utilizes deep learning to predict hand movements that result in touching the face, and provides sensory feedback to stop the user from touching the face. The system utilizes an inertial measurement unit (IMU) to obtain features that characterize hand movement involving face touching. Time-series data can be efficiently classified using 1D-Convolutional Neural Network (CNN) with minimal feature engineering; 1D-CNN filters automatically extract temporal features in IMU data. Thus, a 1D-CNN based prediction model is developed and trained with data from 4800 trials recorded from 40 participants. Training data are collected for hand movements involving face touching during various everyday activities such as sitting, standing, or walking. Results showed that while the average time needed to touch the face is 1200 ms, a prediction accuracy of more than 92% is achieved with less than 550 ms of IMU data. As for the sensory response, the paper presents a psychophysical experiment to compare the response time for three sensory feedback modalities, namely visual, auditory, and vibrotactile. Results demonstrate that the response time is significantly \u2026",
            "Abstract entirety": 0,
            "Author pub id": "9OieklkAAAAJ:NDuN12AVoxsC",
            "Publisher": "Frontiers"
        },
        {
            "Title": "Occlusion-tolerant and personalized 3D human pose estimation in RGB images",
            "Publication year": 2021,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/9411956/",
            "Abstract": "We introduce a real-time method that estimates the 3D human pose directly in the popular Bio Vision Hierarchy (BVH) format, given estimations of the 2D body joints originating from monocular color images. Our contributions include: (a) A novel and compact 2D pose representation. (b) A human body orientation classifier and an ensemble of orientation-tuned neural networks that regress the 3D human pose by also allowing for the decomposition of the body to an upper and lower kinematic hierarchy. This permits the recovery of the human pose even in the case of significant occlusions. (c) An efficient Inverse Kinematics solver that refines the neural-network-based solution providing 3D human pose estimations that are consistent with the limb sizes of a target person (if known). All the above yield a 33% accuracy improvement on the Human 3.6 Million (H3.6M) dataset compared to the baseline method (MocapNET \u2026",
            "Abstract entirety": 0,
            "Author pub id": "9OieklkAAAAJ:kWvqk_afx_IC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Efficient, causal camera tracking in unprepared environments",
            "Publication year": 2005,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S1077314205000202",
            "Abstract": "This paper addresses the problem of tracking the 3D pose of a camera in space, using the images it acquires while moving freely in unmodeled, arbitrary environments. A novel feature-based approach for camera tracking is proposed, intended to facilitate tracking in on-line, time-critical applications such as video see-through augmented reality. In contrast to several existing methods which are designed to operate in a batch, off-line mode, assuming that the whole video sequence to be tracked is available before tracking commences, the proposed method operates on images incrementally. At its core lies a feature-based 3D plane tracking technique, which permits the estimation of the homographies induced by a virtual 3D plane between successive image pairs. Knowledge of these homographies allows the corresponding projection matrices encoding camera motion to be expressed in a common projective frame \u2026",
            "Abstract entirety": 0,
            "Author pub id": "9OieklkAAAAJ:YsMSGLbcyi4C",
            "Publisher": "Academic Press"
        },
        {
            "Title": "Beat synchronous dance animation based on visual analysis of human motion and audio analysis of music tempo",
            "Publication year": 2013,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-642-41939-3_12",
            "Abstract": "We present a framework that generates beat synchronous dance animation based on the analysis of both visual and audio data. First, the articulated motion of a dancer is captured based on markerless visual observations obtained by a multicamera system. We propose and employ a new method for the temporal segmentation of such motion data into the periods of dance. Next, we use a beat tracking algorithm to estimate the pulse related to the tempo of a piece of music. Given an input music that is of the same genre as the one corresponding to the visually observed dance, we automatically produce a beat synchronous dance animation of a virtual character. The proposed approach has been validated with extensive experiments performed on a data set containing a variety on traditional Greek/Cretan dances and the corresponding music.",
            "Abstract entirety": 1,
            "Author pub id": "9OieklkAAAAJ:WqliGbK-hY8C",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "Appreciation to IJCV Reviewers",
            "Publication year": 2015,
            "Publication url": "https://link.springer.com/content/pdf/10.1007/s11263-014-0797-2.pdf",
            "Abstract": "For helping us deliver timely decisions to our authors, the Editors-in-Chief and Publisher would like to thank the following individuals that contributed reviews between October 1st, 2013 and October 1st, 2014. We applaud your efforts and dedication to the community.",
            "Abstract entirety": 1,
            "Author pub id": "9OieklkAAAAJ:4fGpz3EwCPoC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Scale invariant and deformation tolerant partial shape matching",
            "Publication year": 2011,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S0262885611000151",
            "Abstract": "We present a novel approach to the problem of establishing the best match between an open contour and a part of a closed contour. At the heart of the proposed scheme lies a novel shape descriptor that also permits the quantification of local scale. Shape descriptors are computed along open or closed contours in a spatially non-uniform manner. The resulting ordered collections of shape descriptors constitute the global shape representation. A variant of an existing Dynamic Time Warping (DTW) matching technique is proposed to handle the matching of shape representations. Due to the properties of the employed shape descriptor, sampling scheme and matching procedure, the proposed approach performs partial shape matching that is invariant to Euclidean transformations, starting point as well as to considerable shape deformations. Additionally, the problem of matching closed-to-closed contours is naturally \u2026",
            "Abstract entirety": 0,
            "Author pub id": "9OieklkAAAAJ:_xSYboBqXhAC",
            "Publisher": "Elsevier"
        },
        {
            "Title": "Results of field trials with a Mobile service robot for older adults in 16 private households",
            "Publication year": 2019,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/3368554",
            "Abstract": "In this article, we present results obtained from field trials with the Hobbit robotic platform, an assistive, social service robot aiming at enabling prolonged independent living of older adults in their own homes. Our main contribution lies within the detailed results on perceived safety, usability, and acceptance from field trials with autonomous robots in real homes of older users. In these field trials, we studied how 16 older adults (75 plus) lived with autonomously interacting service robots over multiple weeks.Robots have been employed for periods of months previously in home environments for older people, and some have been tested with manipulation abilities, but this is the first time a study has tested a robot in private homes that provided the combination of manipulation abilities, autonomous navigation, and non-scheduled interaction for an extended period of time. This article aims to explore how older adults \u2026",
            "Abstract entirety": 0,
            "Author pub id": "9OieklkAAAAJ:CB2v5VPnA5kC",
            "Publisher": "ACM"
        },
        {
            "Title": "Localizing periodicity in time series and videos",
            "Publication year": 2016,
            "Publication url": "http://www.bmva.org/bmvc/2016/papers/paper047/abstract047.pdf",
            "Abstract": "Periodic patterns and motions are ubiquitous in both natural and man-made environments. Several well established tools and techniques such as the Fourier Transform [2] can be used to analyse purely periodic signals. However, in many real life scenarios, periodic signals appear as segments of larger signals containing nonperiodic parts. The detection and characterization of such periodic parts is an interesting problem that is not yet fully addressed.In this work we propose a method that, given a time series representing a periodic signal that has a non-periodic prefix and tail, estimates the start, end and period of the periodic part of the signal. The resulting method has a small number of free parameters, is unsupervised and can detect short periodic events occurring in the context of extended non-periodic activities.",
            "Abstract entirety": 1,
            "Author pub id": "9OieklkAAAAJ:ruyezt5ZtCIC",
            "Publisher": "BMVA"
        },
        {
            "Title": "Shading models for illumination and reflectance invariant shape detectors",
            "Publication year": 2008,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/4587773/",
            "Abstract": "Many objects have smooth surfaces of a fairly uniform color, thereby exhibiting shading patterns that reveal information about its shape, an important clue to the nature of the object. This papers explores extracting this information from images, by creating shape detectors based on shading.",
            "Abstract entirety": 1,
            "Author pub id": "9OieklkAAAAJ:JV2RwH3_ST0C",
            "Publisher": "IEEE"
        },
        {
            "Title": "From multiple views to textured 3d meshes: a gpu-powered approach",
            "Publication year": 2010,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-642-35740-4_30",
            "Abstract": "We present work on exploiting modern graphics hardware towards the real-time production of a textured 3D mesh representation of a scene observed by a multicamera system. The employed computational infrastructure consists of a network of four PC workstations each of which is connected to a pair of cameras. One of the PCs is equipped with a GPU that is used for parallel computations. The result of the processing is a list of texture mapped triangles representing the reconstructed surfaces. In contrast to previous works, the entire processing pipeline (foreground segmentation, 3D reconstruction, 3D mesh computation, 3D mesh smoothing and texture mapping) has been implemented on the GPU. Experimental results demonstrate that an accurate, high resolution, texture-mapped 3D reconstruction of a scene observed by eight cameras is achievable in real time.",
            "Abstract entirety": 1,
            "Author pub id": "9OieklkAAAAJ:7PzlFSSx8tAC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "Hobbit, a care robot supporting independent living at home: First prototype and lessons learned",
            "Publication year": 2014,
            "Publication url": "https://scholar.google.com/scholar?cluster=16480494772207270945&hl=en&oi=scholarr",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "9OieklkAAAAJ:PYBJJbyH-FwC",
            "Publisher": "Unknown"
        },
        {
            "Title": "A framework for online segmentation and classification of modeled actions performed in the context of unmodeled ones",
            "Publication year": 2017,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/7508494/",
            "Abstract": "In this paper, we propose a discriminative framework for online simultaneous segmentation and classification of modeled visual actions that can be performed in the context of other unknown actions. To this end, we employ Hough transform to vote in a 3D space for the begin point, the end point, and the label of the segmented part of the input stream. A support vector machine is used to model each class and to suggest putative labeled segments on the timeline. To identify the most plausible segments among the putative ones, we apply a dynamic programming algorithm, which maximizes the likelihood for label assignment in linear time. The performance of our method is evaluated on synthetic as well as on real data (Weizmann, TUM Kitchen, UTKAD, and Berkeley Multimodal Human Action databases). Extensive quantitative results obtained on a number of standard data sets demonstrate that the proposed \u2026",
            "Abstract entirety": 0,
            "Author pub id": "9OieklkAAAAJ:i2xiXl-TujoC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Vision-based hand gesture recognition for human-computer interaction",
            "Publication year": 2009,
            "Publication url": "https://www.academia.edu/download/30825754/zabulis09_book.pdf",
            "Abstract": "In recent years, research efforts seeking to provide more natural, human-centered means of interacting with computers have gained growing interest. A particularly important direction is that of perceptive user interfaces, where the computer is endowed with perceptive capabilities that allow it to acquire both implicit and explicit information about the user and the environment. Vision has the potential of carrying a wealth of information in a non-intrusive manner and at a low cost, therefore it constitutes a very attractive sensing modality for developing perceptive user interfaces. Proposed approaches for vision-driven interactive user interfaces resort to technologies such as head tracking, face and facial expression recognition, eye tracking and gesture recognition. In this paper, we focus our attention to vision-based recognition of hand gestures. The first part of the paper provides an overview of the current state of the art regarding the recognition of hand gestures as these are observed and recorded by typical video cameras. In order to make the review of the related literature tractable, this paper does not discuss:\u2022 techniques that are based on cameras operating beyond the visible spectrum (eg thermal cameras, etc),\u2022 active techniques that require the projection of some form of structured light, and,",
            "Abstract entirety": 1,
            "Author pub id": "9OieklkAAAAJ:4TOpqqG69KYC",
            "Publisher": "Unknown"
        },
        {
            "Title": "H-GAN: the power of GANs in your Hands",
            "Publication year": 2021,
            "Publication url": "https://arxiv.org/abs/2103.15017",
            "Abstract": "We present HandGAN (H-GAN), a cycle-consistent adversarial learning approach implementing multi-scale perceptual discriminators. It is designed to translate synthetic images of hands to the real domain. Synthetic hands provide complete ground-truth annotations, yet they are not representative of the target distribution of real-world data. We strive to provide the perfect blend of a realistic hand appearance with synthetic annotations. Relying on image-to-image translation, we improve the appearance of synthetic hands to approximate the statistical distribution underlying a collection of real images of hands. H-GAN tackles not only the cross-domain tone mapping but also structural differences in localized areas such as shading discontinuities. Results are evaluated on a qualitative and quantitative basis improving previous works. Furthermore, we relied on the hand classification task to claim our generated hands are statistically similar to the real domain of hands.",
            "Abstract entirety": 1,
            "Author pub id": "9OieklkAAAAJ:mKu_rENv82IC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Model-based 3D Hand Tracking with on-line Hand Shape Adaptation",
            "Publication year": 2015,
            "Publication url": "https://www.researchgate.net/profile/Antonis-Argyros/publication/296970229_Model-based_3D_Hand_Tracking_with_on-line_Shape_Adaptation/links/580fa95508aea04bbcba5beb/Model-based-3D-Hand-Tracking-with-on-line-Shape-Adaptation.pdf",
            "Abstract": "One of the shortcomings of the existing model-based 3D hand tracking methods is the fact that they consider a fixed hand model, ie one with fixed shape parameters. In this work we propose an online model-based method that tackles jointly the hand pose tracking and the hand shape estimation problems. The hand pose is estimated using a hierarchical particle filter. The hand shape is estimated by fitting the shape model parameters over the observations in a frame history. The candidate shapes required by the fitting framework are obtained by optimizing the shape parameters independently in each frame. Extensive experiments demonstrate that the proposed method tracks the pose of the hand and estimates its shape parameters accurately, even under heavy noise and inaccurate shape initialization.",
            "Abstract entirety": 1,
            "Author pub id": "9OieklkAAAAJ:epqYDVWIO7EC",
            "Publisher": "BMVA Press"
        },
        {
            "Title": "Enhancing museum visitor access through robotic avatars connected to the web",
            "Publication year": 2001,
            "Publication url": "https://www.researchgate.net/profile/Panos-Trahanias/publication/249688649_Enhancing_Museum_Visitor_Access_Through_Robotic_Avatars_Connected_to_the_Web/links/00b495294b26f13a91000000/Enhancing-Museum-Visitor-Access-Through-Robotic-Avatars-Connected-to-the-Web.pdf",
            "Abstract": "Access to cultural exhibits is a central issue in museums and exhibition galleries that is recently",
            "Abstract entirety": 1,
            "Author pub id": "9OieklkAAAAJ:isC4tDSrTZIC",
            "Publisher": "Unknown"
        },
        {
            "Title": "3D Hand Tracking by Employing Probabilistic Principal Component Analysis to Model Action Priors",
            "Publication year": 2019,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-030-34995-0_48",
            "Abstract": "This paper addresses the problem of 3D hand pose estimation by modeling specific hand actions using probabilistic Principal Component Analysis. For each of the considered actions, a parametric subspace is learned based on a dataset of sample action executions. The developed method tracks the 3D hand pose either in the case of unconstrained hand motion or in the case that the hand is engaged in some of the modelled actions. The tracker uses gradient descent optimization to fit a 3D hand model to the available observations. An online criterion is used to automatically switch between tracking the hand in the unconstrained case and tracking it in the case of learned action sub-spaces. To train and evaluate the proposed method, we captured a new dataset that contains sample executions of 5 different grasp-like hand actions and hand/object interactions. We tested the proposed method both quantitatively \u2026",
            "Abstract entirety": 0,
            "Author pub id": "9OieklkAAAAJ:nRpfm8aw39MC",
            "Publisher": "Unknown"
        },
        {
            "Title": "On the Feasibility of Real-Time 3D Hand Tracking using Edge GPGPU Acceleration",
            "Publication year": 2018,
            "Publication url": "https://arxiv.org/abs/1804.11256",
            "Abstract": "This paper presents the case study of a non-intrusive porting of a monolithic C++ library for real-time 3D hand tracking, to the domain of edge-based computation. Towards a proof of concept, the case study considers a pair of workstations, a computationally powerful and a computationally weak one. By wrapping the C++ library in Java container and by capitalizing on a Java-based offloading infrastructure that supports both CPU and GPGPU computations, we are able to establish automatically the required server-client workflow that best addresses the resource allocation problem in the effort to execute from the weak workstation. As a result, the weak workstation can perform well at the task, despite lacking the sufficient hardware to do the required computations locally. This is achieved by offloading computations which rely on GPGPU, to the powerful workstation, across the network that connects them. We show the edge-based computation challenges associated with the information flow of the ported algorithm, demonstrate how we cope with them, and identify what needs to be improved for achieving even better performance.",
            "Abstract entirety": 1,
            "Author pub id": "9OieklkAAAAJ:ODE9OILHJdcC",
            "Publisher": "Unknown"
        },
        {
            "Title": "HOBBIT-The Mutual Care Robot",
            "Publication year": 2013,
            "Publication url": "Unknown",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "9OieklkAAAAJ:U4n9YNQMCAIC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Cell Segmentation via Region-Based Ellipse Fitting",
            "Publication year": 2018,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/8451852/",
            "Abstract": "We present a region based method for segmenting and splitting images of cells in an automatic and unsupervised manner. The detection of cell nuclei is based on the Bradley's method. False positives are automatically identified and rejected based on shape and intensity features. Additionally, the proposed method is able to automatically detect and split touching cells. To do so, we employ a variant of a region based multi-ellipse fitting method that makes use of constraints on the area of the split cells. The quantitative assessment of the proposed method has been based on two challenging public datasets. This experimental study shows that the proposed method outperforms clearly existing methods for segmenting fluorescence microscopy images.",
            "Abstract entirety": 1,
            "Author pub id": "9OieklkAAAAJ:fFSKOagxvKUC",
            "Publisher": "Unknown"
        },
        {
            "Title": "A checkerboard detection utility for intrinsic and extrinsic camera cluster calibration",
            "Publication year": 2009,
            "Publication url": "https://scholar.google.com/scholar?cluster=9735147691541057002&hl=en&oi=scholarr",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "9OieklkAAAAJ:SP6oXDckpogC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Fast positioning of limited-visibility guards for the inspection of 2d workspaces",
            "Publication year": 2002,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/1041701/",
            "Abstract": "This paper presents a novel method for deciding the locations of \"guards\" required to visually inspect a given 2D workspace. The decided guard positions can then be used as control points in the path of a mobile robot that autonomously inspects a workspace. It is assumed that each of the guards (or the mobile robot that visits the guard positions in some order) is equipped with a panoramic camera of 360 degrees field of view. However, the camera has limited visibility, in the sense that it can observe with sufficient detail objects that are not further than a predefined visibility range. The method seeks to efficiently produce solutions that contain the smaller possible number of guards. Experimental results demonstrate that the proposed method is computationally efficient and that, although suboptimal, decides a small number of guards.",
            "Abstract entirety": 1,
            "Author pub id": "9OieklkAAAAJ:eQOLeE2rZwMC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Biomimetic centering behavior [mobile robots with panoramic sensors]",
            "Publication year": 2004,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/1371612/",
            "Abstract": "A reactive robotic centering behavior based on panoramic vision is presented. It is inspired by the way insects exploit visual information in analogous navigation tasks. By employing a panoramic camera, the development of the centering behavior is simplified both from a theoretical and from an implementation point of view. The proposed method relies on the extraction of primitive visual information from appropriately selected areas of a panoramic visual field and its direct use in the control law. Experimental results from an implementation of this method on a robotic platform demonstrate a centering behavior which can be achieved in real-time and with high accuracy. The proposed technique circumvents the need to address complex problems of 3D structure estimation and the resulting control laws were shown to possess the required stability properties.",
            "Abstract entirety": 1,
            "Author pub id": "9OieklkAAAAJ:IjCSPb-OGe4C",
            "Publisher": "IEEE"
        },
        {
            "Title": "Exploiting panoramic vision for bearing-only robot homing",
            "Publication year": 2006,
            "Publication url": "https://link.springer.com/content/pdf/10.1007/978-1-4020-4894-4_12.pdf",
            "Abstract": "K. Daniilidis and R. Klette (eds.), Imaging Beyond the Pinhole Camera, 229\u2013251.\u00a9 2006 Springer.",
            "Abstract entirety": 1,
            "Author pub id": "9OieklkAAAAJ:_Qo2XoVZTnwC",
            "Publisher": "Springer, Dordrecht"
        },
        {
            "Title": "Single-shot 3D hand pose estimation using radial basis function networks trained on synthetic data",
            "Publication year": 2020,
            "Publication url": "https://link.springer.com/article/10.1007/s10044-019-00801-7",
            "Abstract": "In this work, we present a novel framework to perform single-shot hand pose estimation using depth data as input. The method follows a coarse to fine strategy and employs several radial basis function networks (RBFNs) that are trained on a dataset containing only synthetically generated depth maps. Thus, compared to most contemporary deep learning approaches, it does not require the laborious annotation of large, real-world datasets. At run time, an initialization RBFN is used to provide a rough estimation of the hand\u2019s 3D pose. Subsequently, several specialized RBFNs are employed to improve that initial estimation in an iterative refinement scheme. To train the RBFNs, we select a set of hand poses from a real-world sequence that are as diverse as possible. We use this representative set, along with a dense sampling of all possible rotations, as a seed to generate a large synthetic training set. The method is \u2026",
            "Abstract entirety": 0,
            "Author pub id": "9OieklkAAAAJ:Aul-kAQHnToC",
            "Publisher": "Springer London"
        },
        {
            "Title": "Efficient 3D camera matchmoving using markerless, segmentation-free plane tracking",
            "Publication year": 2003,
            "Publication url": "https://ics.forth.gr/cvrl/publications/tech_reports/2003_09_tr324_forth_camera_tracking.pdf",
            "Abstract": "Camera matchmoving is an application involving synthesis of real scenes and artificial objects, in which the goal is to insert computer-generated graphical 3D objects into live-action footage depicting unmodeled, arbitrary scenes. Graphical objects should be inserted in a way so that they appear to move as if they were a part of the real scene. Seamless, convincing insertion of graphical objects calls for accurate 3D camera motion tracking (ie pose estimation), stable enough over extended sequences so as to avoid the problems of jitter and drift in the location and appearance of objects with respect to the real scene. Additionally, the placement of the objects with respect to the real scene often requires the availability of some 3D geometry information; for instance, accurate 3D reconstruction of a few guiding control points is in most cases sufficient. Matchmoving finds several important applications in augmented reality as well as virtual studio shooting and the creation of special effects in the post-production/filmmaking industry [40]. To provide the versatility required by such applications, very demanding camera tracking requirements, both in terms of accuracy and speed, are imposed [4].Optical and electromechanical camera tracking are technologies that have successfully proven themselves in applications such as live TV broadcasting [41]. Nevertheless, apart from suffering from range limitations, such technologies call for special modifications of the environment that render them inapplicable for tracking in unprepared, unstructured scenes, large scale environments or archive footage. Being non-intrusive, passive and capable of covering large \u2026",
            "Abstract entirety": 0,
            "Author pub id": "9OieklkAAAAJ:gVv57TyPmFsC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Multi-GPU SNN Simulation with Static Load Balancing",
            "Publication year": 2021,
            "Publication url": "https://arxiv.org/abs/2102.04681",
            "Abstract": "We present a SNN simulator which scales to millions of neurons, billions of synapses, and 8 GPUs. This is made possible by 1) a novel, cache-aware spike transmission algorithm 2) a model parallel multi-GPU distribution scheme and 3) a static, yet very effective load balancing strategy. The simulator further features an easy to use API and the ability to create custom models. We compare the proposed simulator against two state of the art ones on a series of benchmarks using three well-established models. We find that our simulator is faster, consumes less memory, and scales linearly with the number of GPUs.",
            "Abstract entirety": 1,
            "Author pub id": "9OieklkAAAAJ:-jrNzM816MMC",
            "Publisher": "Unknown"
        },
        {
            "Title": "ICCV 2015 Outstanding Reviewers",
            "Publication year": 2015,
            "Publication url": "https://www.computer.org/csdl/pds/api/csdl/proceedings/download-article/12OmNANBZp1/pdf",
            "Abstract": "Outstanding Reviewers Page 1 ICCV 2015 Outstanding Reviewers We are pleased to \nrecognize the following researchers as \u201cICCV 2015 Outstanding Reviewers\u201d. These reviewers \nwere identified by one or more of the ICCV Area Chairs for their hard work in providing high \nquality and detailed reviews for their assigned papers. Relja Arandjelovic Antonis Argyros \nMoshe Ben-ezra Ohad Ben-Shahar Carlos Benitez-Quiroz Arnav Bhavsar Oliver Cossairt Marco \nCristani Alessio Del Bue Mark Drew Alexei Efros Ross Girshick Ioannis Gkioulekas Daniel \nGlasner Saurabh Gupta Mehrtash Harandi Kaiming He Joao Henriques Derek Hoiem Anthony \nHoogs Ichiro Ide Ivo Ihrke Suyog Jain CV Jawahar Yannis Kalantidis Margret Keuper Martin \nKleinsteuber Kyros Kutulakos Pierre-Yves Laffont Ivan Laptev Clement Mallet Vlad Morariu \nVittorio Murino Naila Murray Alison Noble Guillaume Obozinski Bjorn Ommer Martin R. Oswald --\u2026",
            "Abstract entirety": 0,
            "Author pub id": "9OieklkAAAAJ:kz9GbA2Ns4gC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Synergy-driven performance enhancement of vision-based 3D hand pose reconstruction",
            "Publication year": 2016,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-319-58877-3_42",
            "Abstract": "In this work we propose, for the first time, to improve the performance of a Hand Pose Reconstruction (HPR) technique from RGBD camera data, which is affected by self-occlusions, leveraging upon postural synergy information, i.e., a priori information on how human most commonly use and shape their hands in everyday life tasks. More specifically, in our approach, we ignore joint angle values estimated with low confidence through a vision-based HPR technique and fuse synergistic information with such incomplete measures. Preliminary experiments are reported showing the effectiveness of the proposed integration.",
            "Abstract entirety": 1,
            "Author pub id": "9OieklkAAAAJ:q3CdL3IzO_QC",
            "Publisher": "EAI"
        },
        {
            "Title": "A GPU-powered computational framework for efficient 3D model-based vision",
            "Publication year": 2011,
            "Publication url": "https://scholar.google.com/scholar?cluster=8562315699768300513&hl=en&oi=scholarr",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "9OieklkAAAAJ:uWQEDVKXjbEC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Multicamera tracking of multiple humans based on colored visual hulls",
            "Publication year": 2013,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/6647982/",
            "Abstract": "Detecting, localizing and tracking humans within an industrial environment are three tasks which are of central importance towards achieving automation in workplaces and intelligent environments. This is because unobtrusive, real-time and reliable person tracking provides valuable input to solving problems such as workplace surveillance and event/activity recognition and, also, contributes to safety and optimized use of resources. This paper presents a passive approach to the problem of person tracking that is based on a network of conventional color cameras. The proposed approach exhibits robustness to challenging conditions that are encountered in industrial environments due to illumination artifacts, occlusions and the highly dynamic nature of the observed scenes. The multiple views of the environment that the system employs are used to obtain a volumetric representation of the humans within it, in real \u2026",
            "Abstract entirety": 0,
            "Author pub id": "9OieklkAAAAJ:dQ2og3OwTAUC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Tracking skin-colored objects in real-time",
            "Publication year": 2005,
            "Publication url": "https://books.google.com/books?hl=en&lr=&id=JNEn23UyHuAC&oi=fnd&pg=PA77&dq=info:LONBKna64JIJ:scholar.google.com&ots=yov_9f7loc&sig=zGeeZAIBbBf0CgJA-jbwR93wzbU",
            "Abstract": "Locating and tracking objects of interest in a temporal sequence of images constitutes an essential building block of many vision systems. In particular, techniques for effectively and efficiently tracking the human body, either in part or as a whole, have received considerable attention in the context of applications such as face, gesture and gait recognition, markerless human motion capture, behavior and action interpretation, perceptual user interfaces, intelligent surveillance, etc. In such settings, vision-based tracking needs to provide answers to the following fundamental questions. First, how is a human modeled and how are instances of the employed model detected in an image? Second, how are instances of the detected model associated temporally in sequences of images?Being a complex, non-rigid structure with many degrees of freedom, the human body is intricate to model. This is reflected on the models that have been employed in the literature for human tracking, whose type and complexity vary dramatically (Gavrila, 1999; DeCarlo & Metaxas, 2000; Delamarre & Faugeras, 2001; Pl\u00e4nkers & Fua, 2001), depending heavily on the requirements of the application domain under consideration. For example, tracking people in an indoors environment in the context of a surveillance application has completely different modeling requirements compared to tracking the fingers of a hand for sign language interpretation. Many visual cues like color, shading, edges, texture, motion, depth and their combinations have been employed as the basis for modeling of human body parts. Among those, skin color is very effective towards detecting the \u2026",
            "Abstract entirety": 0,
            "Author pub id": "9OieklkAAAAJ:0EnyYjriUFMC",
            "Publisher": "Advanced Robotic Systems International"
        },
        {
            "Title": "Exploration of Large-scale Museum Artifacts through Non-instrumented, Location-based, Multi-user Interaction.",
            "Publication year": 2010,
            "Publication url": "https://diglib.eg.org/bitstream/handle/10.2312/VAST.VAST10.155-162/155-162.pdf?sequence=1&isAllowed=y",
            "Abstract": "This paper presents a system that supports the exploration of digital representations of large-scale museum artifacts in through non-instrumented, location-based interaction. The system employs a state-of-the-art computer vision system, which localizes and tracks multiple visitors. The artifact is presented in a wall-sized projection screen and it is visually annotated with text and images according to the location as well as walkthrough trajectories of the tracked visitors. The system is evaluated in terms of computational performance, localization accuracy, tracking robustness and usability.",
            "Abstract entirety": 1,
            "Author pub id": "9OieklkAAAAJ:TQgYirikUcIC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Tracking the articulated motion of two strongly interacting hands",
            "Publication year": 2012,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/6247885/",
            "Abstract": "We propose a method that relies on markerless visual observations to track the full articulation of two hands that interact with each-other in a complex, unconstrained manner. We formulate this as an optimization problem whose 54-dimensional parameter space represents all possible configurations of two hands, each represented as a kinematic structure with 26 Degrees of Freedom (DoFs). To solve this problem, we employ Particle Swarm Optimization (PSO), an evolutionary, stochastic optimization method with the objective of finding the two-hands configuration that best explains observations provided by an RGB-D sensor. To the best of our knowledge, the proposed method is the first to attempt and achieve the articulated motion tracking of two strongly interacting hands. Extensive quantitative and qualitative experiments with simulated and real world image sequences demonstrate that an accurate and efficient \u2026",
            "Abstract entirety": 0,
            "Author pub id": "9OieklkAAAAJ:D_sINldO8mEC",
            "Publisher": "IEEE"
        },
        {
            "Title": "3D Head Pose Estimation from Multiple Distant Views.",
            "Publication year": 2009,
            "Publication url": "https://videolectures.net/site/normal_dl/tag=52903/bmvc09_zabulis_3dhp.pdf",
            "Abstract": "3D head pose estimation from multiple distant views Page 1 3D head pose estimation from \nmultiple distant views X. Zabulis, T. Sarmis, AA Argyros Institute of Computer Science, \nFoundation for Research and Technology \u2013 Hellas (ICS-FORTH) Page 2 The problem \u220e \nEstimate X, Y, Z (location) and yaw, pitch and roll (pose), from multiple calibrated distal views \u220e \nBased on face detection \u220e Face detection, in distal viewing, is a significant component of the \nproblem Reference dataset from INRIA (IXMAS) Page 3 Past solutions and issues \u220e Templates, \ndetector arrays \u220e Nonlinear regression, manifold embedding \u220e Tracking rigid landmarks \u220e \nFace alignment \u220e Fusion of single view estimates \u25a1 Bayesian, Conditional probability, Joint \nlikelihood \u25a1 Only coarse pose estimation is reported Single view Page 4 Proposed method \u220e \nTextured visual hull to locate the head in 3D \u220e Unfold head texture from the visual hull, on a the -\u2026",
            "Abstract entirety": 0,
            "Author pub id": "9OieklkAAAAJ:maZDTaKrznsC",
            "Publisher": "BMVA Press"
        },
        {
            "Title": "Accurate Hand Keypoint Localization on Mobile Devices",
            "Publication year": 2019,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/8758059/",
            "Abstract": "We present a novel approach for 2D hand keypoint localization from regular color input. The proposed approach relies on an appropriately designed Convolutional Neural Network (CNN) that computes a set of heatmaps, one per hand keypoint of interest. Extensive experiments with the proposed method compare it against state of the art approaches and demonstrate its accuracy and computational performance on standard, publicly available datasets. The obtained results demonstrate that the proposed method matches or outperforms the competing methods in accuracy, but clearly outperforms them in computational efficiency, making it a suitable building block for applications that require hand keypoint estimation on mobile devices.",
            "Abstract entirety": 1,
            "Author pub id": "9OieklkAAAAJ:Ehil0879vHcC",
            "Publisher": "Unknown"
        },
        {
            "Title": "A two-stage approach for commonality-based temporal localization of periodic motions",
            "Publication year": 2019,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-030-34995-0_33",
            "Abstract": "We present an unsupervised method for the detection of all temporal segments of videos or motion capture data, that correspond to periodic motions. The proposed method is based on the detection of similar segments (commonalities) in different parts of the input sequence and employs a two-stage approach that operates on the matrix of pairwise distances of all input frames. The quantitative evaluation of the proposed method on three standard ground-truth-annotated datasets (two video datasets, one 3D human motion capture dataset) demonstrate its improved performance in comparison to existing approaches.",
            "Abstract entirety": 1,
            "Author pub id": "9OieklkAAAAJ:PaBasH6fAo0C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Hobbit, a care robot supporting independent living at home: First prototype and lessons learned",
            "Publication year": 2016,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S0921889014002140",
            "Abstract": "One option to address the challenge of demographic transition is to build robots that enable aging in place. Falling has been identified as the most relevant factor to cause a move to a care facility. The Hobbit project combines research from robotics, gerontology, and human\u2013robot interaction to develop a care robot which is capable of fall prevention and detection as well as emergency detection and handling. Moreover, to enable daily interaction with the robot, other functions are added, such as bringing objects, offering reminders, and entertainment. The interaction with the user is based on a multimodal user interface including automatic speech recognition, text-to-speech, gesture recognition, and a graphical touch-based user interface. We performed controlled laboratory user studies with a total of 49 participants (aged 70 plus) in three EU countries (Austria, Greece, and Sweden). The collected user responses on \u2026",
            "Abstract entirety": 0,
            "Author pub id": "9OieklkAAAAJ:u-coK7KVo8oC",
            "Publisher": "North-Holland"
        },
        {
            "Title": "Improving deep learning approaches for human activity recognition based on natural language processing of action labels",
            "Publication year": 2020,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/9207397/",
            "Abstract": "Human activity recognition has always been an appealing research topic in computer vision due its theoretic interest and vast range of applications. In recent years, machine learning has dominated computer vision and human activity recognition research. Supervised learning methods and especially deep learning-based ones are considered to provide the best solutions for this task, achieving state-of-the art results. However, the performance of deep learning-based approaches depends greatly on the modelling capabilities of the spatio-temporal neural network architecture and the learning goals of the training process. Moreover, the design complexity is task-depended. In this paper, we show that we can exploit the information contained in the label description of action classes (action labels) to extract information regarding their similarity which can then be used to steer the learning process and improve the \u2026",
            "Abstract entirety": 0,
            "Author pub id": "9OieklkAAAAJ:-7ulzOJl1JYC",
            "Publisher": "IEEE"
        },
        {
            "Title": "A Hybrid Method for 3D Pose Estimation of Personalized Human Body Models",
            "Publication year": 2018,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/8354160/",
            "Abstract": "We propose a new hybrid method for 3D human body pose estimation based on RGBD data. We treat this as an optimization problem that is solved using a stochastic optimization technique. The solution to the optimization problem is the pose parameters of a human model that register it to the available observations. Our method can make use of any skinned, articulated human body model. However, we focus on personalized models that can be acquired easily and automatically based on existing human scanning and mesh rigging techniques. Observations consist of the 3D structure of the human (measured by the RGBD camera) and the body joints locations (computed based on a dis-criminative, CNN-based component). A series of quantitative and qualitative experiments demonstrate the accuracy and the benefits of the proposed approach. In particular, we show that the proposed approach achieves state of \u2026",
            "Abstract entirety": 0,
            "Author pub id": "9OieklkAAAAJ:4vMrXwiscB8C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Angle-based methods for mobile robot navigation: Reaching the entire plane",
            "Publication year": 2004,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/1307416/",
            "Abstract": "Popular approaches for mobile robot navigation involve range information and metric maps of the workspace. For many sensors, however, such as cameras and wireless hardware, the angle between two features or beacons is easier to measure. With these sensors' features in mind, we initially present a control law, which allows a robot with an omni-directional sensor to reach a subset of the plane by monitoring the angles of only three landmarks. By analyzing the law's properties, a second law has been developed that reaches the complementary set of points. The two methods are then combined in a path planning framework that reaches any possible goal configuration in a planar obstacle-free workspace with three landmarks. The proposed framework could be used together with other techniques, such as obstacle avoidance and topological maps to improve the efficiency of autonomous navigation. Experiments \u2026",
            "Abstract entirety": 0,
            "Author pub id": "9OieklkAAAAJ:W7OEmFMy1HYC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Tracking the articulated motion of the human body with two RGBD cameras",
            "Publication year": 2015,
            "Publication url": "https://link.springer.com/article/10.1007/s00138-014-0651-0",
            "Abstract": "We present a model-based, top-down solution to the problem of tracking the 3D position, orientation and full articulation of the human body from markerless visual observations obtained by two synchronized RGBD cameras. Inspired by recent advances to the problem of model-based hand tracking Oikonomidis et al. (Efficient Model-based 3D Tracking of Hand Articulations using Kinect, 2011), we treat human body tracking as an optimization problem that is solved using stochastic optimization techniques. We show that the proposed approach outperforms in accuracy state of the art methods that rely on a single RGBD camera. Thus, for applications that require increased accuracy and can afford the extra-complexity introduced by the second sensor, the proposed approach constitutes a viable solution to the problem of markerless human motion tracking. Our findings are supported by an extensive \u2026",
            "Abstract entirety": 0,
            "Author pub id": "9OieklkAAAAJ:ZfRJV9d4-WMC",
            "Publisher": "Springer Berlin Heidelberg"
        },
        {
            "Title": "Towards a cognitive vision methodology: understanding and interpreting activities of experts",
            "Publication year": 2003,
            "Publication url": "https://scholar.google.com/scholar?cluster=11082918153228829635&hl=en&oi=scholarr",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "9OieklkAAAAJ:BUYA1_V_uYcC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Adaptive heterogeneous multi-robot collaboration from formal task specifications",
            "Publication year": 2021,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S0921889021001512",
            "Abstract": "Efficiently coordinating different types of robots is an important enabler for many commercial and industrial automation tasks. Here, we present a distributed framework that enables a team of heterogeneous robots to dynamically generate actions from a common, user-defined goal specification. In particular, we discuss the integration of various robotic capabilities into a common task allocation and planning formalism, as well as the specification of expressive, temporally-extended goals by non-expert users. Models for task allocation and execution both consider non-deterministic outcomes of actions and thus, are suitable for a wide range of real-world tasks including formally specified reactions to online observations. One main focus of our paper is to evaluate the framework and its integration of software modules through a number of experiments. These experiments comprise industry-inspired scenarios as motivated \u2026",
            "Abstract entirety": 0,
            "Author pub id": "9OieklkAAAAJ:HhcuHIWmDEUC",
            "Publisher": "North-Holland"
        },
        {
            "Title": "Scalable 3D Tracking of Multiple Interacting Objects",
            "Publication year": 2014,
            "Publication url": "http://openaccess.thecvf.com/content_cvpr_2014/html/Kyriazis_Scalable_3D_Tracking_2014_CVPR_paper.html",
            "Abstract": "We consider the problem of tracking multiple interacting objects in 3D, using RGBD input and by considering a hypothesize-and-test approach. Due to their interaction, objects to be tracked are expected to occlude each other in the field of view of the camera observing them. A naive approach would be to employ a Set of Independent Trackers (SIT) and to assign one tracker to each object. This approach scales well with the number of objects but fails as occlusions become stronger due to their disjoint consideration. The solution representing the current state of the art employs a single Joint Tracker (JT) that accounts for all objects simultaneously. This directly resolves ambiguities due to occlusions but has a computational complexity that grows geometrically with the number of tracked objects. We propose a middle ground, namely an Ensemble of Collaborative Trackers (ECT), that combines best traits from both worlds to deliver a practical and accurate solution to the multi-object 3D tracking problem. We present quantitative and qualitative experiments with several synthetic and real world sequences of diverse complexity. Experiments demonstrate that ECT manages to track far more complex scenes than JT at a computational time that is only slightly larger than that of SIT.",
            "Abstract entirety": 1,
            "Author pub id": "9OieklkAAAAJ:Fu2w8maKXqMC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Patch-based reconstruction of a textureless deformable 3D surface from a single RGB image",
            "Publication year": 2019,
            "Publication url": "http://openaccess.thecvf.com/content_ICCVW_2019/html/GMDL/Tsoli_Patch-Based_Reconstruction_of_a_Textureless_Deformable_3D_Surface_from_a_ICCVW_2019_paper.html",
            "Abstract": "We propose a deep learning method for reconstructing a textureless deformable 3D surface from a single RGB image, under various lighting conditions. One of the challenges when training a neural network to predict the shape of a deformable object is that the object exhibits such a great deal of shape variation that it is essentially impractical to have a training set consisting of all possible deformations the object may realize. However, different areas of the deformable object may exhibit similar types of deformations, eg similar wrinkles might appear in different areas on the surface of a cloth. Motivated by this, we propose learning local models of shape variation from image patches that we then combine into a global reconstruction of the observed object. Initially, we divide the input image into overlapping patches and a zero-mean depth map as well as a normal map are estimated for each patch using deep learning. Stitching of depth maps is performed by finding the optimal translation of each patch depth map along the viewing direction of the camera and averaging the depth predictions of neighboring patches at their overlapping areas. Stitching of normal maps is performed by normalizing and averaging the normals predictions of neighboring patches at their overlapping areas. Finally, bilateral filtering is performed on the stitched depth and normal maps in order to perform fine-scale smoothing at the regions around patch boundaries. We show increased accuracy compared to previous work even in the presence of limited training data and more effective generalization to unseen objects.",
            "Abstract entirety": 1,
            "Author pub id": "9OieklkAAAAJ:kw52XkFRtyQC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Towards Improved and Interpretable Action Quality Assessment with Self-Supervised Alignment",
            "Publication year": 2021,
            "Publication url": "http://users.ics.forth.gr/~argyros/mypapers/2021_06_PETRA_AQA-Roditakis.pdf",
            "Abstract": "Action Quality Assessment (AQA) is a video understanding task aiming at the quantification of the execution quality of an action. One of the main challenges in relevant, deep learning-based approaches is the collection of training data annotated by experts. Current methods perform fine-tuning on pre-trained backbone models and aim to improve performance by modeling the subjects and the scene. In this work, we consider embeddings extracted using a self-supervised training method based on a differential cycle consistency loss between sequences of actions. These are shown to improve the state-of-the-art without the need for additional annotations or scene modeling. The same embeddings are also used to temporally align the sequences prior to quality assessment which further increases the accuracy, provides robustness to variance in execution speed and enables us to provide fine-grained interpretability of the assessment score. The experimental evaluation of the method on the MTL-AQA dataset demonstrates significant accuracy gain compared to the state-of-the-art baselines, which grows even more when the action execution sequences are not well aligned.",
            "Abstract entirety": 1,
            "Author pub id": "9OieklkAAAAJ:ce2CqMG-AY4C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Monitoring and Interpreting Human Motion to Support Clinical Applications of a Smart Walker",
            "Publication year": 2016,
            "Publication url": "http://users.ics.forth.gr/~argyros/mypapers/2016_05_IETWorkshop_acanto.pdf",
            "Abstract": "We present two proof-of-concept applications of human motion perception technologies for automating clinical tests performed by the FriWalk smart walker. FriWalk is a robotic walker currently being developed in the context of the EU H2020 project ACANTO that is designed to operate in a \u201cpersonal\u201d or a \u201cclinical\u201d mode. The goal of the clinical FriWalk is to support/automate clinical tests and rehabilitation of patients with mobility problems. The two applications under consideration are the following:(A) The \u201cshort physical performance battery\u201d(SPPB) test: SPPB is a standardized method used by geriatricians to measure the functional status and physical performance of older adults. The test measures lower extremity function using tasks that mimic daily activities. One of these tasks is the \u201csit-stand\u201d test. To pass the test the patient sits on a standard chair and has to perform five sit to stand transitions as quickly as possible and without using his/her hands. FriWalk automates the execution of this test by monitoring and interpreting the motion/activities of the user. To start the test, the user signals the walker to move to the proper position with a gesture. The walker autonomously moves at a proper distance from the user and asks him/her to start the test. Instructions and feedback are displayed on the walker's touch screen called \u201cFriTab\u201d. At any point, the user may stop the test and signal the walker back using the \u201ccancel\u201d and \u201creturn\u201d gestures, respectively. The walker monitors the execution of the test and, upon completion, provides feedback to the user.",
            "Abstract entirety": 1,
            "Author pub id": "9OieklkAAAAJ:lmc2jWPfTJgC",
            "Publisher": "IET"
        },
        {
            "Title": "Temporal segmentation and seamless stitching of motion patterns for synthesizing novel animations of periodic dances",
            "Publication year": 2014,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/6977043/",
            "Abstract": "In this paper, we present an efficient algorithm for synthesizing novel, arbitrarily long animations of periodic dances. The input to the proposed method is motion capture data acquired from markeless visual observations of a human performing a periodic dance. The provided human motion capture data are temporally segmented into the constituent periodic motion patterns. These are further organized in a motion graph that also represents possible transitions among them. Finally, an efficient algorithm exploits this representation to come up with a previously unseen sequence of motion patterns that are stitched seamlessly into a novel, realistic dance animation. Several experiments have been conducted with real recordings of Greek folk dances. The obtained results are very promising and indicate the efficacy of the proposed approach, as well as its tolerance to dynamic and noisy human motion capture input.",
            "Abstract entirety": 1,
            "Author pub id": "9OieklkAAAAJ:NJ774b8OgUMC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Gesture Recognition Apparatuses, Methods and Systems for Human-Machine Interaction",
            "Publication year": 2016,
            "Publication url": "https://patents.google.com/patent/US20160078289A1/en",
            "Abstract": "The GESTURE RECOGNITION APPARATUSES, METHODS AND SYSTEMS FOR HUMAN-MACHINE INTERACTION (\u201cGRA\u201d) discloses vision-based gesture recognition. GRA can be implemented in any application involving tracking, detection and/or recognition of gestures or motion in general. Disclosed methods and systems consider a gestural vocabulary of a predefined number of user specified static and/or dynamic hand gestures that are mapped with a database to convey messages. In one implementation, the disclosed systems and methods support gesture recognition by detecting and tracking body parts, such as arms, hands and fingers, and by performing spatio-temporal segmentation and recognition of the set of predefined gestures, based on data acquired by an RGBD sensor. In one implementation, a model of the hand is employed to detect hand and finger candidates. At a higher level, hand posture \u2026",
            "Abstract entirety": 0,
            "Author pub id": "9OieklkAAAAJ:gsN89kCJA0AC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Robot homing based on panoramic vision",
            "Publication year": 2001,
            "Publication url": "https://139.91.152.92/_pdf/brochures/tr287_argyros_homing.pdf",
            "Abstract": "In robotics, homing can be defined as that behavior, which enables a robot to return to its initial (home) position, after traveling a certain distance along an arbitrary path. Odometry has traditionally been used for the implementation of such a behavior, but it has been shown to be an unreliable source of information. In this work, a novel method for visual homing is proposed, based on a panoramic camera. As the robot departs from its initial position, it tracks characteristic features of the environment (corners). As soon as homing is activated, the robot selects intermediate target positions on the original path. These intermediate positions are then visited sequentially, until the home position is reached. For the robot to move between two consecutive intermediate positions, it is only required to establish correspondence among at least three corners. This correspondence is obtained through a feature tracking mechanism. The proposed homing scheme is based on the extraction of very low-level sensory information, namely the bearing angles of corners, and has been implemented on a robotic platform. Experimental results show that the proposed scheme achieves homing with a remarkable accuracy, which is not affected by the distance traveled by the robot.",
            "Abstract entirety": 1,
            "Author pub id": "9OieklkAAAAJ:TFP_iSt0sucC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Chaining planar homographies for fast and reliable 3d plane tracking",
            "Publication year": 2006,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/1698960/",
            "Abstract": "This paper addresses the problem of tracking a 3D plane over a sequence of images acquired by a free moving camera, a task that is of central importance to a wide variety of vision tasks. A feature-based method is proposed which given a triplet of consecutive images and a plane homography between the first two of them, estimates the homography induced by the same plane between the second and third images, without requiring the plane to be segmented from the rest of the scene. Thus, the proposed method operates by \"chaining\" (i.e. propagating) across frames the image-to-image homographies due to some 3D plane. The chaining operation represents projective space using a \"plane + parallax\" decomposition, which permits the combination of constraints arising from all available point matches, regardless of whether they actually lie on the tracked 3D plane or not. Experimental results are also provided",
            "Abstract entirety": 1,
            "Author pub id": "9OieklkAAAAJ:ZeXyd9-uunAC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Head pose estimation on depth data based on Particle Swarm Optimization",
            "Publication year": 2012,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/6239236/",
            "Abstract": "We propose a method for human head pose estimation based on images acquired by a depth camera. During an initialization phase, a reference depth image of a human subject is obtained. At run time, the method searches the 6-dimensional pose space to find a pose from which the head appears identical to the reference view. This search is formulated as an optimization problem whose objective function quantifies the discrepancy of the depth measurements between the hypothesized views to the reference view. The method is demonstrated in several data sets including ones with known ground truth and comparatively evaluated with respect to state of the art methods. The obtained experimental results show that the proposed method outperforms existing methods in accuracy and tolerance to occlusions. Additionally, compared to the state of the art, it handles head pose estimation in a wider range of head poses.",
            "Abstract entirety": 1,
            "Author pub id": "9OieklkAAAAJ:eflP2zaiRacC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Learning temporal structure for task based control",
            "Publication year": 2008,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S0262885606000655",
            "Abstract": "We present an extension for variable length Markov models (VLMMs) to allow for modelling of continuous input data and show that the generative properties of these VLMMs are a powerful tool for dealing with real world tracking issues. We explore methods for addressing the temporal correspondence problem in the context of a practical hand tracker, which is essential to support expectation in task-based control using these behavioural models. The hand tracker forms a part of a larger multi-component distributed system, providing 3-D hand position data to a gesture recogniser client. We show how the performance of such a hand tracker can be improved by using feedback from the gesture recogniser client. In particular, feedback based on the generative extrapolation of the recogniser's internal models is shown to help the tracker deal with mid-term occlusion. We also show that VLMMs can be used as a means to \u2026",
            "Abstract entirety": 0,
            "Author pub id": "9OieklkAAAAJ:blknAaTinKkC",
            "Publisher": "Elsevier"
        },
        {
            "Title": "Tracking multiple colored blobs with a moving camera",
            "Publication year": 2005,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/1467577/",
            "Abstract": "This paper concerns a method for tracking multiple blobs exhibiting certain color distributions in images acquired by a possibly moving camera. The method encompasses a collection of techniques that enable modeling and detecting the blobs possessing the desired color distribution(s), as well as inferring their temporal association across image sequences. Appropriately colored blobs are detected with a Bayesian classifier, which is bootstrapped with a small set of training data. Then, an online iterative training procedure is employed to refine the classifier using additional training images. Online adaptation of color probabilities is used to enable the classifier to cope with illumination changes. Tracking over time is realized through a novel technique, which can handle multiple colored blobs. Such blobs may move in complex trajectories and occlude each other in the field of view of a possibly moving camera, while \u2026",
            "Abstract entirety": 0,
            "Author pub id": "9OieklkAAAAJ:kNdYIx-mwKoC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Propagation of pixel hypotheses for multiple objects tracking",
            "Publication year": 2009,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-642-10520-3_13",
            "Abstract": "In this paper we propose a new approach for tracking multiple objects in image sequences. The proposed approach differs from existing ones in important aspects of the representation of the location and the shape of tracked objects and of the uncertainty associated with them. The location and the speed of each object is modeled as a discrete time, linear dynamical system which is tracked using Kalman filtering. Information about the spatial distribution of the pixels of each tracked object is passed on from frame to frame by propagating a set of pixel hypotheses, uniformly sampled from the original object\u2019s projection to the target frame using the object\u2019s current dynamics, as estimated by the Kalman filter. The density of the propagated pixel hypotheses provides a novel metric that is used to associate image pixels with existing object tracks by taking into account both the shape of each object and the \u2026",
            "Abstract entirety": 0,
            "Author pub id": "9OieklkAAAAJ:hC7cP41nSMkC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "Developing visual competencies for socially assistive robots: the HOBBIT approach",
            "Publication year": 2013,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/2504335.2504395",
            "Abstract": "In this paper, we present our approach towards developing visual competencies for socially assistive robots within the framework of the HOBBIT project. We show how we integrated several vision modules using a layered architectural scheme. Our goal is to endow the mobile robot with visual perception capabilities so that it can interact with the users. We present the key modules of independent motion detection, object detection, body localization, person tracking, head pose estimation and action recognition and we explain how they serve the goal of natural integration of robots in social environments.",
            "Abstract entirety": 1,
            "Author pub id": "9OieklkAAAAJ:PELIpwtuRlgC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Deformable 2D shape matching based on shape contexts and dynamic programming",
            "Publication year": 2009,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-642-10520-3_43",
            "Abstract": "This paper presents a method for matching closed, 2D shapes (2D object silhouettes) that are represented as an ordered collection of shape contexts [1]. Matching is performed using a recent method that computes the optimal alignment of two cyclic strings in sub-cubic runtime. Thus, the proposed method is suitable for efficient, near real-time matching of closed shapes. The method is qualitatively and quantitatively evaluated using several datasets. An application of the method for joint detection in human figures is also presented.",
            "Abstract entirety": 1,
            "Author pub id": "9OieklkAAAAJ:M05iB0D1s5AC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "HANDS18: Methods, Techniques and Applications for Hand Observation",
            "Publication year": 2018,
            "Publication url": "https://openaccess.thecvf.com/content_eccv_2018_workshops/w32/html/Oikonomidis_HANDS18_Methods_Techniques_and_Applications_for_Hand_Observation_ECCVW_2018_paper.html",
            "Abstract": "This report outlines the proceedings of the Fourth International Workshop on Observing and Understanding Hands in Action (HANDS 2018). The fourth instantiation of this workshop attracted significant interest from both academia and the industry. The program of the workshop included regular papers that are published as the workshop\u2019s proceedings, extended abstracts, invited posters, and invited talks. Topics of the submitted works and invited talks and posters included novel methods for hand pose estimation from RGB, depth, or skeletal data, datasets for special cases and real-world applications, and techniques for hand motion re-targeting and hand gesture recognition. The invited speakers are leaders in their respective areas of specialization, coming from both industry and academia. The main conclusions that can be drawn are the turn of the community towards RGB data and the maturation of some methods and techniques, which in turn has led to increasing interest for real-world applications.",
            "Abstract entirety": 1,
            "Author pub id": "9OieklkAAAAJ:OP4eGU-M3BUC",
            "Publisher": "Unknown"
        },
        {
            "Title": "PaperView: augmenting physical surfaces with location-aware digital information",
            "Publication year": 2011,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/1935701.1935713",
            "Abstract": "A frequent need of museums is to provide visitors with context-sensitive information about exhibits in the form of maps, or scale models. This paper suggests an augmented-reality approach for supplementing physical surfaces with digital information, through the use of pieces of plain paper that act as personal, location-aware, interactive screens. The technologies employed are presented, along with the interactive behavior of the system, which was instantiated and tested in the form of two prototype setups: a wooden table covered with a printed map and a glass case containing a scale model. The paper also discusses key issues stemming from experience and observations in the course of qualitative evaluation sessions.",
            "Abstract entirety": 1,
            "Author pub id": "9OieklkAAAAJ:hFOr9nPyWt4C",
            "Publisher": "ACM"
        },
        {
            "Title": "Novelty Detection for Person Re-identification in an Open World",
            "Publication year": 2019,
            "Publication url": "https://www.scitepress.org/Papers/2019/73683/73683.pdf",
            "Abstract": "A fundamental assumption in most contemporary person re-identification research, is that all query persons that need to be re-identified belong to a closed gallery of known persons, ie, they have been observed and a representation of their appearance is available. For several real-world applications, this closed-world assumption does not hold, as image queries may contain people that the re-identification system has never observed before. In this work, we remove this constraining assumption. To do so, we introduce a novelty detection mechanism that decides whether a person in a query image exists in the gallery. The re-identification of persons existing in the gallery is easily achieved based on the persons representation employed by the novelty detection mechanism. The proposed method operates on a hybrid person descriptor that consists of both supervised (learnt) and unsupervised (hand-crafted) components. A series of experiments on public, state of the art datasets and in comparison with state of the art methods shows that the proposed approach is very accurate in identifying persons that have not been observed before and that this has a positive impact on re-identification accuracy.",
            "Abstract entirety": 1,
            "Author pub id": "9OieklkAAAAJ:8xutWZnSdmoC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Object tracking and segmentation in a closed loop",
            "Publication year": 2010,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-642-17289-2_39",
            "Abstract": "We introduce a new method for integrated tracking and segmentation of a single non-rigid object in an monocular video, captured by a possibly moving camera. A closed-loop interaction between EM-like color-histogram-based tracking and Random Walker-based image segmentation is proposed, which results in reduced tracking drifts and in fine object segmentation. More specifically, pixel-wise spatial and color image cues are fused using Bayesian inference to guide object segmentation. The spatial properties and the appearance of the segmented objects are exploited to initialize the tracking algorithm in the next step, closing the loop between tracking and segmentation. As confirmed by experimental results on a variety of image sequences, the proposed approach efficiently tracks and segments previously unseen objects of varying appearance and shape, under challenging environmental conditions.",
            "Abstract entirety": 1,
            "Author pub id": "9OieklkAAAAJ:vV6vV6tmYwMC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "Faster and Simpler SNN Simulation with Work Queues",
            "Publication year": 2020,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/9206752/",
            "Abstract": "We present a clock-driven Spiking Neural Network simulator which is up to 3x faster than the state of the art while, at the same time, being more general and requiring less programming effort on both the user\u2019s and maintainer\u2019s side. This is made possible by designing our pipeline around \"work queues\" which act as interfaces between stages and greatly reduce implementation complexity. We evaluate our work using three well-established SNN models on a series of benchmarks.",
            "Abstract entirety": 1,
            "Author pub id": "9OieklkAAAAJ:owLR8QvbtFgC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Unsupervised Detection of Periodic Segments in Videos",
            "Publication year": 2018,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/8451336/",
            "Abstract": "We present a solution to the problem of discovering all periodic segments of a video and of estimating their period in a completely unsupervised manner. These segments may be located anywhere in the video, may differ in duration, speed, period and may represent unseen motion patterns of any type of objects (e.g., humans, animals, machines, etc). The proposed method capitalizes on earlier research on the problem of detecting common actions in videos, also known as commonality detection or video co-segmentation. The proposed method has been evaluated quantitatively and in comparison to a baseline, power-spectrum-based approach, on two ground-truth-annotated datasets (MHAD202-v, PERTUBE). From those, PERTUBE has been compiled specifically for the purposes of this study and includes a collection of you tube videos that have been shot in the wild, with several periodic segments. The results of \u2026",
            "Abstract entirety": 0,
            "Author pub id": "9OieklkAAAAJ:3htObqc8RwsC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Fusion of range and visual data for the extraction of scene structure information",
            "Publication year": 2002,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/1047388/",
            "Abstract": "In this paper a method for inferring 3D structure information based on both range and visual data is proposed. Data fusion is achieved by validating assumptions formed according to 2D range scans of the environment, through the exploitation of visual information. The proposed method is readily applicable to robot navigation tasks providing significant advantages over existing methods.",
            "Abstract entirety": 1,
            "Author pub id": "9OieklkAAAAJ:ULOm3_A8WrAC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Three-dimensional tracking of multiple skin-colored regions by a moving stereoscopic system",
            "Publication year": 2004,
            "Publication url": "https://www.osapublishing.org/abstract.cfm?uri=AO-43-2-366",
            "Abstract": "A system that performs three-dimensional (3D) tracking of multiple skin-colored regions (SCRs) in images acquired by a calibrated, possibly moving stereoscopic rig is described. The system consists of a collection of techniques that permit the modeling and detection of SCRs, the determination of their temporal association in monocular image sequences, the establishment of their correspondence between stereo images, and the extraction of their 3D positions in a world-centered coordinate system. The development of these techniques has been motivated by the need for robust, near-real-time tracking performance. SCRs are detected by use of a Bayesian classifier that is trained with the aid of a novel technique. More specifically, the classifier is bootstrapped with a small set of training data. Then, as new images are being processed, an iterative training procedure is employed to refine the classifier. Furthermore, a \u2026",
            "Abstract entirety": 0,
            "Author pub id": "9OieklkAAAAJ:fPk4N6BV_jEC",
            "Publisher": "[New York: Optical Society of America], 1962-"
        },
        {
            "Title": "Retinal image registration as a tool for supporting clinical applications",
            "Publication year": 2021,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S0169260720317338",
            "Abstract": "Background and Objective: The study of small vessels allows for the analysis and diagnosis of diseases with strong vasculopathy. This type of vessels can be observed non-invasively in the retina via fundoscopy. The analysis of these vessels can be facilitated by applications built upon Retinal Image Registration (RIR), such as mosaicing, Super Resolution (SR) or eye shape estimation. RIR is challenging due to possible changes in the retina across time, the utilization of diverse acquisition devices with varying properties, or the curved shape of the retina.Methods: We employ the Retinal Image Registration through Eye Modelling and Pose Estimation (REMPE) framework, which simultaneously estimates the cameras\u2019 relative poses, as well as eye shape and orientation to develop RIR applications and to study their effectiveness.Results: We assess quantitatively the suitability of the REMPE framework towards \u2026",
            "Abstract entirety": 0,
            "Author pub id": "9OieklkAAAAJ:HGTzPopzzJcC",
            "Publisher": "Elsevier"
        },
        {
            "Title": "Retinal Image Registration Based on Keypoint Correspondences, Spherical Eye Modeling and Camera Pose Estimation",
            "Publication year": 2015,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/7319674/",
            "Abstract": "In this work, an image registration method for two retinal images is proposed. The proposed method utilizes keypoint correspondences and assumes a spherical model of the eye. Image registration is treated as a pose estimation problem, which requires estimation of the rigid transformation that relates the two images. Using this estimate, one image can be warped so that it is registered to the coordinate frame of the other. Experimental evaluation shows improved accuracy over state-of-the-art approaches as well as robustness to noise and spurious keypoint correspondences. Experiments also indicate the method's applicability to diagnostic image enhancement and comparative analysis of images from different examinations.",
            "Abstract entirety": 1,
            "Author pub id": "9OieklkAAAAJ:XD-gHx7UXLsC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Interactive tele-presence in exhibitions through web-operated robots",
            "Publication year": 2003,
            "Publication url": "http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.2.8893",
            "Abstract": "The current paper presents techniques that facilitate mobile robots to be deployed as interactive agents in populated environments, such as museum exhibitions or trade shows. The mobile robots can be teleoperated over the Internet and this way provide remote access to distant users. Throughout this paper we describe several key techniques that have been developed in the context of relevant EU-IST projects. The developed robotic systems have been installed and extensively operated in the premises of various sites. The use of the above techniques, combined with appropriate authoring tools, has resulted in drastic reduction in the installation times. Such demonstrations ascertain the functionality and reliability of our methods and provide evidence regarding the effectiveness of the complete systems.",
            "Abstract entirety": 1,
            "Author pub id": "9OieklkAAAAJ:iH-uZ7U-co4C",
            "Publisher": "Unknown"
        },
        {
            "Title": "CVPR 2016 Outstanding Reviewers",
            "Publication year": 2016,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/7789497/",
            "Abstract": "Outstanding Reviewers Page 1 CVPR 2016 Outstanding Reviewers We are pleased to \nrecognize the following researchers as \"CVPR 2016 Outstanding Reviewers\". These reviewers \nwere identified by one or more of the CVPR Area Chairs for their hard work in providing high \nquality and detailed reviews for their assigned papers. Zeynep Akata Relja Arandjelovic Antonis \nArgyros Tamar Avraham Steve Branson Jongmoo Choi Andrew Davison Alexander Fix Andreas \nGeiger Ioannis Gkioulekas Kristen Grauman Abhinav Gupta CV Jawahar Dinesh Jayaraman \nPhilipp Krahenbuhl Josip Krapac Jonathan Long Philippos Mordohai Alison Noble Peter \nOchs Matthew O'Toole Emanuele Rodola Marcus Rohrbach Javier Romero Miki Rubinstein \nOlga Russakovsky Bogdan Savchynskyy Stan Sclaroff Joseph Sivic Cees Snoek Deqing \nSun Akihiko Torii Tinne Tuytelaars Anton van den Hengel Jan van Gemert Andrea Vedaldi \u2026",
            "Abstract entirety": 0,
            "Author pub id": "9OieklkAAAAJ:HbR8gkJAVGIC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Visual homing for undulatory robotic locomotion",
            "Publication year": 2009,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/5152432/",
            "Abstract": "This paper addresses the problem of vision-based closed-loop control for undulatory robots. We present an image-based visual servoing scheme, which drives the robot to a desired location specified by a target image, without explicitly estimating its pose. Instead, the control relies on the computation of the epipolar geometry between the current and target images. We analyze controllability and stability of the proposed control scheme, which is validated by simulation studies using the SIMUUN computational tools. Preliminary experiments, involving the Nereisbot undulatory robotic prototype, are also presented.",
            "Abstract entirety": 1,
            "Author pub id": "9OieklkAAAAJ:RYcK_YlVTxYC",
            "Publisher": "IEEE"
        },
        {
            "Title": "MocapNET: Ensemble of SNN Encoders for 3D Human Pose Estimation in RGB Images",
            "Publication year": 2019,
            "Publication url": "https://bmvc2019.org/wp-content/uploads/papers/0710-paper.pdf",
            "Abstract": "We present MocapNET, an ensemble of SNN [28] encoders that estimates the 3D human body pose based on 2D joint estimations extracted from monocular RGB images. MocapNET provides an efficient divide and conquer strategy for supervised learning. It outputs skeletal information directly into the BVH [41] format which can be rendered in real-time or imported without any additional processing in most popular 3D animation software. The proposed architecture achieves 3D human pose estimations at state of the art rates of 400Hz using only CPU processing.",
            "Abstract entirety": 1,
            "Author pub id": "9OieklkAAAAJ:1taIhTC69MYC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Tracking hands and hand-object interactions",
            "Publication year": 2014,
            "Publication url": "https://scholar.google.com/scholar?cluster=7400781499734029880&hl=en&oi=scholarr",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "9OieklkAAAAJ:xtoqd-5pKcoC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Efficient scale and rotation invariant object detection based on hogs and evolutionary optimization techniques",
            "Publication year": 2012,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-642-33179-4_22",
            "Abstract": "Object detection and localization in an image can be achieved by representing an object as a Histogram of Oriented Gradients (HOG). HOGs have proven to be robust object descriptors. However, to achieve accurate object localization, one must take a sliding window approach and evaluate the similarity of the descriptor over all possible windows in an image. In case that search should also be scale and rotation invariant, the exhaustive consideration of all possible HOG transformations makes the method impractical due to its computational complexity. In this work, we first propose a variant of an existing rotation invariant HOG-like descriptor. We then formulate object detection and localization as an optimization problem that is solved using the Particle Swarm Optimization (PSO) method. A series of experiments demonstrates that the proposed approach results in very large performance gains without \u2026",
            "Abstract entirety": 0,
            "Author pub id": "9OieklkAAAAJ:BrmTIyaxlBUC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "Evolutionary Quasi-random Search for Hand Articulations Tracking",
            "Publication year": 2014,
            "Publication url": "http://openaccess.thecvf.com/content_cvpr_2014/html/Oikonomidis_Evolutionary_Quasi-random_Search_2014_CVPR_paper.html",
            "Abstract": "We present a new method for tracking the 3D position, global orientation and full articulation of human hands. Following recent advances in model-based, hypothesize-and-test methods, the high-dimensional parameter space of hand configurations is explored with a novel evolutionary optimization technique specifically tailored to the problem. The proposed method capitalizes on the fact that samples from quasi-random sequences such as the Sobol have low discrepancy and exhibit a more uniform coverage of the sampled space compared to random samples obtained from the uniform distribution. The method has been tested for the problems of tracking the articulation of a single hand (27D parameter space) and two hands (54D space). Extensive experiments have been carried out with synthetic and real data, in comparison with state of the art methods. The quantitative evaluation shows that for cases of limited computational resources, the new approach achieves a speed-up of four (single hand tracking) and eight (two hands tracking) without compromising tracking accuracy. Interestingly, the proposed method is preferable compared to the state of the art either in the case of limited computational resources or in the case of more complex (ie, higher dimensional) problems, thus improving the applicability of the method in a number of application domains.",
            "Abstract entirety": 1,
            "Author pub id": "9OieklkAAAAJ:W5xh706n7nkC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Parameter-free modelling of 2D shapes with ellipses",
            "Publication year": 2016,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S0031320315004240",
            "Abstract": "Our goal is to represent a given 2D shape with an automatically determined number of ellipses, so that the total area covered by the ellipses is equal to the area of the original shape without any assumption or prior knowledge about the object structure. To solve this interesting theoretical problem, first we employ the skeleton of the 2D shape which provides important information on the parameters of the ellipses that could approximate the original shape. For a given number of such ellipses, the hard Expectation-Maximisation (EM) algorithm is employed to maximise the shape coverage under the Equal Area constraint. Different models (i.e., solutions involving different numbers of ellipses) are evaluated based on the Akaike Information Criterion (AIC). This considers a novel, entropy-based shape complexity measure that balances the model complexity and the model approximation error. In order to minimise the AIC \u2026",
            "Abstract entirety": 0,
            "Author pub id": "9OieklkAAAAJ:nrtMV_XWKgEC",
            "Publisher": "Pergamon"
        },
        {
            "Title": "Localizing unordered panoramic images using the Levenshtein distance",
            "Publication year": 2007,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/4409200/",
            "Abstract": "This paper proposes a feature-based method for recovering the relative positions of the viewpoints of a set of panoramic images for which no a priori order information is available, along with certain structure information regarding the imaged environment. The proposed approach operates incrementally, employing the Levenshtein distance to deduce the spatial proximity of image viewpoints and thus determine the order in which images should be processed. The Levenshtein distance also provides matches between images, from which their underlying environment points can be recovered. Recovered points that are visible in multiple views permit the localization of more views which in turn allow the recovery of more points. The process repeats until all views have been localized. Periodic refinement of the reconstruction with the aid of bundle adjustment, distributes the reconstruction errors among images. The \u2026",
            "Abstract entirety": 0,
            "Author pub id": "9OieklkAAAAJ:k_IJM867U9cC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Robust and efficient event detection for the monitoring of automated processes",
            "Publication year": 2006,
            "Publication url": "https://digital-library.theiet.org/content/conferences/10.1049/cp_20060573",
            "Abstract": "We present a new approach for the detection of events in image sequences. Our method relies on a number of logical sensors that can be defined over specific regions of interest in the viewed scene. These sensors measure time varying image properties that can be attributed to primitive events of interest. Thus, the logical sensors can be viewed as a means to transform image data to a set of symbols that can assist event detection and activities interpretation. On top of these elementary sensors, temporal and logical aggregation mechanisms are used to define hierarchies of progressively more complex sensors, able to detect events having more complex semantics. Finally, scenario verification mechanisms are employed to achieve process monitoring, by checking whether events occur according to a predetermined order. The proposed framework has been tested and validated in an application involving \u2026",
            "Abstract entirety": 0,
            "Author pub id": "9OieklkAAAAJ:YFjsv_pBGBYC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Towards Augmented Reality in Museums: Evaluation of Design Choices for 3D Object Pose Estimation",
            "Publication year": 2021,
            "Publication url": "https://scholar.google.com/scholar?cluster=10652861654384713759&hl=en&oi=scholarr",
            "Abstract": "The solutions to many computer vision problems, including that of 6D object pose estimation, are dominated nowadays by the explosion of the learning-based paradigm. In this paper, we investigate 6D object pose estimation in a practical, real-word setting in which a mobile device (smartphone/tablet) needs to be localized in front of a museum exhibit, in support of an augmented-reality application scenario. In view of the constraints and the priorities set by this particular setting, we consider an appropriately tailored classical as well as a learning-based method. Moreover, we develop a hybrid method that consists of both classical and learning based components. All three methods are evaluated quantitatively on a standard, benchmark dataset, but also on a new dataset that is specific to the museum guidance scenario of interest.",
            "Abstract entirety": 1,
            "Author pub id": "9OieklkAAAAJ:U_HPUtbDl20C",
            "Publisher": "Frontiers"
        },
        {
            "Title": "Integrated vision system for the semantic interpretation of activities where a person handles objects",
            "Publication year": 2009,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S1077314208001847",
            "Abstract": "Interpretation of human activity is primarily known from surveillance and video analysis tasks and concerned with the persons alone. In this paper we present an integrated system that gives a natural language interpretation of activities where a person handles objects. The system integrates low-level image components such as hand and object tracking, detection and recognition, with high-level processes such as spatio-temporal object relationship generation, posture and gesture recognition, and activity reasoning. A task-oriented approach focuses processing to achieve near real-time and to react depending on the situation context.",
            "Abstract entirety": 1,
            "Author pub id": "9OieklkAAAAJ:KlAtU1dfN6UC",
            "Publisher": "Academic Press"
        },
        {
            "Title": "Experiences from the Use of a Robotic Avatar",
            "Publication year": 2001,
            "Publication url": "https://scholar.google.com/scholar?cluster=13971888496148759437&hl=en&oi=scholarr",
            "Abstract": "Access to cultural exhibits is a central issue in museums and exhibition galleries that is recently approached under a new, technological perspective. Although the cultural industries' practices in the cases of museums and cultural exhibits have remained practically unchanged for long, in recent years we are witnessing a gradual adoption of media-technologies in various aspects, such as collections archiving and digital document preservation, media-and Web-presentation, graphical animations, etc. Lately, Internet and Web-based technologies have been employed for providing access, mostly to images of exhibited objects. In few cases, the incorporation of higher-end technology, such as virtual reality, artificial intelligence, or robotics, is explored. In this paper we present such an effort, the TOURBOT project (an acronym for TOUr-guide RoBOT), which emphasizes the development of alternative ways for interactive museum tele-presence, essentially through the use of robotic\" avatars\", and comment on the experience gained from its use in a museum settingCopyright\u00a9 2002 by the Association for Computing Machinery, Inc.",
            "Abstract entirety": 1,
            "Author pub id": "9OieklkAAAAJ:uVUOdF_882EC",
            "Publisher": "Association for Computing Machinery"
        },
        {
            "Title": "Vision based Horizon Detection for UAV Navigation",
            "Publication year": 2018,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-030-00232-9_19",
            "Abstract": "In this paper, we present a novel framework for horizon line (HL) detection that can be effectively used for Unmanned Air Vehicle (UAV) navigation. Our scheme is based on a Canny edge and a Hough detector along with an optimization step performed by a Particle Swarm Optimization (PSO) algorithm. The PSO\u2019s objective function is based on a variation of the Bag of Words (BOW) method to effectively consider multiple image descriptors and facilitate efficient computation times. More specifically, the image descriptors employed are  color features, texture features, and SIFT features. We demonstrate the effectiveness and robustness of the proposed novel horizon line detector in multiple image sets captured under real world conditions. First, we experimentally compare the proposed scheme with the Hough HL detector and a deep learning HL estimator, a prominent example of line detection, and \u2026",
            "Abstract entirety": 0,
            "Author pub id": "9OieklkAAAAJ:a3BOlSfXSfwC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Fast trifocal tensor estimation using virtual parallax",
            "Publication year": 2005,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/1529999/",
            "Abstract": "We present a computationally efficient method for estimating the trifocal tensor corresponding to three images acquired by a freely moving camera. The proposed method represents projective space through a \"plane + parallax\" decomposition and employs a novel technique for estimating the homographies induced by a virtual 3D plane between successive image pairs. Knowledge of these homographies allows the corresponding camera projection matrices to be expressed in a common projective frame and, therefore, to be recovered directly. The trifocal tensor can then be recovered in a straightforward manner from the estimated projection matrices. Sample experimental results demonstrate that the method performs considerably faster compared to a state of the art method, without a serious loss in accuracy.",
            "Abstract entirety": 1,
            "Author pub id": "9OieklkAAAAJ:aqlVkmm33-oC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Horizon matching for localizing unordered panoramic images",
            "Publication year": 2010,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S1077314209000472",
            "Abstract": "There is currently an abundance of vision algorithms which, provided with a sequence of images that have been acquired from sufficiently close successive 3D locations, are capable of determining the relative positions of the viewpoints from which the images have been captured. However, very few of these algorithms can cope with unordered image sets. This paper presents an efficient method for recovering the position and orientation parameters corresponding to the viewpoints of a set of panoramic images for which no a priori order information is available, along with certain structure information regarding the imaged environment. The proposed approach assumes that all images have been acquired from a constant height above a planar ground and operates sequentially, employing the Levenshtein distance to deduce the spatial proximity of image viewpoints and thus determine the order in which images \u2026",
            "Abstract entirety": 0,
            "Author pub id": "9OieklkAAAAJ:1sJd4Hv_s6UC",
            "Publisher": "Academic Press"
        },
        {
            "Title": "Learning to Infer the Depth Map of a Hand from its Color Image",
            "Publication year": 2020,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/9206925/",
            "Abstract": "We present the first direct approach targeted explicitly on human hands that infers depth from monocular RGB images. We achieve this with a Convolutional Neural Network (CNN) that employs a stacked hourglass model as its main building block. Intermediate supervision is used in several outputs of the proposed architecture in a staged approach. To aid the process of training and inference, hand segmentation masks are also estimated in such intermediate supervision steps, and used to guide the subsequent depth estimation process. In order to train and evaluate the proposed method we compile and make publicly available HandRGBD, a new dataset of 20,601 views of hands, each consisting of an RGB image and an aligned depth map. Based on HandRGBD, we explore variants of the proposed approach in an ablative study and determine the most accurate one. The results of an extensive experimental \u2026",
            "Abstract entirety": 0,
            "Author pub id": "9OieklkAAAAJ:nZcligLrVowC",
            "Publisher": "Unknown"
        },
        {
            "Title": "A graph-based approach to corner matching using mutual information as a local similarity measure",
            "Publication year": 2004,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/1334386/",
            "Abstract": "Corner matching constitutes a fundamental vision problem that serves as a building block of several important applications. The common approach to dealing with this problem starts by ranking potential matches according to their affinity, which is assessed with the aid of window-based intensity similarity measures. Then, actual matches are established by optimizing global criteria involving all potential matches. This paper puts forward a novel approach for solving the corner matching problem that uses mutual information as a window similarity measure, combined with graph matching techniques for determining a matching of corners that is globally optimal. Experimental results illustrate the effectiveness of the approach.",
            "Abstract entirety": 1,
            "Author pub id": "9OieklkAAAAJ:8k81kl-MbHgC",
            "Publisher": "Unknown"
        },
        {
            "Title": "A Generative Approach to Tracking Hands and Their Interaction with Objects",
            "Publication year": 2015,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-319-23437-3_2",
            "Abstract": "Markerless 3D tracking of hands in action or in interaction with objects provides rich information that can be used to interpret a number of human activities. In this paper, we review a number of relevant methods we have proposed. All of them focus on hands, objects and their interaction and follow a generative approach. The major strength of such an approach is the straightforward fashion in which arbitrarily complex priors can be easily incorporated towards solving the tracking problem and their capability to generalize to greater and/or different domains. The proposed generative approach is implemented in a single, unified computational framework.",
            "Abstract entirety": 1,
            "Author pub id": "9OieklkAAAAJ:9Nmd_mFXekcC",
            "Publisher": "Springer International Publishing"
        },
        {
            "Title": "The HealthSign project, current state and future activities",
            "Publication year": 2019,
            "Publication url": "Unknown",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "9OieklkAAAAJ:6bLC7aUMtPcC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Qualitative evaluation of the cue integration and the tracking trajectories",
            "Publication year": 2003,
            "Publication url": "http://actipret.acin.tuwien.ac.at/Sites/D2_2_final_V1_0.pdf",
            "Abstract": "Deliverable D2. 2 describes a system that performs 3D tracking of multiple skincolored regions (SCRs) in images acquired by a calibrated, possibly moving stereoscopic rig. The proposed system consists of a collection of techniques that enable the modeling and detection of SCRs, the determination of their temporal association in monocular image sequences, the establishment of their correspondence between stereo images and the extraction of their 3D position in a world-centered coordinate system. The development of these techniques has been motivated by the need for robust, near real time performance. SCRs are detected using a Bayesian classifier whose training is performed with the aid of a novel technique. More specifically, the classifier is bootstrapped with a small set of training data. Then, as new images are being processed, an iterative training procedure is employed to refine the classifier. Furthermore, a technique is proposed for enabling the classifier to cope with illumination changes. Tracking of SCRs in time as well as association of SCRs in the images of the employed stereo rig is performed through computationally inexpensive and robust techniques. Association of SCRs in time is performed by a method that can cope with multiple SCRs, as they dynamically enter and exit the field of view of a moving observer while possibly occluding each other. One of the main characteristics of the developed Skin-Colored Regions Tracker (SCRT) is its ability to report the 3D position of SCRs in a world-centered coordinate system by employing a possibly moving stereo-rig with independently verging CCD cameras. The developed system \u2026",
            "Abstract entirety": 0,
            "Author pub id": "9OieklkAAAAJ:HoB7MX3m0LUC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Robust 3d human pose estimation guided by filtered subsets of body keypoints",
            "Publication year": 2019,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/8757907/",
            "Abstract": "We propose a novel hybrid human 3D body pose estimation method that uses RGBD input. The method relies on a deep neural network to get an initial 2D body pose. Using depth information from the sensor, a set of 2D landmarks on the body are transformed in 3D. Then, a multiple hypothesis tracker uses the obtained 2D and 3D body landmarks to estimate the 3D body pose. In order to safeguard from observation errors, each human pose hypothesis considered by the tracker is constructed using a gradient descent optimization scheme that is applied to a subset of the body landmarks. Landmark selection is driven by a set of geometric constraints and temporal continuity criteria. The resulting 3D poses are evaluated by an objective function that calculates densely the discrepancy between the 3D structure of the rendered 3D human body model and the actual depth observed by the sensor. The quantitative \u2026",
            "Abstract entirety": 0,
            "Author pub id": "9OieklkAAAAJ:7Hz3ACDFbsoC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Towards force sensing from vision: Observing hand-object interactions to infer manipulation forces",
            "Publication year": 2015,
            "Publication url": "http://openaccess.thecvf.com/content_cvpr_2015/html/Pham_Towards_Force_Sensing_2015_CVPR_paper.html",
            "Abstract": "We present a novel, non-intrusive approach for estimating contact forces during hand-object interactions relying solely on visual input provided by a single RGB-D camera. We consider a manipulated object with known geometrical and physical properties. First, we rely on model-based visual tracking to estimate the object's pose together with that of the hand manipulating it throughout the motion. Following this, we compute the object's first and second order kinematics using a new class of numerical differentiation operators. The estimated kinematics is then instantly fed into a second-order cone program that returns a minimal force distribution explaining the observed motion. However, humans typically apply more forces than mechanically required when manipulating objects. Thus, we complete our estimation method by learning these excessive forces and their distribution among the fingers in contact. We provide a full validity analysis of the proposed method by evaluating it based on ground truth data from additional sensors such as accelerometers, gyroscopes and pressure sensors. Experimental results show that force sensing from vision (FSV) is indeed feasible.",
            "Abstract entirety": 1,
            "Author pub id": "9OieklkAAAAJ:evX43VCCuoAC",
            "Publisher": "IEEE"
        },
        {
            "Title": "A prototypical interactive exhibition for the archaeological museum of thessaloniki",
            "Publication year": 2013,
            "Publication url": "https://journals.sagepub.com/doi/abs/10.1260/2047-4970.2.1.75",
            "Abstract": "In 2010, the Institute of Computer Science of the Foundation for Research and Technology-Hellas (ICS-FORTH) and the Archaeological Museum of Thessaloniki (AMTh) collaborated towards the creation of a special exhibition of prototypical interactive systems with subjects drawn from ancient Macedonia, named \u201cMacedonia from fragments to pixels\u201d. The exhibition comprises seven interactive systems based on the research outcomes of ICS-FORTH's Ambient Intelligence Programme. Up to the summer of 2012, more than 165.000 people have visited it. The paper initially provides some background information, including related previous research work, and then illustrates and discusses the development process that was followed for creating the exhibition. Subsequently, the technological and interactive characteristics of the project's outcomes (i.e., the interactive systems) are analysed and the complementary \u2026",
            "Abstract entirety": 0,
            "Author pub id": "9OieklkAAAAJ:_B80troHkn4C",
            "Publisher": "SAGE Publications"
        },
        {
            "Title": "Retinal Image Registration Through Simultaneous Camera Pose and Eye Shape Estimation",
            "Publication year": 2016,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/7591421/",
            "Abstract": "In this paper, a retinal image registration method is proposed. The approach utilizes keypoint correspondences and assumes that the human eye has a spherical or ellipsoidal shape. The image registration problem amounts to solving a camera 3D pose estimation problem and, simultaneously, an eye 3D shape estimation problem. The camera pose estimation problem is solved by estimating the relative pose between the views from which the images were acquired. The eye shape estimation problem parameterizes the shape and orientation of an ellipsoidal model for the eye. Experimental evaluation shows 17.91% reduction of registration error and 47.52% reduction of the error standard deviation over state of the art methods.",
            "Abstract entirety": 1,
            "Author pub id": "9OieklkAAAAJ:PoWvk5oyLR8C",
            "Publisher": "IEEE"
        },
        {
            "Title": "A Software Platform for the Acquisition and Online Processing of Images in a Camera Network",
            "Publication year": 2009,
            "Publication url": "https://www.academia.edu/download/41503880/A_Software_Platform_for_the_Acquisition_20160124-20768-1ode81i.pdf",
            "Abstract": "Applications related to vision-based monitoring of spaces and to the visual understanding of human behaviour, require the synchronous imaging of a scene from multiple views. We present the design and implementation of a software platform that enables synchronous acquisition of images from a camera network and supports their distribution across computers. Seamless and online delivery of acquired data to multiple distributed processes facilitates the development of parallel applications. As a case study, we describe the use of the platform in a vision system targeted at unobtrusive human-computer interaction.",
            "Abstract entirety": 1,
            "Author pub id": "9OieklkAAAAJ:dTyEYWd-f8wC",
            "Publisher": "Unknown"
        },
        {
            "Title": "TOURBOT and WebFAIR: Web-operated mobile robots for tele-presence in populated exhibitions",
            "Publication year": 2002,
            "Publication url": "http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.226.4142&rep=rep1&type=pdf#page=31",
            "Abstract": "The current paper presents techniques that facilitate mobile robots to be deployed as interactive agents in populated environments, such as museum exhibitions or trade shows. The mobile robots can be tele-operated over the Internet and this way provide remote access to distant users. Throughout this paper we describe several key techniques that have been developed in the relevant projects. They include robust mapping and localization, people-tracking and advanced visualizations for Web users. The developed robotic systems have been installed and operated in the premises of various sites. Use of the above techniques, as well as appropriate authoring tools, has resulted in drastic reduction in the installation times. Additionally, the systems were thoroughly tested and validated in real-world conditions. Such demonstrations ascertain the functionality and reliability of our methods and provide evidence as of the operation of the complete systems.",
            "Abstract entirety": 1,
            "Author pub id": "9OieklkAAAAJ:MXK_kJrjxJIC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Using Geometric Constraints for Matching Disparate Stereo Views of 3D Scenes Containing Planes",
            "Publication year": 2000,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/905366/",
            "Abstract": "Several vision tasks rely upon the availability of sets of corresponding features among images. This paper presents a method which, given some corresponding features in two stereo images, addresses the problem of matching them with features extracted from a second stereo pair captured from a distant viewpoint. The proposed method is based on the assumption that the viewed scene contains two planar surfaces and exploits geometric constraints that are imposed by the existence of these planes to predict the location of image features in the second stereo pair. The resulting scheme handles point and line features in a unified manner and is capable of successfully matching features extracted from stereo pairs acquired from considerably different viewpoints. Experimental results from a prototype implementation demonstrate the effectiveness of the approach.",
            "Abstract entirety": 1,
            "Author pub id": "9OieklkAAAAJ:2P1L_qKh6hAC",
            "Publisher": "Unknown"
        },
        {
            "Title": "A Decentralized Framework for Efficient Cooperation of Heterogeneous Robotic Agents",
            "Publication year": 2021,
            "Publication url": "Unknown",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "9OieklkAAAAJ:PyEswDtIyv0C",
            "Publisher": "\u0399\u0395\u0395\u0395"
        },
        {
            "Title": "Design and development of four prototype interactive edutainment exhibits for museums",
            "Publication year": 2011,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-642-21666-4_20",
            "Abstract": "This paper describes the outcomes stemming from the work of a multidisciplinary R&D project of ICS-FORTH, aiming to explore and experiment with novel interactive museum exhibits, and to assess their utility, usability and potential impact. More specifically, four interactive systems are presented in this paper which have been integrated, tested and evaluated in a dedicated, appropriately designed, laboratory space. The paper also discusses key issues stemming from experience and observations in the course of qualitative evaluation sessions with a large number of participants.",
            "Abstract entirety": 1,
            "Author pub id": "9OieklkAAAAJ:bFI3QPDXJZMC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "Vision-based SLAM and moving objects tracking for the perceptual support of a smart walker platform",
            "Publication year": 2014,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-319-16199-0_29",
            "Abstract": "The problems of vision-based detection and tracking of independently moving objects, localization and map construction are highly interrelated, in the sense that the solution of any of them provides valuable information to the solution of the others. In this paper, rather than trying to solve each of them in isolation, we propose a method that treats all of them simultaneously. More specifically, given visual input acquired by a moving RGBD camera, the method detects independently moving objects and tracks them in time. Additionally, the method estimates the camera (ego)motion and the motion of the tracked objects in a coordinate system that is attached to the static environment, a map of which is progressively built from scratch. The loose assumptions that the method adopts with respect to the problem parameters make it a valuable component for any robotic platform that moves in a dynamic environment \u2026",
            "Abstract entirety": 0,
            "Author pub id": "9OieklkAAAAJ:tzM49s52ZIMC",
            "Publisher": "Springer International Publishing"
        },
        {
            "Title": "Physically Plausible 3D Scene Tracking: The Single Actor Hypothesis",
            "Publication year": 2013,
            "Publication url": "http://openaccess.thecvf.com/content_cvpr_2013/html/Kyriazis_Physically_Plausible_3D_2013_CVPR_paper.html",
            "Abstract": "In several hand-object (s) interaction scenarios, the change in the objects' state is a direct consequence of the hand's motion. This has a straightforward representation in Newtonian dynamics. We present the first approach that exploits this observation to perform model-based 3D tracking of a table-top scene comprising passive objects and an active hand. Our forward modelling of 3D hand-object (s) interaction regards both the appearance and the physical state of the scene and is parameterized over the hand motion (26 DoFs) between two successive instants in time. We demonstrate that our approach manages to track the 3D pose of all objects and the 3D pose and articulation of the hand by only searching for the parameters of the hand motion. In the proposed framework, covert scene state is inferred by connecting it to the overt state, through the incorporation of physics. Thus, our tracking approach treats a variety of challenging observability issues in a principled manner, without the need to resort to heuristics.",
            "Abstract entirety": 1,
            "Author pub id": "9OieklkAAAAJ:PR6Y55bgFSsC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Accurate constraint-based modeling from a single perspective view",
            "Publication year": 2007,
            "Publication url": "http://www.inf.ufrgs.br/cgi2007/cd_cgi/papers/lourakis.pdf",
            "Abstract": "Recovery of a 3D model from a single image is possible provided that adequate geometric knowledge about the imaged scene is a priori available. This prior knowledge is essential for disambiguating among the infinitely many 3D reconstructions that are compatible with a given 2D image. In practice, single view reconstruction methods employ geometric knowledge in the form of constraints such as coplanarity, parallelism, perpendicularity, etc, that are assumed to be supplied by a user based on his/her interpretation of the scene. Most of the existing methods, however, produce reconstructions that only approximately satisfy the supplied geometric constraints. This paper puts forward a single view reconstruction method which produces reconstructions that accurately satisfy all specified geometric constraints. This is achieved by first obtaining a preliminary reconstruction and then refining it in an extendable, constrained minimization framework. Sample experimental results demonstrate the approach.",
            "Abstract entirety": 1,
            "Author pub id": "9OieklkAAAAJ:VOx2b1Wkg3QC",
            "Publisher": "Unknown"
        },
        {
            "Title": "FIRE: fundus image registration dataset",
            "Publication year": 2017,
            "Publication url": "https://www.maio-journal.com/index.php/MAIO/article/view/42",
            "Abstract": "Purpose: Retinal image registration is a useful tool for medical professionals. However, performance evaluation of registration methods has not been consistently assessed in the literature. To address that, a dataset comprised of retinal image pairs annotated with ground truth and an evaluation protocol for registration methods is proposed.Methods: The dataset is comprised by 134 retinal fundus image pairs. These pairs are classified into three categories, according to characteristics that are relevant to indicative registration applications. Such characteristics are the degree of overlap between images and the presence/absence of anatomical differences. Ground truth in the form of corresponding image points and a protocol to evaluate registration performance are provided.Results: The proposed protocol is shown to enable quantitative and comparative evaluation of retinal registration methods under a variety of conditions.Conclusion: This work enables the fair comparison of retinal registration methods. It also helps researchers to select the registration method that is most appropriate given a specific target use.",
            "Abstract entirety": 1,
            "Author pub id": "9OieklkAAAAJ:anf4URPfarAC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Macedonia from fragments to pixels: A permanent exhibition of interactive systems at the archaeological museum of thessaloniki",
            "Publication year": 2012,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-642-34234-9_62",
            "Abstract": "The theme of this paper is an exhibition of prototypical interactive systems with subjects drawn from ancient Macedonia, named \"Macedonia from fragments to pixels\". Since 2010, the exhibition is hosted by the Archaeological Museum of Thessaloniki and is open daily to the general public. Up to now, more than 165.000 people have visited it. The exhibition comprises 7 interactive systems which are based on some research outcomes of the Ambient Intelligence Programme of the Institute of Computer Science, Foundation for Research and Technology - Hellas. The digital content of these systems includes objects from the Museum\u2019s permanent collection and from Macedonia.",
            "Abstract entirety": 1,
            "Author pub id": "9OieklkAAAAJ:olpn-zPbct0C",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "FORTH-ICS Internal RTD Programme Ambient Intelligence and Smart Environments",
            "Publication year": 2009,
            "Publication url": "https://www.ics.forth.gr/~argyros/mypapers/2009_11_AmI09_AmI.pdf",
            "Abstract": "This paper introduces the horizontal, interdisciplinary, crossthematic RTD Programme in the field of Ambient Intelligence which has recently been initiated by the Institute of Computer Science of the Foundation for Research and Technology\u2013Hellas, aiming to contribute towards the creation and provision of pioneering human-centric AmI technologies and smart environments.",
            "Abstract entirety": 1,
            "Author pub id": "9OieklkAAAAJ:e5wmG9Sq2KIC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Action Prediction During Human-Object Interaction Based on DTW and Early Fusion of Human and Object Representations",
            "Publication year": 2021,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-030-87156-7_14",
            "Abstract": "Action prediction is defined as the inference of an action label while the action is still ongoing. Such a capability is extremely useful for early response and further action planning. In this paper, we consider the problem of action prediction in scenarios involving humans interacting with objects. We formulate an approach that builds time series representations of the performance of the humans and the objects. Such a representation of an ongoing action is then compared to prototype actions. This is achieved by a Dynamic Time Warping (DTW)-based time series alignment framework which identifies the best match between the ongoing action and the prototype ones. Our approach is evaluated quantitatively on three standard benchmark datasets. Our experimental results reveal the importance of the fusion of human- and object-centered action representations in the accuracy of action prediction. Moreover, we \u2026",
            "Abstract entirety": 0,
            "Author pub id": "9OieklkAAAAJ:VN7nJs4JPk0C",
            "Publisher": "Springer, Cham"
        },
        {
            "Title": "Camera matchmoving in unprepared, unknown environments",
            "Publication year": 2005,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/1467589/",
            "Abstract": "Camera matchmoving is an application involving synthesis of real scenes and artificial objects, in which the goal is to insert computer-generated graphical 3D objects into live-action footage depicting unmodeled, arbitrary scenes. This work addresses the problem of tracking the 3D motion of a camera in space, using only the images it acquires while moving freely in unmodeled, arbitrary environments. A novel feature-based method for camera tracking has been developed, intended to facilitate tracking in online, time-critical applications such as video see-through augmented reality and vision-based control. In contrast to several existing techniques, which are designed to operate in a batch, offline mode, assuming that the whole video sequence to be tracked is available before tracking commences, our method operates on images incrementally, as they are being acquired.",
            "Abstract entirety": 1,
            "Author pub id": "9OieklkAAAAJ:M3NEmzRMIkIC",
            "Publisher": "IEEE"
        },
        {
            "Title": "A platform for monitoring aspects of human presence in real-time",
            "Publication year": 2010,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-642-17274-8_57",
            "Abstract": "In this paper, the design and implementation of a hardware/software platform for parallel and distributed multiview vision processing is presented. The platform is focused at supporting the monitoring of human presence in indoor environments. Its architecture is focused at increased throughput through process pipelining as well as at reducing communication costs and hardware requirements. Using this platform, we present efficient implementations of basic visual processes such as person tracking, textured visual hull computation and head pose estimation. Using the proposed platform multiview visual operations can be combined and third-party ones integrated, to ultimately facilitate the development of interactive applications that employ visual input. Computational performance is benchmarked comparatively to state of the art and the efficacy of the approach is qualitatively assessed in the context of \u2026",
            "Abstract entirety": 0,
            "Author pub id": "9OieklkAAAAJ:CHSYGLWDkRkC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "The muselearn platform: Personalized content for museum visitors assisted by vision-based recognition and 3D pose estimation of exhibits",
            "Publication year": 2020,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-030-49161-1_37",
            "Abstract": " MuseLearn is a platform that enhances the presentation of the exhibits of a museum with multimedia-rich content that is adapted and recommended for certain visitor profiles and playbacks on their mobile devices. The platform consists mainly of a content management system that stores and prepares multimedia material for the presentation of exhibits; a recommender system that monitors objectively the visitor\u2019s behavior so that it can further adapt the content to their needs; and a pose estimation system that identifies an exhibit and links it to the additional content that is prepared for it. We present the systems and the initial results for a selected set of exhibits in Herakleidon Museum, a museum holding temporary exhibitions mainly about ancient Greek technology. The initial evaluation that we presented is encouraging for all systems. Thus, the plan is to use the developed systems for all museum exhibits as \u2026",
            "Abstract entirety": 0,
            "Author pub id": "9OieklkAAAAJ:DBa1UEJaJKAC",
            "Publisher": "Springer, Cham"
        },
        {
            "Title": "Depth based 3D Hand Pose Estimation: From Current Achievements to Future Goals",
            "Publication year": 2018,
            "Publication url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Yuan_Depth-Based_3D_Hand_CVPR_2018_paper.html",
            "Abstract": "In this paper, we strive to answer two questions: What is the current state of 3D hand pose estimation from depth images? And, what are the next challenges that need to be tackled? Following the successful Hands In the Million Challenge (HIM2017), we investigate the top 10 state-of-the-art methods on three tasks: single frame 3D pose estimation, 3D hand tracking, and hand pose estimation during object interaction. We analyze the performance of different CNN structures with regard to hand shape, joint visibility, view point and articulation distributions. Our findings include:(1) isolated 3D hand pose estimation achieves low mean errors (10 mm) in the view point range of [70, 120] degrees, but it is far from being solved for extreme view points;(2) 3D volumetric representations outperform 2D CNNs, better capturing the spatial structure of the depth data;(3) Discriminative methods still generalize poorly to unseen hand shapes;(4) While joint occlusions pose a challenge for most methods, explicit modeling of structure constraints can significantly narrow the gap between errors on visible and occluded joints.",
            "Abstract entirety": 1,
            "Author pub id": "9OieklkAAAAJ:IUKN3-7HHlwC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Improved design for vision-based incident detection in transportation systems using real-time view transformations",
            "Publication year": 2006,
            "Publication url": "https://ascelibrary.org/doi/abs/10.1061/(ASCE)0733-947X(2006)132:11(837)",
            "Abstract": "Advances in machine vision techniques have led to algorithms and integrated systems that can be applied in transportation engineering to improve surveillance and control. Despite these advances, certain problems in the effective integration of machine-vision based systems at complex intersections and complex freeway sections still remain. These are related to increasing system performance in the identification, analysis, and detection of the traffic state in real time. This work examines the feasibility of providing transformed visual input to existing machine-vision based systems, in order to gain increased efficiency and cost effectiveness of integrated transportation systems. Two transformations are developed, homography-based transformation and panoramic image reprojection. Homography-based transformation operates on video of the road scene, provided by classical cameras, and seeks to transform any \u2026",
            "Abstract entirety": 0,
            "Author pub id": "9OieklkAAAAJ:O3NaXMp0MMsC",
            "Publisher": "American Society of Civil Engineers"
        },
        {
            "Title": "Capturing and Reproducing Hand-Object Interactions Through Vision-Based Force Sensing",
            "Publication year": 2015,
            "Publication url": "https://hal.archives-ouvertes.fr/hal-01372238/",
            "Abstract": "Capturing and reproducing hand-objects interactions would open considerable possibilities in computer vision, human-computer interfaces, robotics, animation and rehabilitation. Recently, we witnessed impressive vision-based hand tracking solutions that can potentially be used for such purposes. Yet, a challenging question is: to what extent can vision also capture haptic interactions? These induce motions and constraints that are key for learning and understanding tasks, such as dexterous grasping, manipulation and assembly, as well as enabling their reproduction from either virtual characters or physical embodiments. Contact forces are traditionally measured by means of haptic technologies such as force transducers, whose major drawback lies in their intrusiveness, with respect to the manipulated objects (impacting their physical properties) and the operator's hands (obstructing the human haptic senses). Others include their extensive need for calibration, time-varying accuracy and cost. In this paper, we present the force sensing from vision framework to capture haptic interaction by means of a cheap and simple set-up (e.g., a single RGB-D camera). We then illustrate its use as an implicit force model improving the reproduction of hand-object manipulation scenarios even in poor performance visual tracking conditions.",
            "Abstract entirety": 1,
            "Author pub id": "9OieklkAAAAJ:ILKRHgRFtOwC",
            "Publisher": "Unknown"
        },
        {
            "Title": "A comparative study of matrix completion and recovery techniques for human pose estimation",
            "Publication year": 2018,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/3197768.3197791",
            "Abstract": "We present a comparative study of three matrix completion and recovery techniques, applied to the problem of human pose estimation. Human pose estimation algorithms may exhibit estimation noise or may completely fail to provide estimates for some joints. A post-process is often employed to recover the missing joints' locations from the available ones, typically by enforcing kinematic constraints or by using a prior learned from a database of natural poses. Matrix completion and recovery techniques fall into the latter category and operate by filling-in missing entries of a matrix, with the available/non-missing entries being potentially corrupted by noise. We compare the performance of three such techniques in terms of the estimation error of their output as well as their runtime under varying parameters. We conclude by recommending use cases for each of the compared techniques.",
            "Abstract entirety": 1,
            "Author pub id": "9OieklkAAAAJ:r_AWSJRzSzQC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Vision-based camera motion recovery for augmented reality",
            "Publication year": 2004,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/1309266/",
            "Abstract": "We address the problem of tracking the 3D position and orientation of a camera, using the images it acquires while moving freely in unmodeled, arbitrary environments. This task has a broad spectrum of useful applications in domains such as augmented reality and video post production. Most of the existing methods for vision-based camera tracking are designed to operate in a batch, off-line mode, assuming that the whole video sequence to be tracked is available before tracking commences. Typically, such methods operate noncausally, processing video frames backwards and forwards in time as they see fit. Furthermore, they resort to optimization in very high dimensional spaces, a process that is computationally intensive. For these reasons, batch methods are inapplicable to tracking in online, time-critical applications such as video see-through augmented reality. This paper puts forward a novel feature-based \u2026",
            "Abstract entirety": 0,
            "Author pub id": "9OieklkAAAAJ:Se3iqnhoufwC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Lumen detection for capsule endoscopy",
            "Publication year": 2008,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/4650969/",
            "Abstract": "In this paper, two visual cues are proposed, to be exploited for the navigation of active endoscopic capsules within the gastrointestinal (GI) tract. These cues consist of the detection and tracking of the lumen and of an illumination highlight in capsule endoscopy (CE) images. The proposed approach aims at developing vision algorithms which are robust with respect to the challenging imaging conditions encountered in the GI tract and the great variability of the acquired images. Cases where no or more than one lumens exists, are also detected. The proposed approach extends the state-of-the-art in lumen detection, and is demonstrated for in-vivo video sequences acquired from endoscopic capsules.",
            "Abstract entirety": 1,
            "Author pub id": "9OieklkAAAAJ:43bX7VzcjpAC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Retinal image preprocessing, enhancement, and registration",
            "Publication year": 2019,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/B9780081028162000046",
            "Abstract": "Preprocessing and enhancement is a prerequisite for a wide range of retinal image analysis methods. The goals of such tasks are to improve images and facilitate their subsequent analysis. Registration of retinal images enables the generation of images of higher definition retinal mosaics and facilitates the comparison of images from different examinations. The above processes contribute significantly to the screening and diagnosis of a wide range of diseases. This chapter reviews preprocessing, enhancement, and registration techniques for the modalities of fundus and tomographic imaging of the human eye.",
            "Abstract entirety": 1,
            "Author pub id": "9OieklkAAAAJ:WC23djZS0W4C",
            "Publisher": "Academic Press"
        },
        {
            "Title": "Cue Selection Depending on Contextual Knowledge, Tracking of Hands and Objects and Trajectory Estimation",
            "Publication year": 2003,
            "Publication url": "http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.137.4780&rep=rep1&type=pdf",
            "Abstract": "Deliverable D2. 1 is software (demonstration) deliverable. The demonstration will show how cue integration is used to obtain robust hand tracking. It will also demonstrate the quality of the 3D hand trajectories estimated through tracking.D2. 1 is closely linked with D3. 2, which presents the cue integration methods and relations of cues and features. The next table summarizes the content originally intended for deliverables D2. 1 and D3. 2. It also provides the new distribution of content, which results from the wish to present methods together with results for each of the two components of the ActIPret framework in one deliverable: hand tracking in D2. 1 and object tracking in D3. 2.",
            "Abstract entirety": 1,
            "Author pub id": "9OieklkAAAAJ:SeFeTyx0c_EC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Using geometric constraints for matching disparate stereo views of 3D scenes containing planes",
            "Publication year": 2000,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/905366/",
            "Abstract": "Several vision tasks rely upon the availability of sets of corresponding features among images. This paper presents a method which, given some corresponding features in two stereo images, addresses the problem of matching them with features extracted from a second stereo pair captured from a distant viewpoint. The proposed method is based on the assumption that the viewed scene contains two planar surfaces and exploits geometric constraints that are imposed by the existence of these planes to predict the location of image features in the second stereo pair. The resulting scheme handles point and line features in a unified manner and is capable of successfully matching features extracted from stereo pairs acquired from considerably different viewpoints. Experimental results from a prototype implementation demonstrate the effectiveness of the approach.",
            "Abstract entirety": 1,
            "Author pub id": "9OieklkAAAAJ:M3ejUd6NZC8C",
            "Publisher": "IEEE"
        },
        {
            "Title": "Multi-view Image-based Hand Geometry Refinement using Differentiable Monte Carlo Ray Tracing",
            "Publication year": 2021,
            "Publication url": "https://arxiv.org/abs/2107.05509",
            "Abstract": "The amount and quality of datasets and tools available in the research field of hand pose and shape estimation act as evidence to the significant progress that has been made.However, even the datasets of the highest quality, reported to date, have shortcomings in annotation. We propose a refinement approach, based on differentiable ray tracing,and demonstrate how a high-quality publicly available, multi-camera dataset of hands(InterHand2.6M) can become an even better dataset, with respect to annotation quality. Differentiable ray tracing has not been employed so far to relevant problems and is hereby shown to be superior to the approximative alternatives that have been employed in the past. To tackle the lack of reliable ground truth, as far as quantitative evaluation is concerned, we resort to realistic synthetic data, to show that the improvement we induce is indeed significant. The same becomes evident in real data through visual evaluation.",
            "Abstract entirety": 1,
            "Author pub id": "9OieklkAAAAJ:KNjnJ3z-R6IC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Dimensionality reduction for efficient single frame hand pose estimation",
            "Publication year": 2013,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-642-39402-7_15",
            "Abstract": "Model based approaches for the recovery of the 3D position, orientation and full articulation of the human hand have a number of attractive properties. One bottleneck towards their practical exploitation is their computational cost. To a large extent, this is determined by the large dimensionality of the problem to be solved. In this work we exploit the fact that the parametric joints space representing hand configurations is highly redundant. Thus, we employ Principal Component Analysis (PCA) to learn a lower dimensional space that describes compactly and effectively the human hand articulation. The reduced dimensionality of the resulting space leads to a simpler optimization problem, so model-based approaches require less computational effort to solve it. Experiments demonstrate that the proposed approach achieves better accuracy in hand pose recovery compared to a state of the art baseline method \u2026",
            "Abstract entirety": 0,
            "Author pub id": "9OieklkAAAAJ:eq2jaN3J8jMC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "Plane detection in an uncalibrated image pair",
            "Publication year": 2002,
            "Publication url": "https://scholar.google.com/scholar?cluster=14412780456406564120&hl=en&oi=scholarr",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "9OieklkAAAAJ:otzGkya1bYkC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Navigation assistance and guidance of older adults across complex public spaces: the DALi approach",
            "Publication year": 2015,
            "Publication url": "https://link.springer.com/content/pdf/10.1007/s11370-015-0169-y.pdf",
            "Abstract": "The Devices for Assisted Living(DALi ) project is a research initiative sponsored by the European Commission under the FP7 programmeaiming for the development of a robotic device to assist people with cognitive impairments in navigating complex environments. The project revisits the popular paradigm of the walker enriching it with sensing abilities (to perceive the environment), with cognitive abilities (to decide the best path across the space) and with mechanical, visual, acoustic and haptic guidance devices (to guide the person along the path). In this paper, we offer an overview of the developed system and describe in detail some of its most important technological aspects.",
            "Abstract entirety": 1,
            "Author pub id": "9OieklkAAAAJ:2KloaMYe4IUC",
            "Publisher": "Springer Berlin Heidelberg"
        },
        {
            "Title": "Efficient Model-based Tracking of the Articulated Motion of Hands",
            "Publication year": 2012,
            "Publication url": "Unknown",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "9OieklkAAAAJ:uLbwQdceFCQC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Binding Vision to Physics Based Simulation: The Case Study of a Bouncing Ball",
            "Publication year": 2011,
            "Publication url": "http://www.bmva.org/bmvc/2011/proceedings/paper43/abstract.pdf",
            "Abstract": "A dynamic scene and, therefore, its visual observations are invariably determined by the laws of physics. Based on the case-study of a uniformly colored bouncing ball, we demonstrate that physical explanation, as a vision prior, is not a commodity but a necessity. More specifically, by considering the problem of ball motion estimation we show how physics-based simulation in conjunction with visual processes can lead to the reduction of the visual input required to infer physical attributes of the observed world. Even further, we show that the proposed methodology manages to reveal certain physical attributes of the observed scene that are difficult or even impossible to extract by other means. A series of experiments on synthetic data as well as experiments with image sequences of an actual ball, support the validity of the proposed approach. The use of generic tools and the top-down nature of the proposed approach make it general enough to be a likely candidate for handling even more complex problems in larger contexts.",
            "Abstract entirety": 1,
            "Author pub id": "9OieklkAAAAJ:EUQCXRtRnyEC",
            "Publisher": "BMVA Press"
        },
        {
            "Title": "Refining Single View Calibration With the Aid of Metric Scene Properties.",
            "Publication year": 2007,
            "Publication url": "http://publications.ics.forth.gr/_publications/wscg07.pdf",
            "Abstract": "Intrinsic camera calibration using a single image is possible provided that certain geometric objects such as orthogonal vanishing points and metric homographies can be estimated from the image and give rise to adequate constraints on the sought calibration parameters. In doing so, however, any additional metric information that might be available for the imaged scene is not always straightforward to accommodate. This paper puts forward a method for incorporating into the calibration procedure metric scene information expressed in the form of known segment 3D angles, equal but unknown 3D angles and known 3D length ratios. Assuming the availability of an initial calibration estimate, the proposed method refines the former by numerically minimizing an error term corresponding to the discrepancy between the scene\u2019s known metric properties and the values measured with the aid of the calibration estimate. Sample experimental results demonstrate the improvements in the intrinsic calibration estimates that are achieved by the proposed method.",
            "Abstract entirety": 1,
            "Author pub id": "9OieklkAAAAJ:RGFaLdJalmkC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Predicting Human Intention in Visual Observations of Hand/Object Interactions",
            "Publication year": 2013,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/6630785/",
            "Abstract": "The main contribution of this paper is a probabilistic method for predicting human manipulation intention from image sequences of human-object interaction. Predicting intention amounts to inferring the imminent manipulation task when human hand is observed to have stably grasped the object. Inference is performed by means of a probabilistic graphical model that encodes object grasping tasks over the 3D state of the observed scene. The 3D state is extracted from RGB-D image sequences by a novel vision-based, markerless hand-object 3D tracking framework. To deal with the high-dimensional state-space and mixed data types (discrete and continuous) involved in grasping tasks, we introduce a generative vector quantization method using mixture models and self-organizing maps. This yields a compact model for encoding of grasping actions, able of handling uncertain and partial sensory data \u2026",
            "Abstract entirety": 0,
            "Author pub id": "9OieklkAAAAJ:Y5dfb0dijaUC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Towards a robot for supporting older people to stay longer independent at home",
            "Publication year": 2014,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/6840193/",
            "Abstract": "The paper presents the intentions and the preliminary findings of the Socially Assistive Robot HOBBIT. The goal is to come up with a robotic solution which will balance user needs, acceptance and technical performance in an economic and affordable way while providing a solution for fall detection and prevention. Falls are the main risk of older adults living alone that require moving from home to care institutions. Hence, it is a primary target area to prevent falls and, if they happen nevertheless, to react immediately to prevent aggravated causes. We present first results of user trials given six tasks with the robot. To show the effect of bonding with the user - Mutual Care - users were separated in two groups. Results indicate that users find the robot more usable in the Mutual Care condition.",
            "Abstract entirety": 1,
            "Author pub id": "9OieklkAAAAJ:F1b5ZUV5XREC",
            "Publisher": "VDE"
        },
        {
            "Title": "Apparatuses, methods and systems for recovering a 3-dimensional skeletal model of the human body",
            "Publication year": 2016,
            "Publication url": "https://patents.google.com/patent/US20160086350A1/en",
            "Abstract": "The ARS offers tracking, estimation of position, orientation and full articulation of the human body from marker-less visual observations obtained by a camera, for example an RGBD camera. An ARS may provide hypotheses of the 3D configuration of body parts or the entire body from a single depth frame. The ARS may also propagates estimations of the 3D configuration of body parts and the body by mapping or comparing data from the previous frame and the current frame. The ARS may further compare the estimations and the hypotheses to provide a solution for the current frame. An ARS may select, merge, refine, and/or otherwise combine data from the estimations and the hypotheses to provide a final estimation corresponding to the 3D skeletal data and may apply the final estimation data to capture parameters associated with a moving or still body.",
            "Abstract entirety": 1,
            "Author pub id": "9OieklkAAAAJ:kuK5TVdYjLIC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Back to RGB: 3D tracking of hands and hand-object interactions based on short-baseline stereo",
            "Publication year": 2017,
            "Publication url": "https://openaccess.thecvf.com/content_ICCV_2017_workshops/w11/html/Panteleris_Back_to_RGB_ICCV_2017_paper.html",
            "Abstract": "We present a novel solution to the problem of 3D tracking of the articulated motion of human hand (s), possibly in interaction with other objects. The vast majority of contemporary relevant work capitalizes on depth information provided by RGBD cameras. In this work, we show that accurate and efficient 3D hand tracking is possible, even for the case of RGB stereo. A straightforward approach for solving the problem based on such input would be to first recover depth and then apply a state of the art depth-based 3D hand tracking method. Unfortunately, this does not work well in practice because the stereo-based, dense 3D reconstruction of hands is far less accurate than the one obtained by RGBD cameras. Our approach bypasses 3D reconstruction and follows a completely different route: 3D hand tracking is formulated as an optimization problem whose solution is the hand configuration that maximizes the color consistency between the two views of the hand. We demonstrate the applicability of our method for real time tracking of a single hand, of a hand manipulating an object and of two interacting hands. The method has been evaluated quantitatively using the same datasets as relevant, state of the art RGBD-based approaches. The obtained results demonstrate that the proposed stereo-based method performs equally well to its RGBD-based competitors, and in some cases, it even outperforms them.",
            "Abstract entirety": 1,
            "Author pub id": "9OieklkAAAAJ:Ug5p-4gJ2f0C",
            "Publisher": "Unknown"
        },
        {
            "Title": "A review on deep learning techniques for video prediction",
            "Publication year": 2020,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/9294028/",
            "Abstract": "The ability to predict, anticipate and reason about future outcomes is a key component of intelligent decision-making systems. In light of the success of deep learning in computer vision, deep-learning-based video prediction emerged as a promising research direction. Defined as a self-supervised learning task, video prediction represents a suitable framework for representation learning, as it demonstrated potential capabilities for extracting meaningful representations of the underlying patterns in natural videos. Motivated by the increasing interest in this task, we provide a review on the deep learning methods for prediction in video sequences. We firstly define the video prediction fundamentals, as well as mandatory background concepts and the most used datasets. Next, we carefully analyze existing video prediction models organized according to a proposed taxonomy, highlighting their contributions and their \u2026",
            "Abstract entirety": 0,
            "Author pub id": "9OieklkAAAAJ:SjuI4pbJlxcC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Building a Multi-Touch Display Based on Computer Vision Techniques.",
            "Publication year": 2009,
            "Publication url": "http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.443.8593&rep=rep1&type=pdf",
            "Abstract": "We present the development of a multi-touch display based on computer vision techniques. The developed system is built upon low cost, off-the-shelf hardware components and a careful selection of computer vision techniques. The resulting system is capable of detecting and tracking several objects that may move freely on the surface of a wide projection screen. It also provides additional information regarding the detected and tracked objects, such as their orientation, their full contour, etc. All of the above are achieved robustly, in real time and regardless of the visual appearance of what may be independently projected on the projection screen. We also present indicative results from the exploitation of the developed system in three application scenarios and discuss directions for further research.",
            "Abstract entirety": 1,
            "Author pub id": "9OieklkAAAAJ:HDshCWvjkbEC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Object tracking in a closed loop",
            "Publication year": 2010,
            "Publication url": "https://scholar.google.com/scholar?cluster=17595404801596835541&hl=en&oi=scholarr",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "9OieklkAAAAJ:ALROH1vI_8AC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Towards a Visual Sign Language Dataset for Home Care Services",
            "Publication year": 2020,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/9320304/",
            "Abstract": "We present our work towards creating a dataset, which is intended to be used for the implementation of a home care services system for the deaf. The dataset includes recorded realistic scenarios of interactions between deaf patients and mental health experts in their native sign language. The scenarios allow for contextualized representations, in contrast to typical datasets presenting isolated signs or sentences. It includes continuous videos in RGB and depth, which are challenging to analyze and closely resemble real-life scenarios. The research on representation of signs is supported by providing the hand shapes and trajectories for every video using hand and skeleton models, as well as facial features. Furthermore, the dataset may be used for studying the emotional context, since such conversations are typically emotionally charged.",
            "Abstract entirety": 1,
            "Author pub id": "9OieklkAAAAJ:q-HalDI95KYC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Robotics & Automation Magazine Vol. 11",
            "Publication year": 2004,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/1371620/",
            "Abstract": "This index covers all technical items - papers, correspondence, reviews, etc. - that appeared in this periodical during the year, and items from previous years that were commented upon or corrected in this year. Departments and other items may also be covered if they have been judged to have archival value. The Author Index contains the primary entry for each item, listed under the first author's name. The primary entry includes the co-authors' names, the title of the paper or other item, and its location, specified by the publication abbreviation, year, month, and inclusive pagination. The Subject Index contains entries describing the item under all appropriate subject headings, plus the first author's name, the publication abbreviation, month, and year, and inclusive pages. Note that the item title is found only under the primary entry in the Author Index.",
            "Abstract entirety": 1,
            "Author pub id": "9OieklkAAAAJ:FPJr55Dyh1AC",
            "Publisher": "Unknown"
        },
        {
            "Title": "sba: A generic sparse bundle adjustment C/C++ package based on the Levenberg-Marquardt algorithm",
            "Publication year": 2008,
            "Publication url": "https://scholar.google.com/scholar?cluster=8740668433474445161&hl=en&oi=scholarr",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "9OieklkAAAAJ:3fE2CSJIrl8C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Evaluating Method Design Options for Action Classification based on Bags of Visual Words",
            "Publication year": 2018,
            "Publication url": "https://pdfs.semanticscholar.org/9684/59ed2ea0b11de3a1b35a4a1ef9f3c307ea32.pdf",
            "Abstract": "The Bags of Visual Words (BoVWs) framework has been applied successfully to several computer vision tasks. In this work we are particularly interested on its application to the problem of action recognition/classification. The key design decisions for a method that follows the BoVWs framework are (a) the visual features to be employed,(b) the size of the codebook to be used for representing a certain action and (c) the classifier applied to the developed representation to solve the classification task. We perform several experiments to investigate a variety of options regarding all the aforementioned design parameters. We also propose a new feature type and we suggest a method that determines automatically the size of the codebook. The experimental results show that our proposals produce results that are competitive to the outcomes of state of the art methods.",
            "Abstract entirety": 1,
            "Author pub id": "9OieklkAAAAJ:mNrWkgRL2YcC",
            "Publisher": "Unknown"
        },
        {
            "Title": "3D Tracking of Hands Interacting with Several Objects",
            "Publication year": 2015,
            "Publication url": "https://www.researchgate.net/profile/Antonis-Argyros/publication/296970227_3D_Tracking_of_Hands_Interacting_with_Several_Objects/links/5812049908aeda05f0a56c14/3D-Tracking-of-Hands-Interacting-with-Several-Objects.pdf",
            "Abstract": "Humans and robots may acquire knowledge by observing demonstrations of object manipulation in scenarios ranging from everyday tasks, such as tieing laces and executing a recipe, to critical operations like surgery, electronics (dis-) assembly, etc. As the corpus of related videos is enlarged and the knowledge extraction becomes mission critical, the automation of the knowledge extraction process becomes increasingly important. Estimating the detailed configuration of hands and objects in 3D space and across time may be of fundamental importance towards achieving high level understanding of such hand-object interactions. Most relevant work in the literature regards the presented context with identifiable limits. There is plenty of work on the problem of tracking a single hand in 3D. For a review the reader is referred to [8]. There are also a few approaches to the problem of 3D tracking of a single hand and a single object [2, 12], two hands [11] and two hands and a single object [1]. However, in the aforementioned demonstrations it is rarely the case that only a single object is being manipulated. On the contrary, usual interaction scenarios involve several objects, with instances even involving concurrent interaction among sizeable sub-groups (eg (dis-) assembly, surgery, etc.). Effective handling of the intrinsically large complexity of these cases constitutes a challenging and interesting goal.We propose that the detailed computation of an entire scene\u2019s 3D configuration should be achieved through top-down model-based 3D tracking. Evidently, top-down methods present straightforward generalization paths, as indicated in the transition from \u2026",
            "Abstract entirety": 0,
            "Author pub id": "9OieklkAAAAJ:hMsQuOkrut0C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Exploiting the sparseness of bundle adjustment for efficient 3d reconstruction",
            "Publication year": 2006,
            "Publication url": "https://scholar.google.com/scholar?cluster=11573028513452665683&hl=en&oi=scholarr",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "9OieklkAAAAJ:4xDN1ZYqzskC",
            "Publisher": "Unknown"
        },
        {
            "Title": "and WebFAIR",
            "Publication year": 2005,
            "Publication url": "http://www2.informatik.uni-freiburg.de/~stachnis/pdf/trahanias05webfair-ramprint.pdf",
            "Abstract": "IEEE Robotics & Automation Magazine JUNE 2005 78 an interactive TOUr-guide RoBOT (TOURBOT) able to provide individual access to museums exhibits and cultural heritage over the Web. TOURBOT operates as the user\u2019s avatar in a museum, accepting commands over the Web that direct it to move in its workspace and visit specific exhibits. The imaged scene of the museum and exhibits is communicated over the Internet to a remote visitor. As a result, the user enjoys a personalized tele-presence in the museum, able to choose the exhibits to visit as well as the preferred viewing conditions (point of view, distance to the exhibit, and resolution). At the same time, TOURBOT can guide on-site museum visitors, providing either group or personalized tours. The successful course of TOURBOT, and the vision to introduce similar services to the taxing case of trade fairs, resulted in the launch of the WebFAIR project. The latter was additionally endorsed by experts in the organization and promotion of large trade shows. Besides the TOURBOT functionality, which is now offered in a more demanding environment, WebFAIR introduced teleconferencing between the remote user and on-site attendants and employed a multirobot platform, facilitating simultaneous robot control by multiple users.Focusing on the requirement for autonomous robot motion, both projects opted for the development of a safe and reliable navigation system. For this purpose, the robotic avatars are equipped with sensors such as laser range-scanners, sonars, and cameras. The navigation system uses this sensory information to adapt the robot\u2019s internal model of the environment \u2026",
            "Abstract entirety": 0,
            "Author pub id": "9OieklkAAAAJ:CdxZDUztZiMC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Using a single RGB frame for real time 3D hand pose estimation in the wild",
            "Publication year": 2018,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/8354158/",
            "Abstract": "We present a method for the real-time estimation of the full 3D pose of one or more human hands using a single commodity RGB camera. Recent work in the area has displayed impressive progress using RGBD input. However, since the introduction of RGBD sensors, there has been little progress for the case of monocular color input. We capitalize on the latest advancements of deep learning, combining them with the power of generative hand pose estimation techniques to achieve real-time monocular 3D hand pose estimation in unrestricted scenarios. More specifically, given an RGB image and the relevant camera calibration information, we employ a state-of-the-art detector to localize hands. Given a crop of a hand in the image, we run the pretrained network of OpenPose for hands to estimate the 2D location of hand joints. Finally, non-linear least-squares minimization fits a 3D model of the hand to the \u2026",
            "Abstract entirety": 0,
            "Author pub id": "9OieklkAAAAJ:OTTXONDVkokC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Even Faster SNN Simulation with Lazy+ Event-driven Plasticity and Shared Atomics",
            "Publication year": 2021,
            "Publication url": "https://arxiv.org/abs/2107.04092",
            "Abstract": "We present two novel optimizations that accelerate clock-based spiking neural network (SNN) simulators. The first one targets spike timing dependent plasticity (STDP). It combines lazy- with event-driven plasticity and efficiently facilitates the computation of pre- and post-synaptic spikes using bitfields and integer intrinsics. It offers higher bandwidth than event-driven plasticity alone and achieves a 1.5x-2x speedup over our closest competitor. The second optimization targets spike delivery. We partition our graph representation in a way that bounds the number of neurons that need be updated at any given time which allows us to perform said update in shared memory instead of global memory. This is 2x-2.5x faster than our closest competitor. Both optimizations represent the final evolutionary stages of years of iteration on STDP and spike delivery inside \"Spice\" (/spaIk/), our state of the art SNN simulator. The proposed optimizations are not exclusive to our graph representation or pipeline but are applicable to a multitude of simulator designs. We evaluate our performance on three well-established models and compare ourselves against three other state of the art simulators.",
            "Abstract entirety": 1,
            "Author pub id": "9OieklkAAAAJ:pAkWuXOU-OoC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Tracking hand articulations: Relying on 3D visual hulls versus relying on multiple 2D cues",
            "Publication year": 2013,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/6597722/",
            "Abstract": "We present a method for articulated hand tracking that relies on visual input acquired by a calibrated multicamera system. A state-of-the-art result on this problem has been presented in [12]. In that work, hand tracking is formulated as the minimization of an objective function that quantifies the discrepancy between a hand pose hypothesis and the observations. The objective function treats the observations from each camera view in an independent way. We follow the same general optimization framework but we choose to employ the visual hull [10] as the main observation cue, which results from the integration of information from all available views prior to optimization. We investigate the behavior of the resulting method in extensive experiments and in comparison with that of [12]. The obtained results demonstrate that for low levels of noise contamination, regardless of the number of cameras, the two methods \u2026",
            "Abstract entirety": 0,
            "Author pub id": "9OieklkAAAAJ:5awf1xo2G04C",
            "Publisher": "IEEE"
        },
        {
            "Title": "Unsupervised and Explainable Assessment of Video Similarity",
            "Publication year": 2019,
            "Publication url": "https://bmvc2019.org/wp-content/uploads/papers/0417-paper.pdf",
            "Abstract": "We propose a novel unsupervised method that assesses the similarity of two videos on the basis of the estimated relatedness of the objects and their behavior, and provides arguments supporting this assessment. A video is represented as a complete undirected action graph that encapsulates information on the types of objects and the way they (inter) act. The similarity of a pair of videos is estimated based on the bipartite Graph Edit Distance (GED) of the corresponding action graphs. As a consequence, on-top of estimating a quantitative measure of video similarity, our method establishes spatiotemporal correspondences between objects across videos if these objects are semantically related, if/when they interact similarly, or both. We consider this an important step towards explainable assessment of video and action similarity. The proposed method is evaluated on a publicly available dataset on the tasks of activity classification and ranking and is shown to compare favorably to state of the art supervised learning methods.",
            "Abstract entirety": 1,
            "Author pub id": "9OieklkAAAAJ:7BrZ7Jt4UNcC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Tourbot-interactive museum tele-presence through robotic avatars",
            "Publication year": 2000,
            "Publication url": "https://publications.ics.forth.gr/_publications/2000_05_www9_tourbot.pdf",
            "Abstract": "TOURBOT, the acronym of a project entitled \u201cInteractive Museum Tele-presence Through Robotic Avatars\u201d, represents an EU-IST funded activity aiming at developing alternative ways for interactive museum tele-presence [1]. In this paper we present the project framework, with emphasis on the project goals, approach and innovations, as well as the expected benefits and results.The overal goal of TOURBOT is the development of an interactive tour-guide robot able to provide individual access to museums\u2019 exhibits and cultural heritage over the Internet. TOURBOT operates as the user\u2019s avatar in the museum (ie as a remote \u201crepresentative\u201d of the",
            "Abstract entirety": 1,
            "Author pub id": "9OieklkAAAAJ:QIV2ME_5wuYC",
            "Publisher": "Unknown"
        },
        {
            "Title": "FORTH-ICS/TR-324 September 2003",
            "Publication year": 2003,
            "Publication url": "https://scholar.google.com/scholar?cluster=17942027658769235838&hl=en&oi=scholarr",
            "Abstract": "Camera matchmoving is an application involving synthesis of real scenes and artificial objects, in which the goal is to insert computer-generated graphical 3D objects into live-action footage depicting unmodeled, arbitrary scenes. Graphical objects should be inserted in a way so that they appear to move as if they were a part of the real scene. Seamless, convincing insertion of graphical objects calls for accurate 3D camera motion tracking (ie pose estimation), stable enough over extended sequences so as to avoid the problems of jitter and drift in the location and appearance of objects with respect to the real scene. Additionally, the placement of the objects with respect to the real scene often requires the availability of some 3D geometry information; for instance, accurate 3D reconstruction of a few guiding control points is in most cases sufficient. Matchmoving finds several important applications in augmented reality \u2026",
            "Abstract entirety": 0,
            "Author pub id": "9OieklkAAAAJ:5icHVeHT4IsC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Efficient model-based 3d tracking of hand articulations using kinect",
            "Publication year": 2011,
            "Publication url": "http://publications.ics.forth.gr/_publications/2011_09_bmvc_kinect_hand_tracking.pdf",
            "Abstract": "We present a novel solution to the problem of recovering and tracking the 3D position, orientation and full articulation of a human hand from markerless visual observations obtained by a Kinect sensor. We treat this as an optimization problem, seeking for the hand model parameters that minimize the discrepancy between the appearance and 3D structure of hypothesized instances of a hand model and actual hand observations. This optimization problem is effectively solved using a variant of Particle Swarm Optimization (PSO). The proposed method does not require special markers and/or a complex image acquisition setup. Being model based, it provides continuous solutions to the problem of tracking hand articulations. Extensive experiments with a prototype GPU-based implementation of the proposed method demonstrate that accurate and robust 3D tracking of hand articulations can be achieved in near real-time (15Hz).",
            "Abstract entirety": 1,
            "Author pub id": "9OieklkAAAAJ:HtS1dXgVpQUC",
            "Publisher": "BMVC 2011"
        },
        {
            "Title": "3D Tracking of Human Hands in Interaction with Unknown Objects",
            "Publication year": 2015,
            "Publication url": "https://scholar.google.com/scholar?cluster=1368141253022828440&hl=en&oi=scholarr",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "9OieklkAAAAJ:vDijr-p_gm4C",
            "Publisher": "BMVA Press"
        },
        {
            "Title": "Efficient 3D Hand Tracking in Articulation Subspaces for the Manipulation of Virtual Objects",
            "Publication year": 2016,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/2949035.2949044",
            "Abstract": "We propose an efficient method for model-based 3D tracking of hand articulations observed from an egocentric viewpoint that aims at supporting the manipulation of virtual objects. Previous model-based approaches optimize non-convex objective functions defined in the 26 Degrees of Freedom (DoFs) space of possible hand articulations. In our work, we decompose this space into six articulation subspaces (6 DoFs for the palm and 4 DoFs for each finger). We also label each finger with a Gaussian model that is propagated between successive image frames. As confirmed by a number of experiments, this divide-and-conquer approach tracks hand articulations more accurately than existing model-based approaches. At the same time, real time performance is achieved without the need of GPGPU processing. Additional experiments show that the proposed approach is preferable for supporting the accurate \u2026",
            "Abstract entirety": 0,
            "Author pub id": "9OieklkAAAAJ:M7yex6snE4oC",
            "Publisher": "ACM"
        },
        {
            "Title": "ChaLearn multi-modal gesture recognition 2013: grand challenge and workshop summary",
            "Publication year": 2013,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/2522848.2532597",
            "Abstract": "The MMGR Grand Challenge focused on the recognition of continuous natural gestures from multi-modal data (including RGB, Depth, user mask, Skeletal model, and audio). We made available a large labeled video database of 13, 858 gestures from a lexicon of 20 Italian gesture categories recorded with a KinectTM camera. More than 54 teams participated in the challenge and a final error rate of 12% was achieved by the winner of the competition. Winners of the competition published their work in the workshop of the Challenge.The MMGR Workshop was held at ICMI conference 2013, Sidney. A total of 9 relevant papers with basis on multi-modal gesture recognition were accepted for presentation. This includes multi-modal descriptors, multi-class learning strategies for segmentation and classification of temporal data, as well as relevant applications in the field, including multi-modal Social Signal Processing and \u2026",
            "Abstract entirety": 0,
            "Author pub id": "9OieklkAAAAJ:UHK10RUVsp4C",
            "Publisher": "ACM"
        },
        {
            "Title": "Gesture recognition supporting the interaction of humans with socially assistive robots",
            "Publication year": 2014,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-319-14249-4_76",
            "Abstract": "We propose a new approach for vision-based gesture recognition to support robust and efficient human robot interaction towards developing socially assistive robots. The considered gestural vocabulary consists of five, user specified hand gestures that convey messages of fundamental importance in the context of human-robot dialogue. Despite their small number, the recognition of these gestures exhibits considerable challenges. Aiming at natural, easy-to-memorize means of interaction, users have identified gestures consisting of both static and dynamic hand configurations that involve different scales of observation (from arms to fingers) and exhibit intrinsic ambiguities. Moreover, the gestures need to be recognized regardless of the multifaceted variability of the human subjects performing them. Recognition needs to be performed online, in continuous video streams containing other irrelevant \u2026",
            "Abstract entirety": 0,
            "Author pub id": "9OieklkAAAAJ:wMgC3FpKEyYC",
            "Publisher": "Springer, Cham"
        },
        {
            "Title": "Unsupervised learning of background modeling parameters in multicamera systems",
            "Publication year": 2011,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S1077314210001979",
            "Abstract": "Background modeling algorithms are commonly used in camera setups for foreground object detection. Typically, these algorithms need adjustment of their parameters towards achieving optimal performance in different scenarios and/or lighting conditions. This is a tedious process requiring considerable effort by expert users. In this work we propose a novel, fully automatic method for the tuning of foreground detection parameters in calibrated multicamera systems. The proposed method requires neither user intervention nor ground truth data. Given a set of such parameters, we define a fitness function based on the consensus built from the multicamera setup regarding whether points belong to the scene foreground or background. The maximization of this fitness function through Particle Swarm Optimization leads to the adjustment of the foreground detection parameters. Extensive experimental results confirm the \u2026",
            "Abstract entirety": 0,
            "Author pub id": "9OieklkAAAAJ:abG-DnoFyZgC",
            "Publisher": "Academic Press"
        },
        {
            "Title": "A HIMI model for collaborative multi-touch multimedia education",
            "Publication year": 2009,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/1631005.1631009",
            "Abstract": "Educational testing and learning have evolved from using standard True/False, fill-in-the-blank and multiple choice on paper to more visually enriched formats using interactive multimedia content on digital displays. However, traditional educational application interfaces are primarily mouse-driven, which prevents multiple users working simultaneously. Although touch-based displays have emerged and inspired new developments, they are mainly used in simple tasks. In this paper we show how the multi-touch technology can be extended to collaborative learning and testing at a larger scale, using an existing education implementation for illustration. We propose a Human-Intention-Machine-Interpretation (HIMI) model, which applies a graph-based approach to recognize hand gestures and interpret user intentions. Our focus is not to build a new multi-touch system but to make use of the existing multi-touch \u2026",
            "Abstract entirety": 0,
            "Author pub id": "9OieklkAAAAJ:4JMBOYKVnBMC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Retinal image registration under the assumption of a spherical eye",
            "Publication year": 2017,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S0895611116300544",
            "Abstract": "We propose a method for registering a pair of retinal images. The proposed approach employs point correspondences and assumes that the human eye has a spherical shape. The image registration problem is formulated as a 3D pose estimation problem, solved by estimating the rigid transformation that relates the views from which the two images were acquired. Given this estimate, each image can be warped upon the other so that pixels with the same coordinates image the same retinal point. Extensive experimental evaluation shows improved accuracy over state of the art methods, as well as robustness to noise and spurious keypoint matches. Experiments also indicate the method's applicability to the comparative analysis of images from different examinations that may exhibit changes and its applicability to diagnostic support.",
            "Abstract entirety": 1,
            "Author pub id": "9OieklkAAAAJ:_5tno0g5mFcC",
            "Publisher": "Pergamon"
        },
        {
            "Title": "Region-based Fitting of Overlapping Ellipses and its application to cells segmentation",
            "Publication year": 2020,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S0262885619301350",
            "Abstract": "We present RFOVE, a region-based method for approximating an arbitrary 2D shape with an automatically determined number of possibly overlapping ellipses. RFOVE is completely unsupervised, operates without any assumption or prior knowledge on the object's shape and extends and improves the Decremental Ellipse Fitting Algorithm (DEFA) [1]. Both RFOVE and DEFA solve the multi-ellipse fitting problem by performing model selection that is guided by the minimization of the Akaike Information Criterion on a suitably defined shape complexity measure. However, in contrast to DEFA, RFOVE minimizes an objective function that allows for ellipses with higher degree of overlap and, thus, achieves better ellipse-based shape approximation. A comparative evaluation of RFOVE with DEFA on several standard datasets shows that RFOVE achieves better shape coverage with simpler models (less ellipses). As a \u2026",
            "Abstract entirety": 0,
            "Author pub id": "9OieklkAAAAJ:7wO8s98CvbsC",
            "Publisher": "Elsevier"
        },
        {
            "Title": "Tracking of human hands and faces through probabilistic fusion of multiple visual cues",
            "Publication year": 2008,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-540-79547-6_4",
            "Abstract": "This paper presents a new approach for real time detection and tracking of human hands and faces in image sequences. The proposed method builds upon our previous research on color-based tracking and extends it towards building a system capable of distinguishing between human hands, faces and other skin-colored regions in the image background. To achieve these goals, the proposed approach allows the utilization of additional information cues including motion information given by means of a background subtraction algorithm, and top-down information regarding the formed image segments such as their spatial location, velocity and shape. All information cues are combined under a probabilistic framework which furnishes the proposed approach with the ability to cope with uncertainty due to noise. The proposed approach runs in real time on a standard, personal computer. The presented \u2026",
            "Abstract entirety": 0,
            "Author pub id": "9OieklkAAAAJ:_kc_bZDykSQC",
            "Publisher": "Springer Berlin Heidelberg"
        },
        {
            "Title": "Unsupervised Domain Adaptation for Person Re-Identification with Few and Unlabeled Target Data",
            "Publication year": 2020,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-030-64559-5_28",
            "Abstract": "Existing, fully supervised methods for person re-identification (ReID) require annotated data acquired in the target domain in which the method is expected to operate. This includes the IDs as well as images of persons in that domain. This is an obstacle in the deployment of ReID methods in novel settings. For solving this problem, semi-supervised or even unsupervised ReID methods have been proposed. Still, due to their assumptions and operational requirements, such methods are not easily deployable and/or prove less performant to novel domains/settings, especially those related to small person galleries. In this paper, we propose a novel approach for person ReID that alleviates these problems. This is achieved by proposing a completely unsupervised method for fine tuning the ReID performance of models learned in prior, auxiliary domains, to new, completely different ones. The proposed model \u2026",
            "Abstract entirety": 0,
            "Author pub id": "9OieklkAAAAJ:MAUkC_7iAq8C",
            "Publisher": "Springer, Cham"
        },
        {
            "Title": "Draft of Design Concept of the Cognitive Vision (CV) Framework",
            "Publication year": 2002,
            "Publication url": "https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.121.9173&rep=rep1&type=pdf",
            "Abstract": "This deliverable document provides the first complete overview of the Cognitive Vision (CV) framework. It summarises the work thus far under Task 1.1 (Conception and Interface Definitions). This CV framework is one of the two main deliverables of ActIPret, the second being the development of purposive processing and interpretation techniques according to this framework.",
            "Abstract entirety": 1,
            "Author pub id": "9OieklkAAAAJ:j3f4tGmQtD8C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Fusion of laser and visual data for robot motion planning and collision avoidance",
            "Publication year": 2003,
            "Publication url": "https://link.springer.com/article/10.1007/s00138-003-0133-2",
            "Abstract": "In this paper, a method for inferring scene structure information based on both laser and visual data is proposed. Common laser scanners employed in contemporary robotic systems provide accurate range measurements, but only in 2D slices of the environment. On the other hand, vision is capable of providing dense 3D information of the environment. The proposed fusion scheme combines the accuracy of laser sensors with the broad visual fields of cameras toward extracting accurate scene structure information. Data fusion is achieved by validating 3D structure assumptions formed according to 2D range scans of the environment, through the exploitation of visual information. The proposed methodology is applied to robot motion planning and collision avoidance tasks by using a suitably modified version of the vector field histogram algorithm. Experimental results confirm the effectiveness of the proposed \u2026",
            "Abstract entirety": 0,
            "Author pub id": "9OieklkAAAAJ:UeHWp8X0CEIC",
            "Publisher": "Springer-Verlag"
        },
        {
            "Title": "Quantifying the effect of a colored glove in the 3D tracking of a human hand",
            "Publication year": 2015,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-319-20904-3_36",
            "Abstract": "Research in vision-based 3D hand tracking targets primarily the scenario in which a bare hand performs unconstrained motion in front of a camera system. Nevertheless, in several important application domains, augmenting the hand with color information so as to facilitate the tracking process constitutes an acceptable alternative. With this observation in mind, in this work we propose a modification of a state of the art method [12] for markerless 3D hand tracking, that takes advantage of the richer observations resulting from a colored glove. We do so by modifying the 3D hand model employed in the aforementioned hypothesize-and-test method as well as the objective function that is minimized in its optimization step. Quantitative and qualitative results obtained from a comparative evaluation of the baseline method to the proposed approach confirm that the latter achieves a remarkable increase in tracking \u2026",
            "Abstract entirety": 0,
            "Author pub id": "9OieklkAAAAJ:fEOibwPWpKIC",
            "Publisher": "Springer, Cham"
        },
        {
            "Title": "Project GRASP: Emergence of Cognitive Grasping through Introspection, Emulation and Surprise Contract No: 215821 Starting Date: 01-03-2008",
            "Publication year": 2010,
            "Publication url": "Unknown",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "9OieklkAAAAJ:jgBuDB5drN8C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Enforcing scene constraints in single view reconstruction",
            "Publication year": 2007,
            "Publication url": "https://diglib.eg.org/xmlui/bitstream/handle/10.2312/egs.20071030.045-048/045-048.pdf?sequence=1",
            "Abstract": "Three-dimensional reconstruction from a single view is an under-constrained process that relies critically upon the availability of prior knowledge about the imaged scene. This knowledge is assumed to be supplied by a user in the form of geometric constraints such as coplanarity, parallelism, perpendicularity, etc, based on his/her interpretation of the scene. In the presence of noise, however, most of the existing methods yield reconstructions that only approximately satisfy the supplied geometric constraints. This paper proposes a novel single view reconstruction method that provides reconstructions which exactly satisfy all user-supplied constraints. This is achieved by first obtaining a preliminary reconstruction and then refining it in an extendable, constrained optimization framework.",
            "Abstract entirety": 1,
            "Author pub id": "9OieklkAAAAJ:NMxIlDl6LWMC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Computer Vision in Human-Computer Interaction",
            "Publication year": 2006,
            "Publication url": "https://scholar.google.com/scholar?cluster=3947274094174257769&hl=en&oi=scholarr",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "9OieklkAAAAJ:AHdEip9mkN0C",
            "Publisher": "Springer-Verlag"
        },
        {
            "Title": "10 EURON\u2014The European Robotics Network",
            "Publication year": 2005,
            "Publication url": "https://scholar.archive.org/work/xmwvjex54rf4hgdwvrfgpl6l3a/access/wayback/http://ieeexplore.ieee.org/ielx5/100/31383/01458294.pdf?tp=&arnumber=1458294&isnumber=31383",
            "Abstract": "2 From the Editor\u2019s Desk 3 President\u2019s Message 4 From the Guest Editors 5 Society News 8 \nEducation 99 Industry/Research News Page 1 2 From the Editor\u2019s Desk 3 President\u2019s Message \n4 From the Guest Editors 5 Society News 8 Education 99 Industry/Research News 100 EURON \nReport 102 Calendar 104 On the Shelf IEEE Robotics & Automation Magazine (ISSN \n1070-9932) (IRAMEB) is published quarterly by the Institute of Electrical and Electronics \nEngineers, Inc. Headquarters: 3 Park Avenue, 17th Floor, New York, NY 10016-5997 USA, \nTelephone: +1 212 419 7900. Responsibility for the content rests upon the authors and not upon \nthe IEEE, the Society or its members. IEEE Service Center (for orders, subscriptions, address \nchanges): 445 Hoes Lane, PO Box 1331, Piscataway, NJ 08855-1331 USA. Telephone: +1 732 \n981 0060. Individual copies: IEEE members $20.00 (first copy only), nonmembers $71.00 . (\u2026",
            "Abstract entirety": 0,
            "Author pub id": "9OieklkAAAAJ:hsZV8lGYWTMC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Hand-object contact force estimation from markerless visual tracking",
            "Publication year": 2018,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/8085141/",
            "Abstract": "We consider the problem of estimating realistic contact forces during manipulation, backed with ground-truth measurements, using vision alone. Interaction forces are usually measured by mounting force transducers onto the manipulated objects or the hands. Those are costly, cumbersome, and alter the objects' physical properties and their perception by the human sense of touch. Our work establishes that interaction forces can be estimated in a cost-effective, reliable, non-intrusive way using vision. This is a complex and challenging problem. Indeed, in multi-contact, a given motion can generally be caused by an infinity of possible force distributions. To alleviate the limitations of traditional models based on inverse optimization, we collect and release the first large-scale dataset on manipulation kinodynamics as 3.2 hours of synchronized force and motion measurements under 193 object-grasp configurations. We \u2026",
            "Abstract entirety": 0,
            "Author pub id": "9OieklkAAAAJ:SpbeaW3--B0C",
            "Publisher": "IEEE"
        },
        {
            "Title": "Filling the Joints: Completion and Recovery of Incomplete 3D Human Poses",
            "Publication year": 2018,
            "Publication url": "https://www.mdpi.com/358604",
            "Abstract": "We present a comparative study of three matrix completion and recovery techniques based on matrix inversion, gradient descent, and Lagrange multipliers, applied to the problem of human pose estimation. 3D human pose estimation algorithms may exhibit noise or may completely fail to provide estimates for some joints. A post-process is often employed to recover the missing joints\u2019 locations from the remaining ones, typically by enforcing kinematic constraints or by using a prior learned from a database of natural poses. Matrix completion and recovery techniques fall into the latter category and operate by filling-in missing entries of a matrix whose available/non-missing entries may be additionally corrupted by noise. We compare the performance of three such techniques in terms of the estimation error of their output as well as their runtime, in a series of simulated and real-world experiments. We conclude by recommending use cases for each of the compared techniques. View Full-Text",
            "Abstract entirety": 1,
            "Author pub id": "9OieklkAAAAJ:P7Ujq4OLJYoC",
            "Publisher": "Multidisciplinary Digital Publishing Institute"
        },
        {
            "Title": "A Robot-based Application for Physical Exercise Training",
            "Publication year": 2016,
            "Publication url": "https://www.researchgate.net/profile/Antonis-Argyros/publication/296970008_A_Robot-based_Application_for_Physical_Exercise_Training/links/580fada708ae009606bb8ac5/A-Robot-based-Application-for-Physical-Exercise-Training.pdf",
            "Abstract": "According to studies, performing physical exercise is beneficial for reducing the risk of falling in the elderly and prolonging their stay at home. In addition, regular exercising helps cognitive function and increases positive behaviour for seniors with cognitive impairment and dementia. In this paper, a fitness application integrated into a service robot is presented. Its aim is to motivate the users to perform physical training by providing relevant exercises and useful feedback on their progress. The application utilizes the robot vision system to track and recognize user movements and activities and supports multimodal interaction with the user. The paper describes the design challenges, the system architecture, the user interface and the human motion capturing module. Additionally, it discusses some results from user testing in laboratory and home-based trials.",
            "Abstract entirety": 1,
            "Author pub id": "9OieklkAAAAJ:b1wdh0AR-JQC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Corridor following by mobile robots equipped with panoramic cameras",
            "Publication year": 2000,
            "Publication url": "https://www.academia.edu/download/5382797/10.1.1.129.1366.pdf",
            "Abstract": "The present work considers corridor\u2013following maneuvers for nonholonomic mobile robots, guided by sensory data acquired by panoramic cameras. The panoramic vision system provides information from an environment with textured walls to the motion control system, which drives the robot along a corridor. Panoramic cameras have a 360 visual field, a capability that the proposed control methods exploit. In our sensor\u2013based control scheme, optical flow information from several distinct viewing directions in the entire field of view of the panoramic camera is used directly in the control loop, without the need for state reconstruction. The interest of this lies in the fact that the optical flow information is not sufficient to reconstruct the state of the system, it is however sufficient for the proposed control law to accomplish the desired task. Driving the robot along a corridor amounts to the asymptotic stabilization of a subsystem of the robot\u2019s kinematics and the proposed control schemes are shown to achieve this goal.",
            "Abstract entirety": 1,
            "Author pub id": "9OieklkAAAAJ:bEWYMUwI8FkC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Full dof tracking of a hand interacting with an object by modeling occlusions and physical constraints",
            "Publication year": 2011,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/6126483/",
            "Abstract": "Due to occlusions, the estimation of the full pose of a human hand interacting with an object is much more challenging than pose recovery of a hand observed in isolation. In this work we formulate an optimization problem whose solution is the 26-DOF hand pose together with the pose and model parameters of the manipulated object. Optimization seeks for the joint hand-object model that (a) best explains the incompleteness of observations resulting from occlusions due to hand-object interaction and (b) is physically plausible in the sense that the hand does not share the same physical space with the object. The proposed method is the first that solves efficiently the continuous, full-DOF, joint hand-object tracking problem based solely on markerless multicamera input. Additionally, it is the first to demonstrate how hand-object interaction can be exploited as a context that facilitates hand pose estimation, instead of \u2026",
            "Abstract entirety": 0,
            "Author pub id": "9OieklkAAAAJ:r0BpntZqJG4C",
            "Publisher": "IEEE"
        },
        {
            "Title": "Foreground detection with a moving RGBD camera",
            "Publication year": 2013,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-642-41914-0_22",
            "Abstract": "A method for foreground detection in data acquired by a moving RGBD camera is proposed. The background scene is initially in a reference model. An initial estimation of camera motion is provided by a conventional point cloud registration approach of matched keypoints between the captured scene and the reference model. This initial solution is then refined based on a top-down, model based approach that evaluates candidate camera poses in a Particle Swarm Optimization framework. To evaluate a candidate pose, the method renders color and depth images of the model according to this pose and computes a dissimilarity score of the rendered images to the currently captured ones. This score is based on the direct comparison of color, depth, and surface geometry between the acquired and rendered images, while allowing for outliers due to the potential occurrence of foreground objects, or newly \u2026",
            "Abstract entirety": 0,
            "Author pub id": "9OieklkAAAAJ:1yQoGdGgb4wC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "Hierarchical particle filtering for 3d hand tracking",
            "Publication year": 2015,
            "Publication url": "https://www.cv-foundation.org/openaccess/content_cvpr_workshops_2015/W15/html/Makris_Hierarchical_Particle_Filtering_2015_CVPR_paper.html",
            "Abstract": "We present a fast and accurate 3D hand tracking method which relies on RGB-D data. The method follows a model based approach using a hierarchical particle filter variant to track the model's state. The filter estimates the probability density function of the state's posterior. As such, it has increased robustness to observation noise and compares favourably to existing methods that can be trapped in local minima resulting in track loses. The data likelihood term is calculated by measuring the discrepancy between the rendered 3D model and the observations. Extensive experiments with real and simulated data show that hand tracking is achieved at a frame rate of 90fps with less that 10mm average error using a GPU implementation, thus comparing favourably to the state of the art in terms of both speed and tracking accuracy.",
            "Abstract entirety": 1,
            "Author pub id": "9OieklkAAAAJ:j8SEvjWlNXcC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Efficient Cooperation of Heterogeneous Robotic Agents: A Decentralized Framework",
            "Publication year": 2021,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/9415417/",
            "Abstract": "The efficient supervision and coordination of a heterogeneous system mandates a decentralized framework that integrates high-level task planning, low-level motion planning and control, and robust real-time sensing of the robot\u2019s dynamic environment. Decentralization in multiagent robotic systems is of utmost importance because it provides flexibility, scalability, and fault-tolerance capabilities. In this work, we present the architecture of the decentralized framework developed within the context of the European Union project Co4Robots and its application in a multitasking collaboration scenario involving various heterogeneous robots and humans.",
            "Abstract entirety": 1,
            "Author pub id": "9OieklkAAAAJ:RoXSNcbkSzsC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Integrating tracking with fine object segmentation",
            "Publication year": 2013,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S0262885613001121",
            "Abstract": "We present a novel method for on-line, joint object tracking and segmentation in a monocular video captured by a possibly moving camera. Our goal is to integrate tracking and fine segmentation of a single, previously unseen, potentially non-rigid object of unconstrained appearance, given its segmentation in the first frame of an image sequence as the only prior information. To this end, we tightly couple an existing kernel-based object tracking method with Random Walker-based image segmentation. Bayesian inference mediates between tracking and segmentation, enabling effective data fusion of pixel-wise spatial and color visual cues. The fine segmentation of an object at a certain frame provides tracking with reliable initialization for the next frame, closing the loop between the two building blocks of the proposed framework. The effectiveness of the proposed methodology is evaluated experimentally by \u2026",
            "Abstract entirety": 0,
            "Author pub id": "9OieklkAAAAJ:LjlpjdlvIbIC",
            "Publisher": "Elsevier"
        },
        {
            "Title": "ReActNet: Temporal Localization of Repetitive Activities in Real-World Videos",
            "Publication year": 2019,
            "Publication url": "https://arxiv.org/abs/1910.06096",
            "Abstract": "We address the problem of temporal localization of repetitive activities in a video, i.e., the problem of identifying all segments of a video that contain some sort of repetitive or periodic motion. To do so, the proposed method represents a video by the matrix of pairwise frame distances. These distances are computed on frame representations obtained with a convolutional neural network. On top of this representation, we design, implement and evaluate ReActNet, a lightweight convolutional neural network that classifies a given frame as belonging (or not) to a repetitive video segment. An important property of the employed representation is that it can handle repetitive segments of arbitrary number and duration. Furthermore, the proposed training process requires a relatively small number of annotated videos. Our method raises several of the limiting assumptions of existing approaches regarding the contents of the video and the types of the observed repetitive activities. Experimental results on recent, publicly available datasets validate our design choices, verify the generalization potential of ReActNet and demonstrate its superior performance in comparison to the current state of the art.",
            "Abstract entirety": 1,
            "Author pub id": "9OieklkAAAAJ:MhiOAD_qIWkC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Markerless, Segmentation-Free Plane Tracking",
            "Publication year": 2003,
            "Publication url": "Unknown",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "9OieklkAAAAJ:OU6Ihb5iCvQC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Dynamic time warping for binocular hand tracking and reconstruction.",
            "Publication year": 2008,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/4543555/",
            "Abstract": "We show how matching and reconstruction of contour points can be performed using dynamic time warping (DTW) for the purpose of 3D hand contour tracking. We evaluate the performance of the proposed algorithm in object manipulation activities and perform comparison with the iterative closest point (ICP) method.",
            "Abstract entirety": 1,
            "Author pub id": "9OieklkAAAAJ:L8Ckcad2t8MC",
            "Publisher": "IEEE"
        },
        {
            "Title": "A Multicamera Vision System Supporting the Development of Wide-Area Exertainment Applications.",
            "Publication year": 2009,
            "Publication url": "https://www.ics.forth.gr/cvrl/publications/conferences/2009_05_mva_exertainment.pdf",
            "Abstract": "In this paper, the application of computer vision techniques to the localization of multiple persons in a relatively wide gaming terrain is presented. Multiple views are employed both for terrain coverage, but most importantly, for treatment of occlusions. Through the appropriate selection of lightweight operations and acceleration strategies, an adequate frame rate is achieved despite the large volume of input data. The resulting system is employed in the development of multiplayer entertainment applications, which are demonstrated and evaluated.",
            "Abstract entirety": 1,
            "Author pub id": "9OieklkAAAAJ:NaGl4SEjCO4C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Augmented Reality Interactive Exhibits in Cartographic Heritage: An implemented case-study open to the general public",
            "Publication year": 2011,
            "Publication url": "https://www.academia.edu/download/30825750/2011_04_ica_cartographic.pdf",
            "Abstract": "This paper presents the application of the PaperView system in the domain of cartographic heritage. PaperView is a multi-user augmented-reality system for supplementing physical surfaces with digital information, through the use of pieces of plain paper that act as personal, location-aware, interactive screens. By applying the proposed method of reality augmentation in the cartographic heritage domain, the system provides the capability of retrieving multimedia information about areas of interest, overlaying information on a 2D or 3D (ie, scale model) map, as well as comparing different versions of a single map. The technologies employed are presented, along with the interactive behavior of the system, which was instantiated and tested in three setups:(i) a map of Macedonia, Greece, including ancient Greek cities with archeological interest;(ii) a glass case containing a scale model and (iii) a part of Rigas Velestinlis\u2019 Charta. The first two systems are currently installed and available to the general public at the Archaeological Museum of Thessaloniki, Greece, as part of a permanent exhibition of interactive systems.",
            "Abstract entirety": 1,
            "Author pub id": "9OieklkAAAAJ:lSLTfruPkqcC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Pattern Recognition Referees 2009",
            "Publication year": 2010,
            "Publication url": "https://www.diva-portal.org/smash/record.jsf?pid=diva2:928895",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "9OieklkAAAAJ:ClCfbGk0d_YC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Shape from interaction",
            "Publication year": 2014,
            "Publication url": "https://link.springer.com/article/10.1007/s00138-014-0602-9",
            "Abstract": "We present \u201cshape from interaction\u201d (SfI), an approach to the problem of acquiring 3D representations of rigid objects through observing the activity of a human who handles a tool. SfI relies on the fact that two rigid objects cannot share the same physical space. The 3D reconstruction of the unknown object is achieved by tracking the known 3D tool and by carving out the space it occupies as a function of time. Due to this indirection, SfI reconstructs rigid objects regardless of their material and appearance properties and proves particularly useful for the cases of textureless, transparent, translucent, refractive and specular objects for which there exists no practical vision-based 3D reconstruction method. Additionally, object concavities that are not directly observable can also be reconstructed. The 3D tracking of the tool is formulated as an optimization problem that is solved based on visual input acquired by a \u2026",
            "Abstract entirety": 0,
            "Author pub id": "9OieklkAAAAJ:_Ybze24A_UAC",
            "Publisher": "Springer Berlin Heidelberg"
        },
        {
            "Title": "PYTHEAS: an integrated robotic system with autonomous navigation capabilities",
            "Publication year": 2002,
            "Publication url": "https://139.91.152.92/_publications/2001_07_ktisivios01_pytheas.pdf",
            "Abstract": "PYTHEAS is an integrated robotic software system that offers advanced navigation capabilities, which include localization, workspace mapping, path planning and tracking and obstacle avoidance. PYTHEAS facilitates mapping of an unknown indoors environment by exploiting information extracted from a laser scanner. Based on this acquired environment representation, the system is able to navigate autonomously in the mapped environment, while, at the same time, avoiding dynamic obstacles such as moving persons, etc. All the required competences are coupled in an integrated system, which can be controlled through a user-friendly interface over the web. Extensive experimental results demonstrate the capability of the developed system to map complicated environments and support navigation in dynamic worlds.",
            "Abstract entirety": 1,
            "Author pub id": "9OieklkAAAAJ:ns9cj8rnVeAC",
            "Publisher": "Unknown"
        },
        {
            "Title": "A Review on Intelligent Object Perception Methods Combining Knowledge-based Reasoning and Machine Learning",
            "Publication year": 2020,
            "Publication url": "https://arxiv.org/abs/1912.11861",
            "Abstract": "Object perception is a fundamental sub-field of Computer Vision, covering a multitude of individual areas and having contributed high-impact results. While Machine Learning has been traditionally applied to address related problems, recent works also seek ways to integrate knowledge engineering in order to expand the level of intelligence of the visual interpretation of objects, their properties and their relations with their environment. In this paper, we attempt a systematic investigation of how knowledge-based methods contribute to diverse object perception tasks. We review the latest achievements and identify prominent research directions.",
            "Abstract entirety": 1,
            "Author pub id": "9OieklkAAAAJ:LPtt_HFRSbwC",
            "Publisher": "Unknown"
        },
        {
            "Title": "The HealthSign project, current state and future activities",
            "Publication year": 2020,
            "Publication url": "https://ejupunescochair.library.upatras.gr/iisa/article/view/3332",
            "Abstract": "This paper presents the HealthSign project, which deals with the problem of sign language recognition with focus on medical interac-tion scenarios. The deaf user will be able to communicate in his native sign language with a physician. The continuous signs will be translated to text and presented to the physician. Similarly, the speech will be recognized and presented as text to the deaf users. Two alternative versions of the system will be developed, one doing the recognition on a server, and another one doing the recognition on a mobile device.",
            "Abstract entirety": 1,
            "Author pub id": "9OieklkAAAAJ:rHJHxKgnXwkC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Markerless 3d human pose estimation and tracking based on rgbd cameras: an experimental evaluation",
            "Publication year": 2017,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/3056540.3056543",
            "Abstract": "We present a comparative experimental evaluation of three methods that estimate the 3D position, orientation and articulation of the human body from markerless visual observations obtained by RGBD cameras. The evaluated methods are representatives of three broad 3D human pose estimation/tracking methods. Specifically, the first is the discriminative approach adopted by OpenNI. The second is a hybrid approach that depends on the input of two synchronized and extrinsically calibrated RGBD cameras. Finally, the third one is a recently developed generative method that depends on input provided by a single RGBD camera. The experimental evaluation of these methods has been based on a publicly available data set that is annotated with ground truth. The obtained results expose the characteristics of the three methods and provide evidence that can guide the selection of the most appropriate one \u2026",
            "Abstract entirety": 0,
            "Author pub id": "9OieklkAAAAJ:LO7wyVUgiFcC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Boosting the Performance of Model-based 3D Tracking by Employing Low Level Motion Cues",
            "Publication year": 2015,
            "Publication url": "http://www.bmva.org/bmvc/2015/papers/paper144/abstract144.pdf",
            "Abstract": "3D tracking of objects and hands in an object manipulation scenario is a very interesting computer vision problem with a wide variety of applications ranging from consumer electronics to robotics and medicine. Recent advances in this research topic allow for 3D tracking of complex scenarios involving bi-manual manipulation of several rigid objects using commodity hardware and with high accuracy. The problem with these approaches is that they treat tracking as a search problem whose dimensionality increases with the number of objects in the scene. This fact typically limits the number of the tracked objects and/or the processing framerate. In this paper we present a method that utilizes simple low level motion cues for dynamically assigning computational resources to parts of the scene where they are actually required. In a series of experiments, we show that this simple idea improves tracking performance dramatically at a cost of only a minor degradation of tracking accuracy. The works that are most related to ours are the approaches by Kyriazis and Argyros on top-down 3D tracking of multiple active objects from RGBD input [1, 2]. The methodological part of our contribution can be briefly described as an extra processing node in the pipeline of [2] which it extends. The tracking approach in [2], the Ensemble of Collaborative Trackers (ECT), regards a set of semi-independent trackers. Each tracker is associated with a distinct object in the scene. For an object to be tracked, a separate optimization problem is solved, one for each frame and each object. Each optimization problem is numerically solved using a black box optimizer, ie a variant of \u2026",
            "Abstract entirety": 0,
            "Author pub id": "9OieklkAAAAJ:uWiczbcajpAC",
            "Publisher": "BMVA Press"
        },
        {
            "Title": "Feature transfer and matching in disparate stereo views through the use of plane homographies",
            "Publication year": 2003,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/1177157/",
            "Abstract": "Many vision tasks rely upon the identification of sets of corresponding features among different images. This paper presents a method that, given some corresponding features in two stereo images, matches them with features extracted from a second stereo pair captured from a distant viewpoint. The proposed method is based on the assumption that the viewed scene contains two planar surfaces and exploits geometric constraints that are imposed by the existence of these planes to first transfer and then match image features between the two stereo pairs. The resulting scheme handles point and line features in a unified manner and is capable of successfully matching features extracted from stereo pairs that are acquired from considerably different viewpoints. Experimental results are presented, which demonstrate that the performance of the proposed method compares favorably to that of epipolar and tensor \u2026",
            "Abstract entirety": 0,
            "Author pub id": "9OieklkAAAAJ:roLk4NBRz8UC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Hobbit: providing fall detection and prevention for the elderly in the real world",
            "Publication year": 2018,
            "Publication url": "https://www.hindawi.com/journals/jr/2018/1754657/",
            "Abstract": "We present the robot developed within the Hobbit project, a socially assistive service robot aiming at the challenge of enabling prolonged independent living of elderly people in their own homes. We present the second prototype (Hobbit PT2) in terms of hardware and functionality improvements following first user studies. Our main contribution lies within the description of all components developed within the Hobbit project, leading to autonomous operation of 371 days during field trials in Austria, Greece, and Sweden. In these field trials, we studied how 18 elderly users (aged 75 years and older) lived with the autonomously interacting service robot over multiple weeks. To the best of our knowledge, this is the first time a multifunctional, low-cost service robot equipped with a manipulator was studied and evaluated for several weeks under real-world conditions. We show that Hobbit\u2019s adaptive approach towards the user increasingly eased the interaction between the users and Hobbit. We provide lessons learned regarding the need for adaptive behavior coordination, support during emergency situations, and clear communication of robotic actions and their consequences for fellow researchers who are developing an autonomous, low-cost service robot designed to interact with their users in domestic contexts. Our trials show the necessity to move out into actual user homes, as only there can we encounter issues such as misinterpretation of actions during unscripted human-robot interaction.",
            "Abstract entirety": 1,
            "Author pub id": "9OieklkAAAAJ:cWzG1nlazyYC",
            "Publisher": "Hindawi"
        },
        {
            "Title": "The Design and Implementation of a Generic Sparse Bundle Adjustment Software Package Based on the Levenberg-Marquardt Algorithm",
            "Publication year": 2004,
            "Publication url": "https://www.ics.forth.gr/~argyros/mypapers/2004_08_tr340_forth_sba.pdf",
            "Abstract": "Bundle Adjustment (BA) is almost invariably used as the last step of every featurebased multiview structure and motion estimation algorithm; see, for example,[10, 3, 6, 21, 27]. BA was originally conceived in the field of photogrammetry [24] and has increasingly been used by vision researchers during the last decade. An excellent overview of its application to vision-based reconstruction is given in [25]. BA is a technique for simultaneously refining the 3D structure and viewing parameters (ie camera pose and possibly intrinsic calibration and radial distortion), to obtain a reconstruction which is optimal under certain assumptions regarding the noise pertaining to the observed image features [25]: If the image error is zero-mean Gaussian, then BA is the Maximum Likelihood Estimator. Its name refers to the\" bundles\" of light rays originating from each 3D feature and converging on each camera centre, which are adjusted optimally with respect to both structure and viewing parameters. BA amounts to minimizing the reprojection error between the observed and predicted image points, which is expressed as the sum of squares of a number of nonlinear real-valued functions. Thus, the minimization is achieved using non-linear least squares algorithms [4, 18], of which the Levenberg-Marquardt (LM) has proven to be the most successful due to its use of an effective damping strategy that lends it the ability to converge promptly from a wide range of initial guesses [11]. By iteratively linearizing the function to be minimized in the neighborhood of the current estimate, the LM algorithm involves the solution of linear systems known as the normal equations \u2026",
            "Abstract entirety": 0,
            "Author pub id": "9OieklkAAAAJ:a9-T7VOCCH8C",
            "Publisher": "TR 340"
        },
        {
            "Title": "HOBBIT-The Mutual Care Robot. To be printed at Assistance and Service Robotics in a Human Environment Workshop in conjunction with IEEE",
            "Publication year": 2013,
            "Publication url": "https://scholar.google.com/scholar?cluster=3627375097768266984&hl=en&oi=scholarr",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "9OieklkAAAAJ:1Ye0OR6EYb4C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Smart sensor based vision system for automated processes",
            "Publication year": 2007,
            "Publication url": "http://old.sztaki.hu/~viharos/homepage/Publications/2007/2007_INTSAR/MultiSens_Viharos_Web.pdf",
            "Abstract": "A new approach is proposed for vision-based sensing and processing for process control and monitoring of automated processes. The proposed approach relies on a number of binary logical sensors defined over specific regions of interest in the viewed scene. On top of these elementary sensors, temporal and logical aggregation mechanisms realize hierarchies of compound logical functions, able to detect complex events. Finally, scenario verification mechanisms are employed to monitor the occurrence order and timing of expected and actual events. The proposed framework has been tested and validated in an application involving monitoring of automated processes, demonstrating that the proposed approach provides a promising concept of vision-based event detection. The described framework is being implemented on the Bi-i standalone cellular vision system which has the potential of replacing several conventional sensors used for process control and fault detection in automation.",
            "Abstract entirety": 1,
            "Author pub id": "9OieklkAAAAJ:Mojj43d5GZwC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Exploiting Panoramic Vision for Angle-based Robot Homing",
            "Publication year": 2006,
            "Publication url": "https://scholar.google.com/scholar?cluster=7324443212824239111&hl=en&oi=scholarr",
            "Abstract": "Omni-directional vision allows for the development of techniques for mobile robot navigation that have minimum perceptual requirements. In this paper, we focus on robot navigation algorithms that do not require range information or metric maps of the environment. More specifically, we present a memory-based homing strategy that enables a robot to return to its home position after executing a long path. The proposed strategy relies on measuring the angle between pairs of features extracted from panoramic images, which can be achieved accurately and robustly. In the heart of the proposed homing strategy lies a novel, local control law that enables a robot to reach any position on the plane by exploiting the bearing angles of at least three landmarks of unknown position, without making assumptions regarding the robot\u2019s orientation and without making use of a compass. This control law is the result of the \u2026",
            "Abstract entirety": 0,
            "Author pub id": "9OieklkAAAAJ:ubry08Y2EpUC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Markerless and efficient 26-dof hand pose recovery",
            "Publication year": 2011,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-642-19318-7_58",
            "Abstract": "We present a novel method that, given a sequence of synchronized views of a human hand, recovers its 3D position, orientation and full articulation parameters. The adopted hand model is based on properly selected and assembled 3D geometric primitives. Hypothesized configurations/poses of the hand model are projected to different camera views and image features such as edge maps and hand silhouettes are computed. An objective function is then used to quantify the discrepancy between the predicted and the actual, observed features. The recovery of the 3D hand pose amounts to estimating the parameters that minimize this objective function which is performed using Particle Swarm Optimization. All the basic components of the method (feature extraction, objective function evaluation, optimization process) are inherently parallel. Thus, a GPU-based implementation achieves a speedup of two \u2026",
            "Abstract entirety": 0,
            "Author pub id": "9OieklkAAAAJ:qUcmZB5y_30C",
            "Publisher": "Springer Berlin Heidelberg"
        },
        {
            "Title": "Tracking deformable surfaces that undergo topological changes using an RGB-D camera",
            "Publication year": 2016,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/7785107/",
            "Abstract": "We present a method for 3D tracking of deformable surfaces with dynamic topology, for instance a paper that undergoes cutting or tearing. Existing template-based methods assume a template of fixed topology. Thus, they fail in tracking deformable objects that undergo topological changes. In our work, we employ a dynamic template (3D mesh) whose topology evolves based on the topological changes of the observed geometry. Our tracking framework deforms the defined template based on three types of constraints: (a) the surface of the template has to be registered to the 3D shape of the tracked surface, (b) the template deformation should respect feature (SIFT) correspondences between selected pairs of frames, and (c) the lengths of the template edges should be preserved. The latter constraint is relaxed when an edge is found to lie on a \"geometric gap\", that is, when a significant depth discontinuity is detected \u2026",
            "Abstract entirety": 0,
            "Author pub id": "9OieklkAAAAJ:Dip1O2bNi0gC",
            "Publisher": "Unknown"
        },
        {
            "Title": "TOURBOT-Interactive Museum Telepresence through Robotic Avatars, 9th Int",
            "Publication year": 2000,
            "Publication url": "https://scholar.google.com/scholar?cluster=3011575153153146139&hl=en&oi=scholarr",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "9OieklkAAAAJ:Bg7qf7VwUHIC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Hybrid One-Shot 3D Hand Pose Estimation by Exploiting Uncertainties",
            "Publication year": 2015,
            "Publication url": "https://arxiv.org/abs/1510.08039",
            "Abstract": "Model-based approaches to 3D hand tracking have been shown to perform well in a wide range of scenarios. However, they require initialisation and cannot recover easily from tracking failures that occur due to fast hand motions. Data-driven approaches, on the other hand, can quickly deliver a solution, but the results often suffer from lower accuracy or missing anatomical validity compared to those obtained from model-based approaches. In this work we propose a hybrid approach for hand pose estimation from a single depth image. First, a learned regressor is employed to deliver multiple initial hypotheses for the 3D position of each hand joint. Subsequently, the kinematic parameters of a 3D hand model are found by deliberately exploiting the inherent uncertainty of the inferred joint proposals. This way, the method provides anatomically valid and accurate solutions without requiring manual initialisation or suffering from track losses. Quantitative results on several standard datasets demonstrate that the proposed method outperforms state-of-the-art representatives of the model-based, data-driven and hybrid paradigms.",
            "Abstract entirety": 1,
            "Author pub id": "9OieklkAAAAJ:z_wVstp3MssC",
            "Publisher": "BMVA Press"
        },
        {
            "Title": "The HealthSign Project: Vision and Objectives",
            "Publication year": 2018,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/3197768.3201547",
            "Abstract": "This paper presents the HealthSign project, which deals with the problem of sign language recognition with focus on medical interaction scenarios. The deaf user will be able to communicate in his native sign language with a physician. The continuous signs will be translated to text and presented to the physician. Similarly, the speech will be recognized and presented as text to the deaf users. Two alternative versions of the system will be developed, one doing the recognition on a server, and another one doing the recognition on a mobile device.",
            "Abstract entirety": 1,
            "Author pub id": "9OieklkAAAAJ:yqoGN6RLRZoC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Semi-autonomous navigation of a robotic wheelchair",
            "Publication year": 2002,
            "Publication url": "https://link.springer.com/article/10.1023/A:1016371922451",
            "Abstract": "The present work considers the development of a wheelchair for people with special needs, which is capable of navigating semi-autonomously within its workspace. This system is expected to prove useful to people with impaired mobility and limited fine motor control of the upper extremities. Among the implemented behaviors of this robotic system are the avoidance of obstacles, the motion in the middle of the free space and the following of a moving target specified by the user (e.g., a person walking in front of the wheelchair). The wheelchair is equipped with sonars, which are used for distance measurement in preselected critical directions, and with a panoramic camera with a 360 degree field of view, which is used for following a moving target. After suitably processing the color sequence of the panoramic images using the color histogram of the desired target, the orientation of the target with respect to the \u2026",
            "Abstract entirety": 0,
            "Author pub id": "9OieklkAAAAJ:zYLM7Y9cAGgC",
            "Publisher": "Kluwer Academic Publishers"
        },
        {
            "Title": "Pervasive Computing@ ICS-FORTH",
            "Publication year": 2008,
            "Publication url": "https://www.academia.edu/download/3458447/w3-01.pdf",
            "Abstract": "This paper introduces the Ambient Intelligence (AmI) Programme of the Institute of Computer Science of the Foundation for Research and Technology\u2013Hellas (ICS-FORTH). In this context, a laboratory space of about 100m2 comprising six rooms, called the \u201cAmI Sandbox\u201d, has been created. In this space several AmI technologies have already been installed and related R&D activities are being conducted. In addition to that, a large-scale Ambient Intelligence Facility is currently being built. The facility will occupy a threefloor 3,000 m2 building, comprising simulated AmI-augmented environments and their support spaces, laboratory spaces for developing and testing related technologies, staff offices and public spaces.",
            "Abstract entirety": 1,
            "Author pub id": "9OieklkAAAAJ:mB3voiENLucC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Computer Vision Systems: 12th International Conference, ICVS 2019, Thessaloniki, Greece, September 23\u201325, 2019, Proceedings",
            "Publication year": 2019,
            "Publication url": "https://books.google.com/books?hl=en&lr=&id=OOK_DwAAQBAJ&oi=fnd&pg=PR5&dq=info:ejGC1pobZzAJ:scholar.google.com&ots=C8ct2dmbhp&sig=HNIYNhD1K8k3FmLA8G_qpSvf3NU",
            "Abstract": "This book constitutes the refereed proceedings of the 12th International Conference on Computer Vision Systems, ICVS 2019, held in Thessaloniki, Greece, in September 2019. The 72 papers presented were carefully reviewed and selected from 114 submissions. The papers are organized in the following topical sections; hardware accelerated and real time vision systems; robotic vision; vision systems applications; high-level and learning vision systems; cognitive vision systems; movement analytics and gesture recognition for human-machine collaboration in industry; cognitive and computer vision assisted systems for energy awareness and behavior analysis; and vision-enabled UAV and counter UAV technologies for surveillance and security of critical infrastructures.",
            "Abstract entirety": 1,
            "Author pub id": "9OieklkAAAAJ:AXkvAH5U_nMC",
            "Publisher": "Springer Nature"
        },
        {
            "Title": "SBA: A software package for generic sparse bundle adjustment",
            "Publication year": 2009,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/1486525.1486527",
            "Abstract": "Bundle adjustment constitutes a large, nonlinear least-squares problem that is often solved as the last step of feature-based structure and motion estimation computer vision algorithms to obtain optimal estimates. Due to the very large number of parameters involved, a general purpose least-squares algorithm incurs high computational and memory storage costs when applied to bundle adjustment. Fortunately, the lack of interaction among certain subgroups of parameters results in the corresponding Jacobian being sparse, a fact that can be exploited to achieve considerable computational savings. This article presents sba, a publicly available C/C++ software package for realizing generic bundle adjustment with high efficiency and flexibility regarding parameterization.",
            "Abstract entirety": 1,
            "Author pub id": "9OieklkAAAAJ:u-x6o8ySG0sC",
            "Publisher": "ACM"
        },
        {
            "Title": "Multicamera human detection and tracking supporting natural interaction with large-scale displays",
            "Publication year": 2013,
            "Publication url": "https://link.springer.com/article/10.1007/s00138-012-0408-6",
            "Abstract": "This paper presents a computer vision system that supports non-instrumented, location-based interaction of multiple users with digital representations of large-scale artifacts. The proposed system is based on a camera network that observes multiple humans in front of a very large display. The acquired views are used to volumetrically reconstruct and track the humans robustly and in real time, even in crowded scenes and challenging human configurations. Given the frequent and accurate monitoring of humans in space and time, a dynamic and personalized textual/graphical annotation of the display can be achieved based on the location and the walk-through trajectory of each visitor. The proposed system has been successfully deployed in an archaeological museum, offering its visitors the capability to interact with and explore a digital representation of an ancient wall painting. This installation permits an \u2026",
            "Abstract entirety": 0,
            "Author pub id": "9OieklkAAAAJ:fQNAKQ3IYiAC",
            "Publisher": "Springer-Verlag"
        },
        {
            "Title": "Extracting Action Hierarchies from Action Labels and their Use in Deep Action Recognition",
            "Publication year": 2020,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/9412033/",
            "Abstract": "Human activity recognition is a fundamental and challenging task in computer vision. Its solution can support multiple and diverse applications in areas including but not limited to smart homes, surveillance, daily living assistance, Human-Robot Collaboration (HRC), etc. In realistic conditions, the complexity of human activities ranges from simple coarse actions, such as siting or standing up, to more complex activities that consist of multiple actions with subtle variations in appearance and motion patterns. A large variety of existing datasets target specific action classes, with some of them being coarse and others being fine-grained. In all of them, a description of the action and its complexity is manifested in the action label sentence. As the action/activity complexity increases, so is the label sentence size and the amount of action-related semantic information contained in this description. In this paper, we propose an \u2026",
            "Abstract entirety": 0,
            "Author pub id": "9OieklkAAAAJ:jE2MZjpN3IcC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Rapid Prototyping of an AmI-Augmented Office Environment Demonstrator",
            "Publication year": 2009,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-642-02580-8_43",
            "Abstract": "This paper presents the process and tangible outcomes of a rapid prototyping activity towards the creation of a demonstrator, showcasing the potential use and effect of Ambient Intelligence technologies in a typical office environment. In this context, the hardware and software components used are described, as well as the interactive behavior of the demonstrator. Additionally, some conclusions stemming from the experience gained are presented, along with pointers for future research and development work.",
            "Abstract entirety": 1,
            "Author pub id": "9OieklkAAAAJ:hMod-77fHWUC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "Temporal Action Co-segmentation in 3D Motion Capture Data and Videos",
            "Publication year": 2017,
            "Publication url": "http://openaccess.thecvf.com/content_cvpr_2017/html/Papoutsakis_Temporal_Action_Co-Segmentation_CVPR_2017_paper.html",
            "Abstract": "Given two action sequences, we are interested in spotting/co-segmenting all pairs of sub-sequences that represent the same action. We propose a totally unsupervised solution to this problem. No a-priori model of the actions is assumed to be available. The number of common sub-sequences may be unknown. The sub-sequences can be located anywhere in the original sequences, may differ in duration and the corresponding actions may be performed by a different person, in different style. We treat this type of temporal action co-segmentation as a stochastic optimization problem that is solved by employing Particle Swarm Optimization (PSO). The objective function that is minimized by PSO capitalizes on Dynamic Time Warping (DTW) to compare two action sub-sequences. Due to the generic problem formulation and solution, the proposed method can be applied to motion capture (ie, 3D skeletal) data or to conventional RGB videos acquired in the wild. We present extensive quantitative experiments on standard data sets as well as on data sets we introduced in this paper. The obtained results demonstrate that the proposed method achieves a remarkable increase in co-segmentation quality compared to all tested state of the art methods.",
            "Abstract entirety": 1,
            "Author pub id": "9OieklkAAAAJ:XoXfffV-tXoC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Macedonia: From Fragments to Pixels",
            "Publication year": 2011,
            "Publication url": "https://scholar.google.com/scholar?cluster=13754058242260598065&hl=en&oi=scholarr",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "9OieklkAAAAJ:buQ7SEKw-1sC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Robot homing based on corner tracking in a sequence of panoramic images",
            "Publication year": 2001,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/990917/",
            "Abstract": "In robotics, homing can be defined as that behavior which enables a robot to return to its initial (home) position, after traveling a certain distance along an arbitrary path. Odometry has traditionally been used for the implementation of such a behavior, but it has been shown to be an unreliable source of information. In this work, a novel method for visual homing is proposed, based on a panoramic camera. As the robot departs from its initial position, it tracks characteristic features of the environment (corners). As soon as homing is activated, the robot selects intermediate target positions on the original path. These intermediate positions (IPs) are then visited sequentially, until the home position is reached. For the robot to move between two consecutive IPs, it is only required to establish correspondence among at least three corners. This correspondence is obtained through a feature tracking mechanism. The proposed \u2026",
            "Abstract entirety": 0,
            "Author pub id": "9OieklkAAAAJ:Tyk-4Ss8FVUC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Vision-Based Interpretation of Hand Gestures for Remote Control of a Computer Mouse",
            "Publication year": 2006,
            "Publication url": "https://link.springer.com/chapter/10.1007/11754336_5",
            "Abstract": "This paper presents a vision-based interface for controlling a computer mouse via 2D and 3D hand gestures. The proposed interface builds upon our previous work that permits the detection and tracking of multiple hands that can move freely in the field of view of a potentially moving camera system. Dependable hand tracking, combined with fingertip detection, facilitates the definition of simple and, therefore, robustly interpretable vocabularies of hand gestures that are subsequently used to enable a human operator convey control information to a computer system. Two such vocabularies are defined, implemented and validated. The first one depends only on 2D hand tracking results while the second also makes use of 3D information. As confirmed by several experiments, the proposed interface achieves accurate mouse positioning, smooth cursor movement and reliable recognition of gestures activating \u2026",
            "Abstract entirety": 0,
            "Author pub id": "9OieklkAAAAJ:4MWp96NkSFoC",
            "Publisher": "Springer Berlin/Heidelberg"
        },
        {
            "Title": "Tele-presence in populated exhibitions through web-operated mobile robots",
            "Publication year": 2003,
            "Publication url": "https://link.springer.com/article/10.1023/A:1026272605502",
            "Abstract": "This paper presents techniques that facilitate mobile robots to be deployed as interactive agents in populated environments such as museum exhibitions or trade shows. The mobile robots can be tele-operated over the Internet and, this way, provide remote access to distant users. Throughout this paper we describe several key techniques that have been developed in this context. To support safe and reliable robot navigation, techniques for environment mapping, robot localization, obstacle detection and people-tracking have been developed. To support the interaction of both web and on-site visitors with the robot and its environment, appropriate software and hardware interfaces have been employed. By using advanced navigation capabilities and appropriate authoring tools, the time required for installing a robotic tour-guide in a museum or a trade fair has been drastically reduced. The developed robotic \u2026",
            "Abstract entirety": 0,
            "Author pub id": "9OieklkAAAAJ:9ZlFYXVOiuMC",
            "Publisher": "Kluwer Academic Publishers"
        },
        {
            "Title": "Is Levenberg-Marquardt the most efficient optimization algorithm for implementing bundle adjustment?",
            "Publication year": 2005,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/1544898/",
            "Abstract": "In order to obtain optimal 3D structure and viewing parameter estimates, bundle adjustment is often used as the last step of feature-based structure and motion estimation algorithms. Bundle adjustment involves the formulation of a large scale, yet sparse minimization problem, which is traditionally solved using a sparse variant of the Levenberg-Marquardt optimization algorithm that avoids storing and operating on zero entries. This paper argues that considerable computational benefits can be gained by substituting the sparse Levenberg-Marquardt algorithm in the implementation of bundle adjustment with a sparse variant of Powell's dog leg non-linear least squares technique. Detailed comparative experimental results provide strong evidence supporting this claim",
            "Abstract entirety": 1,
            "Author pub id": "9OieklkAAAAJ:2osOgNQ5qMEC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Online segmentation and classification of modeled actions performed in the context of unmodeled ones",
            "Publication year": 2014,
            "Publication url": "http://www.bmva.org/bmvc/2014/files/abstract087.pdf",
            "Abstract": "In this work we deal with the problem of online segmentation and classification of visually observable actions, ie, we have to provide labels given the fact that the visual observations arrive stream-wise on a sequential fashion and we need to decide on the label shortly after they are received, without having available the full sequence. The video segmentation has been traditionally treated separately from the classification step, however, these two problems are correlated and can be better handled considering simultaneously the low level cues and the high level models representing the candidate classes. Generative models have been used extensively given their ability to build probabilistic models of actions and provide the posterior of assigning labels to observations. Alternatively, discriminative models better predict the conditional probability of the states given the observed features. As a result, several researchers have investigated the use of discriminative models of actions such as CRFs, SVMs [2] or random forests [1]. However, the discriminative models are not without problems, since they cannot easily handle unknown actions, since they were not part of their optimisation process. In this paper, we show how we seek to mitigate that limitation, by employing a discriminative framework for online simultaneous segmentation and classification of visual actions, which deals effectively with unknown sequences that may interrupt the known sequential patterns. Our framework comprises of two main components:(a) a Hough transform to vote in a 3D space for the begin and end points and the label of the segmented part of the input stream. An SVM \u2026",
            "Abstract entirety": 0,
            "Author pub id": "9OieklkAAAAJ:kzcrU_BdoSEC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Tracking the Articulated Motion of Human Hands in 3D",
            "Publication year": 2013,
            "Publication url": "http://refbase.cvc.uab.es/files/Esc2013.pdf#page=23",
            "Abstract": "The FORTH 3D hand tracker recovers the articulated motion of human hands robustly, accurately and in real time (20Hz). This is achieved by employing a carefully designed model-based approach that capitalizes on a powerful optimization framework, GPU processing and the visual information provided by the Kinect sensor.",
            "Abstract entirety": 1,
            "Author pub id": "9OieklkAAAAJ:hkOj_22Ku90C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Towards the automatic definition of the objective function for model-based 3D hand tracking",
            "Publication year": 2015,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-319-23437-3_30",
            "Abstract": "Recently, model-based                                  approaches                                  have produced very promising results to the problems of 3D hand tracking. The current state of the art method recovers the 3D position, orientation and 20 DOF articulation of a human hand from markerless visual observations obtained by an RGB-D sensor. Hand pose estimation is formulated as an optimization problem, seeking for the hand model parameters that minimize an objective function that quantifies the discrepancy between the appearance of hand hypotheses and the actual hand observation. The design of such a function is a complicated process that requires a lot of prior experience with the problem. In this paper we automate the definition of the objective function in such optimization problems. First, a set of relevant, candidate image features is computed. Then, given synthetic data sets with ground truth information \u2026",
            "Abstract entirety": 0,
            "Author pub id": "9OieklkAAAAJ:uJ-U7cs_P_0C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Nonholonomic mobile robots equipped with panoramic cameras: Corridor following",
            "Publication year": 2000,
            "Publication url": "https://www.ics.forth.gr/~argyros/mypapers/2000_06_tr272_forth_corridor_following_panoramic.pdf",
            "Abstract": "The present work considers corridor {following maneuvers for mobile robots with nonholonomic constraints, guided by sensory data acquired by panoramic cameras. The panoramic vision system provides information from an environment with textured walls to the motion control system, which drives the robot along a corridor. Panoramic cameras have a 360 visual field, a capability that the proposed control methods attempt to exploit. We consider two types of sensor {based controllers: one is a path {following state feedback control law where the state of the robot inside the corridor is reconstructed from the visual data in the other, optical flow information from several distinct\\looking\" directions in the field of view of the panoramic camera is used directly in the control loop, without the need for state reconstruction. The interest of the second type of controllers lies in the fact that this optical flow information is not sufficient to reconstruct the state of the system, it is however sufficient for the proposed control law to accomplish the desired task. Driving the robot along a corridor amounts to the asymptotic stabilization of a subsystem of the robot's kinematics and the proposed control schemes are shown to achieve this goal.",
            "Abstract entirety": 1,
            "Author pub id": "9OieklkAAAAJ:GnPB-g6toBAC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Joint 3D tracking of a deformable object in interaction with a hand",
            "Publication year": 2018,
            "Publication url": "http://openaccess.thecvf.com/content_ECCV_2018/html/Aggeliki_Tsoli_Joint_3D_tracking_ECCV_2018_paper.html",
            "Abstract": "We present a novel method that is able to track a complex deformable object in interaction with a hand. This is achieved by formulating and solving an optimization problem that jointly considers the hand, the deformable object and the hand/object contact points. The optimization evaluates several hand/object contact configuration hypotheses and adopts the one that results in the best fit of the object's model to the available RGBD observations in the vicinity of the hand. Thus, the hand is not treated as a distractor that occludes parts of the deformable object, but as a source of valuable information. Experimental results on a dataset that has been developed specifically for this new problem illustrate the superior performance of the proposed approach against relevant, state of the art solutions.",
            "Abstract entirety": 1,
            "Author pub id": "9OieklkAAAAJ:F9fV5C73w3QC",
            "Publisher": "Unknown"
        },
        {
            "Title": "3d hand tracking in the presence of excessive motion blur",
            "Publication year": 2020,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/8998145/",
            "Abstract": "We present a sensor-fusion method that exploits a depth camera and a gyroscope to track the articulation of a hand in the presence of excessive motion blur. In case of slow and smooth hand motions, the existing methods estimate the hand pose fairly accurately and robustly, despite challenges due to the high dimensionality of the problem, self-occlusions, uniform appearance of hand parts, etc. However, the accuracy of hand pose estimation drops considerably for fast-moving hands because the depth image is severely distorted due to motion blur. Moreover, when hands move fast, the actual hand pose is far from the one estimated in the previous frame, therefore the assumption of temporal continuity on which tracking methods rely, is not valid. In this paper, we track fast-moving hands with the combination of a gyroscope and a depth camera. As a first step, we calibrate a depth camera and a gyroscope attached to \u2026",
            "Abstract entirety": 0,
            "Author pub id": "9OieklkAAAAJ:WC9gN4BGCRcC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Real-time tracking of multiple skin-colored objects with a possibly moving camera",
            "Publication year": 2004,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-540-24672-5_29",
            "Abstract": "This paper presents a method for tracking multiple skin-colored objects in images acquired by a possibly moving camera. The proposed method encompasses a collection of techniques that enable the modeling and detection of skin-colored objects as well as their temporal association in image sequences. Skin-colored objects are detected with a Bayesian classifier which is bootstrapped with a small set of training data. Then, an off-line iterative training procedure is employed to refine the classifier using additional training images. On-line adaptation of skin-color probabilities is used to enable the classifier to cope with illumination changes. Tracking over time is realized through a novel technique which can handle multiple skin-colored objects. Such objects may move in complex trajectories and occlude each other in the field of view of a possibly moving camera. Moreover, the number of tracked objects may \u2026",
            "Abstract entirety": 0,
            "Author pub id": "9OieklkAAAAJ:d1gkVwhDpl0C",
            "Publisher": "Springer Berlin Heidelberg"
        },
        {
            "Title": "Language for Learning Complex Human-Object Interactions",
            "Publication year": 2013,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/6631291/",
            "Abstract": "In this paper we use a Hierarchical Hidden Markov Model (HHMM) to represent and learn complex activities/task performed by humans/robots in everyday life. Action primitives are used as a grammar to represent complex human behaviour and learn the interactions and behaviour of human/robots with different objects. The main contribution is the use of a probabilistic model capable of representing behaviours at multiple levels of abstraction to support the proposed hypothesis. The hierarchical nature of the model allows decomposition of the complex task into simple action primitives. The framework is evaluated with data collected for tasks of everyday importance performed by a human user.",
            "Abstract entirety": 1,
            "Author pub id": "9OieklkAAAAJ:AXPGKjj_ei8C",
            "Publisher": "IEEE"
        },
        {
            "Title": "Distributed Real-Time Generative 3D Hand Tracking using Edge GPGPU Acceleration",
            "Publication year": 2018,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/3210240.3211112",
            "Abstract": "This work demonstrates a real-time 3D hand tracking application that runs via computation offloading. The proposed framework enables the application to run on low-end mobile devices such as laptops and tablets, despite the fact that they lack the sufficient hardware to perform the required computations locally. The network connection takes the place of a GPGPU accelerator and sharing resources with a larger workstation becomes the acceleration mechanism. The unique properties of a generative optimizer are examined and constitute a challenging use-case, since the requirement for real-time performance makes it very latency-sensitive.",
            "Abstract entirety": 1,
            "Author pub id": "9OieklkAAAAJ:KbBQZpvPDL4C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Intelligent and Cognitive Systems-Introduction to the Special Theme.",
            "Publication year": 2011,
            "Publication url": "https://scholar.google.com/scholar?cluster=4359432094058020026&hl=en&oi=scholarr",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "9OieklkAAAAJ:0KyAp5RtaNEC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Detecting Planes In An Uncalibrated Image Pair.",
            "Publication year": 2002,
            "Publication url": "https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.673.161&rep=rep1&type=pdf",
            "Abstract": "Plane detection is a prerequisite to a wide variety of vision tasks. This paper proposes a novel method that exploits results from projective geometry to automatically detect planes using two images. Using a set of point and line features that have been matched between images, the method exploits the fact that every pair of a 3D line and a 3D point defines a plane and utilizes an iterative voting scheme for identifying coplanar subsets of the employed feature set. The method does not require camera calibration, circumvents the 3D reconstruction problem, is robust to the existence of mismatched features and is applicable either to stereo or motion sequence images. Sample results from the application of the proposed method to real imagery are also provided.",
            "Abstract entirety": 1,
            "Author pub id": "9OieklkAAAAJ:Y0pCki6q_DkC",
            "Publisher": "BMVA Press"
        },
        {
            "Title": "Robot homing by exploiting panoramic vision",
            "Publication year": 2005,
            "Publication url": "https://link.springer.com/article/10.1007/s10514-005-0603-7",
            "Abstract": "We propose a novel, vision-based method for robot homing, the problem of computing a route so that a robot can return to its initial \u201chome\u201d position after the execution of an arbitrary \u201cprior\u201d path. The method assumes that the robot tracks visual features in panoramic views of the environment that it acquires as it moves. By exploiting only angular information regarding the tracked features, a local control strategy moves the robot between two positions, provided that there are at least three features that can be matched in the panoramas acquired at these positions. The strategy is successful when certain geometric constraints on the configuration of the two positions relative to the features are fulfilled. In order to achieve long-range homing, the features\u2019 trajectories are organized in a visual memory during the execution of the \u201cprior\u201d path. When homing is initiated, the robot selects Milestone Positions (MPs) on the \u2026",
            "Abstract entirety": 0,
            "Author pub id": "9OieklkAAAAJ:9yKSN-GCB0IC",
            "Publisher": "Kluwer Academic Publishers"
        },
        {
            "Title": "Binocular hand tracking and reconstruction based on 2D shape matching",
            "Publication year": 2006,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/1698869/",
            "Abstract": "This paper presents a method for real-time 3D hand tracking in images acquired by a calibrated, possibly moving stereoscopic rig. The proposed method consists of a collection of techniques that enable the modeling and detection of hands, their temporal association in image sequences, the establishment of hand correspondences between stereo images and the 3D reconstruction of their contours. Building upon our previous research on color-based, 2D skin-color tracking, the 3D hand tracker is developed through the coupling of the results of two 2D skin-color trackers that run independently on the two video streams acquired by a stereoscopic system. The proposed method runs in real time on a conventional Pentium 4 processor when operating on 320times240 images. Representative experimental results are also presented",
            "Abstract entirety": 1,
            "Author pub id": "9OieklkAAAAJ:qxL8FJ1GzNcC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Experiences from the Use of a Robotic Avatar in a Museum Setting",
            "Publication year": 2001,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/584993.585017",
            "Abstract": "Access to cultural exhibits is a central issue in museums and exhibition galleries that is recently approached under a new, technological perspective. Although the cultural industries' practices in the cases of museums and cultural exhibits have remained practically unchanged for long, in recent years we are witnessing a gradual adoption of media-technologies in various aspects, such as collections archiving and digital document preservation, media-and Web-presentation, graphical animations, etc. Lately, Internet and Web-based technologies have been employed for providing access, mostly to images of exhibited objects. In few cases, the incorporation of higher-end technology, such as virtual reality, artificial intelligence, or robotics, is explored. In this paper we present such an effort, the TOURBOT project (an acronym for TOUr-guide RoBOT), which emphasizes the development of alternative ways for interactive \u2026",
            "Abstract entirety": 0,
            "Author pub id": "9OieklkAAAAJ:Zph67rFs4hoC",
            "Publisher": "Unknown"
        },
        {
            "Title": "An Experimental Evaluation of the Accuracy of Keypoints-based Retinal Image Registration",
            "Publication year": 2017,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/8036841/",
            "Abstract": "This work regards an investigation of the accuracy of a state-of-the-art, keypoint-based retinal image registration approach, as to the type of keypoint features used to guide the registration process. The employed registration approach is a local method that incorporates the notion of a 3D retinal surface imaged from different viewpoints and has been shown, experimentally, to be more accurate than competing approaches. The correspondences obtained between SIFT, SURF, Harris-PIIFD and vessel bifurcations are studied, either individually or in combinations. The combination of SIFT features with vessel bifurcations was found to perform better than other combinations or any individual feature type, alone. The registration approach is also comparatively evaluated against representative methods of the state-of-the-art in retinal image registration, using a benchmark dataset that covers a broad range of cases \u2026",
            "Abstract entirety": 0,
            "Author pub id": "9OieklkAAAAJ:0izLItjtcgwC",
            "Publisher": "Unknown"
        },
        {
            "Title": "FORTH-ICS/TR-268 February 2000",
            "Publication year": 2000,
            "Publication url": "https://www.ics.forth.gr/cvrl/sites/default/files/cvrlfiles/argyros_tr268.pdf",
            "Abstract": "A fundamental problem in computer vision, appearing in different forms in tasks such as discrete motion estimation 9], feature-based stereo 5], object recognition 24], image registration 3], camera self-calibration 16, 13], image-based rendering 10], etc, is that of determining the correspondence among sets of image features extracted from different views of the same scene. The correspondence problem has proved to be very difficult to solve automatically and a general solution is still lacking. The difficulty mainly stems from the fact that common physical phenomena such as changes in illumination, occlusion, perspective distortion, transparency, etc, might have a tremendous impact on the appearance of a scene in different views, thus complicating their matching. Most approaches for dealing with the correspondence problem rely upon the assumption that the photometric and geometric properties of matching features are similar among images. Thus, feature matching is based on the affinity of pixel intensities and the similarity of geometric descriptions such as image location for points and length or orientation for lines. Such properties, however, are not preserved under general perspective projection, which implies that the correspondence methods that exploit them (eg 26, 19, 12]), are applicable only to images that have been acquired from adjacent viewpoints, for which disparities are small.Images whose viewpoints differ considerably have desirable properties for certain types of applications. In such cases, for example, structure from motion estimation becomes more accurate, the flexibility in image acquisition is increased and fewer views are \u2026",
            "Abstract entirety": 0,
            "Author pub id": "9OieklkAAAAJ:5MTHONV0fEkC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Recovering 3D models of manipulated objects through 3D tracking of hand-object interaction",
            "Publication year": 2015,
            "Publication url": "https://www.researchgate.net/profile/Antonis-Argyros/publication/296970174_Recovering_3D_models_of_manipulated_objects_through_3D_tracking_of_hand-object_interaction/links/5810dcc908aef2ef97b2cf40/Recovering-3D-models-of-manipulated-objects-through-3D-tracking-of-hand-object-interaction.pdf",
            "Abstract": "We are interested in the vision-based 3D tracking of scenes where a human manipulates objects. Existing methods that track hand-object manipulations [3] require accurate 3D models of the manipulated objects. This is a limiting assumption because the acquisition of such 3D models can be a time-consuming process that often involves specialized equipment and accurate calibration. In this work we propose a method that solves the problem when the model of the manipulated object is unknown. A human observing the motions of two hands manipulating an unknown object acquires rich information about the object itself. Previous techniques on in-hand scanning and recostruction [11, 13] where discarding or ignoring this information. Our work, draws inspiration from [5] and uses the hands as tools that facilitate the reconstruction. It leverages on the observed hand configurations and the induced hand-object occlusions. This enables simultaneous tracking and reconstruction of a previously unseen object. The output is the full (26D) articulation and 3D position of the hands and object in each frame as well as a textured 3D model of the manipulated object. An overview of the proposed method is illustrated in Fig. 1. Starting with the raw depth map (left) we perform a pre-processing step and compute the scene point cloud. We employ an appropriately modified model-based hand tracker [7] and temporal information to track the hand 3D positions and posture (middle bottom). In this process, a progressively built object model is also taken into account to cope with hand-object occlusions. We use the estimated fingertip positions of the hand to segment \u2026",
            "Abstract entirety": 0,
            "Author pub id": "9OieklkAAAAJ:g3aElNc5_aQC",
            "Publisher": "Unknown"
        },
        {
            "Title": "A graph-based approach for detecting common actions in motion capture data and videos",
            "Publication year": 2018,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S0031320318300499",
            "Abstract": "We present a novel solution to the problem of detecting common actions in time series of motion capture data and videos. Given two action sequences, our method discovers all pairs of common subsequences, i.e. subsequences that represent the same or similar action. This is achieved in a completely unsupervised manner, i.e., without any prior knowledge of the type of actions, their number and their duration. These common subsequences (commonalities) may be located anywhere in the original sequences, may differ in duration and may be performed under different conditions e.g., by a different actor. The proposed method performs a very efficient graph-based search on the matrix of pairwise distances of frames of the two sequences. This search is supported by an objective function that captures the trade off between the similarity of the common subsequences and their lengths. The proposed method has \u2026",
            "Abstract entirety": 0,
            "Author pub id": "9OieklkAAAAJ:HIFyuExEbWQC",
            "Publisher": "Pergamon"
        },
        {
            "Title": "A novel hyper-spectral imaging system: application on in-vivo detection and grading of cervical precancers and of pigmented skin lesions",
            "Publication year": 2001,
            "Publication url": "https://www.ics.forth.gr/cvrl/publications/conferences/2001_12_cvbvs01_balas_hyperspectral.pdf",
            "Abstract": "We present a novel Hyper-Spectral Imaging (HySI) System capable of acquiring and real time displaying of 5nm specrtal images, with 2nm tuning step, in the range of 400nm-1000nm. Synchronized spectral scanning and image storing enables the collection of a stack of calibrated spectral images, from which a fully resolved spectrum per image pixel can be calculated and displayed. We also present results from a pilot use of the developed HySI system as a research tool, in an attempt to develop novel, non-invasive diagnostic methods for the detection and grading of cervical precancers and of pigmented skin lesions. In the case of cervical diagnosis we have succeeded to detect in vivo, quantitatively assess and map alterations in tissue structure and functionality, associated with progress of the disease, with high sensitivity and specificity. In the case of pigmented skin areas, near infrared spectral analysis and imaging of melanin-rich spots show that they become transparent at certain imaging wavelengths and that the transparency wavelength increases with the melanin content and the lesion\u2019s depth. This information can be used for the in vivo quantitative assessment of the later, which is considered to be of great diagnostic and predictive value.",
            "Abstract entirety": 1,
            "Author pub id": "9OieklkAAAAJ:IWHjjKOFINEC",
            "Publisher": "IEEE"
        },
        {
            "Title": "TOURBOT and WebFAIR: Web-operated mobile robots for tele-presence in populated exhibitions",
            "Publication year": 2005,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/1458329/",
            "Abstract": "This paper presents a number of techniques that are needed for realizing Web-operated mobile robots. These techniques include effective map-building capabilities, a method for obstacle avoidance based on a combination of range and visual information, and advanced Web and onboard robot interfaces. In addition to video streams, the system provides high-resolution virtual reality visualizations that also include the people in the vicinity of the robot. This increases the flexibility of the interface and simultaneously allows a user to understand the navigation actions of the robot. The techniques described in this article have been successfully deployed within the EU-funded projects TOURBOT and WebFAIR, which aimed to develop interactive tour-guided robots able to serve Web as well as on-site visitors. Technical developments in the framework of these projects have resulted in robust and reliable systems that \u2026",
            "Abstract entirety": 0,
            "Author pub id": "9OieklkAAAAJ:hqOjcs7Dif8C",
            "Publisher": "IEEE"
        },
        {
            "Title": "Multiple objects tracking in the presence of long-term occlusions",
            "Publication year": 2010,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S1077314210000615",
            "Abstract": "We present a robust object tracking algorithm that handles spatially extended and temporally long object occlusions. The proposed approach is based on the concept of \u201cobject permanence\u201d which suggests that a totally occluded object will re-emerge near its occluder. The proposed method does not require prior training to account for differences in the shape, size, color or motion of the objects to be tracked. Instead, the method automatically and dynamically builds appropriate object representations that enable robust and effective tracking and occlusion reasoning. The proposed approach has been evaluated on several image sequences showing either complex object manipulation tasks or human activity in the context of surveillance applications. Experimental results demonstrate that the developed tracker is capable of handling several challenging situations, where the labels of objects are correctly identified and \u2026",
            "Abstract entirety": 0,
            "Author pub id": "9OieklkAAAAJ:-f6ydRqryjwC",
            "Publisher": "Academic Press"
        },
        {
            "Title": "Generative 3D Hand Tracking with Spatially Constrained Pose Sampling",
            "Publication year": 2017,
            "Publication url": "https://scholar.google.com/scholar?cluster=16700571397229502424&hl=en&oi=scholarr",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "9OieklkAAAAJ:OcBU2YAGkTUC",
            "Publisher": "Unknown"
        }
    ]
}]