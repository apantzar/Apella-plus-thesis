[{
    "name": "\u0395\u03c5\u03ac\u03b3\u03b3\u03b5\u03bb\u03bf\u03c2 \u039c\u03b1\u03c1\u03ba\u03ac\u03c4\u03bf\u03c2",
    "romanize name": "Evangelos Markatos",
    "School-Department": "\u0395\u03c0\u03b9\u03c3\u03c4\u03ae\u03bc\u03b7\u03c2 \u03a5\u03c0\u03bf\u03bb\u03bf\u03b3\u03b9\u03c3\u03c4\u03ce\u03bd",
    "University": "uoc",
    "Rank": "\u039a\u03b1\u03b8\u03b7\u03b3\u03b7\u03c4\u03ae\u03c2",
    "Apella_id": 4137,
    "Scholar name": "Evangelos Markatos",
    "Scholar id": "Wk7e-kIAAAAJ",
    "Affiliation": "University of Crete and Foundation for Research and Technology - Hellas",
    "Citedby": 8520,
    "Interests": [
        "Computer Systems",
        "Networking",
        "Security"
    ],
    "Scholar url": "https://scholar.google.com/citations?user=Wk7e-kIAAAAJ&hl=en",
    "Publications": [
        {
            "Title": "THROUGH INSTRUCTION SEQUENCE",
            "Publication year": 2010,
            "Publication url": "https://books.google.com/books?hl=en&lr=&id=_7zgBwAAQBAJ&oi=fnd&pg=PA375&dq=info:n4SD0IYuu6kJ:scholar.google.com&ots=EE1NfmqpYb&sig=z5jZ--CxM4hEhtzzQj2c8CWvVrY",
            "Abstract": "Buffer overflow attacks, popularized in 1996 by Aleph One', have been a major security concern ever since, because exploiting a buffer overflow vulnerability allows an attacker located anywhere on the Internet to execute arbitrary code on the compromised system. The highly interconnected",
            "Abstract entirety": 1,
            "Author pub id": "Wk7e-kIAAAAJ:OTTXONDVkokC",
            "Publisher": "Springer"
        },
        {
            "Title": "User tracking in the post-cookie era: How websites bypass gdpr consent to track users",
            "Publication year": 2021,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/3442381.3450056",
            "Abstract": "During the past few years, mostly as a result of the GDPR and the CCPA, websites have started to present users with cookie consent banners. These banners are web forms where the users can state their preference and declare which cookies they would like to accept, if such option exists. Although requesting consent before storing any identifiable information is a good start towards respecting the user privacy, yet previous research has shown that websites do not always respect user choices. Furthermore, considering the ever decreasing reliance of trackers on cookies and actions browser vendors take by blocking or restricting third-party cookies, we anticipate a world where stateless tracking emerges, either because trackers or websites do not use cookies, or because users simply refuse to accept any.",
            "Abstract entirety": 1,
            "Author pub id": "Wk7e-kIAAAAJ:Ehil0879vHcC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Benchmarking and design of string matching intrusion detection systems",
            "Publication year": 2002,
            "Publication url": "ftp://pages.ics.forth.gr/tech-reports/2002/2002.TR_315_Benchmarking_IDS.pdf",
            "Abstract": "A central question in the design and evaluation of a Network Intrusion Detection System (NIDS) is whether it is possible to define a practical, accurate and meaningful performance evaluation methodology. In this direction, we examine how NIDS performance interacts with experiment parameters such as traffic characteristics, NIDS rulesets, string matching algorithms and processor architecture. Our results indicate that NIDS performance is sensitive to the both packet and ruleset content, yet this sensitivity seems to be bounded, allowing us to craft and experiment with synthetic traces and rulesets. Our experiments also show that experiments on a single trace and processor architecture are likely to be misleading; effective NIDS evaluation therefore requires careful consideration of a fairly extensive set of scenarios.",
            "Abstract entirety": 1,
            "Author pub id": "Wk7e-kIAAAAJ:RYcK_YlVTxYC",
            "Publisher": "Unknown"
        },
        {
            "Title": "The Red Book-The SysSec Roadmap for Systems Security Research",
            "Publication year": 2013,
            "Publication url": "https://www.narcis.nl/publication/RecordID/oai:research.vu.nl:publications%2F9c7ee2a5-1429-46a1-a5ae-a38c78b0ec1d",
            "Abstract": "The Red Book - The SysSec Roadmap for Systems Security Research (2013) | www.narcis.nl KNAW \nKNAW Narcis Back to search results VU University Amsterdam Publication The Red Book - The \nSysSec Roadmap for Systems Security Research (2013) Pagina-navigatie: Main Save publication \nSave as MODS Export to Mendeley Save as EndNote Export to RefWorks Title The Red Book - The \nSysSec Roadmap for Systems Security Research Author Bos, HJ; Markatos, E.; Balzarotti, D.; \nAthanasopoulos, E.; Cavallaro, L.; Maggi, F.; Polychronakis, M.; Slowinska, JM; Polakis, I.; Almgren, \nM.; Ioannidis, S.; Platzer, C.; Tsigas, P.; Zanero, S. Publisher Computer Systems; Network Institute; \nSystems and Network Security Date issued 2013 Access Restricted Access Language English Type \nBook Publisher EU Publication https://research.vu.nl/en/publications/9c7ee2a5-1429-46a1-a5... \nPersistent Identifiers NBN urn:nbn:nl:ui:31/\u2026",
            "Abstract entirety": 0,
            "Author pub id": "Wk7e-kIAAAAJ:anf4URPfarAC",
            "Publisher": "EU"
        },
        {
            "Title": "Passive end-to-end packet loss estimation for grid traffic monitoring",
            "Publication year": 2006,
            "Publication url": "https://kapravelos.com/publications/lossestimation-coregrid06.pdf",
            "Abstract": "Accurate network monitoring is vital for the operation of Grids. The packet loss ratio is among the most important metrics for identifying poor network conditions, since it highly affects data throughput performance and the overall end-to-end data transfer quality. In this paper, we present a scalable and non-intrusive technique based on passive network monitoring for estimating the packet loss ratio between different measurement points. The proposed approach is complementary to current active monitoring techniques and can be easily incorporated into the network monitoring components of Grid systems. We describe the design and implementation of the technique, outline its integration within a Grid environment, and present experimental evaluation results, including measurements with real Grid application traffic.",
            "Abstract entirety": 1,
            "Author pub id": "Wk7e-kIAAAAJ:maZDTaKrznsC",
            "Publisher": "Unknown"
        },
        {
            "Title": "No more chasing waterfalls: a measurement study of the header bidding ad-ecosystem",
            "Publication year": 2019,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/3355369.3355582",
            "Abstract": "In recent years, Header Bidding (HB) has gained popularity among web publishers, challenging the status quo in the ad ecosystem. Contrary to the traditional waterfall standard, HB aims to give back to publishers control of their ad inventory, increase transparency, fairness and competition among advertisers, resulting in higher ad-slot prices. Although promising, little is known about how this ad protocol works: What are HB's possible implementations, who are the major players, and what is its network and UX overhead?",
            "Abstract entirety": 1,
            "Author pub id": "Wk7e-kIAAAAJ:OcBU2YAGkTUC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Stream-oriented network traffic capture and analysis for high-speed networks",
            "Publication year": 2014,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/6901242/",
            "Abstract": "Intrusion detection, traffic classification, and other network monitoring applications need to analyze the captured traffic beyond the network layer to allow for connection-oriented analysis, and achieve resilience to evasion attempts based on TCP segmentation. Existing network traffic capture frameworks, however, provide applications with raw packets and leave complex operations like flow tracking and TCP stream reassembly to application developers. This gap, between what applications need and what systems provide, leads to increased application complexity, longer development time, and most importantly, reduced performance due to excessive data copies between the packet capture subsystem and the stream processing module. This paper presents the Stream capture library (Scap), a network monitoring framework built from the ground up for stream-oriented traffic processing. Based on a kernel module \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Wk7e-kIAAAAJ:M7yex6snE4oC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Realistic passive packet loss measurement for high-speed networks",
            "Publication year": 2009,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-642-01645-5_1",
            "Abstract": "Realistic and accurate packet loss measurement of production traffic has been challenging, since the frequently-used active monitoring approaches using probe packets cannot capture the packet loss experienced by the traffic of individual user applications. In this paper, we present a new approach for the accurate measurement of the packet loss rate faced by actual production traffic based on passive network monitoring. In contrast to previous work, our method is able to pinpoint the packet loss rate experienced by the individual traffic flows of concurrently running applications. Experimental results suggest that our approach measures packet loss with 100% accuracy for network speeds as high as 12 Gbit/s, while traditional ICMP-based approaches were usually much less accurate. We also report experiences from a real-world deployment of our method in several 10 Gbit/s links of European research \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Wk7e-kIAAAAJ:nb7KW1ujOQ8C",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "Code generation for packet header intrusion analysis on the ixp1200 network processor",
            "Publication year": 2003,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-540-39920-9_16",
            "Abstract": "We present a software architecture that enables the use of the IXP1200 network processor in packet header analysis for network intrusion detection. The proposed work consists of a simple and efficient run-time infrastructure for managing network processor resources, along with the S2I compiler, a tool that generates efficient C code from high-level, human readable, intrusion signatures. This approach facilitates the employment of the IXP1200 in network intrusion detection systems while our experimental results demonstrate that provides performance comparable to hand-crafted code.",
            "Abstract entirety": 1,
            "Author pub id": "Wk7e-kIAAAAJ:4JMBOYKVnBMC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "xJS: practical XSS prevention for web application development",
            "Publication year": 2010,
            "Publication url": "https://www.usenix.org/event/webapps10/tech/full_papers/webapps10_proceedings.pdf#page=86",
            "Abstract": "We present xJS, a practical framework for preventing code-injections in the web environment and thus assisting for the development of XSS-free web applications. xJS aims on being fast, developer-friendly and providing backwards compatibility. We implement and evaluate our solution in three leading web browsers and in the Apache web server. We show that our framework can successfully prevent all 1,380 real-world attacks that were collected from a wellknown XSS attack repository. Furthermore, our framework imposes negligible computational overhead in both the server and the client side, and has no negative sideeffects in the overall user\u2019s browsing experience.",
            "Abstract entirety": 1,
            "Author pub id": "Wk7e-kIAAAAJ:NMxIlDl6LWMC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Next Generation Attacks on the Internet",
            "Publication year": 2006,
            "Publication url": "https://academiccommons.columbia.edu/doi/10.7916/D8BK1NR3",
            "Abstract": "Over the past few years we have seen the use of Internet worms, ie, malicious selfreplicating programs, as a mechanism to rapidly invade and compromise large numbers of remote computers. Although the first worms released on the Internet were large-scale easyto-spot massive security incidents [MSB02, MPS+03, SM04, BCJ+05b], also known as flash worms [SMPW04], it is currently envisioned that future worms will be increasingly difficult to detect, and will be known as stealth worms [SPW02]. This is partly because the motives of the first worm developers were centered around the self gratification brought by the achievement of compromising large numbers of remote computers, the motives of recent worm and malware developers are centered around financial and political gains. Therefore, although recent attackers still want to be able to control a large number of compromised computers, they prefer to compromise these computers as quietly as possible, over a longer period of time, so as not to be detected by any security defenses. Thus, to achieve a stealthy behavior, these attackers have started using, or at least have the capacity to use a wide variety of mechanisms that will make their worms more difficult to detect. Such mechanisms might include:",
            "Abstract entirety": 1,
            "Author pub id": "Wk7e-kIAAAAJ:l7t_Zn2s7bgC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Flexible and high-performance anonymization of NetFlow records using anontool",
            "Publication year": 2007,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/4550304/",
            "Abstract": "Netflow is a protocol widely adopted by the security and performance measurements community. Nowadays, many distributed applications and architectures base their functionality on Netflow data collected at diverse environments. However, communities and administrators are reluctant to share exported Netflow data for privacy reasons. As a consequence, the effectiveness of distributed approaches is limited due to lack of input data. To overcome this limitation, anonymization on Netflow data is proposed for sharing. However, the available tools are either proprietary or of very limited functionality. Towards this direction, we propose and implement anontool, that allow administrators to anonymize Netflow data in a highly customizable way. A comparison of anontool with existing solutions is provided along two dimensions: functionality and performance. Anontool can anonymize traffic even at high bandwidth rates \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Wk7e-kIAAAAJ:YFjsv_pBGBYC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Designing malicious applications in social networks",
            "Publication year": 2010,
            "Publication url": "https://www.academia.edu/download/45155637/Designing_malicious_applications_in_soci20160427-20771-19s69oi.pdf",
            "Abstract": "The World Wide Web has evolved from a collection of static HTML pages to an assortment of Web 2.0 applications. Online social networking in particular is becoming more popular by the day since the establishment of SixDegrees in 1997. Millions of people use social networking web sites daily, such as Facebook, MySpace, Orkut and LinkedIn. A sideeffect of this growth, is that possible exploits can turn OSNs into platforms for malicious and illegal activities, like DDoS attacks, privacy violations, disk compromise and malware propagation.In this paper we show that social networking web sites have the ideal properties to become attack platforms. We introduce a new term, Antisocial Networks that refers to distributed systems based on social networking web sites which can be exploited carry out network attacks. An adversary can take control of the visitor\u2019s session by remotely manipulating their browsers through legitimate web control functionality such as image-loading HTML tags, JavaScript instructions and Java applets.",
            "Abstract entirety": 1,
            "Author pub id": "Wk7e-kIAAAAJ:dshw04ExmUIC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Issues about the integration of passive and active monitoring for grid networks",
            "Publication year": 2005,
            "Publication url": "http://eprints.adm.unipi.it/2151/1/TR-05-22.pdf.gz#page=287",
            "Abstract": "We discuss the integration of passive and active techniques in a Grid monitoring system. We show the advantages obtained by using the same domain-oriented overlay network to organize both kinds of monitoring.",
            "Abstract entirety": 1,
            "Author pub id": "Wk7e-kIAAAAJ:M3NEmzRMIkIC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Do partner apps offer the same level of privacy protection? The case of wearable applications",
            "Publication year": 2021,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/9431018/",
            "Abstract": "We analyze partner health apps compatible with the Fitbit fitness tracker, and record what third parties they are talking to. We focus on the ten partner Android applications that have more than 50,000 downloads and are fitness-related. Our results show that most of the them contact \u201cunexpected\u201d third parties. Such third parties include social networks; analytics and advertisement services; weather APIs. We also investigate what information is shared by the partner apps with these unexpected entities. Our findings suggest that in many cases personal information of users might be shared, including the phone model; location and SIM carrier; email and connection history.",
            "Abstract entirety": 1,
            "Author pub id": "Wk7e-kIAAAAJ:Aul-kAQHnToC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Digital is calling the analog: Robust prevention of dial attacks",
            "Publication year": 2009,
            "Publication url": "https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.724.9787&rep=rep1&type=pdf",
            "Abstract": "We carry out attacks using Internet platforms that aim on keeping telephone devices busy, denying users any access. We refer to this behavior using the term DIAL (Digital Initiated Abuse of teLephones), or, in the simple form, Dial attack. We develop an intuitive simulation environment for modeling a Dial attack in order to identify its critical characteristics. Based on the simulation\u2019s results we perform the attack in the real world. By using a VoIP provider as the attack media, we manage to hold an existing landline device busy for 85% of the attack\u2019s duration and thus render the device practically unusable. The attack has zero cost and requires negligible computational resources. Furthermore, as we show, anyone can practically launch a Dial attack towards any telephone device. However, in this paper, our primary goal is to protect telephones from Dial attacks. First, we investigate existing countermeasures in VoIP providers and show that they follow an all-or-nothing approach, but most importantly, their anomaly detection systems react slowly against our attacks. We managed to issue tens of thousands of calls before getting spotted. Second, using existing software technologies, Snort and Click, we present a flexible anomaly detection system, which promotes fairness to the callers. With our system in place it is hard for an adversary to keep the device busy for more than 5% of the attack\u2019s duration.",
            "Abstract entirety": 1,
            "Author pub id": "Wk7e-kIAAAAJ:hkOj_22Ku90C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Forward White Book: Emerging ICT Threats",
            "Publication year": 2010,
            "Publication url": "https://scholar.google.com/scholar?cluster=14312198994684499921&hl=en&oi=scholarr",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "Wk7e-kIAAAAJ:dTyEYWd-f8wC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Master of web puppets: Abusing web browsers for persistent and stealthy computation",
            "Publication year": 2018,
            "Publication url": "https://arxiv.org/abs/1810.00464",
            "Abstract": "The proliferation of web applications has essentially transformed modern browsers into small but powerful operating systems. Upon visiting a website, user devices run implicitly trusted script code, the execution of which is confined within the browser to prevent any interference with the user's system. Recent JavaScript APIs, however, provide advanced capabilities that not only enable feature-rich web applications, but also allow attackers to perform malicious operations despite the confined nature of JavaScript code execution. In this paper, we demonstrate the powerful capabilities that modern browser APIs provide to attackers by presenting MarioNet: a framework that allows a remote malicious entity to control a visitor's browser and abuse its resources for unwanted computation or harmful operations, such as cryptocurrency mining, password-cracking, and DDoS. MarioNet relies solely on already available HTML5 APIs, without requiring the installation of any additional software. In contrast to previous browser-based botnets, the persistence and stealthiness characteristics of MarioNet allow the malicious computations to continue in the background of the browser even after the user closes the window or tab of the initial malicious website. We present the design, implementation, and evaluation of a prototype system, MarioNet, that is compatible with all major browsers, and discuss potential defense strategies to counter the threat of such persistent in-browser attacks. Our main goal is to raise awareness regarding this new class of attacks, and inform the design of future browser APIs so that they provide a more secure client-side environment for \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Wk7e-kIAAAAJ:IUKN3-7HHlwC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Panel on future challenges in modeling methodology",
            "Publication year": 2004,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/1371333/",
            "Abstract": "This panel paper presents the views of six researchers and practitioners of simulation modeling. Collectively we attempt to address a range of key future challenges to modeling methodology. It is hoped that the views of this paper, and the presentations made by the panelists at the 2004 Winter Simulation Conference will raise awareness and stimulate further discussion on the future of modeling methodology in areas such as modeling problems in business applications, human factors and geographically dispersed networks; rapid model development and maintenance; legacy modeling approaches; markup languages; virtual interactive process design and simulation; standards; and Grid computing.",
            "Abstract entirety": 1,
            "Author pub id": "Wk7e-kIAAAAJ:b1wdh0AR-JQC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Provable Network Activity for Protecting Users Against False Accusation",
            "Publication year": 2016,
            "Publication url": "https://link.springer.com/content/pdf/10.1007/978-3-319-45931-8.pdf#page=257",
            "Abstract": "With the proliferation of the World Wide Web, data traces that correspond to users\u2019 network activity can be collected by several Internet actors, including (i) web sites,(ii) smartphone apps, and even (iii) Internet Service Providers. Given that the collection and storage of these data are beyond the control of the end user, these data traces can be easily manipulated, if not, tampered with. The result of such manipulated digital traces can be severe: Innocent users can be shamed or even wrongfully accused of carrying out illegal transactions. To eliminate these potential accusations on innocent users, we introduce Provable Network Activity (PNA): a framework with which the ISPs can give the end users control of their stored traces. The framework guarantees that the information collected for the end users is accurate and will remain accurate for as long as it is stored. Our implementation and preliminary evaluation suggest \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Wk7e-kIAAAAJ:FPJr55Dyh1AC",
            "Publisher": "Springer"
        },
        {
            "Title": "Network\u2013level polymorphic shellcode detection using emulation",
            "Publication year": 2006,
            "Publication url": "https://link.springer.com/chapter/10.1007/11790754_4",
            "Abstract": "As state\u2013of\u2013the\u2013art attack detection technology becomes more prevalent, attackers are likely to evolve, employing techniques such as polymorphism and metamorphism to evade detection. Although recent results have been promising, most existing proposals can be defeated using only minor enhancements to the attack vector. We present a heuristic detection method that scans network traffic streams for the presence of polymorphic shellcode. Our approach relies on a NIDS\u2013embedded CPU emulator that executes every potential instruction sequence, aiming to identify the execution behavior of polymorphic shellcodes. Our analysis demonstrates that the proposed approach is more robust to obfuscation techniques like self-modifications compared to previous proposals, but also highlights advanced evasion techniques that need to be more closely examined towards a satisfactory solution to the \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Wk7e-kIAAAAJ:j8SEvjWlNXcC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "ARC: protecting against HTTP parameter pollution attacks using application request caches",
            "Publication year": 2012,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-642-31284-7_24",
            "Abstract": "HTTP Parameter Pollution (HPP) vulnerabilities allow attackers to exploit web applications by manipulating the query parameters of the requested URLs. In this paper, we present Application Request Cache (ARC), a framework for protecting web applications against HPP exploitation. ARC hosts all benign URL schemas, which act as generators of the complete functional set of URLs that compose the application\u2019s logic. For each incoming request, ARC exports the URL, extracts the associated schema, and searches for it in the set of already known benign schemas. In case the schema is not found, the request is rejected, and the event is recorded.ARC can be transparently integrated with existing web applications without any modifications to the server and client code. It is implemented in Google\u2019s Go language and uses efficient data structures for storing the URL schemas, imposing negligible \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Wk7e-kIAAAAJ:_Re3VWB3Y0AC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "Topnet: A Network-aware top (1).",
            "Publication year": 2008,
            "Publication url": "https://www.usenix.org/legacy/event/lisa08/tech/full_papers/theocharides/theocharides.pdf",
            "Abstract": "System administrators regularly use the top utility for understanding the resource consumption of the processes running on UNIX computers. Top provides an accurate and real-time display of the computing and memory capacity of the system among the running processes, but it provides no information about the network traffic sent and received by the processes running on the system. Although we\u2019ve seen a proliferation of network monitoring tools that help system administrators understand the traffic flowing through their networks, most of these tools have been designed for network deployment and can not easily, if at all, provide real-time attribution of network resources to individual processes running on end hosts. In this paper, we describe the design and implementation of Topnet, an extension of the top UNIX utility that provides a process-centric approach to traffic monitoring. Topnet presents users with an intuitive real-time attribution of network resources to individual processes. Our evaluation suggests that Topnet through (i) the familiar user interface of top and (ii) a reasonable performance overhead, provides an accurate way to attribute network traffic to individual processes, enabling users to have a more comprehensive process-aware understanding of network resource consumption in their systems.",
            "Abstract entirety": 1,
            "Author pub id": "Wk7e-kIAAAAJ:VL0QpB8kHFEC",
            "Publisher": "Unknown"
        },
        {
            "Title": "An empirical study on the security of cross-domain policies in rich internet applications",
            "Publication year": 2011,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/1972551.1972558",
            "Abstract": "Adobe Flash and Microsoft Silverlight are two widely adopted platforms for providing Rich Internet Applications (RIA) over the World Wide Web. The need for RIAs to retrieve content hosted on different domains, in order to enrich user experience, led to the use of cross-domain policies by content providers. Cross-domain policies define the list of RIA hosting domains that are allowed to retrieve content from the content provider's domain. Misinterpretation or misconfigurations of the policies may give the opportunity to malicious RIAs to access and handle users' private data.",
            "Abstract entirety": 1,
            "Author pub id": "Wk7e-kIAAAAJ:dfsIfKJdRG4C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Evaluation of compression of remote network monitoring data streams",
            "Publication year": 2008,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/4509936/",
            "Abstract": "Network monitoring and measurement is an invaluable tool for comprehending, analyzing, managing, and optimizing performance and security of networked systems. Network monitoring architectures can take the form of local or distributed deployments of sensors. Local deployments can be very precise and efficient because they benefit from fast links to the central monitoring station, but their scope can be limited to local or small-scale networks. Distributed monitoring infrastructures give a much broader view of the network state, but have the disadvantage that the amount of information they can push back to the central monitoring station is limited by the capacity of the links. In this paper we investigate the effects of compression on network monitoring data streams that are transmitted from distributed network sensors back to a central infrastructure. Our analysis shows that we can achieve very high compression \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Wk7e-kIAAAAJ:70eg2SAEIzsC",
            "Publisher": "IEEE"
        },
        {
            "Title": "I still See You! Inferring Fitness Data from Encrypted Traffic of Wearables.",
            "Publication year": 2021,
            "Publication url": "https://www.scitepress.org/Papers/2021/102331/102331.pdf",
            "Abstract": "In this paper we describe a cyberattack against 2 well-known wearable devices. The attacker presented in this paper is an \u201chonest but curious\u201d Internet Service Provider (ISP) sitting somewhere in the path between the device and the cloud. The ISP launches the attack when the smartbands try to synchronize their data with the permanent cloud storage. By launching its attack, this \u201chonest but curious\u201d ISP is able to learn much personal information about the users of the smartbands, including the frequency of measuring the users\u2019 heart rate and weight; the number and duration of workouts; as well as whether (i) sleep or (ii) steps were recorded on a given day. We show that privacy leaks might occur even when the transferred data are fully encrypted, and the representative mobile application utilizes state-of-the-art security mechanisms: certificate pinning, and source code obfuscation.",
            "Abstract entirety": 1,
            "Author pub id": "Wk7e-kIAAAAJ:GFxP56DSvIMC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Code Generation for Packet Header Intrusion Analysis on the IXP1200 Network Processor",
            "Publication year": 2003,
            "Publication url": "https://scholar.google.com/scholar?cluster=12865360865425200329&hl=en&oi=scholarr",
            "Abstract": "We present a software architecture that enables the use of the IXP1200 network processor in packet header analysis for network intrusion detection. The proposed work consists of a simple and efficient run-time infrastructure for managing network processor resources, along with the S2I compiler, a tool that generates efficient C code from highlevel, human readable, intrusion signatures. This approach facilitates the employment of the IXP1200 in network intrusion detection systems while our experimental results demonstrate that provides performance comparable to hand-crafted code.",
            "Abstract entirety": 1,
            "Author pub id": "Wk7e-kIAAAAJ:cWzG1nlazyYC",
            "Publisher": "Springer-Verlag New York Inc"
        },
        {
            "Title": "The long-standing privacy debate: Mobile websites vs mobile apps",
            "Publication year": 2017,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/3038912.3052691",
            "Abstract": "The vast majority of online services nowadays, provide both a mobile friendly website and a mobile application to their users. Both of these choices are usually released for free, with their developers, usually gaining revenue by allowing advertisements from ad networks to be embedded into their content. In order to provide more personalized and thus more effective advertisements, ad networks usually deploy pervasive user tracking, raising this way significant privacy concerns. As a consequence, the users do not have to think only their convenience before deciding which choice to use while accessing a service: web or app, but also which one harms their privacy the least.",
            "Abstract entirety": 1,
            "Author pub id": "Wk7e-kIAAAAJ:_FM0Bhl9EiAC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Privacy-preserving social plugins",
            "Publication year": 2012,
            "Publication url": "https://www.usenix.org/conference/usenixsecurity12/technical-sessions/presentation/kontaxis&sa=U&ei=oxP7U4jdHKTmyQPIx4G4BQ&ved=0CB4QtwIwBA&usg=AFQjCNHiRk9WrLV3bFp3XOye-ym_O6LnZg",
            "Abstract": "The widespread adoption of social plugins, such as Facebook\u2019s Like and Google\u2019s+ 1 buttons, has raised concerns about their implications to user privacy, as they enable social networking services to track a growing part of their members\u2019 browsing activity. Existing mitigations in the form of browser extensions can prevent social plugins from tracking user visits, but inevitably disable any kind of content personalization, ruining the user experience.",
            "Abstract entirety": 1,
            "Author pub id": "Wk7e-kIAAAAJ:tzM49s52ZIMC",
            "Publisher": "Unknown"
        },
        {
            "Title": "A feedback-based approach to reduce duplicate messages in unstructured peer-to-peer networks",
            "Publication year": 2007,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-0-387-47658-2_8",
            "Abstract": "Resource location in unstructured P2P systems is mainly performed by having each node forward each incoming query message to all of its neighbors, a process called flooding. Although this algorithm has excellent response time and is very simple to implement, it creates a large volume of unnecessary traffic in today\u2019s Internet because each node may receive the same query several times through different paths. We propose an innovative technique, the feedback-based approach that aims to improve the scalability of flooding. The main idea behind our algorithm is to monitor the ratio of duplicate messages transmitted over each network connection, and not forward query messages over connections whose ratio exceeds some threshold. Through extensive simulation we show that this algorithm exhibits significant reduction of traffic in random and small-world graphs, the two most common types of graph that \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Wk7e-kIAAAAJ:JV2RwH3_ST0C",
            "Publisher": "Springer, Boston, MA"
        },
        {
            "Title": "Tracing a large-scale Peer to Peer System",
            "Publication year": 2002,
            "Publication url": "https://scholar.google.com/scholar?cluster=14479398498393876461&hl=en&oi=scholarr",
            "Abstract": "Peer-to-peer computing and networking, a new model of communication and computation, has recently started to gain significant acceptance. This model not only enables clients to take a more active role in the information dissemination process, but also may significantly increase the performance and reliability of the overall system, by eliminating the traditional notion of the \u201cserver\u201d which could be a single point of failure, and a potential bottleneck.",
            "Abstract entirety": 1,
            "Author pub id": "Wk7e-kIAAAAJ:P5F9QuxV20EC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Mandola: A big-data processing and visualization platform for monitoring and detecting online hate speech",
            "Publication year": 2020,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/3371276",
            "Abstract": "In recent years, the increasing propagation of hate speech in online social networks and the need for effective counter-measures have drawn significant investment from social network companies and researchers. This has resulted in the development of many web platforms and mobile applications for reporting and monitoring online hate speech incidents. In this article, we present MANDOLA, a big-data processing system that monitors, detects, visualizes, and reports the spread and penetration of online hate-related speech using big-data approaches. MANDOLA consists of six individual components that intercommunicate to consume, process, store, and visualize statistical information regarding hate speech spread online. We also present a novel ensemble-based classification algorithm for hate speech detection that can significantly improve the performance of MANDOLA\u2019s ability to detect hate speech. To \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Wk7e-kIAAAAJ:yMeIxYmEMEAC",
            "Publisher": "ACM"
        },
        {
            "Title": "Grid reliability: A study of failures on the egee infrastructure",
            "Publication year": 2006,
            "Publication url": "https://www.ics.forth.gr/_publications/grid_reliability.pdf",
            "Abstract": "The emergence of Grid infrastructures like EGEE has enabled the deployment of large-scale computational experiments that address challenging scientific problems in various fields. However, to realize their full potential, Grid infrastructures need to achieve a higher degree of dependability, ie, they need to improve the ratio of Grid-job requests that complete successfully in the presence of Gridcomponent failures. To achieve this, however, we need to determine, analyze and classify the causes of job failures on Grids. In this paper we study the reasons behind Grid job failures in the context of EGEE, the largest Grid infrastructure currently in operation. We present points of failure in a Grid that affect the execution of jobs, and describe error types and contributing factors. We discuss various information sources that provide users and administrators with indications about failures, and assess their usefulness based on error information accuracy and completeness. Finally, we discuss two case studies, describing failures that occurred on a production site of EGEE and the troubleshooting process for each case.",
            "Abstract entirety": 1,
            "Author pub id": "Wk7e-kIAAAAJ:TFP_iSt0sucC",
            "Publisher": "Unknown"
        },
        {
            "Title": "dead. drop: URL-based Stealthy Messaging",
            "Publication year": 2011,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/6377757/",
            "Abstract": "In this paper we propose the use of URLs as a covert channel to relay information between two or more parties. We render our technique practical, in terms of bandwidth, by employing URL-shortening services to form URL chains of hidden information. We discuss the security aspects of this technique and present proof-of-concept implementation details along with measurements that prove the feasibility of our approach.",
            "Abstract entirety": 1,
            "Author pub id": "Wk7e-kIAAAAJ:SdhP9T11ey4C",
            "Publisher": "IEEE"
        },
        {
            "Title": "When AppMon met Stager",
            "Publication year": 2008,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/4509942/",
            "Abstract": "Monitoring applications provide an important service in network related activities, such as network monitoring, network management and network software engineering. They facilitate the need of understanding exactly what occurs inside our networks and how each network interacts with the rest of the Internet. From private and local networks, to large-scale corporate networks and intranets, there is an ever-growing need to characterize and analyze network traffic. Unfortunately, network monitoring applications have the side effect of generating huge amounts of real-time data, that need to be processed, stored and presented, in an effective fashion. If this is done correctly and efficiently, network administrators, researchers, as well as users, can extract useful information from them, such as, traffic patterns, newly deployed network protocols, etc. In this paper we present our experiences on the combination of two tools \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Wk7e-kIAAAAJ:WbkHhVStYXYC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Piranha: A fast lookup pattern matching algorithm for intrusion detection",
            "Publication year": 2005,
            "Publication url": "https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.59.489&rep=rep1&type=pdf",
            "Abstract": "Network Intrusion Detection Systems (nIDS) are nowadays an increasingly important defensive mechanism against numerous attacks taking place on the Internet. As network speed is increasing faster than processor speed, intrusion detection at link speed becomes increasingly more challenging. The most expensive part of a nIDS is pattern matching: finding patterns of attack inside packet payload. This paper presents Piranha, a fast algorithm for pattern matching oriented to intrusion detection domain. It is based on the observation that if the rarest substring of a pattern does not appear, then the whole pattern will definitely not match. Our results, based on traces that represent various network environments, indicate that Piranha can enhance the performance of a nIDS by 11% to 28% in terms of processing time and by 18% to 73% in terms of memory consumption comparing to existing state-of-the-art algorithms.",
            "Abstract entirety": 1,
            "Author pub id": "Wk7e-kIAAAAJ:1sJd4Hv_s6UC",
            "Publisher": "Unknown"
        },
        {
            "Title": "SENTER: A Network of the European Centres of Excellence in Cyber Crime Research, training, and Education",
            "Publication year": 2016,
            "Publication url": "https://scholar.google.com/scholar?cluster=8784368542597415715&hl=en&oi=scholarr",
            "Abstract": "Having exceeded the size of 75 Billion USD in 2015, the worldwide size of the cybersecurity market is expected to reach 170 USD in 2020 increasing rapidly year after year [1]. This market is fueled mainly by cybercrime [2] which has recently reached a cost of 445 billion USD [3]. If left unchecked, cybercrime will have devastating consequences for the development and deployment of our digital society.",
            "Abstract entirety": 1,
            "Author pub id": "Wk7e-kIAAAAJ:hCrLmN-GePgC",
            "Publisher": "EUROPEAN RESEARCH CONSORTIUM INFORMATICS & MATHEMATICS"
        },
        {
            "Title": "Defending against next generation through network/endpoint collaboration and interaction",
            "Publication year": 2009,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-0-387-85555-4_9",
            "Abstract": "Over the past few years we have seen the use of Internet worms, i.e.,malicious self-replicating programs, as a mechanism to rapidly invade and compromise large numbers of remote computers [33]. Although the first worms released on the Internet were large-scale, easy-to-spot massive security incidents [6, 19, 20, 26], also known as flash worms [32], it is currently envisioned (and we see already see signs, in the wild) that future worms will be increasingly difficult to detect, and will be known as stealth worms. This may be partly because the motives of early worm developers are thought to have been centered around self-gratification brought by the achievement of compromising large numbers of remote computers, while the motives of recent worm and malware developers have progressed to more mundane (and sinister) financial and political gains.",
            "Abstract entirety": 1,
            "Author pub id": "Wk7e-kIAAAAJ:tOudhMTPpwUC",
            "Publisher": "Springer, Boston, MA"
        },
        {
            "Title": "Rise of the planet of the apps: A systematic study of the mobile app ecosystem",
            "Publication year": 2013,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/2504730.2504749",
            "Abstract": "Mobile applications (apps) have been gaining rising popularity due to the advances in mobile technologies and the large increase in the number of mobile users. Consequently, several app distribution platforms, which provide a new way for developing, downloading, and updating software applications in modern mobile devices, have recently emerged. To better understand the download patterns, popularity trends, and development strategies in this rapidly evolving mobile app ecosystem, we systematically monitored and analyzed four popular third-party Android app marketplaces. Our study focuses on measuring, analyzing, and modeling the app popularity distribution, and explores how pricing and revenue strategies affect app popularity and developers' income. Our results indicate that unlike web and peer-to-peer file sharing workloads, the app popularity distribution deviates from commonly observed Zipf-like \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Wk7e-kIAAAAJ:p__nRnzSRKYC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Check-It: A plugin for detecting and reducing the spread of fake news and misinformation on the web",
            "Publication year": 2019,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/8909652/",
            "Abstract": "Over the past few years, we have been witnessing the rise of misinformation on the Internet. People fall victims of fake news continuously, and contribute to their propagation knowingly or inadvertently. Many recent efforts seek to reduce the damage caused by fake news by identifying them automatically with artificial intelligence techniques, using signals from domain flag-lists, online social networks, etc. In this work, we present Check-It, a system that combines a variety of signals into a pipeline for fake news identification. Check-It is developed as a web browser plugin with the objective of efficient and timely fake news detection, while respecting user privacy. In this paper, we present the design, implementation and performance evaluation of Check-It. Experimental results show that it outperforms state-of-the-art methods on commonly-used datasets.",
            "Abstract entirety": 1,
            "Author pub id": "Wk7e-kIAAAAJ:yFnVuubrUp4C",
            "Publisher": "IEEE"
        },
        {
            "Title": "A systematic characterization of IM threats using honeypots",
            "Publication year": 2010,
            "Publication url": "https://ics.forth.gr/_publications/imthreats_ndss10.pdf",
            "Abstract": "The popularity of instant messaging (IM) services has recently attracted the interest of attackers that try to send malicious URLs or files to the contact lists of compromised instant messaging accounts or clients. This work focuses on a systematic characterization of IM threats based on the information collected by HoneyBuddy, a honeypot-like infrastructure for detecting malicious activities in IM networks. HoneyBuddy finds and adds contacts to its honeypot messengers by querying popular search engines for IM contacts or by advertising its accounts on contact finder sites. Our deployment has shown that with over six thousand contacts we can gather between 50 and 110 malicious URLs per day as well as executables. Our experiments show that 21% of our collected executable samples were not gathered by other malware collection infrastructures, while 93% of the identified IM phishing domains were not recorded by popular blacklist mechanisms. Furthermore, our findings show that the malicious domains are hosted by a limited number of hosts that remain practically unchanged throughout time.",
            "Abstract entirety": 1,
            "Author pub id": "Wk7e-kIAAAAJ:35N4QoGY0k4C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Detecting targeted attacks using shadow honeypots",
            "Publication year": 2005,
            "Publication url": "https://www.usenix.org/legacy/events/sec05/tech/full_papers/anagnostakis/anagnostakis.pdf",
            "Abstract": "We present Shadow Honeypots, a novel hybrid architecture that combines the best features of honeypots and anomaly detection. At a high level, we use a variety of anomaly detectors to monitor all traffic to a protected network/service. Traffic that is considered anomalous is processed by a \u201cshadow honeypot\u201d to determine the accuracy of the anomaly prediction. The shadow is an instance of the protected software that shares all internal state with a regular (\u201cproduction\u201d) instance of the application, and is instrumented to detect potential attacks. Attacks against the shadow are caught, and any incurred state changes are discarded. Legitimate traffic that was misclassified will be validated by the shadow and will be handled correctly by the system transparently to the end user. The outcome of processing a request by the shadow is used to filter future attack instances and could be used to update the anomaly detector.Our architecture allows system designers to fine-tune systems for performance, since false positives will be filtered by the shadow. Contrary to regular honeypots, our architecture can be used both for server and client applications. We demonstrate the feasibility of our approach in a proof-of-concept implementation of the Shadow Honeypot architecture for the Apache web server and the Mozilla Firefox browser. We show that despite a considerable overhead in the instrumentation of the shadow honeypot (up to 20% for Apache), the overall impact on the system is diminished by the ability to minimize the rate of false-positives.",
            "Abstract entirety": 1,
            "Author pub id": "Wk7e-kIAAAAJ:UeHWp8X0CEIC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Hash-based overlay partitioning in unstructured peer-to-peer systems",
            "Publication year": 2009,
            "Publication url": "https://www.worldscientific.com/doi/abs/10.1142/S0129626409000067",
            "Abstract": "Unstructured peer-to-peer (P2P) networks suffer from the increased volume of traffic produced by flooding. Methods such as random walks or dynamic querying managed to limit the traffic at the cost of reduced network coverage. In this paper, we propose a partitioning method of the unstructured overlay network into a relative small number of distinct subnetworks. The partitioning is driven by the categorization of keywords based on a uniform hash function. The method proposed in this paper is easy to implement and results in significant benefit for the blind flood method. Each search is restricted to a certain partition of the initial overlay network and as a result it is much more targeted. Last but not least, the search accuracy is not sacrificed to the least since all related content is searched. The benefit of the proposed method is demonstrated with extensive simulation results, which show that the overhead for the \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Wk7e-kIAAAAJ:5ugPr518TE4C",
            "Publisher": "World Scientific Publishing Company"
        },
        {
            "Title": "Truth in web mining: Measuring the profitability and cost of cryptominers as a web monetization model",
            "Publication year": 2018,
            "Publication url": "https://arxiv.org/abs/1806.01994",
            "Abstract": "The recent advances of web-based cryptomining libraries along with the whopping market value of cryptocoins have convinced an increasing number of publishers to switch to web mining as a source of monetization for their websites. The conditions could not be better nowadays: the inevitable arms race between adblockers and advertisers is at its peak with publishers caught in the crossfire. But, can cryptomining be the next primary monetization model in the post advertising era of free Internet? In this paper, we respond to this exact question. In particular, we compare the profitability of cryptomining and advertising to assess the most advantageous option for a content provider. In addition, we measure the costs imposed to the user in each case with regards to power consumption, resources utilization, network traffic, device temperature and user experience. Our results show that cryptomining can surpass the profitability of advertising under specific circumstances, however users need to sustain a significant cost on their devices.",
            "Abstract entirety": 1,
            "Author pub id": "Wk7e-kIAAAAJ:IRz6iEL74y4C",
            "Publisher": "Unknown"
        },
        {
            "Title": "A generic anonymization framework for network traffic",
            "Publication year": 2006,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/4024508/",
            "Abstract": "Lack of trust is one of the main reasons for the limited cooperation between different organizations. The privacy of users is of paramount importance to administrators and organizations, which are reluctant to cooperate between each other and exchange network traffic traces. The main reasons behind reluctance to exchange monitored data are the protection of the users' privacy and the fear of information leakage about the internal infrastructure. Anonymization is the technique to overcome this reluctance and enhance the cooperation between different organizations with the smooth exchange of monitored data. Today, several organizations provide network traffic traces that are anonymized by software utilities or ad-hoc solutions that offer limited flexibility. The result of this approach is the creation of unrealistic traces, inappropriate for use in evaluation experiments. Furthermore, the need for fast on-line \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Wk7e-kIAAAAJ:KlAtU1dfN6UC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Regular expression matching on graphics hardware for intrusion detection",
            "Publication year": 2009,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-642-04342-0_14",
            "Abstract": "The expressive power of regular expressions has been often exploited in network intrusion detection systems, virus scanners, and spam filtering applications. However, the flexible pattern matching functionality of regular expressions in these systems comes with significant overheads in terms of both memory and CPU cycles, since every byte of the inspected input needs to be processed and compared against a large set of regular expressions.In this paper we present the design, implementation and evaluation of a regular expression matching engine running on graphics processing units (GPUs). The significant spare computational power and data parallelism capabilities of modern GPUs permits the efficient matching of multiple inputs at the same time against a large set of regular expressions. Our evaluation shows that regular expression matching on graphics hardware can result to a 48 times \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Wk7e-kIAAAAJ:YOwf2qJgpHMC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "A Network-Processor-Based Traffic Splitter for Intrusion Detection",
            "Publication year": 2004,
            "Publication url": "ftp://139.91.151.43/tech-reports/2004/2004.TR342_Network_Processor_Traffic_Splitter_Intrusion_Detection.pdf",
            "Abstract": "Scaling network intrusion detection to high-speed networks can be achieved using multiple intrusion detection sensors operating in parallel coupled with a suitable load balancing traffic splitter. This paper examines a splitter architecture that incorporates two methods for improving system performance: the first is the use of early filtering where a portion of the packets is processed on the splitter instead of the sensors. The second is the use of locality buffering, where the splitter reorders packets in a way that improves memory access locality on the sensors. We have implemented our approach on top of an IXP1200 network processor and evaluated its performance using a combination of experimental evaluation and simulation. Our experiments suggest that early filtering reduces the number of packets to be processed by 32%, giving a 8% increase in sensor performance, while locality buffers improve sensor performance by 10%-18%.",
            "Abstract entirety": 1,
            "Author pub id": "Wk7e-kIAAAAJ:KxtntwgDAa4C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Real-world polymorphic attack detection using network-level emulation",
            "Publication year": 2008,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/1413140.1413164",
            "Abstract": "As state-of-the-art attack detection technology becomes more prevalent, attackers have started to employ techniques such as code obfuscation and polymorphism to defeat these defenses. We have recently proposed network-level emulation, a heuristic detection method that scans network traffic to detect polymorphic attacks. Our approach uses a CPU emulator to dynamically analyze every potential instruction sequence in the inspected traffic, aiming to identify the execution behavior of certain malicious code classes, such as self-decrypting polymorphic shellcode.",
            "Abstract entirety": 1,
            "Author pub id": "Wk7e-kIAAAAJ:RGFaLdJalmkC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Improving the performance of passive network monitoring applications using locality buffering",
            "Publication year": 2007,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/4674410/",
            "Abstract": "In this paper, we present a novel approach for improving the performance of a large class of CPU and memory intensive passive network monitoring applications, such as intrusion detection systems, traffic characterization applications, and NetFlow export probes. Our approach, called locality buffering, reorders the captured packets by clustering packets with the same destination port, before they are delivered to the monitoring application, resulting to improved code and data locality, and consequently to an overall increase in the packet processing throughput and to a decrease in the packet loss rate. We have implemented locality buffering within the widely used libpcap packet capturing library, which allows existing monitoring applications to transparently benefit from the reordered packet stream without the need to change application code. Our experimental evaluation shows that locality buffering improves \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Wk7e-kIAAAAJ:NaGl4SEjCO4C",
            "Publisher": "IEEE"
        },
        {
            "Title": "Minimizing information disclosure to third parties in social login platforms",
            "Publication year": 2012,
            "Publication url": "https://link.springer.com/article/10.1007/s10207-012-0173-6",
            "Abstract": "Over the past few years, a large and ever increasing number of Web sites have incorporated one or more social login platforms and have encouraged users to log in with their Facebook, Twitter, Google, or other social networking identities. Research results suggest that more than two million Web sites have already adopted Facebook\u2019s social login platform, and the number is increasing sharply. Although one might theoretically refrain from such social login features and cross-site interactions, usage statistics show that more than 250 million people might not fully realize the privacy implications of opting-in. To make matters worse, certain Web sites do not offer even the minimum of their functionality unless users meet their demands for information and social interaction. At the same time, in a large number of cases, it is unclear why these sites require all that personal information for their purposes. In this paper \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Wk7e-kIAAAAJ:-_dYPAW6P2MC",
            "Publisher": "Springer-Verlag"
        },
        {
            "Title": "Web Caching: A Survey",
            "Publication year": 2002,
            "Publication url": "https://www.igi-global.com/chapter/web-caching-survey/18424",
            "Abstract": "World Wide Web traffic increases at exponential rates saturating network links and web servers. By replicating popular web pages in strategic places on the Internet, web caching reduces core network traffic, reduces web server load, and improves the end-users\u2019 perceived quality of service. In this paper we survey the area of web caching. We identify major research challenges and their solutions, as well as several commercial products that are being widely used.",
            "Abstract entirety": 1,
            "Author pub id": "Wk7e-kIAAAAJ:LjlpjdlvIbIC",
            "Publisher": "IGI Global"
        },
        {
            "Title": "Mor: Monitoring and measurements through the onion router",
            "Publication year": 2010,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-642-12334-4_14",
            "Abstract": "A free and easy to use distributed monitoring and measurement platform would be valuable in several applications: monitoring network or server infrastructures, performing research experiments using many ISPs and test nodes, or checking for network neutrality violations performed by service providers. In this paper we present MOR, a technique for performing distributed measurement and monitoring tasks using the geographically diverse infrastructure of the Tor anonymizing network. Through several case studies, we show the applicability and value of MOR in revealing the structure and function of large hosting infrastructures and detecting network neutrality violations. Our experiments show that about 7.5% of the tested organizations block at least one popular application port and about 5.5% of them modify HTTP headers.",
            "Abstract entirety": 1,
            "Author pub id": "Wk7e-kIAAAAJ:BrmTIyaxlBUC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "Tracing a large-scale peer to peer system: an hour in the life of gnutella",
            "Publication year": 2002,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/1540442/",
            "Abstract": "Peer-to-peer computing and networking, an emerging model of communication and computation, has recently started to gain significant acceptance. This model not only enables clients to take a more active role in the information dissemination process, but also may significantly increase the performance and reliability of the overall system, by eliminating the traditional notion of the \"server\" which could be a single point of failure, and a potential bottleneck. Although peer-to-peer systems enjoy significant and continually increasing popularity, we still do not have a clear understanding of the magnitude, the traffic patterns, and the potential performance bottlenecks of the recent peer-to-peer networks. In this paper we study the traffic patterns of Gnutella, a popular large-scale peer-to-peer system, and show that traffic patterns are very bursty even over several time scales. We especially focus on the types of the queries \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Wk7e-kIAAAAJ:9yKSN-GCB0IC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Measurement, modeling, and analysis of the mobile app ecosystem",
            "Publication year": 2017,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/2993419",
            "Abstract": "Mobile applications (apps) have been gaining popularity due to the advances in mobile technologies and the large increase in the number of mobile users. Consequently, several app distribution platforms, which provide a new way for developing, downloading, and updating software applications in modern mobile devices, have recently emerged. To better understand the download patterns, popularity trends, and development strategies in this rapidly evolving mobile app ecosystem, we systematically monitored and analyzed four popular third-party Android app marketplaces. Our study focuses on measuring, analyzing, and modeling the app popularity distribution and explores how pricing and revenue strategies affect app popularity and developers\u2019 income.Our results indicate that unlike web and peer-to-peer file sharing workloads, the app popularity distribution deviates from commonly observed Zipf-like \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Wk7e-kIAAAAJ:GtLg2Ama23sC",
            "Publisher": "ACM"
        },
        {
            "Title": "i-Code: Real-time Malicious Code Identification",
            "Publication year": 2012,
            "Publication url": "https://ercim-news.ercim.eu/images/stories/EN90/EN90-web.pdf#page=19",
            "Abstract": "Anubis is a dynamic malware analysis system based on an instrumented Qemu emulator. It is offered as an open service through a public website, where users can submit binaries for analysis, and receive a report that describes the behaviour of the sample in a humanreadable way. For i-Code Anubis was extended to support the analysis and classification of shellcode.The console is designed to collect events generated by these systems, pass the resulting shellcode on to the Anubis sandbox for analysis, and integrate the results in an easy-to-use view. It is also designed to be easily extensible with further detection systems through the use of open communication standards.",
            "Abstract entirety": 1,
            "Author pub id": "Wk7e-kIAAAAJ:EkHepimYqZsC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Be Daring to Push your Ads Forward: Measuring the (Over) use of Service Workers for Advertising Purposes",
            "Publication year": 2021,
            "Publication url": "https://arxiv.org/abs/2110.11241",
            "Abstract": "Rich offline experience, periodic background sync, push notification functionality, network requests control, improved performance via requests caching are only a few of the functionalities provided by the Service Workers API. This new technology, supported by all major browsers, can significantly improve users' experience by providing the publisher with the technical foundations that would normally require anative application. Albeit the capabilities of this new technique and its important role in the ecosystem of Progressive Web Apps (PWAs), it is still unclear what is their actual purpose on the web, and how publishers leverage the provided functionality in their web applications. In this study, we shed light in the real world deployment of Service Workers, by conducting the first large scale analysis of the prevalence of Service Workers in the wild. We see that Service Workers are becoming more and more popular, with the adoption increased by 26% only within the last 5 months. Surprisingly, besides their fruitful capabilities, we see that Service Workers are being mostly used for Push Advertising, in 65.08% of the Service Workers that connect with 3rd parties. We Highlight that this is a relatively new way for advertisers to bypass ad-blockers and render ads on the user's displays natively.",
            "Abstract entirety": 1,
            "Author pub id": "Wk7e-kIAAAAJ:gVv57TyPmFsC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Design and Implementation of a Compressed Certificate Status Protocol",
            "Publication year": 2020,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/3392096",
            "Abstract": "Trust in Secure Sockets Layer\u2013based communications is traditionally provided by Certificate (or Certification) Authorities (CAs) in the form of signed certificates. Checking the validity of a certificate involves three steps: (i) checking its expiration date, (ii) verifying its signature, and (iii) ensuring that it is not revoked. Currently, such certificate revocation checks (i.e., step (iii) above) are done either via Certificate Revocation Lists (CRLs), or Online Certificate Status Protocol (OCSP) servers. Unfortunately, despite the existence of these revocation checks, sophisticated cyber-attackers can still trick web browsers to trust a revoked certificate, believing that it is still valid.Although frequently updated, nonced, and timestamped certificates can reduce the frequency and impact of such cyber-attacks, they add a huge burden to the CAs and OCSP servers. Indeed, CAs and/or OCSP servers need to timestamp and sign on a regular \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Wk7e-kIAAAAJ:HeT0ZceujKMC",
            "Publisher": "ACM"
        },
        {
            "Title": "Dynamic Monitoring of Dark IP Address Space (Poster)",
            "Publication year": 2011,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-642-20305-3_20",
            "Abstract": "number of security-related research topics are based on the monitoring of dark IP address space. Unfortunately there is large administrative overhead associated with the dynamic assignment of a specific subnet for monitoring purposes, such as the deployment of a honeypot farm or a distributed intrusion detection system. In this paper, we propose a system that enables the dynamic allocation of an unadvertised IP address subnet for use by a monitoring sensor. The system dynamically selects network subnets that have been allocated to the organization but are not being advertised, advertises them, and subsequently forwards all received traffic destined to the selected subnet to a monitoring sensor.",
            "Abstract entirety": 1,
            "Author pub id": "Wk7e-kIAAAAJ:ZuybSZzF8UAC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "Detection of intrusions and malware and vulnerability assessment",
            "Publication year": 2006,
            "Publication url": "https://scholar.google.com/scholar?cluster=17422082741042384278&hl=en&oi=scholarr",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "Wk7e-kIAAAAJ:XvxMoLDsR5gC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Imbuing unstructured P2P systems with non-intrusive topology awareness",
            "Publication year": 2009,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/5284549/",
            "Abstract": "The random nature of unstructured P2P overlays imbues them with enhanced self- *  properties. Most of the algorithms which make searching in unstructured P2P systems scalable, such as dynamic querying and 1-hop replication, rely on the random nature of the overlay to function efficiently. However, they do not take into account the structure of the underlying physical communications network, which is anything but random. Efforts to provide topology awareness to unstructured P2P systems often result to clustered graphs which affect negatively algorithms that rely on random overlays. In this paper, we propose ITA, an algorithm which creates a random overlay of randomly connected neighborhoods providing topology awareness to P2P systems, while at the same time has no negative effect on the self- *  properties or the operation of the other P2P algorithms. Using extensive simulations, we demonstrate that ITA \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Wk7e-kIAAAAJ:CHSYGLWDkRkC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Truth in web mining: Measuring the profitability and the imposed overheads of cryptojacking",
            "Publication year": 2019,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-030-30215-3_14",
            "Abstract": "In recent years, we have been observing a new paradigm of attacks, the so-called cryptojacking attacks. Given the lower-risk/lower-effort nature of cryptojacking, the number of such incidents in 2018 were nearly double of those of ransomware attacks. Apart from the cryptojackers, web-cryptomining library providers also enabled benign publishers to use this mechanism as an alternative monetization schema for web in the era of declined ad revenues. In spite of the buzz raised around web-cryptomining, it is not yet known what is the profitability of web-cryptomining and what is the actual cost it imposes on the user side.In this paper, we respond to this exact question by measuring the overhead imposed to the user with regards to power consumption, resources utilization, network traffic, device temperature and user experience. We compare those overheads along with the profitability of web \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Wk7e-kIAAAAJ:OR75R8vi5nAC",
            "Publisher": "Springer, Cham"
        },
        {
            "Title": "Exclusive: How the (synced) cookie monster breached my encrypted vpn session",
            "Publication year": 2018,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/3193111.3193117",
            "Abstract": "In recent years, and after the Snowden revelations, there has been a significant movement in the web from organizations, policymakers and individuals to enhance the privacy awareness among users. As a consequence, more and more publishers support TLS in their websites, and vendors provide privacy and anonymity tools, such as secure VPNs or Tor onions, to cover the need of users for privacy-preserving web browsing. But is the sporadic appliance of such tools enough to provide privacy?",
            "Abstract entirety": 1,
            "Author pub id": "Wk7e-kIAAAAJ:DUooU5lO8OsC",
            "Publisher": "Unknown"
        },
        {
            "Title": "The man who was there: validating check-ins in location-based services",
            "Publication year": 2013,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/2523649.2523653",
            "Abstract": "The growing popularity of location-based services (LBS) has led to the emergence of an economy where users announce their location to their peers, indirectly advertising certain businesses. Venues attract customers through offers and discounts for users of such services. Unfortunately, this economy can become a target of attackers with the intent of disrupting the system for fun and, possibly, profit. This threat has raised the attention of LBS, which have invested efforts in preventing fake check-ins. In this paper, we create a platform for testing the feasibility of fake-location attacks, and present our case study of two popular services, namely Foursquare and Facebook Places. We discover their detection mechanisms and demonstrate that both services are still vulnerable. We implement an adaptive attack algorithm that takes our findings into account and uses information from the LBS at run-time, to maximize its impact \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Wk7e-kIAAAAJ:hMsQuOkrut0C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Traffic Characterization: An Application for Monitoring Peer-To-Peer Systems",
            "Publication year": 2005,
            "Publication url": "http://www.csd.uoc.gr/~danton/final.pdf",
            "Abstract": "As networks get bigger and faster the role of monitoring applications, becomes more complicated. Also application programmers become more clever and manage to camouflage the traffic of their application using dynamic ports. Motivated by the needs for better network monitoring, we have developed a tool for monitoring both static and dynamic port applications. The tool we present is developed using the newly released Monitoring API (MAPI), and aims at expanding our knowledge of what is going on into our network. Using our tool we managed to reduce the portion of unknown traffic, as reported by other\u2013static\u2013classification methods, by almost 57%.",
            "Abstract entirety": 1,
            "Author pub id": "Wk7e-kIAAAAJ:olpn-zPbct0C",
            "Publisher": "Unknown"
        },
        {
            "Title": "One-click hosting services: a file-sharing hideout",
            "Publication year": 2009,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/1644893.1644920",
            "Abstract": "File sharing using peer-to-peer (p2p) systems is a major Internet application and the leading source of network traffic today. However, the dominance of p2p systems for file sharing has been recently challenged by an increasing number of services, such as RapidShare and MegaUpload, which offer users the ability to share files through centralized servers, without relying on an underlying p2p infrastructure. These services, referred to as One-Click Hosting (OCH), have the potential to offer users better performance and availability than p2p systems. If they succeed, OCH services may become the leading platform for file sharing and eventually replace p2p systems for this purpose. In this paper, we present the first, to our knowledge, detailed study of OCH traffic and services focusing on the most popular such service: RapidShare. Through a combination of passive and active measurements, we attempt to understand \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Wk7e-kIAAAAJ:QIV2ME_5wuYC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Stride: Polymorphic sled detection through instruction sequence analysis",
            "Publication year": 2005,
            "Publication url": "https://link.springer.com/chapter/10.1007/0-387-25660-1_25",
            "Abstract": "Despite considerable effort, buffer overflow attacks remain a major security threat today, especially when coupled with self-propagation mechanisms as in worms and viruses. This paper considers the problem of designing network-level mechanisms for detecting polymorphic instances of such attacks. The starting point for our work is the observation that many buffer overflow attacks require a \u201csled\u201d component to transfer control of the system to the exploit code. While previous work has shown that it is possible to detect certain types of sleds, including obfuscated instances, this paper demonstrates that the proposed detection heuristics can be thwarted by more elaborate sled obfuscation techniques. To address this problem, we have designed a new sled detection heuristic, called STRIDE, that offers three main improvements over previous work: it detects several types of sleds that other techniques are blind \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Wk7e-kIAAAAJ:ufrVoPGSRksC",
            "Publisher": "Springer, Boston, MA"
        },
        {
            "Title": "FORWARD Threat Report",
            "Publication year": 2009,
            "Publication url": "https://scholar.google.com/scholar?cluster=12047147593814836086&hl=en&oi=scholarr",
            "Abstract": "This document is the compilation of the three threat reports that were produced independently by the three FORWARD working groups during the second phase of the project. These working groups were established after the first FORWARD workshop that was held in Goteborg, Sweden in April 2008. They are briefly described in the following paragraphs: The Malware and Fraud working group is concerned with the malware and fraud-related threats on the Internet. It covers topics that range from novel malware developments over botnets to cyber crime and Internet fraud. The Smart Environments working group is concerned with ordinary environments that have been enhanced by interconnected computer equipment. There is general expectation that a large number of small devices such as sensors and mobile phones will be interconnected. The group aims to identify emerging trends with respect to security in this \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Wk7e-kIAAAAJ:AXPGKjj_ei8C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Security and Trust Management",
            "Publication year": 2016,
            "Publication url": "https://link.springer.com/content/pdf/10.1007/978-3-319-46598-2.pdf",
            "Abstract": "These proceedings contain the papers selected for presentation at the 12th International Workshop on Security and Trust Management (STM 2016), held in Crete, Greece, during September 26\u201327, 2016, in conjunction with the 21th European Symposium on Research in Computer Security (ESORICS 2016). In response to the call for papers, 34 papers were submitted to the workshop from 17 different countries. Each paper was reviewed by three members of the Program Committee, who considered its significance, novelty, technical quality, and practical impact in their evaluation. As in previous years, reviewing was double-blind. The Program Committee\u2019s work was carried out electronically, yielding intensive discussions over a period of one week. Of the submitted papers, the Program Committee accepted 13 full papers (resulting in an acceptance rate of 38%) and two short papers for presentation at the workshop \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Wk7e-kIAAAAJ:ClCfbGk0d_YC",
            "Publisher": "Springer"
        },
        {
            "Title": "Shadow honeypots",
            "Publication year": 2010,
            "Publication url": "https://academiccommons.columbia.edu/doi/10.7916/D8HD856M",
            "Abstract": "We present Shadow Honeypots, a novel hybrid architecture that combines the best features of honeypots and anomaly detection. At a high level, we use a variety of anomaly detectors to monitor all traffic to a protected network or service. Traffic that is considered anomalous is processed by a \u201cshadow honeypot\u201d to determine the accuracy of the anomaly prediction. The shadow is an instance of the protected software that shares all internal state with a regular (\u201cproduction\u201d) instance of the application, and is instrumented to detect potential attacks. Attacks against the shadow are caught, and any incurred state changes are discarded. Legitimate traffic that was misclassified will be validated by the shadow and will be handled correctly by the system transparently to the end user. The outcome of processing a request by the shadow is used to filter future attack instances and could be used to update the anomaly detector. Our architecture allows system designers to fine-tune systems for performance, since false positives will be filtered by the shadow. We demonstrate the feasibility of our approach in a proof-ofconcept implementation of the Shadow Honeypot architecture for the Apache web server and the Mozilla Firefox browser. We show that despite a considerable overhead in the instrumentation of the shadow honeypot (up to 20% for Apache), the overall impact on the system is diminished by the ability to minimize the rate of false-positives.",
            "Abstract entirety": 1,
            "Author pub id": "Wk7e-kIAAAAJ:yB1At4FlUx8C",
            "Publisher": "Unknown"
        },
        {
            "Title": "SCAMPI-A Scaleable Monitoring Platform for the Internet",
            "Publication year": 2004,
            "Publication url": "http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.5.3342",
            "Abstract": "In this paper we describe the architecture of SCAMPI (A Scaleable Monitoring Platform for the Internet). SCAMPI allows easy writing of monitoring applications, which can run on top of different network adapters without changing the code and which can provide detailed monitoring of high-speed Internet circuits. This is made possible by MAPI (Monitoring API) and the SCAMPI adapter, a programmable hardware monitoring adapter with built-in monitoring functionality.",
            "Abstract entirety": 1,
            "Author pub id": "Wk7e-kIAAAAJ:SeFeTyx0c_EC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Defending against hitlist worms using network address space randomization",
            "Publication year": 2007,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S1389128607000710",
            "Abstract": "Worms are self-replicating malicious programs that represent a major security threat for the Internet, as they can infect and damage a large number of vulnerable hosts at timescales where human responses are unlikely to be effective. Sophisticated worms that use precomputed hitlists of vulnerable targets are especially hard to contain, since they are harder to detect, and spread at rates where even automated defenses may not be able to react in a timely fashion.This paper examines a new proactive defense mechanism called Network Address Space Randomization (NASR) whose objective is to harden networks specifically against hitlist worms. The idea behind NASR is that hitlist information could be rendered stale if nodes are forced to frequently change their IP addresses. NASR limits or slows down hitlist worms and forces them to exhibit features that make them easier to contain at the perimeter. We explore \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Wk7e-kIAAAAJ:5nxA0vEk-isC",
            "Publisher": "Elsevier"
        },
        {
            "Title": "On caching search engine query results",
            "Publication year": 2001,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S014036640000308X",
            "Abstract": "In this paper we explore the problem of Caching of Search Engine Query Results in order to reduce the computing and I/O requirements needed to support the functionality of a search engine of the World Wide Web.We study query traces from the EXCITE search engine and show that they have a significant amount of temporal locality that is, a significant percentage of the queries have been submitted more than once by the same or a different user. Using trace-driven simulation we demonstrate that medium-size caches can hold the results of most of the frequently submitted queries. Finally, we compare the effectiveness of static and dynamic caching and conclude that although dynamic caching can use large caches more effectively, static caching can perform better for (very) small caches.",
            "Abstract entirety": 1,
            "Author pub id": "Wk7e-kIAAAAJ:2osOgNQ5qMEC",
            "Publisher": "Elsevier"
        },
        {
            "Title": "Divide et impera: Partitioning unstructured peer-to-peer systems to improve resource location",
            "Publication year": 2008,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-0-387-72812-4_1",
            "Abstract": "Unstructured P2P systems exhibit a great deal of robustness and self-healing at the cost of reduced scalability. Resource location is performed using a broadcast-like process called flooding. The work presented in this paper comprises an effort to reduce the overwhelming volume of traffic generated by flooding, thus increasing the scalability of unstructured P2P systems. Using a simple hash-based content categorization method the Ultrapeer overlay network is partitioned into a relatively small number of distinct subnetworks. By employing a novel index splitting technique each leaf peer is effectively connected to each different subnetwork. The search space of each individual flooding is restricted to a single partition, and is thus considerably limited. This reduces significantly the volume of traffic produced by flooding without affecting at all the accuracy of the search method. Experimental results demonstrate the \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Wk7e-kIAAAAJ:r0BpntZqJG4C",
            "Publisher": "Springer, Boston, MA"
        },
        {
            "Title": "Available bandwidth measurement as simple as running wget",
            "Publication year": 2006,
            "Publication url": "http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.120.1221&rep=rep1&type=pdf#page=68",
            "Abstract": "Although several available bandwidth measurement tools exist, they usually require access at both ends of the measured path. This important requirement significantly limits the usefulness, applicability, and ease of deployment of existing tools. This work presents a novel available bandwidth measurement tool, called abget, that runs in \u201csingle-end\u201d mode. Our measurement tool can connect to any TCP-based (usually web) server in the Internet, pretending that it is a normal client, and then estimate the variation range of the available bandwidth from the server to the client within a few seconds. Contrary to existing available bandwidth tools, which are based on UDP and ICMP protocols, our methodology is based on the widely prevalent TCP protocol, which enables us to perform accurate measurements even in environments where ICMP and UDP packets are blocked by firewalls or rate-limited.",
            "Abstract entirety": 1,
            "Author pub id": "Wk7e-kIAAAAJ:hqOjcs7Dif8C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Do you know who is talking to your wearable smartband?",
            "Publication year": 2020,
            "Publication url": "https://books.google.com/books?hl=en&lr=&id=iq4SEAAAQBAJ&oi=fnd&pg=PA142&dq=info:7xhxLzWpnWAJ:scholar.google.com&ots=VD0nvjgRk6&sig=5QMg2MnoMhEguaB1wnq8xd9Tyuw",
            "Abstract": "We study seven fitness trackers and their associated smartphone apps from a wide variety of manufacturers, and record who they are talking to. Our results suggest that some of them communicate with unexpected third parties, including social networks, advertisement websites, weather services, and various external APIs. This implies that such unanticipated third-parties may glean personal information of users.",
            "Abstract entirety": 1,
            "Author pub id": "Wk7e-kIAAAAJ:a3BOlSfXSfwC",
            "Publisher": "IOS Press"
        },
        {
            "Title": "On the integration of passive and active network monitoring in grid systems",
            "Publication year": 2007,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-0-387-47658-2_11",
            "Abstract": "This paper focuses on the integration of passive and active network monitoring techniques in Grid systems. We propose a number of performance metrics for assessing the quality of the connectivity, and describe the required measurement methods for obtaining these metrics. Furthermore, the issue of efficiently representing and publishing the measured values is considered. We show that it is important to have both active and passive monitoring strategies applied to Grid systems; and when we do have both strategies it is necessary to have an a priory hybrid design. Finally we depict the tradeoffs introduced by this approach and the description of the components for a domain oriented monitoring infrastructure that supports both passive and active monitoring tools in Grid systems.",
            "Abstract entirety": 1,
            "Author pub id": "Wk7e-kIAAAAJ:2P1L_qKh6hAC",
            "Publisher": "Springer, Boston, MA"
        },
        {
            "Title": "Improving the performance of passive network monitoring applications with memory locality enhancements",
            "Publication year": 2012,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S0140366411002404",
            "Abstract": "Passive network monitoring is the basis for a multitude of systems that support the robust, efficient, and secure operation of modern computer networks. Emerging network monitoring applications are more demanding in terms of memory and CPU resources due to the increasingly complex analysis operations that are performed on the inspected traffic. At the same time, as the traffic throughput in modern network links increases, the CPU time that can be devoted for processing each network packet decreases. This leads to a growing demand for more efficient passive network monitoring systems in which runtime performance becomes a critical issue.In this paper we present locality buffering, a novel approach for improving the runtime performance of a large class of CPU and memory intensive passive monitoring applications, such as intrusion detection systems, traffic characterization applications, and NetFlow \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Wk7e-kIAAAAJ:eq2jaN3J8jMC",
            "Publisher": "Elsevier"
        },
        {
            "Title": "RRDtrace: long-term raw network traffic recording using fixed-size storage",
            "Publication year": 2010,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/5581601/",
            "Abstract": "Recording raw network traffic for long-term periods can be extremely beneficial for a multitude of monitoring and security applications. However, storing all traffic of high volume networks is infeasible even for short-term periods due to the increased storage requirements. Traditional approaches for data reduction like aggregation and sampling either require knowing the traffic features of interest in advance, or reduce the traffic volume by selecting a representative set of packets uniformly over the collecting period. In this work we present RRDtrace, a technique for storing full-payload packets for arbitrary long periods using fixed-size storage. RRDtrace divides time into intervals and retains a larger number of packets for most recent intervals. As traffic ages, an aging daemon is responsible for dynamically reducing its storage space by keeping smaller representative groups of packets, adapting the sampling rate \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Wk7e-kIAAAAJ:PELIpwtuRlgC",
            "Publisher": "IEEE"
        },
        {
            "Title": "SysSec: Managing threats and Vulnerabilities in the future Internet",
            "Publication year": 2012,
            "Publication url": "https://eprints.sztaki.hu/7263/1/EN90-web.pdf#page=13",
            "Abstract": "For many years, cyber attackers have been one step ahead of the defenders. The asymmetric nature of the threat has led to a vicious cycle where attackers end up winning. SysSec, a new Network of Excellence in the area of Systems Security, attempts to break this vicious cycle and encourages researchers to work not on yesterday\u2019s attacks but on tomorrow\u2019s threats, to anticipate the attackers\u2019 next move and to make sure they are prepared.Over the past decade we have seen a large number of cyber attacks on the Internet. Motivated by financial profits or political purposes, cyber attackers usually launch attacks that stay below the radar, are difficult to detect, and exploit the weakest link: the user. We believe that the core of the problem lies in the nature of cyber security itself: in the current practice of cyber security, most defenses are reactive while attackers are by definition proactive. Cyber security researchers usually chase",
            "Abstract entirety": 1,
            "Author pub id": "Wk7e-kIAAAAJ:ipzZ9siozwsC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Exclusion-based signature matching for intrusion detection",
            "Publication year": 2002,
            "Publication url": "http://publications.ics.forth.gr/_publications/2002.CCN02.ExB.pdf",
            "Abstract": "We consider the problem of efficient string-based signature matching for Network Intrusion Detection Systems (NID-Ses). String matching computations dominate in the overall cost of running a NIDS, despite the use of efficient generalpurpose string matching algorithms. Aiming at increasing the efficiency and capacity of NIDSes, we have designed ExB, a string matching algorithm tailored to the specific characteristics of NIDS string matching. We have implemented ExB in snort and present experiments comparing ExB with the current best alternative solution. Our preliminary experiments suggest that ExB offers improvements in overall system performance by as much as a factor of three.",
            "Abstract entirety": 1,
            "Author pub id": "Wk7e-kIAAAAJ:WF5omc3nYNoC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Detection of intrusions and malware & vulnerability assessment",
            "Publication year": 2006,
            "Publication url": "https://link.springer.com/content/pdf/10.1007/978-3-319-60876-1.pdf",
            "Abstract": "On behalf of the Program Committee, it is our pleasure to present the proceedings of the 14th International Conference on Detection of Intrusions and Malware and Vulnerability Assessment (DIMVA), which took place in Bonn, Germany, during July 6\u20137, 2017. Since 2004, DIMVA has been bringing together leading researchers and practitioners from academia, industry, and government to present and discuss novel security research in the broader areas of intrusion detection, malware analysis, and vulnerability assessment. DIMVA is organized by the Special Interest Group\u2013Security, Intrusion Detection, and Response (SIDAR)\u2013of the German Informatics Society (GI). This year, DIMVA received 67 valid submissions from academic and industrial organizations from 25 different countries. Each submission was carefully reviewed by at least three Program Committee members or external experts. The submissions were \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Wk7e-kIAAAAJ:8d8msizDQcsC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Alice, what did you do last time? fighting phishing using past activity tests",
            "Publication year": 2009,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-0-387-85555-4_7",
            "Abstract": "Phishing attacks are one of the most crucial modern security threats in the current World Wide Web. An adversary may clone a legitimate Web site and lure a user to submit her credentials to the malicious construct. The adversary may then use the stolen credentials to the authentic site. In this paper we present a novel idea to fight phishing using Past Activity Tests (PACTs). In a nutshell, PACTs take advantage of the fact that the user has accessed at least once her account in the past, contrary to the phisher who accesses the user\u2019s account for the first time. Thus, a user can answer a question relative to her past activity, but the attacker can not.",
            "Abstract entirety": 1,
            "Author pub id": "Wk7e-kIAAAAJ:_B80troHkn4C",
            "Publisher": "Springer, Boston, MA"
        },
        {
            "Title": "No sugar but all the taste! memory encryption without architectural support",
            "Publication year": 2017,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-319-66399-9_20",
            "Abstract": "The protection of in situ data, typically require solutions that involve different kinds of encryption schemes. Even though the majority of these solutions prioritize the protection of cold data stored on secondary devices, it has been shown that sensitive information like passwords, secrets, and private data can be easily exfiltrated from main memory as well, by adversaries with physical access. As such, the protection of hot data that reside on main memory is equally important.In this paper, we aim to investigate whether it is possible to achieve memory encryption without any architectural support at a reasonable performance cost. In particular, we propose the first of its kind software-based memory encryption approach, which ensures that sensitive data will remain encrypted in main memory at all times. Our approach is based on commodity off-the-shelf hardware, and is totally transparent to legacy \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Wk7e-kIAAAAJ:LO7wyVUgiFcC",
            "Publisher": "Springer, Cham"
        },
        {
            "Title": "Generating realistic workloads for network intrusion detection systems",
            "Publication year": 2004,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/974044.974078",
            "Abstract": "While the use of network intrusion detection systems (nIDS) is becoming pervasive, evaluating nIDS performance has been found to be challenging. The goal of this study is to determine how to generate realistic workloads for nIDS performance evaluation. We develop a workload model that appears to provide reasonably accurate estimates compared to real workloads. The model attempts to emulate a traffic mix of different applications, reflecting characteristics of each application and the way these interact with the system. We have implemented this model as part of a traffic generator that can be extended and tuned to reflect the needs of different scenarios. We also present an approach to measuring the capacity of a nIDS that does not require the setup of a full network testbed.",
            "Abstract entirety": 1,
            "Author pub id": "Wk7e-kIAAAAJ:IjCSPb-OGe4C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Comprehensive shellcode detection using runtime heuristics",
            "Publication year": 2010,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/1920261.1920305",
            "Abstract": "A promising method for the detection of previously unknown code injection attacks is the identification of the shellcode that is part of the attack vector using payload execution. Existing systems based on this approach rely on the self-decrypting behavior of polymorphic code and can identify only that particular class of shellcode. Plain, and more importantly, metamorphic shellcode do not carry a decryption routine nor exhibit any self-modifications and thus both evade existing detection systems. In this paper, we present a comprehensive shellcode detection technique that uses a set of runtime heuristics to identify the presence of shellcode in arbitrary data streams. We have identified fundamental machine-level operations that are inescapably performed by different shellcode types, based on which we have designed heuristics that enable the detection of plain and metamorphic shellcode regardless of the use of self \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Wk7e-kIAAAAJ:J_g5lzvAfSwC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Where's Wally? How to Privately Discover your Friends on the Internet",
            "Publication year": 2018,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/3196494.3196496",
            "Abstract": "Internet friends who would like to connect with each other (eg, VoIP, chat) use point-to-point communication applications such as Skype or WhatsApp. Apart from providing the necessary communication channel, these applications also facilitate contact discovery, where users upload their address-book and learn the network address of their friends. Although handy, this discovery process comes with a significant privacy cost: users are forced to reveal to the service provider every person they are socially connected with, even if they do not ever communicate with them through the app. In this paper, we show that it is possible to implement a scalable User Discovery service, without requiring any centralized entity that users have to blindly trust. Specifically, we distribute the maintenance of the users\u00bb contact information, and allow their friends to query for it, just as they normally query the network for machine services \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Wk7e-kIAAAAJ:2VqYfGB8ITEC",
            "Publisher": "Unknown"
        },
        {
            "Title": "FORWARD--Second Workshop Report",
            "Publication year": 2009,
            "Publication url": "https://scholar.google.com/scholar?cluster=8087870153192932379&hl=en&oi=scholarr",
            "Abstract": "This deliverable summarizes the activity of the second FORWARDworkshop. This workshop constituted the end of the second phase of the project. The aim of this second phase was to establish a number of working groups; each working group had to identify a number of emerging threats in their respective areas (malware and fraud, smart environments, and critical systems). These threats were summarized in three threat reports (Deliverable D2.1.x), one per working group. The goal of the second workshop was to checkpoint and critically review the work that has been done in the working groups, in particular, the threat reports. More precisely, each working group should present their threats to a larger audience comprised of experts. In discussions and presentations, we wanted to make sure that the lists of threats are comprehensive \u2013 that is, each working group has identified all major threats in their respective \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Wk7e-kIAAAAJ:q3oQSFYPqjQC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Detection of Intrusions and Malware, and Vulnerability Assessment",
            "Publication year": 2015,
            "Publication url": "https://link.springer.com/content/pdf/10.1007/978-3-319-20550-2.pdf",
            "Abstract": "It is my pleasure, on behalf of the Program Committee, to present the proceedings of the 12th International Conference on Detection of Intrusions and Malware and Vulnerability Assessment (DIMVA 2015). The conference was hosted by Politecnico di Milano, Italy, during July 9\u201310, 2015. DIMVA is an international conference advancing the state of the art in intrusion detection, malware detection, and vulnerability assessment. It brings together delegates from academic, industrial, and governmental institutions to discuss novel ideas as well as mature research results. This year, DIMVA received 75 submissions from 23 countries. These submissions were carefully reviewed by the Program Committee, where each valid submission had at least three independent reviews. In the end 17 papers were chosen to be presented at the conference and included in the final proceedings. Several of these papers presented large \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Wk7e-kIAAAAJ:4MWp96NkSFoC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Check-It: A plugin for detecting fake news on the web",
            "Publication year": 2021,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S2468696421000380",
            "Abstract": "The rapid proliferation of misinformation and disinformation on the Internet has brought dire consequences upon societies around the world, fostering extremism, undermining social cohesion and threatening the democratic process. This impact can be attested by recent events like the COVID-19 pandemic and the 2020 US presidential election. The impact of misinformation has been so deep and wide that several authors characterize the present historic period as the \u201cpost-truth\u201d era. Many recent efforts seek to contain the proliferation of misinformation by automating the identification of fake news through various techniques that exploit signals derived from linguistic processing of online content, analysis of message diffusion patterns, reputation lists, etc. In this paper we describe the design, implementation of, and experimentation with Check-It, a lightweight, privacy preserving browser plugin that detects fake-news \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Wk7e-kIAAAAJ:lvd772isFD0C",
            "Publisher": "Elsevier"
        },
        {
            "Title": "An Empirical Study of Real-world Polymorphic Code Injection Attacks.",
            "Publication year": 2009,
            "Publication url": "https://www.usenix.org/events/leet09/tech/full_papers/polychronakis/polychronakis_html",
            "Abstract": "Remote code injection attacks against network services remain one of the most effective and widely used exploitation methods for malware propagation. In this paper, we present a study of more than 1.2 million polymorphic code injection attacks targeting production systems, captured using network-level emulation. We focus on the analysis of the structure and operation of the attack code, as well as the overall attack activity in relation to the targeted services. The observed attacks employ a highly diverse set of exploits, often against less widely used vulnerable services, while our results indicate limited use of sophisticated obfuscation schemes and extensive code reuse among different malware families.",
            "Abstract entirety": 1,
            "Author pub id": "Wk7e-kIAAAAJ:isC4tDSrTZIC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Hunting cross-site scripting attacks in the network",
            "Publication year": 2010,
            "Publication url": "https://ics.forth.gr/_publications/hunting_cross_site.pdf",
            "Abstract": "Cross-site Scripting (XSS) attacks in web applications are considered a major threat. In a yearly basis, large IT security vendors export statistics that highlight the need for designing and implementing more efficient countermeasures for securing modern web applications and web users. So far, all these studies are carried out by IT security vendors. The academic community lacks of the tools for performing similar studies for quantifying various properties of XSS attacks. In this paper, we present xHunter, a tool that takes as input a web trace and scans it for identifying possible XSS exploits. xHunter does not provide any defenses against attacks in web applications and browsers. The tool is designed for processing thousands of URLs and isolating XSS exploits. Using xHunter one can see how real XSS exploits look like, what is the geographical distribution of web browsers that trigger XSS exploits, and other valuable properties, which if combined can draw a better picture of the XSS landscape today. xHunter is based on two assumptions. The first one is that a significant fraction of XSS attacks is carried out using URLs and the second one is that these URLs contain parts that produce a valid JavaScript syntax tree with high depth. Thus, the basic operation of xHunter is to process URLs and identify parts that can be parsed in JavaScript. In this paper, we analyze all design choices and challenges for implementing xHunter. We evaluate a preliminary prototype of xHunter using about 11,000 URLs collected by a realworld XSS repository, XSSed. com, and 1,000 URLs collected from a monitoring point in an educational organization with about 1,000 \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Wk7e-kIAAAAJ:yD5IFk8b50cC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Measuring ad value without bankrupting user privacy",
            "Publication year": 2019,
            "Publication url": "https://arxiv.org/abs/1907.10331",
            "Abstract": "Recent work has demonstrated that by monitoring the Real Time Bidding (RTB) protocol, one can estimate the monetary worth of different users for the programmatic advertising ecosystem, even when the so-called winning bids are encrypted. In this paper we describe how to implement the above techniques in a practical and privacy preserving manner. Specifically, we study the privacy consequences of reporting back to a centralized server, features that are necessary for estimating the value of encrypted winning bids. We show that by appropriately modulating the granularity of the necessary information and by scrambling the communication channel to the server, one can increase the privacy performance of the system in terms of K-anonymity. We've implemented the above ideas on a browser extension and disseminated it to some 200 users. Analyzing the results from 6 months of deployment, we show that the average value of users for the programmatic advertising ecosystem has grown more than 75% in the last 3 years.",
            "Abstract entirety": 1,
            "Author pub id": "Wk7e-kIAAAAJ:ODE9OILHJdcC",
            "Publisher": "Unknown"
        },
        {
            "Title": "K-subscription: Privacy-preserving microblogging browsing through obfuscation",
            "Publication year": 2013,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/2523649.2523671",
            "Abstract": "Over the past few years, microblogging social networking services have become a popular means for information sharing and communication. Besides sharing information among friends, such services are currently being used by artists, politicians, news channels, and information providers to easily communicate with their constituency. Even though following specific channels on a microblogging service enables users to receive interesting information in a timely manner, it may raise significant privacy concerns as well. For example, the microblogging service is able to observe all the channels that a particular user follows. This way, it can infer all the subjects a user might be interested in and generate a detailed profile of this user. This knowledge can be used for a variety of purposes that are usually beyond the control of the users.",
            "Abstract entirety": 1,
            "Author pub id": "Wk7e-kIAAAAJ:vbGhcppDl1QC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Efficient content-based detection of zero-day worms",
            "Publication year": 2005,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/1494469/",
            "Abstract": "Recent cybersecurity incidents suggest that Internet worms can spread so fast that in-time human-mediated reaction is not possible, and therefore initial response to cyberattacks has to be automated. The first step towards combating new unknown worms is to be able to detect and identify them at the first stages of their spread. In this paper, we present a novel method for detecting new worms based on identifying similar packet contents directed to multiple destination hosts. We evaluate our method using real traffic traces that contain real worms. Our results suggest that our approach is able to identify novel worms while at the same time the generated false alarms reach as low as zero percent.",
            "Abstract entirety": 1,
            "Author pub id": "Wk7e-kIAAAAJ:_kc_bZDykSQC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Topic 3: Scheduling and Load Balancing",
            "Publication year": 2004,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-540-27866-5_28",
            "Abstract": "Scheduling and Load Balancing techniques are key issues for the performance of applications executed in parallel and distributed environments, and for the efficient utilization of these computational resources. Research in this field has a long history and is well consolidated. Nevertheless, the evolution of parallel and distributed systems toward clusters, computational grids, and global computing environments, introduces new challenging problems that require a new generation of scheduling and load balancing algorithms. Topic 3 in Euro-Par 2004 covers all aspects related to scheduling and load balancing from application and system levels, to theoretical foundations and practical tools. All these aspects are addressed by contributed papers.",
            "Abstract entirety": 1,
            "Author pub id": "Wk7e-kIAAAAJ:eJXPG6dFmWUC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "DIVISOR: Distributed video server for streaming",
            "Publication year": 2001,
            "Publication url": "http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.416.4384&rep=rep1&type=pdf",
            "Abstract": "This paper presents the design and implementation of a networking system architecture targeted to support high-speed video transmission to multiple clients. We have designed, implemented, and evaluated a high-speed, distributed Video Server, which is divided in two different components, the video encoding unit and the network protocol processing unit. The video encoding unit performs the video data encoding, while the network protocol processing unit deals with the network protocol processing. In order to provide a low-cost, scalable system, we have used commercial, off-the-shelf components. We have implemented our system using a small cluster of personal computers, connected via an optical fiber (raw ATM communication). Our initial experimental evaluation suggests that our Distributed Video Server for Streaming (DIVISOR) can efficiently provide predictable response to a large number of clients, guaranteeing Quality of Service and real-time delivery.",
            "Abstract entirety": 1,
            "Author pub id": "Wk7e-kIAAAAJ:HoB7MX3m0LUC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Beyond Black and White: Combining the Benefits of Regular and Incognito Browsing Modes.",
            "Publication year": 2020,
            "Publication url": "https://www.scitepress.org/Papers/2020/98853/98853.pdf",
            "Abstract": "As an increasing number of users seem to be concerned about the sophisticated tracking approaches that web sites employ, most modern browsers provide a privacy-preserving browsing mode. This so called \u201cIncognito\u201d mode enables users to browse web sites with sensitive (eg, medical-, religious-, and substance-abuse-related) content by providing them with a clean-state and disposable browser session. Although incognito-mode browsing is useful, users will eventually need to switch back to regular web browsing as they need to log in to their favorite web sites (eg, Gmail, Facebook, etc.). However, whenever they want to access another unfamiliar or sensitive web site, they are forced to switch back to Incognito mode, and so on and so forth. Pretty soon, users find themselves switching all the time back and forth between regular and incognito mode. Unfortunately, such a chain of actions, is not only tiresome, but may also turn out to be error-prone as well, since users may accidentally use regular browsing mode to visit web sites they intended to access in incognito mode. To provide users with a convenient and privacy-preserving browsing experience, in this paper we propose GRISEO: a new browsing mode that aims to act as a middle-ground, thus enabling users to get the best of both words: the privacy of incognito mode along with the convenience of the regular browsing mode. Our approach is founded on a whitelist-based solution where users \u201cwhitelist\u201d the sites they trust and from which they are willing to receive cookies that will persist even after a single browsing section is over. The rest of the sites are considered black-listed and are \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Wk7e-kIAAAAJ:8xutWZnSdmoC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Speeding up TCP/IP: Faster processors are not enough",
            "Publication year": 2002,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/995168/",
            "Abstract": "Over the last decade we have been witnessing a significant increase in the capabilities of our computing and communication systems. On the one hand, processor speeds have been increasing exponentially, doubling every 18 months or so, while network bandwidth has followed a similar (if not higher) rate of improvement, doubling every 9-12 months, or so. Unfortunately, applications that communicate frequently using standard protocols like TCP/IP do not seem to improve at similar rates. In our attempt to understand the magnitude and reasons for this gap between processor speed and interprocess communication performance, we study the execution of TCP/IP on several processors and operating systems that span a time interval of more than eight years. Our main conclusion is that TCP/IP performance does not scale comparably to processor speed, and this poor scalability is magnified and propagated to \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Wk7e-kIAAAAJ:LkGwnXOMwfcC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Emulation-based detection of non-self-contained polymorphic shellcode",
            "Publication year": 2007,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-540-74320-0_5",
            "Abstract": "Network-level emulation has recently been proposed as a method for the accurate detection of previously unknown polymorphic code injection attacks. In this paper, we extend network-level emulation along two lines. First, we present an improved execution behavior heuristic that enables the detection of a certain class of non-self-contained polymorphic shellcodes that are currently missed by existing emulation-based approaches. Second, we present two generic algorithmic optimizations that improve the runtime performance of the detector. We have implemented a prototype of the proposed technique and evaluated it using off-the-shelf non-self-contained polymorphic shellcode engines and benign data. The detector achieves a modest processing throughput, which however is enough for decent runtime performance on actual deployments, while it has not produced any false positives. Finally, we report \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Wk7e-kIAAAAJ:Se3iqnhoufwC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "Combining static and dynamic analysis for the detection of malicious documents",
            "Publication year": 2011,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/1972551.1972555",
            "Abstract": "The widespread adoption of the PDF format for document exchange has given rise to the use of PDF files as a prime vector for malware propagation. As vulnerabilities in the major PDF viewers keep surfacing, effective detection of malicious PDF documents remains an important issue. In this paper we present MDScan, a standalone malicious document scanner that combines static document analysis and dynamic code execution to detect previously unknown PDF threats. Our evaluation shows that MDScan can detect a broad range of malicious PDF documents, even when they have been extensively obfuscated.",
            "Abstract entirety": 1,
            "Author pub id": "Wk7e-kIAAAAJ:3s1wT3WcHBgC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Communications and Multimedia Security: 10th IFIP TC-6 TC 11 International Conference, CMS 2006, Heraklion Crete, Greece, October 19-21, 2006, Proceedings",
            "Publication year": 2006,
            "Publication url": "https://books.google.com/books?hl=en&lr=&id=NLXBVj0UyfwC&oi=fnd&pg=PA1&dq=info:5n8EKj3Bgz4J:scholar.google.com&ots=jJU_JO1i4J&sig=xnC6giHgD07trp98-wNn83oda0A",
            "Abstract": "Duringthelastfewyearsweseenetworkandinformationsystemsecurityplaying an increasingly important role in our everyday lives. As our computers continue to get infested by all sorts of malware, and as our networks continue to choke with spam and malicious tra? c, we see more and more people losing their co-dence in information technologies as they get signi? cantly concernedabout their security as well as their privacy and that of their loved ones. In their e? ort to cope with the problem, scientists, managers, and politicians all over the world havedesignedandarecurrently implementing systematicapproachesto network and information security, most of which are underlined by the same principle: there is much more room for improvement and research. Along the lines of encouraging and catalyzing research in the area of c-munications and multimedia security, it is our great pleasure to present the proceedings of the 10th IFIP TC-6 TC-11 Conference on Communications and MultimediaSecurity (CMS2006), whichwasheldinHeraklion, CreteonOctober 19-21, 2006. Continuing the tradition of previous CMS conferences, we sought a balanced program containing presentations on various aspects of secure c-munication and multimedia systems. Special emphasis was laid on papers with direct practical relevance for the construction of secure communication systems. The selection of the program was a challenging task. In total, we received 76 submissions, from which 22 were selected for presentation as full paper",
            "Abstract entirety": 1,
            "Author pub id": "Wk7e-kIAAAAJ:B3FOqHPlNUQC",
            "Publisher": "Springer Science & Business Media"
        },
        {
            "Title": "Large Scale Attacks on the Internet Lessons learned from the LOBSTER project",
            "Publication year": 2008,
            "Publication url": "https://scholar.google.com/scholar?cluster=6516698707542818395&hl=en&oi=scholarr",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "Wk7e-kIAAAAJ:a9-T7VOCCH8C",
            "Publisher": "Unknown"
        },
        {
            "Title": "An active splitter architecture for intrusion detection and prevention",
            "Publication year": 2006,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/1593585/",
            "Abstract": "State-of-the-art high-speed network intrusion detection and prevention systems are often designed using multiple intrusion detection sensors operating in parallel coupled with a suitable front-end load-balancing traffic splitter. In this paper, we argue that, rather than just passively providing generic load distribution, traffic splitters should implement more active operations on the traffic stream, with the goal of reducing the load on the sensors. We present an active splitter architecture and three methods for improving performance. The first is early filtering/forwarding, where a fraction of the packets is processed on the splitter instead of the sensors. The second is the use of locality buffering, where the splitter reorders packets in a way that improves memory access locality on the sensors. The third is the use of cumulative acknowledgments, a method that optimizes the coordination between the traffic splitter and the \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Wk7e-kIAAAAJ:0EnyYjriUFMC",
            "Publisher": "IEEE"
        },
        {
            "Title": "CCSP: A compressed certificate status protocol",
            "Publication year": 2017,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/8057065/",
            "Abstract": "Trust in SSL-based communications is provided by Certificate Authorities (CAs) in the form of signed certificates. Checking the validity of a certificate involves three steps: (i) checking its expiration date, (ii) verifying its signature, and (iii) ensuring that it is not revoked. Currently, such certificate revocation checks are done either via Certificate Revocation Lists (CRLs) or Online Certificate Status Protocol (OCSP) servers. Unfortunately, despite the existence of these revocation checks, sophisticated cyber-attackers, may trick web browsers to trust a revoked certificate, believing that it is still valid. Consequently, the web browser will communicate (over TLS) with web servers controlled by cyber-attackers. Although frequently updated, nonced, and timestamped certificates may reduce the frequency and impact of such cyber-attacks, they impose a very large overhead to the CAs and OCSP servers, which now need to \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Wk7e-kIAAAAJ:4fGpz3EwCPoC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Experiences and observations from the noah infrastructure",
            "Publication year": 2010,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/5663312/",
            "Abstract": "Monitoring large chunks of unused IP address space yields interesting observations and useful results. However, the volume and diversity of the collected data makes the extraction of information a challenging task. Additionally, the maintenance of the monitoring infrastructure is another demanding and time-consuming effort. To overcome these problems, we present several visualization techniques that enable users to observe what happens in their unused address space over arbitrary time periods and provide the necessary tools for administrators to monitor their infrastructure. Our approach, which is based on open-source standard technologies, transforms the raw information at the network level and provides a customized and Web-accessible view. In this paper, we present the design, implementation and early experiences of the visualization techniques and tools deployed for the NoAH project, a large-scale \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Wk7e-kIAAAAJ:ZHo1McVdvXMC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Honey@ home: A new approach to large-scale threat monitoring",
            "Publication year": 2007,
            "Publication url": "https://scholar.google.com/scholar?cluster=767261501822883667&hl=en&oi=scholarr",
            "Abstract": "Honeypots have been shown to be very useful for accurately detecting attacks, including zero-day threats, at a reasonable cost and without false positives. However, there are two pressing problems with existing approaches. The first problem is that timely detection requires deployment of honeypots in a large fraction of the network address space, many organizations cannot afford. The second problem is that attackers are evolving, and it has been shown that it is not difficult for them to identify honeypots and develop blacklists to avoid them when launching an attack. In response to these problems, we propose a new architecture that enables large-scale deployment at low cost, while making it harder for attackers to maintain accurate blacklists. The honey@ home architecture relies on communities of regular users installing a lightweight honeypot that monitors unused addresses and ports. Because it does not \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Wk7e-kIAAAAJ:_xSYboBqXhAC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Tolerating overload attacks against packet capturing systems",
            "Publication year": 2012,
            "Publication url": "https://www.usenix.org/conference/atc12/technical-sessions/presentation/papadogiannakis",
            "Abstract": "Passive network monitoring applications such as intrusion detection systems are susceptible to overloads, which can be induced by traffic spikes or algorithmic singularities triggered by carefully crafted malicious packets. Under overload conditions, the system may consume all the available resources, dropping most of the monitored traffic until the overload condition is resolved. Unfortunately, such an awkward response to overloads may be easily capitalized by attackers who can intentionally overload the system to evade detection.",
            "Abstract entirety": 1,
            "Author pub id": "Wk7e-kIAAAAJ:ZfRJV9d4-WMC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Real-world polymorphic attack detection",
            "Publication year": 2009,
            "Publication url": "http://publications.ics.forth.gr/_publications/nemu.wdfia09.pdf",
            "Abstract": "As state-of-the-art attack detection technology becomes more prevalent, attackers have started to employ evasion techniques such as code obfuscation and polymorphism to defeat existing defenses. We have recently proposed network-level emulation, a heuristic detection method that scans network traffic to detect polymorphic attacks. Our approach uses a CPU emulator to dynamically analyze every potential instruction sequence in the inspected traffic, aiming to identify the execution behavior of certain malicious code classes, such as self-decrypting polymorphic shellcode. In this paper, we present results and experiences from deployments of network-level emulation in production networks. After more than a year of continuous operation, our prototype implementation has captured more than a million attacks against real systems, while so far has not resulted to any false positives. The observed attacks employ a highly diverse set of exploits, often against less widely used vulnerable services, and in some cases, sophisticated obfuscation schemes.",
            "Abstract entirety": 1,
            "Author pub id": "Wk7e-kIAAAAJ:JoZmwDi-zQgC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Gnort: High performance network intrusion detection using graphics processors",
            "Publication year": 2008,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-540-87403-4_7",
            "Abstract": "The constant increase in link speeds and number of threats poses challenges to network intrusion detection systems (NIDS), which must cope with higher traffic throughput and perform even more complex per-packet processing. In this paper, we present an intrusion detection system based on the Snort open-source NIDS that exploits the underutilized computational power of modern graphics cards to offload the costly pattern matching operations from the CPU, and thus increase the overall processing throughput. Our prototype system, called Gnort, achieved a maximum traffic processing throughput of 2.3 Gbit/s using synthetic network traces, while when monitoring real traffic using a commodity Ethernet interface, it outperformed unmodified Snort by a factor of two. The results suggest that modern graphics cards can be used effectively to speed up intrusion detection systems, as well as other systems that \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Wk7e-kIAAAAJ:W7OEmFMy1HYC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "HoneyLab: large-scale honeypot deployment and resource sharing",
            "Publication year": 2009,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/5319295/",
            "Abstract": "Honeypots are valuable tools for detecting and analyzing malicious activity on the Internet. Successful and time-critical detection of such activity often depends on large-scale deployment. However, commercial organizations usually do not share honeypot data, and large, open honeypot initiatives only provide read-only alert feeds. As a result, while large and resourceful organizations can afford the high cost of this technology, smaller security firms and security researchers are fundamentally constrained. We propose and build a shared infrastructure for deploying and monitoring honeypots, called HoneyLab, that is similar in spirit to PlanetLab. With an overlay and distributed structure of address space and computing resources, HoneyLab increases coverage and accelerates innovation among security researchers as well as security industry experts relying on honeypot-based attack detection technology. Unlike \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Wk7e-kIAAAAJ:pyW8ca7W8N0C",
            "Publisher": "IEEE"
        },
        {
            "Title": "Improving the accuracy of network intrusion detection systems under load using selective packet discarding",
            "Publication year": 2010,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/1752046.1752049",
            "Abstract": "Under conditions of heavy traffic load or sudden traffic bursts, the peak processing throughput of network intrusion detection systems (NIDS) may not be sufficient for inspecting all monitored traffic, and the packet capturing subsystem inevitably drops excess arriving packets before delivering them to the NIDS. This impedes the detection ability of the system and leads to missed attacks. In this work we present selective packet discarding, a best effort approach that enables the NIDS to anticipate overload conditions and minimize their impact on attack detection. Instead of letting the packet capturing subsystem randomly drop arriving packets, the NIDS proactively discards packets that are less likely to affect its detection accuracy, and focuses on the traffic at the early stages of each network flow. We present the design of selective packet discarding and its implementation in Snort NIDS. Our experiments show that \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Wk7e-kIAAAAJ:lSLTfruPkqcC",
            "Publisher": "Unknown"
        },
        {
            "Title": "An architecture for enforcing javascript randomization in web2. 0 applications",
            "Publication year": 2010,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-642-18178-8_18",
            "Abstract": "Instruction Set Randomization (ISR) is a promising technique for preventing code-injection attacks. In this paper we present a complete randomization framework for JavaScript aiming at detecting and preventing Cross-Site Scripting (XSS) attacks. RaJa randomizes JavaScript source without changing the code structure. Only JavaScript identifiers are carefully modified and the randomized code can be mixed with many other programming languages. Thus, RaJa can be practically deployed in existing web applications, which intermix server-side, client-side and markup languages.",
            "Abstract entirety": 1,
            "Author pub id": "Wk7e-kIAAAAJ:PR6Y55bgFSsC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "Is Privacy possible without Anonymity? The case for microblogging services",
            "Publication year": 2019,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/3301417.3312498",
            "Abstract": "Traditional approaches to privacy are usually based on top of anonymizing or pseudonymizing systems. For example, users who would like to protect their identity and/or hide their activities while browsing the web frequently use anonymizing systems (eg, Tor) or services (eg, VPNs and proxies). Although anonymizing systems are usually effective, recent revelations suggest that anonymization can be compromised and can be used to provide a false sense of security. In this paper we assume a world where anonymization is (practically) not possible. Imagine, for example, a community where the use of anonymizing systems is frowned upon or even forbidden. Is it possible for users to protect their privacy when they can not hide their identity?",
            "Abstract entirety": 1,
            "Author pub id": "Wk7e-kIAAAAJ:bKqednn6t2AC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Multiprogramming and Multiprocessing",
            "Publication year": 2001,
            "Publication url": "https://onlinelibrary.wiley.com/doi/abs/10.1002/047134608X.W5706",
            "Abstract": "The sections in this article are",
            "Abstract entirety": 1,
            "Author pub id": "Wk7e-kIAAAAJ:eMMeJKvmdy0C",
            "Publisher": "John Wiley & Sons, Inc."
        },
        {
            "Title": "E 2 xB: A Domain-Specific String Matching Algorithm for Intrusion Detection",
            "Publication year": 2003,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-0-387-35691-4_19",
            "Abstract": "We consider the problem of string matching in Network Intrusion Detection Systems (NIDSes). String matching computations dominate in the overall cost of running a NIDS, despite the use of efficient general-purpose string matching algorithms. Aiming at increasing the efficiency and capacity of NIDSes, we have designed E 2 xB, a string matching algorithm that is tailored to the specific characteristics of NIDS string matching. We have implemented E 2 xB in snort, a popular open-source NIDS, and present experiments comparing E 2 xB with the current best alternative solution. Our results suggest that for typical traffic patterns E 2 xB improves NIDS performance by 10%\u201336%, while for certain ruleset and traffic patterns string matching performance can be improved by as much as a factor of three.",
            "Abstract entirety": 1,
            "Author pub id": "Wk7e-kIAAAAJ:YsMSGLbcyi4C",
            "Publisher": "Springer, Boston, MA"
        },
        {
            "Title": "Performance analysis of content matching intrusion detection systems",
            "Publication year": 2004,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/1266118/",
            "Abstract": "Although network intrusion detection systems (nIDS) are widely used, there is limited understanding of how these systems perform in different settings and how they should be evaluated. This paper examines how nIDS performance is affected by traffic characteristics, rulesets, string matching algorithms and processor architecture. The analysis presented in this paper shows that nIDS performance is very sensitive to these factors. Evaluating a nIDS therefore requires careful consideration of a fairly extensive set of scenarios. Our results also highlight potential dangers with the use of workloads based on combining widely-available packet header traces with synthetic packet content as well as with the use of synthetic rulesets.",
            "Abstract entirety": 1,
            "Author pub id": "Wk7e-kIAAAAJ:roLk4NBRz8UC",
            "Publisher": "IEEE"
        },
        {
            "Title": "The Rise and Fall of Fake News sites: A Traffic Analysis",
            "Publication year": 2021,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/3447535.3462510",
            "Abstract": "Over the past decade, we have witnessed the rise of misinformation on the Internet, with online users constantly falling victims of fake news. A multitude of past studies have analyzed fake news diffusion mechanics and detection and mitigation techniques. However, there are still open questions about their operational behavior such as: How old are fake news websites? Do they typically stay online for long periods of time? Do such websites synchronize with each other their up and down time? Do they share similar content through time? Which third-parties support their operations? How much user traffic do they attract, in comparison to mainstream or real news websites? In this paper, we perform a first of its kind investigation to answer such questions regarding the online presence of fake news websites and characterize their behavior in comparison to real news websites. Based on our findings, we build a content \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Wk7e-kIAAAAJ:_OXeSy2IsFwC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Incognitus: Privacy-Preserving User Interests in Online Social Networks",
            "Publication year": 2018,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-030-12085-6_8",
            "Abstract": "Online Social Networks have changed the way we reach news and information. An increasing number of people use social networks not only for communicating with friends and colleagues but also for their daily information needs. Apart from providing the users with personalized information in a timely manner, this functionality may also raise significant privacy concerns. The service provider is able to observe both the Pages a user is subscribed to and her inter- actions with them. The collected data can form a detailed user profile, which can later be used for several purposes; usually beyond the control of the user. To ad- dress these privacy concerns, we propose Incognitus: an approach to allow users browse Pages of OSNs without disclosing their interests or activity to the service provider. Our approach provides (i) a incognito mode of operation when browsing privacy-sensitive content. In this isolated \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Wk7e-kIAAAAJ:9c2xU6iGI7YC",
            "Publisher": "Springer, Cham"
        },
        {
            "Title": "Web-conscious storage management for web proxies",
            "Publication year": 2002,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/1134299/",
            "Abstract": "Many proxy servers are limited by their file I/O needs. Even when a proxy is configured with sufficient I/O hardware, the file system software often fails to provide the available bandwidth to the proxy processes. Although specialized file systems may offer a significant improvement and overcome these limitations, we believe that user-level disk management on top of industry-standard file systems can offer similar performance advantages. We study the overheads associated with file I/O in Web proxies, we investigate their underlying causes, and we propose Web-conscious storage management, a set of techniques that exploit the unique reference characteristics of Web-page accesses in order to allow Web proxies to overcome file I/O limitations. Using realistic trace-driven simulations, we show that these techniques can improve the proxy's secondary storage I/O throughput by a factor of 15 over traditional open-source \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Wk7e-kIAAAAJ:hFOr9nPyWt4C",
            "Publisher": "IEEE"
        },
        {
            "Title": "European Cyber-Security Research and Innovation",
            "Publication year": 2015,
            "Publication url": "http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.675.7175&rep=rep1&type=pdf",
            "Abstract": "Looking back at the evolution of cyber criminal activities, from the nineties to the present day, we observe interesting trends coming together in what may seem a perfectly orchestrated scene. In parallel with the \u2018security by design\u2019, we recall the importance of reactive security in a field of ever-changing arms races.From the Morris Worm to Invisible Malware In 1988 the Morris Worm [1] marked the beginning of the first of three decades of malicious software: malware written by developers to demonstrate their skill. In the early days, it was not uncommon to find reconnaissance traces identifying the author purposely buried in the code.",
            "Abstract entirety": 1,
            "Author pub id": "Wk7e-kIAAAAJ:i2xiXl-TujoC",
            "Publisher": "EUROPEAN RESEARCH CONSORTIUM INFORMATICS & MATHEMATICS"
        },
        {
            "Title": "Piranha: Fast and memory-efficient pattern matching for intrusion detection",
            "Publication year": 2005,
            "Publication url": "https://link.springer.com/chapter/10.1007/0-387-25660-1_26",
            "Abstract": "Network Intrusion Detection Systems (NIDS) provide an important security function to help defend against network attacks. As network speeds and detection workloads increase, it is important for NIDSes to be highly efficient. Most NIDSes need to check for thousands of known attack patterns in every packet, making pattern matching the most expensive part of signature-based NIDSes in terms of processing and memory resources. This paper describes Piranha, a new algorithm for pattern matching tailored specifically for intrusion detection. Piranha is based on the observation that if the rarest substring of a pattern does not appear, then the whole pattern will definitely not match. Our experimental results, based on traces that represent typical NIDS workloads, indicate that Piranha can enhance the performance of a NIDS by 11% to 28% in terms of processing time and by 18% to 73% in terms of memory usage \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Wk7e-kIAAAAJ:L8Ckcad2t8MC",
            "Publisher": "Springer, Boston, MA"
        },
        {
            "Title": "Scap: Stream-oriented network traffic capture and analysis for high-speed networks",
            "Publication year": 2013,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/2504730.2504750",
            "Abstract": "Many network monitoring applications must analyze traffic beyond the network layer to allow for connection-oriented analysis, and achieve resilience to evasion attempts based on TCP segmentation. However, existing network traffic capture frameworks provide applications with just raw packets, and leave complex operations like flow tracking and TCP stream reassembly to application developers. This gap leads to increased application complexity, longer development time, and most importantly, reduced performance due to excessive data copies between the packet capture subsystem and the stream processing module. This paper presents the Stream capture library (Scap), a network monitoring framework built from the ground up for stream-oriented traffic processing. Based on a kernel module that directly handles flow tracking and TCP stream reassembly, Scap delivers to user-level applications flow-level \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Wk7e-kIAAAAJ:BwyfMAYsbu0C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Cookie synchronization: Everything you always wanted to know but were afraid to ask",
            "Publication year": 2019,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/3308558.3313542",
            "Abstract": "User data is the primary input of digital advertising, fueling the free Internet as we know it. As a result, web companies invest a lot in elaborate tracking mechanisms to acquire user data that can sell to data markets and advertisers. However, with same-origin policy and cookies as a primary identification mechanism on the web, each tracker knows the same user with a different ID. To mitigate this, Cookie Synchronization (CSync) came to the rescue, facilitating an information sharing channel between 3rd-parties that may or not have direct access to the website the user visits. In the background, with CSync, they merge user data they own, but also reconstruct a user's browsing history, bypassing the same origin policy.",
            "Abstract entirety": 1,
            "Author pub id": "Wk7e-kIAAAAJ:WJVC3Jt7v1AC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Monitoring three National Research Networks for Eight Weeks: Observations and Implications",
            "Publication year": 2008,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/4509941/",
            "Abstract": "With the advent of dynamic and elusive distributed applications such as peer-to-peer file sharing systems, network administrators find it increasingly difficult to understand the types of applications running in their networks and the amount of traffic each application produces. In this paper, we present measurement results from the deployment of an accurate traffic characterization application in three national research and education networks for a period of two months. Our observations go beyond traffic distribution; we explore the application usage in terms of active IP addresses, the existence of IP addresses generating massive amounts of traffic, the asymmetry of incoming and outgoing traffic, and the existence of SPAM-sending mail servers.",
            "Abstract entirety": 1,
            "Author pub id": "Wk7e-kIAAAAJ:rO6llkc54NcC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Failure Management in Grids: The Case of the EGEE Infrastructure",
            "Publication year": 2006,
            "Publication url": "https://www.researchgate.net/profile/Marios-Dikaiakos/publication/220440011_Failure_Management_in_Grids_the_Case_of_the_EGEE_Infrastructure/links/02e7e53999eebe140b000000/Failure-Management-in-Grids-the-Case-of-the-EGEE-Infrastructure.pdf",
            "Abstract": "The emergence of Grid infrastructures like EGEE has enabled the deployment of large-scale computational experiments that address challenging scientific problems in various fields. However, to realize their full potential, Grid infrastructures need to achieve a higher degree of dependability, ie, they need to improve the ratio of Grid-job requests that complete successfully in the presence of Grid-component failures. To achieve this, however, we need to determine, analyze and classify the causes of job failures on Grids. In this paper we study the reasons behind Grid job failures in the context of EGEE, the largest Grid infrastructure currently in operation. We present points of failure in a Grid that affect the execution of jobs, and describe error types and contributing factors. We discuss various information sources that provide users and administrators with indications about failures, and assess their usefulness based on error information accuracy and completeness. Finally, we discuss two case studies, describing failures that occurred on a production site of EGEE and the troubleshooting process for each case.",
            "Abstract entirety": 1,
            "Author pub id": "Wk7e-kIAAAAJ:b0M2c_1WBrUC",
            "Publisher": "CoreGRID Technical Report, Number TR-0055 July 20, 2006-11-12"
        },
        {
            "Title": "Isolating javascript in dynamic code environments",
            "Publication year": 2010,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/1810139.1810147",
            "Abstract": "We analyze the source code of four well-known large web applications, namely WordPress, phpBB, phpMyAdmin and Drupal. We want to quantify the level of language intermixing in modern web applications and, if possible, we want to categorize all coding idioms that involve intermixing of JavaScript with a server-side programming language, like PHP. Our analysis processes more than half of a million of LoCs and identifies about 1,000 scripts. These scripts contain 163 cases, where the source code is mixed in a way that is hard to isolate JavaScript from PHP. We manually investigate all 163 scripts and proceed in a classification scheme of five distinct classes. Our analysis can be beneficial for all applications that apply operations in the client-side part of a web application, various XSS mitigation schemes, as well as code refactoring and optimization tools.",
            "Abstract entirety": 1,
            "Author pub id": "Wk7e-kIAAAAJ:4OULZ7Gr8RgC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Network-level polymorphic shellcode detection using emulation",
            "Publication year": 2007,
            "Publication url": "https://link.springer.com/article/10.1007/s11416-006-0031-z",
            "Abstract": "Significant progress has been made in recent years towards preventing code injection attacks at the network level. However, as state-of-the-art attack detection technology becomes more prevalent, attackers are likely to evolve, employing techniques such as polymorphism and metamorphism to defeat these defenses. A major outstanding question in security research and engineering is thus whether we can proactively develop the tools needed to contain advanced polymorphic and metamorphic attacks. While recent results have been promising, most of the existing proposals can be defeated using only minor enhancements to the attack vector. In fact, some publicly-available polymorphic shellcode engines are currently one step ahead of the most advanced publicly-documented network-level detectors. In this paper, we present a heuristic detection method that scans network traffic streams for the presence \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Wk7e-kIAAAAJ:eQOLeE2rZwMC",
            "Publisher": "Springer-Verlag"
        },
        {
            "Title": "DCSP: Performant Certificate Revocation a DNS-based approach",
            "Publication year": 2016,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/2905760.2905767",
            "Abstract": "Trust in SSL-based communication on the Internet is provided by Certificate Authorities (CAs) in the form of signed certificates. Checking the validity of a certificate involves three steps:(i) checking its expiration date,(ii) verifying its signature, and (iii) making sure that it is not revoked. Currently, Certificate Revocation checks (ie step (iii) above) are done either via Certificate Revocation Lists (CRLs) or Online Certificate Status Protocol (OCSP) servers. Unfortunately, both current approaches tend to incur such a high overhead that several browsers (including almost all mobile ones) choose not to check certificate revocation status, thereby exposing their users to significant security risks.",
            "Abstract entirety": 1,
            "Author pub id": "Wk7e-kIAAAAJ:ruyezt5ZtCIC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Misusing unstructured p2p systems to perform dos attacks: The network that never forgets",
            "Publication year": 2006,
            "Publication url": "https://link.springer.com/chapter/10.1007/11767480_9",
            "Abstract": "Unstructured P2P systems have gained great popularity in recent years and are currently used by millions of users. One fundamental property of these systems is the lack of structure, which allows decentralized operation and makes it easy for new users to join and participate in the system. However, the lack of structure can also be abused by malicious users. We explore one such attack, that enables malicious users to use unstructured P2P systems to perform Denial of Service (DoS) attacks to third parties. Specifically, we show that a malicious node can coerce a large number of peers to perform requests to a target host that may not even be part of the P2P network, including downloading unwanted files from a target Web Server. This is a classic form of denial-of-service which also has two interesting characteristics: (a) it is hard to identify the originator of the attack, (b) it is even harder to stop the attack. The \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Wk7e-kIAAAAJ:M3ejUd6NZC8C",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "Detecting social network profile cloning",
            "Publication year": 2011,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/5766886/",
            "Abstract": "Social networking is one of the most popular Internet activities, with millions of users from around the world. The time spent on sites like Facebook or LinkedIn is constantly increasing at an impressive rate. At the same time, users populate their online profile with a plethora of information that aims at providing a complete and accurate representation of themselves. Attackers may duplicate a user's online presence in the same or across different social networks and, therefore, fool other users into forming trusting social relations with the fake profile. By abusing that implicit trust transferred from the concept of relations in the physical world, they can launch phishing attacks, harvest sensitive user information, or cause unfavorable repercussions to the legitimate profile's owner. In this paper we propose a methodology for detecting social network profile cloning. We present the architectural design and implementation \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Wk7e-kIAAAAJ:a0OBvERweLwC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Using social networks to harvest email addresses",
            "Publication year": 2010,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/1866919.1866922",
            "Abstract": "Social networking is one of the most popular Internet activities with millions of members from around the world. However, users are unaware of the privacy risks involved. Even if they protect their private information, their name is enough to be used for malicious purposes. In this paper we demonstrate and evaluate how names extracted from social networks can be used to harvest email addresses as a first step for personalized phishing campaigns. Our blind harvesting technique uses names collected from the Facebook and Twitter networks as query terms for the Google search engine, and was able to harvest almost 9 million unique email addresses. We compare our technique with other harvesting methodologies, such as crawling the World Wide Web and dictionary attacks, and show that our approach is more scalable and efficient than the other techniques. We also present three targeted harvesting, techniques \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Wk7e-kIAAAAJ:D03iK_w7-QYC",
            "Publisher": "Unknown"
        },
        {
            "Title": "GAS: Overloading a File Sharing Network as an Anonymizing System",
            "Publication year": 2007,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-540-75651-4_25",
            "Abstract": "Anonymity is considered as a valuable property as far as everyday transactions in the Internet are concerned. Users care about their privacy and they seek for new ways to keep secret as much as of their personal information from third parties. Anonymizing systems exist nowadays that provide users with the technology, which is able to hide their origin when they use applications such as the World Wide Web or Instant Messaging. However, all these systems are vulnerable to a number of attacks and some of them may collapse under a low strength adversary. In this paper we explore anonymity from a different perspective. Instead of building a new anonymizing system, we try to overload an existing file sharing system, Gnutella, and use it for a different purpose. We develop a technique that transforms Gnutella as an Anonymizing System (GAS) for a single download from the World Wide Web.",
            "Abstract entirety": 1,
            "Author pub id": "Wk7e-kIAAAAJ:EUQCXRtRnyEC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "On looking FORWARD",
            "Publication year": 2009,
            "Publication url": "https://scholar.google.com/scholar?cluster=1519623139499577196&hl=en&oi=scholarr",
            "Abstract": "Computer systems, networks and Internet users are under constant threat from cyber attacks. FORWARD is an initiative by the European Commission to promote collaboration and partnership between academia and industry in their common goal of protecting Information and Communication Technology infrastructures.",
            "Abstract entirety": 1,
            "Author pub id": "Wk7e-kIAAAAJ:QYdC8u9Cj1oC",
            "Publisher": "EUROPEAN RESEARCH CONSORTIUM INFORMATICS & MATHEMATICS"
        },
        {
            "Title": "ITA: innocuous topology awareness for unstructured p2p networks",
            "Publication year": 2012,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/6197180/",
            "Abstract": "One of the most appealing characteristics of unstructured P2P overlays is their enhanced self-* properties, which results from their loose, random structure. In addition, most of the algorithms which make searching in unstructured P2P systems scalable, such as dynamic querying and 1-hop replication, rely on the random nature of the overlay to function efficiently. The underlying communications network (i.e., the Internet), however, is not as randomly constructed. This leads to a mismatch between the distance of two peers on the overlay and the hosts they reside on at the IP layer, which in turn leads to its misuse. The crux of the problem arises from the fact that any effort to provide a better match between the overlay and the IP layer will inevitably lead to a reduction in the random structure of the P2P overlay, with many adverse results. With this in mind, we propose ITA, an algorithm which creates a random overlay of \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Wk7e-kIAAAAJ:tKAzc9rXhukC",
            "Publisher": "IEEE"
        },
        {
            "Title": "\u00d8pass: Zero-storage password management based on password reminders",
            "Publication year": 2018,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/3193111.3193113",
            "Abstract": "A plethora of Internet services and applications require user authentication. Although many alternatives have been proposed, and despite the significant advancement in attackers' capabilities to perform password cracking, the most attractive authentication technology today, is still text-based passwords.",
            "Abstract entirety": 1,
            "Author pub id": "Wk7e-kIAAAAJ:sNmaIFBj_lkC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Antisocial networks: Turning a social network into a botnet",
            "Publication year": 2008,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-540-85886-7_10",
            "Abstract": "Antisocial Networks are distributed systems based on social networking Web sites that can be exploited by attackers, and directed to carry out network attacks. Malicious users are able to take control of the visitors of social sites by remotely manipulating their browsers through legitimate Web control functionality such as image-loading HTML tags, JavaScript instructions, etc. In this paper we experimentally show that Social Network web sites have the ideal properties to become attack platforms.We start by identifying all the properties of Facebook, a real-world Social Network, and then study how we can utilize these properties and transform it into an attack platform against any host connected to the Internet. Towards this end, we developed a real-world Facebook application that can perform malicious actions covertly. We experimentally measured it\u2019s impact by studying how innocent Facebook users \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Wk7e-kIAAAAJ:3fE2CSJIrl8C",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "A CC/PP aware apache web server",
            "Publication year": 2002,
            "Publication url": "https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.20.6208&rep=rep1&type=pdf",
            "Abstract": "While current Internet is looking for standards that it can be based and grown upon them in a stable manner, different protocols have been suggested by several consortiums and groups. The Internet of the future will likely contain not only the standard PCs and portable computers but many other devices as well. We have already seen the mobile phones that are trying to access the world of Internet despite their limited capabilities in power and size. In order for such mobile devices to access the Internet a new protocol must be used. The weaknesses mentioned, about the low power and limited size that such devices may have forced us to treat them in a different way depending on their capabilities. This can be explained by the following example.When a PC (a client) is requesting a web server for a web document the web server will return that document. When another device with some different capabilities (mobile) is requesting the same document as in the previous case the interaction between the client and the server should not be the same. Suppose that the web document contains large images. In the first case, the computer has a screen capable of presenting such images. In the latter case however, the mobile phone has a much smaller screen incapable of handling those large images. Such devices need to be integrated with the current Internet in a way that they receive the best result depending on their capabilities. For that reason, we need a protocol that will take care of the interaction between clients and servers and make servers' recognize'the kind and the capabilities of the client of each incoming request.",
            "Abstract entirety": 1,
            "Author pub id": "Wk7e-kIAAAAJ:zA6iFVUQeVQC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Code-injection attacks in browsers supporting policies",
            "Publication year": 2009,
            "Publication url": "https://projects.ics.forth.gr/_publications/2009.w2sp.code_injection.pdf",
            "Abstract": "Code-injection attacks can take place in a large variety of layers, from native code to databases and web applications. The latter case involves mainly client-side code injection in the browser environment, also known as Cross-Site Scripting (XSS). There are numerous ways to defeat XSS attacks, from static and taint analysis to policy enforcement in the web browser. In this paper, we enlist new forms of XSS attacks that seek to bypass browser enforced policies. The attacks outlined in this paper resemble the classic return-tolibc attack in native code. We propose a new form of code isolation, based on browser actions, in order to mitigate the problem.",
            "Abstract entirety": 1,
            "Author pub id": "Wk7e-kIAAAAJ:O3NaXMp0MMsC",
            "Publisher": "Unknown"
        },
        {
            "Title": "PDS2: A user-centered decentralized marketplace for privacy preserving data processing",
            "Publication year": 2021,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/9438799/",
            "Abstract": "We envision PDS 2 , a decentralized data marketplace in which consumers submit their tasks to be run within the platform, on the data of willing providers. The goal of PDS 2  is to ensure that users maintain full control on their data and do not compromise their privacy, while being rewarded for the value that their data generates. In order to achieve this, our marketplace architecture employs blockchain technology, privacy-preserving computation and decentralized machine learning.We then compare different potential solutions and identify the Ethereum blockchain, trusted execution environments and gossip learning as the most suitable for the implementation of PDS 2 . We also discuss the main open challenges that are left to tackle and possible directions for future work.",
            "Abstract entirety": 1,
            "Author pub id": "Wk7e-kIAAAAJ:ZzlSgRqYykMC",
            "Publisher": "IEEE"
        },
        {
            "Title": "An active traffic splitter architecture for intrusion detection",
            "Publication year": 2003,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/1240665/",
            "Abstract": "Scaling network intrusion detection to high network speeds can be achieved using multiple sensors operating in parallel coupled with a suitable load balancing traffic splitter. This paper examines a splitter architecture that incorporates two methods for improving system performance: the first is the use of early filtering where a portion of the packets is processed on the splitter instead of the sensors. The second is the use of locality buffering, where the splitter reorders packets in a way that improves memory access locality on the sensors. Our experiments suggest that early filtering reduces the number of packets to be processed by 32%, giving a 8% increase in sensor performance, while locality buffers improve sensor performance by about 10%. Combined together, the two methods result in an overall improvement of 20% while the performance of the slowest sensor is improved by 14%.",
            "Abstract entirety": 1,
            "Author pub id": "Wk7e-kIAAAAJ:Zph67rFs4hoC",
            "Publisher": "IEEE"
        },
        {
            "Title": "WSIM: A software platform to simulate all-optical security operations",
            "Publication year": 2008,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/4721228/",
            "Abstract": "Network throughput rates increase every day in contrast to electronic chip processingspeed and electronic I/O. Today's firewalls operate by using traditional electronic circuits just like any common PC. However, performing these operations in a fast fiber optics network on the scale of 40 Gbps is impossible. In this paper, we propose a novel system that is currently being researched and tries to perform the security operations of a firewall using optical components. We describe the basic limitations of the optical domain that make this project difficult to implement. We outline the basic software platform called WSIM which is a simulator that offers theoretical support of the project's feasibility. The marriage of an all-optical firewall with the traditional digital systems' architecture can offer significant benefits to the network from both a security and a performance perspective.",
            "Abstract entirety": 1,
            "Author pub id": "Wk7e-kIAAAAJ:u_35RYKgDlwC",
            "Publisher": "IEEE"
        },
        {
            "Title": "D (e| i) aling with VoIP: Robust Prevention of DIAL Attacks",
            "Publication year": 2010,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-642-15497-3_40",
            "Abstract": "We carry out attacks using Internet services that aim to keep telephone devices busy, hindering legitimate callers from gaining access. We use the term DIAL (Digitally Initiated Abuse of teLephones), or, in the simple form, Dial attack, to refer to this behavior. We develop a simulation environment for modeling a Dial attack in order to quantify its full potential and measure the effect of attack parameters. Based on the simulation\u2019s results we perform the attack in the real-world. By using a Voice over IP (VoIP) provider as the attack medium, we manage to hold an existing landline device busy for 85% of the attack duration by issuing only 3 calls per second and, thus, render the device unusable. The attack has zero financial cost, requires negligible computational resources and cannot be traced back to the attacker. Furthermore, the nature of the attack is such that anyone can launch a Dial attack towards any \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Wk7e-kIAAAAJ:LPZeul_q3PIC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "The coin that never sleeps. The privacy preserving usage of Bitcoin in a longitudinal analysis as a speculative asset",
            "Publication year": 2019,
            "Publication url": "https://arxiv.org/abs/1911.03226",
            "Abstract": "Bitcoin is the first and undoubtedly most successful cryptocurrecny to date with a market capitalization of more than 100 billion dollars. Today, Bitcoin has more than 100,000 supporting merchants and more than 3 million active users. Besides the trust it enjoys among people, Bitcoin lacks of a basic feature a substitute currency must have: stability of value. Hence, although the use of Bitcoin as a mean of payment is relative low, yet the wild ups and downs of its value lure investors to use it as useful asset to yield a trading profit. In this study, we explore this exact nature of Bitcoin aiming to shed light in the newly emerged and rapid growing marketplace of cryptocurencies and compare the investmet landscape and patterns with the most popular traditional stock market of Dow Jones. Our results show that most of Bitcoin addresses are used in the correct fashion to preserve security and privacy of the transactions and that the 24/7 open market of Bitcoin is not affected by any political incidents of the offline world, in contrary with the traditional stock markets. Also, it seems that there are specific longitudes that lead the cryptocurrency in terms of bulk of transactions, but there is not the same correlation with the volume of the coins being transferred.",
            "Abstract entirety": 1,
            "Author pub id": "Wk7e-kIAAAAJ:3htObqc8RwsC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Scampi-a scaleable monitoring platform for the internet",
            "Publication year": 2004,
            "Publication url": "https://projects.ics.forth.gr/dcs/Activities/papers/SCAMPI-coppens-ips2004.pdf",
            "Abstract": "In this paper we describe the architecture of SCAMPI (A Scaleable Monitoring Platform for the Internet). SCAMPI allows easy writing of monitoring applications, which can run on top of different network adapters without changing the code and which can provide detailed monitoring of high-speed Internet circuits. This is made possible by MAPI (Monitoring API) and the SCAMPI adapter, a programmable hardware monitoring adapter with built-in monitoring functionality.",
            "Abstract entirety": 1,
            "Author pub id": "Wk7e-kIAAAAJ:aqlVkmm33-oC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Design and Implementation of a High-Performance Network Intrusion Prevention System",
            "Publication year": 2010,
            "Publication url": "https://scholar.google.com/scholar?cluster=14850761634398025151&hl=en&oi=scholarr",
            "Abstract": "Network intrusion prevention systems provide proactive defense against security threats by detecting and blocking attack-related",
            "Abstract entirety": 1,
            "Author pub id": "Wk7e-kIAAAAJ:5awf1xo2G04C",
            "Publisher": "Unknown"
        },
        {
            "Title": "On using Reliable Network RAM for Database Systems",
            "Publication year": 2000,
            "Publication url": "https://139.91.152.92/dcs/Activities/papers/1997.SOSP.poster.pdf",
            "Abstract": "The performance of traditional database systems has been limited by the latency of magnetic disks, where they store their data. Magnetic disks have an access time, which is orders of magnitude higher than that of main memory storage. Thus, they impose a signicant overhead in transaction processing systems. The need for better response times and greater transaction throughput makes it necessary to remove the access of magnetic disks from the critical path of the transaction processing.To ensure recovery in case of failures, most database systems use a (write ahead) log le. The log le must reside in stable storage (usually magnetic disks). Accesses to the log le are usually in the critical path of the transaction processing and usually need synchronous input/output (Figure 1).",
            "Abstract entirety": 1,
            "Author pub id": "Wk7e-kIAAAAJ:_axFR9aDTf0C",
            "Publisher": "Unknown"
        },
        {
            "Title": "LEoNIDS: A low-latency and energy-efficient network-level intrusion detection system",
            "Publication year": 2014,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/6977945/",
            "Abstract": "Over the past decade, design and implementation of low-power systems has received significant attention. While it started with data centers and battery-operated mobile devices, it has recently branched to core network devices such as routers. However, this emerging need for low-power system design has not been studied for security systems, which are becoming increasingly important today. Toward this direction, we aim to reduce the power consumption of network-level intrusion detection systems (NIDS), which are used to improve the secure operation of modern computer networks. Unfortunately, traditional approaches to low-power system design, such as frequency scaling, lead to a disproportionate increase in packet processing and queuing times. In this paper, we show that this increase has a negative impact on the detection latency and impedes a timely reaction. To address this issue, we present a low \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Wk7e-kIAAAAJ:k8Z6L05lTy4C",
            "Publisher": "IEEE"
        },
        {
            "Title": "The red book",
            "Publication year": 2013,
            "Publication url": "http://publications.lib.chalmers.se/records/fulltext/188847/local_188847.pdf",
            "Abstract": "After the completion of its second year of operation, the SysSec Network of Excellence produced this \u201cRed Book of Cybersecurity\u201d to serve as a Roadmap in the area of Systems Security. To realize this book, SysSec put together a \u201cTask Force\u201d of top-level young researchers in the area steered by the advice of SysSec WorkPackage Leaders. The Task Force had vibrant consultations (i) with the Working Groups of SysSec, (ii) with the Associated members of SysSec, and (iii) with the broader Systems Security Community. Capturing their feedback in an on-line questionnaire and in forward-looking \u201cwhat if\u201d questions, the Task Force was able to distill their knowledge, their concerns, and their vision for the future. The result of this consultation has been captured in this Red Book which we hope will serve as a Road Map of Systems Security Research and as an advisory document for policy makers and researchers who would like to have an impact on the Security of the Future Internet.",
            "Abstract entirety": 1,
            "Author pub id": "Wk7e-kIAAAAJ:g3aElNc5_aQC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Reaper: real-time app analysis for augmenting the android permission system",
            "Publication year": 2019,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/3292006.3300027",
            "Abstract": "Android's app ecosystem relies heavily on third-party libraries as they facilitate code development and provide a steady stream of revenue for developers. However, while Android has moved towards a more fine-grained run time permission system, users currently lack the required resources for deciding whether a specific permission request is actually intended for the app itself or is requested by possibly dangerous third-party libraries. In this paper we present Reaper, a novel dynamic analysis system that traces the permissions requested by apps in real time and distinguishes those requested by the app's core functionality from those requested by third-party libraries linked with the app. We implement a sophisticated UI automator and conduct an extensive evaluation of our system's performance and find that Reaper introduces negligible overhead, rendering it suitable both for end users (by integrating it in the OS \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Wk7e-kIAAAAJ:dBIO0h50nwkC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Honey@ home: a new approach to large-scale threat monitoring",
            "Publication year": 2007,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/1314389.1314398",
            "Abstract": "Honeypots have been shown to be very useful for accurately detecting attacks, including zero-day threats, at a reasonable cost and without false positives. However, there are two pressing problems with existing approaches. The first problem is that timely detection requires deployment of honeypots in a large fraction of the network address space, many organizations cannot afford. The second problem is that attackers are evolving, and it has been shown that it is not difficult for them to identify honeypots and develop blacklists to avoid them when launching an attack",
            "Abstract entirety": 1,
            "Author pub id": "Wk7e-kIAAAAJ:HDshCWvjkbEC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Design and implementation of a high-performance network intrusion prevention system",
            "Publication year": 2005,
            "Publication url": "https://link.springer.com/chapter/10.1007/0-387-25660-1_24",
            "Abstract": "Network intrusion prevention systems provide proactive defense against security threats by detecting and blocking attack-related traffic. This task can be highly complex, and therefore, software-based network intrusion prevention systems have difficulty in handling high speed links. This paper describes the design and implementation of a high-performance network intrusion prevention system that combines the use of software-based network intrusion prevention sensors and a network processor board. The network processor acts as a customized load balancing splitter that cooperates with a set of modified content-based network intrusion detection sensors in processing network traffic. We show that the components of such a system, if co-designed, can achieve high performance, while minimizing redundant processing and communication. We have implemented the system using low-cost, off-the- shelf \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Wk7e-kIAAAAJ:e5wmG9Sq2KIC",
            "Publisher": "Springer, Boston, MA"
        },
        {
            "Title": "Communications and Multimedia Security",
            "Publication year": 2006,
            "Publication url": "https://link.springer.com/content/pdf/10.1007/11909033.pdf",
            "Abstract": "During the last few years we see network and information system security playing an increasingly important role in our everyday lives. As our computers continue to get infested by all sorts of malware, and as our networks continue to choke with spam and malicious traffic, we see more and more people losing their confidence in information technologies as they get significantly concerned about their security as well as their privacy and that of their loved ones. In their effort to cope with the problem, scientists, managers, and politicians all over the world have designed and are currently implementing systematic approaches to network and information security, most of which are underlined by the same principle: there is much more room for improvement and research.Along the lines of encouraging and catalyzing research in the area of communications and multimedia security, it is our great pleasure to present the \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Wk7e-kIAAAAJ:EYYDruWGBe4C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Understanding the behavior of malicious applications in social networks",
            "Publication year": 2010,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/5578913/",
            "Abstract": "The World Wide Web has evolved from a collection of static HTML pages to an assortment of Web 2.0 applications. Online social networking in particular is becoming more popular by the day since the establishment of SixDegrees in 1997. Millions of people use social networking web sites daily, such as Facebook, My-Space, Orkut, and LinkedIn. A side-effect of this growth is that possible exploits can turn OSNs into platforms for malicious and illegal activities, like DDoS attacks, privacy violations, disk compromise, and malware propagation. In this article we show that social networking web sites have the ideal properties to become attack platforms. We introduce a new term, antisocial networks, that refers to distributed systems based on social networking web sites which can be exploited to carry out network attacks. An adversary can take control of a visitor's session by remotely manipulating their browsers through \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Wk7e-kIAAAAJ:ldfaerwXgEUC",
            "Publisher": "IEEE"
        },
        {
            "Title": "we. b: The web of short URLs",
            "Publication year": 2011,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/1963405.1963505",
            "Abstract": "Short URLs have become ubiquitous. Especially popular within social networking services, short URLs have seen a significant increase in their usage over the past years, mostly due to Twitter's restriction of message length to 140 characters. In this paper, we provide a first characterization on the usage of short URLs. Specifically, our goal is to examine the content short URLs point to, how they are published, their popularity and activity over time, as well as their potential impact on the performance of the web.",
            "Abstract entirety": 1,
            "Author pub id": "Wk7e-kIAAAAJ:BqipwSGYUEgC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Issues about the Integration of Passive and Active Monitoring for Grid Networks",
            "Publication year": 2007,
            "Publication url": "http://eprints.adm.unipi.it/654/",
            "Abstract": "In this paper we discuss the issues arising with the integration of passive and active monitoring techniques for Grid network infrastructure monitoring. Our proposal is related to the monitoring information production and publication. Initially, we present the context of our work within the Grid world. We enlist the range of different techniques to perform measurements and obtain monitoring data. We propose a number of interesting performance metrics of the quality of the Grid infrastructure connectivity, and the related passive and active monitoring techniques that are required in order to obtain these metrics.",
            "Abstract entirety": 1,
            "Author pub id": "Wk7e-kIAAAAJ:geHnlv5EZngC",
            "Publisher": "Springer"
        },
        {
            "Title": "Mandola: Monitoring and Detecting Online Hate Speech",
            "Publication year": 2016,
            "Publication url": "https://scholar.google.com/scholar?cluster=4858793524073021967&hl=en&oi=scholarr",
            "Abstract": "MANDOLA wants to make a bold step towards improving our understanding of the prevalence and spread of online hate speech and towards empowering ordinary citizens and policy makers to monitor and report hate speech.",
            "Abstract entirety": 1,
            "Author pub id": "Wk7e-kIAAAAJ:9pM33mqn1YgC",
            "Publisher": "EUROPEAN RESEARCH CONSORTIUM INFORMATICS & MATHEMATICS"
        },
        {
            "Title": "Appmon: An application for accurate per application network traffic characterization",
            "Publication year": 2006,
            "Publication url": "https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.455.1549&rep=rep1&type=pdf",
            "Abstract": "Accurate per-application network traffic characterization is becoming increasingly difficult in the face of emerging applications that use dynamically negotiated port numbers. At the same time, information about the contribution of different network applications and services to the traffic mix is highly demanded by network administrators for facilitating effective network management and traffic engineering. In this thesis we present appmon, a passive monitoring application for per-application network traffic classification. Appmon uses deep packet inspection to accurately attribute traffic flows to the applications that generate them, and reports in real time the network traffic breakdown through a Web-based GUI. Appmon manages to classify traffic up to Gigabit speeds and shows a steady performance when monitoring a real network environment. Appmon is easy to configure and deploy, and is publicly available as an open source application.",
            "Abstract entirety": 1,
            "Author pub id": "Wk7e-kIAAAAJ:Wp0gIr-vW9MC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Real-world Detection of Polymorphic Attacks.",
            "Publication year": 2009,
            "Publication url": "https://books.google.com/books?hl=en&lr=&id=0b0QAwAAQBAJ&oi=fnd&pg=PA33&dq=info:R3GrDGZ6Bl4J:scholar.google.com&ots=np2pi7WkHW&sig=Fea3CKux7lNpXiPOViKLrhrgaYQ",
            "Abstract": "As state-of-the-art attack detection technology becomes more prevalent, attackers have started to employ evasion techniques such as code obfuscation and polymorphism to defeat existing defenses. We have recently proposed network-level emulation, a heuristic detection method that scans network traffic to detect polymorphic attacks. Our approach uses a CPU emulator to dynamically analyze every potential instruction sequence in the inspected traffic, aiming to identify the execution behavior of certain malicious code classes, such as self-decrypting polymorphic shellcode. In this paper, we present results and experiences from deployments of network-level emulation in production networks. After more than a year of continuous operation, our prototype implementation has captured more than a million attacks against real systems, while so far has not resulted to any false positives. The observed attacks employ a highly diverse set of exploits, often against less widely used vulnerable services, and in some cases, sophisticated obfuscation schemes.",
            "Abstract entirety": 1,
            "Author pub id": "Wk7e-kIAAAAJ:MLfJN-KU85MC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Giannis Tzagarakis",
            "Publication year": 2018,
            "Publication url": "http://www.protasis.eu/m/filer_public/2c/b6/2cb67f7c-9297-429a-bf3a-9f3605c11923/eurosec2018-0pass.pdf",
            "Abstract": "A plethora of Internet services and applications require user authentication. Although many alternatives have been proposed, and despite the significant advancement in attackers\u2019 capabilities to perform password cracking, the most attractive authentication technology today, is still text-based passwords. The last years, there is a rapid increase in the number of web services a user accesses in their everyday life. Most of these services (eg, online shops, OSNs, chat clients, etc.) require their very own password, thus increasing the burden of password management on the user side. In this paper, we propose\u2205 pass, a novel system that combines ideas from existing authentication methods, to offer a user-friendly mechanism to securely maintain accounts.\u2205 pass works as a password manager, but it requires zero storage for the passwords: no password will ever get stored either in the user\u2019s device, or in a third-party database. We implement\u2205 pass as an extension for the popular Google Chrome browser, and we evaluate it by using the popular businessoriented social networking service LinkedIn. Early results from our performance tests show that\u2205 pass, using a proactive strategy, can achieve more than 2 orders of magnitude better performance than the current state-of-the-art authentication mechanism.",
            "Abstract entirety": 1,
            "Author pub id": "Wk7e-kIAAAAJ:6ZxmRoH8BuwC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Digging up social structures from documents on the web",
            "Publication year": 2012,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/6503202/",
            "Abstract": "We collected more than ten million Microsoft Office documents from public websites, analyzed the metadata stored in each document and extracted information related to social activities. Our analysis revealed the existence of exactly identified cliques of users that edit, revise and collaborate on industrial and military content. We also examined cliques in documents downloaded from Fortune-500 company websites. We constructed their graphs and measured their properties. The graphs contained many connected components and presented social properties. The a priori knowledge of a company's social graph may significantly assist an adversary to launch targeted attacks, such as targeted advertisements and phishing emails. Our study demonstrates the privacy risks associated with metadata by cross-correlating all members identified in a clique with users of Twitter. We show that it is possible to match authors \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Wk7e-kIAAAAJ:Z5m8FVwuT1cC",
            "Publisher": "IEEE"
        },
        {
            "Title": "The cost of digital advertisement: Comparing user and advertiser views",
            "Publication year": 2018,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/3178876.3186060",
            "Abstract": "Digital advertisements are delivered in the form of static images, animations or videos, with the goal to promote a product, a service or an idea to desktop or mobile users. Thus, the advertiser pays a monetary cost to buy ad-space in a content provider\u00bb s medium (eg, website) to place their advertisement in the consumer\u00bb s display. However, is it only the advertiser who pays for the ad delivery? Unlike traditional advertisements in mediums such as newspapers, TV or radio, in the digital world, the end-users are also paying a cost for the advertisement delivery. Whilst the cost on the advertiser\u00bb s side is clearly monetary, on the end-user, it includes both quantifiable costs, such as network requests and transferred bytes, and qualitative costs such as privacy loss to the ad ecosystem. In this study, we aim to increase user awareness regarding the hidden costs of digital advertisement in mobile devices, and compare the \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Wk7e-kIAAAAJ:umqufdRvDiIC",
            "Publisher": "Unknown"
        },
        {
            "Title": "STRIDE: Polymorphic Sled Detection Through Instruction Sequence Analysis",
            "Publication year": 2010,
            "Publication url": "https://scholar.google.com/scholar?cluster=4298326919624177530&hl=en&oi=scholarr",
            "Abstract": "Despite considerable effort, buffer overflow attacks remain a major security threat today, especially when coupled with self-propagation",
            "Abstract entirety": 1,
            "Author pub id": "Wk7e-kIAAAAJ:4fKUyHm3Qg0C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Compromising anonymity using packet spinning",
            "Publication year": 2008,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-540-85886-7_11",
            "Abstract": "We present a novel attack targeting anonymizing systems. The attack involves placing a malicious relay node inside an anonymizing system and keeping legitimate nodes \u201cbusy.\u201d We achieve this by creating circular circuits and injecting fraudulent packets, crafted in a way that will make them spin an arbitrary number of times inside our artificial loops. At the same time we inject a small number of malicious nodes that we control into the anonymizing system. By keeping a significant part of the anonymizing system busy spinning useless packets, we increase the probability of having our nodes selected in the creation of legitimate circuits, since we have more free capacity to route requests than the legitimate nodes. This technique may lead to the compromise of the anonymity of people using the system.To evaluate our novel attack, we used a real-world anonymizing system, TOR. We show that an \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Wk7e-kIAAAAJ:hMod-77fHWUC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "Detection of Intrusions and Malware, and Vulnerability Assessment: 9th International Conference, DIMVA 2012, Heraklion, Crete, Greece, July 26-27, 2012, Revised Selected Papers",
            "Publication year": 2013,
            "Publication url": "https://books.google.com/books?hl=en&lr=&id=QFe5BQAAQBAJ&oi=fnd&pg=PP2&dq=info:k3UHuohq6ZwJ:scholar.google.com&ots=IJzGbkBZb9&sig=VBhBdi5ycMrfLsH3JonH2o18CUg",
            "Abstract": "This book constitutes the refereed post-proceedings of the 9th International Conference on Detection of Intrusions and Malware, and Vulnerability Assessment, DIMVA 2012, held in Heraklion, Crete, Greece, in July 2012. The 10 revised full papers presented together with 4 short papers were carefully reviewed and selected from 44 submissions. The papers are organized in topical sections on malware, mobile security, secure design, and intrusion detection systems (IDS).",
            "Abstract entirety": 1,
            "Author pub id": "Wk7e-kIAAAAJ:4hFrxpcac9AC",
            "Publisher": "Springer"
        },
        {
            "Title": "Design of an application programming interface for ip network monitoring",
            "Publication year": 2004,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/1317735/",
            "Abstract": "We propose a novel general-purpose network traffic monitoring application programming interface (MAPI) for network monitoring applications. Our work builds on a generalized network flow model that we argue is flexible enough to capture emerging application needs, and expressive enough to allow the system to exploit specialized monitoring hardware, where available. We describe an implementation of MAPI using the DAG 4.2 Gigabit Ethernet monitoring card and a commodity Gigabit Ethernet adapter, we present a set of experiments measuring overheads, and we demonstrate potential applications. Our experimental results suggest that MAPI has more expressive power than competing approaches, while at the same time is able to achieve significant performance improvements.",
            "Abstract entirety": 1,
            "Author pub id": "Wk7e-kIAAAAJ:kNdYIx-mwKoC",
            "Publisher": "IEEE"
        },
        {
            "Title": "SCAMPI: A scalable and programmable architecture for monitoring gigabit networks",
            "Publication year": 2003,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-540-39404-4_36",
            "Abstract": "Effective network monitoring is vital for the growing number of control and management applications typically found in present-day networks. Increasing link speeds and the diversity of monitoring applications\u2019 needs have exposed severe limitations of existing monitoring techniques. As a response, the EU IST SCAMPI project designs and implements a scalable and programmable architecture for monitoring multi-gigabit networks. The SCAMPI architecture has an expressive programming interface, uses intelligent hardware, provides user policy management and resource control, and achieves scalability through parallelism. This paper addresses the problems with current high-speed network monitoring and presents the system architecture and components of the SCAMPI platform.",
            "Abstract entirety": 1,
            "Author pub id": "Wk7e-kIAAAAJ:ZeXyd9-uunAC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "SudoWeb: Minimizing information disclosure to third parties in single sign-on platforms",
            "Publication year": 2011,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-642-24861-0_14",
            "Abstract": "Over the past few months we are seeing a large and ever increasing number of Web sites encouraging users to log in with their Facebook, Twitter, or Gmail identity, or personalize their browsing experience through a set of plug-ins that interact with the users\u2019 social profile. Research results suggest that more than two million Web sites have already adopted Facebook\u2019s social plug-ins, and the number is increasing sharply. Although one might theoretically refrain from such single sign-on platforms and cross-site interactions, usage statistics show that more than 250 million people might not fully realize the privacy implications of opting-in. To make matters worse, certain Web sites do not offer even the minimum of their functionality unless the users meet their demands for information and social interaction. At the same time, in a large number of cases, it is unclear why these sites require all that personal \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Wk7e-kIAAAAJ:Mojj43d5GZwC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "Failure management in grids: The case of the egee infrastructure",
            "Publication year": 2007,
            "Publication url": "https://www.worldscientific.com/doi/abs/10.1142/S0129626407003113",
            "Abstract": "The emergence of Grid infrastructures like EGEE has enabled the deployment of large-scale computational experiments that address challenging scientific problems in various fields. However, to realize their full potential, Grid infrastructures need to achieve a higher degree of dependability, i.e., they need to improve the ratio of Grid-job requests that complete successfully in the presence of Grid-component failures. To achieve this, however, we need to determine, analyze and classify the causes of job failures on Grids. In this paper we study the reasons behind Grid job failures in the context of EGEE, the largest Grid infrastructure currently in operation. We present points of failure in a Grid that affect the execution of jobs, and describe error types and contributing factors. We discuss various information sources that provide users and administrators with indications about failures, and assess their usefulness based on \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Wk7e-kIAAAAJ:hC7cP41nSMkC",
            "Publisher": "World Scientific Publishing Company"
        },
        {
            "Title": "Provable network activity for protecting users against false accusation",
            "Publication year": 2016,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-319-45931-8_17",
            "Abstract": "With the proliferation of the World Wide Web, data traces that correspond to users\u2019 network activity can be collected by several Internet actors, including (i) web sites, (ii) smartphone apps, and even (iii) Internet Service Providers. Given that the collection and storage of these data are beyond the control of the end user, these data traces can be easily manipulated, if not, tampered with. The result of such manipulated digital traces can be severe: Innocent users can be shamed or even wrongfully accused of carrying out illegal transactions.To eliminate these potential accusations on innocent users, we introduce Provable Network Activity (PNA): a framework with which the ISPs can give the end users control of their stored traces. The framework guarantees that the information collected for the end users is accurate and will remain accurate for as long as it is stored. Our implementation and preliminary \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Wk7e-kIAAAAJ:0N-VGjzr574C",
            "Publisher": "Springer, Cham"
        },
        {
            "Title": "DiMAPI: An application programming interface for distributed network monitoring",
            "Publication year": 2006,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/1687568/",
            "Abstract": "Network monitoring and measurement is commonly regarded as an essential function for understanding, managing and improving the performance and security of network infrastructures. Traditional passive network monitoring approaches are not adequate for fine-grained performance measurements nor for security applications. In addition, many applications would benefit from monitoring data gathered at multiple vantage points within a network infrastructure. This paper presents the design and implementation of DiMAPI, an application programming interface for distributed passive network monitoring. DiMAPI extends the notion of the network flow with the scope attribute, which enables flow creation and manipulation over a set of local and remote monitoring sensors. Experiments with a number of applications on top of DiMAPI show that it has reasonable performance, while the response latency is very close to \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Wk7e-kIAAAAJ:dhFuZR0502QC",
            "Publisher": "IEEE"
        }
    ]
}]