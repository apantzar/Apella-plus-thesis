[{
    "name": "\u0391\u03bd\u03c4\u03ce\u03bd\u03b9\u03bf\u03c2 \u0393\u03b1\u03c3\u03c4\u03b5\u03c1\u03ac\u03c4\u03bf\u03c2",
    "romanize name": "Antonios Gasteratos",
    "School-Department": "\u039c\u03b7\u03c7\u03b1\u03bd\u03b9\u03ba\u03ce\u03bd \u03a0\u03b1\u03c1\u03b1\u03b3\u03c9\u03b3\u03ae\u03c2 \u03ba\u03b1\u03b9  \u0394\u03b9\u03bf\u03af\u03ba\u03b7\u03c3\u03b7\u03c2",
    "University": "duth",
    "Rank": "\u039a\u03b1\u03b8\u03b7\u03b3\u03b7\u03c4\u03ae\u03c2",
    "Apella_id": 1794,
    "Scholar name": "Antonios Gasteratos",
    "Scholar id": "ZzxSO8QAAAAJ",
    "Affiliation": "Democritus University of Thrace, Greece",
    "Citedby": 4360,
    "Interests": [
        "Robotics",
        "Robot Vision",
        "Machine Vision",
        "Mechatronics",
        "Machine Learning"
    ],
    "Scholar url": "https://scholar.google.com/citations?user=ZzxSO8QAAAAJ&hl=en",
    "Publications": [
        {
            "Title": "Do Neural Network Weights account for Classes Centers?",
            "Publication year": 2021,
            "Publication url": "https://arxiv.org/abs/2104.07004",
            "Abstract": "The exploitation of Deep Neural Networks (DNNs) as descriptors in feature learning challenges enjoys apparent popularity over the past few years. The above tendency focuses on the development of effective loss functions that ensure both high feature discrimination among different classes, as well as low geodesic distance between the feature vectors of a given class. The vast majority of the contemporary works rely their formulation on an empirical assumption about the feature space of a network's last hidden layer, claiming that the weight vector of a class accounts for its geometrical center in the studied space. The paper at hand follows a theoretical approach and indicates that the aforementioned hypothesis is not exclusively met. This fact raises stability issues regarding the training procedure of a DNN, as shown in our experimental study. Consequently, a specific symmetry is proposed and studied both analytically and empirically that satisfies the above assumption, addressing the established convergence issues.",
            "Abstract entirety": 1,
            "Author pub id": "ZzxSO8QAAAAJ:oQQVFBP0nzwC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Lighting compensating multiview stereo",
            "Publication year": 2011,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/5962170/",
            "Abstract": "In this paper, a method that performs 3D object reconstruction from multiple views of the same scene is presented. This reconstruction method initially produces a basic model, based on the space carving algorithm, that is further refined in a subsequent step. The algorithm is fast, computationally simple and produces accurate representations of the input scenes. In addition, compared to previously presented works the proposed algorithm is able to cope with non uniformly lighted scenes due to the characteristics of the used voxel dissimilarity measure. The proposed algorithm is assessed and the experimental results are presented and discussed.",
            "Abstract entirety": 1,
            "Author pub id": "ZzxSO8QAAAAJ:JV2RwH3_ST0C",
            "Publisher": "IEEE"
        },
        {
            "Title": "A reinforcement learning approach for production control in manufacturing systems",
            "Publication year": 2008,
            "Publication url": "http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.577.259&rep=rep1&type=pdf",
            "Abstract": "The problem of production control in serial manufacturing lines that consist of a number of unreliable machines linked with intermediate buffers is addressed. We make use of Reinforcement Learning methodologies in order to derive efficient control policies. Our aim is to derive control policies that are more state-dependent and therefore more efficient than well-known pull type control policies such as Kanban. Manufacturing systems of this type are studied under average measures such as average WorkInProcess inventories etc. and thus, a learning algorithm from the currently developing field of Average Reward Reinforcement Learning was applied. The Reinforcement Learning control policy was compared to three existing efficient pull type control policies, namely Kanban, Base Stock and CONWIP on the basis of simulated data and found to outperform them. The simulation experiments involved a single-product system with two machines that allows backordering. Numerical results are presented along with a qualitative interpretation of our findings. The paper concludes with directions for future research.",
            "Abstract entirety": 1,
            "Author pub id": "ZzxSO8QAAAAJ:rO6llkc54NcC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Pose manifolds for efficient visual servoing",
            "Publication year": 2012,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/6295582/",
            "Abstract": "In order to adequately accomplish vision-based manipulation tasks, robotic platforms require an accurate estimation of the 3D pose of the target, which is efficiently approached by imaging techniques excessively utilizing large databases that consist of images of several objects captured under varying viewpoints. However, such approaches are characterized by large computational burden and complexity accompanied by limited capacities to interpolate between two known instances of an object. To address these issues we propose a robust 3D object pose estimation technique that entails a manifold modeling procedure based on appearance, geometrical and shape attributes of objects. We utilize a bunch-based method that is followed by a shape descriptor module, in order to establish low dimensional pose manifolds capable of distinguishing similar poses of different objects into the corresponding classes \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ZzxSO8QAAAAJ:l7t_Zn2s7bgC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Identifying hazardous emerging behaviors in search and rescue missions with drones: a proposed methodology",
            "Publication year": 2017,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-319-67633-3_6",
            "Abstract": " Search and rescue (SAR) teams are trained to swiftly act and operate in a feasible way, so as to reduce the risk of death associated with accidents due to natural and manmade disasters, as well as during recreational or sports activities such as swimming, climbing and hiking. In this context, SAR teams test emergent and rapidly evolving technologies to evaluate their usefulness in different operational scenarios and to assess if these technologies can increase their effectiveness. Unmanned Aerial Vehicles (UAVs) are examples of such technologies. UAVs are agile, fast and can exhibit autonomous behavior. Therefore, there is a need to assess their usefulness and learn their limitations aiming at comprehending under which settings and contexts can seamlessly collaborate with SAR teams. In our ongoing research, we have designed and implemented an autonomous UAV platform suitable for rescue and \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ZzxSO8QAAAAJ:JG67p0iyyesC",
            "Publisher": "Springer, Cham"
        },
        {
            "Title": "Avert: An autonomous multi-robot system for vehicle extraction and transportation",
            "Publication year": 2015,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/7139411/",
            "Abstract": "This paper presents a multi-robot system for autonomous vehicle extraction and transportation based on the \u201ca-robot-for-a-wheel\u201d concept. The developed prototype is able to extract vehicles from confined spaces with delicate handling, swiftly and in any direction. The novel lifting robots are capable of omnidirectional movement, thus they can under-ride the desired vehicle and dock to its wheels for a synchronized lifting and extraction. The overall developed system applies reasoning about available trajectory paths, wheel identification, local and undercarriage obstacle detection, in order to fully automate the process. The validity and efficiency of the AVERT robotic system is illustrated via experiments in an indoor parking lot, demonstrating successful autonomous navigation, docking, lifting and transportation of a conventional vehicle.",
            "Abstract entirety": 1,
            "Author pub id": "ZzxSO8QAAAAJ:HNqp4bORoCIC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Comparison of data fusion techniques for robot navigation [J]",
            "Publication year": 2006,
            "Publication url": "https://scholar.google.com/scholar?cluster=9084365152072577706&hl=en&oi=scholarr",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "ZzxSO8QAAAAJ:c6chOJGeGucC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Fast loop-closure detection using visual-word-vectors from image sequences",
            "Publication year": 2018,
            "Publication url": "https://journals.sagepub.com/doi/abs/10.1177/0278364917740639",
            "Abstract": "In this paper, a novel pipeline for loop-closure detection is proposed. We base our work on a bag of binary feature words and we produce a description vector capable of characterizing a physical scene as a whole. Instead of relying on single camera measurements, the robot\u2019s trajectory is dynamically segmented into image sequences according to its content. The visual word occurrences from each sequence are then combined to create sequence-visual-word-vectors and provide additional information to the matching functionality. In this way, scenes with considerable visual differences are firstly discarded, while the respective image-to-image associations are provided subsequently. With the purpose of further enhancing the system\u2019s performance, a novel temporal consistency filter (trained offline) is also introduced to advance matches that persist over time. Evaluation results prove that the presented method \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ZzxSO8QAAAAJ:uHQrz-U2knEC",
            "Publisher": "SAGE Publications"
        },
        {
            "Title": "Object recognition using saliency maps and HTM learning",
            "Publication year": 2012,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/6295575/",
            "Abstract": "In this paper a pattern classification and object recognition approach based on bio-inspired techniques is presented. It exploits the Hierarchical Temporal Memory (HTM) topology, which imitates human neocortex for recognition and categorization tasks. The HTM comprises a hierarchical tree structure that exploits enhanced spatiotemporal modules to memorize objects appearing in various orientations. In accordance with HTM's biological inspiration, human vision mechanisms can be used to preprocess the input images. Therefore, the input images undergo a saliency computation step, revealing the plausible information of the scene, where a human might fixate. The adoption of the saliency detection module releases the HTM network from memorizing redundant information and augments the classification accuracy. The efficiency of the proposed framework has been experimentally evaluated in the ETH-80 \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ZzxSO8QAAAAJ:vRqMK49ujn8C",
            "Publisher": "IEEE"
        },
        {
            "Title": "6DoF object pose measurement by a monocular manifold-based pattern recognition technique",
            "Publication year": 2012,
            "Publication url": "https://iopscience.iop.org/article/10.1088/0957-0233/23/11/114005/meta",
            "Abstract": "In this paper, a novel solution to the compound problem of object recognition and 3D pose estimation is presented. An accurate measurement of the geometrical configuration of a recognized target, relative to a known coordinate system, is of fundamental importance and constitutes a prerequisite for several applications such as robot grasping or obstacle avoidance. The proposed method lays its foundations on the following assumptions:(a) the same object captured under varying viewpoints and perspectives represents data that could be projected onto a well-established and highly distinguishable subspace;(b) totally different objects observed under the same viewpoints and perspectives share identical 3D pose that can be sufficiently modeled to produce a generalized model. Toward this end, we propose an advanced architecture that allows both recognizing patterns and providing efficient solution for 6DoF \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ZzxSO8QAAAAJ:8AbLer7MMksC",
            "Publisher": "IOP Publishing"
        },
        {
            "Title": "Stereo-based terrain traversability analysis for robot navigation",
            "Publication year": 2009,
            "Publication url": "https://www.academia.edu/download/42018976/Stereo-based-Terrain-Traversability.pdf",
            "Abstract": "1Royal Military Academy Department of Mechanical Engineering (MSTA) Av. de la Renaissance 30, 1000 Brussels Geert. De. Cubber@ rma. ac. be, Daniela. Doroftei@ rma. ac. be 2Democritus University of Thrace Department of Production and Management Engineering University Campus, Kimmeria, 671 00 Xanthi, Greece lanalpa@ pme. duth. gr, agaster@ pme. duth. gr 3Democritus University of Thrace Department of Electrical and Computer Engineering University Campus, Kimmeria, 671 00 Xanthi, Greece gsirak@ ee. duth. gr",
            "Abstract entirety": 1,
            "Author pub id": "ZzxSO8QAAAAJ:3fE2CSJIrl8C",
            "Publisher": "Unknown"
        },
        {
            "Title": "An intelligent multi-sensor system for first responder indoor navigation",
            "Publication year": 2011,
            "Publication url": "https://iopscience.iop.org/article/10.1088/0957-0233/22/11/114025/meta",
            "Abstract": "This paper presents an indoor navigation system based on sensor data from first responder wearable modules. The system combines an inertial measurement unit, a digital camera and a radio frequency identification device in a way that allows the advantages of each sensor to be fully exploited. The key to this synergy is the extracted qualitative criteria which characterize the performance of each sensor subsystem at various first responder activities and operational conditions under certain time intervals. The accuracy of the detected walking pattern through measurements of the acceleration magnitude from the inertial sensor is utilized for the performance evaluation of the dead-reckoning algorithm. The amount of correct feature matches is linked to the three-dimensional scene representation from the camera navigation subsystem and finally, the degree of probability of each radio frequency identification location \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ZzxSO8QAAAAJ:hMod-77fHWUC",
            "Publisher": "IOP Publishing"
        },
        {
            "Title": "A biologically inspired scale-space for illumination invariant feature detection",
            "Publication year": 2013,
            "Publication url": "https://iopscience.iop.org/article/10.1088/0957-0233/24/7/074024/meta",
            "Abstract": "This paper presents a new illumination invariant operator, combining the nonlinear characteristics of biological center-surround cells with the classic difference of Gaussians operator. It specifically targets the underexposed image regions, exhibiting increased sensitivity to low contrast, while not affecting performance in the correctly exposed ones. The proposed operator can be used to create a scale-space, which in turn can be a part of a SIFT-based detector module. The main advantage of this illumination invariant scale-space is that, using just one global threshold, keypoints can be detected in both dark and bright image regions. In order to evaluate the degree of illumination invariance that the proposed, as well as other, existing, operators exhibit, a new benchmark dataset is introduced. It features a greater variety of imaging conditions, compared to existing databases, containing real scenes under various \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ZzxSO8QAAAAJ:mvPsJ3kp5DgC",
            "Publisher": "IOP Publishing"
        },
        {
            "Title": "A new content based median filter",
            "Publication year": 2004,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/7079776/",
            "Abstract": "In this paper the hardware implementation of a content based median filter suitable for real-time impulse noise suppression is presented. The function of the proposed circuitry is adaptive; it detects the existence of impulse noise in an image neighborhood and applies the median filter operator only when necessary. In this way, the blurring of the image in process is avoided and the integrity of edge and detail information is preserved. The proposed digital hardware structure is capable of processing gray-scale images of 8-bit resolution and is fully pipelined, whereas parallel processing is used to minimize computational time. The architecture presented was implemented in FPGA and it can be used in industrial imaging applications, where fast processing is of the utmost importance. The typical system clock frequency is 55 MHz.",
            "Abstract entirety": 1,
            "Author pub id": "ZzxSO8QAAAAJ:Se3iqnhoufwC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Real-time algorithm for obstacle avoidance",
            "Publication year": 2009,
            "Publication url": "https://www.diva-portal.org/smash/record.jsf?pid=diva2:463247",
            "Abstract": "This work presents a vision-based obstacle detection and avoidance method for autonomous mobile robots. The implementation of an algorithm able to navigate a robot in arbitrary environments usually demands of the synergy of several sensors. This work presents an algorithm employing only one sensor, ie a stereo camera, thus significantly diminishing the system\u2019s complexity. The implementation of this algorithm can be divided into two separate and independent modules. First, the stereo vision module retrieves information from the environment and produces disparity maps and then the decision making module analyses the data of the disparity maps and governs the robot\u2019s direction. The achieved frame rate ensures that the robot will have enough time to accomplish the proposed decisions in real time. Both of the modules have been implemented in C++. The complete algorithm has been examined by being applied on an extensive set of pre-captured stereo images.",
            "Abstract entirety": 1,
            "Author pub id": "ZzxSO8QAAAAJ:OU6Ihb5iCvQC",
            "Publisher": "Unknown"
        },
        {
            "Title": "A Log-Polar interpolation applied to image scaling",
            "Publication year": 2007,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/4258810/",
            "Abstract": "This paper proposes a bio-inspired interpolation algorithm suitable for image scaling. A log-polar neighbor model is adopted, utilizing the feature of applying larger weights to pixels at the center of the interpolation region and logarithmically decreasing weights to pixels away from the center. The interpolation is performed in the Cartesian plane without requiring the full transformation of the image to the log-polar plane. Experiments show that in both visual comparisons and quantitative analysis, the results extracted by the proposed log-polar neighbor model are better than those extracted from pixel repetition, bilinear and bicubic interpolation.",
            "Abstract entirety": 1,
            "Author pub id": "ZzxSO8QAAAAJ:hFOr9nPyWt4C",
            "Publisher": "IEEE"
        },
        {
            "Title": "Modest-vocabulary loop-closure detection with incremental bag of tracked words",
            "Publication year": 2021,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S0921889021000671",
            "Abstract": "A key feature in the context of simultaneous localization and mapping is loop-closure detection, a process determining whether the current robot\u2019s environment perception coincides with previous observation. However, in long-term operations, both computational efficiency and memory requirements involved in an autonomous robot operation in uncontrolled environments, are of particular importance. The majority of approaches scale linearly with the environment\u2019s size in terms of storage and query time. The article at hand presents an efficient appearance-based loop-closure detection pipeline, which encodes the traversed trajectory by a low amount of unique visual words generated on-line through feature tracking. The incrementally constructed visual vocabulary is referred to as the \u201cBag of Tracked Words.\u201d A nearest-neighbor voting scheme is utilized to query the database and assign probabilistic scores to all \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ZzxSO8QAAAAJ:bcT4vkklUMwC",
            "Publisher": "North-Holland"
        },
        {
            "Title": "SeqSLAM with bag of visual words for appearance based loop closure detection",
            "Publication year": 2018,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-030-00232-9_61",
            "Abstract": "The detection of pre-visited areas in robots\u2019 traversed path, widely known as loop closure detection, is vital for drift and position correction in robotic applications, such as simultaneous localization and mapping. In this paper, we present a sequence based approach for pose estimation, by advancing the well known SeqSLAM algorithm with the usage of Bag of Words (BoW) model. A visual vocabulary is produced in an offline procedure resulting in the system \u2019s ability to describe the incoming image stream by visual words, at the online process. Image similarity is achieved through BoW histogram comparisons instead of sum of absolute differences metric. Comparative results on several publicly-available datasets show the benefits of the proposed method offering high recall scores at 100% precision against the original one.",
            "Abstract entirety": 1,
            "Author pub id": "ZzxSO8QAAAAJ:Y4-Jr3-UGfkC",
            "Publisher": "Springer, Cham"
        },
        {
            "Title": "Modeling regions of interest on orbital and rover imagery for planetary exploration missions",
            "Publication year": 2016,
            "Publication url": "https://www.tandfonline.com/doi/abs/10.1080/01969722.2016.1154771",
            "Abstract": "Planetary rover exploration missions require accurate and computationally efficient robot localization in order to perform complex and cooperative tasks. The global localization on planetary environments can be competently addressed by incorporating orbital and ground rover imagery. An indicative approach could include (1) the extraction of regions of interest (ROIs) in orbital images, (2) the extraction of ROIs in rover images, (3) the ROI matching, and (4) the localization. In order to perform adequately in ROI matching, a model should be able to detect common ROIs. The work in hand tackles the problem of extracting such regions of interest that are observable on both orbital and rover images. The dedicated model that was designed and implemented contains a detection and a classification part. The detection of the ROIs is based on both their texture and their geometrical properties. Classification was performed \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ZzxSO8QAAAAJ:H2XcuePHLsAC",
            "Publisher": "Taylor & Francis"
        },
        {
            "Title": "Online spatiotemporal-coherent semantic maps for advanced robot navigation",
            "Publication year": 2013,
            "Publication url": "https://www.researchgate.net/profile/Antonios-Gasteratos/publication/259738880_Online_Spatiotemporal-Coherent_Semantic_Maps_for_Advanced_Robot_Navigation/links/5471d2490cf24af340c3c3b4/Online-Spatiotemporal-Coherent-Semantic-Maps-for-Advanced-Robot-Navigation.pdf",
            "Abstract": "In this paper we introduce a novel online semantic mapping framework apt to establish the seamless cooperation between the low level geometrical information and the high level environment\u2019s perception. Its main contribution involves the online formation of a semantic map, relying on the memorization of abstract place representations and capitalizing both on space quantization and time proximity. A time evolving Augmented Navigation Graph is formed describing the semantic topology of the explored environment and the connectivity among the places visited, which is expressed as the interplaces transition probability. A side contribution of this paper involves the utilization of the learned semantic maps for efficient navigation in the explored environment. Moreover, a specific human-robot interaction paradigm is proposed by illustrating a competent methodology to address the go-to tasks. The performance of the proposed framework was evaluated on long range robot datasets in an unstructured office environment and it exhibits remarkable performance by inferring semantic maps in previously unexplored environments.",
            "Abstract entirety": 1,
            "Author pub id": "ZzxSO8QAAAAJ:l2sC-qQILUoC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Computer Vision Systems: 10th International Conference, ICVS 2015, Copenhagen, Denmark, July 6-9, 2015, Proceedings",
            "Publication year": 2015,
            "Publication url": "https://books.google.com/books?hl=en&lr=&id=KuPyCQAAQBAJ&oi=fnd&pg=PR5&dq=info:7q1HqNIPVCwJ:scholar.google.com&ots=RwNUeDAkNj&sig=7gO-0O5QKh_O0OiAf1PtDyes8FU",
            "Abstract": "This book constitutes the refereed proceedings of the 10th International Conference on Computer Vision Systems, ICVS 2015, held in Copenhagen, Denmark, in July 2015. The 48 papers presented were carefully reviewed and selected from 92 submissions. The paper are organized in topical sections on biological and cognitive vision; hardware-implemented and real-time vision systems; high-level vision; learning and adaptation; robot vision; and vision systems applications.",
            "Abstract entirety": 1,
            "Author pub id": "ZzxSO8QAAAAJ:d4Uf0zfqV5IC",
            "Publisher": "Springer"
        },
        {
            "Title": "A Sociotechnical Approach to UAV Safety for Search and Rescue Missions",
            "Publication year": 2020,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/9213921/",
            "Abstract": "Nowadays search and rescue teams are using Unmanned Aerial Vehicles (UAVs) to complete important tasks. Unfortunately, the safety aspect of UAVs during search and rescue missions from a sociotechnical point of view has not been excessively studied. In this paper, the Systems Theoretic Process Analysis (STPA) has been applied to a fully autonomous UAV system called ROLFER (Robotic Lifeguard For Emergency Rescue). ROLFER has two operational modes. The first one indicates the preparations that have to take place before the ROLFERs SAR missions and the second mode indicates the actual SAR mission of the UAV. STPA was applied in both operational modes and identified new safety specifications between the technical components of the system and the human administration during the preparation phase, during the checks between each SAR mission and also on the interactions involving the \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ZzxSO8QAAAAJ:z62hWG5Wpo0C",
            "Publisher": "IEEE"
        },
        {
            "Title": "Sparse pose manifolds",
            "Publication year": 2014,
            "Publication url": "https://link.springer.com/article/10.1007/s10514-014-9388-x",
            "Abstract": "The efficient manipulation of randomly placed objects relies on the accurate estimation of their 6 DoF geometrical configuration. In this paper we tackle this issue by following the intuitive idea that different objects, viewed from the same perspective, should share identical poses and, moreover, these should be efficiently projected onto a well-defined and highly distinguishable subspace. This hypothesis is formulated here by the introduction of pose manifolds relying on a bunch-based structure that incorporates unsupervised clustering of the abstracted visual cues and encapsulates appearance and geometrical properties of the objects. The resulting pose manifolds represent the displacements among any of the extracted bunch points and the two foci of an ellipse fitted over the members of the bunch-based structure. We post-process the established pose manifolds via  norm minimization so as to build \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ZzxSO8QAAAAJ:Zp9IZb6oESQC",
            "Publisher": "Springer US"
        },
        {
            "Title": "ROBVISION Vision Based Navigation for Mobile Robots",
            "Publication year": 2001,
            "Publication url": "https://vbn.aau.dk/en/publications/robvision-vision-based-navigation-for-mobile-robots",
            "Abstract": "ROBVISION Vision Based Navigation for Mobile Robots \u2014 Aalborg University's Research \nPortal Skip to main navigation Skip to search Skip to main content Aalborg University's \nResearch Portal Logo Dansk English Home Profiles Projects Publications Activities Research \nUnits Facilities Press / Media Prizes Datasets Impacts Search by keywords, name or affiliation \nROBVISION Vision Based Navigation for Mobile Robots M. Ayromlou, C. Beltran, A. \nGasteratos, Ole Madsen, W. Ponweiser, US Bititci Research output: Contribution to book/anthology/report/conference \nproceeding \u203a Article in proceeding \u203a Research 9 Citations (Scopus) Overview Original \nlanguage English Title of host publication Proceedings of OAGM 2001 Editors S. Scherer \nPublication date 2001 Publication status Published - 2001 Event OAGM 2001, 25th Workshop \nof the AAPR, June 7-8 2001 - Bavaria, Germany, Germany Duration: 19 May 2010 \u2192 \u2026 , /\u2026",
            "Abstract entirety": 0,
            "Author pub id": "ZzxSO8QAAAAJ:isC4tDSrTZIC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Armour W: see Merrifield DR 115703 Aroussi A: see Lad N 064003 Arthington MR, Siviour CR, Petrinic N and Elliott BCF: Optical surface profile tracking for high-resolution strain measurement 025304",
            "Publication year": 2011,
            "Publication url": "https://iopscience.iop.org/article/10.1088/0957-0233/22/12/129901/meta",
            "Abstract": "Asami K: Design of a measurement cell for low-frequency dielectric spectroscopy of biological cell suspensions 085801 Asano Y: see Yamazaki M 075602 Ashok A: see Hultmark M 055401 Asundi AK: see Huang L 035304 Atieh Z, Allouche AR, Graveron-Demilly D and Aubert-Fr\u00e9con M: Density functional theory (DFT) calculations of the proton nuclear magnetic resonance (NMR) spin-Hamiltonian parameters for serine 114015 Attota R and Silver R: Nanometrology using a through-focus scanning optical microscopy method 024002 Attota R: see Barnes BM 024003 Attridge A: see Kumar J 035105 Aubert-Fr\u00e9con M: see Atieh Z 114015 Aubert-Fr\u00e9con M: see Lazariev A 114020 Awaji S: see Takahashi K 035703 Axford D: see Merrifield DR 115703 Ayaz UK, Ioppolo T and Ot\u00fcgen MV: Wall shear stress sensor based on the optical resonances of dielectric microspheres 075203",
            "Abstract entirety": 1,
            "Author pub id": "ZzxSO8QAAAAJ:IT5EXw6i2GUC",
            "Publisher": "Unknown"
        },
        {
            "Title": "An adaptive fuzzy system for the control of the vergence angle on a robotic head",
            "Publication year": 2010,
            "Publication url": "https://content.iospress.com/articles/journal-of-intelligent-and-fuzzy-systems/ifs459",
            "Abstract": "An important issue in realizing robots with stereo vision is the efficient control of the vergence angle. In an active robotic vision system the vergence angle along with the pan and tilt ones determines uniquely the fixation point in the 3D space. The vergence control involves the adjustment of the angle between the two cameras\u2019 axes towards the fixation point and, therefore, it enables the robot to perceive depth and to compute obstacle maps. Vergence movement is directly related to the binocular fusion. Additionally, the decision for convergence or divergence is extracted either by motion affine models or by mathematical ones. In this paper, a new method for extracting the cameras\u2019 movement direction is presented. The movement decision is performed by an adaptive fuzzy control system, the inputs of which are the zero-mean normalized cross correlation (ZNCC) and the depth estimations at each time step. The \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ZzxSO8QAAAAJ:ZHo1McVdvXMC",
            "Publisher": "IOS Press"
        },
        {
            "Title": "Acknowledgment to Reviewers of Robotics in 2020.",
            "Publication year": 2021,
            "Publication url": "https://scholar.google.com/scholar?cluster=6504659464008422909&hl=en&oi=scholarr",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "ZzxSO8QAAAAJ:1n-LKbgTOzoC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Towards orbital based global rover localization",
            "Publication year": 2015,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/7139591/",
            "Abstract": "Space exploratory rovers do well in autonomous or composite semi-autonomous exploration of extraterrestrial surfaces, yet their localization relies on the particular spot they had landed, rather than being universal, i.e. based on the absolute coordinate system of the explored planet. The idea underlaying the work presented in this paper is the transition from the relative to absolute localization by inspecting common Regions of Interest (ROIs) on both rover and orbital imagery. In order to achieve that we propose a method comprising an offline and an onboard procedure. Particularly, prior to the mission the orbital images of the intended landing area are examined to extract ROIs and to construct an offline Global Network (GN). The onboard procedure is based on the rover's self localization which is performed via an inertial aided visual odometry (VO). During its roaming the rover extracts ROIs from the ground and \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ZzxSO8QAAAAJ:whNN5KpgZFsC",
            "Publisher": "IEEE"
        },
        {
            "Title": "A Dense Stereo Correspondence Algorithm for Hardware",
            "Publication year": 2008,
            "Publication url": "https://scholar.google.com/scholar?cluster=83950603885303939&hl=en&oi=scholarr",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "ZzxSO8QAAAAJ:ziW8EwMpto0C",
            "Publisher": "Unknown"
        },
        {
            "Title": "SPARTAN system: Towards a low-cost and high-performance vision architecture for space exploratory rovers",
            "Publication year": 2011,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/6130493/",
            "Abstract": "The \u201cSPAring Robotics Technologies for Autonomous Navigation\u201d (SPARTAN) activity of the European Space Agency (ESA) aims to develop an efficient, low-cost and accurate vision system for the future Martian exploratory rovers. The interest on vision systems for space robots has been steadily growing during the last years. The SPARTAN system considers an optimal implementation of computer vision algorithms for space rover navigation and is designated for application to a space exploratory robotic rover, such as the ExoMars. The goal of the present work is the development of an appropriate architecture for the vision system. Thus, the arrangement and characteristics of the rover's vision sensors will be defined and the required computer vision modules will be presented. The analysis will be performed taking into consideration the constraints defined by ESA about the SPARTAN system.",
            "Abstract entirety": 1,
            "Author pub id": "ZzxSO8QAAAAJ:nb7KW1ujOQ8C",
            "Publisher": "IEEE"
        },
        {
            "Title": "ROLFER: An innovative proactive platform to reserve swimmer\u2019s safety",
            "Publication year": 2017,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-319-67633-3_5",
            "Abstract": "The major problem of an emergency situation is the immediate reaction and the rescue assistance when people call for help. The response time is a vital factor in search and rescue (SAR) operations, owed to the fact that potential delays may have dramatic and even lethal results. Moreover, the safety of rescue workers is another major issue and must be ensured in any circumstance. SAR operations can greatly benefit from the use of Unmanned Aerial Vehicles (UAV) to reduce the time to detect the victim and provide him/her invaluable assistance. UAVs are nimble, quick-moving and can be easily programmed to exhibit autonomous behaviors. Thus, they are able to operate in difficult environments and under circumstances onerous for humans to cope with. This paper presents ROLFER (RObotic Lifeguard For Emergency Rescue), a completely autonomous robotic aerial system for immediate provision of \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ZzxSO8QAAAAJ:zuN7wi50mysC",
            "Publisher": "Springer, Cham"
        },
        {
            "Title": "Extraction of salient contours in color images",
            "Publication year": 2006,
            "Publication url": "https://link.springer.com/chapter/10.1007/11752912_40",
            "Abstract": "In this paper we present an artificial cortical network, inspired by the Human Visual System (HVS), which extracts the salient contours in color images. Similarly to the primary visual cortex, the network consists of orientation hypercolumns. Lateral connections between the hypercolumns are modeled by a new connection pattern based on co-exponentiality. The initial color edges of the image are extracted in a way inspired by the double-opponent cells of the HVS. These edges are inputs to the network, which outputs the salient contours based on the local interactions between the hypercolumns. The proposed network was tested on real color images and displayed promising performance, with execution times small enough even for a conventional personal computer.",
            "Abstract entirety": 1,
            "Author pub id": "ZzxSO8QAAAAJ:4JMBOYKVnBMC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "Three-dimensional scene reconstruction: A review of approaches",
            "Publication year": 2012,
            "Publication url": "https://www.igi-global.com/chapter/depth-map-imaging-applications/60264",
            "Abstract": "The production of 3D models has been a popular research topic already for a long time, and important progress has been made since the early days. During the last decades, vision systems have established to become the standard and one of the most efficient sensorial assets in industrial and everyday applications. Due to the fact that vision provides several vital attributes, many applications tend to use novel vision systems into domestic, working, industrial, and any other environments. To achieve such goals, a vision system should robustly and effectively reconstruct the 3D surface and the working space. This chapter discusses different methods for capturing the three-dimensional surface of a scene. Geometric approaches to three-dimensional scene reconstruction are generally based on the knowledge of the scene structure from the camera\u2019s internal and external parameters. Another class of methods \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ZzxSO8QAAAAJ:PN3Jufe71OMC",
            "Publisher": "IGI global"
        },
        {
            "Title": "A comparative study of invariant descriptors for shape retrieval",
            "Publication year": 2009,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/5071672/",
            "Abstract": "This paper presents a comparative study between scale, rotation and translation invariant descriptors for shape representation and retrieval. Specifically, we studied Fourier, angular radial transform and image moment descriptors for shape representation. Since shape is one of the most widely used image feature exploited in content-based image retrieval systems, we studied for each descriptor, the number of coefficients needed for indexing and their retrieval performance. Results showed that moment descriptors present the best performance in both terms of shape representation quality as well as in the amount of required coefficients.",
            "Abstract entirety": 1,
            "Author pub id": "ZzxSO8QAAAAJ:LkGwnXOMwfcC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Enhancing satellite semantic maps with ground-level imagery",
            "Publication year": 2021,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S0921889021000452",
            "Abstract": "The paper at hand introduces a novel system for producing an enhanced semantic map that leverages a reconstruction approach of street-view scenes using computer vision and machine learning techniques. Focusing on the recognition and localization of objects/entities, the composed map combines semantic information from publicly available, yet of lower accuracy, satellite images, with more detailed data from ground-level camera measurements. This merging is achieved by utilizing odometry information from a street-moving vehicle and the 3D reconstruction of its recorded view. Then, the 3D semantic segmentation results are georeferenced and superimposed on the semantic map from the satellite images. In such a way, areas that require fine semantic accuracy can be improved, while the rest are left with the segmentation results of the satellite information. Every part of the proposed system is individually \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ZzxSO8QAAAAJ:EXDW3tg14iEC",
            "Publisher": "North-Holland"
        },
        {
            "Title": "Morphological edge detector implemented in quantum cellular automata",
            "Publication year": 2013,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/6729731/",
            "Abstract": "Non-linear morphological edge detectors have been proven to be robust in the presence of noise and able to discriminate between edges and regions corrupted by noise. In this paper a novel non-linear morphological edge detector is presented when implemented as a compact circuit on Quantum Cellular Automata (QCA) in crossbar nanoelectronic architecture. The proposed QCA implementation provides high circuit performance, very low dimensions, parallel processing and very low power consumption. Moreover, the presented QCA circuit design obeys with the QCA design rules while focusing on circuit functionality robustness and thereafter provides real time image processing. The corresponding simulation results indicate the efficiency of the proposed circuitry.",
            "Abstract entirety": 1,
            "Author pub id": "ZzxSO8QAAAAJ:UO8fSLLLPykC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Semantic mapping for mobile robotics tasks: A survey",
            "Publication year": 2014,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S0921889014003030",
            "Abstract": "The evolution of contemporary mobile robotics has given thrust to a series of additional conjunct technologies. Of such is the semantic mapping, which provides an abstraction of space and a means for human\u2013robot communication. The recent introduction and evolution of semantic mapping motivated this survey, in which an explicit analysis of the existing methods is sought. The several algorithms are categorized according to their primary characteristics, namely scalability, inference model, temporal coherence and topological map usage. The applications involving semantic maps are also outlined in the work at hand, emphasizing on human interaction, knowledge representation and planning. The existence of publicly available validation datasets and benchmarking, suitable for the evaluation of semantic mapping techniques is also discussed in detail. Last, an attempt to address open issues and questions is also \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ZzxSO8QAAAAJ:AUmYgNQ2pq4C",
            "Publisher": "North-Holland"
        },
        {
            "Title": "Review of stereo vision algorithms: from software to hardware",
            "Publication year": 2008,
            "Publication url": "https://www.tandfonline.com/doi/abs/10.1080/15599610802438680",
            "Abstract": "Stereo vision, resulting in the knowledge of deep information in a scene, is of great importance in the field of machine vision, robotics and image analysis. In this article, an explicit analysis of the existing stereo matching methods, up to date, is presented. The presented algorithms are discussed in terms of speed, accuracy, coverage, time consumption, and disparity range. Towards the direction of real-time operation, the development of stereo matching algorithms, suitable for efficient hardware implementation is highly desirable. Implementations of stereo matching algorithms in hardware for real-time applications are also discussed in details.",
            "Abstract entirety": 1,
            "Author pub id": "ZzxSO8QAAAAJ:IjCSPb-OGe4C",
            "Publisher": "Taylor & Francis Group"
        },
        {
            "Title": "Assigning visual words to places for loop closure detection",
            "Publication year": 2018,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/8461146/",
            "Abstract": "Place recognition of pre-visited areas, widely known as Loop Closure Detection (LCD), constitutes one of the most important components in robotic applications, where the robot needs to estimate its pose while navigating through the field (e.g., simultaneous localization and mapping). In this paper, we present a novel approach for LCD based on the assignment of Visual Words (VWs) to particular places of the traversed path. The system operates in real time and does not require any pre-training procedure, such as visual vocabulary construction or descriptor-space dimensionality reduction. A place is defined through a dynamic segmentation of the incoming image stream and is assigned with VWs through the usage of an on-line clustering algorithm. At query time, image descriptors are converted into VWs on the map accumulating votes to the corresponding places. By means of a probability function, the \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ZzxSO8QAAAAJ:RW1BPcyHXiwC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Multi-camera 3D object reconstruction for industrial automation",
            "Publication year": 2012,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-642-40352-1_66",
            "Abstract": "In this paper, a method to automate industrial manufacturing processes using an intelligent multi-camera system to assist a robotic arm on a production line is presented. The examined assembly procedure employs a volumetric method for the initial estimation of object\u2019s properties and an octree decomposition process to generate the path plans for the robotic arm. Initially, the object is captured by four cameras and its volumetric representation is produced. Thereafter, a quality check with its respective CAD model is performed and the final details of the 3D model are refined. An octree decomposition technique is utilized afterwards to facilitate the automatic generation of the assembly path plans and translate them to a sequence of movements for the robotic arm. The algorithm is fast, computationally simple and produces an assembly sequence that can be translated to any major robotic programming \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ZzxSO8QAAAAJ:1qzjygNMrQYC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "An intelligent tool for the automated evaluation of pedestrian simulation",
            "Publication year": 2014,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-319-07064-3_12",
            "Abstract": "One of the most cumbersome tasks in the implementation of an accurate pedestrian model is the calibration and fine tuning based on real life experimental data. Traditionally, this procedure employs the manual extraction of information about the position and locomotion of pedestrians in multiple videos. The paper in hand proposes an automated tool for the evaluation of pedestrian models. It employees state of the art techniques for the automated 3D reconstruction, pedestrian detection and data analysis. The proposed method constitutes a complete system which, given a video stream, automatically determines both the workspace and the initial state of the simulation. Moreover, the system is able to track the evolution of the movement of pedestrians. The evaluation of the quality of the pedestrian model is performed via automatic extraction of critical information from both real and simulated data.",
            "Abstract entirety": 1,
            "Author pub id": "ZzxSO8QAAAAJ:BQCiT8P4igIC",
            "Publisher": "Springer, Cham"
        },
        {
            "Title": "A rotational and translational image stabilization system for remotely operated robots",
            "Publication year": 2007,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/4258802/",
            "Abstract": "Remotely operated robots equipped with on board cameras, apart from providing video input to operators, perform optical measurements to assist their navigation as well. Such image processing algorithms require image sequences, free of high frequency unwanted movements, in order to generate their optimal results. Image stabilization is the process which removes the undesirable position fluctuations of a video sequence improving, therefore, its visual quality. In this paper, we introduce the implementation of an image stabilization system that utilizes input from an on board camera and a gyrosensor. The frame sequence is processed by an optic flow algorithm and the inertial data is processed by a discrete Kalman filter. The compensation is performed using two servo motors for the pan and tilt movements and frame shifting for the vertical and horizontal movements. Experimental results of the robot head, have \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ZzxSO8QAAAAJ:aqlVkmm33-oC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Optimum multi-camera arrangement using a bee colony algorithm",
            "Publication year": 2012,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/6295580/",
            "Abstract": "This paper presents a new method for designing multi-camera arrangements with aim to maximize coverage with the minimum number of cameras. More specifically, the presented problem has three different components, namely (a) to maximize the coverage subject to a given number of cameras (b) to optimize the camera topology given fixed locations and (c) to minimize the cost of the arrangement, while the least required percentage of coverage is provided. In order to solve these problems, a bee colony algorithm is utilized as an optimization technique that is able to determine the minimum number of cameras needed to cover the given space completely while taking into consideration the minimum possible cost for the proposed arrangement as well. The algorithm employs several camera placement constraints referring to geometrical, optical as well as reconstructive limitations and delivers promising \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ZzxSO8QAAAAJ:K3LRdlH-MEoC",
            "Publisher": "IEEE"
        },
        {
            "Title": "A new method to combine detection and tracking algorithms for fast and accurate human localization in UAV-based SAR operations",
            "Publication year": 2020,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/9213873/",
            "Abstract": "This paper presents the study and the evaluation of GPS/GNSS techniques combined with advanced image processing algorithms for the precise detection, positioning and tracking of distressed humans. In particular, the issue of human detection on both terrestrial and marine environments, as the human silhouette in a marine environment may differ substantially from a land one, is addressed. A robust approach, including an adaptive distressed human detection algorithm running every N input image frames combined with a much faster human tracking algorithm, is proposed. Real time or near-real-time distressed human detection rates, under several illumination and background conditions, can be achieved using a single, low cost day/night NIR camera. It is mounted onboard a fully autonomous UAV for Search and Rescue (SAR) missions. Moreover, the collection of a novel dataset, suitable for training the \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ZzxSO8QAAAAJ:JjBZBFkNMTQC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Vision-based product tracking method for cyber-physical production systems in industry 4.0",
            "Publication year": 2018,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/8577189/",
            "Abstract": "A competitive company should possess the ability to rapidly adopt to changes and the new era of the fourth industrial revolution (Industry 4.0) puts forward an incredible reshaping of the entire manufacturing sector. The primary goal of Industry 4.0 should be to transform the massive production lines from a system-based scheme to a product-based one, while individuals and cyber-physical systems (CPSs) should interact with each other and with objects. This advantage can be achieved in a smart factory, so as to allow product tracking all the way through manufacturing by interacting with any other factory component via cloud computing. Towards this end, in this paper we propose a vision-oriented method, which utilizes detection and tracking along with a cloud-based platform to facilitate product tracking and interaction. The proposed method make use of a panoramic camera composing a CPS, which a part of a \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ZzxSO8QAAAAJ:A5aiAONn640C",
            "Publisher": "IEEE"
        },
        {
            "Title": "A multi-objective exploration strategy for mobile robots under operational constraints",
            "Publication year": 2013,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/6605521/",
            "Abstract": "Multi-objective robot exploration constitutes one of the most challenging tasks for autonomous robots performing in various operations and different environments. However, the optimal exploration path depends heavily on the objectives and constraints that both these operations and environments introduce. Typical environment constraints include partially known or completely unknown workspaces, limited-bandwidth communications, and sparse or dense clattered spaces. In such environments, the exploration robots must satisfy additional operational constraints, including time-critical goals, kinematic modeling, and resource limitations. Finding the optimal exploration path under these multiple constraints and objectives constitutes a challenging non-convex optimization problem. In our approach, we model the environment constraints in cost functions and utilize the cognitive-based adaptive optimization algorithm \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ZzxSO8QAAAAJ:bnK-pcrLprsC",
            "Publisher": "IEEE"
        },
        {
            "Title": "A System to Navigate a Robot into a Ship Structure",
            "Publication year": 2001,
            "Publication url": "https://scholar.google.com/scholar?cluster=15126281101005186058&hl=en&oi=scholarr",
            "Abstract": "A prototype system has been built to navigate a walking robot into a ship structure. The robot is equipped with a stereo head for monocular and stereo vision. From the CAD-model of the ship good viewpoints are selected such that the head can look at locations with sufficient features. The edge features for the views are extracted automatically. The pose of the robot is estimated from the features detected by two vision approaches. One approach searches in the full image for junctions and uses the stereo information to extract 3D information. The other method is monocular and tracks 2D edge features. To achieve robust tracking of the features a model-based tracking approach is enhanced with a method of Edge Projected Integration of Cues (EPIC). EPIC uses object knowledge to select the correct features in real-time. The two vision systems are synchronised by sending the images over a fibre channel network. The pose estimation uses both the 2D and 3D features and locates the robot within a few centimetres over the range of ship cells of several metres. Gyros are used to stabilise the head while the robot moves. The system has been developed within the Rob Vision project and the results of the final demonstration are given.",
            "Abstract entirety": 1,
            "Author pub id": "ZzxSO8QAAAAJ:Ow2R9nchCv8C",
            "Publisher": "Springer"
        },
        {
            "Title": "HDPR: A mobile testbed for current and future rover technologies",
            "Publication year": 2016,
            "Publication url": "https://qspace.library.queensu.ca/handle/1974/15004",
            "Abstract": "The paper in hand presents a mobile testbed \u2013namely the Heavy Duty Planetary Rover (HDPR)\u2013 that was designed and constructed at the Automation and Robotics Laboratories (ARL) of the European Space Agency to fulfill the lab\u2019s internal needs in the context of long range rover exploration as well as in order to provide the means to perform in situ testing of novel algorithms. We designed a rover that: a) is able to reliably perform long range routes, and b) carries an abundant of sensors (both current rover technology and futuristic ones). The testbed includes all the additional hardware and software (i.e. ground control station, UAV, networking, mobile power) to allow the prompt deployment on the field. The reader can find in the paper the description of the system as well as a report on our experiences during our first experiments with the testbed.",
            "Abstract entirety": 1,
            "Author pub id": "ZzxSO8QAAAAJ:Es-9c2L5hKwC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Safety bounds in human robot interaction: A survey",
            "Publication year": 2020,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S0925753520300643",
            "Abstract": "In the era of industrialization and automation, safety is a critical factor that should be considered during the design and realization of each new system that targets operation in close collaboration with humans. Of such systems are considered personal and professional service robots which collaborate and interact with humans at diverse applications environments. In this collaboration, human safety is an important factor in the wider field of human-robot interaction (HRI) since it facilitates their harmonic coexistence. The paper at hand aims to systemize the recent literature by describing the required levels of safety during human-robot interaction, focusing on the core functions of the collaborative robots when performing specific processes. It is also oriented towards the existing methods for psychological safety during human-robot collaboration and its impact at the robot behaviour, while also discusses in depth the \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ZzxSO8QAAAAJ:xpFxhiwfz1QC",
            "Publisher": "Elsevier"
        },
        {
            "Title": "Stereo vision for robotic applications in the presence of non-ideal lighting conditions",
            "Publication year": 2010,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S0262885609002674",
            "Abstract": "Many robotic and machine-vision applications rely on the accurate results of stereo correspondence algorithms. However, difficult environmental conditions, such as differentiations in illumination depending on the viewpoint, heavily affect the stereo algorithms\u2019 performance. This work proposes a new illumination-invariant dissimilarity measure in order to substitute the established intensity-based ones. The proposed measure can be adopted by almost any of the existing stereo algorithms, enhancing it with its robust features. The performance of the dissimilarity measure is validated through experimentation with a new adaptive support weight (ASW) stereo correspondence algorithm. Experimental results for a variety of lighting conditions are gathered and compared to those of intensity-based algorithms. The algorithm using the proposed dissimilarity measure outperforms all the other examined algorithms, exhibiting \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ZzxSO8QAAAAJ:8k81kl-MbHgC",
            "Publisher": "Elsevier"
        },
        {
            "Title": "Stereovision-based fuzzy obstacle avoidance method",
            "Publication year": 2011,
            "Publication url": "https://www.worldscientific.com/doi/abs/10.1142/S0219843611002381",
            "Abstract": "This work presents a stereovision-based obstacle avoidance method for autonomous mobile robots. The decision about the direction on each movement step is based on a fuzzy inference system. The proposed method provides an efficient solution that uses a minimum of sensors and avoids computationally complex processes. The only sensor required is a stereo camera. First, a custom stereo algorithm provides reliable depth maps of the environment in frame rates suitable for a robot to move autonomously. Then, a fuzzy decision making algorithm analyzes the depth maps and deduces the most appropriate direction for the robot to avoid any existing obstacles. The proposed methodology has been tested on a variety of self-captured outdoor images and the results are presented and discussed.",
            "Abstract entirety": 1,
            "Author pub id": "ZzxSO8QAAAAJ:vV6vV6tmYwMC",
            "Publisher": "World Scientific Publishing Company"
        },
        {
            "Title": "SPARTAN/SEXTANT/COMPASS: advancing space rover vision via reconfigurable platforms",
            "Publication year": 2015,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-319-16214-0_44",
            "Abstract": "Targeting enhanced navigational speed and autonomy for the space exploration rovers, researchers are gradually turning to reconfigurable computing and FPGAs. High-density space-grade FPGAs will enable the acceleration of high-complexity computer vision algorithms for improving the localization and mapping functions of the future Mars rovers. In the projects SPARTAN/SEXTANT/COMPASS of the European Space Agency, we study the potential use of FPGAs for implementing a variety of stereo correspondence, feature extraction, and visual odometry algorithms, all with distinct cost-performance tradeoffs. The most efficient of the developed accelerators will assist the slow space-grade CPU in completing the visual tasks of the rover faster, by one order of magnitude, and thus, will allow the future missions to visit larger areas on Mars. Our work bases on a custom HW/SW co-design methodology \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ZzxSO8QAAAAJ:in81wS_EFI4C",
            "Publisher": "Springer, Cham"
        },
        {
            "Title": "Remotely Operated Robots",
            "Publication year": 2010,
            "Publication url": "https://books.google.com/books?hl=en&lr=&id=v_ugDwAAQBAJ&oi=fnd&pg=PA59&dq=info:t5PZdy1DljEJ:scholar.google.com&ots=FJuAypaBII&sig=0s5Ke_jyk2_R5BEavmnCdM3TtJQ",
            "Abstract": "Remotely operated robots, functioning in hazardous and time critical environments, have significant requirements for control and visual information (Davids (2002), Murphy (2004)). The control systems are supposed to guarantee a precise timely response in order to prevent fatal scenarios in bomb disposal operations or in life rescue missions. Significant role to these operating scenarios play the concurrent visual information provided to the remote operators by the on-board mounted cameras.Visual information (Fong & Thorpe (2001), Desouza & Kak (2002)) is often displayed in one or more monitors depending on the number of on-board mounted cameras. In sophisticated and multi-tasking robots more than one operators are performing certain actions. Especially, in case of robots with grippers and robotic arms, one operator might be dedicated only with the maneuvering and controlling of the robotic arms or grippers. In these operation scenarios, the dedicated user must be focused only on this task and furthermore should have the best visual understanding of the working field. The widely used equipment and gear for these assignments is a Head Mounted Display (HMD) and an attached head tracker. The HMD projects visual feedback of the remote robot in front of operator eyes. A single camera feedback projection in both eyes is not so significant since the result in operator\u2019s perception is the same as being watched from a single monitor. Thus, a pair of cameras are used instead, in order to provide a real stereo feedback to the operator\u2019s HMD, thus enhancing his visual perception and improving the sense of depth (Willemsen et al.(2004 \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ZzxSO8QAAAAJ:f2IySw72cVMC",
            "Publisher": "BoD\u2013Books on Demand"
        },
        {
            "Title": "A system to navigate a robot into a ship structure",
            "Publication year": 2003,
            "Publication url": "https://link.springer.com/article/10.1007/s00138-002-0098-6",
            "Abstract": " Abstract. A prototype system has been built to navigate a walking robot into a ship structure. The 8-legged robot is equipped with an active stereo head. From the CAD-model of the ship good view points are selected, such that the head can look at locations with sufficient edge features, which are extracted automatically for each view. The pose of the robot is estimated from the features detected by two vision approaches. One approach searches in stereo images for junctions and measures the 3-D position. The other method uses monocular image and tracks 2-D edge features. Robust tracking is achieved with a method of edge projected integration of cues (EPIC). Two inclinometres are used to stabilise the head while the robot moves. The results of the final demonstration to navigate the robot within centimetre accuracy are given.",
            "Abstract entirety": 1,
            "Author pub id": "ZzxSO8QAAAAJ:roLk4NBRz8UC",
            "Publisher": "Springer-Verlag"
        },
        {
            "Title": "Dense disparity estimation using a hierarchical matching technique from uncalibrated stereo vision",
            "Publication year": 2009,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/5071680/",
            "Abstract": "In motion estimation, the sub-pixel matching technique involves the search of sub-sample positions as well as integer-sample positions between the image pairs, choosing the one that gives the best match. Based on this idea, the proposed disparity estimation algorithm performs a 2-D correspondence search using a hierarchical search pattern. The disparity value is then defined using the distance of the matching position. Therefore, the proposed algorithm can process non-rectified stereo image pairs, maintaining the computational load within reasonable levels.",
            "Abstract entirety": 1,
            "Author pub id": "ZzxSO8QAAAAJ:RYcK_YlVTxYC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Tracking\u2010DOSeqSLAM: A dynamic sequence\u2010based visual place recognition paradigm",
            "Publication year": 2021,
            "Publication url": "https://www.researchgate.net/profile/Konstantinos-Tsintotas/publication/350770254_Tracking-DOSeqSLAM_A_dynamic_sequence-based_visual_place_recognition_paradigm/links/60741d2692851c8a7bbef327/Tracking-DOSeqSLAM-A-dynamic-sequence-based-visual-place-recognition-paradigm.pdf",
            "Abstract": "Simultaneous localization and mapping (SLAM) refers to a process that permits a mobile robot to build up a map of the environment and, at the same time, to use it to compute its location. One of its most important components is its ability to associate the most recently perceived visual measurement to the one derived from previsited locations, a technique widely known as loop closure detection. In this article, we evolve our previous approach, dubbed as \u2018DOSeqSLAM\u2019by presenting a low complexity loop closure detection pipeline wherein the traversed trajectory (map) is represented by sequence\u2010based locations (submaps). Each of these groups of images, referred to as place, is generated online through a point tracking repeatability check employed on the perceived visual sensory information. When querying the database, the proper candidate place is selected and, through an image\u2010to\u2010image search, the appropriate location is chosen. The method is subjected to an extensive evaluation on seven publicly available datasets, revealing a substantial improvement in computational complexity and performance over its predecessors, while performing favourably against other state\u2010of\u2010the art solutions. The system\u2019s effectiveness is owed to the reduced number of places, which, compared to the original approach, is at least one order of magnitude less.",
            "Abstract entirety": 1,
            "Author pub id": "ZzxSO8QAAAAJ:prvsfHNhuEoC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Robot guided crowd evacuation",
            "Publication year": 2014,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/6824875/",
            "Abstract": "The congregation of crowd undoubtedly constitutes an important risk factor, which may endanger the safety of the gathered people. The solution reported against this significant threat to citizens safety is to consider careful planning and measures. Thereupon, in this paper, we address the crowd evacuation problem by suggesting an innovative technological solution, namely, the use of mobile robot agents. The contribution of the proposed evacuation system is twofold: (i) it proposes an accurate Cellular Automaton simulation model capable of assessing the human behavior during emergency situations and (ii) it takes advantage of the simulation output to provide sufficient information to the mobile robotic guide, which in turn approaches and redirects a group of people towards a less congestive exit at a time. A custom-made mobile robotic platform was accordingly designed and developed. Last, the performance of \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ZzxSO8QAAAAJ:4_yl7nwqy4oC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Global Localization for Future Space Exploration Rovers",
            "Publication year": 2017,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-319-68345-4_8",
            "Abstract": "In the context of robotic space exploration the problem of autonomous global or absolute localization remains unsolved. Current rovers require human in the loop approaches to acquire global positioning. In this paper we assess this problem by refining our previous work in a way that advances the performance of the system while making the procedure feasible for real implementation on rovers. A map of semantic landmarks (the Global Network - GN) is extracted on an area that the rover traverses prior to the mission and, during the exploration, a Local Network (LN) is built and matched to estimate rover\u2019s global location. We have optimized several aspects of the system: the motion estimation, the detection and classification \u2013by benchmarking several classifiers\u2013 and we have tested the system in a Mars like scenario. With the aim to achieve realistic terms in our scenario a custom robotic platform was \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ZzxSO8QAAAAJ:Qovp55VTycgC",
            "Publisher": "Springer, Cham"
        },
        {
            "Title": "Visual odometry for autonomous robot navigation through efficient outlier rejection",
            "Publication year": 2013,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/6729660/",
            "Abstract": "The ability of autonomous robots to precisely compute their spatial coordinates constitutes an important attribute. In this regard, Visual Odometry (VO) becomes a most appropriate tool, in estimating the full pose of a camera, placed onboard a robot by analyzing a sequence of images. The paper at hand proposes an accurate computationally-efficient VO algorithm relying exclusively on stereo vision. A non-iterative outlier detection technique capable of efficiently discarding outliers of matched features is suggested. The developed technique is combined with an incremental motion estimation approach to estimate the robot's trajectory. The accuracy of the proposed system has been evaluated both on simulated data and using a real robotic platform. Experimental results from rough terrain routes show remarkable accuracy with positioning errors as low as 1.1%.",
            "Abstract entirety": 1,
            "Author pub id": "ZzxSO8QAAAAJ:t6usbXjVLHcC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Computer vision systems",
            "Publication year": 2008,
            "Publication url": "https://repository.vnu.edu.vn/handle/VNU_123/27888",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "ZzxSO8QAAAAJ:P5iVsrg4GywC",
            "Publisher": "Springer"
        },
        {
            "Title": "Image retrieval based on fuzzy color histogram processing",
            "Publication year": 2005,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S0030401804013069",
            "Abstract": "Content-based image retrieval (CBIR) is a collection of techniques for retrieving images on the basis of features, such as color, texture and shape. An efficient tool, which is widely used in CBIR, is that of color image histograms. The classic method of color histogram creation results in very large histograms with large variations between neighboring bins. Thus, small changes in the image might result in great changes in the histogram. Moreover, the fact that each color space consists of three components leads to 3-dimensional histograms. Manipulating and comparing 3D histograms is a complicated and computationally expensive procedure. The need, therefore, for reduction of the three dimensions to one could lead to efficient approaches. This procedure of projecting the 3D histogram onto one single-dimension histogram is called histogram linking. In this paper, a new fuzzy linking method of color histogram \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ZzxSO8QAAAAJ:9yKSN-GCB0IC",
            "Publisher": "North-Holland"
        },
        {
            "Title": "Graph-based semantic segmentation",
            "Publication year": 2018,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-030-00232-9_60",
            "Abstract": "This work deals with the graph-based semantic segmentation of a robot\u2019s traversed environment using the Louvain algorithm. In recent years, semantic segmentation has been the focus of several researchers\u2019 interest and is applied to a variety of robotic applications. The Louvain method for community detection is a novel technique for extracting communities from large networks. The method is a greedy optimization one with a complexity of O(nlogn). We first assessed the Louvain algorithm with the COLD-Freiburg dataset to create the semantic map and compute the communities. We demonstrate that lighting conditions do not affect the system\u2019s ability to categorize places. In particular, we train the system with COLD Freiburg seg1cloudy1 and we query images from seg1sunny1 and seg1night1. The results exhibit that the system is capable of categorizing the evaluated frames into the correct community.",
            "Abstract entirety": 1,
            "Author pub id": "ZzxSO8QAAAAJ:r5yabEp13iMC",
            "Publisher": "Springer, Cham"
        },
        {
            "Title": "Real-Time Robot Path Planning for Dynamic Obstacle Avoidance.",
            "Publication year": 2014,
            "Publication url": "http://search.ebscohost.com/login.aspx?direct=true&profile=ehost&scope=site&authtype=crawler&jrnl=15575969&AN=98321903&h=PbqDhtIJseS3yHMVoDNGdXwIhIGH2eYrRH%2BNnIxvdFiB0ZAx1xz%2FIiEQf7JdNRgGv2GeQLXgYm7qmDrvAIwUzw%3D%3D&crl=c",
            "Abstract": "In this paper we present a method based on Cellular Automata (CA) rules, suitable for path planning in dynamically changing environments. The algorithm underlaying this method is the A* search one in combination with CAs, the discrete nature of which renders the method appropriate for both robot and obstacle state spaces. Moreover, the finite properties of the A* algorithm were amalgamated with the CA rules to built up a substantial search strategy. The proposed algorithm assures a collision-free cost-efficient path to target with optimal computational cost. The algorithm's main attribute is that it expands the map state space with respect to time using adaptive time intervals to predict the potential expansion of obstacles, assuring a safe and minimum cost path. The proposed method has been examined in real world planar environments and exhibits remarkable performance, thus it can be applied to any arbitrary \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ZzxSO8QAAAAJ:-152x6qmK5kC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Imaging systems and techniques 2011",
            "Publication year": 2012,
            "Publication url": "https://iopscience.iop.org/article/10.1088/0957-0233/23/11/110101/meta",
            "Abstract": "This special feature on Imaging Systems and Techniques comprises 11 papers, covering essential facets in imaging systems and techniques both in theory and applications, from research groups in three different continents. It mainly contains peer-reviewed articles from the IEEE International Conference on Imaging Systems and Techniques (IST 2011), held in Batu Ferringi, Penang, Malaysia, as well a number of articles relevant to the scope of this issue.",
            "Abstract entirety": 1,
            "Author pub id": "ZzxSO8QAAAAJ:5Ul4iDaHHb8C",
            "Publisher": "IOP Publishing"
        },
        {
            "Title": "A mechatronic platform for robotic educational activities",
            "Publication year": 2013,
            "Publication url": "https://onlinelibrary.wiley.com/doi/abs/10.1002/9781118577516.ch20",
            "Abstract": "This chapter discusses an end\u2010to\u2010end procedure to develop an autonomous robotic platform, as part of the educational procedure. First, the architectural design and the implementation of the platform are described in detail and then the educational activities that can be applied to this platform are detailed. The chapter highlights methods to stimulate the interest of students in robotics through their involvement in the development of a robotic platform and, later on, of the required software applications. In a nutshell, it summarizes experiments in mechatronics educational activities that actively involved students.",
            "Abstract entirety": 1,
            "Author pub id": "ZzxSO8QAAAAJ:q3oQSFYPqjQC",
            "Publisher": "John Wiley & Sons, Inc."
        },
        {
            "Title": "Fast centre\u2013surround contrast modification",
            "Publication year": 2008,
            "Publication url": "https://digital-library.theiet.org/content/journals/10.1049/iet-ipr_20070012",
            "Abstract": "A new algorithm for fast contrast modification of standard dynamic range (SDR) images (8\u2005bits/channel) is presented. Its thrust is to enhance the contrast in the under-/over-exposed regions of SDR images, caused by the low dynamic range of the capturing device. It is motivated by the attributes of the shunting centre\u2013surround cells of the human visual system. The main advantage of the proposed algorithm is its O(N) complexity which results in very fast execution, even when executed on a conventional personal computer (0.2\u2005s/frame for a 640\u00d7480\u2005pixel resolution on a 3\u2005GHz Pentium 4). Thus, it moderately increases the computational burden if it is used as a pre-processing stage for other image processing algorithms. The proposed method is compared with other established algorithms, which can enhance the contrast in the under-/over-exposed regions of SDR images: the multi-scale Retinex with colour \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ZzxSO8QAAAAJ:UeHWp8X0CEIC",
            "Publisher": "IET Digital Library"
        },
        {
            "Title": "Unsupervised semantic clustering and localization for mobile robotics tasks",
            "Publication year": 2020,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S0921889020304073",
            "Abstract": "Due to its vast applicability, the semantic interpretation of regions or entities increasingly attracts the attention of scholars within the robotics community. The paper at hand introduces a novel unsupervised technique to semantically identify the position of an autonomous agent in unknown environments. When the robot explores a certain path for the first time, community detection is achieved through graph-based segmentation. This allows the agent to semantically define its surroundings in future traverses even if the environment\u2019s lighting conditions are changed. The proposed semantic clustering technique exploits the Louvain community detection algorithm, which constitutes a novel and efficient method for identifying groups of measurements with consistent similarity. The produced communities are combined with metric information, as provided by the robot\u2019s odometry through a hierarchical agglomerative \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ZzxSO8QAAAAJ:HfY9tUF4VgMC",
            "Publisher": "North-Holland"
        },
        {
            "Title": "Efficient robot path planning in the presence of dynamically expanding obstacles",
            "Publication year": 2012,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-642-33350-7_34",
            "Abstract": "This paper presents a framework for robot path planning based on the A* search algorithm in the presence of dynamically expanding obstacles. The overall method follows Cellular Automata (CA) based rules, exploiting the discrete nature of CAs for both obstacle and robot state spaces. For the search strategy, the discrete properties of the A* algorithm were utilized, allowing a seamless merging of both CA and A* theories. The proposed algorithm guarantees both a collision free and a cost efficient path to target with optimal computational cost. More particular, it expands the map state space with respect to time using adaptive time intervals in order to predict the necessary future expansion of obstacles for assuring both a safe and a minimum cost path. The proposed method can be considered as being a general framework in the sense that it can be applied to any arbitrary shaped obstacle.",
            "Abstract entirety": 1,
            "Author pub id": "ZzxSO8QAAAAJ:4fKUyHm3Qg0C",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "Biologically and psychophysically inspired adaptive support weights algorithm for stereo correspondence",
            "Publication year": 2010,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S0921889010000394",
            "Abstract": "In this paper a novel stereo correspondence algorithm is presented. It incorporates many biologically and psychologically inspired features to an adaptive weighted sum of absolute differences (SAD) framework in order to determine the correct depth of a scene. In addition to ideas already exploited, such as the color information utilization, gestalt laws of proximity and similarity, new ones have been adopted. The presented algorithm introduces the use of circular support regions, the gestalt law of continuity as well as the psychophysically-based logarithmic response law. All the aforementioned perceptual tools act complementarily inside a straightforward computational algorithm applicable to robotic applications. The results of the algorithm have been evaluated and compared to those of similar algorithms.",
            "Abstract entirety": 1,
            "Author pub id": "ZzxSO8QAAAAJ:9ZlFYXVOiuMC",
            "Publisher": "North-Holland"
        },
        {
            "Title": "The Imapct of Low-Level Features in Semantic-Based Image",
            "Publication year": 2007,
            "Publication url": "https://www.igi-global.com/chapter/imapct-low-level-features-semantic/28920",
            "Abstract": "Image Retrieval (IR) is generally known as a collection of techniques for retrieving images on the basis of features, either low-level (Content-based IR) or high-level (Semantic-based IR). Since Semantic-based features rely on low-level ones, in this chapter the reader is initially familiarized with the most widely used low-level features. An efficient way to present these features is by means of a statistical tool capable of bearing concrete information, such as the histogram. For use in IR, the histograms extracted from the previously mentioned features need to be compared by means of a metric. The most popular methods and distances are, thus, apposed. Finally, a number of IR systems using histograms are presented in a thorough manner and their experimental results are discussed. The steps in order to develop a custom IR system, along with modern techniques in image feature extraction are also presented.",
            "Abstract entirety": 1,
            "Author pub id": "ZzxSO8QAAAAJ:HoB7MX3m0LUC",
            "Publisher": "IGI Global"
        },
        {
            "Title": "ROLFER: A fully autonomous aerial rescue support system",
            "Publication year": 2018,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S0141933118301224",
            "Abstract": "Unmanned Aerial Vehicle (UAVs) technology can provide a critical and multifaceted support in Search and Rescue (SAR) operations. They can be of invaluable use in preserving victims\u2019 lives, as well as backing-up rescue workers. Their main advantage is the shrinkage of intervention time, which constitutes a fundamental parameter being seriously accounted when designing such procedures and missions. Bearing this in mind, the paper in hand describes the design and implementation of a robotic Autonomous Unmanned Aerial System (AUAS), namely the ROLFER (Robotic Lifeguard for Emergency Rescue) system, which aims to immediately provide rescue and life-saving services. The proposed platform is suitable for life-saving services that require fast reaction in the context of an emergency. ROLFER's architecture and its elements are detailed concerning both hardware and software. We study the \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ZzxSO8QAAAAJ:dZbaGXT4iR0C",
            "Publisher": "Elsevier"
        },
        {
            "Title": "Unsupervised human detection with an embedded vision system on a fully autonomous UAV for search and rescue operations",
            "Publication year": 2019,
            "Publication url": "https://www.mdpi.com/514798",
            "Abstract": "Unmanned aerial vehicles (UAVs) play a primary role in a plethora of technical and scientific fields owing to their wide range of applications. In particular, the provision of emergency services during the occurrence of a crisis event is a vital application domain where such aerial robots can contribute, sending out valuable assistance to both distressed humans and rescue teams. Bearing in mind that time constraints constitute a crucial parameter in search and rescue (SAR) missions, the punctual and precise detection of humans in peril is of paramount importance. The paper in hand deals with real-time human detection onboard a fully autonomous rescue UAV. Using deep learning techniques, the implemented embedded system was capable of detecting open water swimmers. This allowed the UAV to provide assistance accurately in a fully unsupervised manner, thus enhancing first responder operational capabilities. The novelty of the proposed system is the combination of global navigation satellite system (GNSS) techniques and computer vision algorithms for both precise human detection and rescue apparatus release. Details about hardware configuration as well as the system\u2019s performance evaluation are fully discussed. View Full-Text",
            "Abstract entirety": 1,
            "Author pub id": "ZzxSO8QAAAAJ:i9B0nK2ie9AC",
            "Publisher": "Multidisciplinary Digital Publishing Institute"
        },
        {
            "Title": "Ontology-based 3d pose estimation for autonomous object manipulation",
            "Publication year": 2012,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/6295586/",
            "Abstract": "In this paper a novel solution to the problem of guiding a robotic gripper in order to perform manipulation tasks, is presented. The proposed approach consists of two main modules corresponding to the training and testing sessions, respectively. During training, we employ an ontology-based framework with a view to the establishment of a database holding information regarding several geometrical attributes of the training objects. An accurate estimation of the 3D pose of an object-target is obtained during the testing phase and through the efficient exploitation of the established database. The most common solution to the 3D pose estimation problem implies extensive training sessions that are based on oversampled datasets containing several instances objects captured under varying view-points. However, such an approach engenders high complexity accompanied by large computational burden. We address this \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ZzxSO8QAAAAJ:tOudhMTPpwUC",
            "Publisher": "IEEE"
        },
        {
            "Title": "A System to Navigate a Robot into a Ship Structure",
            "Publication year": 2001,
            "Publication url": "https://vbn.aau.dk/en/publications/a-system-to-navigate-a-robot-into-a-ship-structure",
            "Abstract": "A System to Navigate a Robot into a Ship Structure \u2014 Aalborg University's Research Portal Skip \nto main navigation Skip to search Skip to main content Aalborg University's Research Portal \nLogo Dansk English Home Profiles Projects Publications Activities Research Units Facilities \nPress / Media Prizes Datasets Impacts Search by keywords, name or affiliation A System to \nNavigate a Robot into a Ship Structure US Bititci, M. Ayromlou, C. Beltran, A. Gasteratos, \nSimon Hoffgaard, Ole Madsen, W. Ponweiser, Michael Zillich Research output: Contribution to \nbook/anthology/report/conference proceeding \u203a Article in proceeding \u203a Research 1 Citation \n(Scopus) Overview Original language English Title of host publication Proceedings of ICVS'01 \nEditors Olivier Balet, Gerard Subsol, Patrice Touguet Publication date 2001 Publication status \nPublished - 2001 Event ICVS'01, 7-8 July 2001 - Vancouver, Canada, Canada Duration: ', \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ZzxSO8QAAAAJ:bFI3QPDXJZMC",
            "Publisher": "Unknown"
        },
        {
            "Title": "PRONTO: a system for mobile robot navigation via CAD-model guidance",
            "Publication year": 2002,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S0141933101001429",
            "Abstract": "This paper presents a vision system that finds and measures the location of 3D structures with respect to a CAD-model. The integration of a CAD-model to visual measurement and direct feedback of measurement results to the CAD is a key aspect. For the extraction of basic visual cues, independent and complementary modules are envisaged. The goal is that of navigating a legged robot into a ship structure using the pose estimated from visual landmarks extracted from the CAD-model. These are tracked in real-time by the vision system and are matched to the CAD-model. For the implementation of the vision system, commercial off-the-shelf parts were used along with a custom designed robot stereo head. The communication with other modules is done using simple ASCII commands on a fiber channel network with standard TCP/IP protocol. This allows easy debugging, straightforward development of applications \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ZzxSO8QAAAAJ:W7OEmFMy1HYC",
            "Publisher": "Elsevier"
        },
        {
            "Title": "Obtaining reliable depth maps for robotic applications from a quad-camera system",
            "Publication year": 2009,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-642-10817-4_89",
            "Abstract": "Autonomous navigation behaviors in robotics often require reliable depth maps. The use of vision sensors is the most popular choice in such tasks. On the other hand, accurate vision-based depth computing methods suffer from long execution times. This paper proposes a novel quad-camera based system able to calculate fast and accurately a single depth map of a scenery. The four cameras are placed on the corners of a square. Thus, three, differently oriented, stereo pairs result when considering a single reference image (namely an horizontal, a vertical and a diagonal pair). The proposed system utilizes a custom tailored, simple, rapidly executed stereo correspondence algorithm applied to each stereo pair. This way, the computational load is kept within reasonable limits. A reliability measure is used in order to validate each point of the resulting disparity maps. Finally, the three disparity maps are fused \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ZzxSO8QAAAAJ:L8Ckcad2t8MC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "Accelerating single-image super-resolution polynomial regression in mobile devices",
            "Publication year": 2015,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/7064112/",
            "Abstract": "This paper introduces a new super-resolution algorithm based on machine learning along with a novel hybrid implementation for next generation mobile devices. The proposed super-resolution algorithm entails a two dimensional polynomial regression method using only the input image properties for the learning task. Model selection is applied for defining the optimal degree of polynomial by adopting regularization capability in order to avoid overfitting. Although it is widely believed that machine learning algorithms are not appropriate for real-time implementation, the paper in hand proves that there are indeed specific hypothesis representations that are able to be integrated into real-time mobile applications. With aim to achieve this goal, the increasing GPU employment in modern mobile devices is exploited. More precisely, by utilizing the mobile GPU as a co-processor in a hybrid pipelined implementation \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ZzxSO8QAAAAJ:A1VvXmYcXXgC",
            "Publisher": "IEEE"
        },
        {
            "Title": "CNN\u2010based novelty detection for terrestrial and extra\u2010terrestrial autonomous exploration",
            "Publication year": 2021,
            "Publication url": "https://orbit.dtu.dk/files/246170602/csy2.12013.pdf",
            "Abstract": "Novelty detection is concerned with detecting features that do not belong to any known class or are not well represented by existing models. Ergo, in autonomous navigation novelty detection determines whether an input camera frame contains certain entities of high interest which do not correspond to a known category. One of the key requirements for the future space exploration missions is the reduction of the information to be transferred back to Earth. Thus, novelty detection techniques have been developed to select the subset of acquired images with significant measurements that justify utilisation of the limited bandwidth from the available information link. Such methods are based on the identification of salient regions, which are then evaluated against a set of trained classifiers. We explore a novelty detection approach, based on the reasoning properties of Neural Networks, which follow the same guidelines while also being trainable in an end\u2010to\u2010end manner. This characteristic allows for the intertwined optimisation of the individual components leading to a closer estimation of a global solution. Our experiments reveal that the proposed novelty detection system achieves better performance, as compared to hand\u2010crafted techniques, when the learning and testing examples refer to similar environments.",
            "Abstract entirety": 1,
            "Author pub id": "ZzxSO8QAAAAJ:jW3pDOCzWhQC",
            "Publisher": "Unknown"
        },
        {
            "Title": "SPARTAN project: Efficient implementation of computer vision algorithms onto reconfigurable platform targeting to space applications",
            "Publication year": 2011,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/5981524/",
            "Abstract": "Vision-based robotic applications exhibit increased computational complexity. This problem becomes even more important regarding mission critical application domains. The SPARTAN project focuses in the tight and optimal implementation of computer vision algorithms targeting to rover navigation for space applications. For evaluation purposes, these algorithms will be implemented with a co-design methodology onto a Virtex-6 FPGA device.",
            "Abstract entirety": 1,
            "Author pub id": "ZzxSO8QAAAAJ:O3NaXMp0MMsC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Computer Vision Systems: 6th International Conference on Computer Vision Systems, ICVS 2008 Santorini, Greece, May 12-15, 2008, Proceedings",
            "Publication year": 2008,
            "Publication url": "https://books.google.com/books?hl=en&lr=&id=mh1qCQAAQBAJ&oi=fnd&pg=PR4&dq=info:BAM4NNcRguEJ:scholar.google.com&ots=-znXArm6I_&sig=sEHSUpu86zH1xO6_qhr1kIcr0QA",
            "Abstract": "In the past few years, with the advances in microelectronics and digital te-nology, cameras became a widespread media. This, along with the enduring increase in computing power boosted the development of computer vision s-tems. The International Conference on Computer Vision Systems (ICVS) covers the advances in this area. This is to say that ICVS is not and should not be yet another computer vision conference. The? eld of computer vision is fully covered by many well-established and famous conferences and ICVS di? ers from these by covering the systems point of view. ICVS 2008 was the 6th International Conference dedicated to advanced research on computer vision systems. The conference, continuing a series of successful events in Las Palmas, Vancouver, Graz, New York and Bielefeld, in 2008 was held on Santorini. In all, 128 papers entered the review process and each was reviewed by three independent reviewers using the double-blind review method. Of these, 53-pers were accepted (23 as oral and 30 as poster presentation). There were also two invited talks by P. Anandan and by Heinrich H. Bultho \u0308?. The presented papers cover all aspects of computer vision systems, namely: cognitive vision, monitor and surveillance, computer vision architectures, calibration and reg-tration, object recognition and tracking, learning, human\u2014machine interaction and cross-modal systems.",
            "Abstract entirety": 1,
            "Author pub id": "ZzxSO8QAAAAJ:blknAaTinKkC",
            "Publisher": "Springer"
        },
        {
            "Title": "A LoCATe\u2010based visual place recognition system for mobile robotics and GPGPUs",
            "Publication year": 2017,
            "Publication url": "http://hephaestus.nup.ac.cy/handle/11728/10137",
            "Abstract": "In this paper, a novel visual Place Recognition approach is evaluated based on a visual vocabulary of the Color and Edge Directivity Descriptor (CEDD) to address the loop closure detection task. Even though CEDD was initially designed so as to globally describe the color and texture information of an input image addressing Image Indexing and Retrieval tasks, its scalability on characterizing single feature points has already been proven. Thus, instead of using CEDD as a global descriptor, we adopt a bottom-up approach and use its localized version, Local Color And Texture dEscriptor, as an input to a state-of-the-art visual Place Recognition technique based on Visual Word Vectors. Also, we use a parallel execution pipeline based on a previous work of ours using the well established General Purpose Graphics Processing Unit (GPGPU) computing. Our experiments show that the usage of CEDD as a local descriptor produces high accuracy visual Place Recognition results, while the parallelization used allows for a real-time implementation even in the case of a low-cost mobile device.",
            "Abstract entirety": 1,
            "Author pub id": "ZzxSO8QAAAAJ:XUmZziu-z7kC",
            "Publisher": "John Wiley & Sons Ltd"
        },
        {
            "Title": "Comparative presentation of real-time obstacle avoidance algorithms using solely stereo vision",
            "Publication year": 2010,
            "Publication url": "https://www.academia.edu/download/32588046/Comparative_Presentation_of_Real-Time_Obstacle_Avoidance_Kos.pdf",
            "Abstract": "This work presents a comparison between vision-based obstacle avoidance algorithms for mobile robot navigation. The issue of obstacle avoidance in robotics demands a reliable solution since mobile platforms often have to maneuver in arbitrary environments with high level of risk. The most significant advantage of the presented work is the use of only one sensor, ie a stereo camera, which significantly diminishes the computational cost. Three different versions of the proposed method have been developed. The implementation of these algorithms consists of a stereo vision module, which is common for all the versions, and a decision making module, which is different in each version and proposes an efficient method of processing stereo information in order to navigate a robotic platform. The algorithms have been implemented in C++ and the produced frame rate ensures that the robot will be able to accomplish the proposed decisions in real time. The presented algorithms have been tested on various different input images and their results are shown and discussed.",
            "Abstract entirety": 1,
            "Author pub id": "ZzxSO8QAAAAJ:dfsIfKJdRG4C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Enhancement of fast acquired disparity maps using a 1-D cellular automation filter",
            "Publication year": 2005,
            "Publication url": "https://www.researchgate.net/profile/Antonios-Gasteratos/publication/259885133_Enhancement_of_Fast_Acquired_Disparity_Maps_using_a_1-D_Cellular_Automation_Filter/links/54721ecd0cf24af340c53151/Enhancement-of-Fast-Acquired-Disparity-Maps-using-a-1-D-Cellular-Automation-Filter.pdf",
            "Abstract": "Among others, stereo vision analysis deals with the extraction of depth in a scene, using the disparity between the images acquired by a stereo camera setup. The disparity calculation for the whole of an image is mostly a computation demanding procedure, commonly being performed by dedicated hardware. In this paper a hardware architecture for real time extraction of disparity maps is proposed, capable of processing images of 1MPixels in less than 25ms. The produced disparity maps are indented to be used for real-time navigation of a mobile platform, as well as in other time critical applications which demand 3D information.",
            "Abstract entirety": 1,
            "Author pub id": "ZzxSO8QAAAAJ:MXK_kJrjxJIC",
            "Publisher": "Unknown"
        },
        {
            "Title": "On-line deep learning method for action recognition",
            "Publication year": 2014,
            "Publication url": "https://link.springer.com/article/10.1007/s10044-014-0404-8",
            "Abstract": "In this paper an unsupervised on-line deep learning algorithm for action recognition in video sequences is proposed. Deep learning models capable of deriving spatio-temporal data have been proposed in the past with remarkable results, yet, they are mostly restricted to building features from a short window length. The model presented here, on the other hand, considers the entire sample sequence and extracts the description in a frame-by-frame manner. Each computational node of the proposed paradigm forms clusters and computes point representatives, respectively. Subsequently, a first-order transition matrix stores and continuously updates the successive transitions among the clusters. Both the spatial and temporal information are concurrently treated by the Viterbi Algorithm, which maximizes a criterion based upon (a) the temporal transitions and (b) the similarity of the respective input sequence \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ZzxSO8QAAAAJ:9AucIJLffosC",
            "Publisher": "Unknown"
        },
        {
            "Title": "The HCUAV project: Electronics and software development for medium altitude remote sensing",
            "Publication year": 2014,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/7017668/",
            "Abstract": "The continuous increase of illegal migration flows to southern European countries has been recently in the spotlight of European Union due to numerous deadly incidents. Another common issue that the aforementioned countries share is the Mediterranean wildfires which are becoming more frequent due to the warming climate and increasing magnitudes of droughts. Different ground early warning systems have been funded and developed across these countries separately for these incidents, however they have been proved insufficient mainly because of the limited surveyed areas and challenging Mediterranean shoreline and landscape. In 2011, the Greek Government along with European Commission, decided to support the development of the first Hellenic Civil Unmanned Aerial Vehicle (HCUAV), which will provide solutions to both illegal migration and wildfires. This paper presents the challenges in the \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ZzxSO8QAAAAJ:PQ1NLOpCoVAC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Confronting pharmaceutical products selection criteria: A comparative survey of consumers in Greece, France and Bulgaria",
            "Publication year": 2018,
            "Publication url": "https://www.ceeol.com/search/article-detail?id=713324",
            "Abstract": "Purpose: The survey at hand explores the factors describing the consumers\u2019 profile in the pharmaceutical markets of three European nations Design/methodology/approach: A primary research was carried out using questionnaires with a sample of citizens (pharmacy customers) in the capital of each nation and aiming to to determine the criteria motivating the customer/patient to purchase particular pharmaceutical preparations and the ultimate goal is to get an objective picture of the buying behavior of Greek, French and Bulgarian consumers Findings: Behavioral motives appear to be affected by health scientists, price, advertising, alternative available options and \u201cpublic opinion\u201d. Moreover, it appears that customers differ from one nation to the other but also between themselves, both with respect to their choices, as well as their special mode of action. Such individuality mainly results from the different levels of \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ZzxSO8QAAAAJ:SFOYbPikdlgC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Multi-view 3D scene reconstruction using ant colony optimization techniques",
            "Publication year": 2012,
            "Publication url": "https://iopscience.iop.org/article/10.1088/0957-0233/23/11/114002/meta",
            "Abstract": "This paper presents a new method performing high-quality 3D object reconstruction of complex shapes derived from multiple, calibrated photographs of the same scene. The novelty of this research is found in two basic elements, namely:(i) a novel voxel dissimilarity measure, which accommodates the elimination of the lighting variations of the models and (ii) the use of an ant colony approach for further refinement of the final 3D models. The proposed reconstruction procedure employs a volumetric method based on a novel projection test for the production of a visual hull. While the presented algorithm shares certain aspects with the space carving algorithm, it is, nevertheless, first enhanced with the lightness compensating image comparison method, and then refined using ant colony optimization. The algorithm is fast, computationally simple and results in accurate representations of the input scenes. In addition \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ZzxSO8QAAAAJ:fQNAKQ3IYiAC",
            "Publisher": "IOP Publishing"
        },
        {
            "Title": "A Multi-Objective Exploration Strategy for Mobile Robots Under Operational Constraints",
            "Publication year": 2013,
            "Publication url": "http://hephaestus.nup.ac.cy/handle/11728/10152",
            "Abstract": "Multi-objective robot exploration constitutes one of the most challenging tasks for autonomous robots performing in various operations and different environments. However, the optimal exploration path depends heavily on the objectives and constraints that both these operations and environments introduce. Typical environment constraints include partially known or completely unknown workspaces, limitedbandwidth communications, and sparse or dense clattered spaces. In such environments, the exploration robots must satisfy additional operational constraints, including time-critical goals, kinematic modeling, and resource limitations. Finding the optimal exploration path under these multiple constraints and objectives constitutes a challenging non-convex optimization problem. In our approach, we model the environment constraints in cost functions and utilize the cognitive-based adaptive optimization algorithm to meet timecritical objectives. The exploration path produced is optimal in the sense of globally minimizing the required time as well as maximizing the explored area of a partially unknown workspace. Since obstacles are sensed during operation, initial paths are possible to be blocked leading to a robot entrapment. A supervisor is triggered to signal a blocked passage and subsequently escape from the basin of cost function local minimum. Extensive simulations and comparisons in typical scenarios are presented to show the efficiency of the proposed approach.",
            "Abstract entirety": 1,
            "Author pub id": "ZzxSO8QAAAAJ:WzbvD7BMtBoC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Attention! a lightweight 2d hand pose estimation approach",
            "Publication year": 2020,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/9171866/",
            "Abstract": "Vision based human pose estimation is an non-invasive technology for Human-Computer Interaction (HCI). The direct use of the hand as an input device provides an attractive interaction method, with no need for specialized sensing equipment, such as exoskeletons, gloves etc, but a camera. Traditionally, HCI is employed in various applications spreading in areas including manufacturing, surgery, entertainment industry and architecture, to mention a few. Deployment of vision based human pose estimation algorithms can give a breath of innovation to these applications. In this article, we present a novel Convolutional Neural Network architecture, reinforced with a Self-Attention module. Our proposed model can be deployed on an embedded system due to its lightweight nature with just  1.9 Million  parameters. The source code and qualitative results are publicly available.",
            "Abstract entirety": 1,
            "Author pub id": "ZzxSO8QAAAAJ:oFKsPyNwwpYC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Three-Dimensional Scene Reconstruction",
            "Publication year": 2012,
            "Publication url": "https://scholar.google.com/scholar?cluster=13809052373971569554&hl=en&oi=scholarr",
            "Abstract": "The production of 3D models has been a popular research topic already for a long time, and important progress has been made since the early days. During the last decades, vision systems have established to become the standard and one of the most efficient sensorial assets in industrial and everyday applications. Due to the fact that vision provides several vital attributes, many applications tend to use novel vision systems into domestic, working, industrial, and any other environments. To achieve such goals, a vision system should robustly and effectively reconstruct the 3D surface and the working space. This chapter discusses different methods for capturing the three-dimensional surface of a scene. Geometric approaches to three-dimensional scene reconstruction are generally based on the knowledge of the scene structure from the camera\u2019s internal and external parameters. Another class of methods encompasses the photometric approaches, which evaluate the pixels\u2019 intensity to understand the three-dimensional scene structure. The third and final category of approaches, the so-called real aperture approaches, includes methods that use the physical properties of the visual sensors for image acquisition in order to reproduce the depth information of a scene.",
            "Abstract entirety": 1,
            "Author pub id": "ZzxSO8QAAAAJ:hbz17DqrwuEC",
            "Publisher": "Unknown"
        },
        {
            "Title": "The katwijk beach planetary rover dataset",
            "Publication year": 2018,
            "Publication url": "https://journals.sagepub.com/doi/abs/10.1177/0278364917737153",
            "Abstract": "This paper describes a dataset collected along a 1 km section of beach near Katwijk, The Netherlands, which was populated with a collection of artificial rocks of varying sizes to emulate known rock size densities at current and potential Mars landing sites. First, a fixed-wing unmanned aerial vehicle collected georeferenced images of the entire area. Then, the beach was traversed by a rocker-bogie-style rover equipped with a suite of sensors that are envisioned for use in future planetary rover missions. These sensors, configured so as to emulate the ExoMars rover, include stereo cameras, and time-of-flight and scanning light-detection-and-ranging sensors. This dataset will be of interest to researchers developing localization and mapping algorithms for vehicles traveling over natural and unstructured terrain in environments that do not have access to the global navigation satellite system, and where only previously \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ZzxSO8QAAAAJ:PpfTWA6RG0gC",
            "Publisher": "SAGE Publications"
        },
        {
            "Title": "Autonomous vehicle emergency recovery tool: a cooperative robotic system for car extraction",
            "Publication year": 2016,
            "Publication url": "https://onlinelibrary.wiley.com/doi/abs/10.1002/rob.21593",
            "Abstract": "Vehicles have been proven to be an ideal means for terrorists because they can be meticulously prepared well in advance before being deployed in urban and public places. To increase the risk and burden of explosive ordnance disposal teams, third\u2010party vehicles have also been used to block the access path to the explosive loaded vehicle. In this paper, we present a multirobot system that can remove vehicles from confined spaces with delicate handling, swiftly and in any direction to a safer disposal point. The new lifting robots, capable of omnidirectional movement, autonomously underride the identified vehicle and dock to its wheels for a synchronized lifting and extraction. The validity and efficiency of the novel robotic system is illustrated via experiments in an indoor parking lot, demonstrating successful autonomous navigation, docking, lifting, and extraction of a conventional car for a total covered distance of \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ZzxSO8QAAAAJ:5Klqo5HVOaoC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Establishing low dimensional manifolds for 3D object pose estimation",
            "Publication year": 2012,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/6295483/",
            "Abstract": "We propose a novel solution to the problem of 3D object pose estimation problem that is based on an efficient representation and feature extraction technique. We build a part-based architecture that takes into account both appearance-based characteristics of targets along with their geometrical attributes. This bunch-based structure encompasses an image feature extraction procedure accompanied by a clustering scheme over the abstracted key-points. In a follow-up step, these clusters are considered to establish representative manifolds capable of distinguishing similar poses of different objects into the corresponding classes. We form low dimensional manifolds by incorporating sophisticated operations over the members (clusters) of the extracted part-based architecture. An accurate estimation of the pose of a target is provided by a neural network-based solution that entails a novel input-output space targeting \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ZzxSO8QAAAAJ:738O_yMBCRsC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Non-linear image processing in hardware",
            "Publication year": 2000,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S0031320399001612",
            "Abstract": "A new ASIC capable of computing rank order filters, weighted rank order filters, standard erosion and dilation, soft erosion and dilation, order statistic soft erosion and dilation, fuzzy erosion and dilation and fuzzy soft erosion and dilation is presented in this paper. Its function is based on local histogram and a successive approximation technique and performs on 3\u00d73-pixel image windows. The hardware complexity of the proposed structure is linearly related to both image data window size and pixel resolution. The dimensions of the core of the proposed ASIC are 2.88 mm\u00d72.8 mm=8.06 mm2 and its die size dimensions are 3.72 mm\u00d73.64 mm=13.54 mm2. It executes 3.5\u00d7106 non-linear filter operations per second.",
            "Abstract entirety": 1,
            "Author pub id": "ZzxSO8QAAAAJ:zYLM7Y9cAGgC",
            "Publisher": "Pergamon"
        },
        {
            "Title": "Factors affecting the accuracy of an active vision head",
            "Publication year": 2002,
            "Publication url": "https://link.springer.com/chapter/10.1007/3-540-46014-4_37",
            "Abstract": "In any measuring system the categorization of the error generation factors leads to simplification of complex error problems and to higher suppression of the error. In this paper we categorize, quantify and analyze the errors that affect a binocular active vision head. Simulations have been made and experimental results on a high resolution pan-tilt-vergence mechanism are also proposed. As a conclusion it can be said that the system performs optimal when it is initialized so that the two cameras are perfectly aligned and perpendicular to the baseline. Small variations in the vergence angle or small horizontal deviations of the principal point alters the measurement dramatically. On the other hand, variations in pan and tilt and vertical deviations of the principal point, affect the measurement insignificantly.",
            "Abstract entirety": 1,
            "Author pub id": "ZzxSO8QAAAAJ:QIV2ME_5wuYC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "A hardware structure for time-to-impact computation using log-polar images",
            "Publication year": 2005,
            "Publication url": "http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.472.7270&rep=rep1&type=pdf",
            "Abstract": "This paper describes the design of a new hardware system for the optical flow and time-to-impact computation with real-time response. This is achieved by estimating the optical flow of the object on the camera plane. In order to reduce the image size without losing significant information, the log-polar transformation is utilized. The system employs a sequence of log-polar images for the optical flow and time-to-impact computation of a moving object. The algorithm that has been implemented belongs to \u201cdifferential techniques\u201d category, which is suitable for parallel computation of the parameters. The structure of the implementation allows the processing of grey-level log-polar images of 45x60 pixels in real time (25 frames per second)",
            "Abstract entirety": 1,
            "Author pub id": "ZzxSO8QAAAAJ:TQgYirikUcIC",
            "Publisher": "Unknown"
        },
        {
            "Title": "A novel moving-base RTK-GPS-Based wearable apparatus for precise localization of humans in peril",
            "Publication year": 2021,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S0141933121000132",
            "Abstract": "The paper in hand addresses the issue of precise positioning of a human in peril, who is supervised by means of carrying a novel wearable apparatus in the context of a crisis event. A completely Autonomous Unmanned Aerial Vehicle (AUAV) comprises the main component of an Autonomous Aerial Rescue System (AARS), namely the ROLFER (Robotic Lifeguard For Emergency Rescue), which has been specifically designed for instantaneous response and provision of assistance in Search and Rescue (SAR) scenarios. As short response times constitute a sine qua non criterion in SAR operations, all the accuracy issues of such systems have to be seriously accounted so as for a rescue mission or activity to be considered successful. After examining and evaluating the performance of several Global Positioning System (GPS) methods and techniques, the moving-base Real-Time Kinematics (RTK)-GPS \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ZzxSO8QAAAAJ:M3zsPnPgUlUC",
            "Publisher": "Elsevier"
        },
        {
            "Title": "Robot navigation via spatial and temporal coherent semantic maps",
            "Publication year": 2016,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S0952197615002596",
            "Abstract": "The ability of mobile robots to sense, interpret and map their environments in human terms is decisive for their applicability to everyday activities hereafter. Bearing this view in mind, we present here, for the first time, an integrated framework that aims: (i) to introduce a semantic mapping method and (ii) to use this semantic map, as a means to provide a hierarchical navigation solution. The semantic map is formed in a bottom-up fashion, along the robot\u05f3s course, relying on the conceptual space quantization, the time proximity and the spatial coherence integrated into the labeled sparse topological map. A novel time-evolving augmented navigation graph determines the semantic topology of the explored environment and the connectivity among the recognized places expressed by the inter-place transition probability. The robot navigation part is addressed through an interface that facilitates human robot interaction \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ZzxSO8QAAAAJ:oYc2ogjtvagC",
            "Publisher": "Pergamon"
        },
        {
            "Title": "Extraction of common regions of interest from orbital and rover (ground) acquired imagery",
            "Publication year": 2014,
            "Publication url": "https://www.researchgate.net/profile/Antonios-Gasteratos/publication/260872189_Extraction_of_Common_Regions_of_Interest_from_Orbital_and_Rover_Ground_acquired_Imagery/links/5471d2270cf216f8cfad1640/Extraction-of-Common-Regions-of-Interest-from-Orbital-and-Rover-Ground-acquired-Imagery.pdf",
            "Abstract": "Accurate global localization of space exploratory rovers is of high importance to the future extraterrestrial missions. In particular, the Mars Sample Return mission (MSR) needs precise localization techniques for the Sample Fetching Rover (SFR) to collect a previously drilled cache of soil. Moreover, exact positioning is sine qua non for a successful rendezvous of the SFR with a Mars Ascent Vehicle (MAV) that will launch the load into Martian orbit. The utilization of prior information to refine the localization has been the main approach in mobile robotics during the past decades. In extraterrestrial scenery, orbital images constitute an excellent source of such prior information. With long term aim to provide accurate global rover localization, as a first step, the proposed paper assesses the ability to automatically detect common regions of interest from both rover (ground) and orbital images. The approach comprises the separate extraction of salient regions, employing distinct techniques for the orbital and ground images.",
            "Abstract entirety": 1,
            "Author pub id": "ZzxSO8QAAAAJ:SEmTV4UfSqwC",
            "Publisher": "Unknown"
        },
        {
            "Title": "What, Where and How? Introducing pose manifolds for industrial object manipulation",
            "Publication year": 2015,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S0957417415004418",
            "Abstract": "In this paper we propose a novel method for object grasping that aims to unify robot vision techniques for efficiently accomplishing the demanding task of autonomous object manipulation. Through ontological concepts, we establish three mutually complementary processes that lead to an integrated grasping system able to answer conjunctive queries such as \u201cWhat\u201d, \u201cWhere\u201d and \u201cHow\u201d? For each query, the appropriate module provides the necessary output based on ontological formalities. The \u201cWhat\u201d is handled by a state of the art object recognition framework. A novel 6 DoF object pose estimation technique, which entails a bunch-based architecture and a manifold modeling method, answers the \u201cWhere\u201d. Last, \u201cHow\u201d is addressed by an ontology-based semantic categorization enabling the sufficient mapping between visual stimuli and motor commands.",
            "Abstract entirety": 1,
            "Author pub id": "ZzxSO8QAAAAJ:Cd1N8iHLSCsC",
            "Publisher": "Pergamon"
        },
        {
            "Title": "A hybrid static/active video surveillance system",
            "Publication year": 2011,
            "Publication url": "https://www.tandfonline.com/doi/abs/10.1080/15599612.2011.553252",
            "Abstract": "In this article, we present an effective real\u2013time video surveillance system for real-life outdoor surveillance scenarios. The system integrates two different camera's behaviors: a static and a moving one. Static camera subsystem operates multiple object tracking and classification. Abnormal behaviors are detected using information about objects' routes. In case of a probable collision scenario, the operation of the moving camera subsystem initiates and a PID controller gives instructions at a pan/tilt mechanism in order to rotate the camera and record the activity. The approaches employed address properly the challenges that might arise in a typical outdoor scene, such as local and global lighting changes, variations in objects' appearance and occlusions.",
            "Abstract entirety": 1,
            "Author pub id": "ZzxSO8QAAAAJ:u_35RYKgDlwC",
            "Publisher": "Taylor & Francis Group"
        },
        {
            "Title": "Simultaneous visual object recognition and position estimation using SIFT",
            "Publication year": 2009,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-642-10817-4_85",
            "Abstract": "In the last decade, pattern recognition tasks have flourished and become one of the most popular tasks in computer vision. A wealth of research focused on building vision systems capable of recognizing objects in cluttered environments. Moreover industries address all their efforts to developing new frameworks for assisting people in everyday life. The need of robots working closely to human beings in domestic workplaces, makes a necessity the usage of intelligent sensorial systems that are able to find patterns and provide their location in the working space. In this paper a novel method able to recognize objects in a scene and provide their spatial information is presented. Furthermore, we investigate how SIFT could expand for the purposes of location assignment of an object in a scene.",
            "Abstract entirety": 1,
            "Author pub id": "ZzxSO8QAAAAJ:M3ejUd6NZC8C",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "Light-invariant 3D object's pose estimation using color distance transform",
            "Publication year": 2010,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/5548505/",
            "Abstract": "This paper presents a novel pose estimation method based on color distance transform. Although the distance transform has already been used for object detection, pose estimation and active contouring we use it in a completely novel way to isolate the colors from which the pose is estimated. Standard matching and pose estimation techniques usually rely on the available texture and feature points. However, they are bound to fail in low texture or extreme noise presence conditions. The edge-based approaches can overcome such failures but they are generally too slow for real-time performance. Moreover the image luminance affects these techniques as the edges are not visible and in many cases the foreground and the background are merged. On the other hand, we obtain robustness against extreme lighting conditions by using the HSV-HSL color spaces. We isolate the colors operating only on the \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ZzxSO8QAAAAJ:fPk4N6BV_jEC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Image Sequence Stabilization Using Fuzzy Kalman Filtering and Log-Polar Transformation.",
            "Publication year": 2008,
            "Publication url": "https://www.scitepress.org/Papers/2008/10714/10714.pdf",
            "Abstract": "Digital image stabilization (DIS) is the process that compensates the undesired fluctuations of a frame\u2019s position in an image sequence by means of digital image processing techniques. DIS techniques usually comprise two successive units. The first one estimates the motion and the successive one compensates it. In this paper, a novel digital image stabilization technique is proposed, which is featured with a fuzzy Kalman estimation of the global motion vector in the log-polar plane. The global motion vector is extracted using four local motion vectors computed on respective sub-images in the log-polar plane. The proposed technique exploits both the advantages of the fuzzy Kalman system and the log-polar plane. The compensation is based on the motion estimation in the log-polar domain, filtered by the fuzzy Kalman system. The described technique outperforms in terms of response times, the output quality and the level of compensation.",
            "Abstract entirety": 1,
            "Author pub id": "ZzxSO8QAAAAJ:maZDTaKrznsC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Intelligent stereo vision in autonomous robot traversability estimation",
            "Publication year": 2013,
            "Publication url": "https://www.igi-global.com/chapter/content/73192",
            "Abstract": "Traversability estimation is the process of assessing whether a robot is able to move across a specific area. Autonomous robots need to have such an ability to automatically detect and avoid non-traversable areas and, thus, stereo vision is commonly used towards this end constituting a reliable solution under a variety of circumstances. This chapter discusses two different intelligent approaches to assess the traversability of the terrain in front of a stereo vision-equipped robot. First, an approach based on a fuzzy inference system is examined and then another approach is considered, which extracts geometrical descriptions of the scene depth distribution and uses a trained support vector machine (SVM) to assess the traversability. The two methods are presented and discussed in detail.",
            "Abstract entirety": 1,
            "Author pub id": "ZzxSO8QAAAAJ:XdYaqolBBq8C",
            "Publisher": "IGI global"
        },
        {
            "Title": "Evaluation of two-part algorithms for objects' depth estimation",
            "Publication year": 2012,
            "Publication url": "https://ieeexplore.ieee.org/document/6135450/",
            "Abstract": "During the last decade, a wealth of research was devoted to building integrated vision systems capable of both recognising objects and providing their spatial information. Object recognition and pose estimation are among the most popular and challenging tasks in computer vision. Towards this end, in this work the authors propose a novel algorithm for objects' depth estimation. Moreover, they comparatively study two common two-part approaches, namely the scale invariant feature transform SIFT and the speeded-up robust features algorithm, in the particular application of location assignment of an object in a scene relatively to the camera, based on the proposed algorithm. Experimental results prove the authors' claim that an accurate estimation of objects' depth in a scene can be obtained by taking into account extracted features' distribution over the target's surface.",
            "Abstract entirety": 1,
            "Author pub id": "ZzxSO8QAAAAJ:P5F9QuxV20EC",
            "Publisher": "IET"
        },
        {
            "Title": "Recent trends in social aware robot navigation: A survey",
            "Publication year": 2017,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S0921889016302287",
            "Abstract": "With the robots tending to accumulate more and more capabilities beyond the level of acting in a deterministic fashion, the idea of introducing them into our every day lives seems to be closer now. Robotics systems and techniques appeared during the recent years have achieved astonishing potential to perceive and interpret their surrounding not only as low level features but also close to human understandable concepts. Such advances, in conjunction with the aspiration to incorporate robots into domestic or public places, led to the flourishing of fields dealing with their response in human presence. Following this notion, the field of social mapping was recently introduced in order to manage the shared space among robots and individuals in an ordinary fashion. This manuscript aims to systemize the recent literature by describing the required levels of robot perception, focusing on methods related to robot\u2019s social \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ZzxSO8QAAAAJ:f4T9rk490XkC",
            "Publisher": "North-Holland"
        },
        {
            "Title": "Spartan: Developing a vision system for future autonomous space exploration robots",
            "Publication year": 2014,
            "Publication url": "https://onlinelibrary.wiley.com/doi/abs/10.1002/rob.21484",
            "Abstract": "Mars exploration is expected to remain a focus of the scientific community in the years to come. A Mars rover should be highly autonomous because communication between the rover and the terrestrial operation center is difficult, and because the vehicle should spend as much of its traverse time as possible moving. Autonomous behavior of the rover implies that the vision system provides both a wide view to enable navigation and three\u2010dimensional (3D) reconstruction, and at the same time a close\u2010up view ensuring safety and providing reliable odometry data. The European Space Agency funded project \u201cSPAring Robotics Technologies for Autonomous Navigation\u201d (SPARTAN) aimed to develop an efficient vision system to cover all such aspects of autonomous exploratory rovers. This paper presents the development of such a system, starting from the requirements up to the testing of the working prototype. The \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ZzxSO8QAAAAJ:XiVPGOgt02cC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Precise 3d measurements with a high resolution stereo head",
            "Publication year": 2000,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/914909/",
            "Abstract": "We investigate a method to obtain accurate 3D measurements and we compare it with a standard photogrammetry method. The method utilizes a closed-loop to bring the point under measure in the middle of the two images of a stereo pair. It uses poor calibrated cameras and the accuracy of the measurements relies on the high resolution of the stereo head encoders and on its calibration as well. Experimental results have shown that the proposed method is more accurate than the standard photogrammetry method, as well as it is more robust to small variations of the initial position of the cameras.",
            "Abstract entirety": 1,
            "Author pub id": "ZzxSO8QAAAAJ:YsMSGLbcyi4C",
            "Publisher": "IEEE"
        },
        {
            "Title": "Evaluation of two-part algorithms for objects\u2019 depth estimation IET Comput",
            "Publication year": 2012,
            "Publication url": "https://scholar.google.com/scholar?cluster=6425654523981032741&hl=en&oi=scholarr",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "ZzxSO8QAAAAJ:eK4aujBuqBIC",
            "Publisher": "Vision"
        },
        {
            "Title": "Deep feature space: A geometrical perspective",
            "Publication year": 2020,
            "Publication url": "https://arxiv.org/abs/2007.00062",
            "Abstract": "One of the most prominent attributes of Neural Networks (NNs) constitutes their capability of learning to extract robust and descriptive features from high dimensional data, like images. Hence, such an ability renders their exploitation as feature extractors particularly frequent in an abundant of modern reasoning systems. Their application scope mainly includes complex cascade tasks, like multi-modal recognition and deep Reinforcement Learning (RL). However, NNs induce implicit biases that are difficult to avoid or to deal with and are not met in traditional image descriptors. Moreover, the lack of knowledge for describing the intra-layer properties -- and thus their general behavior -- restricts the further applicability of the extracted features. With the paper at hand, a novel way of visualizing and understanding the vector space before the NNs' output layer is presented, aiming to enlighten the deep feature vectors' properties under classification tasks. Main attention is paid to the nature of overfitting in the feature space and its adverse effect on further exploitation. We present the findings that can be derived from our model's formulation, and we evaluate them on realistic recognition scenarios, proving its prominence by improving the obtained results.",
            "Abstract entirety": 1,
            "Author pub id": "ZzxSO8QAAAAJ:NWFKKQzSIN4C",
            "Publisher": "Unknown"
        },
        {
            "Title": "From Object Recognition to Object Localization",
            "Publication year": 2012,
            "Publication url": "https://www.igi-global.com/chapter/content/62681",
            "Abstract": "Recognizing objects in a scene is a fundamental task in image understanding. The recent advances in robotics and related technologies have placed more challenges and stricter requirements to this issue. In such applications, robots must be equipped with a sense of location and direction with a view to the efficient accomplishment of navigation or demanding pick and place tasks. In addition, spatial information is required in surveillance processes where recognized targets are located in the working space of the robot. Furthermore, accurate perception of depth is mandatory in driver assistance applications. This chapter presents several recently proposed methods capable of first recognizing objects and then providing their spatial information in cluttered environments.",
            "Abstract entirety": 1,
            "Author pub id": "ZzxSO8QAAAAJ:KxtntwgDAa4C",
            "Publisher": "IGI Global"
        },
        {
            "Title": "Efficient representation and feature extraction for neural network-based 3D object pose estimation",
            "Publication year": 2013,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S0925231213003111",
            "Abstract": "This paper introduces an efficient representation and feature extraction technique for 3D pose estimation of objects, incorporating a novel mechanism for the exploitation of the extracted visual cues. A combination of a fuzzy clustering technique for the input space, with supervised learning, results in a problem of reduced dimensionality and an efficient mapping of the input\u2013output space. While other neural network-based approaches for 3D pose estimation focus on reducing dimensionality based on input space characteristics, such as with PCA-based approaches, the proposed scheme directly targets the input\u2013output mapping, based on the available visual data. Evaluation results provide evidence of low generalization error when estimating the 3D pose of objects, with the best performance achieved when employing Radial Basis Functions. The proposed system can be adopted in several computer vision \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ZzxSO8QAAAAJ:BrmTIyaxlBUC",
            "Publisher": "Elsevier"
        },
        {
            "Title": "Color-based monocular visuoinertial 3-D pose estimation of a volant robot",
            "Publication year": 2010,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/5491171/",
            "Abstract": "The pose estimation from visual sensors is widely practiced nowadays. The pose vector is estimated by means of homographies and projection geometry. The integration of visual and inertial measurements is getting more attractive due to its robustness and flexibility. The cooperation of visual with inertial sensors for finding a robot's pose bears many advantages, as it exploits their complementary attributes. Most of the visual pose estimation systems identify a geometrically known planar target to extract the pose vector. In this paper, the pose is estimated from a set of colored markers arranged in a known geometry, fused with the measurements of an inertial unit. The utilization of an extended Kalman filter (EKF) compensates the error and fuses the two heterogeneous measurements. The novelty of the proposed system is the use of low-cost colored post-it markers, along with the capability of handling different \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ZzxSO8QAAAAJ:ULOm3_A8WrAC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Decomposition of grey-scale morphological structuring elements in hardware",
            "Publication year": 2002,
            "Publication url": "https://www.researchgate.net/profile/Antonios-Gasteratos/publication/2948731_Decomposition_of_Grey-Scale_Morphological_Structuring_Elements_in_Hardware/links/0fcfd51091bc508339000000/Decomposition-of-Grey-Scale-Morphological-Structuring-Elements-in-Hardware.pdf",
            "Abstract": "Morphological image processing machines are not capable of handling large-size structuring elements. A new architecture for fast execution of the erosion/dilation operations in an up to 9\u00d7 9-pixel, arbitrarily shaped, image window through decomposition of grey-scale morphological structuring element into 3\u00d7 3-pixel sub-domains is presented in this paper. The proposed hardware structure has been also implemented in VLSI and its throughput rate is 10 Mbytes/sec.",
            "Abstract entirety": 1,
            "Author pub id": "ZzxSO8QAAAAJ:_xSYboBqXhAC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Computer Vision Systems: 6th International Conference on Computer Vision Systems, ICVS 2008 Santorini, Greece, May 12-15, 2008, Proceedings",
            "Publication year": 2008,
            "Publication url": "https://books.google.com/books?hl=en&lr=&id=cPkzdgnvJVgC&oi=fnd&pg=PA3&dq=info:LToRE-caCMYJ:scholar.google.com&ots=Kh2X17MCN0&sig=YJPbbhDIzPgdImsoD9hIoYaPp4I",
            "Abstract": "In the past few years, with the advances in microelectronics and digital te-nology, cameras became a widespread media. This, along with the enduring increase in computing power boosted the development of computer vision s-tems. The International Conference on Computer Vision Systems (ICVS) covers the advances in this area. This is to say that ICVS is not and should not be yet another computer vision conference. The? eld of computer vision is fully covered by many well-established and famous conferences and ICVS di? ers from these by covering the systems point of view. ICVS 2008 was the 6th International Conference dedicated to advanced research on computer vision systems. The conference, continuing a series of successful events in Las Palmas, Vancouver, Graz, New York and Bielefeld, in 2008 was held on Santorini. In all, 128 papers entered the review process and each was reviewed by three independent reviewers using the double-blind review method. Of these, 53-pers were accepted (23 as oral and 30 as poster presentation). There were also two invited talks by P. Anandan and by Heinrich H. Bultho \u0308?. The presented papers cover all aspects of computer vision systems, namely: cognitive vision, monitor and surveillance, computer vision architectures, calibration and reg-tration, object recognition and tracking, learning, human\u2014machine interaction and cross-modal systems.",
            "Abstract entirety": 1,
            "Author pub id": "ZzxSO8QAAAAJ:0D9gKr9vLLUC",
            "Publisher": "Springer Science & Business Media"
        },
        {
            "Title": "Hot spot method for pedestrian detection using saliency maps, discrete Chebyshev moments and support vector machine",
            "Publication year": 2018,
            "Publication url": "https://ieeexplore.ieee.org/iel7/4149689/8387043/08387035.pdf",
            "Abstract": "The increasing risks of border intrusions or attacks on sensitive facilities and the growing availability of surveillance cameras lead to extensive research efforts for robust detection of pedestrians using images. However, the surveillance of borders or sensitive facilities poses many challenges including the need to set up many cameras to cover the whole area of interest, the high bandwidth requirements for data streaming and the high-processing requirements. Driven by day and night capabilities of the thermal sensors and the distinguished thermal signature of humans, the authors propose a novel and robust method for the detection of pedestrians using thermal images. The method is composed of three steps: a detection which is based on a saliency map in conjunction with a contrast-enhancement technique, a shape description based on discrete Chebyshev moments and a classification step using a support \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ZzxSO8QAAAAJ:RF4BjkDOTHkC",
            "Publisher": "IET"
        },
        {
            "Title": "Theta-disparity: An efficient representation of the 3d scene structure",
            "Publication year": 2016,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-319-08338-4_57",
            "Abstract": "We propose a new representation                                  of 3D scene structure, named theta-disparity. The proposed representation is a 2D angular                                  depth histogram                                  that is calculated using                                  a disparity map. It models the structure of the prominent objects in the scene and reveals their radial distribution relative to a point of interest. The proposed representation is analyzed and used as a basic attention mechanism to autonomously resolve two different robotic scenarios. The method is efficient due to the low computational complexity. We show that the method can be successfully used for the planning of different tasks in the industrial and service robotics domains, e.g., object grasping, manipulation, plane extraction, path detection, and obstacle avoidance.",
            "Abstract entirety": 1,
            "Author pub id": "ZzxSO8QAAAAJ:TniZHWc1JwoC",
            "Publisher": "Springer, Cham"
        },
        {
            "Title": "Guest Editorial: Deep Learning and Robotics",
            "Publication year": 2021,
            "Publication url": "https://scholar.google.com/scholar?cluster=9515389348511179516&hl=en&oi=scholarr",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "ZzxSO8QAAAAJ:r4zddjZt6C4C",
            "Publisher": "WILEY"
        },
        {
            "Title": "Sparse deep-learning algorithm for recognition and categorisation",
            "Publication year": 2012,
            "Publication url": "https://ieeexplore.ieee.org/document/6329560/",
            "Abstract": "Presented is a deep-learning method for pattern classification and object recognition. The proposed methodology is based on an optimised version of the hierarchical temporal memory (HTM) algorithm and it preserves its basic structure, along with a tree structure of connected nodes. The tree structured scheme is inspired by the human neocortex, which provides great capabilities for recognition and categorisation. The proposed method is enriched with more representative quantisation centres using an adaptive neural gas algorithm, and a more accurate and dense grouping by applying a graph clustering technique. Sparse representation using  L 1  norm minimisation is embedded as a liaison between the quantisation centres and their grouping, reinforcing the proposed technique with advantages, such as a natural discrimination capability. The proposed work is experimentally compared with the aforementioned \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ZzxSO8QAAAAJ:sSrBHYA8nusC",
            "Publisher": "IET"
        },
        {
            "Title": "Location Assignment of Recognized Objects via a Multi-Camera System",
            "Publication year": 2011,
            "Publication url": "https://www.academia.edu/download/32385661/1.pdf",
            "Abstract": "This paper aims at making a contribution to a typical recognition scheme by means of providing position information of the recognized objects. In the near future, robotics systems are expected to be able to provide services in humans\u2019 daily life which can only be achieved if they are designed with advanced intelligent vision systems. Highly motivated from that fact, this work presents a framework capable of recognizing objects and estimating their location in the 3D space. The method excels in simplicity and computational cost, whilst its database can be easily adopted to the needs of simultaneous multi-object recognition. In real-life scenarios, lighting conditions may alter drastically and, along with possible shadow effects, may affect directly the efficiency of the visual data encoding scheme. Towards this end, recently proposed image enhancement methods emphasize in reducing the effect of unfavorable illumination conditions and their consequences. The proposed 3D position estimation framework was assessed under several image-enhancement conditions by means of selecting the most appropriate pre-processing algorithm.",
            "Abstract entirety": 1,
            "Author pub id": "ZzxSO8QAAAAJ:D03iK_w7-QYC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Social mapping on RGB-D scenes",
            "Publication year": 2014,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/6958512/",
            "Abstract": "The more the robotics technology tends to get established in human everyday life, the greater the necessity for robots to obtain social skills, facilitating their presence and behavior among humans. In order for robots to attain socially-aware characteristics, their navigation strategy should comply with a set of certain criteria, such as the respect of spatial interactions. Towards this end, the paper in hand presents a framework that operates on a single RGB-D scene. Initially it seeks the human presence and defines respective bounding boxes. Then, within the 3D reconstructed scene the people in the bounding boxes are replaced by points following a Gaussian distribution. The latter results to a grading occupancy grid, which complies with the spatial human comfort zones.",
            "Abstract entirety": 1,
            "Author pub id": "ZzxSO8QAAAAJ:dQJM2trw0wsC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Real-time disparity map computation module",
            "Publication year": 2008,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S014193310700124X",
            "Abstract": "Stereo vision deals with images acquired by a stereo camera setup, where the disparity between the stereo images allows depth estimation within a scene. 3D information, hence, is retrieved which is essential in many machine vision applications. Disparity map extraction of an image is a computationally demanding task. Previous work on disparity map computation is mainly limited to software based techniques on general-purpose architectures. In this paper a new hardware-efficient real-time disparity map computation module is developed. This enables a hardware-based cellular automata (CA) parallel-pipelined design, for the overall module, realized on a single FPGA device, the typical operating frequency of which is 256 MHz. Accurate disparity maps are computed at a rate of nearly 275 per second, for a stereo image pair with a disparity range of 80 pixels and 640 \u00d7 480 pixels spatial resolution. The presented \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ZzxSO8QAAAAJ:qjMakFHDy7sC",
            "Publisher": "Elsevier"
        },
        {
            "Title": "Real-time algorithm for obstacle avoidance using a stereoscopic camera",
            "Publication year": 2009,
            "Publication url": "https://www.academia.edu/download/30626906/real-time-algorithm-for-obstacle-avoidance.pdf",
            "Abstract": "This work presents a vision-based obstacle detection and avoidance method for autonomous mobile robots. The implementation of an algorithm able to navigate a robot in arbitrary environments usually demands of the synergy of several sensors. This work presents an algorithm employing only one sensor, ie a stereo camera, thus significantly diminishing the system\u2019s complexity. The implementation of this algorithm can be divided into two separate and independent modules. First, the stereo vision module retrieves information from the environment and produces disparity maps and then the decision making module analyses the data of the disparity maps and governs the robot\u2019s direction. The achieved frame rate ensures that the robot will have enough time to accomplish the proposed decisions in real time. Both of the modules have been implemented in C++. The complete algorithm has been examined by being applied on an extensive set of pre-captured stereo images.",
            "Abstract entirety": 1,
            "Author pub id": "ZzxSO8QAAAAJ:1sJd4Hv_s6UC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Robot navigation in large-scale social maps: An action recognition approach",
            "Publication year": 2016,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S0957417416305103",
            "Abstract": "As robots tend to establish their presence in every day human environments the necessity for them to attain socially acceptable behavior is a condition sine qua non. Consequently, robots need to learn and react appropriately, should they be able to share the same space with people and to reconcile their operation to man\u2019s activity. This work proposes an integrated robot framework that allows navigation in a human populated environment. This is the first work that employs the performed actions of individuals so as to re-plan and design a collision-free and at the same time a socially acceptable trajectory. Expandability is another feature of the suggested mapping module since it is capable of incorporating an unconstrained number of actions and subsequently responses, according to the needs of the task in hand and the environment in which the robot operates. Moreover, the paper addresses the integration of the \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ZzxSO8QAAAAJ:MDBbo4b0KHEC",
            "Publisher": "Pergamon"
        },
        {
            "Title": "SPARTAN: Efficient Implementation of Computer Vision Algorithms for Autonomous Rover Navigation",
            "Publication year": 2013,
            "Publication url": "https://vbn.aau.dk/en/publications/spartan-efficient-implementation-of-computer-vision-algorithms-fo-2",
            "Abstract": "SPARTAN: Efficient Implementation of Computer Vision Algorithms for Autonomous Rover \nNavigation \u2014 Aalborg University's Research Portal Skip to main navigation Skip to search \nSkip to main content Aalborg University's Research Portal Logo Dansk English Home \nProfiles Projects Publications Activities Research Units Facilities Press / Media Prizes \nDatasets Impacts Search by keywords, name or affiliation SPARTAN: Efficient \nImplementation of Computer Vision Algorithms for Autonomous Rover Navigation George \nLentaris, Dionysios Diamantopoulos, Kostas Siozios, Ioannis Stamoulias, Ioannis Kostavelis, \nEvangelos Boukas, Lazaros Nalpantidis, Dimitrios Soudris, Antonios Gasteratos, Marcos \nAviles Aviles Research output: Contribution to book/anthology/report/conference \nproceeding \u203a Article in proceeding \u203a Research \u203a peer-review 25 Downloads (Pure) Overview \nOriginal language English Title of host 7th on - - /\u2026",
            "Abstract entirety": 0,
            "Author pub id": "ZzxSO8QAAAAJ:5ugPr518TE4C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Can speedup assist accuracy? An on-board GPU-accelerated image georeference method for UAVs",
            "Publication year": 2015,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-319-20904-3_10",
            "Abstract": "This paper presents a georeferenced map extraction method, for Medium-Altitude Long-Endurance UAVs. The adopted technique of projecting world points to an image plane is a perfect candidate for a GPU implementation. The achieved high frame rate leads to a plethora of measurements even in the case of a low-power mobile processing unit. These measurements can later be combined in order to refine the output and create a more accurate result.",
            "Abstract entirety": 1,
            "Author pub id": "ZzxSO8QAAAAJ:MreiaWo1ERkC",
            "Publisher": "Springer, Cham"
        },
        {
            "Title": "Probabilistic appearance-based place recognition through bag of tracked words",
            "Publication year": 2019,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/8633405/",
            "Abstract": "A key feature in robotics applications is to recognize whether the current environment observation corresponds to a previously visited location. Should the place be recognized by the robot, a Loop Closure Detection (LCD) has occurred. The letter in hand deploys a novel low complexity LCD method based on the representation of the route by unique visual features (VFs). Each of these VFs, referred to as \u201cTracked Word\u201d (TW), is generated on-line through a tracking technique coupled with a guided feature-detection mechanism and belongs to a group of successive images. During the robot's navigation, new TWs are added to the database forming a bag of tracked words. When querying the database seeking for loop closures, the new local-feature descriptors are associated with the nearest neighboring TWs in the map casting votes to the corresponding instances. The system relies on a probabilistic method to select \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ZzxSO8QAAAAJ:pXiCqeVOhFwC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Comparison and evaluation of similarity measures for vergence angle estimation",
            "Publication year": 2007,
            "Publication url": "https://www.academia.edu/download/32588041/COMPARISON_AND_EVALUATION_OF.pdf",
            "Abstract": "This paper presents a comparison of various similarity measures developed for the real-time control of the vergence angle in an active vision robot head. The vergence angle can be estimated using several difference or correlation measures. These methods are studied comparatively for various image sizes. The Zero-mean Normalized Cross Correlation (ZNCC) measure proved to outperform the other methods. The results also show that we can sufficiently control the vergence mechanism, using images even 256 times smaller than the original (ie 40x30 pixels), in less than 1ms. We evaluated these results using by extracting the disparity maps of the stereo pair to test whether the disparity value is zeroed, when we reach the correct vergence angle. We also calculated the Mean Square Error (MSE) and the Normalized MSE (NMSE) of the correlation index between the sub-sampled and the initial images.",
            "Abstract entirety": 1,
            "Author pub id": "ZzxSO8QAAAAJ:dhFuZR0502QC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Novel personal digital support systems for Emergency Responders to a crises occurring in a Critical Infrastructure",
            "Publication year": 2010,
            "Publication url": "https://scholar.google.com/scholar?cluster=9584390004550088407&hl=en&oi=scholarr",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "ZzxSO8QAAAAJ:RfQ-KHj5eBsC",
            "Publisher": "Unknown"
        },
        {
            "Title": "A bio-inspired multi-camera system for dynamic crowd analysis",
            "Publication year": 2014,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S0167865513004650",
            "Abstract": "Analysis of crowd density has emerged nowadays as a hot topic issue related to the crowd safety and comfort and directly depended on the design and the operation of the crowded places under study. Usually multiple camera networks are employed to cover, monitor and improve the safety of people in large multifunctional crowded buildings. On the other hand, the art gallery problem is a computational geometry approach to a classical real-world visibility challenge. In a nutshell, it concerns the minimization of the free moving guards required to observe the entire gallery. In this paper we attempt to approach this problem from a novel perspective. To begin with, the number of guards are replaced by multiple cameras whose number should be minimized. At the same time, the observability of the camera network in the available space should be dynamically maximized, so as to observe the evolving density of the \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ZzxSO8QAAAAJ:Mojj43d5GZwC",
            "Publisher": "North-Holland"
        },
        {
            "Title": "Review of stereo matching algorithms for 3D vision",
            "Publication year": 2007,
            "Publication url": "https://www.diva-portal.org/smash/record.jsf?pid=diva2:463256",
            "Abstract": "Stereo vision, resulting in the knowledge of deep information in a scene, is of great importance in the field of machine vision, robotics and image analysis. As a result, in order to address the problem of matching points between two images of a stereo pair several algorithms have been proposed so far. In this paper, an explicit analysis of the existing stereo matching methods, up to date, is presented in full detail. The algorithms found in literature can be grouped into those producing sparse output and those giving a dense result, while the later can be classified as local (area-based) and global (energy-based). The presented algorithms are discussed in terms of speed, accuracy, coverage, time consumption and disparity range. Comparative test results concerning different image sizes as well as different stereo data sets are presented. Furthermore, the usage of advanced computational intelligence techniques such as neural networks and cellular automata in the development and application of such algorithms is also considered. However, due to the fact that the resulting depth calculation is a computationally demanding procedure, most of the presented algorithms perform poorly in real-time applications. Towards this direction, the development of real-time stereo matching algorithms, able to be efficiently implemented in dedicated hardware is of great interest in the contexts of 3D reconstruction, simultaneous localization and mapping (SLAM), virtual reality, robot navigation and control. Some possible implementations of stereo-matching algorithms in hardware for real-time applications are also discussed in details.",
            "Abstract entirety": 1,
            "Author pub id": "ZzxSO8QAAAAJ:Zph67rFs4hoC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Evaluation of shape descriptors for shape-based image retrieval",
            "Publication year": 2011,
            "Publication url": "https://ieeexplore.ieee.org/document/5963789/",
            "Abstract": "This article presents a comparative study between scale, rotation and translation invariant descriptors for shape representation and retrieval. Since shape is one of the most widely used image feature exploited in content-based image retrieval systems, the authors studied for each descriptor, the number of coefficients needed for indexing and their retrieval performance. Specifically, the authors studied Fourier, curvature scale space, angular radial transform (ART) and image moment descriptors for shape representation. The four shape descriptors are evaluated against each other using the standard methodology and the two most appropriate and available databases. The results showed that moment descriptors present the best performance in terms of shape representation quality while ART presents the lowest descriptor size.",
            "Abstract entirety": 1,
            "Author pub id": "ZzxSO8QAAAAJ:j3f4tGmQtD8C",
            "Publisher": "IET"
        },
        {
            "Title": "On the accuracy of the Eurohead",
            "Publication year": 2000,
            "Publication url": "https://scholar.google.com/scholar?cluster=4913799081844495090&hl=en&oi=scholarr",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "ZzxSO8QAAAAJ:Y0pCki6q_DkC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Development of A Holistic Framework for the Key Packaging Elements of Agri-Food Products.",
            "Publication year": 2020,
            "Publication url": "https://www.jestr.org/downloads/Volume13Issue3/fulltext41332020.pdf",
            "Abstract": "In this paper, a holistic methodological framework is developed aimed at the design and production of effective packaging that satisfies the needs of the modern market. Marketing and logistics managers, food technologists and social responsibility executives acknowledge the importance of a holistic approach to marketing and strive to consolidate their perception of such an approach and what it entails for packaging. Food producers can take account of these efforts and utilize those elements which emerge as being appreciated by all of the constituents cited above. To this end, primary research data was collected using a questionnaire that was completed by managers in the relevant business units of companies operating in the prepackaged agri-foodstuffs market in Greece, a major and competitive market.",
            "Abstract entirety": 1,
            "Author pub id": "ZzxSO8QAAAAJ:fXbrI0tPCuEC",
            "Publisher": "Unknown"
        },
        {
            "Title": "A fuzzy multi-sensor architecture for indoor navigation",
            "Publication year": 2010,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/5548497/",
            "Abstract": "This paper presents an indoor navigation system based on sensor data from first responder wearable modules. The proposed system integrates data from an inertial sensor, a digital camera and a radio frequency identification device using a sophisticated fuzzy algorithm. To improve the navigation accuracy, different types of first responder activities and operational conditions were examined and classified according to extracted qualitative attributes. The vertical acceleration data, which indicates the periodic vibration during gait cycle, is used to evaluate the accuracy of the inertial based navigation subsystem. The amount of strong feature correspondences assess the quality of the three-dimensional scene knowledge from digital camera feedback. Finally, the qualitative attribute, in order to evaluate the efficiency of the radio frequency identification subsystem, is the degree of probability of each location estimate \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ZzxSO8QAAAAJ:-f6ydRqryjwC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Learning the terrain and planning a collision-free trajectory for indoor post-disaster environments",
            "Publication year": 2012,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/6523901/",
            "Abstract": "Mobile robots dedicated in post-disaster missions should be capable of moving arbitrarily in unknown cluttered environments so as to accomplish their assigned security task. The paper in hand describes such an agent equipped with collision risk assessment capabilities, while it is able to trace an obstacle-free path in the scene as well. The robot exploits machine learning techniques for the traversability evaluation of the environment by making use of geometrical features, which derive from a postprocessing step of the depth map, obtained by an RGBD sensor. Then, the traversable scenes, are assessed by the likelihood the robot to collide on any arbitrary direction in front of it. Besides, the collision risk likelihood is combined with a path tracing algorithm based on Cellular Automata so that an obstacle-free route is then detected. The proposed method has been examined for several indoor scenarios revealing \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ZzxSO8QAAAAJ:eJXPG6dFmWUC",
            "Publisher": "IEEE"
        },
        {
            "Title": "The avert project: Autonomous vehicle emergency recovery tool",
            "Publication year": 2013,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/6719342/",
            "Abstract": "Terrorism threatens horrific loss of life, extensive disruption to city transport and damage to commercial real estate. Vehicles provide an ideal delivery mechanism because they can be meticulously prepared well in advance of deployment and then brought into the area of operations. Furthermore, a real and present danger comes from the threat of Chemical, Radiological, Biological and Nuclear (CRBN) contamination. Current methods of bomb disruption and neutralisation are hindered in the event that the device is shielded, blocked or for whatever reason cannot be accessed for examination. The Autonomous Vehicle Emergency Recovery Tool (AVERT) project introduces a unique capability to Police and Armed Services to rapidly deploy, extract and remove blocking vehicles from vulnerable positions such as enclosed infrastructure spaces, tunnels, low bridges as well as under-building and underground car \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ZzxSO8QAAAAJ:PFhWnMnuT1QC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Real\u2010time surveillance detection system for medium\u2010altitude long\u2010endurance unmanned aerial vehicles",
            "Publication year": 2018,
            "Publication url": "https://onlinelibrary.wiley.com/doi/abs/10.1002/cpe.4145",
            "Abstract": "The detection of ambiguous objects, although challenging, is of great importance for any surveillance system and especially for an unmanned aerial vehicle, where the measurements are affected by the great observing distance. Wildfire outbursts and illegal migration are only some of the examples that such a system should distinguish and report to the appropriate authorities. More specifically, Southern European countries commonly suffer from those problems due to the mountainous terrain and thick forests that contain. Unmanned aerial vehicles like the \u201cHellenic Civil Unmanned Air Vehicle\u201d project have been designed to address high\u2010altitude detection tasks and patrol the borders and woodlands for any ambiguous activity. In this paper, a moment\u2010based blob detection approach is proposed that uses the thermal footprint obtained from single infrared images and distinguishes human\u2010 or fire\u2010sized and shaped \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ZzxSO8QAAAAJ:-Viv1fr_sjoC",
            "Publisher": "Unknown"
        },
        {
            "Title": "A novel three stage technique for accurate disparity maps",
            "Publication year": 2005,
            "Publication url": "https://scholar.google.com/scholar?cluster=4815991738056697947&hl=en&oi=scholarr",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "ZzxSO8QAAAAJ:IuzW4o0J_HAC",
            "Publisher": "Unknown"
        },
        {
            "Title": "On visuo-inertial fusion for robot pose estimation using hierarchical fuzzy systems",
            "Publication year": 2012,
            "Publication url": "https://www.tandfonline.com/doi/abs/10.1080/15599612.2012.664241",
            "Abstract": "This article presents a novel application of a three level fuzzy hierarchical system for the fusion of visual and inertial pose estimations. The goal is to provide accurate and robust pose measurements of an indoor volant robot, which operates in real working conditions, in order to facilitate its control. The first level corrects the error of the inertial measurement unit based on the acceleration measurements. The second level fuses the measurements from the visual sensor with the ones from the first level. Finally, the output of the fuzzy hierarchical system is available at the third level; the inputs of which are the previous system's state and the one of the second level. The achieved results are compared to ground truth pose estimations, which are used to analyze the behavior of the proposed fusion system against possible changes. The system provides accurate and precise measurements, while its straightforward design \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ZzxSO8QAAAAJ:dshw04ExmUIC",
            "Publisher": "Taylor & Francis Group"
        },
        {
            "Title": "Semantic maps from multiple visual cues",
            "Publication year": 2017,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S0957417416305450",
            "Abstract": "Future service robots targeted to operate in domestic or industrial environment and in close collaboration with humans should possess the ability to produce meaningful internal perceptual representations of their own surroundings, enabling them to fulfill a variety of real-world tasks. For this purpose, we present here a semantic mapping framework featuring geometrical and semasiological attributes that reveal the relationships between objects and places in a real-life environment. The geometrical component consists of a 3D metric map, onto which a topological map is deployed. The semasiological part is realized by putting together a place recognition algorithm and an object recognition one. The categorization of the different places relies on the resolution of appearance-based consistency histograms, while for the recognition of objects in the scene, a hierarchical temporal memory (HTM) network boosted by a \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ZzxSO8QAAAAJ:hEp1lTclR2YC",
            "Publisher": "Pergamon"
        },
        {
            "Title": "Context-dependent social mapping",
            "Publication year": 2016,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/7738193/",
            "Abstract": "Advanced robotics systems in human frequented environments need to be equipped with avant-garde capabilities, so as to attain a social behavior acceptable by their human proprietors. Therefore, robots should learn and react properly when they share a common domain with humans and adjust their operation according to the activity of the people around. This paper proposes a social mapping method which makes use of 3D maps, action recognition and proxemics theory. In particular, as it moves around, the robot builds a metric map of the surroundings and arranges it in topological graphs. Meanwhile, it can detect any individual existing nearby and capitalizes on a deep learning technique to recognize its action. The recognized actions form the context-dependent social zones which are registered with specific proxemics rules to determine the robot's navigational behavior. The proposed method was assessed \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ZzxSO8QAAAAJ:0aNKY9CYzMkC",
            "Publisher": "IEEE"
        },
        {
            "Title": "A dense stereo correspondence algorithm for hardware implementation with enhanced disparity selection",
            "Publication year": 2008,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-540-87881-0_34",
            "Abstract": "In this paper an effective, hardware oriented stereo correspondence algorithm, able to produce dense disparity maps of improved fidelity is presented. The proposed algorithm combines rapid execution, simple and straight-forward structure as well as comparably high quality of results. These features render it as an ideal candidate for hardware implementation and for real-time applications. The proposed algorithm utilizes the Absolute Differences (AD) as matching cost and aggregates the results inside support windows, assigning Gaussian distributed weights to the support pixels, based on their Euclidean distance. The resulting Disparity Space Image (DSI) is furthered refined by Cellular Automata (CA) acting in all of the three dimensions of the DSI. The algorithm is applied to typical as well as to self-recorded real-life image sets. The disparity maps obtained are presented and quantitatively examined.",
            "Abstract entirety": 1,
            "Author pub id": "ZzxSO8QAAAAJ:Tyk-4Ss8FVUC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "Robust 3D vision for robots using dynamic programming",
            "Publication year": 2011,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/5962204/",
            "Abstract": "In this paper a new stereo vision method is presented that combines the use of a lightness-invariant pixel dissimilarity measure within a dynamic programming depth estimation framework. This method uses concepts such as the proper projection of the HSL colorspace for lightness tolerance, as well as the Gestalt-based adaptive support weight aggregation and a dynamic programming optimization scheme. The robust behavior of this method is suitable for the working environments of outdoor robots, where non ideal lighting conditions often occur. Such problematic conditions heavily affect the efficiency of robot vision algorithms in exploration, military and security applications. The proposed algorithm is presented and applied to standard image sets.",
            "Abstract entirety": 1,
            "Author pub id": "ZzxSO8QAAAAJ:YFjsv_pBGBYC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Learning Long-Term Behavior through Continuous Emotion Estimation",
            "Publication year": 2021,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/3453892.3461626",
            "Abstract": "Emotions convey concise information regarding an individual\u2019s internal state, while in the long-term they can be used to form an opinion about his/her overall personality. The latter can be proved particularly vital in many human-robot interaction tasks, like in the case of an assisted living robotic agent, where the human\u2019s mood may in turn require the adaptation of the robot\u2019s behavior. As a result, the paper at hand proposes a novel approach enabling an artificial agent to conceive and gradually learn the personality of a human, by tracking his emotional variations throughout their interaction time. To achieve that, the facial landmarks of the subject are extracted and fed into a Deep Neural Network architecture that estimates the two coefficients of human emotions, viz., arousal and valence, as introduced by the broadly known Russell\u2019s model. Finally, by creating a dashboard for user-friendly display of our results, we \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ZzxSO8QAAAAJ:HHUT0vUrEqMC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Disparity estimation on log-polar images and vergence control",
            "Publication year": 2001,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S1077314201909245",
            "Abstract": "An important issue in the realization of an autonomous robot with stereoscopic vision is the control of vergence. Together with version, it determines uniquely the position of the fixation point in space. Vergence control is directly related to both depth perception and binocular fusion. Previous works in this field employed either a measure of correlation of stereo images or some kind of disparity-related estimate. In this paper, we present a new method of extracting a global disparity measure for vergence control, which does not require a priori segmentation of the object of interest. Our method uses images acquired by retina-like sensors and, therefore, the computation is performed in the log-polar plane. The technique we present here is: (i) global, in the sense that it is an integral measure over the whole image, (ii) computationally inexpensive, considering that the goal was to use it in the robot control loop rather than to \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ZzxSO8QAAAAJ:u5HHmVD_uO8C",
            "Publisher": "Academic Press"
        },
        {
            "Title": "Safety certification requirements for domestic robots",
            "Publication year": 2012,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S0925753512001294",
            "Abstract": "Domestic robotics is a growing sector with the potential for a large number of commercial applications. Robotics technologies have been successfully applied in industrial production lines, yet, for them to be successful in a dynamic household environment the need for increased reliability, robustness and other special capabilities become paramount. We are not far from the time when people will live and interact with robots and, thus, safety becoming the fundamental issue to observe. Robot designers should produce safe products for humans no matter what failure, malfunction or mishandle may occur. Thus, respective safety procedures ought to be applied to domestic robots as well. The most critical challenge is to preserve safety of humans without forfeiting a single token of the efficiency required to perform any task. In this technical communication, the authors address the need for safety regulations in domestic \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ZzxSO8QAAAAJ:u9iWguZQMMsC",
            "Publisher": "Elsevier"
        },
        {
            "Title": "Encoding the description of image sequences: A two-layered pipeline for loop closure detection",
            "Publication year": 2016,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/7759667/",
            "Abstract": "In this paper we propose a novel technique for detecting loop closures on a trajectory by matching sequences of images instead of single instances. We build upon well established techniques for creating a bag of visual words with a tree structure and we introduce a significant novelty by extending these notions to describe the visual information of entire regions using Visual-Word-Vectors. The fact that the proposed approach does not rely on a single image to recognize a site allows for a more robust place recognition, and consequently loop closure detection, while reduces the computational complexity for long trajectory cases. We present evaluation results for multiple publicly available indoor and outdoor datasets using Precision-Recall curves, which reveal that our method outperforms other state of the art algorithms.",
            "Abstract entirety": 1,
            "Author pub id": "ZzxSO8QAAAAJ:PbVfkCSoiPoC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Place categorization through object classification",
            "Publication year": 2014,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/6958497/",
            "Abstract": "This paper proposes a novel methodology for place categorization in mobile robots based on the presence of objects. In order to achieve such categorization, the robot is equipped with an RGB-D sensor. For a given time interval the sensor's measurements are combined with robot's localization data and reconstruct the 3D scene from the respective pointclouds. Afterwards, the method searches for dominant planes which are the most probable locations for finding objects. Given those planes, this work seeks and discriminates objects. The recognized objects, form a distribution which is given as input to a Naive Bayesian classifier in order to categorize the place.",
            "Abstract entirety": 1,
            "Author pub id": "ZzxSO8QAAAAJ:BxcezVm2apwC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Pose estimation of a volant platform with a monocular visuo-inertial system",
            "Publication year": 2009,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/5071679/",
            "Abstract": "One of the serious problems in robotics applications is the estimation of the robot's pose. A lot of research effort has been put on finding the pose via inertial and proximity sensors. However, the last decades many systems adopt vision to estimate the pose, by using homographies and projection geometry. In this paper the pose estimation is achieved by the identification of a geometrically known platform from one camera and from the measurements of an inertial unit. The extended Kalman filter (EKF) is used for data fusion and error compensation. The novelty of this system is that the visual sensor and the inertial unit are mounted on different mobile systems. The proposed pose estimation system exhibits high accuracy in real-time.",
            "Abstract entirety": 1,
            "Author pub id": "ZzxSO8QAAAAJ:kNdYIx-mwKoC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Non-probabilistic cellular automata-enhanced stereo vision simultaneous localization and mapping",
            "Publication year": 2011,
            "Publication url": "https://iopscience.iop.org/article/10.1088/0957-0233/22/11/114027/meta",
            "Abstract": "In this paper, a visual non-probabilistic simultaneous localization and mapping (SLAM) algorithm suitable for area measurement applications is proposed. The algorithm uses stereo vision images as its only input and processes them calculating the depth of the scenery, detecting occupied areas and progressively building a map of the environment. The stereo vision-based SLAM algorithm embodies a stereo correspondence algorithm that is tolerant to illumination differentiations, the robust scale-and rotation-invariant feature detection and matching speeded-up robust features method, a computationally effective v-disparity image calculation scheme, a novel map-merging module, as well as a sophisticated cellular automata-based enhancement stage. A moving robot equipped with a stereo camera has been used to gather image sequences and the system has autonomously mapped and measured two different \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ZzxSO8QAAAAJ:BqipwSGYUEgC",
            "Publisher": "IOP Publishing"
        },
        {
            "Title": "EU FP6 Project RESCUER: the development of a dexterous robot and intelligent information technologies for EOD/IEDD/rescue missions",
            "Publication year": 2007,
            "Publication url": "https://www.academia.edu/download/32588049/EU_FP6_Project_RESCUER_the_development_of_a_dexterous_robot_and_intelligent_information.pdf",
            "Abstract": "The RESCUER project of the European Commission\u2019s 6th Framework Programme for Research, Technology Innovation and Demonstration focuses on the development of an intelligent Information and Communication Technology and mechatronic Emergency Risk Management tool for the improvement of Explosive Ordnance Disposal, Improvised Explosive Device Disposal, and Civil Protection Rescue Mission scenarios. The tool will be tested in five selected tasks. The project output will include guidance for management of risk, which extends the range of interventions possible beyond those, which are currently considered. The extended range of interventions will include tasks which are too risky at present to commit human involvement, tasks where access might not be possible without ICT and mechatronic support, tasks where such support would significantly enhance the speed, accuracy or range of tasks/sensors especially in EOD, IEDD, significant toxic/radiation/flammable/explosive contamination, mechanical failure and other relevant hazardous situations or combinations of hazards. The paper reviews the technical concepts formulated during the first eight months of the project.",
            "Abstract entirety": 1,
            "Author pub id": "ZzxSO8QAAAAJ:iH-uZ7U-co4C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Methods and techniques for intelligent navigation and manipulation for bomb disposal and rescue operations",
            "Publication year": 2007,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/4381291/",
            "Abstract": "Handing a teleoperated robotic mechanism demands special skills and involves particular problems. Especially in cases of robots dealing with rescue operations or bomb disposal. In such cases any lost in communications might arise unpredictable results. Also either a bomb or a survivor need attentional handling. In this paper we describe automatic methods and techniques developed on a multifunctional teleoperated robot. These intend to assist both the robot and the human operator in accomplishing their mission towards rescue or bomb disposal.",
            "Abstract entirety": 1,
            "Author pub id": "ZzxSO8QAAAAJ:RHpTSmoSYBkC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Image Moment Invariants as Local Features for Content Based Image Retrieval using The Bag-of-visual-Words Model",
            "Publication year": 2015,
            "Publication url": "http://hephaestus.nup.ac.cy/handle/11728/10143",
            "Abstract": "This paper presents an image retrieval framework that uses affine image moment invariants as descriptors of local image areas. Detailed feature vectors are generated by feeding the produced moments into a Bag-of-Visual-Words representation. Image moment invariants have been selected for their compact representation of image areas as well as due to their ability to remain unchanged under affine image transformations. Three different setups were examined in order to evaluate and discuss the overall approach. The retrieval results are promising compared with other widely used local descriptors, allowing the proposed framework to serve as a reference point for future image moment local descriptors applied to the general task of content based image retrieval.",
            "Abstract entirety": 1,
            "Author pub id": "ZzxSO8QAAAAJ:cAX_JoMERPUC",
            "Publisher": "Elsevier"
        },
        {
            "Title": "Localization of Planetary Exploration Rovers with Orbital Imaging: a survey of approaches",
            "Publication year": 2014,
            "Publication url": "https://pdfs.semanticscholar.org/8898/7bbd595440de8f00e2fda0fa60246fc6c8d3.pdf",
            "Abstract": "Localization of Planetary Exploration Rovers with Orbital Imaging: a survey of approaches Page \n1 Group of Robotics and Cognitive Systems http://robotics.pme.duth.gr/ School of Engineering, \nDemocritus University of Thrace, Xanthi, Greece Localization of Planetary Exploration Rovers \nwith Orbital Imaging: a survey of approaches Evangelos Boukas, Antonios Gasteratos and \nGianfranco Visentin Page 2 \u2022 Motivation \u2022 ESA Network/Partnering Initiative \u2022 Survey: \u2013 Descent \nImagery Presentation\u2019s Outline \u2013 Descent Imagery \u2013 Skyline (animated) \u2013 Terrain Matching \n(animated) \u2022 Assessment Framework \u2022 Conclusion June 1st, 2014, Hong-Kong, China ICRA14 \nWorkshop on Modelling, Estimation, Perception and Control of All Terrain Mobile Robots 2 \nPage 3 Motivation \u2022 Advanced space missions require increased autonomy \u2022 Localization \nis sine qua non for Space Exploratory Rovers June 1st, 2014, Hong-Kong, China on , , /\u2026",
            "Abstract entirety": 0,
            "Author pub id": "ZzxSO8QAAAAJ:Itmi1h0dExoC",
            "Publisher": "Unknown"
        },
        {
            "Title": "An active learning paradigm for online audio-visual emotion recognition",
            "Publication year": 2019,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/8937495/",
            "Abstract": "The advancement of Human-Robot Interaction (HRI) drives research into the development of advanced emotion identification architectures that fathom audio-visual (A-V) modalities of human emotion. State-of-the-art methods in multi-modal emotion recognition mainly focus on the classification of complete video sequences, leading to systems with no online potentialities. Such techniques are capable of predicting emotions only when the videos are concluded, thus restricting their applicability in practical scenarios. The paper at hand provides a novel paradigm for online emotion classification, which exploits both audio and visual modalities and produces a responsive prediction when the system is confident enough. We propose two deep Convolutional Neural Network (CNN) models for extracting emotion features, one for each modality, and a Deep Neural Network (DNN) for their fusion. In order to conceive the \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ZzxSO8QAAAAJ:kkSDTGFLcmwC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Visual assistance to an advanced mechatronic platform for pick and place tasks",
            "Publication year": 2010,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-642-16587-0_64",
            "Abstract": "Recent advances in mechanical and electronic engineering led to the building of more sophisticated mechatronic systems excelling in simplicity, reliability and versatility. On the contrary, the complexity of their parts necessitate integrated control systems along with advanced visual feedback. Generally, a vision system aims at bridging the gap between humans and machines in terms of providing to the latter information about what is perceived visually. This paper shows how the vision system of an advanced mechatronic framework named ACROBOTER is used for the localization of objects. ACROBOTER develops a new locomotion technology that can effectively be utilized in a workplace environment for manipulating small objects simultaneously. Its vision system is based on a multi-camera framework that is responsible for both finding patterns and providing their location in the 3D working space \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ZzxSO8QAAAAJ:70eg2SAEIzsC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "RobVision-Visually guiding a walking robot through a ship structure",
            "Publication year": 2000,
            "Publication url": "http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.58.6696&rep=rep1&type=pdf",
            "Abstract": "The EU funded ROBVISION project develops a vision system that finds and measures the location of 3D structures with respect to a CAD-model. The main objective is to build an integrated vision system capable of providing adequate information to navigate a walking robot through a ship structure. The key aspect is the integration of a CAD-model to visual measurement and the direct feedback of the measurement results. The objective is to render visual processing robust to deviations in parts and environmental conditions. To achieve this goal a technique is developed that integrates different cues of images to obtain confidence of the measurement result.",
            "Abstract entirety": 1,
            "Author pub id": "ZzxSO8QAAAAJ:4TOpqqG69KYC",
            "Publisher": "na"
        },
        {
            "Title": "On the evaluation of illumination compensation algorithms",
            "Publication year": 2018,
            "Publication url": "https://link.springer.com/article/10.1007/s11042-017-4783-x",
            "Abstract": "This paper presents a comparison framework for algorithms that can diminish the effects of illumination in images. Its main objective is to reveal the positive and negative characteristics of such algorithms, allowing researchers to select the most appropriate one for their target application. The proposed framework utilizes artificial illumination degradations on real images, which are then processed by the tested algorithms. The results are evaluated by an ensemble of performance metrics, highlighting the various characteristics of the algorithms across a range of different image attributes. The proposed framework represents a useful tool for the selection of illumination compensation algorithms due to a) its quantitative nature, b) its multifaceted analysis and c) its easy reproducibility. The validity of the proposed framework is tested by applying it to the enhancement results of four illumination compensation \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ZzxSO8QAAAAJ:KR6TXPE-FHQC",
            "Publisher": "Springer US"
        },
        {
            "Title": "MARMA: A Mobile Augmented Reality Maintenance Assistant for Fast-Track Repair Procedures in the Context of Industry 4.0",
            "Publication year": 2020,
            "Publication url": "https://www.mdpi.com/930678",
            "Abstract": "The integration of exponential technologies in the traditional manufacturing processes constitutes a noteworthy trend of the past two decades, aiming to reshape the industrial environment. This kind of digital transformation, which is driven by the Industry 4.0 initiative, not only affects the individual manufacturing assets, but the involved human workforce, as well. Since human operators should be placed in the centre of this revolution, they ought to be endowed with new tools and through-engineering solutions that improve their efficiency. In addition, vivid visualization techniques must be utilized, in order to support them during their daily operations in an auxiliary and comprehensive way. Towards this end, we describe a user-centered methodology, which utilizes augmented reality (AR) and computer vision (CV) techniques, supporting low-skilled operators in the maintenance procedures. The described mobile augmented reality maintenance assistant (MARMA) makes use of the handheld\u2019s camera and locates the asset on the shop floor and generates AR maintenance instructions. We evaluate the performance of MARMA in a real use case scenario, using an automotive industrial asset provided by a collaborative manufacturer. During the evaluation procedure, manufacturer experts confirmed its contribution as an application that can effectively support the maintenance engineers. View Full-Text",
            "Abstract entirety": 1,
            "Author pub id": "ZzxSO8QAAAAJ:twffdjNOitAC",
            "Publisher": "Multidisciplinary Digital Publishing Institute"
        },
        {
            "Title": "A Product Pose Tracking Paradigm Based on Deep Points Detection",
            "Publication year": 2021,
            "Publication url": "https://www.mdpi.com/2075-1702/9/6/112",
            "Abstract": "The paper at hand presents a novel and versatile method for tracking the pose of varying products during their manufacturing procedure. By using modern Deep Neural Network techniques based on Attention models, the most representative points to track an object can be automatically identified using its drawing. Then, during manufacturing, the body of the product is processed with Aluminum Oxide on those points, which is unobtrusive in the visible spectrum, but easily distinguishable from infrared cameras. Our proposal allows for the inclusion of Artificial Intelligence in Computer-Aided Manufacturing to assist the autonomous control of robotic handlers. View Full-Text",
            "Abstract entirety": 1,
            "Author pub id": "ZzxSO8QAAAAJ:SSGWEqmz6gUC",
            "Publisher": "Multidisciplinary Digital Publishing Institute"
        },
        {
            "Title": "Fault diagnosis of photovoltaic modules through image processing and Canny edge detection on field thermographic measurements",
            "Publication year": 2015,
            "Publication url": "https://www.tandfonline.com/doi/abs/10.1080/14786451.2013.826223",
            "Abstract": "Today, conventional condition monitoring of installed, operating photovoltaic (PV) modules is mainly based on electrical measurements and performance evaluation. However, such practices exhibit restricted fault-detection ability. This study proposes the use of standard thermal image processing and the Canny edge detection operator as diagnostic tools for module-related faults that lead to hot-spot heating effects. The intended techniques were applied on thermal images of defective PV modules, from several field infrared thermographic measurements conducted during this study. The whole approach provided promising results with the detection of hot-spot formations that were diagnosed to specific defective cells in each inspected module. These evolving hot spots lead to abnormally low performance of the PV modules, a fact that is also validated by the manufacturer's standard electrical tests.",
            "Abstract entirety": 1,
            "Author pub id": "ZzxSO8QAAAAJ:wbdj-CoPYUoC",
            "Publisher": "Taylor & Francis"
        },
        {
            "Title": "SPARTAN project: On profiling computer vision algorithms for rover navigation",
            "Publication year": 2012,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/6268647/",
            "Abstract": "The exploration of Mars is one of the main goals for NASA/ESA, as confirmed by past and recent activities. One of the most challenging tasks for these missions is the autonomous robot's navigation. Existing approaches incorporate vision-based solutions and exhibit remarkable results in term of accuracy. Unfortunately, these approaches affect mostly computational and memory intensive algorithms running on software-level. In this paper, we introduce a novel methodology for efficient implementation of computer vision algorithms for the SPARTAN project (ExoMars 2018 mission). Experimental results prove the effectiveness of the introduced solution, as compared to a software-based implementation.",
            "Abstract entirety": 1,
            "Author pub id": "ZzxSO8QAAAAJ:SP6oXDckpogC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Deep learning features exception for cross-season visual place recognition",
            "Publication year": 2017,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S0167865517303963",
            "Abstract": "The use of Convolutional Neural Networks (CNNs) in image analysis and recognition paved the way for long-term visual place recognition. The transferable power of generic descriptors extracted at different layers of off-the-shelf CNNs has been successfully exploited in various visual place recognition scenarios. In this paper we tackle this problem by extracting the full output of an intermediate layer and building an image descriptor of lower dimensionality by omitting the activation of filters corresponding to environmental changes. Thus, we are able to increase the robustness of the cross-season visual place recognition. We test our approach on the Nordland dataset, the biggest and the most challenging dataset up to date, where the included four seasons induce great illumination and appearance changes. The experiments show that our new approach can significantly increase, up to 14%, the baseline (single \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ZzxSO8QAAAAJ:4DpXlaHga4wC",
            "Publisher": "North-Holland"
        },
        {
            "Title": "Laboratory of Robotics and Automation",
            "Publication year": 2011,
            "Publication url": "https://scholar.google.com/scholar?cluster=16702693301644898331&hl=en&oi=scholarr",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "ZzxSO8QAAAAJ:s_JjmAzd-pQC",
            "Publisher": "Unknown"
        },
        {
            "Title": "RobVision: vision based navigation for mobile robots",
            "Publication year": 2001,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/1013517/",
            "Abstract": "This paper introduces the system, developed during the Esprit project RobVision (robust vision for sensing in industrial operations and needs), that navigates a climbing robot through a ship section for inspection and welding tasks. The basic idea is to continuously generate robot position and orientation (pose) signals by matching the visual sensing information from the environment with predetermined CAD-information. The key for robust behaviour is the integration of two different vision methods: one measures the 3D junctions with a stereo head, the other tracks the edge and junction features in a single image. To render robust and fast tracking, a model knowledge such as the feature topology, object side, and view dependent information is utilised. The pose calculation step then integrates the finding of both vision systems, detects outliers and sends the result to the robot. The real-time capability is important to \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ZzxSO8QAAAAJ:0EnyYjriUFMC",
            "Publisher": "IEEE"
        },
        {
            "Title": "A comparison framework for the evaluation of illumination compensation algorithms",
            "Publication year": 2013,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/6729703/",
            "Abstract": "This paper presents a new comparison framework, with the view to help researchers in selecting the most appropriate illumination compensation algorithm to serve as a preprocessing step in computer vision applications. The main objective of this framework is to reveal the positive and negative characteristics of the algorithms, rather than providing a single metric to rank their overall performance. The comparison tests, that comprise the proposed framework, aim to quantitatively evaluate the efficiency of algorithms in diminishing the effects of illumination in images. The proposed framework utilizes synthetic images, with artificial illumination degradations, which are enhanced by the tested algorithms. It represents a useful tool for the selection of illumination compensation algorithms as preprocessing in other applications, due to (a) its quantitative nature, (b) its easy implementation and (c) its useful estimations \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ZzxSO8QAAAAJ:olpn-zPbct0C",
            "Publisher": "IEEE"
        },
        {
            "Title": "Image stabilization in active robot vision",
            "Publication year": 2010,
            "Publication url": "https://books.google.com/books?hl=en&lr=&id=xAmhDwAAQBAJ&oi=fnd&pg=PA261&dq=info:x9KgSO2HIfEJ:scholar.google.com&ots=urvCEdI54b&sig=-z4eRVVvdeSuPADMpa5nyHFf66A",
            "Abstract": "Recent demands in sophisticated mobile robots require many semi-autonomous or even autonomous operations, such as decision making, simultaneous localization and mapping, motion tracking and risk assessment, while operating in dynamic environments. Most of these capabilities depend highly on the quality of the input from the cameras mounted on the mobile platforms and require fast processing times and responses. However, quality in robot vision systems is not given only by the quantitative features such as the resolution of the cameras, the frame rate or the sensor gain, but also by the qualitative features such as sequences free of unwanted movement, fast and good image pre-processing algorithms and real-time response. A robot having optimal quantitative features for its vision system cannot achieve the finest performance when the qualitative features are not met. Image stabilization is one of the most important qualitative features for a mobile robot vision system, since it removes the unwanted motion from the frame sequences captured from the cameras. This image sequence enhancement is necessary in order to improve the performance of the subsequently complicated image processing algorithms that will be executed. Many image processing applications require stabilized sequences for input while other present substantially better performance when processing stabilized sequences. Intelligent transportation systems equipped with vision systems use digital image stabilization for substantial reduction of the algorithm computational burden and complexity (Tyan et al.(2004)),(Jin et al.(2000)). Video communication systems \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ZzxSO8QAAAAJ:dhZ1Wuf5EGsC",
            "Publisher": "BoD\u2013Books on Demand"
        },
        {
            "Title": "An efficient method to reconstruct prismatic rigid objects by multiple camera arrangements",
            "Publication year": 2012,
            "Publication url": "https://iopscience.iop.org/article/10.1088/0957-0233/23/11/114006/meta",
            "Abstract": "An efficient method to reconstruct prismatic rigid objects by multiple camera arrangements is presented in this paper. The proposed method estimates accurately the dominant vanishing points in remarkably short time. First, concurrent multiple views from the distinct cameras located at the upper corners of a room are used as the input to the algorithm. An implementation of the Radon transform is then applied in order to detect line segments across the respective views. An initial hypothesis about the existing vanishing points is made. The J-linkage algorithm is utilized to cluster the different groups of line segments and to refine the calculation of the respective vanishing points. The regions across the multi-camera system are then distinguished and the correspondences across the multiple views of the test room are obtained. Last, the volume of objects is estimated accurately with multiple cross ratios along the images \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ZzxSO8QAAAAJ:LPZeul_q3PIC",
            "Publisher": "IOP Publishing"
        },
        {
            "Title": "Active camera stabilization with a fuzzy-grey controller",
            "Publication year": 2009,
            "Publication url": "https://scholar.google.com/scholar?cluster=807862749652132498&hl=en&oi=scholarr",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "ZzxSO8QAAAAJ:rQcm2j6_ZE8C",
            "Publisher": "Unknown"
        },
        {
            "Title": "EU FP6 Project RESCUER: The development of a dexterous robot and intelligent information technologies for EOD",
            "Publication year": 2005,
            "Publication url": "https://scholar.google.com/scholar?cluster=8240427679613487830&hl=en&oi=scholarr",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "ZzxSO8QAAAAJ:N8RR74vhTp4C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Development of a stereo vision system for remotely operated robots: A control and video streaming architecture",
            "Publication year": 2008,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/4592745/",
            "Abstract": "This paper describes the open and flexible architecture of a stereo vision system prototype, using open source software. The system is designed for teleoperated robots and includes a four degrees of freedom stereo head mechanism, a pair of high performance digital cameras, a head tracker and a head mounted display. All processes for the head control and video streaming are performed in Linux-based Real-time Operating Systems using open source libraries under GPL license. Experimental results showed that our system is capable of satisfying the hard-real time requirements for the head control, with great precision, and a low latency for the stereo video streaming. The video streaming management is particularly sophisticated resulting in a flexible, efficient and reliable service.",
            "Abstract entirety": 1,
            "Author pub id": "ZzxSO8QAAAAJ:_kc_bZDykSQC",
            "Publisher": "IEEE"
        },
        {
            "Title": "A Full-Scale Hardware Solution for Crowd Evacuation via Multiple Cameras",
            "Publication year": 2014,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-319-10807-0_6",
            "Abstract": "Crowd evacuation is thoroughly investigated in recent years. All efforts focus on improving safety standards of such a process. Past and latest life-threatening incidents related to evacuation procedures justify both the growing scientific interest as well as the interdisciplinary character of most research approaches. In this chapter, we describe the hardware implementation of a management system that aims at acting anticipatively against crowd congestion during evacuation. The system consists of two structural components. The first one relies on an elaborated form of the Viola et al. [55] detection and tracking algorithm, which incorporates both appearance and motion in real-time. Being supported by cameras, this algorithm realises the initialisation process. In principal, it consists of simple sum-of-pixel filters that are boosted into a strong classifier. A linear combination of these filters properly set thresholds \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ZzxSO8QAAAAJ:lf0D1wPZyaoC",
            "Publisher": "Springer, Cham"
        },
        {
            "Title": "ViPED: On-road vehicle passenger detection for autonomous vehicles",
            "Publication year": 2019,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S0921889018302045",
            "Abstract": "This paper is about detecting and counting the passengers of a tracking vehicle using on-car monocular vision. By having a model of nearby vehicle occupants, intelligent reasoning systems of autonomous cars will be provided with this additional knowledge needed in emergency situations such as those that many philosophers have recently raised. The on-road Vehicle PassengEr Detection (ViPED) system is based on the human perception model in terms of spatio-temporal reasoning, namely the slight movements of passenger shape silhouettes inside the cabin. The main challenges we face are the low light conditions of the cabin (no feature points), the subtle non-rigid motions of the occupants (possible artifactual transitions), and the puzzling discrimination problem of back or front seat occupants (lack of depth information inside the cabin). To overcome these challenges, we first track the detected car \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ZzxSO8QAAAAJ:UO6ax3c-pNsC",
            "Publisher": "North-Holland"
        },
        {
            "Title": "Improving the robustness in feature detection by local contrast enhancement",
            "Publication year": 2012,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/6295482/",
            "Abstract": "This paper presents a new feature detector, with improved local contrast performance. The proposed method is based on an improved non-linear version of the classic Difference of Gaussians, which exhibits increased sensitivity to low contrast. Additionally, it does not employ computationally expensive or memory demanding routines. In order to evaluate the degree of illumination invariance that the proposed, as well as, other existing detectors exhibit, a new benchmark image database has been created. It features a greater variety of imaging conditions, compared to existing databases, containing real scenes under various degrees and combinations of uniform and non-uniform illumination. Experimental results show that the proposed detector extracts greater number of features, with high level of repeatability, compared to other existing ones. These results are evident for both uniform and non-uniform illumination \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ZzxSO8QAAAAJ:08ZZubdj9fEC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Recognition of 2-d shapes inspired by the human visual system",
            "Publication year": 2010,
            "Publication url": "https://content.iospress.com/articles/journal-of-computational-methods-in-sciences-and-engineering/jcm00288",
            "Abstract": "This paper presents a new method suitable for shape recognition, inspired by the Primary Visual Cortex of the Human Visual System. It extracts a description for 2-dimensional shapes with a closed contour, regardless of their size, rotation and position, with low computational cost. The paper introduces a new computational approach to the modeling of the hypercolumns of the Primary Visual Cortex, which requires significantly less computational burden and which is highly parallel. A new shape descriptor based on the relative angles of an object is also proposed. It produces close results for different shapes of the same object, it is proportion-flexible and it can identify distorted shapes correctly. Experimental results prove that the method is adequate for shape-based image retrieval and classification, as well as for efficiently storage of edges and line drawings.",
            "Abstract entirety": 1,
            "Author pub id": "ZzxSO8QAAAAJ:M05iB0D1s5AC",
            "Publisher": "IOS Press"
        },
        {
            "Title": "Digital elevation model fusion using spectral methods",
            "Publication year": 2014,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/6958501/",
            "Abstract": "This paper presents the application of different spectral methods, like Fourier series and polynomial-based expansions, to Digital Elevation Models (DEMs) in order to fuse their content. Two different fusion techniques: 1) a filter-based one and 2) a weighted average of expansion coefficients, are examined. Their performance is evaluated by using both ground-truth lidar data as well as fusion quality measures. The results point out that polynomial-based spectral expansions perform better than the traditional Fourier approach.",
            "Abstract entirety": 1,
            "Author pub id": "ZzxSO8QAAAAJ:Et1yZiPVzsMC",
            "Publisher": "IEEE"
        },
        {
            "Title": "HASeparator: Hyperplane-Assisted Softmax",
            "Publication year": 2020,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/9356294/",
            "Abstract": "Efficient feature learning with Convolutional Neural Networks (CNNs) constitutes an increasingly imperative property since several challenging tasks of computer vision tend to require cascade schemes and modalities fusion. Feature learning aims at CNN models capable of extracting embeddings, exhibiting high discrimination among the different classes, as well as intra-class compactness. In this paper, a novel approach is introduced that has separator, which focuses on an effective hyperplane-based segregation of the classes instead of the common class centers separation scheme. Accordingly, an innovatory separator, namely the Hyperplane-Assisted Softmax separator (HASeparator), is proposed that demonstrates superior discrimination capabilities, as evaluated on popular image classification benchmarks.",
            "Abstract entirety": 1,
            "Author pub id": "ZzxSO8QAAAAJ:VDARjI3xf8gC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Efficient hierarchical matching algorithm for processing uncalibrated stereo vision images and its hardware architecture",
            "Publication year": 2011,
            "Publication url": "https://ieeexplore.ieee.org/iel5/4149689/5963771/05963788.pdf",
            "Abstract": "In motion estimation, the sub-pixel matching technique involves the search of sub-sample positions as well as integer-sample positions between the image pairs, choosing the one that gives the best match. Based on this idea, this work proposes an estimation algorithm, which performs a 2-D correspondence search using a hierarchical search pattern. The intermediate results are refined by 3-D cellular automata (CA). The disparity value is then defined using the distance of the matching position. Therefore the proposed algorithm can process uncalibrated and non-rectified stereo image pairs, maintaining the computational load within reasonable levels. Additionally, a hardware architecture of the algorithm is deployed. Its performance has been evaluated on both synthetic and real self-captured image sets. Its attributes, make the proposed method suitable for autonomous outdoor robotic applications.",
            "Abstract entirety": 1,
            "Author pub id": "ZzxSO8QAAAAJ:pqnbT2bcN3wC",
            "Publisher": "IET"
        },
        {
            "Title": "Fast Dynamic Range Compression for Grayscale Images",
            "Publication year": 2007,
            "Publication url": "https://www.researchgate.net/profile/Antonios-Gasteratos/publication/235350541_Fast_Dynamic_Range_Compression_for_Grey_Scale_Images/links/54721df70cf2d67fc035c3f2/Fast-Dynamic-Range-Compression-for-Grey-Scale-Images.pdf",
            "Abstract": "This paper presents a new center-surround network for the dynamic range compression of grayscale images. The proposed method exploits some of the shunting characteristics of biological center-surround networks, in order to reduce the effects of uneven illumination and improve the dynamic range of images. The main advantage of the proposed method is its low computational burden, which allows the rendition of high-resolution 5-MPixel images in approximately 1.3 seconds, when executed by a conventional personal computer. The method is compared to the latest commercial version of the Retinex algorithm, and exhibits promising results for a wide variety of real images and lighting conditions.",
            "Abstract entirety": 1,
            "Author pub id": "ZzxSO8QAAAAJ:g5m5HwL7SMYC",
            "Publisher": "Unknown"
        },
        {
            "Title": "DOSeqSLAM: Dynamic on-line sequence based loop closure detection algorithm for SLAM",
            "Publication year": 2018,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/8577113/",
            "Abstract": "Simultaneous Localization and Mapping (SLAM) is vital for modern autonomous robots. Visual place recognition of pre-visited areas, widely known as Loop Closure Detection (LCD), constitutes one of the most important SLAM components. In this paper a sequence-based LCD algorithm is proposed by evolving SeqSLAM method. Instead of using fixed-size sequences' length during search process, as in the original approach, we suggest a dynamical length definition based on the images' content proximity. Specifically, sequence segmentation is achieved through a feature matching technique applied on the incoming visual sensory information, while the mechanism operates on-line without the need of any pre-training procedure. Each sequence's similarity score, produced by a weighted average function, is utilized as a decision factor for the loop closing selection. Finally, an extended image-to-image search in the \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ZzxSO8QAAAAJ:G60ApcfeQaAC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Autonomous robot path planning techniques using cellular automata",
            "Publication year": 2015,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-319-10924-4_8",
            "Abstract": "Path planning for autonomous navigation remains an active research topic, ensuring safe maneuver of mobile robots in congestive environments by producing collision free trajectories. To this end, this chapter introduces the amalgamation of path planning techniques with Cellular Automata (CA) operations in order to embody analogous desired properties. These navigation systems are consist of signee scene and global map components. Regarding the single scene method presented here, it achieves obstacle free routes from the current position of the robot towards the goal one. The latter serves as local planner and is accomplished via the attenuation of a v-disparity image formed upon the respective depth map. Afterwards, a CA floor field is created revealing the traversable regions within the scene. Once the target point is brought to light, a supplementary CA routine is performed on the floor field to \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ZzxSO8QAAAAJ:2C0LhDdYSbcC",
            "Publisher": "Springer, Cham"
        },
        {
            "Title": "Adaptive document binarization",
            "Publication year": 2007,
            "Publication url": "https://www.researchgate.net/profile/Antonios-Gasteratos/publication/221415249_Adaptive_document_binarization_A_human_vision_approach/links/0912f505a1e127129a000000/Adaptive-document-binarization-A-human-vision-approach.pdf",
            "Abstract": "This paper presents a new approach to adaptive document binarization, inspired by the attributes of the Human Visual System (HVS). The proposed algorithm combines the characteristics of the OFF ganglion cells of the HVS with the classic Otsu binarization technique. Ganglion cells with four receptive field sizes tuned to different spatial frequencies are employed, which, adopting a new activation function, are independent of gradual illumination changes, such as shadows. The Otsu technique is then used for thresholding the outputs of the ganglion cells, resulting to the final segmentation of the characters from the background. The proposed method was quantitatively and qualitatively tested against other contemporary adaptive binarization techniques in various shadow levels and noise densities, and it was found to outperform them.",
            "Abstract entirety": 1,
            "Author pub id": "ZzxSO8QAAAAJ:k_IJM867U9cC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Finding the 3D orientation of a line using hough transform and a stereo pair",
            "Publication year": 2000,
            "Publication url": "http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.11.9958",
            "Abstract": "In human vision system, the differences between the left and right images are used to recover 3D properties of a scene. Similarly on an artificial vision system, the differences between the two images can be used for the extraction of many useful 3D characteristics such as the depth, the surface normal and the exact position of a point. In this report we derive the formulation for the computation of a line in space based on its projections on a stereo pair of images and on the angle of converge of the two cameras. Experiments have been carried out that shows using our setup the proposed technique is rather unstable. Solutions for future implementations are proposed, which are rising the estimation range of the Hough accumulation array, and increasing the length of the baseline.",
            "Abstract entirety": 1,
            "Author pub id": "ZzxSO8QAAAAJ:lR2ECBI0YV4C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Stereo-based visual odometry for autonomous robot navigation",
            "Publication year": 2016,
            "Publication url": "https://journals.sagepub.com/doi/abs/10.5772/62099",
            "Abstract": "Mobile robots should possess accurate self-localization capabilities in order to be successfully deployed in their environment. A solution to this challenge may be derived from visual odometry (VO), which is responsible for estimating the robot's pose by analysing a sequence of images. The present paper proposes an accurate, computationally-efficient VO algorithm relying solely on stereo vision images as inputs. The contribution of this work is twofold. Firstly, it suggests a non-iterative outlier detection technique capable of efficiently discarding the outliers of matched features. Secondly, it introduces a hierarchical motion estimation approach that produces refinements to the global position and orientation for each successive step. Moreover, for each subordinate module of the proposed VO algorithm, custom non-iterative solutions have been adopted. The accuracy of the proposed system has been evaluated and \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ZzxSO8QAAAAJ:SQZOXlr1FBsC",
            "Publisher": "SAGE Publications"
        },
        {
            "Title": "A bio-inspired multi-camera topology for crowd analysis",
            "Publication year": 2012,
            "Publication url": "https://www.researchgate.net/profile/Antonios-Gasteratos/publication/236166906_A_Bio-inspired_Multi-camera_Topology_for_Crowd_Analysis/links/5471d2ec0cf216f8cfad16c0/A-Bio-inspired-Multi-camera-Topology-for-Crowd-Analysis.pdf",
            "Abstract": "This paper presents a bio-inspired method for introducing an adequate multi-camera topology aiming to maximize the coverage of the available space for sufficient crowd analysis. More specifically, a twofold bio-inspired approach is proposed, taking into advantage the emergent computation that arrives from swarms able to find solutions to complex mathematical problems which keep computers busy for days. In the proposed approach, artificial bumblebees are used to determine the number of requested cameras needed to maximize the coverage of an available space subject under the safety specifications dictated by the crowd analysis application, while artificial spiders following the way they wave their webs indicate the exact positions of the aforementioned cameras in the under study crowd environment. Experimental results show that the algorithm is capable of producing promising results where 95% coverage of the given room is possible.",
            "Abstract entirety": 1,
            "Author pub id": "ZzxSO8QAAAAJ:A7-hzOuI2KQC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Stereo vision depth estimation methods for robotic applications",
            "Publication year": 2012,
            "Publication url": "https://www.igi-global.com/chapter/depth-map-imaging-applications/60277",
            "Abstract": "Vision is undoubtedly the most important sense for humans. Apart from many other low and higher level perception tasks, stereo vision has been proven to provide remarkable results when it comes to depth estimation. As a result, stereo vision is a rather popular and prosperous subject among the computer and machine vision research community. Moreover, the evolution of robotics and the demand for vision-based autonomous behaviors has posed new challenges that need to be tackled. Autonomous operation of robots in real working environments, given limited resources requires effective stereo vision algorithms. This chapter presents suitable depth estimation methods based on stereo vision and discusses potential robotic applications.",
            "Abstract entirety": 1,
            "Author pub id": "ZzxSO8QAAAAJ:p2g8aNsByqUC",
            "Publisher": "IGI global"
        },
        {
            "Title": "Sequence-based visual place recognition: a scale-space approach for boundary detection",
            "Publication year": 2021,
            "Publication url": "https://link.springer.com/article/10.1007/s10514-021-09984-7",
            "Abstract": "In the field of visual Place Recognition (vPR), sequence-based techniques have received close attention since they combine visual information from multiple measurements to enhance the results. This paper is concerned with the task of identifying sequence boundaries, corresponding to physical scene limits of the robot\u2019s trajectory, that can potentially be re-encountered during an autonomous mission. In contrast to other vPR techniques that select a predefined length for all the image sequences, our approach focuses on a dynamic segmentation and allows for the visual information to be consistently grouped between different visits of the same area. To achieve this, we compute similarity measurements between consecutively acquired frames to incrementally formulate a similarity signal. Then, local extrema are detected in the Scale-Space domain regardless the velocity that a camera travels and perceives the \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ZzxSO8QAAAAJ:Uo5fLKClJkAC",
            "Publisher": "Springer US"
        },
        {
            "Title": "A recursive fuzzy system for efficient digital image stabilization",
            "Publication year": 2008,
            "Publication url": "https://www.hindawi.com/journals/afs/2008/920615/",
            "Abstract": "A novel digital image stabilization technique is proposed in this paper. It is based on a fuzzy Kalman compensation of the global motion vector (GMV), which is estimated in the log-polar plane. The GMV is extracted using four local motion vectors (LMVs) computed on respective subimages in the logpolar plane. The fuzzy Kalman system consists of a fuzzy system with the Kalman filter's discrete time-invariant definition. Due to this inherited recursiveness, the output results into smoothed image sequences. The proposed stabilization system aims to compensate any oscillations of the frame absolute positions, based on the motion estimation in the log-polar domain, filtered by the fuzzy Kalman system, and thus the advantages of both the fuzzy Kalman system and the log-polar transformation are exploited. The described technique produces optimal results in terms of the output quality and the level of compensation.",
            "Abstract entirety": 1,
            "Author pub id": "ZzxSO8QAAAAJ:hC7cP41nSMkC",
            "Publisher": "Hindawi"
        },
        {
            "Title": "A co-design methodology for implementing computer vision algorithms for rover navigation onto reconfigurable hardware",
            "Publication year": 2011,
            "Publication url": "https://www.academia.edu/download/32588016/A_CO-DESIGN_METHODOLOGY_FOR_IMPLEMENTING_COMPUTER_VISION_ALGORITHMS_FOR_ROVER_NAVIGATION_ONTO_RECONFIGURABLE_HARDWARE.pdf",
            "Abstract": "Vision-based robotics applications have been widely studied in the last years. However, up to now solutions that have been proposed were affecting mostly software level. The SPARTAN project focuses in the tight and optimal implementation of computer vision algorithms targeting to rover navigation. For evaluation purposes, these algorithms will be implemented with a co-design methodology onto a Virtex-6 FPGA device.",
            "Abstract entirety": 1,
            "Author pub id": "ZzxSO8QAAAAJ:uWQEDVKXjbEC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Image moment invariants as local features for content based image retrieval using the bag-of-visual-words model",
            "Publication year": 2015,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S0167865515000239",
            "Abstract": "This paper presents an image retrieval framework that uses affine image moment invariants as descriptors of local image areas. Detailed feature vectors are generated by feeding the produced moments into a Bag-of-Visual-Words representation. Image moment invariants have been selected for their compact representation of image areas as well as due to their ability to remain unchanged under affine image transformations. Three different setups were examined in order to evaluate and discuss the overall approach. The retrieval results are promising compared with other widely used local descriptors, allowing the proposed framework to serve as a reference point for future image moment local descriptors applied to the general task of content based image retrieval.",
            "Abstract entirety": 1,
            "Author pub id": "ZzxSO8QAAAAJ:mqcSLZKRP28C",
            "Publisher": "North-Holland"
        },
        {
            "Title": "The Vision System of the ACROBOTER Project",
            "Publication year": 2009,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-642-10817-4_94",
            "Abstract": "The ACROBOTER project aims to develop a radically new locomotion technology that can effectively be used in a home and/or in a workplace environment for manipulating small objects autonomously. It extends the workspace of existing indoor service robots in the vertical direction, whilst its novel structure allows covering the whole volume of a room. For the adequate accomplishment of demanding manipulating tasks, its vision system must provide vital visual information concerning the position of the robot in the 3D working space and the topology of possible objects/obstacles in robot\u2019s trajectory. Thus, the proposed system is capable of: estimating robot\u2019s pose in the room; reconstruct the 3D working space and; recognize objects with remarkable efficiency. In this work, initially, we present the basic structure of ACROBOTER and its vision system and, we also evaluate the aforementioned functions.",
            "Abstract entirety": 1,
            "Author pub id": "ZzxSO8QAAAAJ:TFP_iSt0sucC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "3d maps registration and path planning for autonomous robot navigation",
            "Publication year": 2013,
            "Publication url": "https://arxiv.org/abs/1312.2822",
            "Abstract": "Mobile robots dedicated in security tasks should be capable of clearly perceiving their environment to competently navigate within cluttered areas, so as to accomplish their assigned mission. The paper in hand describes such an autonomous agent designed to deploy competently in hazardous environments equipped with a laser scanner sensor. During the robot's motion, consecutive scans are obtained to produce dense 3D maps of the area. A 3D point cloud registration technique is exploited to merge the successively created maps during the robot's motion followed by an ICP refinement step. The reconstructed 3D area is then top-down projected with great resolution, to be fed in a path planning algorithm suitable to trace obstacle-free trajectories in the explored area. The main characteristic of the path planner is that the robot's embodiment is considered for producing detailed and safe trajectories of   resolution. The proposed method has been evaluated with our mobile robot in several outdoor scenarios revealing remarkable performance.",
            "Abstract entirety": 1,
            "Author pub id": "ZzxSO8QAAAAJ:WA5NYHcadZ8C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Adaptive card-based production control policies",
            "Publication year": 2017,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S0360835216304363",
            "Abstract": "This article is about adaptive production control policies based on Kanban and CONWIP. First, it is shown that the Extended Kanban and the Generalized Kanban control policies, which have not been considered up to now in the relevant literature, actually fall within the category of adaptive card-based production control policies. Moving further, two novel adaptive production control policies are proposed, the Adaptive Generic Kanban and the Adaptive Extended Kanban. The proposed policies along with Extended Kanban and Generalized Kanban are compared in a simulation study to five existing adaptive approaches for controlling Kanban and CONWIP systems. It is noted that a comparative evaluation of these five existing adaptive policies is also absent from the relevant bibliography. The set of nine policies is tested in a tri-objective optimization problem, i.e. minimizing mean Work-In-Process, mean finished \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ZzxSO8QAAAAJ:njp6nI0QjqAC",
            "Publisher": "Pergamon"
        },
        {
            "Title": "A robotic assembly procedure using 3D object reconstruction",
            "Publication year": 2014,
            "Publication url": "https://vbn.aau.dk/ws/files/208912539/AAU_assembly.pdf",
            "Abstract": "Aalborg Universitet A robotic assembly procedure using 3D object reconstruction Chrysostomou, \nDimitrios; Bitzidou, Malamati; Gas Page 1 Aalborg Universitet A robotic assembly procedure \nusing 3D object reconstruction Chrysostomou, Dimitrios; Bitzidou, Malamati; Gasteratos, \nAntonios Publication date: 2014 Document Version Accepted author manuscript, peer reviewed \nversion Link to publication from Aalborg University Citation for published version (APA): \nChrysostomou, D., Bitzidou, M., & Gasteratos, A. (2014). A robotic assembly procedure using 3D \nobject reconstruction. Abstract from 2nd AAU Workshop on Robotics, Aalborg, Denmark. General \nrights Copyright and moral rights for the publications made accessible in the public portal \nare retained by the authors and/or other copyright owners and it is a condition of accessing \npublications that users recognise and abide by the legal requirements associated with . -\u2026",
            "Abstract entirety": 0,
            "Author pub id": "ZzxSO8QAAAAJ:HE397vMXCloC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Simple-Shape Classification Based on the Human Visual System",
            "Publication year": 2005,
            "Publication url": "https://www.researchgate.net/profile/Antonios-Gasteratos/publication/235350539_Simple_Shape_Classification_Based_on_the_Human_Visual_System/links/00b4952b5cb7a9d1a1000000/Simple-Shape-Classification-Based-on-the-Human-Visual-System.pdf",
            "Abstract": "This paper presents a new method suitable for shape classification, inspired by the early processing levels of the human visual system. It extracts a description for any simple 2-dimensional shape having a closed contour, regardless of its size, rotation and position, in affordable computational cost. The paper introduces a new approach to the modeling of the hypercolumns of the primary visual cortex, which requires significantly less computational burden and that is highly parallel. A new shape descriptor based on the relative angles of an object is also proposed. It produces close results for different shapes of the same object, it is proportion-flexible and it can identify distorted shapes correctly. Experimental results prove that the method is adequate for industrial production applications based on shape classification, as well as for shape-based image retrieval.",
            "Abstract entirety": 1,
            "Author pub id": "ZzxSO8QAAAAJ:mB3voiENLucC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Real-time video surveillance by a hybrid static/active camera mechatronic system",
            "Publication year": 2010,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/5695742/",
            "Abstract": "In this paper we present an effective real-time video surveillance system for real-life outdoor surveillance scenarios. The system is an integration of two subsystems: the static camera and moving one. The approaches employed address properly the challenges that might arise in a typical outdoor scene, such as local and global lighting changes, variations in objects' appearance and occlusions. Our aim is to detect and follow abnormal behaviors, which may occur when vehicles and pedestrians interact typical urban environment. Static camera subsystem operates multiple object tracking and classification. In case that an object of special interest is identified, the operation of the moving camera subsystem initiates, in order to track this object and record its activity.",
            "Abstract entirety": 1,
            "Author pub id": "ZzxSO8QAAAAJ:abG-DnoFyZgC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Binary, gray-scale, and vector soft mathematical morphology: extensions, algorithms, and implementations",
            "Publication year": 2001,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S1076567001800859",
            "Abstract": "This chapter discusses standard morphological operations, their algebraic properties, and fuzzy morphology. Soft morphological filters are a relatively new subclass of nonlinear filters. They were introduced to improve the behavior of standard morphological filters in noisy environments. Soft mathematical morphology and the definitions of vector soft morphological operations, their basic properties, and their use in color impulse noise attenuation are provided in the chapter. Several implementations of soft morphological filters and an implementation of vector morphological filters are analyzed in the chapter. Soft morphological operations are based on weighted order statistics. Algorithms for implementation of soft morphological operations include the well-known mergesort and quicksort algorithms for weighted order statistics computation. Fuzzy soft mathematical morphology applies the concepts \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ZzxSO8QAAAAJ:HDshCWvjkbEC",
            "Publisher": "Elsevier"
        },
        {
            "Title": "Revisiting the bag-of-visual-words model: A hierarchical localization architecture for mobile systems",
            "Publication year": 2019,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S0921889018305293",
            "Abstract": "In this paper, an enhanced visual place recognition system is proposed aiming to improve the localization performance of a mobile platform. Our technique takes full advantage of the continuous input image stream in order to provide additional knowledge to the matching functionality. The well-established Bag-of-Visual-Words model is adapted into a hierarchical design that derives the visual information from the full entity of a natural scene into the description, while it additionally preserves the geometric structure of the explored world. Our approach is evaluated as part of a state-of-the-art Simultaneous-Localization-and-Mapping algorithm, and parallelization techniques are exploited utilizing every available hardware module in a low-power device. The implemented algorithm has been tested on several publicly available datasets offering consistently accurate localization results and preventing the majority of \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ZzxSO8QAAAAJ:TpYZtc-0n-8C",
            "Publisher": "North-Holland"
        },
        {
            "Title": "A LoCATe\u2010based visual place recognition system for mobile robotics and GPGPUs",
            "Publication year": 2018,
            "Publication url": "https://onlinelibrary.wiley.com/doi/abs/10.1002/cpe.4146",
            "Abstract": "In this paper, a novel visual Place Recognition approach is evaluated based on a visual vocabulary of the Color and Edge Directivity Descriptor (CEDD) to address the loop closure detection task. Even though CEDD was initially designed so as to globally describe the color and texture information of an input image addressing Image Indexing and Retrieval tasks, its scalability on characterizing single feature points has already been proven. Thus, instead of using CEDD as a global descriptor, we adopt a bottom\u2010up approach and use its localized version, Local Color And Texture dEscriptor, as an input to a state\u2010of\u2010the\u2010art visual Place Recognition technique based on Visual Word Vectors. Also, we use a parallel execution pipeline based on a previous work of ours using the well established General Purpose Graphics Processing Unit (GPGPU) computing. Our experiments show that the usage of CEDD as a local \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ZzxSO8QAAAAJ:Oi-j_DTgP3cC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Efficient priority rules for dynamic sequencing with sequence-dependent setups",
            "Publication year": 2016,
            "Publication url": "http://m.growingscience.com/beta/ijiec/2222-efficient-priority-rules-for-dynamic-sequencing-with-sequence-dependent-setups.html",
            "Abstract": "This article addresses the problem of dynamic sequencing on n identical parallel machines with stochastic arrivals, processing times, due dates and sequence-dependent setups. The system operates under a completely reactive scheduling policy and the sequence of jobs is determined with the use of dispatching rules. Seventeen existing dispatching rules are considered including standard and setup-oriented rules. The performance of the system is evaluated by four metrics. An experimental study of the system is conducted where the effect of categorical and continuous system parameters on the objective functions is examined. In light of the results from the simulation experiments, a parameterized priority rule is introduced and tested. The simulation output is analyzed using rigorous statistical methods and the proposed rule is found to produce significantly better results regarding the metrics of mean cycle time and mean tardiness in single machine cases. In respect to three machine cases, the proposed rule matches the performance of the best rule from the set of existing rules which were studied in this research for three metrics.",
            "Abstract entirety": 1,
            "Author pub id": "ZzxSO8QAAAAJ:eCFM_hdDfssC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Collision risk assessment for autonomous robots by offline traversability learning",
            "Publication year": 2012,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S0921889012000486",
            "Abstract": "Autonomous robots should be able to move freely in unknown environments and avoid impacts with obstacles. The overall traversability estimation of the terrain and the subsequent selection of an obstacle-free route are prerequisites of a successful autonomous operation. This work proposes a computationally efficient technique for the traversability estimation of the terrain, based on a machine learning classification method. Additionally, a new method for collision risk assessment is introduced. The proposed system uses stereo vision as a first step in order to obtain information about the depth of the scene. Then, a v-disparity image calculation processing step extracts information-rich features about the characteristics of the scene, which are used to train a support vector machine (SVM) separating the traversable and non-traversable scenes. The ones classified as traversable are further processed exploiting the \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ZzxSO8QAAAAJ:UxriW0iASnsC",
            "Publisher": "North-Holland"
        },
        {
            "Title": "Multi-layer map: Augmenting semantic visual memory",
            "Publication year": 2020,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/9213923/",
            "Abstract": "The modern view of things in the science of robotics imposes that when working in a human environment, understanding of its equivalent semantics is required. In this paper, we present a graph-based unsupervised semantic clustering method and a novel cluster matching technique, with a view to create a multi-layer semantic memory map robust to illumination changes. Using indoor data collected by an unmanned aerial robot (UAR) and a publicly available dataset, we apply a community detection algorithm (CDA) to find efficiently coherent visual data throughout the trajectory creating a semantic base map. Then, we optimize the formed communities using metric information by implementing an hierarchical agglomerative clustering algorithm. The multilayer semantic map is created by constructing map instances for variant lighting conditions and matching the generated clusters to their base map correspondence \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ZzxSO8QAAAAJ:ealulPZkXgsC",
            "Publisher": "IEEE"
        },
        {
            "Title": "ACROBOTER: a ceiling based crawling, hoisting and swinging service robot platform",
            "Publication year": 2009,
            "Publication url": "https://www.cl.cam.ac.uk/events/drd09/papers/toth.pdf",
            "Abstract": "Concept and design of a new indoor service robot locomotion technology are described in the paper. The proposed solution extends the workspace of existing indoor ground based service robots in the vertical direction, while ensuring higher payload capability than aerial robots and less environment invasive than industrial gantry robots. The concept under development is highly innovative in the sense that it will combine the planar stepping motion of an arm on the ceiling in 2D, and the thrusted-hoisted pendulum like motion of the working unit in 3D relative to the arm. This is a novel approach to cover the whole volume of a room. In addition, the ACROBOTER is designed to work autonomously or in close cooperation with humans and to be capable of collaborating with other robotic devices.",
            "Abstract entirety": 1,
            "Author pub id": "ZzxSO8QAAAAJ:Wp0gIr-vW9MC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Path tracing on polar depth maps for robot navigation",
            "Publication year": 2012,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-642-33350-7_41",
            "Abstract": "In this paper a Cellular Automata-based (CA) path estimation algorithm suitable for safe robot navigation is presented. The proposed method combines well established 3D vision techniques with CA operations and traces a collision free route from the foot of the robot to the horizon of a scene. Firstly, the depth map of the scene is obtained and, then, a polar transformation is applied. A v-disparity image calculation processing step is applied to the initial depth map separating the ground plane from the obstacles. In the next step, a CA floor field is formed representing all the distances from the robot to the traversable regions in the scene. The target point that the robot should move towards to, is tracked down and an additional CA routine is applied to the floor field revealing a traversable route that the robot should follow to reach its target location.",
            "Abstract entirety": 1,
            "Author pub id": "ZzxSO8QAAAAJ:tS2w5q8j5-wC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "Graph based localisation refinement by orbital images",
            "Publication year": 2012,
            "Publication url": "http://robotics.estec.esa.int/i-SAIRAS/isairas2012/Papers/Session%203A/03A_02_boukas.pdf",
            "Abstract": "The paper in hand proposes a localization algorithm, where refinements in the robot\u2019s trajectory take place by exploiting the orbital images that cover the same area as a surface exploratory robot. It makes use of elementary graph theory terms in order to compare the 3D reconstructed area with the respective satellite image by examining the spatial distribution of the salient landmarks between the two different views. The utilized dissimilarity metric is the Graph Edit Distance (GED), which compares the two views and defines wether improvements in global orientation and position of the robot should be done. Once there is an indication for improvement the Iterative Closest Point (ICP) algorithm is used to refine the position of the robot backwards to the last executed orbital refinement. The proposed method is evaluated in unstructured non-urban scenes, where canonical formations are not available, as it is the case of space environments.",
            "Abstract entirety": 1,
            "Author pub id": "ZzxSO8QAAAAJ:geHnlv5EZngC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Enhancement of perceptually salient contours using a parallel artificial cortical network",
            "Publication year": 2006,
            "Publication url": "https://link.springer.com/article/10.1007/s00422-005-0040-x",
            "Abstract": "In this paper we present a parallel artificial cortical network inspired by the Human visual system, which enhances the salient contours of an image. The network consists of independent processing elements, which are organized into hypercolumns. They process concurrently the distinct orientations of all the edges of the image. These processing elements are a new set of orientation kernels appropriate for the discrete lattice of the hypercolumns. The Gestalt laws of proximity and continuity that describe the process of saliency extraction in the human brain are encoded by means of weights. These weights interconnect the kernels according to a novel connection pattern based on co-exponentiality. The output of every kernel is modulated by the outputs of its neighboring kernels, according to a new affinity function. This function takes into account the degree of difference between the facilitation of the two lobes \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ZzxSO8QAAAAJ:YOwf2qJgpHMC",
            "Publisher": "Springer-Verlag"
        },
        {
            "Title": "Accelerating image super-resolution regression by a hybrid implementation in mobile devices",
            "Publication year": 2014,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/6776029/",
            "Abstract": "This paper introduces a new super-resolution algorithm based on machine learning along with a novel hybrid implementation for next generation mobile devices. The proposed super-resolution algorithm entails a multivariate polynomial regression method using only the input image properties for the learning task. Although it is widely believed that machine learning algorithms are not appropriate for real-time implementation, the paper in hand proves that there are indeed specific hypothesis representations that are able to be integrated into real-time mobile applications. With aim to achieve this goal, we take advantage of the increasing GPU employment in modern mobile devices. More precisely, we utilize the mobile GPU as a co-processor in a hybrid pipelined implementation achieving significant performance speedup along with superior quantitative interpolation results.",
            "Abstract entirety": 1,
            "Author pub id": "ZzxSO8QAAAAJ:PbrqR9PZhrEC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Supervised traversability learning for robot navigation",
            "Publication year": 2011,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-642-23232-9_26",
            "Abstract": "This work presents a machine learning method for terrain\u2019s traversability classification. Stereo vision is used to provide the depth map of the scene. Then, a v-disparity image calculation and processing step extracts suitable features about the scene\u2019s characteristics. The resulting data are used as input for the training of a support vector machine (SVM). The evaluation of the traversability classification is performed with a leave-one-out cross validation procedure applied on a test image data set. This data set includes manually labeled traversable and non-traversable scenes. The proposed method is able to classify the scene of further stereo image pairs as traversable or non-traversable, which is often the first step towards more advanced autonomous robot navigation behaviours.",
            "Abstract entirety": 1,
            "Author pub id": "ZzxSO8QAAAAJ:ns9cj8rnVeAC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "Matching Sparse Networks of Semantic ROIs Among Rover and Orbital Imagery",
            "Publication year": 2015,
            "Publication url": "http://robotics.estec.esa.int/ASTRA/Astra2015/Presentations/Session%208B/99000_Boukas.pdf",
            "Abstract": "Matching Sparse Networks of Semantic ROIs Among Rover and Orbital Imagery Page 1 Group \nof Robotics and Cognitive Systems http://robotics.pme.duth.gr/ Democritus University of Thrace \nDepartment of Production and Management Engineering, Greece European Space Agency, \nEuropean Space Research and Technology Centre (ESTEC) Network/Partnering Initiative \n(NPI) Matching Sparse Networks of Semantic ROIs Among Rover and Orbital Imagery \nEvangelos Boukas, Antonios Gasteratos, Gianfranco Visentin Page 2 Outline \u2022 Motivation \u2022 ESA \nNetwork/Partnering Initiative (NPI) \u2022 Related Work \u2022 Global Localization System \u2022 Repeatability \nof Matching \u2022 Discussion - Conclusions 5/19/2015 Advanced Space Technologies in Robotics \nand Automation (ASTRA 2015) 2 Page 3 Outline \u2022 Motivation \u2022 ESA Network/Partnering \nInitiative (NPI) \u2022 Related Work \u2022 Global Localization System \u2022 Repeatability of Matching \u2022 - 5/19\u2026",
            "Abstract entirety": 0,
            "Author pub id": "ZzxSO8QAAAAJ:zEYdoEEwLqEC",
            "Publisher": "Unknown"
        },
        {
            "Title": "An advanced walking vehicle with autonomous navigation capabilities",
            "Publication year": 2000,
            "Publication url": "https://www.academia.edu/download/30626950/an-advanced-walking-vehicle-with-autonomous-naviation-capabilities.pdf",
            "Abstract": "Legged machine technology is constantly improving and as the result the world is moving closer and closer to a scenario in which walking robots are Widespread. Before this can happen, such machines must be shown to be safe and reliable\u2014an attribute that has previously been very difficult to demonstrate. Robots that stumble and bump into terrain features are classic examples of robots with inef\ufb01cient controlling strategies; with each terrain contact there is a loss of energy and accelerated wear and tear on the vehicle, resulting in a reduction of the expected lifespan. in the deveiopment of a legged robot that can efficiently negotiate unrnapped rough terrain it is believed to be necessary to be able to combine autonomous navigation facilities with the ability to learn and react adaptively to the unknown terrain contours. This paper presents a new legged robot system that combines revolutionary vision-based \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ZzxSO8QAAAAJ:QNfnWKgKwv8C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Bio-inspired deep learning model for object recognition",
            "Publication year": 2013,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/6729661/",
            "Abstract": "This paper proposes a bio-inspired deep learning architecture for object recognition and classification. The image samples are subjected to a saliency-based pre-processing step suitable for scene analysis and feature derivation. This preprocessing step bears similarities with the primate visual system which also assembles a saliency map. Thereafter, the deep learning model which relies upon the Hierarchical Temporal Memories (HTM) notion is utilized to form the corresponding feature vector. The latter HTM architecture consists of a tree shaped hierarchy of computational nodes where all nodes perform an identical procedure. Concerning the node operation, it forms representative vectors in order to sufficiently describe the input space. Afterwards, the representative vectors are utilized in order to derive spatial groups. The samples are expressed according to their degree of similarity with these groups using the L \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ZzxSO8QAAAAJ:69viAa4lnfgC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Human and fire detection from high altitude uav images",
            "Publication year": 2015,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/7092737/",
            "Abstract": "Illegal migration as well as wildfires constitute commonplace situations in southern European countries, where the mountainous terrain and thick forests make the surveillance and location of these incidents a tall task. This territory could benefit from Unmanned Aerial Vehicles (UAVs) equipped with optical and thermal sensors in conjunction with sophisticated image processing and computer vision algorithms, in order to detect suspicious activity or prevent the spreading of a fire. Taking into account that the flight height is about to two kilometers, human and fire detection algorithms are mainly based on blob detection. For both processes thermal imaging is used in order to improve the accuracy of the algorithms, while in the case of human recognition information like movement patterns as well as shadow size and shape are also considered. For fire detection a blob detector is utilized in conjunction with a color based \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ZzxSO8QAAAAJ:GfAJFcoWUJEC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Fuzzy vergence control for an active binocular vision system",
            "Publication year": 2008,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/4798931/",
            "Abstract": "Vergence control in binocular vision systems involves the adjustment of the angle between the two cameras' axes so that they are both fixated at the same point of interest. Vergence enables stereo vision systems to perceive depth and to acquire obstacle maps. Vergence movement is directly related to the binocular fusion. Additionally, the decision for convergence or divergence is extracted either by motion affine models or by mathematical ones. In this paper, a new method for extracting the cameras' movement direction, for verge or diverge, is presented. The movement decision is performed by a fuzzy control system, the inputs of which are the zero-mean normalized cross correlation (ZNCC) and the depth estimations at each time step. The suggested system can be used in any active binocular system and is computationally inexpensive. Moreover, the proposed system is independent to a priori camera calibration.",
            "Abstract entirety": 1,
            "Author pub id": "ZzxSO8QAAAAJ:qUcmZB5y_30C",
            "Publisher": "IEEE"
        },
        {
            "Title": "Intelligent Integrated Vision System for Indoor Robotics Applications",
            "Publication year": 2009,
            "Publication url": "https://www.academia.edu/download/30626909/intelligent-integrated-vision-system-for-indoor-robotics-applications.pdf",
            "Abstract": "In the last few years, a remarkable increase of robots\u2019 usage in domestic environments has been observed. A wealth of research is devoted in building new frameworks capable of assisting people in everyday life. Furthermore, systems introduced into domestic environments aim to substitute humans in house chores such as tidying child\u2019s bedroom after a party or collecting clothes before they enter the washing machines. The need of robots working closely to human beings makes a necessity the usage of intelligent sensorial system. In this work we present a novel intelligent integrated vision system that is able to: reconstruct the 3D working space of a room; recognize objects and estimate their pose; perform edge detection and extract the optical flow of a moving subject.",
            "Abstract entirety": 1,
            "Author pub id": "ZzxSO8QAAAAJ:GjXqcohcbckC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Robots in crisis management: A survey",
            "Publication year": 2017,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-319-67633-3_4",
            "Abstract": "Robots are flexible intelligent machines designed to replace human operators in dangerous, dirty, and dull tasks. Therefore, an apparent application of robotics is to provide assistance in managing critical situations, by carrying out tasks that might be harmful for us. Indeed, almost any police corps around the globe is nowadays equipped with a a counter improvise explosive device (IED) robot. Although counter-IED robots constitute the most famous robots for crisis management, they formulate just one of the areas that robots can be used for. An abundance of research has been performed through the last ten years in safety, security and rescue robotics. This paper attempts to review the efforts reported so far. Moreover, it attempts to systemize the robots for crisis management, in the sense that it categorizes them according to the specific use and examines which architecture would be most suitable for each \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ZzxSO8QAAAAJ:vM5yiaU9oLoC",
            "Publisher": "Springer, Cham"
        },
        {
            "Title": "Computationally effective stereovision SLAM",
            "Publication year": 2010,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/5548507/",
            "Abstract": "In this paper a visual Simultaneous Localization and Mapping (SLAM) algorithm suitable for indoor area measurement applications is proposed. The algorithm is focused on computational effectiveness. The only sensor used is a stereo camera placed onboard a moving robot. The algorithm processes the acquired images calculating the depth of the scenery, detecting occupied areas and progressively building a map of the environment. The stereo vision-based SLAM algorithm embodies a custom-tailored stereo correspondence algorithm, the robust scale and rotation invariant feature detection and matching Speeded Up Robust Features (SURF) method, a computationally effective v-disparity image calculation scheme, a novel map-merging module, as well as a sophisticated Cellular Automata (CA)-based enhancement stage. The proposed algorithm is suitable for autonomously mapping and measuring indoor \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ZzxSO8QAAAAJ:r0BpntZqJG4C",
            "Publisher": "IEEE"
        },
        {
            "Title": "Introducing a globally consistent orbital\u2010based localization system",
            "Publication year": 2018,
            "Publication url": "https://onlinelibrary.wiley.com/doi/abs/10.1002/rob.21739",
            "Abstract": "In spite of the good performance of space exploratory missions, open issues still await to be solved. In autonomous or composite semi\u2010autonomous exploration of planetary land surfaces, rover localization is such an issue. The rovers of these missions (e.g., the MER and MSL) navigate relatively to their landing spot, ignoring their exact position on the coordinate system defined for the celestial body they explore. However, future advanced missions, like the Mars Sample Return, will require the localization of rovers on a global frame rather than the arbitrarily defined landing frame. In this paper we attempt to retrieve the absolute rover's location by identifying matching Regions of Interest (ROIs) between orbital and land images. In particular, we propose a system comprising two parts, an offline and an onboard one, which functions as follows: in advance of the mission a Global ROI Network (GN) is built offline by \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ZzxSO8QAAAAJ:Rj7SuZOA3CsC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Learning to track colored objects with log-polar vision",
            "Publication year": 2004,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S0957415804000510",
            "Abstract": "An approach bringing together space-variant vision through a simple color segmentation technique and learning is presented. The proposed approach is employed to control the movement of a 5 degree of freedom (d.o.f.) robotic head. Color information is used to determine the position of the object of interest in the image plane and, consequently, to track it during its motion. The distance of the target from the center of the image is used to feed both a closed-loop and an open-loop controller. Most important, the parameters of the controllers are learnt on-line in a self-supervised fashion. Experiments are presented to demonstrate empirically the feasibility of the approach and its application to a real world control problem.",
            "Abstract entirety": 1,
            "Author pub id": "ZzxSO8QAAAAJ:d1gkVwhDpl0C",
            "Publisher": "Pergamon"
        },
        {
            "Title": "Learning spatially semantic representations for cognitive robot navigation",
            "Publication year": 2013,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S0921889013001346",
            "Abstract": "Contemporary mobile robots should exhibit enhanced capacities, which allow them self-localization and semantic interpretation as they move into an unexplored environment. The coexistence of accurate SLAM and place recognition can provide a descriptive and adaptable navigation model. In this paper such a two-layer navigation scheme is introduced suitable for indoor environments. The low layer comprises a 3D SLAM system based solely on an RGB-D sensor, whilst the high one employs a novel content-based representation algorithm, suitable for spatial abstraction. In course of robot\u2019s locomotion, salient visual features are detected and they shape a bag-of-features problem, quantized by a Neural Gas to code the spatial information for each scene. The learning procedure is performed by an SVM classifier able to accurately recognize multiple dissimilar places. The two layers mutually interact with a \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ZzxSO8QAAAAJ:V3AGJWp-ZtQC",
            "Publisher": "North-Holland"
        },
        {
            "Title": "Appearance-Based Loop Closure Detection with Scale-Restrictive Visual Features",
            "Publication year": 2019,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-030-34995-0_7",
            "Abstract": "In this paper, an appearance-based loop closure detection pipeline for autonomous robots is presented. Our method uses scale-restrictive visual features for image representation with a view to reduce the computational cost. In order to achieve this, a training process is performed, where a feature matching technique indicates the features\u2019 repeatability with respect to scale. Votes are distributed into the database through a nearest neighbor method, while a binomial probability function is responsible for the selection of the most suitable loop closing pair. Subsequently, a geometrical consistency check on the chosen pair follows. The method is subjected into an extensive evaluation via a variety of outdoor, publicly-available datasets revealing high recall rates for 100 precision, as compared against its baseline version, as well as, other state-of-the-art approaches.",
            "Abstract entirety": 1,
            "Author pub id": "ZzxSO8QAAAAJ:gubd_9ZgCi8C",
            "Publisher": "Springer, Cham"
        },
        {
            "Title": "Fast image retrieval based on attributes of the human visual system",
            "Publication year": 2006,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/4052219/",
            "Abstract": "In this paper we present a new method for content-based image retrieval (CBIR), based on the retinal signal processing of the human visual system (HVS). A center-surround operator similar to the receptive fields of the ganglion cells of the retina is employed to create a new form of color histogram, the center-surround histogram (CSH). Unlike other proposed color histograms, the CSH takes into consideration only the visual signal surrounding the zero-crossings of an image. This reduces the processed amount of visual information and minimizes the computational burden. Furthermore, a combination of spatial and chromatic information of the image is also achieved. The method is compared to other contemporary methods for image retrieval, exhibiting better results in shorter computational times",
            "Abstract entirety": 1,
            "Author pub id": "ZzxSO8QAAAAJ:7PzlFSSx8tAC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Can Speedup Assist Accuracy? An On-Board GPU-Accelerated Image Georeference Method for UAVs",
            "Publication year": 2015,
            "Publication url": "https://books.google.com/books?hl=en&lr=&id=KuPyCQAAQBAJ&oi=fnd&pg=PA104&dq=info:8nX9HYdvHakJ:scholar.google.com&ots=RwNUeDAkPi&sig=Ey9SL_fHpcXpWesVcAlwRBMqxNs",
            "Abstract": "This paper presents a georeferenced map extraction method, for Medium-Altitude Long-Endurance UAVs. The adopted technique of projecting world points to an image plane is a perfect candidate for a GPU implementation. The achieved high frame rate leads to a plethora of measurements even in the case of a low-power mobile processing unit. These measurements can later be combined in order to refine the output and create a more accurate result.",
            "Abstract entirety": 1,
            "Author pub id": "ZzxSO8QAAAAJ:w2Aknop99M4C",
            "Publisher": "Springer"
        },
        {
            "Title": "Mathematical morphology operations and structuring elements",
            "Publication year": 2001,
            "Publication url": "https://scholar.google.com/scholar?cluster=4067638309721500693&hl=en&oi=scholarr",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "ZzxSO8QAAAAJ:LHWLPdAD5FMC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Cognitive navigation dataset, group of robotics and cgnitive systems",
            "Publication year": 2012,
            "Publication url": "https://scholar.google.com/scholar?cluster=10067425544937525646&hl=en&oi=scholarr",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "ZzxSO8QAAAAJ:SkU8VjQp03IC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Stereovision-based algorithm for obstacle avoidance",
            "Publication year": 2009,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-642-10817-4_19",
            "Abstract": "This work presents a vision-based obstacle avoidance algorithm for autonomous mobile robots. It provides an efficient solution that uses a minimum of sensors and avoids, as much as possible, computationally complex processes. The only sensor required is a stereo camera. The proposed algorithm consists of two building blocks. The first one is a stereo algorithm, able to provide reliable depth maps of the scenery in frame rates suitable for a robot to move autonomously. The second building block is a decision making algorithm that analyzes the depth maps and deduces the most appropriate direction for the robot to avoid any existing obstacles. The proposed methodology has been tested on sequences of self-captured outdoor images and its results have been evaluated. The performance of the algorithm is presented and discussed.",
            "Abstract entirety": 1,
            "Author pub id": "ZzxSO8QAAAAJ:IWHjjKOFINEC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "On the optimization of hierarchical temporal memory",
            "Publication year": 2012,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S0167865511004077",
            "Abstract": "In this paper an optimized classification method for object recognition is presented. The proposed method is based on the Hierarchical Temporal Memory (HTM), which stems from the memory prediction theory of the human brain. As in HTM, this method comprises a tree structure of connected computational nodes, whilst utilizing different rules to memorize objects appearing in various orientations. These rules involve both the spatial and the temporal module. As HTM is inspired from brain activity, its input should also comply with the human vision system. Thus, for the representation of the input images the logpolar was given preference to the Cartesian one. As compared to the original HTM method, experimental results exhibit performance enhancements with this approach, in recognition and categorization applications. Results obtained prove that the proposed method is more accurate and faster in training, whilst \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ZzxSO8QAAAAJ:NhqRSupF_l8C",
            "Publisher": "North-Holland"
        },
        {
            "Title": "Intelligent robots need intelligent vision: visual 3D perception",
            "Publication year": 2008,
            "Publication url": "https://www.academia.edu/download/42019000/Intelligent_Robots_need_Intelligent_Vision_-_Visual_3D_Perception_Full_Paper_v3.pdf",
            "Abstract": "Contemporary autonomous robots are generally equipped with an abundance of sensors like for example GPS, Laser, ultrasound sensors, etc to be able to navigate in an environment. However, this stands in contrast to the ultimate biological example for these robots: us humans. Indeed, humans seem perfectly capable to navigate in a complex, dynamic environment using primarily vision as a sensing modality. This observation inspired us to investigate visually guided intelligent mobile robots.In order to understand and reason about its environment, an intelligent robot needs to be aware of the three-dimensional status of this environment. The problem with vision, though, is that the perceived image is a two-dimensional input. Recovering 3D-information has been in the focus of attention of the computer vision community for a few decades now, yet no all-satisfying method has been found so far. Most attention in this area has been on stereo-vision based methods, which use the displacement of objects in two (or more) images. Where stereo vision must be seen as a spatial integration of multiple viewpoints to recover depth, it is also possible to perform a temporal integration. The problem arising in this situation is known as the\" Structure from Motion\"(SfM) problem and deals with extracting 3-dimensional information about the environment from the motion of its projection onto a twodimensional surface.",
            "Abstract entirety": 1,
            "Author pub id": "ZzxSO8QAAAAJ:M3NEmzRMIkIC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Guiding a robotic gripper by visual feedback for object manipulation tasks",
            "Publication year": 2011,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/5971325/",
            "Abstract": "This paper presents a novel object manipulation technique that could be adopted by any advanced mechatronic platform in order to perform demanding pick and place tasks. The ultimate goal of a robotics researcher is to provide an applicable manipulation solution that minimizes user's involvement. It has been shown that the best solution to this problem is provided by the introduction of sensors that allow an automatic or, at least, semi-automatic grasping of the targets. The proposed method relies on a vision-based framework that is responsible for several vital tasks that affect directly the manipulation process. The contribution of the paper incorporates a shape retrieval technique accompanied with classification and clustering algorithms that are utilized during the objects' pose estimation process. The experimental results obtained confirm the validity of the presented approach.",
            "Abstract entirety": 1,
            "Author pub id": "ZzxSO8QAAAAJ:GnPB-g6toBAC",
            "Publisher": "IEEE"
        },
        {
            "Title": "How do you help a robot to find a place? A supervised learning paradigm to semantically infer about places",
            "Publication year": 2013,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-642-40846-5_33",
            "Abstract": "In this paper a visual place recognition algorithm suitable for semantic inference is presented. It combines place and object classification attributes suitable for the recognition of congested and cluttered scenes. The place learning task is undertaken by a method capable of abstracting appearance information from the places to be memorized. The detected visual features are treated as a bag of words and quantized by a clustering algorithm to form a visual vocabulary of the explored places. Each query image is represented by a consistency histogram spread over the memorized vocabulary. Simultaneously, an object recognition approach based on Hierarchical Temporal Memory network, updates the robot\u2019s belief of its current position exploiting the features of scattered objects within the scene. The input images which are introduced to the network undergo a saliency computation step and are subsequently \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ZzxSO8QAAAAJ:J-pR_7NvFogC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "TECHNICAL REPORT LIRA TR 3/00 NOVEMBER 2000",
            "Publication year": 2000,
            "Publication url": "http://utopia.duth.gr/~agaster/papers/LIRATR300.pdf",
            "Abstract": "In human vision system, the differences between the left and right images are used to recover 3D properties of a scene. Similarly on an artificial vision system, the differences between the two images can be used for the extraction of many useful 3D characteristics such as the depth, the surface normal and the exact position of a point. In this report we derive the formulation for the computation of a line in space based on its projections on a stereo pair of images and on the angle of converge of the two cameras. Experiments have been carried out that shows using our setup the proposed technique is rather unstable. Solutions for future implementations are proposed, which are rising the estimation range of the Hough accumulation array, and increasing the length of the baseline.",
            "Abstract entirety": 1,
            "Author pub id": "ZzxSO8QAAAAJ:pyW8ca7W8N0C",
            "Publisher": "Unknown"
        },
        {
            "Title": "High order visual words for structure-aware and viewpoint-invariant loop closure detection",
            "Publication year": 2017,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/8206289/",
            "Abstract": "In the field of loop closure detection, the most conventional approach is based on the Bag-of-Visual-Words (BoVW) image representation. Although well-established, this model rejects the spatial information regarding the local feature points' layout and performs the associations based only on their similarities. In this paper we propose a novel BoVW-based technique which additionally incorporates the operational environment's structure into the description, treating bunches of visual words with similar optical flow measurements as single similarity votes. The presented experimental results prove that our method offers superior loop closure detection accuracy while still ensuring real-time performance, even in the case of a low power consuming mobile device.",
            "Abstract entirety": 1,
            "Author pub id": "ZzxSO8QAAAAJ:yCEqH1SBpFUC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Multi-camera 3d scene reconstruction from vanishing points",
            "Publication year": 2010,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/5548495/",
            "Abstract": "In this paper we present a multi-camera system, which serves as the primary vision apparatus for a ceiling based swinging service robotic platform. To facilitate a smooth and unimpeded movement of the swinging platform the knowledge of the working environment is essential. To this end we examine the 3D scene reconstruction by concurrent multiple views from the distinct cameras located at the upper corners of a room for volume calculation of objects in everyday indoor environments. The 3D scene reconstruction is used to determine the working volume where the swinging robot will be able to operate. At first, we detect lines across the views using the hough transformation while the computation of multiple vanishing points serves as the platform to distinguish regions across the multi camera system. We thereafter obtain correspondences across the multiple views of the test room and finally we determine the 3D \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ZzxSO8QAAAAJ:b0M2c_1WBrUC",
            "Publisher": "IEEE"
        },
        {
            "Title": "A tensor-based deep learning framework",
            "Publication year": 2014,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S0262885614001292",
            "Abstract": "This paper presents an unsupervised deep learning framework that derives spatio-temporal features for human\u2013robot interaction. The respective models extract high-level features from low-level ones through a hierarchical network, viz. the Hierarchical Temporal Memory (HTM), providing at the same time a solution to the curse of dimensionality in shallow techniques. The presented work incorporates the tensor-based framework within the operation of the nodes and, thus, enhances the feature derivation procedure. This is due to the fact that tensors allow the preservation of the initial data format and their respective correlation and, moreover, attain more compact representations. The computational nodes form spatial and temporal groups by exploiting the multilinear algebra and subsequently express the samples according to those groups in terms of proximity. This generic framework may be applied in a diverse of \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ZzxSO8QAAAAJ:5bFWG3eDk9wC",
            "Publisher": "Elsevier"
        },
        {
            "Title": "A stereo matching approach based on particle filters and scattered control landmarks",
            "Publication year": 2015,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S0262885615000347",
            "Abstract": "In robot localization, particle filtering can estimate the position of a robot in a known environment with the help of sensor data. In this paper, we present an approach based on particle filtering, for accurate stereo matching. The proposed method consists of three parts. First, we utilize multiple disparity maps in order to acquire a very distinctive set of features called landmarks, and then we use segmentation as a grouping technique. Secondly, we apply scan line particle filtering using the corresponding landmarks as a virtual sensor data to estimate the best disparity value. Lastly, we reduce the computational redundancy of particle filtering in our stereo correspondence with a Markov chain model, given the previous scan line values. More precisely, we assist particle filtering convergence by adding a proportional weight in the predicted disparity value estimated by Markov chains. In addition to this, we optimize our \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ZzxSO8QAAAAJ:7XCffrwrS2sC",
            "Publisher": "Elsevier"
        },
        {
            "Title": "An intelligent system for aerial image retrieval and classification",
            "Publication year": 2004,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-540-24674-9_8",
            "Abstract": "Content based image retrieval is an active research area of pattern recognition. A new method of extracting global texture energy descriptors is proposed and it is combined with features describing the color aspect of texture, suitable for image retrieval. The same features are also used for image classification, by its semantic content. An exemplar fuzzy system for aerial image retrieval and classification is proposed. The fuzzy system calculates the degree that a class, such as sea, clouds, desert, forests and plantations, participates in the input image. Target applications include remote sensing, computer vision, forestry, fishery, agricultures, oceanography and weather forecasting.",
            "Abstract entirety": 1,
            "Author pub id": "ZzxSO8QAAAAJ:_FxGoFyzp5QC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "Tele-autonomous active stereo-vision head",
            "Publication year": 2008,
            "Publication url": "https://www.tandfonline.com/doi/abs/10.1080/15599610802081753",
            "Abstract": "Supervised autonomy is defined as a framework to control robotic systems, which combines tele-operation in the high-level with autonomous functions in the low-level. The main advantage of such a scheme is that the human operator of the tele-operated device does not need to care about functions, which can be performed by a local controller and, thus, he remains undistracted during his activity. In this article, the autonomous functions that a robotized stereo head should bear to accomplish outdoors rescue tasks is discussed. Paradigm algorithms implementing these functions are presented and respective experimental results are apposed.",
            "Abstract entirety": 1,
            "Author pub id": "ZzxSO8QAAAAJ:qxL8FJ1GzNcC",
            "Publisher": "Taylor & Francis Group"
        },
        {
            "Title": "Appearance-Based Loop Closure Detection with Scale-Restrictive Visual",
            "Publication year": 2019,
            "Publication url": "https://books.google.com/books?hl=en&lr=&id=OOK_DwAAQBAJ&oi=fnd&pg=PA75&dq=info:RsGTo7lA6-QJ:scholar.google.com&ots=C8ct2doajj&sig=3gFjCmGw_c7Z24w7rSXo0gCSfj0",
            "Abstract": "In this paper, an appearance-based loop closure detection pipeline for autonomous robots is presented. Our method uses scalerestrictive visual features for image representation with a view to reduce the computational cost. In order to achieve this, a training process is performed, where a feature matching technique indicates the features\u2019 repeatability with respect to scale. Votes are distributed into the database through a nearest neighbor method, while a binomial probability function is responsible for the selection of the most suitable loop closing pair. Subsequently, a geometrical consistency check on the chosen pair follows. The method is subjected into an extensive evaluation via a variety of outdoor, publicly-available datasets revealing high recall rates for 100% precision, as compared against its baseline version, as well as, other state-of-the-art approaches.",
            "Abstract entirety": 1,
            "Author pub id": "ZzxSO8QAAAAJ:FnaCo-ypupUC",
            "Publisher": "Springer Nature"
        },
        {
            "Title": "A system to navigate a robot into a ship structure",
            "Publication year": 2001,
            "Publication url": "https://link.springer.com/chapter/10.1007/3-540-48222-9_18",
            "Abstract": "A prototype system has been built to navigate a walking robot into a ship structure. The robot is equipped with a stereo head for monocular and stereo vision. From the CAD-model of the ship good viewpoints are selected such that the head can look at locations with sufficient features. The edge features for the views are extracted automatically. The pose of the robot is estimated from the features detected by two vision approaches. One approach searches in the full image for junctions and uses the stereo information to extract 3D information. The other method is monocular and tracks 2D edge features. To achieve robust tracking of the features a model-based tracking approach is enhanced with a method of Edge Projected Integration of Cues (EPIC). EPIC uses object knowledge to select the correct features in real-time. The two vision systems are synchronised by sending the images over a fibre channel \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ZzxSO8QAAAAJ:4DMP91E08xMC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "Comparison of data fusion techniques for robot navigation",
            "Publication year": 2006,
            "Publication url": "https://link.springer.com/chapter/10.1007/11752912_65",
            "Abstract": "This paper proposes and compares several data fusion techniques for robot navigation. The fusion techniques investigated here are several topologies of the Kalman filter. The problem that had been simulated is the navigation of a robot carrying two sensors, one Global Positioning System (GPS) and one Inertial Navigation System (INS). For each of the above topologies, the statistic error and its, mean value, variance and standard deviation were examined.",
            "Abstract entirety": 1,
            "Author pub id": "ZzxSO8QAAAAJ:R3hNpaxXUhUC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "View-finder: robotics assistance to fire-fighting services and crisis management",
            "Publication year": 2009,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/5424172/",
            "Abstract": "In the event of an emergency due to a fire or other crisis, a necessary but time consuming pre-requisite, that could delay the real rescue operation, is to establish whether the ground or area can be entered safely by human emergency workers. The objective of the VIEW-FINDER project is to develop robots which have the primary task of gathering data. The robots are equipped with sensors that detect the presence of chemicals and, in parallel, image data is collected and forwarded to an advanced Control station (COC). The robots will be equipped with a wide array of chemical sensors, on-board cameras, Laser and other sensors to enhance scene understanding and reconstruction. At the Base Station (BS) the data is processed and combined with geographical information originating from a Web of sources; thus providing the personnel leading the operation with in-situ processed data that can improve decision \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ZzxSO8QAAAAJ:e5wmG9Sq2KIC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Thorough robot navigation based on SVM local planning",
            "Publication year": 2015,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S0921889015000342",
            "Abstract": "A prerequisite for autonomous robot navigation is the extraction of a path that is both efficient and safe in terms of collision. Towards this end, the paper in hand presents a novel local path planning method, incorporating the support vector machines (SVM) theory. The original SVM based module exploits a 2D map of points which are considered to be obstacles, so as to culminate in a collision free path. A unique attribute of the proposed SVM based local path planning algorithm is that it considers the consecutive positions of the global path trajectory, the embodiment of the robot and clusters the obstacles accordingly. Thus, the derived trajectory is a physically constrained path inasmuch as it considers the maximum margin notion of the SVM theory. Instead of providing a purely theoretical approach for local planning assessed using only artificial data, we integrate our local planner into an autonomous navigation \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ZzxSO8QAAAAJ:tUtwDVdCwjgC",
            "Publisher": "North-Holland"
        },
        {
            "Title": "An algorithm for adaptive mean filtering and its hardware implementation",
            "Publication year": 2006,
            "Publication url": "https://link.springer.com/article/10.1007/s11265-006-5920-3",
            "Abstract": "Noise due to the sensor and the electronics of a camera is an undesirable issue in any machine vision application. Such noise tends to corrupt images and to obstruct any further analysis. An algorithm to detect and cancel such noise, using statistical methods, is presented in this paper. The proposed algorithm is an adaptive mean filter, which filters out image regions that are found to be noise corrupted. The efficiency of the proposed filter was examined both qualitatively and quantitatively, by software simulation in several noisy conditions. The main advantage of the filter in hand is that it is appropriate for hardware implementation and can be easily incorporated to smart cameras. The hardware implementation of the filter is also presented in this paper. This implementation aims at time critical applications such as machine vision, inspection and visual surveillance.",
            "Abstract entirety": 1,
            "Author pub id": "ZzxSO8QAAAAJ:KlAtU1dfN6UC",
            "Publisher": "Birkh\u00e4user-Verlag"
        },
        {
            "Title": "A New Approach to Machine Contour Perception",
            "Publication year": 2019,
            "Publication url": "https://www.taylorfrancis.com/chapters/edit/10.1201/9780429081385-139/new-approach-machine-contour-perception-vassilios-vonikakis-ioannis-andreadis-antonios-gasteratos",
            "Abstract": "This chapter presents a new shape descriptor suitable for machine contour perception that mimics the orientation selective cells of the human visual cortex. It provides a description for any 2-dimensional shape, regardless of its size, rotation and position, with affordable computational cost. Furthermore, it can identify different shapes of the same object, distorted shapes and heavily contaminated shapes with up to 20% spike noise. The earliest stage of visual processing in the Human Visual System (HVS) is located in the primary visual cortex in an area known as VI. Similarly to the HVS, the proposed shape descriptor uses 12 groups of artificial VI cells each one specialized in detecting any edge with a particular orientation within its receptive field. Cells from higher levels of the HVS, receive whole visual maps of stimulated VI cells, and identify certain combinations among them, resulting to the gradual perception of \u2026",
            "Abstract entirety": 0,
            "Author pub id": "ZzxSO8QAAAAJ:SrsqWtBqNIQC",
            "Publisher": "CRC Press"
        }
    ]
}]