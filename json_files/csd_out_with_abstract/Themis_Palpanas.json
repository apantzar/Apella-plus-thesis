[{
    "name": "Themis Palpanas",
    "romanize name": "Themis Palpanas",
    "School-Department": "Computer Science",
    "University": "Paris Descartes University",
    "Rank": "\u039a\u03b1\u03b8\u03b7\u03b3\u03b7\u03c4\u03ae\u03c2",
    "Apella_id": 10115,
    "Scholar name": "Themis Palpanas",
    "Scholar id": "qUBdmWgAAAAJ",
    "Affiliation": "University of Paris, French University Institute (IUF)",
    "Citedby": 8140,
    "Scholar url": "https://scholar.google.com/citations?user=qUBdmWgAAAAJ&hl=en",
    "Publications": [
        {
            "Title": "Graphan: Graph-based subsequence anomaly detection",
            "Publication year": 2020,
            "Publication url": "https://dl.acm.org/doi/abs/10.14778/3415478.3415514",
            "Abstract": "Subsequence anomaly detection in long sequences is an important problem with applications in a wide range of domains. However, the state-of-the-art approaches have severe limitations: they either require prior domain knowledge, or become cumbersome and inefficient/ineffective in situations with recurrent anomalies of the same type. We recently proposed Series2Graph, a novel method based on a graph representation of a low-dimensionality embedding of subsequences, that detects anomalous subsequences. The experimental results, on the largest set of synthetic and real datasets used to date, demonstrate that the proposed approach correctly identifies single and recurrent anomalies of various types without any prior knowledge of the characteristics of these anomalies, outperforming by a large margin several competing approaches in accuracy, while being up to orders of magnitude faster. In this \u2026",
            "Abstract entirety": 0,
            "Author pub id": "qUBdmWgAAAAJ:jgBuDB5drN8C",
            "Publisher": "VLDB Endowment"
        },
        {
            "Title": "Paris+: Data series indexing on multi-core architectures",
            "Publication year": 2020,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/9003246/",
            "Abstract": "Data series similarity search is a core operation for several data series analysis applications across many different domains. Nevertheless, even state-of-the-art techniques cannot provide the time performance required for large data series collections. We propose ParIS and ParIS+, the  first  disk-based data series indices carefully designed to inherently take advantage of multi-core architectures, in order to accelerate similarity search processing times. Our experiments demonstrate that ParIS+ completely removes the CPU latency during index construction for disk-resident data, and for exact query answering is up to 1 order of magnitude faster than the current state of the art index scan method, and up to 3 orders of magnitude faster than the optimized serial scan method. ParIS+ (which is an evolution of the ADS+ index) owes its efficiency to the effective use of multi-core and multi-socket architectures, in order to \u2026",
            "Abstract entirety": 0,
            "Author pub id": "qUBdmWgAAAAJ:1lhNe0rCu4AC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Entity data management in OKKAM",
            "Publication year": 2008,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/4624805/",
            "Abstract": "In the past years, we are witnessing an increasing interest in the semantic Web and the relevant technologies, which can have a significant impact in the enterprise environment of information and knowledge management. An important observation is that the entity identification problem lies at the core of many semantic Web applications. In this paper, we examine the special requirements of storage and management for entities, in the context of an entity management system for the semantic Web. We study the requirements with respect to creating and modifying these entities, as well as to managing their evolution over time. Finally, we propose a conceptual model for there presentation of entities, and discuss related research directions.",
            "Abstract entirety": 1,
            "Author pub id": "qUBdmWgAAAAJ:isC4tDSrTZIC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Very Large Time Series Analysis for Predictive Maintenance",
            "Publication year": 2017,
            "Publication url": "https://fondation-hadamard.fr/sites/default/files/public/bibliotheque/PGMO/pgmodays2017bookofabstracts.pdf#page=103",
            "Abstract": "1Paris Descartes University, France paul. boniol@ grenoble-inp. org 2Paris Descartes University, France edouard. mehlman@ polytechnique. edu 3Paris Descartes University, France, themis@ mi. parisdescartes. fr 4Ecole Normale Sup\u00e9rieure, France nboers@ lmd. ens. fr",
            "Abstract entirety": 1,
            "Author pub id": "qUBdmWgAAAAJ:hCrLmN-GePgC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Social networking: Power to the people",
            "Publication year": 2009,
            "Publication url": "https://www.academia.edu/download/30307335/10.1.1.190.2341.pdf",
            "Abstract": "Social networking sites have gained much popularity in the recent years, because of the opportunities they give people to connect to each other in an easy and timely manner, and to exchange and share various kinds of information. However, these sites are architected based on a centralized paradigm, which limits the mobility of their users, and ultimately, their chances for establishing new relationships and benefiting from diverse networking services.In this paper, we argue for a decentralized paradigm for social networking, in which users retain control of their profiles, and social networking sites focus on the delivery of innovative and competitive services. Our position is that only in this environment will both the social networking sites and their users be able to develop to their full potential.",
            "Abstract entirety": 1,
            "Author pub id": "qUBdmWgAAAAJ:4OULZ7Gr8RgC",
            "Publisher": "Unknown"
        },
        {
            "Title": "JedAI^ 3: beyond batch, blocking-based Entity Resolution",
            "Publication year": 2020,
            "Publication url": "https://iris.unimore.it/handle/11380/1193222",
            "Abstract": "La simulazione pu\u00f2 differire dall'esito di un\u2019eventuale domanda ASN sia per errori di catalogazione e/o dati mancanti in IRIS, sia per la variabilit\u00e0 dei dati bibliometrici nel tempo. L\u2019Universit\u00e0 di Modena e Reggio Emilia non si assume alcuna responsabilit\u00e0 in merito all\u2019uso che il diretto interessato o terzi faranno della simulazione.",
            "Abstract entirety": 1,
            "Author pub id": "qUBdmWgAAAAJ:ALROH1vI_8AC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Online outlier detection in sensor data using non-parametric models",
            "Publication year": 2006,
            "Publication url": "http://vldb.org/conf/2006/p187-subramaniam.pdf",
            "Abstract": "Sensor networks have recently found many popular applications in a number of different settings. Sensors at different locations can generate streaming data, which can be analyzed in real-time to identify events of interest. In this paper, we propose a framework that computes in a distributed fashion an approximation of multi-dimensional data distributions in order to enable complex applications in resource-constrained sensor networks.We motivate our technique in the context of the problem of outlier detection. We demonstrate how our framework can be extended in order to identify either distance-or density-based outliers in a single pass over the data, and with limited memory requirements. Experiments with synthetic and real data show that our method is efficient and accurate, and compares favorably to other proposed techniques. We also demonstrate the applicability of our technique to other related problems in sensor networks.",
            "Abstract entirety": 1,
            "Author pub id": "qUBdmWgAAAAJ:e5wmG9Sq2KIC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Scalable, variable-length similarity search in data series: The ULISSE approach",
            "Publication year": 2018,
            "Publication url": "https://dl.acm.org/doi/abs/10.14778/3275366.3284968",
            "Abstract": "Data series similarity search is an important operation and at the core of several analysis tasks and applications related to data series collections. Despite the fact that data series indexes enable fast similarity search, all existing indexes can only answer queries of a single length (fixed at index construction time), which is a severe limitation. In this work, we propose ULISSE, the first data series index structure designed for answering similarity search queries of variable length. Our contribution is two-fold. First, we introduce a novel representation technique, which effectively and succinctly summarizes multiple sequences of different length (irrespective of Z-normalization). Based on the proposed index, we describe efficient algorithms for approximate and exact similarity search, combining disk based index visits and in-memory sequential scans. We experimentally evaluate our approach using several synthetic and real \u2026",
            "Abstract entirety": 0,
            "Author pub id": "qUBdmWgAAAAJ:4vMrXwiscB8C",
            "Publisher": "VLDB Endowment"
        },
        {
            "Title": "Twin subsequence search in time series",
            "Publication year": 2021,
            "Publication url": "https://arxiv.org/abs/2104.06874",
            "Abstract": "We address the problem of subsequence search in time series using Chebyshev distance, to which we refer as twin subsequence search. We first show how existing time series indices can be extended to perform twin subsequence search. Then, we introduce TS-Index, a novel index tailored to this problem. Our experimental evaluation compares these approaches against real time series datasets, and demonstrates that TS-Index can retrieve twin subsequences much faster under various query conditions. This paper has been published in the 24th International Conference on Extending Database Technology (EDBT 2021).",
            "Abstract entirety": 1,
            "Author pub id": "qUBdmWgAAAAJ:WHdLCjDvYFkC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Decentralised social network management",
            "Publication year": 2011,
            "Publication url": "https://www.inderscienceonline.com/doi/abs/10.1504/IJWBC.2011.041199",
            "Abstract": "Social networking sites have gained much popularity in the recent years because of the opportunities they give to people to connect to each other in an easy and timely manner, and to exchange and share various kinds of information. However, these sites are based on a centralised paradigm, which limits the mobility of their users, and ultimately, their chances to establish new relationships and benefit from diverse networking services. In this paper, we argue for a decentralised paradigm for social networking, in which users retain control of their profiles, and social networking sites focus on the delivery of innovative and competitive services. In this environment, both the social networking sites and their users will be able to develop to their full potential. This goal can be achieved by using a combination of semantic web technologies and tools, loosening the bind between the social network management and social \u2026",
            "Abstract entirety": 0,
            "Author pub id": "qUBdmWgAAAAJ:Tiz5es2fbqcC",
            "Publisher": "Inderscience Publishers"
        },
        {
            "Title": "The lernaean hydra of data series similarity search: An experimental evaluation of the state of the art",
            "Publication year": 2020,
            "Publication url": "https://arxiv.org/abs/2006.11454",
            "Abstract": "Increasingly large data series collections are becoming commonplace across many different domains and applications. A key operation in the analysis of data series collections is similarity search, which has attracted lots of attention and effort over the past two decades. Even though several relevant approaches have been proposed in the literature, none of the existing studies provides a detailed evaluation against the available alternatives. The lack of comparative results is further exacerbated by the non-standard use of terminology, which has led to confusion and misconceptions. In this paper, we provide definitions for the different flavors of similarity search that have been studied in the past, and present the first systematic experimental evaluation of the efficiency of data series similarity search techniques. Based on the experimental results, we describe the strengths and weaknesses of each approach and give recommendations for the best approach to use under typical use cases. Finally, by identifying the shortcomings of each method, our findings lay the ground for solid further developments in the field.",
            "Abstract entirety": 1,
            "Author pub id": "qUBdmWgAAAAJ:DJbcl8HfkQkC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Report on the first international workshop on personal data analytics in the internet of things (PDA@ IOT 2014)",
            "Publication year": 2015,
            "Publication url": "https://dl.acm.org/doi/pdf/10.1145/2783888.2783905",
            "Abstract": "In the last few years, we are witnessing a wave of connected things (ie, devices) that are flooding our everyday living spaces. These networks of physical objects with embedded sensors and actuators that communicate with other objects, databases, and in some cases with people, are often described under the umbrella term Internet of Things (IoT). Recent studies1 estimate that by 2020 the IoT will scale up to 50 billion daily-use objects, while its economic value will reach $14.4 trillion dollars, spread across all sectors (both consumer2 and industrial3 markets). According to the IoT vision,\u201csmart things\u201d will \u201cdisappear\u201d in our living environments (aka Pervasive Computing), or be embodied in humans (aka Wearable Computing, with the goal of building disruptive services for humanbeings, offering a seamless and implicit interaction between the real and the virtual worlds.",
            "Abstract entirety": 1,
            "Author pub id": "qUBdmWgAAAAJ:yB1At4FlUx8C",
            "Publisher": "ACM"
        },
        {
            "Title": "Micropropagation and validation of genetic homogeneity of Alhagi maurorum using SCoT, ISSR and RAPD markers",
            "Publication year": 2015,
            "Publication url": "https://link.springer.com/article/10.1007/s11240-014-0608-z",
            "Abstract": "A reliable and reproducible protocol for in vitro regeneration has been developed for Alhagi maurorum, a rare and medicinally important plant of family fabaceae. MS medium with BAP (2.0 mg l\u22121) proved to be the best for shoot bud induction from nodal segments. The rate of shoot multiplication was found to be influenced by a number of factors, viz., media composition, plant growth regulator\u2019s type and concentration, successive transfer of mother explant for different passage, culture vessels and gelling agents. Modified MS medium (modified having nitrates reduced to half) solidified with 0.14 % gelrite and containing BAP (0.5 mg l\u22121), IAA (0.1 mg l\u22121) and additives was found optimum for shoot multiplication which gave rise to maximum number of shoots (33.5 \u00b1 3.43 per culture vessel). The in vitro regenerated shoots were rooted under both in vitro (on half strength MS salts with 1.0 mg l\u22121 IBA + 100 mg l \u2026",
            "Abstract entirety": 0,
            "Author pub id": "qUBdmWgAAAAJ:hkOj_22Ku90C",
            "Publisher": "Springer Netherlands"
        },
        {
            "Title": "Meta-blocking: Taking entity resolutionto the next level",
            "Publication year": 2013,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/6487505/",
            "Abstract": "Entity Resolution is an inherently quadratic task that typically scales to large data collections through blocking. In the context of highly heterogeneous information spaces, blocking methods rely on redundancy in order to ensure high effectiveness at the cost of lower efficiency (i.e., more comparisons). This effect is partially ameliorated by coarse-grained block processing techniques that discard entire blocks either a-priori or during the resolution process. In this paper, we introduce meta-blocking as a generic procedure that intervenes between the creation and the processing of blocks, transforming an initial set of blocks into a new one with substantially fewer comparisons and equally high effectiveness. In essence, meta-blocking aims at extracting the most similar pairs of entities by leveraging the information that is encapsulated in the block-to-entity relationships. To this end, it first builds an abstract graph \u2026",
            "Abstract entirety": 0,
            "Author pub id": "qUBdmWgAAAAJ:wbdj-CoPYUoC",
            "Publisher": "IEEE"
        },
        {
            "Title": "A knowledge mining framework for business analysts",
            "Publication year": 2012,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/2139011.2139015",
            "Abstract": "Several studies have focused on problems related to data mining techniques, including several applications of these techniques in the e-commerce setting. In this work, we describe how data mining technology can be effectively applied in an e-commerce environment, delivering significant benefits to the business analyst. We propose a framework that takes the results of the data mining process as input, and converts these results into actionable knowledge, by enriching them with information that can be readily interpreted by the business analyst. The framework can accommodate various data mining algorithms, and provides a customizable user interface.We experimentally evaluate the proposed approach by using a real-world case study that demonstrates the added benefit of the proposed method. The same study validates the claim that the produced results represent actionable knowledge that can help the \u2026",
            "Abstract entirety": 0,
            "Author pub id": "qUBdmWgAAAAJ:P5F9QuxV20EC",
            "Publisher": "ACM"
        },
        {
            "Title": "Exploring the data wilderness through examples",
            "Publication year": 2019,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/3299869.3314031",
            "Abstract": "Exploration is one of the primordial ways to accrue knowledge about the world and its nature. As we accumulate, mostly automatically, data at unprecedented volumes and speed, our datasets have become complex and hard to understand. In this context exploratory search provides a handy tool for progressively gather the necessary knowledge by starting from a tentative query that hopefully leads to answers at least partially relevant and that can provide cues about the next queries to issue. Recently, we have witnessed a rediscovery of the so-called example-based methods, in which the user or the analyst circumvent query languages by using examples as input. This shift in semantics has led to a number of methods receiving as query a set of example members of the answer set. The search system then infers the entire answer set based on the given examples and any additional information provided by the \u2026",
            "Abstract entirety": 0,
            "Author pub id": "qUBdmWgAAAAJ:OcBU2YAGkTUC",
            "Publisher": "Unknown"
        },
        {
            "Title": "BLADYG: A graph processing framework for large dynamic graphs",
            "Publication year": 2017,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S2214579617300047",
            "Abstract": "Recently, distributed processing of large dynamic graphs has become very popular, especially in certain domains such as social network analysis, Web graph analysis and spatial network analysis. In this context, many distributed/parallel graph processing systems have been proposed, such as Pregel, PowerGraph, GraphLab, and Trinity. However, these systems deal only with static graphs and do not consider the issue of processing evolving and dynamic graphs. In this paper, we are considering the issues of scale and dynamism in the case of graph processing systems. We present bladyg, a graph processing framework that addresses the issue of dynamism in large-scale graphs. We present an implementation of bladyg on top of akka framework. We experimentally evaluate the performance of the proposed framework by applying it to problems such as distributed k-core decomposition and partitioning of large \u2026",
            "Abstract entirety": 0,
            "Author pub id": "qUBdmWgAAAAJ:2VqYfGB8ITEC",
            "Publisher": "Elsevier"
        },
        {
            "Title": "Time-Decaying Representations of Streaming Time Series",
            "Publication year": 2004,
            "Publication url": "http://disi.unitn.it/~themis/publications/setn04.pdf",
            "Abstract": "During the last years we have witnessed a wealth of research on approximate representations for time series. The vast majority of the proposed approaches represent each value with approximately equal fidelity, which may not be always desirable. For example, mobile devices and real time sensors have brought home the need for representations that can approximate the data with fidelity proportional to its age. We call such time-decaying representations amnesic.In this work, we introduce a novel representation of time series that can represent arbitrary, user-specified time-decaying functions. We propose online algorithms for our representation, and discuss their properties. The algorithms we describe are designed to work on both the entire stream of data, or on a sliding window of the data stream. Finally, we perform an extensive empirical evaluation on\u00a3\u00a5\u00a4 datasets, and show that our approach can efficiently maintain a high quality amnesic approximation.",
            "Abstract entirety": 1,
            "Author pub id": "qUBdmWgAAAAJ:u9iWguZQMMsC",
            "Publisher": "Unknown"
        },
        {
            "Title": "IQR: an interactive query relaxation system for the empty-answer problem",
            "Publication year": 2014,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/2588555.2594512",
            "Abstract": "We present IQR, a system that demonstrates optimization based interactive relaxations for queries that return an empty answer. Given an empty answer, IQR dynamically suggests one relaxation of the original query conditions at a time to the user, based on certain optimization objectives, and the user responds by either accepting or declining the relaxation, until the user arrives at a non-empty answer, or a non-empty answer is impossible to achieve with any further relaxations. The relaxation suggestions hinge on a proba-bilistic framework that takes into account the probability of the user accepting a suggested relaxation, as well as how much that relaxation serves towards the optimization objec-tive. IQR accepts a wide variety of optimization objectives-user centric objectives, such as, minimizing the number of user interactions (ie, effort) or returning relevant results, as well as seller centric objectives, such as \u2026",
            "Abstract entirety": 0,
            "Author pub id": "qUBdmWgAAAAJ:SdhP9T11ey4C",
            "Publisher": "Unknown"
        },
        {
            "Title": "What does model-driven data acquisition really achieve in wireless sensor networks?",
            "Publication year": 2012,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/6199853/",
            "Abstract": "Model-driven data acquisition techniques aim at reducing the amount of data reported, and therefore the energy consumed, in wireless sensor networks (WSNs). At each node, a model predicts the sampled data; when the latter deviate from the current model, a new model is generated and sent to the data sink. However, experiences in real-world deployments have not been reported in the literature. Evaluation typically focuses solely on the quantity of data reports suppressed at source nodes: the interplay between data modeling and the underlying network protocols is not analyzed. In contrast, this paper investigates in practice whether i) model-driven data acquisition works in a real application; ii) the energy savings it enables in theory are still worthwhile once the network stack is taken into account. We do so in the concrete setting of a WSN-based system for adaptive lighting in road tunnels. Our novel modeling \u2026",
            "Abstract entirety": 0,
            "Author pub id": "qUBdmWgAAAAJ:08ZZubdj9fEC",
            "Publisher": "IEEE"
        },
        {
            "Title": "SING: Sequence Indexing Using GPUs",
            "Publication year": 2021,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/9458657/",
            "Abstract": "Data series similarity search is a core operation for several data series analysis applications across many domains. This has attracted lots of interest that led to the development of several indexing techniques. Nevertheless, these techniques fail to deliver the similarity search time performance that is needed for interactive exploration, or analysis of large data series collections. We propose SING, the first data series index designed to take advantage of Graphics Processing Units (GPUs). SING is an in-memory index that uses CPU+GPU co-processing (as well as SIMD, multi-core and multi-socket architectures), in order to accelerate similarity search. Our experimental evaluation with synthetic and real datasets shows that SING is up to 5.1x faster than the state-of-the-art parallel in-memory approach, and up to 62x faster than the state-of-the-art parallel serial scan algorithm. SING achieves exact similarity search query \u2026",
            "Abstract entirety": 0,
            "Author pub id": "qUBdmWgAAAAJ:IaI1MmNe2tcC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Big sequence management: on scalability",
            "Publication year": 2020,
            "Publication url": "https://helios.mi.parisdescartes.fr/~themisp/publications/ieeeBigData20-bigsequencemanagement-summary.pdf",
            "Abstract": "Data series are a prevalent data type that has attracted lots of interest in recent years. Specifically, there has been an explosive interest towards the analysis of large volumes of data series in many different domains. This is both in businesses (eg, in mobile applications) and in sciences (eg, in biology). In this tutorial, we focus on applications that produce massive collections of data series, and we provide the necessary background on data series storage, retrieval and analytics. We look at systems historically used to handle and mine data in the form of data series, as well as at the state of the art data series management systems that were recently proposed. Moreover, we discuss the need for fast similarity search for supporting data mining applications, and describe efficient similarity search techniques, indexes and query processing algorithms. Finally, we look at the gap of modern data series management systems in regards to support for efficient complex analytics, and we argue in favor of the integration of summarizations and indexes in modern data series management systems. We conclude with the challenges and open research problems in this domain.Duration: 2 hours",
            "Abstract entirety": 1,
            "Author pub id": "qUBdmWgAAAAJ:FiytvqdAVhgC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Blocking for large-scale entity resolution: Challenges, algorithms, and practical examples",
            "Publication year": 2016,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/7498364/",
            "Abstract": "Entity Resolution constitutes one of the cornerstone tasks for the integration of overlapping information sources. Due to its quadratic complexity, a large amount of research has focused on improving its efficiency so that it scales to Web Data collections, which are inherently voluminous and highly heterogeneous. The most common approach for this purpose is blocking, which clusters similar entities into blocks so that the pair-wise comparisons are restricted to the entities contained within each block. In this tutorial, we take a close look on blocking-based Entity Resolution, starting from the early blocking methods that were crafted for database integration. We highlight the challenges posed by contemporary heterogeneous, noisy, voluminous Web Data and explain why they render inapplicable these schema-based techniques. We continue with the presentation of blocking methods that have been developed for large \u2026",
            "Abstract entirety": 0,
            "Author pub id": "qUBdmWgAAAAJ:hMsQuOkrut0C",
            "Publisher": "IEEE"
        },
        {
            "Title": "Towards mega-modeling: a walk through data analysis experiences",
            "Publication year": 2013,
            "Publication url": "https://dl.acm.org/doi/pdf/10.1145/2536669.2536673",
            "Abstract": "Big data is perceived as a fundamental ingredient for fostering the progress of science in a variety of disciplines. However, we believe that the current ICT solutions are not adequate for this challenge. Abstractions and languages for big data management are tailored to vertical domains and influenced by underlying ICT platforms, hence unsuitable for supporting \u201ccomputational interdisciplinarity\u201d, as it is required if one wants to use the best of, eg, analytical, inductive, and simulation techniques, all at work on the same data. In other words,\u201cour society is data-rich, but it lacks the conceptual tools to handle it\u201d[1].In previous work [2], we advocate the need for a new approach to data analysis, based on mega-modeling as a new holistic data and model management system for the acquisition, composition, integration, management, querying and mining of data and models, capable of mastering the co-evolution of data and \u2026",
            "Abstract entirety": 0,
            "Author pub id": "qUBdmWgAAAAJ:tkaPQYYpVKoC",
            "Publisher": "ACM"
        },
        {
            "Title": "Srf: A framework for the study of classifier behavior under training set mislabeling noise",
            "Publication year": 2012,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-642-30217-6_10",
            "Abstract": "Machine learning algorithms perform differently in settings with varying levels of training set mislabeling noise. Therefore, the choice of a good algorithm for a particular learning problem is crucial. In this paper, we introduce the \u201cSigmoid Rule\u201d Framework focusing on the description of classifier behavior in noisy settings. The framework uses an existing model of the expected performance of learning algorithms as a sigmoid function of the signal-to-noise ratio in the training instances. We study the parameters of the above sigmoid function using five different classifiers, namely, Naive Bayes, kNN, SVM, a decision tree classifier, and a rule-based classifier. Our study leads to the definition of intuitive criteria based on the sigmoid parameters that can be used to compare the behavior of learning algorithms in the presence of varying levels of noise. Furthermore, we show that there exists a connection between \u2026",
            "Abstract entirety": 0,
            "Author pub id": "qUBdmWgAAAAJ:l7t_Zn2s7bgC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "Multi-example search in rich information graphs",
            "Publication year": 2018,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/8509299/",
            "Abstract": "In rich information spaces, it is often hard for users to formally specify the characteristics of the desired answers, either due to the complexity of the schema or of the query language, or even because they do not know exactly what they are looking for. Exemplar queries constitute a query paradigm that overcomes those problems, by allowing users to provide examples of the elements of interest in place of the query specification. In this paper, we propose a general approach where the user-provided example can comprise several partial specification fragments, where each fragment describes only one part of the desired result. We provide a formal definition of the problem, which generalizes existing formulations for both the relational and the graph model. We then describe exact algorithms for its solution for the case of information graphs, as well as top-k algorithms. Experiments on large real datasets demonstrate the \u2026",
            "Abstract entirety": 0,
            "Author pub id": "qUBdmWgAAAAJ:a9-T7VOCCH8C",
            "Publisher": "IEEE"
        },
        {
            "Title": "Corpus evidence for age effects on priming in child language",
            "Publication year": 2010,
            "Publication url": "https://escholarship.org/content/qt09f6j430/qt09f6j430.pdf",
            "Abstract": "Structural priming, the tendency to repeat previously uttered syntactic structures, can give insight into human language processing and acquisition. We report two corpus-based studies of children\u2019s structural priming that test the following claim of the item-based account of language acquisition: as older children generalize over structures, priming increases with age. A hypothesis derived from this claim, viz., that the lexical boost effect decreases with age, is also tested. We fit mixed-effects logistic regression models on data from children aged 2 to 7.5 years from the CHILDES corpus. We demonstrate structural priming of arbitrary syntactic structures for the first time in child language data. We also find evidence that priming increases with age, but fail to confirm the hypothesis that the lexical boost effect decreases with age.",
            "Abstract entirety": 1,
            "Author pub id": "qUBdmWgAAAAJ:cFHS6HbyZ2cC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Data series progressive similarity search with probabilistic quality guarantees",
            "Publication year": 2020,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/3318464.3389751",
            "Abstract": "Existing systems dealing with the increasing volume of data series cannot guarantee interactive response times, even for fundamental tasks such as similarity search. Therefore, it is necessary to develop analytic approaches that support exploration and decision making by providing progressive results, before the final and exact ones have been computed. Prior works lack both efficiency and accuracy when applied to large-scale data series collections. We present and experimentally evaluate a new probabilistic learning-based method that provides quality guarantees for progressive Nearest Neighbor (NN) query answering. We provide both initial and progressive estimates of the final answer that are getting better during the similarity search, as well suitable stopping criteria for the progressive queries. Experiments with synthetic and diverse real datasets demonstrate that our prediction methods constitute the first \u2026",
            "Abstract entirety": 0,
            "Author pub id": "qUBdmWgAAAAJ:buQ7SEKw-1sC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Updating a data warehouse schema based on changes in an observation model",
            "Publication year": 2011,
            "Publication url": "https://patents.google.com/patent/US8024305B2/en",
            "Abstract": "A method, information processing system, and computer readable medium for modifying at least one data warehouse schema based on detected changes in an associated observation model are disclosed. The method includes determining if at least one new observation model has been created. The method also includes determining if at least one existing observation model is associated with the new observation model. In response to the existing observation model being associated with the new observation model, at least one changed attribute is identified by comparing the new observation model and the existing observation model. A set of files associated with the existing observation model is updated to reflect the changed attribute between the new observation model and the existing observation model.",
            "Abstract entirety": 1,
            "Author pub id": "qUBdmWgAAAAJ:g5m5HwL7SMYC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Interdisciplinary Research in Artificial Intelligence: Challenges and Opportunities",
            "Publication year": 2020,
            "Publication url": "https://www.frontiersin.org/articles/10.3389/fdata.2020.577974/full?utm_source=F-NTF&utm_medium=EMLX&utm_campaign=PRD_FEOPS_20170000_ARTICLE",
            "Abstract": "The use of artificial intelligence (AI) in a variety of research fields is speeding up multiple digital revolutions, from shifting paradigms in healthcare, precision medicine and wearable sensing, to public services and education offered to the masses around the world, to future cities made optimally efficient by autonomous driving. When a revolution happens, the consequences are not obvious straight away, and to date, there is no uniformly adapted framework to guide AI research to ensure a sustainable societal transition. To answer this need, here we analyze three key challenges to interdisciplinary AI research, and deliver three broad conclusions: (i) future development of AI should not only impact other scientific domains but should also take inspiration and benefit from other fields of science, (ii) AI research must be accompanied by decision explainability, dataset bias transparency as well as development of evaluation methodologies and creation of regulatory agencies to ensure responsibility, and (iii) AI education should receive more attention, efforts and innovation from the educational and scientific communities. Our analysis is of interest not only to AI practitioners but also to other researchers and the general public as it offers ways to guide the emerging collaborations and interactions towards the most fruitful outcomes.",
            "Abstract entirety": 1,
            "Author pub id": "qUBdmWgAAAAJ:7BrZ7Jt4UNcC",
            "Publisher": "Frontiers"
        },
        {
            "Title": "Example-based Exploration: Exploring Knowledge through Examples",
            "Publication year": 2020,
            "Publication url": "https://people.cs.aau.dk/~matteo/pdf/ESWC20-exq-tutorial.pdf",
            "Abstract": "Exploration is one of the primordial ways to accrue knowledge about the world and its nature. As we accumulate, mostly automatically, data at unprecedented volumes and speed, our datasets have become complex and hard to understand. In this context, exploratory search provides a handy tool to progressively gather the necessary knowledge by starting from a tentative query that can provide cues about the next queries to issue. An exploratory query should be simple enough to avoid complicate declarative languages (such as SQL or SPARQL) and convoluted mechanism, and at the same time retain the flexibility and expressiveness required to express complex information needs. Recently, we have witnessed a rediscovery of the so called example-based methods, in which the user, or the analyst circumvent query languages by using examples as input. This shift in semantics has led to a number of methods receiving as query a set of example members of the answer set. The search system then infers the entire answer set based on the given examples and any additional information provided by the underlying database. In this tutorial, we present an excursus over the main example-based methods for exploratory analysis. We show how different data types require different techniques, and present algorithms that are specifically designed for relational, textual, and graph data. We conclude by providing a unifying view of this queryparadigm and identify new exciting research directions.",
            "Abstract entirety": 1,
            "Author pub id": "qUBdmWgAAAAJ:AHdEip9mkN0C",
            "Publisher": "Unknown"
        },
        {
            "Title": "A holistic and principled approach for the empty-answer problem",
            "Publication year": 2016,
            "Publication url": "https://link.springer.com/article/10.1007/s00778-016-0431-8",
            "Abstract": "We propose a principled optimization-based interactive query relaxation framework for queries that return no answers. Given an initial query that returns an empty-answer set, our framework dynamically computes and suggests alternative queries with fewer conditions than those the user has initially requested, in order to help the user arrive at a query with a non-empty-answer, or at a query for which no matter how many additional conditions are ignored, the answer will still be empty. Our proposed approach for suggesting query relaxations is driven by a novel probabilistic framework based on optimizing a wide variety of application-dependent objective functions. We describe optimal and approximate solutions of different optimization problems using the framework. Moreover, we discuss two important extensions to the base framework: the specification of a minimum size on the number of results returned \u2026",
            "Abstract entirety": 0,
            "Author pub id": "qUBdmWgAAAAJ:ILKRHgRFtOwC",
            "Publisher": "Springer Berlin Heidelberg"
        },
        {
            "Title": "System and method for incrementally maintaining non-distributive aggregate functions in a relational database",
            "Publication year": 2006,
            "Publication url": "https://patents.google.com/patent/US7020649B2/en",
            "Abstract": "A system for incrementally maintaining non-distributive aggregate functions in a relational database includes a data storage device in which a relational database is stored. A processor communicates with the data storage device and includes a database maintenance module. The database maintenance module includes a program for incrementally maintaining non-distributive aggregate functions in a relational database. The method embodied in the program includes determining whether all functions in a relational database query are distributive. Based on this determination, a basic propagate phase graph is selectively altered to yield a new propagate phase graph. Changes to an automatic summary table are then applied thereto based on the new propagate phase graph.",
            "Abstract entirety": 1,
            "Author pub id": "qUBdmWgAAAAJ:D03iK_w7-QYC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Multi-core meta-blocking for big linked data",
            "Publication year": 2017,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/3132218.3132230",
            "Abstract": "Discovering matching entities in different Knowledge Bases constitutes a core task in the Linked Data paradigm. Due to its quadratic time complexity, Entity Resolution typically scales to large datasets through blocking, which restricts comparisons to similar entities. For Big Linked Data, Meta-blocking is also needed to restructure the blocks in a way that boosts precision, while maintaining high recall. Based on blocking and Meta-blocking, JedAI Toolkit implements an end-to-end ER workflow for both relational and RDF data. However, its bottleneck is the time-consuming procedure of Meta-blocking, which iterates over all comparisons in each block. To accelerate it, we present a suite of parallelization techniques that are suitable for multi-core processors. We present 2 categories of parallelization strategies, with each one comprising 4 different approaches that are orthogonal to Meta-blocking algorithms. We perform \u2026",
            "Abstract entirety": 0,
            "Author pub id": "qUBdmWgAAAAJ:0N-VGjzr574C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Pulling down the walled garden: Towards a paradigm for decentralized social network management",
            "Publication year": 2009,
            "Publication url": "https://www.academia.edu/download/43383624/PULLING_DOWN_THE_WALLED_GARDEN_TOWARDS_A20160305-2534-4kzopm.pdf",
            "Abstract": "Social networking sites have gained much popularity in the recent years, because of the opportunities they give people to connect to each other in an easy and timely manner, and to exchange and share various kinds of information. However, these sites are based on a centralized paradigm, which limits the mobility of their users, and ultimately, their chances for establishing new relationships and benefiting from diverse networking services. In this paper, we argue for a decentralized paradigm for social networking, in which users retain control of their profiles, and social networking sites focus on the delivery of innovative and competitive services. Our position is that only in this environment will both the social networking sites and their users be able to develop to their full potential.",
            "Abstract entirety": 1,
            "Author pub id": "qUBdmWgAAAAJ:ns9cj8rnVeAC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Comparative analysis of approximate blocking techniques for entity resolution",
            "Publication year": 2016,
            "Publication url": "https://dl.acm.org/doi/abs/10.14778/2947618.2947624",
            "Abstract": "Entity Resolution is a core task for merging data collections. Due to its quadratic complexity, it typically scales to large volumes of data through blocking: similar entities are clustered into blocks and pair-wise comparisons are executed only between co-occurring entities, at the cost of some missed matches. There are numerous blocking methods, and the aim of this work is to offer a comprehensive empirical survey, extending the dimensions of comparison beyond what is commonly available in the literature. We consider 17 state-of-the-art blocking methods and use 6 popular real datasets to examine the robustness of their internal configurations and their relative balance between effectiveness and time efficiency. We also investigate their scalability over a corpus of 7 established synthetic datasets that range from 10,000 to 2 million entities.",
            "Abstract entirety": 1,
            "Author pub id": "qUBdmWgAAAAJ:EYYDruWGBe4C",
            "Publisher": "VLDB Endowment"
        },
        {
            "Title": "A platform for urban analytics and semantic data integration in city planning",
            "Publication year": 2015,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-662-47386-3_2",
            "Abstract": "This paper presents a novel web-based platform that supports the analysis, integration, and visualization of large-scale and heterogeneous urban data, with application to city planning and decision-making. Motivated by the non-scalable character of conventional urban analytics methods, as well as by the interoperability challenges present in contemporary data silos, the illustrated system \u2013 coined SocialGlass \u2013 leverages the combined potential of diverse urban data sources. These include sensor and social media streams (Twitter, Instagram, Foursquare), publicly available municipal records, and resources from knowledge repositories. Through data science, semantic integration, and crowdsourcing techniques the platform enables the mapping of demographic information, human movement patterns, place popularity, traffic conditions, as well as citizens\u2019 and visitors\u2019 opinions and preferences about \u2026",
            "Abstract entirety": 0,
            "Author pub id": "qUBdmWgAAAAJ:_Ybze24A_UAC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "The return of jedai: End-to-end entity resolution for structured and semi-structured data",
            "Publication year": 2018,
            "Publication url": "https://lirias.kuleuven.be/2335974?limo=0",
            "Abstract": "JedAI is an Entity Resolution toolkit that can be used in three ways:(i) as an open-source library that combines state-of-the-art methods into a plethora of end-to-end workflows,(ii) as a user-friendly desktop application with a wizardlike interface that provides complex, out-of-the-box solutions even to lay users, and (iii) as a workbench for comparing the performance of numerous workflows over both structured and semi-structured data. Here, we present its significant upgrade, JedAI 2.0, which enhances the original version in three important respects:(i) time efficiency, as the running time has been drastically reduced with the use of high performance data structures and multi-core processing,(ii) effectiveness, since we enriched its library with more established methods, a new layer that exploits loose schema binding as well as the automatic, data-driven configuration of individual methods or entire workflows, and (iii) usability, as the GUI now enables users to manually configure any method based on concrete guidelines, to store the matching results into any of the supported data formats and to visually explore both input and output data.",
            "Abstract entirety": 1,
            "Author pub id": "qUBdmWgAAAAJ:QYdC8u9Cj1oC",
            "Publisher": "VLDB Endowment"
        },
        {
            "Title": "The Four Generations of Entity Resolution",
            "Publication year": 2021,
            "Publication url": "https://www.morganclaypool.com/doi/abs/10.2200/S01067ED1V01Y202012DTM064",
            "Abstract": "Entity Resolution (ER) lies at the core of data integration and cleaning and, thus, a bulk of the research examines ways for improving its effectiveness and time efficiency. The initial ER methods primarily target Veracity in the context of structured (relational) data that are described by a schema of well-known quality and meaning. To achieve high effectiveness, they leverage schema, expert, and/or external knowledge. Part of these methods are extended to address Volume, processing large datasets through multi-core or massive parallelization approaches, such as the MapReduce paradigm. However, these early schema-based approaches are inapplicable to Web Data, which abound in voluminous, noisy, semi-structured, and highly heterogeneous information. To address the additional challenge of Variety, recent works on ER adopt a novel, loosely schema-aware functionality that emphasizes scalability and \u2026",
            "Abstract entirety": 0,
            "Author pub id": "qUBdmWgAAAAJ:7wO8s98CvbsC",
            "Publisher": "Morgan & Claypool Publishers"
        },
        {
            "Title": "New Trends in High-D Vector Similarity Search: AI-driven, Progressive, and Distributed",
            "Publication year": 2021,
            "Publication url": "http://helios.mi.parisdescartes.fr/~themisp/publications/vldb2021-HighDSimilaritySearch-EchihabiZoumpatianosPalpanas-summary.pdf",
            "Abstract": "Similarity search is a core operation of many critical applications, involving massive collections of high-dimensional (high-d) objects. Objects can be data series, text, multimedia, graphs, database tables or deep network embeddings. In this tutorial, we revisit the similarity search problem in light of the recent advances in the field and the new big data landscape. We discuss key data science applications that require efficient high-d similarity search, we survey recent approaches and share surprising insights about their strengths and weaknesses, and we discuss open research problems, including the directions of AI-driven, progressive, and distributed high-d similarity search.",
            "Abstract entirety": 1,
            "Author pub id": "qUBdmWgAAAAJ:CB2v5VPnA5kC",
            "Publisher": "VLDB"
        },
        {
            "Title": "Mining subjective data on the web",
            "Publication year": 2010,
            "Publication url": "http://eprints.biblio.unitn.it/1881/",
            "Abstract": "In the past years we have witnessed Sentiment Analysis and Opinion Mining becoming increasingly popular topics in Information Retrieval and Web data analysis. With the rapid growth of the user-generated content represented in blogs, wikis and Web forums, such an analysis became a useful tool for mining the Web, since it allowed us to capture sentiments and opinions at a large scale. Opinion retrieval has established itself as an important part of search engines. Ratings, opinion trends and representative opinions enrich the search experience of users when combined with traditional document retrieval, by showing more insights about a subject. Opinion aggregation over product reviews can be very useful for product marketing and positioning, revealing the customers\u2019 attitude to a product and its features along different dimensions, such as time, geographical location, and experience. Tracking how opinions or discussions evolve over time can help us identify interesting trends and patterns and better understand the ways that information is propagated in the Internet. In this study, we review the development of Sentiment Analysis and Opinion Mining during the last years, and also discuss the evolution of a relatively new research direction, namely, Contradiction Analysis. We give an overview of the proposed methods and recent advances in these areas, and we try to layout the future research directions in the field.",
            "Abstract entirety": 1,
            "Author pub id": "qUBdmWgAAAAJ:2P1L_qKh6hAC",
            "Publisher": "University of Trento"
        },
        {
            "Title": "Three-dimensional entity resolution with jedai",
            "Publication year": 2020,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S0306437920300570",
            "Abstract": "Entity Resolution (ER) is the task of detecting different entity profiles that describe the same real-world objects. To facilitate its execution, we have developed JedAI, an open-source system that puts together a series of state-of-the-art ER techniques that have been proposed and examined independently, targeting parts of the ER end-to-end pipeline. This is a unique approach, as no other ER tool brings together so many established techniques. Instead, most ER tools merely convey a few techniques, those primarily developed by their creators. In addition to democratizing ER techniques, JedAI goes beyond the other ER tools by offering a series of unique characteristics: (i) It allows for building and benchmarking millions of ER pipelines. (ii) It is the only ER system that applies seamlessly to any combination of structured and/or semi-structured data. (iii) It constitutes the only ER system that runs seamlessly both on \u2026",
            "Abstract entirety": 0,
            "Author pub id": "qUBdmWgAAAAJ:LdasjJ6CEcoC",
            "Publisher": "Pergamon"
        },
        {
            "Title": "Sindbad: a location-based social networking system",
            "Publication year": 2012,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/2213836.2213923",
            "Abstract": "This demo presents Sindbad; a location-based social networking system. Sindbad supports three new services beyond traditional social networking services, namely, location-aware news feed, location-aware recommender, and location-aware ranking. These new services not only consider social relevance for its users, but they also consider spatial relevance. Since location-aware social networking systems have to deal with large number of users, large number of messages, and user mobility, efficiency and scalability are important issues. To this end, Sindbad encapsulates its three main services inside the query processing engine of PostgreSQL. Usage and internal functionality of Sindbad, implemented with PostgreSQL and Google Maps API, are demonstrated through user (ie, web/phone) and system analyzer GUI interfaces, respectively.",
            "Abstract entirety": 1,
            "Author pub id": "qUBdmWgAAAAJ:kz9GbA2Ns4gC",
            "Publisher": "Unknown"
        },
        {
            "Title": "X2Q: your personal example-based graph explorer",
            "Publication year": 2018,
            "Publication url": "https://dl.acm.org/doi/abs/10.14778/3229863.3236251",
            "Abstract": "Exploring knowledge graphs can be a daunting task for any user, expert or novice. This is due to the complexity of the schema or because they are unfamiliar with the contents of the data, or even because they do not know precisely what they are looking for. For the same reason there is a significant demand for exploratory methods for this kind of data. We propose X2Q, a system that facilitates the exploration of knowledge graphs with a hands-on approach. X2Q embodies the flexible multi-exemplar query paradigm, in which easy to express examples serve as the basis for formulating sophisticated, and hard to express queries. Our system helps building examples in an interactive fashion, by showing results of the partial exemplar query as well as suggestions for improving the current examples. Then, the user feedback is incorporated in our scores to filter the irrelevant suggestions upfront. X2Q returns answers in \u2026",
            "Abstract entirety": 0,
            "Author pub id": "qUBdmWgAAAAJ:9c2xU6iGI7YC",
            "Publisher": "VLDB Endowment"
        },
        {
            "Title": "Data reduction in data warehouses.",
            "Publication year": 2004,
            "Publication url": "https://elibrary.ru/item.asp?id=5920396",
            "Abstract": "Degree: Ph. D.DegreeYear: 2003Institute: University of Toronto (Canada)Adviser: Alberto Mendelzon.Much research has been devoted to the efficient computation of relational aggregations. In this paper we consider the inverse problem, that of deriving (approximately) the original data from the aggregates.",
            "Abstract entirety": 1,
            "Author pub id": "qUBdmWgAAAAJ:pqnbT2bcN3wC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Social listening of city scale events using the streaming linked data framework",
            "Publication year": 2013,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-642-41338-4_1",
            "Abstract": "City-scale events may easily attract half a million of visitors in hundreds of venues over just a few days. Which are the most attended venues? What do visitors think about them? How do they feel before, during and after the event? These are few of the questions a city-scale event manger would like to see answered in real-time. In this paper, we report on our experience in social listening of two city-scale events (London Olympic Games 2012, and Milano Design Week 2013) using the Streaming Linked Data Framework.",
            "Abstract entirety": 1,
            "Author pub id": "qUBdmWgAAAAJ:HE397vMXCloC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "Distributed algorithms to find similar time series",
            "Publication year": 2019,
            "Publication url": "https://hal-lirmm.ccsd.cnrs.fr/lirmm-02265726/",
            "Abstract": "As sensors improve in both bandwidth and quantity over time, the need for high performance sensor fusion increases. This requires both better (quasi-linear time if possible) algorithms and paral-lelism. This demonstration uses financial and seismic data to show how two state-of-the-art algorithms construct indexes and answer similarity queries using Spark. Demo visitors will be able to choose query time series, see how each algorithm approximates nearest neighbors and compare times in a parallel environment.",
            "Abstract entirety": 1,
            "Author pub id": "qUBdmWgAAAAJ:u-coK7KVo8oC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Diverse dimension decomposition for itemset spaces",
            "Publication year": 2012,
            "Publication url": "https://link.springer.com/article/10.1007/s10115-012-0518-5",
            "Abstract": "We introduce the problem of diverse dimension decomposition in transactional databases, where a dimension is a set of mutually exclusive itemsets. The problem we consider requires to find a decomposition of the itemset space into dimensions, which are orthogonal to each other and which provide high coverage of the input database. The mining framework we propose can be interpreted as a dimensionality-reducing transformation from the space of all items to the space of orthogonal dimensions. Relying on information-theoretic concepts, we formulate the diverse dimension decomposition problem with a single objective function that simultaneously captures constraints on coverage, exclusivity, and orthogonality. We show that our problem is NP-hard, and we propose a greedy algorithm exploiting the well-known FP-tree data structure. Our algorithm is equipped with strategies for pruning the search \u2026",
            "Abstract entirety": 0,
            "Author pub id": "qUBdmWgAAAAJ:SP6oXDckpogC",
            "Publisher": "Springer-Verlag"
        },
        {
            "Title": "Revisiting the effect of history on learning performance: the problem of the demanding lord",
            "Publication year": 2013,
            "Publication url": "https://link.springer.com/article/10.1007/s10115-012-0568-8",
            "Abstract": "In a variety of settings ranging from recommendation systems to information filtering, approaches which take into account feedback have been introduced to improve services and user experience. However, as also indicated in the machine learning literature, there exist several settings where the requirements and target concept of a learning system changes over time, which consists a case of \u201cconcept drift\u201d. In several systems, a sliding window over the training instances has been used to follow drifting concepts. However, no general analytic study has been performed on the relation between the size of the sliding window and the average performance of a learning system, since previous works have focused on instantaneous performance and specific underlying learners and data characteristics. This work proposes an analytic model that describes the effect of memory window size on the prediction \u2026",
            "Abstract entirety": 0,
            "Author pub id": "qUBdmWgAAAAJ:eJXPG6dFmWUC",
            "Publisher": "Springer London"
        },
        {
            "Title": "Searching with xq: the exemplar query search engine",
            "Publication year": 2014,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/2588555.2594529",
            "Abstract": "We demonstrate XQ, a query engine that implements a novel technique for searching relevant information on the web and in various data sources, called Exemplar Queries. While the traditional query model expects the user to provide a set of specifications that the elements of interest need to satisfy, XQ expects the user to provide only an element of interest and we infer the desired answer set based on that element. Through the various examples we demonstrate the functionality of the system and its applicability in various cases. At the same time, we highlight the technical challenges for this type of query answering and illustrate the implementation approach we have materialized. The demo is intended for both researchers and practitioners and aims at illustrating the benefits of the adoption of this new form of query answering in practical applications and the further study and advancement of its technical solutions.",
            "Abstract entirety": 1,
            "Author pub id": "qUBdmWgAAAAJ:9vf0nzSNQJEC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Rinse: Interactive data series exploration",
            "Publication year": 2015,
            "Publication url": "https://scholar.google.com/scholar?cluster=16877685243917061222&hl=en&oi=scholarr",
            "Abstract": "Numerous applications continuously produce big amounts of data series, and in several time critical scenarios analysts need to be able to query these data as soon as they become available, which is not currently possible with the state-of-the-art indexing methods and for very large data series collections. We develop the first adaptive data series indexing mechanism, called ADS+, specifically tailored to solve the problem of indexing and querying very large data series collections. The main idea is that instead of building the complete index over the complete data set up-front and querying only later, we interactively and adaptively build parts of the index, only for the parts of the data on which the users pose queries. The net effect is that instead of waiting for extended periods of time for the index creation, users can immediately start exploring the data series. In this demonstration we present RINSE, a system that \u2026",
            "Abstract entirety": 0,
            "Author pub id": "qUBdmWgAAAAJ:a3BOlSfXSfwC",
            "Publisher": "VLDB"
        },
        {
            "Title": "Coconut: A scalable bottom-up approach for building data series indexes",
            "Publication year": 2020,
            "Publication url": "https://arxiv.org/abs/2006.13713",
            "Abstract": "Many modern applications produce massive amounts of data series that need to be analyzed, requiring efficient similarity search operations. However, the state-of-the-art data series indexes that are used for this purpose do not scale well for massive datasets in terms of performance, or storage costs. We pinpoint the problem to the fact that existing summarizations of data series used for indexing cannot be sorted while keeping similar data series close to each other in the sorted order. This leads to two design problems. First, traditional bulk-loading algorithms based on sorting cannot be used. Instead, index construction takes place through slow top-down insertions, which create a non-contiguous index that results in many random I/Os. Second, data series cannot be sorted and split across nodes evenly based on their median value; thus, most leaf nodes are in practice nearly empty. This further slows down query speed and amplifies storage costs. To address these problems, we present Coconut. The first innovation in Coconut is an inverted, sortable data series summarization that organizes data series based on a z-order curve, keeping similar series close to each other in the sorted order. As a result, Coconut is able to use bulk-loading techniques that rely on sorting to quickly build a contiguous index using large sequential disk I/Os. We then explore prefix-based and median-based splitting policies for bottom-up bulk-loading, showing that median-based splitting outperforms the state of the art, ensuring that all nodes are densely populated. Overall, we show analytically and empirically that Coconut dominates the state-of-the-art data series \u2026",
            "Abstract entirety": 0,
            "Author pub id": "qUBdmWgAAAAJ:XvxMoLDsR5gC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Method and apparatus for ranked join indices",
            "Publication year": 2011,
            "Publication url": "https://patents.google.com/patent/US8024346B2/en",
            "Abstract": "A method and apparatus for ranked join indices includes a solution providing performance guarantees for top-k join queries over two relations, when preprocessing to construct a ranked join index for a specific join condition is permitted. The concepts of ranking join indices presented herein are also applicable in the case of a single relation. In this case, the concepts herein provide a solution to the top-k selection problem with monotone linear functions, having guaranteed worst case search performance for the case of two ranked attributes and arbitrary preference vectors.",
            "Abstract entirety": 1,
            "Author pub id": "qUBdmWgAAAAJ:_5tno0g5mFcC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Entity resolution: Past, present and yet-to-come: From structured to heterogeneous, to crowd-sourced, to deep learned",
            "Publication year": 2020,
            "Publication url": "https://research.tilburguniversity.edu/en/publications/entity-resolution-past-present-and-yet-to-come-from-structured-to",
            "Abstract": "Entity Resolution (ER) lies at the core of data integration, with a bulk of research focusing on its effectiveness and its time efficiency. Most past relevant works were crafted for addressing Veracity over structured (relational) data. They typically rely on schema, expert and external knowledge to maximize accuracy. Part of these methods have been recently extended to process large volumes of data through massive parallelization techniques, such as the MapReduce paradigm. With the present advent of Big Web Data, the scope moved towards Variety, aiming to handle semi-structured data collections, with noisy and highly heterogeneous information. Relevant works adopt a novel, loosely schema-aware functionality that emphasizes scalability and robustness to noise. Another line of present research focuses on Velocity, ie, processing data collections of a continuously increasing volume.",
            "Abstract entirety": 1,
            "Author pub id": "qUBdmWgAAAAJ:0CzhzZyukY4C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Enabling Better Decisions through Quality-Aware Reports in Business Intelligence Applications.",
            "Publication year": 2008,
            "Publication url": "http://disi.unitn.it/~themis/publications/iciq08.pdf",
            "Abstract": "Business Intelligence (BI) solutions commonly aim at assisting decision-making processes by providing a comprehensive view over a company\u2019s core business data and suitable abstractions thereof. Decision-making based on BI solutions therefore builds on the assumption that providing users with targeted, problem-specific fact data enables them to make informed and, hence, better decisions in their everyday businesses. In order to really provide users with all the necessary details to make informed decisions, we however believe that\u2013in addition to conventional reports\u2013it is essential to also provide users with information about the quality, ie with quality metadata, regarding the data from which reports are generated. Identifying a lack of support for quality metadata management in conventional BI solutions, in this paper we propose the idea of quality-aware reports and a possible architecture for quality-aware BI able to involve the users themselves into the quality metadata management process by soliciting and exploiting user feedback.",
            "Abstract entirety": 1,
            "Author pub id": "qUBdmWgAAAAJ:3s1wT3WcHBgC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Distributed real-time detection and tracking of homogeneous regions in sensor networks",
            "Publication year": 2006,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/4032367/",
            "Abstract": "In many applications we can deploy large number of sensors spanning wide geographical areas, to monitor environmental phenomena. The analysis of the data collected by such sensor network can help us to understand the field dynamics, and optimize the deployment of other solutions. We define a group of sensors having similar underlying distribution over a period of time as a homogeneous region. In this paper we propose distributed algorithms to detect such regions, approximate their boundary with a piece-wise linear curve and track the boundary in real-time. Experimental results show the accuracy and efficiency of our detection and tracking algorithms",
            "Abstract entirety": 1,
            "Author pub id": "qUBdmWgAAAAJ:JV2RwH3_ST0C",
            "Publisher": "IEEE"
        },
        {
            "Title": "Report on the first and second interdisciplinary time series analysis workshop (itisa)",
            "Publication year": 2019,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/3377391.3377400",
            "Abstract": "The analysis of time-series data associated with modernday industrial operations and scientific experiments is now pushing both computational power and resources to their limits. In order to analyze the existing and (more importantly) future very large time series collections, new technologies and the development of more efficient and smarter algorithms are required. The two editions of the Interdisciplinary Time Series Analysis Workshop brought together data analysts from the fields of computer science, astrophysics, neuroscience, engineering, electricity networks, and music. The focus of these workshops was on the requirements of different applications in the various domains, and also on the advances in both academia and industry, in the areas of time-series management and analysis. In this paper, we summarize the experiences presented in and the results obtained from the two workshops, highlighting the \u2026",
            "Abstract entirety": 0,
            "Author pub id": "qUBdmWgAAAAJ:lvd772isFD0C",
            "Publisher": "ACM"
        },
        {
            "Title": "ADS: the adaptive data series index",
            "Publication year": 2016,
            "Publication url": "https://link.springer.com/article/10.1007/s00778-016-0442-5",
            "Abstract": "Numerous applications continuously produce big amounts of data series, and in several time critical scenarios analysts need to be able to query these data as soon as they become available. This, however, is not currently possible with the state-of-the-art indexing methods and for very large data series collections. In this paper, we present the first adaptive indexing mechanism, specifically tailored to solve the problem of indexing and querying very large data series collections. We present a detailed design and evaluation of our method using approximate and exact query algorithms with both synthetic and real data sets. Adaptive indexing significantly outperforms previous solutions, gracefully handling large data series collections, reducing the data to query delay: By the time state-of-the-art indexing techniques finish indexing 1 billion data series (and before answering even a single query), our method has \u2026",
            "Abstract entirety": 0,
            "Author pub id": "qUBdmWgAAAAJ:tYavs44e6CUC",
            "Publisher": "Springer Berlin Heidelberg"
        },
        {
            "Title": "Data series management: The next challenge",
            "Publication year": 2016,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/7495646/",
            "Abstract": "There is an increasingly pressing need, by several applications in diverse domains, for developing techniques able to index and mine very large collections of sequences, or data series. Examples of such applications come from biology, astronomy, entomology, the web, and other domains. It is not unusual for these applications to involve numbers of data series in the order of hundreds of millions to billions, which are often times not analyzed in their full detail due to their sheer size. In this study, we describe recent efforts in designing techniques for indexing and mining truly massive collections of data series that will enable scientists to easily analyze their data. We argue that the main bottleneck in mining such massive datasets is the time taken to build the index. Therefore, we discuss solutions to this problem, including novel techniques that adaptively create data series indexes, allowing users to correctly answer \u2026",
            "Abstract entirety": 0,
            "Author pub id": "qUBdmWgAAAAJ:vbGhcppDl1QC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Topic-related sentiment analysis for discovering contradicting opinions in weblogs",
            "Publication year": 2009,
            "Publication url": "http://eprints.biblio.unitn.it/1644/",
            "Abstract": "This work addresses the problem of analyzing the evolution of community opinions across time. First, a two-step approach is introduced to determine a continuous sentiment value for each topic discussed in a text based on SentiWordNet as lexical resource. Sentences are clustered according to their topic using Latent Dirichlet Allocation. Both steps are extensively evaluated and tested. The output is then exploited for studying contradictions among weblog posts and comments. We introduce a novel measure for contradictions based on a mean value and the variance of opinions among different posts. In addition, a method is proposed, which identifies posts with contradicting opinions on certain topics on a basis of such a measure. It can be used to analyze and track opinion evolution over time and to identify interesting trends and patterns. The developed algorithm is applied to a dataset of medical blogs and comments on political news with promising performance and accuracy.",
            "Abstract entirety": 1,
            "Author pub id": "qUBdmWgAAAAJ:fPk4N6BV_jEC",
            "Publisher": "University of Trento"
        },
        {
            "Title": "The parallel and distributed future of data series mining",
            "Publication year": 2017,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/8035186/",
            "Abstract": "There is an increasingly pressing need, by several applications in diverse domains, for developing techniques able to index and mine very large collections of sequences, or data series. Examples of such applications come from biology, astronomy, entomology, the web, and other domains. It is not unusual for these applications to involve numbers of data series in the order of hundreds of millions to billions, which are often times not analyzed in their full detail due to their sheer size. In this work, we describe past efforts in designing techniques for indexing and mining truly massive collections of data series, based on indexing techniques for fast similarity search, an operation that lies at the core of many mining algorithms. We show that there are two bottlenecks in mining such massive datasets, namely, the time taken to build the index, and the time required to answer exactly similarity queries. In response to these \u2026",
            "Abstract entirety": 0,
            "Author pub id": "qUBdmWgAAAAJ:edDO8Oi4QzsC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Massively distributed time series indexing and querying",
            "Publication year": 2018,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/8528881/",
            "Abstract": "Indexing is crucial for many data mining tasks that rely on efficient and effective similarity query processing. Consequently, indexing large volumes of time series, along with high performance similarity query processing, have became topics of high interest. For many applications across diverse domains though, the amount of data to be processed might be intractable for a single machine, making existing centralized indexing solutions inefficient. We propose a parallel indexing solution that gracefully scales to billions of time series, and a parallel query processing strategy that, given a batch of queries, efficiently exploits the index. Our experiments, on both synthetic and real world data, illustrate that our index creation algorithm works on four billion time series in less than five hours, while the state of the art centralized algorithms do not scale and have their limit on 1 billion time series, where they need more than five \u2026",
            "Abstract entirety": 0,
            "Author pub id": "qUBdmWgAAAAJ:cWzG1nlazyYC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Beyond 100 million entities: large-scale blocking-based resolution for heterogeneous data",
            "Publication year": 2012,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/2124295.2124305",
            "Abstract": "A prerequisite for leveraging the vast amount of data available on the Web is Entity Resolution, ie, the process of identifying and linking data that describe the same real-world objects. To make this inherently quadratic process applicable to large data sets, blocking is typically employed: entities (records) are grouped into clusters-the blocks-of matching candidates and only entities of the same block are compared. However, novel blocking techniques are required for dealing with the noisy, heterogeneous, semi-structured, user-generateddata in the Web, as traditional blocking techniques are inapplicable due to their reliance on schema information. The introduction of redundancy, improves the robustness of blocking methods but comes at the price of additional computational cost.",
            "Abstract entirety": 1,
            "Author pub id": "qUBdmWgAAAAJ:tS2w5q8j5-wC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Domain-and structure-agnostic end-to-end entity resolution with JedAI",
            "Publication year": 2020,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/3385658.3385664",
            "Abstract": "We present JedAI, a new open-source toolkit for endto- end Entity Resolution. JedAI is domain-agnostic in the sense that it does not depend on background expert knowledge, applying seamlessly to data of any domain with minimal human intervention. JedAI is also structure-agnostic, as it can process any type of data, ranging from structured (relational) to semi-structured (RDF) and un-structured (free-text) entity descriptions. JedAI consists of two parts: (i) JedAI-core is a library of numerous state-of-the-art methods that can be mixed and matched to form (thousands of) end-to-end workflows, allowing for easily benchmarking their relative performance. (ii) JedAI-gui is a user-friendly desktop application that facilitates the composition of complex workflows via a wizard-like interface. It is suitable for both lay and power users, offering concrete guidelines and automatic configuration, as well as manual configuration \u2026",
            "Abstract entirety": 0,
            "Author pub id": "qUBdmWgAAAAJ:F1b5ZUV5XREC",
            "Publisher": "ACM"
        },
        {
            "Title": "Parallel meta-blocking: Realizing scalable entity resolution over large, heterogeneous data",
            "Publication year": 2015,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/7363782/",
            "Abstract": "Entity resolution constitutes a crucial task for many applications, but has an inherently quadratic complexity. Typically, it scales to large volumes of data through blocking: similar entities are clustered into blocks so that it suffices to perform comparisons only within each block. Meta-blocking further increases efficiency by cleaning the overlapping blocks from unnecessary comparisons. However, even Meta-blocking can be time-consuming: applying it to blocks with 7.4 million entities and 2.21011 comparisons takes almost 8 days on a modern high-end server. In this paper, we parallelize Meta-blocking based on MapReduce. We propose a simple strategy that explicitly creates the core concept of Meta-blocking, the blocking graph. We then describe an advanced strategy that creates the blocking graph implicitly, reducing the overhead of data exchange. We also introduce a load balancing algorithm that distributes the \u2026",
            "Abstract entirety": 0,
            "Author pub id": "qUBdmWgAAAAJ:URolC5Kub84C",
            "Publisher": "IEEE"
        },
        {
            "Title": "Bestneighbor: efficient evaluation of knn queries on large time series databases",
            "Publication year": 2021,
            "Publication url": "https://link.springer.com/article/10.1007/s10115-020-01518-4",
            "Abstract": "This paper presents parallel solutions (developed based on two state-of-the-art algorithms iSAX and sketch) for evaluating k nearest neighbor queries on large databases of time series, compares them based on various measures of quality and time performance, and offers a tool that uses the characteristics of application data to determine which algorithm to choose for that application and how to set the parameters for that algorithm. Specifically, our experiments show that: (i) iSAX and its derivatives perform best in both time and quality when the time series can be characterized by a few low-frequency Fourier Coefficients, a regime where the iSAX pruning approach works well. (ii) iSAX performs significantly less well when high-frequency Fourier Coefficients have much of the energy of the time series. (iii) A random projection approach based on sketches by contrast is more or less independent of the \u2026",
            "Abstract entirety": 0,
            "Author pub id": "qUBdmWgAAAAJ:wMgC3FpKEyYC",
            "Publisher": "Springer London"
        },
        {
            "Title": "Local similarity search on geolocated time series using hybrid indexing",
            "Publication year": 2019,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/3347146.3359349",
            "Abstract": "Geolocated time series, ie, time series associated with certain locations, abound in many modern applications. In this paper, we consider hybrid queries for retrieving geolocated time series based on filters that combine spatial distance and time series similarity. For the latter, unlike existing work, we allow filtering based on local similarity, which is computed based on subsequences rather than the entire length of each series, thus allowing the discovery of more fine-grained trends and patterns. To efficiently support such queries, we first leverage the state-of-the-art BTSR-tree index, which utilizes bounds over both the locations and the shapes of time series to prune the search space. Moreover, we propose optimizations that check at specific timestamps to identify candidate time series that may exceed the required local similarity threshold. To further increase pruning power, we introduce the SBTSR-tree index, an \u2026",
            "Abstract entirety": 0,
            "Author pub id": "qUBdmWgAAAAJ:gVv57TyPmFsC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Web-scale, schema-agnostic, end-to-end entity resolution",
            "Publication year": 2018,
            "Publication url": "https://helios.mi.parisdescartes.fr/~themisp/publications/www18-summary.pdf",
            "Abstract": "Entity Resolution lies at the core of data integration, with a bulk of research focusing on both its effectiveness and time efficiency. Initially, most relevant works were crafted for structured, relational data that are described by a schema of well-known quality and meaning. With the advent of Big Data, though, these early schema-based approaches became inapplicable, as the scope of Entity Resolution moved to Web Data collections, which abound in noisy, semi-structured, voluminous and highly heterogeneous information. To address these inherent challenges of Web Data, recent works on Entity Resolution adopt a novel, schema-agnostic functionality that emphasizes scalability and robustness to noise. In this tutorial, we take a close look on this line of research, organizing the state-of-the-art in the field into a scalable, schemaagnostic end-to-end workflow that consists of 4 steps. The first two focus on improving time efficiency through blocking, while the last two steps are dedicated to effectiveness:(i) Block Building clusters similar entities into blocks so as to restrict the originally quadratic complexity to comparing just pairs of entities that are highly likely to be matching.(ii) Block Processing further cuts down on the computational cost by discarding pairwise comparisons that are repeated or lack sufficient evidence for producing duplicates.(iii) Entity Matching carries out all comparisons in the final set of blocks, creating a similarity graph with a node for every entity and a weighted edge for every pair of compared entities.(iv) Entity Clustering partitions the nodes of the similarity graph into equivalence clusters such that every cluster contains all resources \u2026",
            "Abstract entirety": 0,
            "Author pub id": "qUBdmWgAAAAJ:6yz0xqPARnAC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Blocking and filtering techniques for entity resolution: A survey",
            "Publication year": 2020,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/3377455",
            "Abstract": "Entity Resolution (ER), a core task of Data Integration, detects different entity profiles that correspond to the same real-world object. Due to its inherently quadratic complexity, a series of techniques accelerate it so that it scales to voluminous data. In this survey, we review a large number of relevant works under two different but related frameworks: Blocking and Filtering. The former restricts comparisons to entity pairs that are more likely to match, while the latter identifies quickly entity pairs that are likely to satisfy predetermined similarity thresholds. We also elaborate on hybrid approaches that combine different characteristics. For each framework we provide a comprehensive list of the relevant works, discussing them in the greater context. We conclude with the most promising directions for future work in the field.",
            "Abstract entirety": 1,
            "Author pub id": "qUBdmWgAAAAJ:otzGkya1bYkC",
            "Publisher": "ACM"
        },
        {
            "Title": "Electricity demand activation extraction: From known to uknown signatures, using similarity search",
            "Publication year": 2021,
            "Publication url": "http://helios.mi.parisdescartes.fr/~themisp/publications/eenergy21.pdf",
            "Abstract": "Energy management is the center of attention in current environmental and economical debates. Energy efficiency, one of the key of a successful ecological transition, requires precise and robust information about energy consumption. Davis and all [4] advocates that aggregate energy feedback can reduce energy consumption by about 3%. Non-Intrusive Load Monitoring (NILM) or energy disaggregation is one way to give this feedback. NILM is the process of estimating information (consumption, time of use...) on each individual appliance (eg, heating, water heating, washing machine, refrigerator) from the global consumption of a household. The NILM problem was formalized in the mid-1980s by George Hart [11]. More recently deep learning for NILM was introduced by Jack Kelly [12] with major progress on state of the art models, it made a major breakthrough against old methodology. In this paper, we focus on automated activation extraction from single appliance load curve methods. This is an intermediate step in order to work on NILM techniques. It can be useful in two cases:(1) To tag start and end of single-appliance activations in order to train NILM algorithms which aims at detecting the operating time of an appliance.(2) To create a signature collection. Indeed, lack of supervised data (with both the sub-meter and aggregated load curves) in the NILM field is one of the main problems stalling the improvement of disaggregation algorithms, especially deep learning ones. One way to overcome this limitation is to",
            "Abstract entirety": 1,
            "Author pub id": "qUBdmWgAAAAJ:wKETBy42zhYC",
            "Publisher": "Unknown"
        },
        {
            "Title": "The entity name system: Enabling the web of entities",
            "Publication year": 2010,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/5452708/",
            "Abstract": "We are currently witnessing an increasing interest in the use of the web as an information and knowledge source. Much of the information sought after in the web is in this case relevant to named entities (i.e., persons, locations, organizations, etc.). An important observation is that the entity identification problem lies at the core of many applications in this context. In order to deal with this problem, we propose the Entity Name System (ENS), a large scale, distributed infrastructure for assigning and managing unique identifiers for entities in the web. In this paper, we examine the special requirements for storage and management of entities, in the context of the ENS. We present a conceptual model for the representation of entities, and discuss problems related to data quality, as well as the management of the entity lifecycle. Finally, we describe the architecture of the current prototype of the system.",
            "Abstract entirety": 1,
            "Author pub id": "qUBdmWgAAAAJ:rO6llkc54NcC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Distributed deviation detection in sensor networks",
            "Publication year": 2003,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/959060.959074",
            "Abstract": "Sensor networks have recently attracted much attention, because of their potential applications in a number of different settings. The sensors can be deployed in large numbers in wide geographical areas, and can be used to monitor physical phenomena, or to detect certain events.An interesting problem which has not been adequately addressed so far is that of distributed online deviation detection in streaming data. The identification of deviating values provides an efficient way to focus on the interesting events in the sensor network.In this work, we propose a technique for online deviation detection in streaming data. We discuss how these techniques can operate efficiently in the distributed environment of a sensor network, and discuss the tradeoffs that arise in this setting. Our techniques process as much of the data as possible in a decentralized fashion, so as to avoid unnecessary communication and \u2026",
            "Abstract entirety": 0,
            "Author pub id": "qUBdmWgAAAAJ:4JMBOYKVnBMC",
            "Publisher": "ACM"
        },
        {
            "Title": "A probabilistic optimization framework for the empty-answer problem",
            "Publication year": 2013,
            "Publication url": "https://dl.acm.org/doi/abs/10.14778/2556549.2556560",
            "Abstract": "We propose a principled optimization-based interactive query relaxation framework for queries that return no answers. Given an initial query that returns an empty answer set, our framework dynamically computes and suggests alternative queries with less conditions than those the user has initially requested, in order to help the user arrive at a query with a non-empty answer, or at a query for which no matter how many additional conditions are ignored, the answer will still be empty. Our proposed approach for suggesting query relaxations is driven by a novel probabilistic framework based on optimizing a wide variety of application-dependent objective functions. We describe optimal and approximate solutions of different optimization problems using the framework. We analyze these solutions, experimentally verify their efficiency and effectiveness, and illustrate their advantage over the existing approaches.",
            "Abstract entirety": 1,
            "Author pub id": "qUBdmWgAAAAJ:eMMeJKvmdy0C",
            "Publisher": "VLDB Endowment"
        },
        {
            "Title": "dbTrento: the data and information management group at the University of Trento",
            "Publication year": 2012,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/2380776.2380784",
            "Abstract": "[Semantic-based Keyword Search] Keyword search is becoming the de-facto mechanism for querying data [19], since it does not require knowledge of the full semantics or their organization in the repository, neither knowledge of some complex query language. For this reason, there has been enough work on querying structured (mostly relational) data through keywords. These works are typically based on an index that is built in advance, and which supports at run time the mapping of",
            "Abstract entirety": 1,
            "Author pub id": "qUBdmWgAAAAJ:eflP2zaiRacC",
            "Publisher": "ACM"
        },
        {
            "Title": "On space constrained set selection problems",
            "Publication year": 2008,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S0169023X08000918",
            "Abstract": "Space constrained optimization problems arise in a variety of applications, ranging from databases to ubiquitous computing. Typically, these problems involve selecting a set of items of interest, subject to a space constraint.We show that in many important applications, one faces variants of this basic problem, in which the individual items are sets themselves, and each set is associated with a benefit value. Since there are no known approximation algorithms for these problems, we explore the use of greedy and randomized techniques. We present a detailed performance and theoretical evaluation of the algorithms, highlighting the efficiency of the proposed solutions.",
            "Abstract entirety": 1,
            "Author pub id": "qUBdmWgAAAAJ:35N4QoGY0k4C",
            "Publisher": "North-Holland"
        },
        {
            "Title": "New Trends in Database and Information Systems II",
            "Publication year": 2015,
            "Publication url": "https://link.springer.com/content/pdf/10.1007/978-3-319-10518-5.pdf",
            "Abstract": "This volume contains a selection of papers presented at the 18th East-European Conference on Advances in Databases and Information Systems (ADBIS 2014), held on September 7\u201310, 2014, in Ohrid, Republic of Macedonia. Database and information systems technologies have been rapidly evolving in several directions in the recent years. New types of data, new kinds of emerging applications and information systems to support them, raise diverse challenges to be addressed. The so-called big data challenge, streaming data management and processing, social networks and other complex data analysis, including semantic reasoning into information systems supporting for instance trading, negotiations, and bidding mechanisms are but a few examples of such emerging research areas. The ADBIS series of conferences aims to provide a forum for the presentation and dissemination of research on database \u2026",
            "Abstract entirety": 0,
            "Author pub id": "qUBdmWgAAAAJ:1yQoGdGgb4wC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Scaling entity resolution to large, heterogeneous data with enhanced meta-blocking.",
            "Publication year": 2016,
            "Publication url": "http://shichuan.org/hin/time/2016.%20EDBT2016%20Scaling%20Entity%20Resolution%20to%20Large,%20Heterogeneous%20Data%20with%20Enhanced%20Meta-blocking.pdf",
            "Abstract": "Entity Resolution constitutes a quadratic task that typically scales to large entity collections through blocking. The resulting blocks can be restructured by Meta-blocking in order to significantly increase precision at a limited cost in recall. Yet, its processing can be time-consuming, while its precision remains poor for configurations with high recall. In this work, we propose new meta-blocking methods that improve precision by up to an order of magnitude at a negligible cost to recall. We also introduce two efficiency techniques that, when combined, reduce the overhead time of Metablocking by more than an order of magnitude. We evaluate our approaches through an extensive experimental study over 6 realworld, heterogeneous datasets. The outcomes indicate that our new algorithms outperform all meta-blocking techniques as well as the state-of-the-art methods for block processing in all respects.",
            "Abstract entirety": 1,
            "Author pub id": "qUBdmWgAAAAJ:BwyfMAYsbu0C",
            "Publisher": "Unknown"
        },
        {
            "Title": "End-to-end entity resolution for big data: A survey",
            "Publication year": 2019,
            "Publication url": "https://arxiv.org/abs/1905.06397",
            "Abstract": "One of the most important tasks for improving data quality and the reliability of data analytics results is Entity Resolution (ER). ER aims to identify different descriptions that refer to the same real-world entity, and remains a challenging problem. While previous works have studied specific aspects of ER (and mostly in traditional settings), in this survey, we provide for the first time an end-to-end view of modern ER workflows, and of the novel aspects of entity indexing and matching methods in order to cope with more than one of the Big Data characteristics simultaneously. We present the basic concepts, processing steps and execution strategies that have been proposed by different communities, i.e., database, semantic Web and machine learning, in order to cope with the loose structuredness, extreme diversity, high speed and large scale of entity descriptions used by real-world applications. Finally, we provide a synthetic discussion of the existing approaches, and conclude with a detailed presentation of open research directions.",
            "Abstract entirety": 1,
            "Author pub id": "qUBdmWgAAAAJ:8xutWZnSdmoC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Quality of sentiment analysis tools: the reasons of inconsistency",
            "Publication year": 2020,
            "Publication url": "https://dl.acm.org/doi/abs/10.14778/3436905.3436924",
            "Abstract": "In this paper, we present a comprehensive study that evaluates six state-of-the-art sentiment analysis tools on five public datasets, based on the quality of predictive results in the presence of semantically equivalent documents, i.e., how consistent existing tools are in predicting the polarity of documents based on paraphrased text. We observe that sentiment analysis tools exhibit intra-tool inconsistency, which is the prediction of different polarity for semantically equivalent documents by the same tool, and inter-tool inconsistency, which is the prediction of different polarity for semantically equivalent documents across different tools. We introduce a heuristic to assess the data quality of an augmented dataset and a new set of metrics to evaluate tool inconsistencies. Our results indicate that tool inconsistencies is still an open problem, and they point towards promising research directions and accuracy improvements that \u2026",
            "Abstract entirety": 0,
            "Author pub id": "qUBdmWgAAAAJ:nRpfm8aw39MC",
            "Publisher": "VLDB Endowment"
        },
        {
            "Title": "When a Tweet Finds its Place: Fine-Grained Tweet Geolocalisation.",
            "Publication year": 2016,
            "Publication url": "http://helios.mi.parisdescartes.fr/~themisp/publications/sogood16.pdf",
            "Abstract": "The recent rise in the use of social networks has resulted in an abundance of information on different aspects of everyday social activities that is available online. In the process of analysis of the information originating from social networks, and especially Twitter, an important aspect is that of the geographic coordinates, ie, geolocalisation, of the relevant information. This information is used by a variety of applications for the better understanding of an urban area, the tracking of the way a virus spreads, the identification of people that need help in case of a disaster (eg, an earthquake), or just for the better understanding of the dynamics of a major event (eg, a concert). However, only a tiny percentage of the twitter posts are geotagged, which restricts the applicability of location-based applications. In this work, we extend our framework for geolocating tweets that are not geotagged, and describe a general solution for estimating the city and neighborhood in the city, from which a post was generated. In addition, we study the specific problem of geolocalising tweets deriving from targeted locations of interest (ie, cities and neighborhoods in these cities), and present the visualizations of the prototype dashboard application we have developed, which can help end-users and large-scale event organizers to better plan and manage their activities. The experimental evaluation with real data demonstrates the efficiency and effectiveness of our approach.",
            "Abstract entirety": 1,
            "Author pub id": "qUBdmWgAAAAJ:gsN89kCJA0AC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Model-driven dashboards for business performance reporting",
            "Publication year": 2006,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/4031224/",
            "Abstract": "Business performance modeling and model-driven business transformation are two research directions that are attracting much attention lately. In this study, we propose an approach for dashboard development that is model-driven and can be integrated with the business performance models. We adopt the business performance modeling framework, and we extend it in order to capture the reporting aspect of the business operation. We describe models that can effectively represent all the elements necessary for the business performance reporting process, and the interactions among them. We also demonstrate how all these models can be combined and automatically generate the final solution. Finally, we discuss our experience from the application of our technique in a real-world scenario. This case study shows that our technique can be efficiently applied to and handle changes in the underlying business \u2026",
            "Abstract entirety": 0,
            "Author pub id": "qUBdmWgAAAAJ:YFjsv_pBGBYC",
            "Publisher": "IEEE"
        },
        {
            "Title": "New Trends in Databases and Information Systems",
            "Publication year": 2013,
            "Publication url": "https://link.springer.com/content/pdf/10.1007/978-3-319-01863-8.pdf",
            "Abstract": "This volume contains a selection of the papers presented at the 17th East-European Conference on Advances in Databases and Information Systems (ADBIS 2013) and the associated satellite events, held on September 1\u20134, 2013 in Genoa, Italy.The ADBIS series of conferences aims at providing a forum for the dissemination of research accomplishments and to promote interaction and collaboration between the database and information system research communities from Central and East European countries and the rest of the world. The ADBIS conferences provide an international platform for the presentation of research on database theory, development of advanced DBMS technologies, and their advanced applications. ADBIS 2013 continued the ADBIS series held in St. Petersburg (1997), Poznan (1998), Maribor (1999), Prague (2000), Vilnius (2001), Bratislava (2002), Dresden (2003), Budapest (2004 \u2026",
            "Abstract entirety": 0,
            "Author pub id": "qUBdmWgAAAAJ:Mojj43d5GZwC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Unsupervised and scalable subsequence anomaly detection in large data series",
            "Publication year": 2021,
            "Publication url": "https://link.springer.com/article/10.1007/s00778-021-00655-8",
            "Abstract": "Subsequence anomaly (or outlier) detection in long sequences is an important problem with applications in a wide range of domains. However, the approaches that have been proposed so far in the literature have severe limitations: they either require prior domain knowledge or become cumbersome and expensive to use in situations with recurrent anomalies of the same type. In this work, we address these problems and propose NormA, a novel approach, suitable for domain-agnostic anomaly detection. NormA is based on a new data series primitive, which permits to detect anomalies based on their (dis) similarity to a model that represents normal behavior. The experimental results on several real datasets demonstrate that the proposed approach correctly identifies all single and recurrent anomalies of various types, with no prior knowledge of the characteristics of these anomalies (except for their length \u2026",
            "Abstract entirety": 0,
            "Author pub id": "qUBdmWgAAAAJ:MhiOAD_qIWkC",
            "Publisher": "Springer Berlin Heidelberg"
        },
        {
            "Title": "RINSE: interactive data series exploration with ADS+",
            "Publication year": 2015,
            "Publication url": "https://dl.acm.org/doi/abs/10.14778/2824032.2824099",
            "Abstract": "Numerous applications continuously produce big amounts of data series, and in several time critical scenarios analysts need to be able to query these data as soon as they become available. An adaptive index data structure, ADS+, which is specifically tailored to solve the problem of indexing and querying very large data series collections has been recently proposed as a solution to this problem. The main idea is that instead of building the complete index over the complete data set up-front and querying only later, we interactively and adaptively build parts of the index, only for the parts of the data on which the users pose queries. The net effect is that instead of waiting for extended periods of time for the index creation, users can immediately start exploring the data series. In this work, we present a demonstration of ADS+; we introduce RINSE, a system that allows users to experience the benefits of the ADS \u2026",
            "Abstract entirety": 0,
            "Author pub id": "qUBdmWgAAAAJ:0KyAp5RtaNEC",
            "Publisher": "VLDB Endowment"
        },
        {
            "Title": "iSAX 2.0: Indexing and mining one billion time series",
            "Publication year": 2010,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/5693959/",
            "Abstract": "There is an increasingly pressing need, by several applications in diverse domains, for developing techniques able to index and mine very large collections of time series. Examples of such applications come from astronomy, biology, the web, and other domains. It is not unusual for these applications to involve numbers of time series in the order of hundreds of millions to billions. However, all relevant techniques that have been proposed in the literature so far have not considered any data collections much larger than one-million time series. In this paper, we describe iSAX 2.0, a data structure designed for indexing and mining truly massive collections of time series. We show that the main bottleneck in mining such massive datasets is the time taken to build the index, and we thus introduce a novel bulk loading mechanism, the first of this kind specifically tailored to a time series index. We show how our method \u2026",
            "Abstract entirety": 0,
            "Author pub id": "qUBdmWgAAAAJ:NaGl4SEjCO4C",
            "Publisher": "IEEE"
        },
        {
            "Title": "Paris: The next destination for fast data series indexing and query answering",
            "Publication year": 2018,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/8622293/",
            "Abstract": "We propose ParIS, the first disk-based data series index that inherently takes advantage of modern hardware parallelization, in order to accelerate processing times. Our experimental results demonstrate that ParIS completely removes the CPU latency during index construction for disk-resident data. In terms of exact query answering, ParIS is more than 2 orders of magnitude faster than the current state of the art index scan method, and more than 3 orders of magnitude faster than the optimized serial scan method. ParIS owes its efficiency not only to the effective use of multi-core and multi-socket architectures, in order to distribute and execute in parallel both index construction and query answering, but also to the exploitation of the Single Instruction Multiple Data (SIMD) capabilities of modern CPUs, in order to further parallelize the execution of individual instructions inside each core.",
            "Abstract entirety": 1,
            "Author pub id": "qUBdmWgAAAAJ:HtS1dXgVpQUC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Example-based Search: a New Frontier for Exploratory Search",
            "Publication year": 2019,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/3331184.3331387",
            "Abstract": "Exploration is one of the primordial ways to accrue knowledge about the world and its nature. As we accumulate, mostly automatically, data at unprecedented volumes and speed, our datasets have become complex and hard to understand. In this context, exploratory search provides a handy tool for progressively gather the necessary knowledge by starting from a tentative query that can provide cues about the next queries to issue. An exploratory query should be simple enough to avoid complicate declarative languages (such as SQL) and convoluted mechanism, and at the same time retain the flexibility and expressiveness required to express complex information needs. Recently, we have witnessed a rediscovery of the so called example-based methods, in which the user, or the analyst circumvent query languages by using examples as input. This shift in semantics has led to a number of methods receiving as \u2026",
            "Abstract entirety": 0,
            "Author pub id": "qUBdmWgAAAAJ:Aul-kAQHnToC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Uncertain time-series similarity: Return to the basics",
            "Publication year": 2012,
            "Publication url": "https://arxiv.org/abs/1208.1931",
            "Abstract": "In the last years there has been a considerable increase in the availability of continuous sensor measurements in a wide range of application domains, such as Location-Based Services (LBS), medical monitoring systems, manufacturing plants and engineering facilities to ensure efficiency, product quality and safety, hydrologic and geologic observing systems, pollution management, and others. Due to the inherent imprecision of sensor observations, many investigations have recently turned into querying, mining and storing uncertain data. Uncertainty can also be due to data aggregation, privacy-preserving transforms, and error-prone mining algorithms. In this study, we survey the techniques that have been proposed specifically for modeling and processing uncertain time series, an important model for temporal data. We provide an analytical evaluation of the alternatives that have been proposed in the literature, highlighting the advantages and disadvantages of each approach, and further compare these alternatives with two additional techniques that were carefully studied before. We conduct an extensive experimental evaluation with 17 real datasets, and discuss some surprising results, which suggest that a fruitful research direction is to take into account the temporal correlations in the time series. Based on our evaluations, we also provide guidelines useful for the practitioners in the field.",
            "Abstract entirety": 1,
            "Author pub id": "qUBdmWgAAAAJ:5Ul4iDaHHb8C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Scalable Discovery of Contradicting Opinions in Weblogs",
            "Publication year": 2009,
            "Publication url": "http://eprints.biblio.unitn.it/1645/",
            "Abstract": "Weblogs are a popular means of information communication, where people discuss a variety of topics, and often times also express their opinions on these topics. In this work, we address the problem of analyzing the evolution of community opinions across time, as these are represented in the weblogs. In particular, we are interested in identifying topics and time windows, for which contradictory opinions have been expressed. We describe an approach for solving the above problem, which consists of the following steps. We first introduce a technique for topic and opinion extraction that operates at the sentence level. Then, we propose a novel measure for contradictions that can effectively aggregate the relevant information from the weblog posts. We discuss its properties, and show how it can be used to detect two different types of contradictions, namely, simultaneous contradictions, and change of sentiment. Finally, we describe an efficient data structure for answering queries related to contradiction detection, and show that it has the additional property of being incrementally maintainable. A detailed experimental evaluation of our approach with synthetic and real datasets demonstrates the applicability and efficiency of our techniques.",
            "Abstract entirety": 1,
            "Author pub id": "qUBdmWgAAAAJ:u_35RYKgDlwC",
            "Publisher": "University of Trento"
        },
        {
            "Title": "Temporal analytics in social media",
            "Publication year": 2018,
            "Publication url": "https://hal.archives-ouvertes.fr/hal-02349260/",
            "Abstract": "Temporal Analytics in Social Media - Archive ouverte HAL Acc\u00e9der directement au contenu \nAcc\u00e9der directement \u00e0 la navigation Toggle navigation CCSD HAL HAL HALSHS TEL M\u00e9diHAL \nListe des portails AUR\u00e9HAL API Data Documentation Episciences.org Episciences.org Revues \nDocumentation Sciencesconf.org Support hal Accueil D\u00e9p\u00f4t Consultation Les derniers d\u00e9p\u00f4ts \nPar type de publication Par discipline Par ann\u00e9e de publication Par structure de recherche Les \nportails de l'archive Recherche Documentation hal-02349260, version 1 Chapitre d'ouvrage \nTemporal Analytics in Social Media Sihem Amer-Yahia 1 Themis Palpanas 2 Mikalai \nTsytsarau 2 Sofia Kleisarchaki 3 Ahlame Douzal Vassilis Christophides 4 D\u00e9tails 1 CNRS - \nCentre National de la Recherche Scientifique 2 DISI - Department of Information Engineering \nand Computer Science 3 CEA - Commissariat \u00e0 l'\u00e9nergie atomique et aux \u00e9nergies 4 -- \u2026",
            "Abstract entirety": 0,
            "Author pub id": "qUBdmWgAAAAJ:tH6gc1N1XXoC",
            "Publisher": "Springer New York"
        },
        {
            "Title": "Jedai: The force behind entity resolution",
            "Publication year": 2017,
            "Publication url": "https://link.springer.com/content/pdf/10.1007/978-3-319-70407-4_30.pdf",
            "Abstract": "We present JedAI, a toolkit for Entity Resolution that can be used in three different ways: as an open-source Java library that implements numerous state-of-the-art, domain-independent methods, as a workbench that facilitates the evaluation of their relative performance and as a desktop application that offers out-of-the-box ER solutions. JedAI bridges the gap between the database and the Semantic Web communities, offering solutions that are applicable to both relational and RDF data. It also conveys a modular architecture that facilitates its extension with more methods and with more comprehensive workflows.",
            "Abstract entirety": 1,
            "Author pub id": "qUBdmWgAAAAJ:Dip1O2bNi0gC",
            "Publisher": "Springer, Cham"
        },
        {
            "Title": "Entity Resolution: Past, Present and Yet-to-Come.",
            "Publication year": 2020,
            "Publication url": "https://helios.mi.parisdescartes.fr/~themisp/publications/edbt20-summary.pdf",
            "Abstract": "Entity Resolution (ER) lies at the core of data integration, with a bulk of research focusing on its effectiveness and its time efficiency. Most past relevant works were crafted for addressing Veracity over structured (relational) data. They typically rely on schema, expert and external knowledge to maximize accuracy. Part of these methods have been recently extended to process large volumes of data through massive parallelization techniques, such as the MapReduce paradigm. With the present advent of Big Web Data, the scope moved towards Variety, aiming to handle semi-structured data collections, with noisy and highly heterogeneous information. Relevant works adopt a novel, loosely schemaaware functionality that emphasizes scalability and robustness to noise. Another line of present research focuses on Velocity, ie, processing data collections of a continuously increasing volume. In this tutorial, we present the ER generations by discussing past, present, and yet-to-come mechanisms. For each generation, we outline the corresponding ER workflow along with the state-of-the-art methods per workflow step. Thus, we provide the participants with a deep understanding of the broad field of ER, highlighting the recent advances in crowd-sourcing and deep learning applications in this active research domain. We also equip them with practical skills in applying ER workflows through a hands-on session that involves our publicly available ER toolbox and data.",
            "Abstract entirety": 1,
            "Author pub id": "qUBdmWgAAAAJ:4X0JR2_MtJMC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Return of the lernaean hydra: Experimental evaluation of data series approximate similarity search",
            "Publication year": 2020,
            "Publication url": "https://arxiv.org/abs/2006.11459",
            "Abstract": "Data series are a special type of multidimensional data present in numerous domains, where similarity search is a key operation that has been extensively studied in the data series literature. In parallel, the multidimensional community has studied approximate similarity search techniques. We propose a taxonomy of similarity search techniques that reconciles the terminology used in these two domains, we describe modifications to data series indexing techniques enabling them to answer approximate similarity queries with quality guarantees, and we conduct a thorough experimental evaluation to compare approximate similarity search techniques under a unified framework, on synthetic and real datasets in memory and on disk. Although data series differ from generic multidimensional vectors (series usually exhibit correlation between neighboring values), our results show that data series techniques answer approximate %similarity queries with strong guarantees and an excellent empirical performance, on data series and vectors alike. These techniques outperform the state-of-the-art approximate techniques for vectors when operating on disk, and remain competitive in memory.",
            "Abstract entirety": 1,
            "Author pub id": "qUBdmWgAAAAJ:artPoR2Yc-kC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Knowledge Mining for the Business Analyst",
            "Publication year": 2008,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-540-85654-2_69",
            "Abstract": "There is an extensive literature on data mining techniques, including several applications of these techniques in the e-commerce setting. However, all previous approaches require that expert users interpret the data mining results, making them cumbersome to use by business analysts. In this work, we describe a framework that shows how data mining technology can be effectively applied in an e-commerce environment, delivering significant benefits to the business analyst. Using a real-world case study, we demonstrate the added benefit of the proposed method. We also validate the claim that the produced results represent actionable knowledge that can help the business analyst improve the business performance, by significantly reducing the time needed for data analysis, which results in substantial financial savings.",
            "Abstract entirety": 1,
            "Author pub id": "qUBdmWgAAAAJ:SeFeTyx0c_EC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "A Case Study of Active, Continuous and Predictive Social Media Analytics for Smart City.",
            "Publication year": 2014,
            "Publication url": "https://core.ac.uk/download/pdf/55151189.pdf",
            "Abstract": "Imagine you are in Milano for the Design Week. You have just spent a couple of days attending few nice events in Brera district. Which of the other hundreds of events spread around in Milano shall you attend now? This paper presents a system able to recommend venues to the visitors of such a city-scale event based on the digital footprints they left on Social Media. By combining deductive and inductive stream reasoning techniques with visitor-modeling functionality, this system semantically analyses and links visitors\u2019 social network activities to produce high-quality recommendations even when information about visitors\u2019 preferences for venues and events is sparse.",
            "Abstract entirety": 1,
            "Author pub id": "qUBdmWgAAAAJ:dQ2og3OwTAUC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Eliminating the redundancy in blocking-based entity resolution methods",
            "Publication year": 2011,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/1998076.1998093",
            "Abstract": "Entity resolution is the task of identifying entities that refer to the same real-world object. It has important applications in the context of digital libraries, such as citation matching and author disambiguation. Blocking is an established methodology for efficiently addressing this problem; it clusters similar entities together, and compares solely entities inside each cluster. In order to effectively deal with the current large, noisy and heterogeneous data collections, novel blocking methods that rely on redundancy have been introduced: they associate each entity with multiple blocks in order to increase recall, thus increasing the computational cost, as well.",
            "Abstract entirety": 1,
            "Author pub id": "qUBdmWgAAAAJ:RYcK_YlVTxYC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Using social media for sub-event detection during disasters",
            "Publication year": 2021,
            "Publication url": "https://link.springer.com/article/10.1186/s40537-021-00467-1",
            "Abstract": "Social media platforms have become fundamental tools for sharing information during natural disasters or catastrophic events. This paper presents SEDOM-DD (Sub-Events Detection on sOcial Media During Disasters), a new method that analyzes user posts to discover sub-events that occurred after a disaster (e.g., collapsed buildings, broken gas pipes, floods). SEDOM-DD has been evaluated with datasets of different sizes that contain real posts from social media related to different natural disasters (e.g., earthquakes, floods and hurricanes). Starting from such data, we generated synthetic datasets with different features, such as different percentages of relevant posts and/or geotagged posts. Experiments performed on both real and synthetic datasets showed that SEDOM-DD is able to identify sub-events with high accuracy. For example, with a percentage of relevant posts of 80% and geotagged posts of 15 \u2026",
            "Abstract entirety": 0,
            "Author pub id": "qUBdmWgAAAAJ:7H_MAutzIkAC",
            "Publisher": "SpringerOpen"
        },
        {
            "Title": "Identifying news events that cause a shift in sentiment",
            "Publication year": 2013,
            "Publication url": "https://patents.google.com/patent/US20130290232A1/en",
            "Abstract": "A method identifies news events that cause shifts in sentiments. The method includes compiling a sentiment time series, the sentiment time series expressing a shift in sentiment; compiling a news events time series; correlating the sentiment and news events time series; identifying from the correlation news events that caused a shift in sentiment and predicting if a selected news event may cause a shift in sentiment in the future.",
            "Abstract entirety": 1,
            "Author pub id": "qUBdmWgAAAAJ:_B80troHkn4C",
            "Publisher": "Unknown"
        },
        {
            "Title": "The effect of history on modeling systems' performance: The problem of the demanding lord",
            "Publication year": 2010,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/5694043/",
            "Abstract": "In several concept attainment systems, ranging from recommendation systems to information filtering, a sliding window of learning instances has been used in the learning process to allow the learner to follow concepts that change over time. However, no analytic study has been performed on the relation between the size of the sliding window and the performance of a learning system. In this work, we present such an analytic model that describes the effect of the sliding window size on the prediction performance of a learning system based on iterative feedback. Using a signal-to-noise approach to model the learning ability of the underlying machine learning algorithms, we can provide good estimates of the average performance of a modeling system independently of the supervised machine learning algorithm employed. We experimentally validate the effectiveness of the proposed methodology with detailed \u2026",
            "Abstract entirety": 0,
            "Author pub id": "qUBdmWgAAAAJ:xtRiw3GOFMkC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Ranked join indices",
            "Publication year": 2003,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/1260799/",
            "Abstract": "A plethora of data sources contain data entities that could be ordered according to a variety of attributes associated with the entities. Such orderings result effectively in a ranking of the entities according to the values in the attribute domain. Commonly, users correlate such sources for query processing purposes through join operations. In query processing, it is desirable to incorporate user preferences towards specific attributes or their values. A way to incorporate such preferences is by utilizing scoring functions that combine user preferences and attribute values and return a numerical score for each tuple in the join result. Then, a target query, which we refer to as top-k join query, seeks to identify the k tuples in the join result with the highest scores. We propose a novel technique, which we refer to as ranked join index, to efficiently answer top-k join queries for arbitrary, user specified, preferences and a large class \u2026",
            "Abstract entirety": 0,
            "Author pub id": "qUBdmWgAAAAJ:UeHWp8X0CEIC",
            "Publisher": "IEEE"
        },
        {
            "Title": "System and method for model-driven dashboard for business performance management",
            "Publication year": 2014,
            "Publication url": "https://patents.google.com/patent/US8843883B2/en",
            "Abstract": "A system, method, and framework resulting therefrom, for a model-driven dashboard for business performance management, which includes capturing business dashboard model requirements at a business model level by providing at least one user-customizable model for capturing functionality of a dashboard, and after the user defines the functionality of the dashboard using the at least one user-customizable model, automatically generating code for a deployable dashboard application.",
            "Abstract entirety": 1,
            "Author pub id": "qUBdmWgAAAAJ:738O_yMBCRsC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Exemplar queries: a new way of searching",
            "Publication year": 2016,
            "Publication url": "https://link.springer.com/article/10.1007/s00778-016-0429-2",
            "Abstract": "Modern search engines employ advanced techniques that go beyond the structures that strictly satisfy the query conditions in an effort to better capture the user intentions. In this work, we introduce a novel query paradigm that considers a user query as an example of the data in which the user is interested. We call these queries exemplar queries. We provide a formal specification of their semantics and show that they are fundamentally different from notions like queries by example, approximate queries and related queries. We provide an implementation of these semantics for knowledge graphs and present an exact solution with a number of optimizations that improve performance without compromising the result quality. We study two different congruence relations, isomorphism and strong simulation, for identifying the answers to an exemplar query. We also provide an approximate solution that prunes the \u2026",
            "Abstract entirety": 0,
            "Author pub id": "qUBdmWgAAAAJ:L7CI7m0gUJcC",
            "Publisher": "Springer Berlin Heidelberg"
        },
        {
            "Title": "Maximizing the sustained throughput of distributed continuous queries",
            "Publication year": 2006,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/1183614.1183754",
            "Abstract": "Monitoring systems today often involve continuous queries over streaming data, in a distributed collaborative system. The distribution of query operators over a network of processors, and their processing sequence, form a query configuration with inherent constraints on the throughput it can support. In this paper we propose to optimize stream queries with respect to a version of throughput measure, the profiled input throughput. This measure is focused on matching the expected behavior of the input streams. To prune the search space we used hill-climbing techniques that proved to be efficient and effective.",
            "Abstract entirety": 1,
            "Author pub id": "qUBdmWgAAAAJ:EUQCXRtRnyEC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Big Sequence Management",
            "Publication year": 2020,
            "Publication url": "https://wwww.easychair.org/publications/preprint_download/zpvT",
            "Abstract": "Data series are a prevalent data type that has attracted lots of interest in recent years. Specifically, there has been an explosive interest towards the analysis of large volumes of data series in many different domains. This is both in businesses (eg, in mobile applications) and in sciences (eg, in biology). In this tutorial, we focus on applications that produce massive collections of data series, and we provide the necessary background on data series storage, retrieval and analytics. We look at systems historically used to handle and mine data in the form of data series, as well as at the state of the art data series management systems that were recently proposed. Moreover, we discuss the need for fast similarity search for supporting data mining applications, and describe efficient similarity search techniques, indexes and query processing algorithms. Finally, we look at the gap of modern data series management systems in regards to support for efficient complex analytics, and we argue in favor of the integration of summarizations and indexes in modern data series management systems. We conclude with the challenges and open research problems in this domain.",
            "Abstract entirety": 1,
            "Author pub id": "qUBdmWgAAAAJ:ubry08Y2EpUC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Data series management: Fulfilling the need for big sequence analytics",
            "Publication year": 2018,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/8509432/",
            "Abstract": "Massive data sequence collections exist in virtually every scientific and social domain, and have to be analyzed to extract useful knowledge. However, no existing data management solution (such as relational databases, column stores, array databases, and time series management systems) can offer native support for sequences and the corresponding operators necessary for complex analytics. We argue for the need to study the theory and foundations for sequence management of big data sequences, and to build corresponding systems that will enable scalable management and analysis of very large sequence collections. To this effect, we need to develop novel techniques to efficiently support a wide range of sequence queries and mining operations, while leveraging modern hardware. The overall goal is to allow analysts across domains to tap in the goldmine of the massive and ever-growing sequence \u2026",
            "Abstract entirety": 0,
            "Author pub id": "qUBdmWgAAAAJ:4hFrxpcac9AC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Coconut: sortable summarizations for scalable indexes over static and streaming data series",
            "Publication year": 2019,
            "Publication url": "https://link.springer.com/article/10.1007/s00778-019-00573-w",
            "Abstract": "Many modern applications produce massive streams of data series that need to be analyzed, requiring efficient similarity search operations. However, the state-of-the-art data series indexes that are used for this purpose do not scale well for massive datasets in terms of performance, or storage costs. We pinpoint the problem to the fact that existing summarizations of data series used for indexing cannot be sorted while keeping similar data series close to each other in the sorted order. To address this problem, we present Coconut, the first data series index based on sortable summarizations and the first efficient solution for indexing and querying streaming series. The first innovation in Coconut is an inverted, sortable data series summarization that organizes data series based on a z-order curve, keeping similar series close to each other in the sorted order. As a result, Coconut is able to use bulk loading and \u2026",
            "Abstract entirety": 0,
            "Author pub id": "qUBdmWgAAAAJ:5MTHONV0fEkC",
            "Publisher": "Springer Berlin Heidelberg"
        },
        {
            "Title": "Maximization of sustained throughput of distributed continuous queries",
            "Publication year": 2012,
            "Publication url": "https://patents.google.com/patent/US8122150B2/en",
            "Abstract": "A system, method, and computer readable medium for optimizing throughput of a stream processing system are disclosed. The method comprises analyzing a set of input streams and creating, based on the analyzing, an input profile for at least one input stream in the set of input streams. The input profile comprises at least a set of processing requirements associated with the input stream. The method also comprises generating a search space, based on an initial configuration, comprising a plurality of configurations associated with the input stream. A configuration in the plurality of configurations is identified that increases throughput more than the other configurations in the plurality of configurations based on at least one of the input profile and system resources.",
            "Abstract entirety": 1,
            "Author pub id": "qUBdmWgAAAAJ:pyW8ca7W8N0C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Linguistic rough sets",
            "Publication year": 2016,
            "Publication url": "https://link.springer.com/article/10.1007/s13042-014-0297-2",
            "Abstract": "We introduce linguistic rough set (LRS) by integrating linguistic quantifiers in the rough set framework. The proposed LRS is inspired by the ways in which humans process imprecise information. It operates directly with the linguistic summaries and caters to imprecision implicit in the real world with partial knowledge. The measures of LRS are developed and its properties are investigated in detail. An approach is proposed for approximation of fuzzy concepts with the proposed LRS. This approach is applied in a real world case-study on the credit scoring analysis problem.",
            "Abstract entirety": 1,
            "Author pub id": "qUBdmWgAAAAJ:k8Z6L05lTy4C",
            "Publisher": "Springer Berlin Heidelberg"
        },
        {
            "Title": "Big Sequence Management: Scaling up and Out.",
            "Publication year": 2021,
            "Publication url": "http://helios.mi.parisdescartes.fr/~themisp/publications/edbt21-BigSequenceManagement-summary.pdf",
            "Abstract": "Data series are a prevalent data type that has attracted lots of interest in recent years. Specifically, there has been an explosive interest towards the analysis of large volumes of data series in many different domains. This is both in businesses (eg, in mobile applications) and in sciences (eg, in biology). In this tutorial, we focus on applications that produce massive collections of data series, and we provide the necessary background on data series storage, retrieval and analytics. We look at systems historically used to handle and mine data in the form of data series, as well as at the state of the art data series management systems that were recently proposed. Moreover, we discuss the need for fast similarity search for supporting data mining applications, and describe efficient similarity search techniques, indexes and query processing algorithms. Finally, we look at the gap of modern data series management systems in regards to support for efficient complex analytics, and we argue in favor of the integration of summarizations and indexes in modern data series management systems. We conclude with the challenges and open research problems in this domain.",
            "Abstract entirety": 1,
            "Author pub id": "qUBdmWgAAAAJ:1taIhTC69MYC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Scalable data series subsequence matching with ULISSE",
            "Publication year": 2020,
            "Publication url": "https://link.springer.com/article/10.1007/s00778-020-00619-4",
            "Abstract": "Data series similarity search is an important operation, and at the core of several analysis tasks and applications related to data series collections. Despite the fact that data series indexes enable fast similarity search, all existing indexes can only answer queries of a single length (fixed at index construction time), which is a severe limitation. In this work, we propose ULISSE, the first data series index structure designed for answering similarity search queries of variable length (within some range). Our contribution is twofold. First, we introduce a novel representation technique, which effectively and succinctly summarizes multiple sequences of different length. Based on the proposed index, we describe efficient algorithms for approximate and exact similarity search, combining disk-based index visits and in-memory sequential scans. Our approach supports non-Z-normalized and Z-normalized sequences and can \u2026",
            "Abstract entirety": 0,
            "Author pub id": "qUBdmWgAAAAJ:U4n9YNQMCAIC",
            "Publisher": "Springer Berlin Heidelberg"
        },
        {
            "Title": "Monitoring and diagnosing indicators for business analytics",
            "Publication year": 2013,
            "Publication url": "https://zoumpatianos.com/papers/cascon13.pdf",
            "Abstract": "Modeling the strategic objectives has been shown to be useful both for understanding a business as well as planning and guiding the overall activities within an enterprise. Business strategy is modeled according to human expertise, setting up the goals as well as the indicators that monitor activities and goals. However, usually indicators provide highlevel aggregated views of data, making it difficult to pinpoint problems within specific sub-areas until they have a significant impact into the aggregated value. By the time these problems become evident, they have already hindered the performance of the organization. However, performing a detailed analysis manually can be a daunting task, due to the size of the data space. In order to solve this problem, we propose a user-driven method to analyze the data related to each business indicator by means of data mining. We illustrate our approach with a real world example based on the Europe 2020 framework. Our approach allows us not only to identify latent problems, but also to highlight deviations from anticipated trends that may represent opportunities and exceptional situations, thereby enabling",
            "Abstract entirety": 1,
            "Author pub id": "qUBdmWgAAAAJ:AXPGKjj_ei8C",
            "Publisher": "Unknown"
        },
        {
            "Title": "SCALABLE DISCOVERY OF CONTRADICTING OPINIONS IN",
            "Publication year": 2009,
            "Publication url": "https://scholar.google.com/scholar?cluster=7289721114760345587&hl=en&oi=scholarr",
            "Abstract": "are a popular means of information com-munication, where people discuss a variety of topics, and often times also express their opinions on these topics. In this work, we address the problem of analyzing the evolution of community opinions across time, as these are represented in the weblogs. In particular, we are interested in identifying topics and time windows, for which contradictory opinions have been expressed. We describe an approach for solving the above problem, which consists of the following steps. We first introduce a technique for topic and opinion extraction that operates at the sentence level. Then, we propose a novel measure for contradictions that can effectively aggregate the relevant information from the weblog posts. We discuss its properties, and show how it can be used to detect two different types of contradictions, namely, simultaneous contradictions, and change of sentiment.",
            "Abstract entirety": 1,
            "Author pub id": "qUBdmWgAAAAJ:kw52XkFRtyQC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Improving Classification Quality in Uncertain Graphs",
            "Publication year": 2019,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/3242095",
            "Abstract": "In many real applications that use and analyze networked data, the links in the network graph may be erroneous or derived from probabilistic techniques. In such cases, the node classification problem can be challenging, since the unreliability of the links may affect the final results of the classification process. If the information about link reliability is not used explicitly, then the classification accuracy in the underlying network may be affected adversely. In this article, we focus on situations that require the analysis of the uncertainty that is present in the graph structure. We study the novel problem of node classification in uncertain graphs, by treating uncertainty as a first-class citizen. We propose two techniques based on a Bayes model and automatic parameter selection and show that the incorporation of uncertainty in the classification process as a first-class citizen is beneficial. We experimentally evaluate the \u2026",
            "Abstract entirety": 0,
            "Author pub id": "qUBdmWgAAAAJ:mNrWkgRL2YcC",
            "Publisher": "ACM"
        },
        {
            "Title": "Scalable discovery of contradictions on the web",
            "Publication year": 2010,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/1772690.1772871",
            "Abstract": "Our study addresses the problem of large-scale contradiction detection and management, from data extracted from the Web. We describe the first systematic solution to the problem, based on a novel statistical measure for contradictions, which exploits first-and second-order moments of sentiments. Our approach enables the interactive analysis and online identification of contradictions under multiple levels of time granularity. The proposed algorithm can be used to analyze and track opinion evolution over time and to identify interesting trends and patterns. It uses an incrementally updatable data structure to achieve computational efficiency and scalability. Experiments with real datasets show promising time performance and accuracy.",
            "Abstract entirety": 1,
            "Author pub id": "qUBdmWgAAAAJ:NMxIlDl6LWMC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Fine-grained geolocalisation of non-geotagged tweets",
            "Publication year": 2015,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/2808797.2808869",
            "Abstract": "The rise in the use of social networks in the recent years has resulted in an abundance of information on different aspects of everyday social activities that is available online, with the most prominent and timely source of such information being Twitter. This has resulted in a proliferation of tools and applications that can help end-users and large-scale event organizers to better plan and manage their activities. In this process of analysis of the information originating from social networks, an important aspect is that of the geographic coordinates, ie, geolocalisation, of the relevant information, which is necessary for several applications (eg, on trending venues, traffic jams, etc.). Unfortunately, only a very small percentage of the twitter posts are geotagged, which significantly restricts the applicability and utility of such applications. In this work, we address this problem by proposing a framework for geolocating tweets that \u2026",
            "Abstract entirety": 0,
            "Author pub id": "qUBdmWgAAAAJ:vDijr-p_gm4C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Comparing time series similarity perception under different color interpolations",
            "Publication year": 2018,
            "Publication url": "https://hal.inria.fr/hal-01844994/",
            "Abstract": "In previous work [1] we compared three time series visualization techniques (colorfields, horizon graphs, and line charts) in small multiples [2], in order to determine if the time series results returned from automatic similarity measures are perceived in a similar manner, irrespective of the visualization technique. Our results indicated that the notion of similarity is visualization dependent. In that first study, our colorfields implementation used a naive RGB color interpolation between red and blue hues. In this research report we describe a follow-up experiment, comparing this simple RGB interpolation to one that is perceptually uniform (CIE L*a*b*), in order to understand if the choice of color interpolation plays a role in the perception of similarity.",
            "Abstract entirety": 1,
            "Author pub id": "qUBdmWgAAAAJ:dBIO0h50nwkC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Space constrained selection problems for data warehouses and pervasive computing",
            "Publication year": 2003,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/1214954/",
            "Abstract": "Space constrained optimization problems arise in a multitude of important applications such as data warehouses and pervasive computing. A typical instance of such problems is to select a set of items of interest, subject to a constraint on the total space occupied by these items. Assuming that each item is associated with a benefit, for a suitably defined notion of benefit, one wishes to optimize the total benefit for the selected items. We show that in many important applications, one faces variants of this basic problem in which the individual items are sets themselves, and each set is associated with a benefit value. We present instances of such problems in the context of data warehouse management and pervasive computing, derive their complexity, and propose several techniques for solving them. Since there are no known approximation algorithms for these problems, we explore the use of greedy and randomized \u2026",
            "Abstract entirety": 0,
            "Author pub id": "qUBdmWgAAAAJ:f2IySw72cVMC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Data series similarity using correlation-aware measures",
            "Publication year": 2017,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/3085504.3085515",
            "Abstract": "The increased availability of unprecedented amounts of sequential data (generated by Internet-of-Things, as well as scientific applications) has led in the past few years to a renewed interest and attention to the field of data series processing and analysis. Data series collections are processed and analyzed using a large variety of techniques, most of which are based on the computation of some distance function. In this study, we revisit this basic operation of data series distance calculation. We observe that the popular distance measures are oblivious to the correlations inherent in neighboring values in a data series. Therefore, we evaluate the plausibility and benefit of incorporating into the distance function measures of correlation, which enable us to capture the associations among neighboring values in the sequence. We propose four such measures, inspired by statistical and probabilistic approaches, which can \u2026",
            "Abstract entirety": 0,
            "Author pub id": "qUBdmWgAAAAJ:xtoqd-5pKcoC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Series2graph: Graph-based subsequence anomaly detection for time series",
            "Publication year": 2020,
            "Publication url": "https://dl.acm.org/doi/abs/10.14778/3407790.3407792",
            "Abstract": "Subsequence anomaly detection in long sequences is an important problem with applications in a wide range of domains. However, the approaches that have been proposed so far in the literature have severe limitations: they either require prior domain knowledge that is used to design the anomaly discovery algorithms, or become cumbersome and expensive to use in situations with recurrent anomalies of the same type. In this work, we address these problems, and propose an unsupervised method suitable for domain agnostic subsequence anomaly detection. Our method, Series2Graph, is based on a graph representation of a novel low-dimensionality embedding of subsequences. Series2Graph needs neither labeled instances (like supervised techniques), nor anomaly-free data (like zero-positive learning techniques), and identifies anomalies of varying lengths. The experimental results, on the largest set of \u2026",
            "Abstract entirety": 0,
            "Author pub id": "qUBdmWgAAAAJ:48xauSegjOkC",
            "Publisher": "VLDB Endowment"
        },
        {
            "Title": "Beyond one billion time series: indexing and mining very large time series collections with  SAX2+",
            "Publication year": 2014,
            "Publication url": "https://link.springer.com/article/10.1007/s10115-012-0606-6",
            "Abstract": "There is an increasingly pressing need, by several applications in diverse domains, for developing techniques able to index and mine very large collections of time series. Examples of such applications come from astronomy, biology, the web, and other domains. It is not unusual for these applications to involve numbers of time series in the order of hundreds of millions to billions. However, all relevant techniques that have been proposed in the literature so far have not considered any data collections much larger than one-million time series. In this paper, we describe SAX 2.0 and its improvements, SAX 2.0 Clustered and SAX2+, three methods designed for indexing and mining truly massive collections of time series. We show that the main bottleneck in mining such massive datasets is the time taken to build the index, and we thus introduce a novel bulk loading mechanism, the first of this kind \u2026",
            "Abstract entirety": 0,
            "Author pub id": "qUBdmWgAAAAJ:kRWSkSYxWN8C",
            "Publisher": "Springer London"
        },
        {
            "Title": "Determination of health status of systems equipped with sensors",
            "Publication year": 2021,
            "Publication url": "https://patents.google.com/patent/US20210321956A1/en",
            "Abstract": "A method for determining a health status of a system of interest is proposed. The method comprises acquiring (S1) a time series, extracting (S2) subsequences, selecting (S3) a set of subsequences, classifying (S4) the subsequences of the set into several groups on the basis of at least one criterion of resemblance to at least one reference subsequence, and constructing (S5) a normal operating model of the system of interest. The construction includes, for each group, a modeling (S51) of a representative subsequence and a determination (S52) of an associated weight. The normal model is defined by the modeled subsequences and the associated weights. The method further includes an attribution (S6) of a normality score to each subsequence extracted by comparison with the normal model, an identification (S7) of at least one abnormal subsequence, and a determination (S8) of the health status of the system of \u2026",
            "Abstract entirety": 0,
            "Author pub id": "qUBdmWgAAAAJ:3NQIlFlcGxIC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Entity lifecycle management for okkam",
            "Publication year": 2008,
            "Publication url": "http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.143.803",
            "Abstract": "In this paper, we examine the special requirements of lifecycle management for entities in the context of an entity management system for the semantic web. We study the requirements with respect to creating and modifying these entities, as well as to managing their evolution over time. Furthermore, we present the issues arising from the access control models needed for the management of a large, distributed repository of entities. Finally, we discuss the research directions that can offer solutions to the above problems, and give a brief overview of techniques and methods relevant to these solution directions.",
            "Abstract entirety": 1,
            "Author pub id": "qUBdmWgAAAAJ:J-pR_7NvFogC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Node classification in uncertain graphs",
            "Publication year": 2014,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/2618243.2618277",
            "Abstract": "In many real applications that use and analyze networked data, the links in the network graph may be erroneous, or derived from probabilistic techniques. In such cases, the node classification problem can be challenging, since the unreliability of the links may affect the final results of the classification process. In this paper, we focus on situations that require the analysis of the uncertainty that is present in the graph structure. We study the novel problem of node classification in uncertain graphs, by treating uncertainty as a first-class citizen. We propose two techniques based on a Bayes model, and show the benefits of incorporating uncertainty in the classification process as a first-class citizen. The experimental results demonstrate the effectiveness of our approaches.",
            "Abstract entirety": 1,
            "Author pub id": "qUBdmWgAAAAJ:LjlpjdlvIbIC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Identification and characterization of human behavior patterns from mobile phone data",
            "Publication year": 2013,
            "Publication url": "https://helios.mi.parisdescartes.fr/~themisp/publications/netmob13.pdf",
            "Abstract": "The availability of datasets coming from the telecommunications industry, and specifically those relevant to the use of mobile phones, are helping to conduct studies on the patterns that appear at large scales, and to better understand social behaviors. This study aims at developing methods for enabling the extraction and characterization of normal behavior patterns, and the identification of exceptional, or divergent behaviors. We study call activity and mobility patterns to classify the observed behaviors that exhibit similar characteristics, and we analyze and characterize the anomalous behaviors. Moreover, we link the identified behaviors to important events (eg, national and religious holidays) that took place in the same time period, and examine the interplay between the behaviors we observe and the nature of these events. The results of our work could be used for early identification of exceptional situations, monitoring the effects of important events in large areas, urban and transportation planning, and others.",
            "Abstract entirety": 1,
            "Author pub id": "qUBdmWgAAAAJ:bnK-pcrLprsC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Event Processing Architectures leading to a EPTS Reference Architecture",
            "Publication year": 2010,
            "Publication url": "https://www.academia.edu/download/46131538/Architectural_and_functional_design_patt20160601-25070-2h7rcb.pdf",
            "Abstract": "We introduce a reference architecture for event processing, as defined by the EPTS reference architecture (RA) working group. An event processing reference architecture allows users to quickly create event processing solutions that adhere to known stakeholder requirements and architectural qualities, such as performance, scalability, and application coverage. The common EPTS reference architecture description is supported by the contributed event processing\" architectures\" from EPTS working group members, including multiple vendors and researchers.",
            "Abstract entirety": 1,
            "Author pub id": "qUBdmWgAAAAJ:Fu2w8maKXqMC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Scalable detection of sentiment-based contradictions",
            "Publication year": 2011,
            "Publication url": "https://www.academia.edu/download/30915142/DiversiWebproceedings.pdf#page=14",
            "Abstract": "The analysis of user opinions expressed on the Web is becoming increasingly relevant to a variety of applications. It allows us to track the evolution of opinions or discussions in the blogosphere, or perform product surveys. The aggregation of sentiments and analysis of contradictions is another important application, which becomes effective since we are able to capture the diversity in sentiments on different topics with more precision and on a large scale. Though, there is still a need for a scalable way of sentiment aggregation with respect to the time dimension, which preserves enough information to capture contradictions.In this paper, we are focusing on the problem of finding sentimentbased contradictions at a large scale. First, we define two types of contradictions, depending on the distributions of opposite sentiments over time. Second, we introduce a novel measure of contradiction based on the mean value and the variance of sentiments among different texts. Third, we propose a scalable method for identifying both types of contradictions at different time scales. We evaluate the performance of our method using synthetic and realworld datasets, as well as a user-study. The experiments demonstrate the effectiveness of the proposed method in capturing contradictions in a scalable manner.",
            "Abstract entirety": 1,
            "Author pub id": "qUBdmWgAAAAJ:lSLTfruPkqcC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Big sequence management: A glimpse of the past, the present, and the future",
            "Publication year": 2016,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-662-49192-8_6",
            "Abstract": "There is an increasingly pressing need, by several applications in diverse domains, for developing techniques able to index and mine very large collections of sequences, or data series. Examples of such applications come from biology, astronomy, entomology, the web, and other domains. It is not unusual for these applications to involve numbers of data series in the order of hundreds of millions to billions, which are often times not analyzed in their full detail due to their sheer size. In this work, we describe recent efforts in designing techniques for indexing and mining truly massive collections of data series that will enable scientists to easily analyze their data. We show that the main bottleneck in mining such massive datasets is the time taken to build the index, and we thus introduce solutions to this problem. Furthermore, we discuss novel techniques that adaptively create data series indexes, allowing \u2026",
            "Abstract entirety": 0,
            "Author pub id": "qUBdmWgAAAAJ:BUYA1_V_uYcC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "Progressive data science: Potential and challenges",
            "Publication year": 2018,
            "Publication url": "https://arxiv.org/abs/1812.08032",
            "Abstract": "Data science requires time-consuming iterative manual activities. In particular, activities such as data selection, preprocessing, transformation, and mining, highly depend on iterative trial-and-error processes that could be sped-up significantly by providing quick feedback on the impact of changes. The idea of progressive data science is to compute the results of changes in a progressive manner, returning a first approximation of results quickly and allow iterative refinements until converging to a final result. Enabling the user to interact with the intermediate results allows an early detection of erroneous or suboptimal choices, the guided definition of modifications to the pipeline and their quick assessment. In this paper, we discuss the progressiveness challenges arising in different steps of the data science pipeline. We describe how changes in each step of the pipeline impact the subsequent steps and outline why progressive data science will help to make the process more effective. Computing progressive approximations of outcomes resulting from changes creates numerous research challenges, especially if the changes are made in the early steps of the pipeline. We discuss these challenges and outline first steps towards progressiveness, which, we argue, will ultimately help to significantly speed-up the overall data science process.",
            "Abstract entirety": 1,
            "Author pub id": "qUBdmWgAAAAJ:ODE9OILHJdcC",
            "Publisher": "Unknown"
        },
        {
            "Title": "SentiQ: A Probabilistic Logic Approach to Enhance Sentiment Analysis Tool Quality",
            "Publication year": 2020,
            "Publication url": "https://arxiv.org/abs/2008.08919",
            "Abstract": "The opinion expressed in various Web sites and social-media is an essential contributor to the decision making process of several organizations. Existing sentiment analysis tools aim to extract the polarity (i.e., positive, negative, neutral) from these opinionated contents. Despite the advance of the research in the field, sentiment analysis tools give \\textit{inconsistent} polarities, which is harmful to business decisions. In this paper, we propose SentiQ, an unsupervised Markov logic Network-based approach that injects the semantic dimension in the tools through rules. It allows to detect and solve inconsistencies and then improves the overall accuracy of the tools. Preliminary experimental results demonstrate the usefulness of SentiQ.",
            "Abstract entirety": 1,
            "Author pub id": "qUBdmWgAAAAJ:cK4Rrx0J3m0C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Using datacube aggregates for approximate querying and deviation detection",
            "Publication year": 2005,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/1512033/",
            "Abstract": "Much research has been devoted to the efficient computation of relational aggregations and, specifically, the efficient execution of the datacube operation. In this paper, we consider the inverse problem, that of deriving (approximately) the original data from the aggregates. We motivate this problem in the context of two specific application areas, approximate query answering and data analysis. We propose a framework based on the notion of information entropy that enables us to estimate the original values in a data set, given only aggregated information about it. We then show how approximate queries on the data from which the aggregates were derived can be performed using our framework. We also describe an alternate use of the proposed framework that enables us to identify values that deviate from the underlying data distribution, suitable for data mining purposes. We present a detailed performance study of \u2026",
            "Abstract entirety": 0,
            "Author pub id": "qUBdmWgAAAAJ:iH-uZ7U-co4C",
            "Publisher": "IEEE"
        },
        {
            "Title": "Twindex fuorisalone: Social listening of milano during fuorisalone 2013",
            "Publication year": 2013,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-642-41242-4_59",
            "Abstract": "Fuorisalone during Milano Design Week, with almost three thousands events spread around more than six hundreds venues, attracts half a million visitors: what do they say and feel about those events? Twindex Fuorisalone is a mash-up that listens what all those visitors posted on Twitter and Instragram in that week. In this paper, we briefly report on how Twindex Fuorisalone works and on its ability to listen in real-time the pulse of Fuorisalone on social media.",
            "Abstract entirety": 1,
            "Author pub id": "qUBdmWgAAAAJ:t6usbXjVLHcC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "Progressive similarity search on time series data",
            "Publication year": 2019,
            "Publication url": "https://hal.inria.fr/hal-02103998/",
            "Abstract": "Time series data are increasing at a dramatic rate, yet their analysis remains highly relevant in a wide range of human activities. Due to their volume, existing systems dealing with time series data cannot guarantee interactive response times, even for fundamental tasks such as similarity search. Therefore , in this paper, we present our vision to develop analytic approaches that support exploration and decision making by providing progressive results, before the final and exact ones have been computed. We demonstrate through experiments that providing first approximate and then progressive answers is useful (and necessary) for similarity search queries on very large time series data. Our findings indicate that there is a gap between the time the most similar answer is found and the time when the search algorithm terminates, resulting in inflated waiting times without any improvement. We present preliminary ideas on computing probabilistic estimates of the final results that could help users decide when to stop the search process, i.e., deciding when improvement in the final answer is unlikely, thus eliminating waiting time. Finally, we discuss two additional challenges: how to compute efficiently these probabilistic estimates, and how to communicate them to users.",
            "Abstract entirety": 1,
            "Author pub id": "qUBdmWgAAAAJ:OP4eGU-M3BUC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Deep Learning Embeddings for Data Series Similarity Search",
            "Publication year": 2021,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/3447548.3467317",
            "Abstract": "A key operation for the (increasingly large) data series collection analysis is similarity search. According to recent studies, SAX-based indexes offer state-of-the-art performance for similarity search tasks. However, their performance lags under high-frequency, weakly correlated, excessively noisy, or other dataset-specific properties. In this work, we propose Deep Embedding Approximation (DEA), a novel family of data series summarization techniques based on deep neural networks. Moreover, we describe SEAnet, a novel architecture especially designed for learning DEA, that introduces the Sum of Squares preservation property into the deep network design. Finally, we propose a new sampling strategy, SEASam, that allows SEAnet to effectively train on massive datasets. Comprehensive experiments on 7 diverse synthetic and real datasets verify the advantages of DEA learned using SEAnet, when compared to \u2026",
            "Abstract entirety": 0,
            "Author pub id": "qUBdmWgAAAAJ:prdVHNxh-e8C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Scalable similarity matching in streaming time series",
            "Publication year": 2012,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-642-30220-6_19",
            "Abstract": "Nowadays online monitoring of data streams is essential in many real life applications, like sensor network monitoring, manufacturing process control, and video surveillance. One major problem in this area is the online identification of streaming sequences similar to a predefined set of pattern-sequences.In this paper, we present a novel solution that extends the state of the art both in terms of effectiveness and efficiency. We propose the first online similarity matching algorithm based on Longest Common SubSequence that is specifically designed to operate in a streaming context, and that can effectively handle time scaling, as well as noisy data. In order to deal with high stream rates and multiple streams, we extend the algorithm to operate on multilevel approximations of the streaming data, therefore quickly pruning the search space. Finally, we incorporate in our approach error estimation \u2026",
            "Abstract entirety": 0,
            "Author pub id": "qUBdmWgAAAAJ:K3LRdlH-MEoC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "Scalable machine learning on high-dimensional vectors: From data series to deep network embeddings",
            "Publication year": 2020,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/3405962.3405989",
            "Abstract": "There is an increasingly pressing need, by several applications in diverse domains, for developing techniques able to analyze very large collections of static and streaming sequences (aka data series), predominantly in real-time. Examples of such applications come from Internet of Things installations, neuroscience, astrophysics, and a multitude of other scientific and application domains that need to apply machine learning techniques for knowledge extraction. It is not unusual for these applications, for which similarity search is a core operation, to involve numbers of data series in the order of hundreds of millions to billions, which are seldom analyzed in their full detail due to their sheer size. Such application requirements have driven the development of novel similarity search methods that can facilitate scalable analytics in this context. At the same time, a host of other methods have been developed for similarity \u2026",
            "Abstract entirety": 0,
            "Author pub id": "qUBdmWgAAAAJ:zCSUwVk65WsC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Query workloads for data series indexes",
            "Publication year": 2015,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/2783258.2783382",
            "Abstract": "Data series are a prevalent data type that has attracted lots of interest in recent years. Most of the research has focused on how to efficiently support similarity or nearest neighbor queries over large data series collections (an important data mining task), and several data series summarization and indexing methods have been proposed in order to solve this problem. Nevertheless, up to this point very little attention has been paid to properly evaluating such index structures, with most previous work relying solely on randomly selected data series to use as queries (with/without adding noise). In this work, we show that random workloads are inherently not suitable for the task at hand and we argue that there is a need for carefully generating a query workload. We define measures that capture the characteristics of queries, and we propose a method for generating workloads with the desired properties, that is, effectively \u2026",
            "Abstract entirety": 0,
            "Author pub id": "qUBdmWgAAAAJ:epqYDVWIO7EC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Semantic Challenges for the Variety and Velocity Dimensions of Big Data",
            "Publication year": 2016,
            "Publication url": "https://www.igi-global.com/pdf.aspx?tid%3D164479%26ptid%3D131668%26ctid%3D15%26t%3Dsemantic+challenges+for+the+variety+and+velocity+dimensions+of+big+data",
            "Abstract": "With the increasing use of sensor devices, machine-to-machine communications, and social networks there are large volumes of real world data that are multi-modal, dynamic and heterogeneous. Among the main challenges of the Internet of Things, Social Media Analytics and their blending in Cyber-Social-Physical Systems is how to deal with large volumes of sensory and social data, and how to extract actionable information.",
            "Abstract entirety": 1,
            "Author pub id": "qUBdmWgAAAAJ:VaXvl8Fpj5cC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Transactions on Large-Scale Data-and Knowledge-Centered Systems I",
            "Publication year": 2009,
            "Publication url": "https://link.springer.com/content/pdf/10.1007/978-3-642-03722-1.pdf",
            "Abstract": "Data management, knowledge discovery, and knowledge processing are core and hot topics in computer science. They are widely accepted as enabling technologies for modern enterprises, enhancing their performance and their decision making processes. Since the 1990s the Internet has been the outstanding driving force for application development in all domains.An increase in the demand for resource sharing (eg, computing resources, services, metadata, data sources) across different sites connected through networks has led to an evolvement of data-and knowledge-management systems from centralized systems to decentralized systems enabling large-scale distributed applications providing high scalability. Current decentralized systems still focus on data and knowledge as their main resource characterized by:",
            "Abstract entirety": 1,
            "Author pub id": "qUBdmWgAAAAJ:foquWX3nUaYC",
            "Publisher": "Springer Berlin Heidelberg"
        },
        {
            "Title": "Tasm: Top-k approximate subtree matching",
            "Publication year": 2010,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/5447905/",
            "Abstract": "We consider the Top-k Approximate Subtree Matching (TASM) problem: finding the k best matches of a small query tree, e.g., a DBLP article with 15 nodes, in a large document tree, e.g., DBLP with 26M nodes, using the canonical tree edit distance as a similarity measure between subtrees. Evaluating the tree edit distance for large XML trees is difficult: the best known algorithms have cubic runtime and quadratic space complexity, and, thus, do not scale. Our solution is TASM-postorder, a memory-efficient and scalable TASM algorithm. We prove an upper-bound for the maximum subtree size for which the tree edit distance needs to be evaluated. The upper bound depends on the query and is independent of the document size and structure. A core problem is to efficiently prune subtrees that are above this size threshold. We develop an algorithm based on the prefix ring buffer that allows us to prune all subtrees \u2026",
            "Abstract entirety": 0,
            "Author pub id": "qUBdmWgAAAAJ:M05iB0D1s5AC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Automated anomaly detection in large sequences",
            "Publication year": 2020,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/9101523/",
            "Abstract": "Subsequence anomaly (or outlier) detection in long sequences is an important problem with applications in a wide range of domains. However, current approaches have severe limitations: they either require prior domain knowledge, or become cumbersome and expensive to use in situations with recurrent anomalies of the same type. In this work, we address these problems, and propose NorM, a novel approach, suitable for domain-agnostic anomaly detection. NorM is based on a new data series primitive, which permits to detect anomalies based on their (dis)similarity to a model that represents normal behavior. The experimental results on several real datasets demonstrate that the proposed approach outperforms by a large margin the current state-of-the art algorithms in terms of accuracy, while being orders of magnitude faster.",
            "Abstract entirety": 1,
            "Author pub id": "qUBdmWgAAAAJ:uDGL6kOW6j0C",
            "Publisher": "IEEE"
        },
        {
            "Title": "Incremental maintenance for non-distributive aggregate functions",
            "Publication year": 2002,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/B9781558608696500767",
            "Abstract": "This chapter describes an efficient method for maintaining materialized views with non-distributive aggregate functions, even in the presence of super aggregates. Incremental view maintenance is an extremely important aspect of the modern database management systems. It enables the fast execution of complex queries without sacrificing the freshness of the data. However, the maintenance of views defined with non-distributive aggregate functions was not sufficiently explored. Incremental refresh has been studied in depth only for a subset of the aggregate functions. Materialized views, or automatic summary tables (ASTs), are increasingly being used to facilitate the analysis of the large amounts of data being collected in relational databases. The use of ASTs can significantly reduce the execution time of a query, often by orders of magnitude, which is particularly significant for databases with \u2026",
            "Abstract entirety": 0,
            "Author pub id": "qUBdmWgAAAAJ:j3f4tGmQtD8C",
            "Publisher": "Morgan Kaufmann"
        },
        {
            "Title": "Efficient rehabilitation of vergence accommodation in children: A case study",
            "Publication year": 2019,
            "Publication url": "http://helios.mi.parisdescartes.fr/~themisp/publications/hcsmc19.pdf",
            "Abstract": "Background: Disorders of binocular vision are frequently due to the vergence eye movement abnormalities and their synergy with accommodation. Nowadays, it isa public health problem, as it concerns many children, adolescents and young adults.Material: We report here a new efficient rehabilitation protocol (patent W02011073288, see Kapoula et al. 2016) applied for a 9 years old child and fourteen years old adolescent. This method called double step vergence protocol has been used previously exclusively for saccades. The double step vergence protocol was applied for vergence training, during four sessions of 15min, and vergence and accommodation were recorded before, during, and after the rehabilitation procedure.Results: After the rehabilitation, the latency of vergence decreased, the amplitude increased as well as its mean velocity increased. Importantly the accommodation taking place during the convergence and the desaccommodation during the divergence became significantly faster following training with the double step vergence protocol. Importantly, the benefits were spread to saccades and to both components of combined saccade eye movements.Conclusion: The study provides convincing evidence for fast vergence-accommodation neuroplasticity in both the child and the adolescent and supports further clinical research and use of this method.",
            "Abstract entirety": 1,
            "Author pub id": "qUBdmWgAAAAJ:nVrZBo8bIpAC",
            "Publisher": "Unknown"
        },
        {
            "Title": "On classifier behavior in the presence of mislabeling noise",
            "Publication year": 2017,
            "Publication url": "https://link.springer.com/article/10.1007/s10618-016-0484-8",
            "Abstract": "Machine learning algorithms perform differently in settings with varying levels of training set mislabeling noise. Therefore, the choice of the right algorithm for a particular learning problem is crucial. The contribution of this paper is towards two, dual problems: first, comparing algorithm behavior; and second, choosing learning algorithms for noisy settings. We present the \u201csigmoid rule\u201d framework, which can be used to choose the most appropriate learning algorithm depending on the properties of noise in a classification problem. The framework uses an existing model of the expected performance of learning algorithms as a sigmoid function of the signal-to-noise ratio in the training instances. We study the characteristics of the sigmoid function using five representative non-sequential classifiers, namely, Na\u00efve Bayes, kNN, SVM, a decision tree classifier, and a rule-based classifier, and three widely used \u2026",
            "Abstract entirety": 0,
            "Author pub id": "qUBdmWgAAAAJ:MLfJN-KU85MC",
            "Publisher": "Springer US"
        },
        {
            "Title": "New Weighting Schemes for Meta-blocking",
            "Publication year": 2021,
            "Publication url": "http://lipade.mi.parisdescartes.fr/wp-content/uploads/2021/10/LipadeTR-5.pdf",
            "Abstract": "Entity Resolution constitutes a core data integration task that relies on Blocking in order to tame its quadratic time complexity. Schema-agnostic blocking comes at the cost of many irrelevant candidate pairs (ie, comparisons), which can be significantly reduced with Meta-blocking. In Meta-blocking, a weighting scheme is first applied on every pair of candidate entities in proportion to the likelihood that they are matching, and a pruning algorithm then discards the pairs with the lowest scores.",
            "Abstract entirety": 1,
            "Author pub id": "qUBdmWgAAAAJ:Br1UauaknNIC",
            "Publisher": "Unknown"
        },
        {
            "Title": "A SOA-Driven Content Discovery and Retrieval Platform",
            "Publication year": 2008,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/4785101/",
            "Abstract": "Service-oriented architecture (SOA) has emerged as a promising paradigm for the inter-organizational sharing of domain-specific capabilities. Perhaps an equally important emergence is the use of SOA to manage the sharing of disparate information within a distributed environment. SOA provides a platform for organizations to enable the user-driven advertisement, discovery, and retrieval of data. A major shortcoming in the state-of-the-art is the lack of principled approaches for handling the sharing of large amounts of data within potentially resource-constrained environments while respecting the fundamental tenants of SOA. In this paper, we present several use cases where information sharing is paramount within a heterogeneous enterprise setting. Subsequently, we discuss a SOA-driven framework for realizing enterprise-wide data discovery and retrieval leveraging industry best practices and open standards.",
            "Abstract entirety": 1,
            "Author pub id": "qUBdmWgAAAAJ:bFI3QPDXJZMC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Indexation et interrogation de s\u00e9ries temporelles massivement distribu\u00e9es",
            "Publication year": 2018,
            "Publication url": "https://hal.inria.fr/hal-02563558/document#page=54",
            "Abstract": "L\u2019indexation est cruciale pour de nombreuses t\u00e2ches d\u2019analyse de donn\u00e9es qui reposent sur un traitement efficace des requ\u00eates de similitude. Par cons\u00e9quent, l\u2019indexation de grands volumes de s\u00e9ries temporelles, ainsi que le traitement des requ\u00eates de similitude \u00e0 haute performance, sont devenus des sujets d\u2019int\u00e9r\u00eat majeur. Pour de nombreuses applications dans divers domaines, la quantit\u00e9 de donn\u00e9es \u00e0 traiter peut cependant \u00eatre difficile \u00e0 traiter pour une seule machine, ce qui rend les solutions d\u2019indexation centralis\u00e9e existantes inefficaces. Nous proposons une solution d\u2019indexation parall\u00e8le qui s\u2019 adapte \u00e0 des milliards de s\u00e9ries temporelles (ou de vecteurs \u00e0 haute dimension, en g\u00e9n\u00e9ral), et une strat\u00e9gie de traitement des requ\u00eates parall\u00e8le qui exploite efficacement l\u2019index \u00e0 partir d\u2019un ensemble de requ\u00eates. Nos exp\u00e9riences, tant sur des donn\u00e9es synth\u00e9tiques que sur des donn\u00e9es du monde r\u00e9el, illustrent que notre algorithme de cr\u00e9ation d\u2019index fonctionne sur 4 milliards de s\u00e9ries temporelles en moins de 5 heures, alors que les algorithmes centralis\u00e9s de la litt\u00e9rature ne passent pas \u00e0 l\u2019\u00e9chelle et sont limit\u00e9s \u00e0 1 milliard de s\u00e9ries temporelles, pour lesquelles ils ont besoin de plus de 5 jours pour construire l\u2019index. De plus, notre algorithme d\u2019interrogation distribu\u00e9 est capable de traiter efficacement des millions de requ\u00eates sur des collections de milliards de s\u00e9ries temporelles, gr\u00e2ce \u00e0 un m\u00e9canisme efficace d\u2019\u00e9quilibrage de charge.",
            "Abstract entirety": 1,
            "Author pub id": "qUBdmWgAAAAJ:NyGDZy8z5eUC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Updating a data warehouse schema based on changes in an observation model",
            "Publication year": 2014,
            "Publication url": "https://patents.google.com/patent/US8671084B2/en",
            "Abstract": "A method, information processing system, and computer readable medium for modifying at least one data warehouse schema based on detected changes in an associated observation model are disclosed. The method includes determining if at least one new observation model has been created. The method also includes determining if at least one existing observation model is associated with the new observation model. In response to the existing observation model being associated with the new observation model, at least one changed attribute is identified by comparing the new observation model and the existing observation model. A set of files associated with the existing observation model is updated to reflect the changed attribute between the new observation model and the existing observation model.",
            "Abstract entirety": 1,
            "Author pub id": "qUBdmWgAAAAJ:a0OBvERweLwC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Indexing for interactive exploration of big data series",
            "Publication year": 2014,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/2588555.2610498",
            "Abstract": "Numerous applications continuously produce big amounts of data series, and in several time critical scenarios analysts need to be able to query these data as soon as they become available, which is not currently possible with the state-of-the-art indexing methods and for very large data series collections. In this paper, we present the first adaptive indexing mechanism, specifically tailored to solve the problem of indexing and querying very large data series collections. The main idea is that instead of building the complete index over the complete data set up-front and querying only later, we interactively and adaptively build parts of the index, only for the parts of the data on which the users pose queries. The net effect is that instead of waiting for extended periods of time for the index creation, users can immediately start exploring the data series. We present a detailed design and evaluation of adaptive data series \u2026",
            "Abstract entirety": 0,
            "Author pub id": "qUBdmWgAAAAJ:WqliGbK-hY8C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Ulisse: Ultra compact index for variable-length similarity search in data series",
            "Publication year": 2018,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/8509370/",
            "Abstract": "Data series similarity search is an important operation and at the core of several analysis tasks and applications related to data series collections. Despite the fact that data series indexes enable fast similarity search, all existing indexes can only answer queries of a single length (fixed at index construction time), which is a severe limitation. In this work, we propose ULISSE, the first data series index structure designed for answering similarity search queries of variable length. Our contribution is two-fold. First, we introduce a novel representation technique, which effectively and succinctly summarizes multiple sequences of different length. Based on the proposed index, we describe efficient algorithms for approximate and exact similarity search, combining disk based index visits and in-memory sequential scans. We experimentally evaluate our approach using several synthetic and real datasets. The results show that \u2026",
            "Abstract entirety": 0,
            "Author pub id": "qUBdmWgAAAAJ:NXb4pA-qfm4C",
            "Publisher": "IEEE"
        },
        {
            "Title": "Efficient sentiment correlation for large-scale demographics",
            "Publication year": 2013,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/2463676.2465317",
            "Abstract": "Analyzing sentiments of demographic groups is becoming important for the Social Web, where millions of users provide opinions on a wide variety of content. While several approaches exist for mining sentiments from product reviews or micro-blogs, little attention has been devoted to aggregating and comparing extracted sentiments for different demographic groups over time, such as' Students in Italy'or'Teenagers in Europe'. This problem demands efficient and scalable methods for sentiment aggregation and correlation, which account for the evolution of sentiment values, sentiment bias, and other factors associated with the special characteristics of web data. We propose a scalable approach for sentiment indexing and aggregation that works on multiple time granularities and uses incrementally updateable data structures for online operation. Furthermore, we describe efficient methods for computing meaningful \u2026",
            "Abstract entirety": 0,
            "Author pub id": "qUBdmWgAAAAJ:5ugPr518TE4C",
            "Publisher": "Unknown"
        },
        {
            "Title": "SentiQ: A Probabilistic Logic Approach to Enhance Sentiment Analysis Tool Quality",
            "Publication year": 2020,
            "Publication url": "https://ui.adsabs.harvard.edu/abs/2020arXiv200808919M/abstract",
            "Abstract": "The opinion expressed in various Web sites and social-media is an essential contributor to the decision making process of several organizations. Existing sentiment analysis tools aim to extract the polarity (ie, positive, negative, neutral) from these opinionated contents. Despite the advance of the research in the field, sentiment analysis tools give\\textit {inconsistent} polarities, which is harmful to business decisions. In this paper, we propose SentiQ, an unsupervised Markov logic Network-based approach that injects the semantic dimension in the tools through rules. It allows to detect and solve inconsistencies and then improves the overall accuracy of the tools. Preliminary experimental results demonstrate the usefulness of SentiQ.",
            "Abstract entirety": 1,
            "Author pub id": "qUBdmWgAAAAJ:kVjdVfd2voEC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Steel structure system",
            "Publication year": 2005,
            "Publication url": "https://patents.google.com/patent/US6874287B2/en",
            "Abstract": "The invention relates to a steel structural system for erecting stories of buildings, especially stories containing dwelling rooms, work rooms or rooms for accommodating household appliances where at least one floor structure (3) and ceiling structure (30) are provided, that each ceiling structure (30) serves as a floor structure (3) for another story, that load-bearing story supports (2) are arranged on the floor structure (3), and the ceiling structure (30) rests on these story supports, that an elastically sound-dampening joining system (4) is provided, which joins each of the story supports (2) with the floor structure (3), that the joining system (4) has a securing element (5), which is provided for laterally fixing the story support (2) to the floor structure (3), and is joined to the floor structure (3), that the joining system (4) exhibits a separating layer made out of flexible material with a high degree of resilience when deformed and a \u2026",
            "Abstract entirety": 0,
            "Author pub id": "qUBdmWgAAAAJ:5icHVeHT4IsC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Where has this tweet come from? fast and fine-grained geolocalization of non-geotagged tweets",
            "Publication year": 2016,
            "Publication url": "https://link.springer.com/article/10.1007/s13278-016-0400-7",
            "Abstract": "The rise in the use of social networks in the recent years has resulted in an abundance of information on different aspects of everyday social activities that is available online, with the most prominent and timely source of such information being Twitter. This has resulted in a proliferation of tools and applications that can help end users and large-scale event organizers to better plan and manage their activities. In this process of analysis of the information originating from social networks, an important aspect is that of the geographic coordinates, i.e., geolocalization, of the relevant information, which is necessary for several applications (e.g., on trending venues, traffic jams). Unfortunately, only a very small percentage of the twitter posts are geotagged, which significantly restricts the applicability and utility of such applications. In this work, we address this problem by proposing a framework for geolocating tweets \u2026",
            "Abstract entirety": 0,
            "Author pub id": "qUBdmWgAAAAJ:b1wdh0AR-JQC",
            "Publisher": "Springer Vienna"
        },
        {
            "Title": "Maximization of sustained throughput of distributed continuous queries",
            "Publication year": 2009,
            "Publication url": "https://patents.google.com/patent/US7496683B2/en",
            "Abstract": "A system, method, and computer readable medium for optimizing throughput of a stream processing system are disclosed. The method comprises analyzing a set of input streams and creating, based on the analyzing, an input profile for at least one input stream in the set of input streams. The input profile comprises at least a set of processing requirements associated with the input stream. The method also comprises generating a search space, based on an initial configuration, comprising a plurality of configurations associated with the input stream. A configuration in the plurality of configurations is identified that increases throughput more than the other configurations in the plurality of configurations based on at least one of the input profile and system resources.",
            "Abstract entirety": 1,
            "Author pub id": "qUBdmWgAAAAJ:IRz6iEL74y4C",
            "Publisher": "Unknown"
        },
        {
            "Title": "To compare or not to compare: making entity resolution more efficient",
            "Publication year": 2011,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/1999299.1999302",
            "Abstract": "Blocking methods are crucial for making the inherently quadratic task of Entity Resolution more efficient. The blocking methods proposed in the literature rely on the homogeneity of data and the availability of binding schema information; thus, they are inapplicable to the voluminous, noisy, and highly heterogeneous data of the Web 2.0 user-generated content. To deal with such data, attribute-agnostic blocking has been recently introduced, following a two-fold strategy: the first layer places entities into overlapping blocks in order to achieve high effectiveness, while the second layer reduces the number of unnecessary comparisons in order to enhance efficiency.",
            "Abstract entirety": 1,
            "Author pub id": "qUBdmWgAAAAJ:uWQEDVKXjbEC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Streaming time series summarization using user-defined amnesic functions",
            "Publication year": 2008,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/4407712/",
            "Abstract": "The past decade has seen a wealth of research on time series representations. The vast majority of research has concentrated on representations that are calculated in batch mode and represent each value with approximately equal fidelity. However, the increasing deployment of mobile devices and real time sensors has brought home the need for representations that can be incrementally updated, and can approximate the data with fidelity proportional to its age. The latter property allows us to answer queries about the recent past with greater precision, since in many domains recent information is more useful than older information. We call such representations amnesic. While there has been previous work on amnesic representations, the class of amnesic functions possible was dictated by the representation itself. In this work, we introduce a novel representation of time series that can represent arbitrary, user \u2026",
            "Abstract entirety": 0,
            "Author pub id": "qUBdmWgAAAAJ:maZDTaKrznsC",
            "Publisher": "IEEE"
        },
        {
            "Title": "SAD: an unsupervised system for subsequence anomaly detection",
            "Publication year": 2020,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/9101752/",
            "Abstract": "Subsequence anomaly (or outlier) detection in long sequences is an important problem with applications in a wide range of domains. However, current approaches have severe limitations: they either require prior domain knowledge, or become cumbersome and expensive to use in situations with recurrent anomalies of the same type. We recently proposed NorM, a novel approach suitable for domain-agnostic anomaly detection, which addresses the aforementioned problems by detecting anomalies based on their (dis)similarity to a model that represents normal behavior. The experimental results on several real datasets demonstrate that the proposed approach outperforms the current state-of-the art in terms of both accuracy and execution time. In this demonstration, we present a system for unsupervised Subsequence Anomaly Detection (SAD) that uses the NorM method. Through various scenarios with real \u2026",
            "Abstract entirety": 0,
            "Author pub id": "qUBdmWgAAAAJ:MpfHP-DdYjUC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Coconut palm: Static and streaming data series exploration now in your palm",
            "Publication year": 2019,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/3299869.3320233",
            "Abstract": "Many modern applications produce massive streams of data series and maintain them in indexes to be able to explore them through nearest neighbor search. Existing data series indexes, however, are expensive to operate as they issue many random I/Os to storage. To address this problem, we recently proposed Coconut, a new infrastructure that organizes data series based on a new sortable format. In this way, Coconut is able to leverage state-of-the-art indexing techniques that rely on sorting for the first time to build, maintain and query data series indexes using fast sequential I/Os. In this demonstration, we present Coconut Palm, a new exploration tool that allows to interactively combine different indexing techniques from within the Coconut infrastructure and to thereby seamlessly explore data series from across various scientific domains. We highlight the rich indexing design choices that Coconut opens up \u2026",
            "Abstract entirety": 0,
            "Author pub id": "qUBdmWgAAAAJ:nZcligLrVowC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Strategic management for real-time business intelligence",
            "Publication year": 2012,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-642-39872-8_9",
            "Abstract": "Even though much research has been devoted on real-time data warehousing, most of it ignores business concerns that underlie all uses of such data. The complete Business Intelligence (BI) problem begins with modeling and analysis of business objectives and specifications, followed by a systematic derivation of real-time BI queries on warehouse data. In this position paper, we motivate the need for the development of a complete Real Time BI stack able to continuously evaluate and reason about strategic objectives. We argue that an integrated system, able to receive formal specifications of the organization\u2019s strategic objectives and to transform them into a set of queries that are continuously evaluated against the warehouse, offers significant benefits. In this context, we propose the development of a set of real-time query answering mechanisms able to identify warehouse segments with temporal \u2026",
            "Abstract entirety": 0,
            "Author pub id": "qUBdmWgAAAAJ:fQNAKQ3IYiAC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "Entropy based approximate querying and exploration of datacubes",
            "Publication year": 2001,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/938541/",
            "Abstract": "Much research has been devoted to the efficient computation of relational aggregations and specifically the efficient execution of the datacube operation. We consider the inverse problem, that of deriving (approximately) the original data from the aggregates. We motivate this problem in the context of two specific application areas, that of approximate query answering and data analysis. We propose a framework based on the notion of information entropy that enables us to estimate the original values in a data set, given only aggregated information about it. We also describe an alternate utility of the proposed framework, that enables us to identify values that deviate from the underlying data distribution, suitable for data mining purposes. Finally, we present a detailed performance study of the algorithms using both real and synthetic data, highlighting the benefits of our approach as well as the efficiency of the proposed \u2026",
            "Abstract entirety": 0,
            "Author pub id": "qUBdmWgAAAAJ:TFP_iSt0sucC",
            "Publisher": "IEEE"
        },
        {
            "Title": "From web data to entities and back",
            "Publication year": 2010,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-642-13094-6_25",
            "Abstract": "We present the Entity Name System (ENS), an enabling infrastructure, which can host descriptions of named entities and provide unique identifiers, on large-scale. In this way, it opens new perspectives to realize entity-oriented, rather than keyword-oriented, Web information systems. We describe the architecture and the functionality of the ENS, along with tools, which all contribute to realize the Web of entities.",
            "Abstract entirety": 1,
            "Author pub id": "qUBdmWgAAAAJ:ldfaerwXgEUC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "Conditional heavy hitters: detecting interesting correlations in data streams",
            "Publication year": 2015,
            "Publication url": "https://link.springer.com/article/10.1007/s00778-015-0382-5",
            "Abstract": "The notion of heavy hitters\u2014items that make up a large fraction of the population\u2014has been successfully used in a variety of applications across sensor and RFID monitoring, network data analysis, event mining, and more. Yet this notion often fails to capture the semantics we desire when we observe data in the form of correlated pairs. Here, we are interested in items that are conditionally frequent: when a particular item is frequent within the context of its parent item. In this work, we introduce and formalize the notion of conditional heavy hitters to identify such items, with applications in network monitoring and Markov chain modeling. We explore the relationship between conditional heavy hitters and other related notions in the literature, and show analytically and experimentally the usefulness of our approach. We introduce several algorithm variations that allow us to efficiently find conditional heavy hitters \u2026",
            "Abstract entirety": 0,
            "Author pub id": "qUBdmWgAAAAJ:W5xh706n7nkC",
            "Publisher": "Springer Berlin Heidelberg"
        },
        {
            "Title": "Imitates",
            "Publication year": 2019,
            "Publication url": "https://hal.archives-ouvertes.fr/hal-02095640/",
            "Abstract": "Imitates is a complete solution for similarity search over very large time series datasets (Terabytes). It implements two efficient approaches for time series indexing and querying: DPiSAX and parSketch. DPiSAX is a parallel solution developed to construct iSAX-based index over billions of time series by making the most of the parallel environment by carefully distributing the work load. The other approach, i.e., parSketch, is based on sketches / random projections to efficiently perform both the parallel indexing of large sets of time series and a similarity search on them. Our solutions take advantage of the computing power of distributed systems by using the Spark parallel framework. The experiments illustrate the high performance of our index construction solution with an indexing time of less than 2 hours for more than 1 billion time series, while the baseline centralized algorithm needs more than 5 days.",
            "Abstract entirety": 1,
            "Author pub id": "qUBdmWgAAAAJ:P7Ujq4OLJYoC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Fast data series indexing for in-memory data",
            "Publication year": 2021,
            "Publication url": "https://link.springer.com/article/10.1007/s00778-021-00677-2",
            "Abstract": "Data series similarity search is a core operation for several data series analysis applications across many different domains. However, the state-of-the-art techniques fail to deliver the time performance required for interactive exploration, or analysis of large data series collections. In this work, we propose MESSI, the first data series index designed for in-memory operation on modern hardware. Our index takes advantage of the modern hardware parallelization opportunities (ie, SIMD instructions, multi-socket and multi-core architectures), in order to accelerate both index construction and similarity search processing times. Moreover, it benefits from a careful design in the setup and coordination of the parallel workers and data structures, so that it maximizes its performance for in-memory operations. MESSI supports similarity search using both the Euclidean and dynamic time warping (DTW) distances. Our experiments \u2026",
            "Abstract entirety": 0,
            "Author pub id": "qUBdmWgAAAAJ:owLR8QvbtFgC",
            "Publisher": "Springer Berlin Heidelberg"
        },
        {
            "Title": "Efficient Error-tolerant Search on Knowledge Graphs",
            "Publication year": 2016,
            "Publication url": "https://arxiv.org/abs/1609.03095",
            "Abstract": "Edge-labeled graphs are widely used to describe relationships between entities in a database. Given a query subgraph that represents an example of what the user is searching for, we study the problem of efficiently searching for similar subgraphs in a large data graph, where the similarity is defined in terms of the well-known graph edit distance. We call these queries \"error-tolerant exemplar queries\" since matches are allowed despite small variations in the graph structure and the labels. The problem in its general case is computationally intractable, but efficient solutions are reachable for labeled graphs under well-behaved distribution of the labels, commonly found in knowledge graphs. We propose two efficient exact algorithms, based on a filtering-and-verification framework, for finding subgraphs in a large data graph that are isomorphic to a query graph under some edit operations. Our filtering scheme, which uses the neighbourhood structure around a node and the presence or absence of paths, significantly reduces the number of candidates that are passed to the verification stage. Moreover, we analyze the costs of our algorithms and the conditions under which one algorithm is expected to outperform the other. Our analysis identifies some of the variables that affect the cost, including the number and the selectivity of query edge labels and the degree of nodes in the data graph, and characterizes their relationships. We empirically evaluate the effectiveness of our filtering schemes and queries, the efficiency of our algorithms and the reliability of our cost models on real datasets.",
            "Abstract entirety": 1,
            "Author pub id": "qUBdmWgAAAAJ:WJVC3Jt7v1AC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Messi: In-memory data series indexing",
            "Publication year": 2020,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/9101877/",
            "Abstract": "Data series similarity search is a core operation for several data series analysis applications across many different domains. However, the state-of-the-art techniques fail to deliver the time performance required for interactive exploration, or analysis of large data series collections. In this work, we propose MESSI, the first data series index designed for in-memory operation on modern hardware. Our index takes advantage of the modern hardware parallelization opportunities (i.e., SIMD instructions, multi-core and multi-socket architectures), in order to accelerate both index construction and similarity search processing times. Moreover, it benefits from a careful design in the setup and coordination of the parallel workers and data structures, so that it maximizes its performance for in-memory operations. Our experiments with synthetic and real datasets demonstrate that overall MESSI is up to 4\u00d7 faster at index \u2026",
            "Abstract entirety": 0,
            "Author pub id": "qUBdmWgAAAAJ:BJbdYPG6LGMC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Integrated model-driven dashboard development",
            "Publication year": 2007,
            "Publication url": "https://link.springer.com/content/pdf/10.1007/s10796-007-9032-9.pdf",
            "Abstract": "Business performance modeling and model-driven business transformation are two research directions that are attracting much attention lately. In this study, we propose an approach for dashboard development that is model-driven and can be integrated with the business performance models. We adopt the business performance modeling framework, and we extend it in order to capture the reporting aspect of the business operation. We describe models that can effectively represent all the elements necessary for the business performance reporting process, and the interactions among them. We demonstrate how all these models can be combined and automatically generate the final solution. We further extend the proposed framework with mechanisms that can detect changes in the models and incrementally update the deployed solutions. Finally, we discuss our experience from the application of our \u2026",
            "Abstract entirety": 0,
            "Author pub id": "qUBdmWgAAAAJ:blknAaTinKkC",
            "Publisher": "Kluwer Academic Publishers-Plenum Publishers"
        },
        {
            "Title": "Exemplar queries: Give me an example of what you need",
            "Publication year": 2014,
            "Publication url": "https://dl.acm.org/doi/abs/10.14778/2732269.2732273",
            "Abstract": "Search engines are continuously employing advanced techniques that aim to capture user intentions and provide results that go beyond the data that simply satisfy the query conditions. Examples include the personalized results, related searches, similarity search, popular and relaxed queries. In this work we introduce a novel query paradigm that considers a user query as an example of the data in which the user is interested. We call these queries exemplar queries and claim that they can play an important role in dealing with the information deluge. We provide a formal specification of the semantics of such queries and show that they are fundamentally different from notions like queries by example, approximate and related queries. We provide an implementation of these semantics for graph-based data and present an exact solution with a number of optimizations that improve performance without compromising \u2026",
            "Abstract entirety": 0,
            "Author pub id": "qUBdmWgAAAAJ:PELIpwtuRlgC",
            "Publisher": "VLDB Endowment"
        },
        {
            "Title": "Dagstuhl Reports, Vol. 9, Issue 7 ISSN 2192-5283",
            "Publication year": 2020,
            "Publication url": "https://drops.dagstuhl.de/opus/volltexte/2020/11837/pdf/dagrep_v009_i007_complete.pdf",
            "Abstract": "A formal semantics of a language serves many purposes. It can help debug the language\u2019s design, be used to prove type soundness, and guide optimizers to confirm that their work is correctnesspreserving. Formal semantics are evaluated by several criteria: full abstraction, adequacy, soundness and completeness, faithfulness to an underlying implementation, and so on. Unfortunately, we know relatively little about how non-experts, such as students, actually employ a semantics. Which models are they able to grasp? How useful are these as they explain or debug programs? How does their use of models evolve with the kinds of programs they write? And does studying these kinds of questions yield any new insights into forms of semantics? This Dagstuhl Seminar intended to bridge this gap. It brought together representatives of the two communities-who usually travel in non-intersecting circles-to enable mutual understanding and cross-pollination. The Programming Languages community uses mathematics and focuses on formal results; the Computing Education Research community uses social science methods and focuses on the impact on humans. Neither is superior: both are needed to arrive at a comprehensive solution to creating tools for learning.",
            "Abstract entirety": 1,
            "Author pub id": "qUBdmWgAAAAJ:QD3KBmkZPeQC",
            "Publisher": "Unknown"
        },
        {
            "Title": "In memoriam Alberto Oscar Mendelzon-July 28, 1951-June 16, 2005",
            "Publication year": 2005,
            "Publication url": "https://scholar.google.com/scholar?cluster=8568994246624522812&hl=en&oi=scholarr",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "qUBdmWgAAAAJ:XiVPGOgt02cC",
            "Publisher": "ASSOC COMPUTING MACHINERY"
        },
        {
            "Title": "Predicting Dyslexia and Reading Speed in Adolescents from Eye Movements in Reading and Non-Reading Tasks: A Machine Learning Approach",
            "Publication year": 2021,
            "Publication url": "https://www.mdpi.com/1306832",
            "Abstract": "There is evidence that abnormalities in eye movements exist during reading in dyslexic individuals. A few recent studies applied Machine Learning (ML) classifiers to such eye movement data to predict dyslexia. A general problem with these studies is that eye movement data sets are limited to reading saccades and fixations that are confounded by reading difficulty, e.g., it is unclear whether abnormalities are the consequence or the cause of reading difficulty. Recently, Ward and Kapoula used LED targets (with the REMOBI & AIDEAL method) to demonstrate abnormalities of large saccades and vergence eye movements in depth demonstrating intrinsic eye movement problems independent from reading in dyslexia. In another study, binocular eye movements were studied while reading two texts: one using the \u201cAlouette\u201d text, which has no meaning and requires word decoding, the other using a meaningful text. It was found the Alouette text exacerbates eye movement abnormalities in dyslexics. In this paper, we more precisely quantify the quality of such eye movement descriptors for dyslexia detection. We use the descriptors produced in the four different setups as input to multiple classifiers and compare their generalization performances. Our results demonstrate that eye movement data from the Alouette test predicts dyslexia with an accuracy of 81.25%; similarly, we were able to predict dyslexia with an accuracy of 81.25% when using data from saccades to LED targets on the Remobi device and 77.3% when using vergence movements to LED targets. Noticeably, eye movement data from the meaningful text produced the lowest accuracy (70.2 \u2026",
            "Abstract entirety": 0,
            "Author pub id": "qUBdmWgAAAAJ:yxmsSjX2EkcC",
            "Publisher": "Multidisciplinary Digital Publishing Institute"
        },
        {
            "Title": "An Automated System for Internet Pharmacy Verification.",
            "Publication year": 2018,
            "Publication url": "https://helios2.mi.parisdescartes.fr/~themisp/publications/edbt18.pdf",
            "Abstract": "In the past years, we have witnessed an explosion of web applications, and in particular of electronic commerce websites. This has led to unquestionable benefits for both producers and consumers of goods. On the other hand, however, untrusted companies have the opportunity to bypass checks and regulations imposed by relevant bodies. This problem is prevalent in the context of online commerce of pharmaceutical products, where it is essential that such products are safe, of good quality, and only used with a proper prescription. In this work, we study the problem of internet pharmacy verification. To this effect, we build a classifier, able to find patterns and predict the class of unseen data. Moreover, we devise algorithms that give a trust score to each pharmacy, in order to have a legitimacy indicator usable by human reviewers. We experimentally evaluate the proposed approach with real data coming from two different time periods. The results demonstrate the effectiveness of our approach, as well as the potential of using similar techniques for automatically checking regulation compliance in electronic commerce.",
            "Abstract entirety": 1,
            "Author pub id": "qUBdmWgAAAAJ:HtEfBTGE9r8C",
            "Publisher": "Unknown"
        },
        {
            "Title": "What do Geotagged Tweets Reveal about Mobility Behavior?",
            "Publication year": 2017,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-319-73521-4_3",
            "Abstract": "People\u2019s attention tends to be drawn by important, or unique events, such as concerts, demonstrations, major football games, and others. Many individuals are even willing to travel long distances in order to attend events they regard as important. As a result, the everyday patterns that a person has, changes. This includes changes in the normal mobility patterns of this person, as well as changes in their social activities. In this work, we study these phenomena by analyzing the behavior of social media users. We investigate the activity and movement of users that either attend a unique event, or visit an important location, and contrast those to users that do not. Furthermore, based on the online activity of users that attend an event, we study the information that we can extract related to the mobility of these users. This information reveals some important characteristics that can be useful for a variety of location \u2026",
            "Abstract entirety": 0,
            "Author pub id": "qUBdmWgAAAAJ:Ug5p-4gJ2f0C",
            "Publisher": "Springer, Cham"
        },
        {
            "Title": "Characterizing home device usage from wireless traffic time series",
            "Publication year": 2016,
            "Publication url": "https://hal.inria.fr/hal-01249778/",
            "Abstract": "The analysis of temporal behavioral patterns of home network users can reveal important information to Internet Service Providers (ISPs) and help them to optimize their networks and offer new services (e.g., remote software upgrades, troubleshooting, energy savings). This study uses time series analysis of continuous traffic data from wireless home networks , to extract traffic patterns recurring within, or across homes, and assess the impact of different device types (fixed or portable) on home traffic. Traditional techniques for time series analysis are not suited in this respect, due to the limited stationary and evolving distribution properties of wireless home traffic data. We propose a novel framework that relies on a correlation-based similarity measure of time series , as well as a notion of strong stationarity to define motifs and dominant devices. Using this framework, we analyze the wireless traffic collected from 196 home gateways over two months. The proposed approach goes beyond existing application-specific analysis techniques, such as analysis of wireless traffic, which mainly rely on data aggregated across hundreds, or thousands of users. Our framework, enables the extraction of recurring patterns from traffic time series of individual homes, leading to a much more fine-grained analysis of the behavior patterns of the users. We also determine the best time aggregation policy w.r.t. to the number and statistical importance of the extracted motifs, as well as the device types dominating these motifs and the overall gateway traffic. Our results show that ISPs can exceed the simple observation of the aggregated gateway traffic and better understand \u2026",
            "Abstract entirety": 0,
            "Author pub id": "qUBdmWgAAAAJ:ML0RJ9NH7IQC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Nia: System for news impact analytics",
            "Publication year": 2014,
            "Publication url": "https://core.ac.uk/download/pdf/34655536.pdf#page=127",
            "Abstract": "The analysis of news impact on people is relevant to a variety of applications, ranging from monitoring product and companies reputations, to stock market prediction. Therefore, it is important to understand the underlying mechanisms which affect the propagation of news and drive the evolution of sentiments in one way or another. In this demonstration paper, we describe NIA, a system that identifies and describes news events that caused changes of sentiments. NIA is based on a novel framework for a complex news event modeling, which is capable of detecting time and importance characteristics of events by only observing a time series of news articles publications, and then correlating this data with a time series of sentiment shifts. The operation of our system is summarized as follows. First, we apply a deconvolution to recover the time, longitude, importance and impact of news events. Second, we compute a sentiment time series, eg, by monitoring sentiments for positive or negative bursts, and coherently analyze sentiment and news time series, automatically determining their time lag. Third, we evaluate the corresponding news articles for a time interval of interest and extract the essence of what happened. Finally, we present the selected news time series to the user, as well as several more correlated stories, which could have affected sentiments as well, proposing to interactively explore their connections.",
            "Abstract entirety": 1,
            "Author pub id": "qUBdmWgAAAAJ:N5tVd3kTz84C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Real-time data analytics in sensor networks",
            "Publication year": 2013,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-1-4614-6309-2_7",
            "Abstract": "The proliferation of Wireless Sensor Networks (WSNs) in the past decade has provided the bridge between the physical and digital worlds, enabling the monitoring and study of physical phenomena at a granularity and level of detail that was never before possible. In this study, we review the efforts of the research community with respect to two important problems in the context of WSNs: real-time collection of the sensed data, and real-time processing of these data series.",
            "Abstract entirety": 1,
            "Author pub id": "qUBdmWgAAAAJ:D_sINldO8mEC",
            "Publisher": "Springer, Boston, MA"
        },
        {
            "Title": "VALMOD: A suite for easy and exact detection of variable length motifs in data series",
            "Publication year": 2018,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/3183713.3193556",
            "Abstract": "Data series motif discovery represents one of the most useful primitives for data series mining, with applications to many domains, such as robotics, entomology, seismology, medicine, and climatology, and others. The state-of-the-art motif discovery tools still require the user to provide the motif length. Yet, in several cases, the choice of motif length is critical for their detection. Unfortunately, the obvious brute-force solution, which tests all lengths within a given range, is computationally untenable, and does not provide any support for ranking motifs at different resolutions (ie, lengths). We demonstrate VALMOD, our scalable motif discovery algorithm that efficiently finds all motifs in a given range of lengths, and outputs a length-invariant ranking of motifs. Furthermore, we support the analysis process by means of a newly proposed meta-data structure that helps the user to select the most promising pattern length. This \u2026",
            "Abstract entirety": 0,
            "Author pub id": "qUBdmWgAAAAJ:sNmaIFBj_lkC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Similarity matching for uncertain time series: analytical and experimental comparison",
            "Publication year": 2011,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/2064969.2064971",
            "Abstract": "In the last years there has been a considerable increase in the availability of continuous sensor measurements in a wide range of application domains, such as Location-Based Services (LBS), medical monitoring systems, manufacturing plants and engineering facilities to ensure efficiency, product quality and safety, hydrologic and geologic observing systems, pollution management, and others.",
            "Abstract entirety": 1,
            "Author pub id": "qUBdmWgAAAAJ:yD5IFk8b50cC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Frequent items in streaming data: An experimental evaluation of the state-of-the-art",
            "Publication year": 2009,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S0169023X08001663",
            "Abstract": "The problem of detecting frequent items in streaming data is relevant to many different applications across many domains. Several algorithms, diverse in nature, have been proposed in the literature for the solution of the above problem. In this paper, we review these algorithms, and we present the results of the first extensive comparative experimental study of the most prominent algorithms in the literature. The algorithms were comprehensively tested using a common test framework on several real and synthetic datasets. Their performance with respect to the different parameters (i.e., parameters intrinsic to the algorithms, and data related parameters) was studied. We report the results, and insights gained through these experiments.",
            "Abstract entirety": 1,
            "Author pub id": "qUBdmWgAAAAJ:bEWYMUwI8FkC",
            "Publisher": "North-Holland"
        },
        {
            "Title": "Updating a data warehouse schema based on changes in an observation model",
            "Publication year": 2008,
            "Publication url": "https://patents.google.com/patent/US7418453B2/en",
            "Abstract": "A method, information processing system, and computer readable medium for modifying at least one data warehouse schema based on detected changes in an associated observation model are disclosed. The method includes determining if at least one new observation model has been created. The method also includes determining if at least one existing observation model is associated with the new observation model. In response to the existing observation model being associated with the new observation model, at least one changed attribute is identified by comparing the new observation model and the existing observation model. A set of files associated with the existing observation model is updated to reflect the changed attribute between the new observation model and the existing observation model.",
            "Abstract entirety": 1,
            "Author pub id": "qUBdmWgAAAAJ:oNZyr7d5Mn4C",
            "Publisher": "Unknown"
        },
        {
            "Title": "JedAI3: beyond batch, blocking-based Entity Resolution.",
            "Publication year": 2020,
            "Publication url": "http://cgi.di.uoa.gr/~koubarak/publications/2020/JedAIrising.pdf",
            "Abstract": "JedAI is an open-source toolkit that allows for building and benchmarking thousands of schema-agnostic Entity Resolution (ER) pipelines through a non-learning, blocking-based end-to-end workflow. In this paper, we present its latest release, JedAI3, which conveys two new end-to-end workflows: one for budgetagnostic ER that is based on similarity joins, and one for budgetaware (ie, progressive) ER. This version also adds support for pre-trained word or character embeddings and connects JedAI to the Python data analysis ecosystem. Overall, these enhancements provide JedAI with features offered by no other ER tool, especially in the schema-and domain-agnostic context.",
            "Abstract entirety": 1,
            "Author pub id": "qUBdmWgAAAAJ:LgRImbQfgY4C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Error-tolerant exemplar queries on rdf graphs",
            "Publication year": 2016,
            "Publication url": "http://webdocs.cs.ualberta.ca/~drafiei/papers/edbt17-ext.pdf",
            "Abstract": "Edge-labeled graphs are widely used to describe relationships between entities in a database. We study a class of queries, referred to as exemplar queries, on edge-labeled graphs where each query gives an example of what the user is searching for. Given an exemplar query, we study the problem of efficiently searching for similar subgraphs in a large data graph, where the similarity is defined in terms of the well-known graph edit distance. We call these queries errortolerant exemplar queries since matches are allowed despite small variations in the graph structure and the labels. The problem in its general case is computationally intractable but efficient solutions are reachable for labeled graphs under well-behaved distribution of the labels, commonly found in knowledge graphs and RDF databases. In this paper, we propose two efficient exact algorithms, based on a filteringand-verification framework, for finding subgraphs in a large data graph that are isomorphic to a query graph under some edit operations. Our filtering scheme, which uses the neighbourhood structure around a node and the presence or absence of paths, significantly reduces the number of candidates that are passed to the verification stage. We analyze the costs of our algorithms and the conditions under which one algorithm is expected to outperform the other. Our cost analysis identifies some of the variables that affect the cost, including the number and the selectivity of the edge labels in the query and the degree of nodes in the data graph, and characterizes the relationships. We empirically evaluate the effectiveness of our filtering schemes and queries, the efficiency of \u2026",
            "Abstract entirety": 0,
            "Author pub id": "qUBdmWgAAAAJ:TIZ-Mc8IlK0C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Towards mega-modeling",
            "Publication year": 2013,
            "Publication url": "https://arpi.unipi.it/handle/11568/474269",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "qUBdmWgAAAAJ:8d8msizDQcsC",
            "Publisher": "Unknown"
        },
        {
            "Title": "A survey of blocking and filtering techniques for entity resolution",
            "Publication year": 2019,
            "Publication url": "https://arxiv.org/abs/1905.06167",
            "Abstract": "Efficiency techniques are an integral part of Entity Resolution, since its infancy. In this survey, we organized the bulk of works in the field into Blocking, Filtering and hybrid techniques, facilitating their understanding and use. We also provided an in-dept coverage of each category, further classifying the corresponding works into novel sub-categories. Lately, the efficiency techniques have received more attention, due to the rise of Big Data. This includes large volumes of semi-structured data, which pose challenges not only to the scalability of efficiency techniques, but also to their core assumptions: the requirement of Blocking for schema knowledge and of Filtering for high similarity thresholds. The former led to the introduction of schema-agnostic Blocking in conjunction with Block Processing techniques, while the latter led to more relaxed criteria of similarity. Our survey covers these new fields in detail, putting in context all relevant works.",
            "Abstract entirety": 1,
            "Author pub id": "qUBdmWgAAAAJ:_OXeSy2IsFwC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Defining and measuring data-driven quality dimension of staleness",
            "Publication year": 2012,
            "Publication url": "http://eprints.biblio.unitn.it/3978/",
            "Abstract": "With the growing complexity of data acquisition and processing methods, there is an increasing demand in understanding which data is outdated and how to have it as fresh as possible. Staleness is one of the key, time-related, data quality characteristics, that represents a degree of synchronization between data originators and information systems possessing the data. However, nowadays there is no common and pervasive notion of data staleness, as well as methods for its measurement in a wide scope of applications. Our work provides a definition of a data-driven notion of staleness for information systems with frequently updatable data. For such a data, we demonstrate an efficient exponential smoothing method of staleness measurement, compared to na\u00efve approaches, using the same limited amount of memory, based on averaging of frequency of updates. We present experimental results of staleness measurement algorithms that we run on history of updates of articles from Wikipedia.",
            "Abstract entirety": 1,
            "Author pub id": "qUBdmWgAAAAJ:sSrBHYA8nusC",
            "Publisher": "Universit\u00e0 degli Studi di Trento"
        },
        {
            "Title": "Matrix profile X: VALMOD-scalable discovery of variable-length motifs in data series",
            "Publication year": 2018,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/3183713.3183744",
            "Abstract": "In the last fifteen years, data series motif discovery has emerged as one of the most useful primitives for data series mining, with applications to many domains, including robotics, entomology, seismology, medicine, and climatology. Nevertheless, the state-of-the-art motif discovery tools still require the user to provide the motif length. Yet, in at least some cases, the choice of motif length is critical and unforgiving. Unfortunately, the obvious brute-force solution, which tests all lengths within a given range, is computationally untenable. In this work, we introduce VALMOD, an exact and scalable motif discovery algorithm that efficiently finds all motifs in a given range of lengths. We evaluate our approach with five diverse real datasets, and demonstrate that it is up to 20 times faster than the state-of-the-art. Our results also show that removing the unrealistic assumption that the user knows the correct length, can often \u2026",
            "Abstract entirety": 0,
            "Author pub id": "qUBdmWgAAAAJ:6ZxmRoH8BuwC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Efficient top-k approximate subtree matching in small memory",
            "Publication year": 2010,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/5669314/",
            "Abstract": "We consider the Top-k Approximate Subtree Matching (TASM) problem: finding the k best matches of a small query tree within a large document tree using the canonical tree edit distance as a similarity measure between subtrees. Evaluating the tree edit distance for large XML trees is difficult: the best known algorithms have cubic runtime and quadratic space complexity, and, thus, do not scale. Our solution is TASM-postorder, a memory-efficient and scalable TASM algorithm. We prove an upper bound for the maximum subtree size for which the tree edit distance needs to be evaluated. The upper bound depends on the query and is independent of the document size and structure. A core problem is to efficiently prune subtrees that are above this size threshold. We develop an algorithm based on the prefix ring buffer that allows us to prune all subtrees above the threshold in a single postorder scan of the document \u2026",
            "Abstract entirety": 0,
            "Author pub id": "qUBdmWgAAAAJ:HoB7MX3m0LUC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Whitewater: Distributed processing of fast streams",
            "Publication year": 2007,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/4288141/",
            "Abstract": "Monitoring systems today often involve continuous queries over streaming data in a distributed collaborative fashion. The distribution of query operators over a network of processors, as well as their processing sequence, form a query configuration with inherent constraints on the throughput that it can support. In this paper, we discuss the implications of measuring and optimizing for output throughput, as well as its limitations. We propose to use instead the more granular input throughput and a version of throughput measure, the profiled input throughput, that is focused on matching the expected behavior of the input streams. We show how we can evaluate a query configuration based on profiled input throughput and that the problem of finding the optimal configuration is NP-hard. Furthermore, we describe how we can overcome the complexity limitation by adapting hill-climbing heuristics to reduce the search space \u2026",
            "Abstract entirety": 0,
            "Author pub id": "qUBdmWgAAAAJ:70eg2SAEIzsC",
            "Publisher": "IEEE"
        },
        {
            "Title": "High-Dimensional Similarity Search for Scalable Data Science",
            "Publication year": 2021,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/9458625/",
            "Abstract": "Similarity search is a core operation of many critical data science applications, involving massive collections of high-dimensional objects. Similarity search finds objects in a collection close to a given query according to some definition of sameness. Objects can be data series, text, multimedia, graphs, database tables or deep network embeddings. In this tutorial, we revisit the similarity search problem in light of the recent advances in the field and the new big data landscape. We discuss key data science applications that require efficient high-dimensional similarity search, we survey the state-of-the-art high-dimensional similarity search approaches and share surprising insights about their strengths and weaknesses, and we discuss the challenges and open research problems in this area.",
            "Abstract entirety": 1,
            "Author pub id": "qUBdmWgAAAAJ:PYBJJbyH-FwC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Challenges for interdisciplinary research in the AI era",
            "Publication year": 2020,
            "Publication url": "https://scholar.google.com/scholar?cluster=17399106643862095902&hl=en&oi=scholarr",
            "Abstract": "The use of artificial intelligence (AI) in a variety of research fields is speeding up multiple digital revolutions, from shifting paradigms in healthcare, precision medicine and wearable sensing, to public services and education offered to the masses around the world, to future cities made optimally efficient by autonomous driving. When a revolution happens, the consequences are not obvious straight away, and to date, there is no uniformly adapted framework to guide AI research to ensure a sustainable societal transition. To answer this need, here we analyze three key challenges to interdisciplinary AI research, and deliver three broad conclusions: (i) future development of AI should not only impact other scientific domains but should also take inspiration and benefit from other fields of science, (ii) AI research must be accompanied by decision explainability, dataset bias transparency as well as development of \u2026",
            "Abstract entirety": 0,
            "Author pub id": "qUBdmWgAAAAJ:PaBasH6fAo0C",
            "Publisher": "Frontiers"
        },
        {
            "Title": "Parallel meta-blocking for scaling entity resolution over big heterogeneous data",
            "Publication year": 2017,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S030643791530199X",
            "Abstract": "Entity resolution constitutes a crucial task for many applications, but has an inherently quadratic complexity. In order to enable entity resolution to scale to large volumes of data, blocking is typically employed: it clusters similar entities into (overlapping) blocks so that it suffices to perform comparisons only within each block. To further increase efficiency, Meta-blocking is being used to clean the overlapping blocks from unnecessary comparisons, increasing precision by orders of magnitude at a small cost in recall. Despite its high time efficiency though, using Meta-blocking in practice to solve entity resolution problem on very large datasets is still challenging: applying it to 7.4 million entities takes (almost) 8 full days on a modern high-end server.In this paper, we introduce scalable algorithms for Meta-blocking, exploiting the MapReduce framework. Specifically, we describe a strategy for parallel execution that explicitly \u2026",
            "Abstract entirety": 0,
            "Author pub id": "qUBdmWgAAAAJ:LI9QrySNdTsC",
            "Publisher": "Pergamon"
        },
        {
            "Title": "Cache management policies for semantic caching",
            "Publication year": 2001,
            "Publication url": "http://disi.unitn.it/~themis/publications/recycman-tr01.pdf",
            "Abstract": "Commercial database systems make extensive use of caching to speed up query execution. Semantic caching is the idea of caching actual query results in the hope of being able to reuse them to speed up subsequent queries. This paper deals with cache management policies, which refer to policies for admission into the cache and eviction from the cache. When a query is executed, we must decide what part, if any, of the query result to add to the cache. If the cache is full, we must also decide which, if any, of the currently cached results to evict from the cache. The objective of these policies is to minimize the cost of executing the current and future queries or, phrased differently, maximize the benefit of the cache. The main difficulty is predicting the cost savings of future queries.In this study we present a family of cache admission and eviction policies, named RECYCLE, specifically designed for semantic caching within a relational database server. Our policies were designed to be both effective (high reuse ratio) and efficient (low overhead). The policies make use of a novel type of statistics, called access statistics. These statistics are easy to gather and maintain, yet, they offer a solid and flexible framework for dealing with the complexity of the problem. The decision whether to cache a query result takes into account the current content of the cache and the estimated benefit of the result during its lifetime. We experimentally compare the effectiveness of our policies with several other caching policies, and show the superiority of our solution.",
            "Abstract entirety": 1,
            "Author pub id": "qUBdmWgAAAAJ:p2g8aNsByqUC",
            "Publisher": "Technical Report CSRG-439, Dept. of Computer Science, University of Toronto"
        },
        {
            "Title": "Indexing large human-motion databases",
            "Publication year": 2004,
            "Publication url": "http://www.vldb.org/conf/2004/RS21P1.PDF",
            "Abstract": "Data-driven animation has become the industry standard for computer games and many animated movies and special effects. In particular, motion capture data recorded from live actors, is the most promising approach offered thus far for animating realistic human characters. However, the manipulation of such data for general use and re-use is not yet a solved problem. Many of the existing techniques dealing with editing motion rely on indexing for annotation, segmentation, and re-ordering of the data. Euclidean distance is inappropriate for solving these indexing problems because of the inherent variability found in human motion. The limitations of Euclidean distance stems from the fact that it is very sensitive to distortions in the time axis. A partial solution to this problem, Dynamic Time Warping (DTW), aligns the time axis before calculating the Euclidean distance. However, DTW can only address the problem of local scaling. As we demonstrate in this paper, global or uniform scaling is just as important in the indexing of human motion. We propose a novel technique to speed up similarity search under uniform scaling, based on bounding envelopes. Our technique is intuitive and simple to implement. We describe algorithms that make use of this technique, we perform an experimental analysis with real datasets, and we evaluate it in the context of a motion capture processing system. The results demonstrate the utility of our approach, and show that we can achieve orders of magnitude of speedup over the brute force approach, the only alternative solution currently available.",
            "Abstract entirety": 1,
            "Author pub id": "qUBdmWgAAAAJ:_Qo2XoVZTnwC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Towards a general entity representation model",
            "Publication year": 2009,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/5211594/",
            "Abstract": "In this paper, we argue for an infrastructure responsible for assigning and managing unique identifiers for entities in the semantic Web, and we propose a conceptual model for the storage and management of these entities.",
            "Abstract entirety": 1,
            "Author pub id": "qUBdmWgAAAAJ:M3NEmzRMIkIC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Managing diverse sentiments at large scale",
            "Publication year": 2016,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/7530818/",
            "Abstract": "The large-scale aggregation and analysis of user opinions is becoming increasingly relevant to a variety of applications, from detecting social mood on some political topics to tracking their sentiment changes related to events. The analysis of diverse sentiments is another important application, which becomes possible based on the ability of modern methods to capture sentiment polarity on various topics with high precision and on the ever-growing scale. Therefore, there is a need for a scalable way of sentiment aggregation with respect to the time dimension, which stores enough information to preserve diversity, and which allows statistically accurate analysis of sentiment trends and opinion shifts. In this paper, we are focusing on the novel problem of aggregating diverse sentiments at a large scale, based on data sources that are continuously updated. First, we develop a theoretical framework that models \u2026",
            "Abstract entirety": 0,
            "Author pub id": "qUBdmWgAAAAJ:KUbvn5osdkgC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Generating data series query workloads",
            "Publication year": 2018,
            "Publication url": "https://link.springer.com/article/10.1007/s00778-018-0513-x",
            "Abstract": "Data series (including time series) has attracted lots of interest in recent years. Most of the research has focused on how to efficiently support similarity or nearest neighbor queries over large data series collections (an important data mining task), and several data series summarization and indexing methods have been proposed in order to solve this problem. Up to this point, very little attention has been paid to properly evaluating such index structures, with most previous works relying solely on randomly selected data series to use as queries. In this work, we show that random workloads are inherently not suitable for the task at hand and we argue that there is a need for carefully generating query workloads. We define measures that capture the characteristics of queries, and we propose a method for generating workloads with the desired properties, that is, effectively evaluating and comparing data series \u2026",
            "Abstract entirety": 0,
            "Author pub id": "qUBdmWgAAAAJ:OTTXONDVkokC",
            "Publisher": "Springer Berlin Heidelberg"
        },
        {
            "Title": "Blocking Techniques for Web-scale Entity Resolution",
            "Publication year": 2014,
            "Publication url": "https://iit.demokritos.gr/sites/default/files/parousiase_demokritos.pdf",
            "Abstract": "Blocking Techniques for Web-scale Entity Resolution Page 1 Blocking Techniques for Web-scale \nEntity Resolution George Papadakis \u2013 Themis Palpanas IMIS, Athena RC Paris Descartes \nUniversity gpapadis@imis.athena.innovation.gr themis@mi.parisdescartes.fr Papadakis & \nPalpanas, Tutorial@WISE14, 12. October 2014 Page 2 Outline 1. Introduction to Entity Resolution \n2. Introduction to Blocking 3. Blocking Methods for Databases 4. Blocking Methods for Web Data \n5. Meta-blocking 6. Block Processing Techniques 7. ER framework Papadakis & Palpanas, \nTutorial@WISE14, 12. October 2014 Page 3 Papadakis & Palpanas, Tutorial@WISE14, 12. \nOctober 2014 Part 1: Introduction to Entity Resolution Page 4 Entities: an invaluable asset \n\u201cEntities\u201d is what a large part of our knowledge is about: Persons Organizations Projects \nLocations Products Events Papadakis & Palpanas, Tutorial@WISE14, 12. October 2014 5 \u2026",
            "Abstract entirety": 0,
            "Author pub id": "qUBdmWgAAAAJ:sJsF-0ZLhtgC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Graph-query suggestions for knowledge graph exploration",
            "Publication year": 2020,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/3366423.3380005",
            "Abstract": "We consider the task of exploratory search through graph queries on knowledge graphs. We propose to assist the user by expanding the query with intuitive suggestions to provide a more informative (full) query that can retrieve more detailed and relevant answers. To achieve this result, we propose a model that can bridge graph search paradigms with well-established techniques for information-retrieval. Our approach does not require any additional knowledge from the user and builds on principled language modelling approaches. We empirically show the effectiveness and efficiency of our approach on a large knowledge graph and how our suggestions are able to help build more complete and informative queries.",
            "Abstract entirety": 1,
            "Author pub id": "qUBdmWgAAAAJ:2tRrZ1ZAMYUC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Entity ranking using click-log information",
            "Publication year": 2013,
            "Publication url": "https://content.iospress.com/articles/intelligent-data-analysis/ida00609",
            "Abstract": "Log information describing the items the users have selected from the set of answers a query engine returns to their queries constitute an excellent form of indirect user feedback that has been extensively used in the web to improve the effectiveness of search engines.",
            "Abstract entirety": 1,
            "Author pub id": "qUBdmWgAAAAJ:LPZeul_q3PIC",
            "Publisher": "IOS Press"
        },
        {
            "Title": "SAND in action: subsequence anomaly detection for streams",
            "Publication year": 2021,
            "Publication url": "https://dl.acm.org/doi/abs/10.14778/3476311.3476365",
            "Abstract": "Subsequence anomaly detection in long data series is a significant problem. While the demand for real-time analytics and decision making increases, anomaly detection methods have to operate over streams and handle drifts in data distribution. Nevertheless, existing approaches either require prior domain knowledge or become cumbersome and expensive to use in situations with recurrent anomalies of the same type. Moreover, subsequence anomaly detection methods usually require access to the entire dataset and are not able to learn and detect anomalies in streaming settings. To address these limitations, we propose SAND, a novel online system suitable for domain-agnostic anomaly detection. SAND relies on a novel steaming methodology to incrementally update a model that adapts to distribution drifts and omits obsolete data. We demonstrate our system over different streaming scenarios and compare \u2026",
            "Abstract entirety": 0,
            "Author pub id": "qUBdmWgAAAAJ:L1USKYWJimsC",
            "Publisher": "VLDB Endowment"
        },
        {
            "Title": "Efficiently discovering recent frequent items in data streams",
            "Publication year": 2008,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-540-69497-7_16",
            "Abstract": "The problem of frequent item discovery in streaming data has attracted a lot of attention lately. While the above problem has been studied extensively, and several techniques have been proposed for its solution, these approaches treat all the values of the data stream equally. Nevertheless, not all values are of equal importance. In several situations, we are interested more in the new values that have appeared in the stream, rather than in the older ones.In this paper, we address the problem of finding recent frequent items in a data stream given a small bounded memory, and present novel algorithms to this direction. We propose a basic algorithm that extends the functionality of existing approaches by monitoring item frequencies in recent windows. Subsequently, we present an improved version of the algorithm with significantly improved performance (in terms of accuracy), at no extra memory cost \u2026",
            "Abstract entirety": 0,
            "Author pub id": "qUBdmWgAAAAJ:k_IJM867U9cC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "Practical data prediction for real-world wireless sensor networks",
            "Publication year": 2015,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/7056557/",
            "Abstract": "Data prediction is proposed in wireless sensor networks (WSNs) to extend the system lifetime by enabling the sink to determine the data sampled, within some accuracy bounds, with only minimal communication from source nodes. Several theoretical studies clearly demonstrate the tremendous potential of this approach, able to suppress the vast majority of data reports at the source nodes. Nevertheless, the techniques employed are relatively complex, and their feasibility on resource-scarce WSN devices is often not ascertained. More generally, the literature lacks reports from real-world deployments, quantifying the overall system-wide lifetime improvements determined by the interplay of data prediction with the underlying network. These two aspects, feasibility and system-wide gains, are key in determining the practical usefulness of data prediction in real-world WSN applications. In this paper, we describe \u2026",
            "Abstract entirety": 0,
            "Author pub id": "qUBdmWgAAAAJ:eq2jaN3J8jMC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Survey on mining subjective data on the web",
            "Publication year": 2012,
            "Publication url": "https://link.springer.com/article/10.1007/s10618-011-0238-6",
            "Abstract": "In the past years we have witnessed Sentiment Analysis and Opinion Mining becoming increasingly popular topics in Information Retrieval and Web data analysis. With the rapid growth of the user-generated content represented in blogs, wikis and Web forums, such an analysis became a useful tool for mining the Web, since it allowed us to capture sentiments and opinions at a large scale. Opinion retrieval has established itself as an important part of search engines. Ratings, opinion trends and representative opinions enrich the search experience of users when combined with traditional document retrieval, by revealing more insights about a subject. Opinion aggregation over product reviews can be very useful for product marketing and positioning, exposing the customers\u2019 attitude towards a product and its features along different dimensions, such as time, geographical location, and experience. Tracking \u2026",
            "Abstract entirety": 0,
            "Author pub id": "qUBdmWgAAAAJ:zA6iFVUQeVQC",
            "Publisher": "Springer US"
        },
        {
            "Title": "Knowledge discovery in data warehouses",
            "Publication year": 2000,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/362084.362142",
            "Abstract": "As the size of data warehouses increase to several hundreds of gigabytes or terabytes, the need for methods and tools that will automate the process of knowledge extraction, or guide the user to subsets of the dataset that are of particular interest, is becoming prominent. In this survey paper we explore the problem of identifying and extracting interesting knowledge from large collections of data residing in data warehouses, by using data mining techniques. Such techniques have the ability to identify patterns and build succinct models to describe the data. These models can also be used to achieve summarization and approximation. We review the associated work in the OLAP, data mining, and approximate query answering literature. We discuss the need for the traditional data mining techniques to adapt, and accommodate the specific characteristics of OLAP systems. We also examine the notion of interestingness \u2026",
            "Abstract entirety": 0,
            "Author pub id": "qUBdmWgAAAAJ:r0BpntZqJG4C",
            "Publisher": "ACM"
        },
        {
            "Title": "Schema-agnostic progressive entity resolution",
            "Publication year": 2018,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/8403302/",
            "Abstract": "Entity Resolution (ER) is the task of finding entity profiles that correspond to the same real-world entity. Progressive ER aims to efficiently resolve large datasets when limited time and/or computational resources are available. In practice, its goal is to provide the best possible partial solution by approximating the optimal comparison order of the entity profiles. So far, Progressive ER has only been examined in the context of structured (relational) data sources, as the existing methods rely on schema knowledge to save unnecessary comparisons: they restrict their search space to similar entities with the help of schema-based blocking keys (i.e., signatures that represent the entity profiles). As a result, these solutions are not applicable in Big Data integration applications, which involve large and heterogeneous datasets, such as relational and RDF databases, JSON files, Web corpus etc. To cover this gap, we propose a \u2026",
            "Abstract entirety": 0,
            "Author pub id": "qUBdmWgAAAAJ:umqufdRvDiIC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Content and type as orthogonal modeling features: a study on user interest awareness in entity subscription services",
            "Publication year": 2010,
            "Publication url": "http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.225.9966&rep=rep1&type=pdf#page=310",
            "Abstract": "Real-word entities can be mapped to unique entity identifiers through an Entity Name System (ENS), to systematically support the re-use of these identifiers and disambiguate references to real world entities in the Web. An entity subscription service informs subscribed users of changes in the descriptive data of an entity, which is a set of free-form attribute name-value pairs. We study the design, implementation and application of an adaptable, push-policy subscription service, within a large-scale ENS. The subscription system aims to deliver ranked descriptions of the changes on entities, following user preferences through a feedbackdriven adaptation process. Within this paper, we offer a novel approach based on the discrimination between the content (descriptive aspect) and the type (directly quantifiable or binary aspects) of information instances (ie, entity changes in our case). We study and evaluate two different approaches of adaptation to user interests: one that only manages constant user preferences and one that adapts to interest shifts of the users. We evaluate the learning curve of the variations of the system, the utility of the content-type discrimination, as well as the effectiveness of modeling user behavior for random interest shifts of the user. The experiments demonstrate good results, especially in the system\u2019s content-aware adaptation aspect, which takes into account user interest shifts. We also extract a set of useful conclusions concerning the detection of user interest shifts, based on feedback, as well as the relation between the user interest shift frequency and the optimality of learning memory window size.",
            "Abstract entirety": 1,
            "Author pub id": "qUBdmWgAAAAJ:vV6vV6tmYwMC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Tweeloc: A system for geolocalizing tweets at fine-grain",
            "Publication year": 2017,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/8215801/",
            "Abstract": "The recent rise in the use of social networks has resulted in an abundance of information on different aspects of everyday social activities that is available online. In the process of analysis of identifying the information originating from social networks, and especially Twitter, an important aspect is that of the geographic coordinates, i.e., geolocalisation, of the relevant information. Geolocalized information can be used by a variety of applications in order to offer better, or new services. However, only a small percentage of the twitter posts are geotagged, which restricts the applicability of location-based applications. In this work, we describe TweeLoc, our prototype system for geolocalizing tweets that are not geotagged, which can effectively estimate the tweet location at the level of a city neighborhood. TweeLoc employs a dashboard that visualizes the social activity of the geographic regions specified by the user, and \u2026",
            "Abstract entirety": 0,
            "Author pub id": "qUBdmWgAAAAJ:86PQX7AUzd4C",
            "Publisher": "IEEE"
        },
        {
            "Title": "SYSTEMS AND METHODS FOR EFFICIENT TOP-k APPROXIMATE SUBTREE MATCHING",
            "Publication year": 2012,
            "Publication url": "https://patents.google.com/patent/US20120254251A1/en",
            "Abstract": "Systems and method for searching for approximate matches in a database of documents represented by a tree structure. A fast solution to the Top-k Approximate Subtree Matching Problem involves determining candidate subtrees which will be considered as possible matches to a query also represented by a tree structure. Once these candidate subtrees are found, a tree edit distance between each candidate subtree and the query tree is calculated. The results are then sorted to find those with the lowest tree edit distance.",
            "Abstract entirety": 1,
            "Author pub id": "qUBdmWgAAAAJ:BrmTIyaxlBUC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Dpisax: Massively distributed partitioned isax",
            "Publication year": 2017,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/8215614/",
            "Abstract": "Indexing is crucial for many data mining tasks that rely on efficient and effective similarity query processing. Consequently, indexing large volumes of time series, along with high performance similarity query processing, have became topics of high interest. For many applications across diverse domains though, the amount of data to be processed might be intractable for a single machine, making existing centralized indexing solutions inefficient. We propose a parallel indexing solution that gracefully scales to billions of time series, and a parallel query processing strategy that, given a batch of queries, efficiently exploits the index. Our experiments, on both synthetic and real world data, illustrate that our index creation algorithm works on 1 billion time series in less than 2 hours, while the state of the art centralized algorithms need more than 5 days. Also, our distributed querying algorithm is able to efficiently process \u2026",
            "Abstract entirety": 0,
            "Author pub id": "qUBdmWgAAAAJ:ClCfbGk0d_YC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Data series management (dagstuhl seminar 19282)",
            "Publication year": 2019,
            "Publication url": "https://drops.dagstuhl.de/opus/volltexte/2019/11634/",
            "Abstract": "We now witness a very strong interest by users across different domains on data series (aka time series) management. It is not unusual for industrial applications that produce data series to involve numbers of sequences (or subsequences) in the order of billions (ie, multiple TBs). As a result, analysts are unable to handle the vast amounts of data series that they have to manage and process. The goal of this seminar is to enable researchers and practitioners to exchange ideas and foster collaborations in the topic of data series management and identify the corresponding open research directions. The main questions answered are the following: i) What are the data series management needs across various domains and what are the shortcomings of current systems, ii) How can we use machine learning to optimize our current data systems, and how can these systems help in machine learning pipelines? iii) How can visual analytics assist the process of analyzing big data series collections? The seminar focuses on the following key topics related to data series management: 1) Data series storage and access paterns, 2) Query optimization, 3) Machine learning and data mining for data serie, 4) Visualization for data series exploration, 5) Applications in multiple domains.",
            "Abstract entirety": 1,
            "Author pub id": "qUBdmWgAAAAJ:Bg7qf7VwUHIC",
            "Publisher": "Schloss Dagstuhl-Leibniz-Zentrum fuer Informatik"
        },
        {
            "Title": "Dynamics of news events and social media reaction",
            "Publication year": 2014,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/2623330.2623670",
            "Abstract": "The analysis of social sentiment expressed on the Web is becoming increasingly relevant to a variety of applications, and it is important to understand the underlying mechanisms which drive the evolution of sentiments in one way or another, in order to be able to predict these changes in the future. In this paper, we study the dynamics of news events and their relation to changes of sentiment expressed on relevant topics. We propose a novel framework, which models the behavior of news and social media in response to events as a convolution between event's importance and media response function, specific to media and event type. This framework is suitable for detecting time and duration of events, as well as their impact and dynamics, from time series of publication volume. These data can greatly enhance events analysis; for instance, they can help distinguish important events from unimportant, or predict \u2026",
            "Abstract entirety": 0,
            "Author pub id": "qUBdmWgAAAAJ:VL0QpB8kHFEC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Sliding windows over uncertain data streams",
            "Publication year": 2015,
            "Publication url": "https://link.springer.com/article/10.1007/s10115-014-0804-5",
            "Abstract": "Uncertain data streams can have tuples with both value and existential uncertainty. A tuple has value uncertainty when it can assume multiple possible values. A tuple is existentially uncertain when the sum of the probabilities of its possible values is 1. A situation where existential uncertainty can arise is when applying relational operators to streams with value uncertainty. Several prior works have focused on querying and mining data streams with both value and existential uncertainty. However, none of them have studied, in depth, the implications of existential uncertainty on sliding window processing, even though it naturally arises when processing uncertain data. In this work, we study the challenges arising from existential uncertainty, more specifically the management of count-based sliding windows, which are a basic building block of stream processing applications. We extend the semantics of \u2026",
            "Abstract entirety": 0,
            "Author pub id": "qUBdmWgAAAAJ:UHK10RUVsp4C",
            "Publisher": "Springer London"
        },
        {
            "Title": "Method and apparatus for ranked join indices",
            "Publication year": 2007,
            "Publication url": "https://patents.google.com/patent/US7185012B1/en",
            "Abstract": "A method and apparatus for ranked join indices includes a solution providing performance guarantees for top-k join queries over two relations, when preprocessing to construct a ranked join index for a specific join condition is permitted. The concepts of ranking join indices presented herein are also applicable in the case of a single relation. In this case, the concepts herein provide a solution to the top-k selection problem with monotone linear functions, having guaranteed worst case search performance for the case of two ranked attributes and arbitrary preference vectors.",
            "Abstract entirety": 1,
            "Author pub id": "qUBdmWgAAAAJ:KlAtU1dfN6UC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Online amnesic approximation of streaming time series",
            "Publication year": 2004,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/1320009/",
            "Abstract": "The past decade has seen a wealth of research on time series representations, because the manipulation, storage, and indexing of large volumes of raw time series data is impractical. The vast majority of research has concentrated on representations that are calculated in batch mode and represent each value with approximately equal fidelity. However, the increasing deployment of mobile devices and real time sensors has brought home the need for representations that can be incrementally updated, and can approximate the data with fidelity proportional to its age. The latter property allows us to answer queries about the recent past with greater precision, since in many domains recent information is more useful than older information. We call such representations amnesic. While there has been previous work on amnesic representations, the class of amnesic functions possible was dictated by the representation \u2026",
            "Abstract entirety": 0,
            "Author pub id": "qUBdmWgAAAAJ:RHpTSmoSYBkC",
            "Publisher": "IEEE"
        },
        {
            "Title": "SAND: streaming subsequence anomaly detection",
            "Publication year": 2021,
            "Publication url": "https://helios.mi.parisdescartes.fr/~themisp/publications/pvldb21-sand.pdf",
            "Abstract": "With the increasing demand for real-time analytics and decision making, anomaly detection methods need to operate over streams of values and handle drifts in data distribution. Unfortunately, existing approaches have severe limitations: they either require prior domain knowledge or become cumbersome and expensive to use in situations with recurrent anomalies of the same type. In addition, subsequence anomaly detection methods usually require access to the entire dataset and are not able to learn and detect anomalies in streaming settings. To address these problems, we propose SAND, a novel online method suitable for domain-agnostic anomaly detection. SAND aims to detect anomalies based on their distance to a model that represents normal behavior. SAND relies on a novel steaming methodology to incrementally update such model, which adapts to distribution drifts and omits obsolete data. The experimental results on several real-world datasets demonstrate that SAND correctly identifies single and recurrent anomalies without prior knowledge of the characteristics of these anomalies. SAND outperforms by a large margin the current state-of-the-art algorithms in terms of accuracy while achieving orders of magnitude speedups.",
            "Abstract entirety": 1,
            "Author pub id": "qUBdmWgAAAAJ:XUvXOeBm_78C",
            "Publisher": "PVLDB"
        },
        {
            "Title": "Data Exploration Using Example-Based Methods",
            "Publication year": 2018,
            "Publication url": "https://www.morganclaypool.com/doi/abs/10.2200/S00881ED1V01Y201810DTM053",
            "Abstract": " Data usually comes in a plethora of formats and dimensions, rendering the information extraction and exploration processes challenging. Thus, being able to perform exploratory analyses of the data with the intent of having an immediate glimpse of some of the data properties is becoming crucial. Exploratory analyses should be simple enough to avoid complicated declarative languages (such as SQL) and mechanisms, while at the same time retaining the flexibility and expressiveness of such languages. Recently, we have witnessed a rediscovery of the so-called example-based methods, in which the user, or analyst, circumvents query languages by using examples as input. An example is a representative of the intended results or, in other words, an item from the result set. Example-based methods exploit inherent characteristics of the data to infer the results that the user has in mind but may not be able to (easily \u2026",
            "Abstract entirety": 0,
            "Author pub id": "qUBdmWgAAAAJ:bKqednn6t2AC",
            "Publisher": "Morgan & Claypool Publishers"
        },
        {
            "Title": "Boosting the efficiency of large-scale entity resolution with enhanced meta-blocking",
            "Publication year": 2016,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S2214579616300168",
            "Abstract": "Entity Resolution constitutes a quadratic task that typically scales to large entity collections through blocking. The resulting blocks can be restructured by Meta-blocking to raise precision at a limited cost in recall. At the core of this procedure lies the blocking graph, where the nodes correspond to entities and the edges connect the comparable pairs. There are several configurations for Meta-blocking, but no hints on best practices. In general, the node-centric approaches are more robust and suitable for a series of applications, but suffer from low precision, due to the large number of unnecessary comparisons they retain.In this work, we present three novel methods for node-centric Meta-blocking that significantly improve precision. We also introduce a pre-processing method that restricts the size of the blocking graph by removing a large number of noisy edges. As a result, it reduces the overhead time of Meta \u2026",
            "Abstract entirety": 0,
            "Author pub id": "qUBdmWgAAAAJ:kzcrU_BdoSEC",
            "Publisher": "Elsevier"
        },
        {
            "Title": "Detecting and exploiting stability in evolving heterogeneous information spaces",
            "Publication year": 2011,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/1998076.1998094",
            "Abstract": "Individuals contribute content on the Web at an unprecedented rate, accumulating immense quantities of (semi-) structured data. Wisdom of the Crowds theory advocates that such information (or parts of it) is constantly overwritten, updated, or even deleted by other users, with the goal of rendering it more accurate, or up-to-date. This is particularly true for the collaboratively edited, semi-structured data of entity repositories, whose entity profiles are consistently kept fresh. Therefore, their core information that remain stable with the passage of time, despite being reviewed by numerous users, are particularly useful for the description of an entity.",
            "Abstract entirety": 1,
            "Author pub id": "qUBdmWgAAAAJ:KxtntwgDAa4C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Reproducible experiments on Three-Dimensional Entity Resolution with JedAI",
            "Publication year": 2021,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S0306437921000685",
            "Abstract": "In Papadakis et al. (2020), we presented the latest release of JedAI, an open-source Entity Resolution (ER) system that allows for building a large variety of end-to-end ER pipelines. Through a thorough experimental evaluation, we compared a schema-agnostic ER pipeline based on blocks with another schema-based ER pipeline based on similarity joins. We applied them to 10 established, real-world datasets and assessed them with respect to effectiveness and time efficiency. Special care was taken to juxtapose their scalability, too, using seven established, synthetic datasets. Moreover, we experimentally compared the effectiveness of the batch schema-agnostic ER pipeline with its progressive counterpart. In this companion paper, we describe how to reproduce the entire experimental study that pertains to JedAI\u2019s serial execution through its intuitive user interface. We also explain how to examine the \u2026",
            "Abstract entirety": 0,
            "Author pub id": "qUBdmWgAAAAJ:jU7OWUQzBzMC",
            "Publisher": "Pergamon"
        },
        {
            "Title": "A conceptual model for a web-scale entity name system",
            "Publication year": 2009,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-642-10871-6_4",
            "Abstract": "The problem of identity and reference is receiving increasing attention in the (semantic) web community and is emerging as one of the key features which distinguish traditional knowledge representation from knowledge representation on the web with respect to data interlinking and knowledge integration on a large scale. As part of this debate, the OKKAM project proposed the creation of an Entity Name System which provides rigid identifiers, named OKKAMids, for any type of concrete and particular entities, and links OKKAMids to existing identifiers which have been created elsewhere for the same entity. The introduction of these identifiers raises some practical and conceptual concerns. In this paper we address them by extending two proposed ontologies (IRE and IRW) to accomodate the notion of OKKAMid, describe their formal properties, illustrate why they may play an important role in the construction \u2026",
            "Abstract entirety": 0,
            "Author pub id": "qUBdmWgAAAAJ:hMod-77fHWUC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "Managing Data Quality in Business Intelligence Applications.",
            "Publication year": 2008,
            "Publication url": "https://www.academia.edu/download/30725016/mud08.pdf#page=137",
            "Abstract": "Business Intelligence (BI) solutions commonly aim at assisting decision-making processes by providing a comprehensive view over a company\u2019s core business data and suitable abstractions thereof. Decision-making based on BI solutions therefore builds on the assumption that providing users with targeted, problemspecific fact data enables them to make informed and, hence, better decisions in their everyday businesses. In order to really provide users with all the necessary details to make informed decisions, we however believe that\u2013in addition to conventional reports\u2013it is essential to also provide users with information about the quality, ie with quality metadata, regarding the data from which reports are generated. Identifying a lack of support for quality metadata management in conventional BI solutions, in this paper we propose the idea of quality-aware reports and a possible architecture for quality-aware BI, able to involve the users themselves into the quality metadata management process, by explicitly soliciting and exploiting user feedback.",
            "Abstract entirety": 1,
            "Author pub id": "qUBdmWgAAAAJ:J_g5lzvAfSwC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Transactions on Large-scale Data-and Knowledge-centered Systems XV: Selected Papers from ADBIS 2013 Satellite Events",
            "Publication year": 2014,
            "Publication url": "https://scholar.google.com/scholar?cluster=10223522663538670730&hl=en&oi=scholarr",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "qUBdmWgAAAAJ:j7_hQOaDUrUC",
            "Publisher": "Springer"
        },
        {
            "Title": "Identifying streaming frequent items in ad hoc time windows",
            "Publication year": 2013,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S0169023X13000621",
            "Abstract": "The problem of frequent item discovery in streaming data has attracted a lot of attention, mainly because of its numerous applications in diverse domains, such as network traffic monitoring and e-business transactions analysis.While the above problem has been studied extensively, and several techniques have been proposed for its solution, these approaches are geared towards the recent values in the stream. Nevertheless, in several situations the users would like to be able to query about the item frequencies in ad hoc windows in the stream history, and compare these values among themselves.In this paper, we address the problem of finding frequent items in ad hoc windows in a data stream given a small bounded memory, and present novel algorithms to this direction. We propose basic sketch- and count-based algorithms that extend the functionality of existing approaches by monitoring item frequencies in \u2026",
            "Abstract entirety": 0,
            "Author pub id": "qUBdmWgAAAAJ:olpn-zPbct0C",
            "Publisher": "North-Holland"
        },
        {
            "Title": "A blocking framework for entity resolution in highly heterogeneous information spaces",
            "Publication year": 2012,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/6255742/",
            "Abstract": "In the context of entity resolution (ER) in highly heterogeneous, noisy, user-generated entity collections, practically all block building methods employ redundancy to achieve high effectiveness. This practice, however, results in a high number of pairwise comparisons, with a negative impact on efficiency. Existing block processing strategies aim at discarding unnecessary comparisons at no cost in effectiveness. In this paper, we systemize blocking methods for clean-clean ER (an inherently quadratic task) over highly heterogeneous information spaces (HHIS) through a novel framework that consists of two orthogonal layers: the effectiveness layer encompasses methods for building overlapping blocks with small likelihood of missed matches; the efficiency layer comprises a rich variety of techniques that significantly restrict the required number of pairwise comparisons, having a controllable impact on the number of \u2026",
            "Abstract entirety": 0,
            "Author pub id": "qUBdmWgAAAAJ:8AbLer7MMksC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Evolution of a data series index",
            "Publication year": 2020,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-030-44900-1_5",
            "Abstract": "There is an increasingly pressing need, by several applications in diverse domains, for developing techniques able to index and mine very large collections of sequences, or data series. It is not unusual for these applications to involve numbers of data series in the order of billions, which are often times not analyzed in their full detail due to their sheer size. In this work, we describe techniques for indexing and efficient similarity search in truly massive collections of data series, focusing on the iSAX family of data series indexes. We present their design characteristics, and describe their evolution to address different needs: bulk loading, adaptive indexing, parallelism and distribution, variable-length query answering, and bottom-up indexing. Based on this discussion, we conclude by presenting promising research directions.",
            "Abstract entirety": 1,
            "Author pub id": "qUBdmWgAAAAJ:7Hz3ACDFbsoC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Correlation-Aware Distance Measures for Data Series.",
            "Publication year": 2017,
            "Publication url": "http://k.mirylenka.com/sites/default/files/downloadfiles/edbt17.pdf",
            "Abstract": "The field of data series processing has attracted lots of attention thanks to the increased availability of unprecedented amounts of sequential data. These data are then processed and analyzed using a large variety of techniques, most of which are based on the computation of some distance function. In this study, we evaluate the benefits of incorporating into the distance functions correlation measures, which enable us to capture the associations among neighboring values in the sequence. We propose three such measures, inspired by statistical and probabilistic approaches. We analytically and experimentally demonstrate the benefits of the new measures using the 1NN classification task, and discuss the lessons learned.",
            "Abstract entirety": 1,
            "Author pub id": "qUBdmWgAAAAJ:WZBGuue-350C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Unleashing the power of information graphs",
            "Publication year": 2015,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/2737817.2737822",
            "Abstract": "Information graphs are generic graphs that model different types of information through nodes and edges. Knowledge graphs are the most common type of information graphs in which nodes represent entities and edges represent relationships among them. In this paper, we argue that exploitation of information graphs can lead into novel query answering capabilities that go beyond the existing capabilities of keyword search, and focus on one of them, namely, exemplar queries. Exemplar queries is a recently introduced paradigm that treats a user query as an example from the desired result set. In this paper, we describe the foundations of exemplar queries and the significant role of information graphs, and we present several applications and relevant research directions.",
            "Abstract entirety": 1,
            "Author pub id": "qUBdmWgAAAAJ:JQOojiI6XY0C",
            "Publisher": "ACM"
        },
        {
            "Title": "Arranging Pixels in a DBMS When Vision and Databases Come Together",
            "Publication year": 2000,
            "Publication url": "https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.34.4208&rep=rep1&type=pdf",
            "Abstract": "The rapid technological advances augmented our capabilities for generating and storing multimedia content data. The large amount of image and video data makes it very cumbersome to manually search, browse, and annotate them. Therefore, the need for systems that would automate the aforementioned procedures is now evident more than ever. The focus of this paper is on image and video databases. We investigate what techniques are used in order to achieve the goals of searching, browsing, and annotating multimedia content. We analyze the state of the art methods employed for extracting interesting features from the data (colour moments, texture and shape, high level representation, motion components, camera operations). Most of the above methods originate from the vision community. Yet, many interesting problems arise when we try to apply these methods in conjunction with a DataBase Management System (DBMS). Thus, in many cases, the database community has derived new techniques to deal with the problem of indexing multimedia data. Note, that this survey does not intend to be exhaustive, but rather indicative of the state of the art trends, and the future research directions in both the vision and database communities.",
            "Abstract entirety": 1,
            "Author pub id": "qUBdmWgAAAAJ:ZHo1McVdvXMC",
            "Publisher": "Technical Report CSRG-404, Department of Computer Science, University of Toronto"
        },
        {
            "Title": "Data series management: The road to big sequence analytics",
            "Publication year": 2015,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/2814710.2814719",
            "Abstract": "Massive data series collections are becoming a reality for virtually every scientific and social domain, and have to be processed and analyzed, in order to extract useful knowledge. Current data series management solutions are ad hoc, requiring huge investments in time and effort, and duplication of effort across different teams. Systems like relational databases, Column Stores, and Array Databases are not a suitable solution either, since none of these systems offers native support for data series. Our vision is to design and develop a generalpurpose Data Series Management System, able to copewith big data series, that is, very large and fast-changing collections of data series, which can be heterogeneous (i.e., originate from disparate domains and thus exhibit very different characteristics), and which can have uncertainty in their values (e.g., due to inherent errors in the measurements). Just like databases \u2026",
            "Abstract entirety": 0,
            "Author pub id": "qUBdmWgAAAAJ:uWiczbcajpAC",
            "Publisher": "ACM"
        },
        {
            "Title": "Cloudalloc: A monitoring and reservation system for compute clusters",
            "Publication year": 2012,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/2213836.2213942",
            "Abstract": "Cloud computing has emerged as a promising environment capable of providing flexibility, scalability, elasticity, fail-over mechanisms, high availability, and other important features to applications. Compute clusters are relatively easy to create and use, but tools to effectively share cluster resources are lacking. CloudAlloc addresses this problem and schedules workloads to cluster resources using allocation algorithms that can be easily changed according to the objectives of the enterprise. It also monitors resource utilization and thus, provides accountability for actual usage. CloudAlloc is a lightweight, flexible, easy-to-use tool for cluster resource allocation that has also proved useful as a research platform. We demonstrate its features and also discuss its allocation algorithms that minimize power usage. CloudAlloc was implemented and is in use at HP Labs.",
            "Abstract entirety": 1,
            "Author pub id": "qUBdmWgAAAAJ:B3FOqHPlNUQC",
            "Publisher": "Unknown"
        },
        {
            "Title": "New trends on exploratory methods for data analytics",
            "Publication year": 2017,
            "Publication url": "https://dl.acm.org/doi/abs/10.14778/3137765.3137824",
            "Abstract": "Data usually comes in a plethora of formats and dimensions, rendering the exploration and information extraction processes cumbersome. Thus, being able to cast exploratory queries in the data with the intent of having an immediate glimpse on some of the data properties is becoming crucial. An exploratory query should be simple enough to avoid complicate declarative languages (such as SQL) and mechanisms, and at the same time retain the flexibility and expressiveness of such languages. Recently, we have witnessed a rediscovery of the so called example-based methods, in which the user, or the analyst circumvent query languages by using examples as input. An example is a representative of the intended results, or in other words, an item from the result set. Example-based methods exploit inherent characteristics of the data to infer the results that the user has in mind, but may not able to (easily) express \u2026",
            "Abstract entirety": 0,
            "Author pub id": "qUBdmWgAAAAJ:q3CdL3IzO_QC",
            "Publisher": "VLDB Endowment"
        },
        {
            "Title": "Self-organizing energy aware clustering of nodes in sensor networks using relevant attributes",
            "Publication year": 2010,
            "Publication url": "http://dit.unitn.it/~themis/publications/sensorkdd10.pdf",
            "Abstract": "Physical clustering of nodes in sensor networks aims at grouping together sensor nodes according to some similarity criteria like neighborhood. Out of each group, one selected node will be the group representative for forwarding the data collected by its group. This considerably reduces the total energy consumption, as only representatives need to communicate with distant data sink. In data mining, one is interested in constructing these physical clusters according to similar measurements of sensor nodes. Previous data mining approaches for physical clustering concentrated on the similarity over all dimensions of measurements.We propose ECLUN, an energy aware method for physical clustering of sensor nodes based on both spatial and measurements similarities. Our approach uses a novel method for constructing physical clusters according to similarities over some dimensions of the measured data. In an unsupervised way, our method maintains physical clusters and detects outliers. Through extensive experiments on synthetic and real world data sets, we show that our approach outperforms a competing state-of-the-art technique in both the amount of consumed energy and the effectiveness of detecting changes in the sensor network. Thus, we achieve an overall significantly better life times of sensor networks, while still following changes of observed phenomena.",
            "Abstract entirety": 1,
            "Author pub id": "qUBdmWgAAAAJ:dfsIfKJdRG4C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Local pair and bundle discovery over co-evolving time series",
            "Publication year": 2019,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/3340964.3340982",
            "Abstract": "Time series exploration and mining has many applications across several industrial and scientific domains. In this paper, we consider the problem of detecting locally similar pairs and groups, called bundles, over co-evolving time series. These are pairs or groups of subsequences whose values do not differ by more than \u03b5 for at least \u03b4 consecutive timestamps, thus indicating common local patterns and trends. We first present a baseline algorithm that performs a sweep line scan across all timestamps to identify matches. Then, we propose a filter-verification technique that only examines candidate matches at judiciously chosen checkpoints across time. Specifically, we introduce two block scanning algorithms for discovering local pairs and bundles respectively, which leverage the potential of checkpoints to aggressively prune the search space. We experimentally evaluate our methods against real-world and \u2026",
            "Abstract entirety": 0,
            "Author pub id": "qUBdmWgAAAAJ:fbc8zXXH2BUC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Towards a framework for detecting and managing opinion contradictions",
            "Publication year": 2011,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/6137522/",
            "Abstract": "Sentiment Analysis gains in interest due to the large amount of potential applications and the increasing number of opinions expressed in particular in the Web. The focus of this paper is the development of a framework on top of sentiment analysis for detecting contradictions. First, we introduce a statistical model of contradictions based on a mean value and the variance of sentiments among different posts. It can be used to analyze and track sentiment evolution over time, to identify interesting trends and patterns or even to enable argument extraction. Using synthetic datasets, we demonstrate the effectiveness of our method in capturing contradictions on noisy data. Inspired by this model, which has proven to be effective and efficient for numeric sentiments, we are trying to generalize it for arbitrary opinion data and outline a universal framework which can be efficiently used on a large scale. We discuss various \u2026",
            "Abstract entirety": 0,
            "Author pub id": "qUBdmWgAAAAJ:XiSMed-E-HIC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Comparing similarity perception in time series visualizations",
            "Publication year": 2018,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/8440826/",
            "Abstract": "A common challenge faced by many domain experts working with time series data is how to identify and compare similar patterns. This operation is fundamental in high-level tasks, such as detecting recurring phenomena or creating clusters of similar temporal sequences. While automatic measures exist to compute time series similarity, human intervention is often required to visually inspect these automatically generated results. The visualization literature has examined similarity perception and its relation to automatic similarity measures for line charts, but has not yet considered if alternative visual representations, such as horizon graphs and colorfields, alter this perception. Motivated by how neuroscientists evaluate epileptiform patterns, we conducted two experiments that study how these three visualization techniques affect similarity perception in EEG signals. We seek to understand if the time series results \u2026",
            "Abstract entirety": 0,
            "Author pub id": "qUBdmWgAAAAJ:IUKN3-7HHlwC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Top-k nearest neighbor search in uncertain data series",
            "Publication year": 2014,
            "Publication url": "https://dl.acm.org/doi/abs/10.14778/2735461.2735463",
            "Abstract": "Many real applications consume data that is intrinsically uncertain, noisy and error-prone. In this study, we investigate the problem of finding the top-k nearest neighbors in uncertain data series, which occur in several different domains. We formalize the top-k nearest neighbor problem for uncertain data series, and describe a model for uncertain data series that captures both uncertainty and correlation. This distinguishes our approach from prior work that compromises the accuracy of the model by assuming independence of the value distribution at neighboring time-stamps. We introduce the Holistic-PkNN algorithm, which uses novel metric bounds for uncertain series and an efficient refinement strategy to reduce the overall number of required probability estimates. We evaluate our proposal under a variety of settings using a combination of synthetic and 45 real datasets from diverse domains. The results \u2026",
            "Abstract entirety": 0,
            "Author pub id": "qUBdmWgAAAAJ:ZuybSZzF8UAC",
            "Publisher": "VLDB Endowment"
        },
        {
            "Title": "Online Distribution Estimation for Streaming Data: Framework and Applications.",
            "Publication year": 2007,
            "Publication url": "http://dit.unitn.it/~themis/publications/sebd07.pdf",
            "Abstract": "In the last few years, we have been witnessing an evergrowing need for continuous observation and monitoring applications. This need is driven by recent technological advances that have made streaming applications possible, and by the fact that analysts in various domains have realized the value that such applications can provide.In this paper, we propose a general framework for computing efficiently an approximation of multi-dimensional distributions of streaming data. This framework enables the development of a wide variety of complex streaming applications. In addition, we demonstrate how our framework can operate in a distributed fashion, thus, making better use of the available resources. We motivate our techniques using two concrete problems, both in the challening context of resource-constrained sensor networks. The first problem is outlier detection, while the second is detection and tracking of homogeneous regions. Experiments with synthetic and real data show that our method is efficient and accurate, and compares favorably to other proposed techniques for both the problems that we studied.",
            "Abstract entirety": 1,
            "Author pub id": "qUBdmWgAAAAJ:O3NaXMp0MMsC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Georgios Chatzigeorgakidis",
            "Publication year": 2021,
            "Publication url": "https://openproceedings.org/2021/conf/edbt/p63.pdf",
            "Abstract": "We address the problem of subsequence search in time series using Chebyshev distance, to which we refer as twin subsequence search. We first show how existing time series indices can be extended to perform twin subsequence search. Then, we introduce TS-Index, a novel index tailored to this problem. Our experimental evaluation compares these approaches against real time series datasets, and demonstrates that TS-Index can retrieve twin subsequences much faster under various query conditions.",
            "Abstract entirety": 1,
            "Author pub id": "qUBdmWgAAAAJ:WC23djZS0W4C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Adaptivity in entity subscription services",
            "Publication year": 2009,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/5359556/",
            "Abstract": "Real-word entities can be mapped to unique entity identifiers through an Entity Name System (ENS), to systematically support the re-use of these identifiers and disambiguate references to real world entities in the Web. An entity subscription service informs subscribed users of changes in the descriptive data of an entity, which is a set of attribute name-value pairs. We study the design, implementation and application of an adaptable push-policy subscription service, within a large-scale ENS. The subscription system aims to deliver ranked descriptions of the changes on entities, following user preferences through a feedback-driven adaptation process. The adaptation is based on both the content and the type of each entity change. We evaluate the learning curve of the system and the utility of the content-type discrimination. The experiments demonstrate good results, especially in the system's content-aware \u2026",
            "Abstract entirety": 0,
            "Author pub id": "qUBdmWgAAAAJ:RGFaLdJalmkC",
            "Publisher": "IEEE"
        },
        {
            "Title": "New trends in databases and information systems: Contributions from adbis 201",
            "Publication year": 2014,
            "Publication url": "https://elibrary.ru/item.asp?id=24050752",
            "Abstract": "AIT AMEUR Y. 1, ANDRZEJEWSKI W. 2, BELLATRECHE L. 3, CATANIA B. 4, GUERRINI G. 4, CERQUITELLI T. 5, CHIUSANO S. 5, GOLFARELLI M. 6, RIZZI S. 6, KACZMARSKI K. 7, K \u00d6 MPF M. 8, KEMPER A. 9, LAUER T. 10, NOVIKOV B. 11, PALPANAS T. 12, POKORNY J. 13, VAKALI A. 14",
            "Abstract entirety": 1,
            "Author pub id": "qUBdmWgAAAAJ:PVgj2kMGcgYC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Finding interesting correlations with conditional heavy hitters",
            "Publication year": 2013,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/6544898/",
            "Abstract": "The notion of heavy hitters-items that make up a large fraction of the population - has been successfully used in a variety of applications across sensor and RFID monitoring, network data analysis, event mining, and more. Yet this notion often fails to capture the semantics we desire when we observe data in the form of correlated pairs. Here, we are interested in items that are conditionally frequent: when a particular item is frequent within the context of its parent item. In this work, we introduce and formalize the notion of Conditional Heavy Hitters to identify such items, with applications in network monitoring, and Markov chain modeling. We introduce several streaming algorithms that allow us to find conditional heavy hitters efficiently, and provide analytical results. Different algorithms are successful for different input characteristics. We perform experimental evaluations to demonstrate the efficacy of our methods, and \u2026",
            "Abstract entirety": 0,
            "Author pub id": "qUBdmWgAAAAJ:mvPsJ3kp5DgC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Resource sharing in computer clusters according to objectives",
            "Publication year": 2015,
            "Publication url": "https://patents.google.com/patent/US8972579B2/en",
            "Abstract": "A method of assigning resources of a computer duster with resource sharing according to objectives. The method includes monitoring resources of each of a plurality of cloud nodes, providing information descriptive of the cloud node resources, receiving a reservation, determining whether resources are available to satisfy the reservation and any other pending reservations, if resources are available, using a rapid search to determine resource assignments for the reservation and any other pending reservations according to one or more objectives, and allocating resources according to the resource assignments.",
            "Abstract entirety": 1,
            "Author pub id": "qUBdmWgAAAAJ:35r97b3x0nAC",
            "Publisher": "Unknown"
        },
        {
            "Title": "An overview of end-to-end entity resolution for big data",
            "Publication year": 2020,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/3418896",
            "Abstract": "One of the most critical tasks for improving data quality and increasing the reliability of data analytics is Entity Resolution (ER), which aims to identify different descriptions that refer to the same real-world entity. Despite several decades of research, ER remains a challenging problem. In this survey, we highlight the novel aspects of resolving Big Data entities when we should satisfy more than one of the Big Data characteristics simultaneously (i.e., Volume and Velocity with Variety). We present the basic concepts, processing steps, and execution strategies that have been proposed by database, semantic Web, and machine learning communities in order to cope with the loose structuredness, extreme diversity, high speed, and large scale of entity descriptions used by real-world applications. We provide an end-to-end view of ER workflows for Big Data, critically review the pros and cons of existing methods, and \u2026",
            "Abstract entirety": 0,
            "Author pub id": "qUBdmWgAAAAJ:lgwcVrK6X84C",
            "Publisher": "ACM"
        },
        {
            "Title": "Density-based projected clustering over high dimensional data streams",
            "Publication year": 2012,
            "Publication url": "https://epubs.siam.org/doi/abs/10.1137/1.9781611972825.85",
            "Abstract": "Clustering of high dimensional data streams is an important problem in many application domains, a prominent example being network monitoring. Several approaches have been lately proposed for solving independently the different aspects of the problem. There exist methods for clustering over full dimensional streams and methods for finding clusters in subspaces of high dimensional static data. Yet only a few approaches have been proposed so far which tackle both the stream and the high dimensionality aspects of the problem simultaneously. In this work, we propose a new density-based projected clustering algorithm, HDDSTREAM, for high dimensional data streams. Our algorithm summarizes both the data points and the dimensions where these points are grouped together and maintains these summaries online, as new points arrive over time and old points expire due to ageing. Our experimental results \u2026",
            "Abstract entirety": 0,
            "Author pub id": "qUBdmWgAAAAJ:tOudhMTPpwUC",
            "Publisher": "Society for Industrial and Applied Mathematics"
        },
        {
            "Title": "WeBrowse: Leveraging User Clicks for Content Discovery in Communities of a Place",
            "Publication year": 2017,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/3134728",
            "Abstract": "One of the limits of web content discovery tools, let them be recommender systems or content curation tools such as social rating, social bookmarking and other social media, is the scarcity of user input (e.g. rate, submit, share). This problem is even worse in the case of what we call communities of a place: people who study, live or work at the same place. Such people often share common interests but either do not know each other or fail to actively engage in submitting and relaying information. In this paper, we investigate the feasibility of using the aggregated clicks of entire communities of users to passively emulate a content curation service a la Reddit. To this end, we prototype and deploy WeBrowse, a content curation service based on the processing of raw HTTP logs. Evaluation based on our deployments demonstrates feasibility at scale while respecting user privacy. The majority of WeBrowse's users \u2026",
            "Abstract entirety": 0,
            "Author pub id": "qUBdmWgAAAAJ:0izLItjtcgwC",
            "Publisher": "ACM"
        },
        {
            "Title": "A systematic approach for dynamic targeted monitoring of KPIs.",
            "Publication year": 2014,
            "Publication url": "http://disi.unitn.it/~themis/publications/cascon14.pdf",
            "Abstract": "There has been growing interest for more than a decade in Business Analytics as a means for improving business performance. One of the most popular Business Analytics technique involves monitoring performance by means of Key Performance Indicators (KPIs). A KPI is a powerful tool that relates enterprise data to business goals, thereby enabling managers to guide the analytic process and identify deviations in their strategic plan. Nevertheless, monitoring KPIs requires that they are evaluated at multiple levels of detail, in order to identify potential problems earlier instead of being noted after the fact. Unfortunately, there are obstacles to the generation and enactment of such monitoring processes. In particular, there is no systematic, tool-supported process for defining what is to be monitored given a strategic plan, nor are there tools for automatically generating monitoring queries. As a result, monitoring consists of a manual process whereby queries are generated for high level indicators across a few scorecards and dashboards. In this paper we present a systematic semi-automatic approach that covers the entire monitoring process. Our approach performs a par-",
            "Abstract entirety": 1,
            "Author pub id": "qUBdmWgAAAAJ:PR6Y55bgFSsC",
            "Publisher": "Unknown"
        },
        {
            "Title": "New Trends in Databases and Information Systems: Contributions from ADBIS 2013",
            "Publication year": 2014,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-319-01863-8_1",
            "Abstract": "Research on database and information system technologies has been rapidly evolving over the last few years. Advances concern either new data types, new management issues, and new kind of architectures and systems. The 17th East-European Conference on Advances in Databases and Information Systems (ADBIS 2013), held on September 1\u20134, 2013 in Genova, Italy, and associated satellite events aimed at covering some emerging issues concerning such new trends in database and information system research. The aim of this paper is to present such events, their motivations and topics of interest, as well as briefly outline the papers selected for presentations. The selected papers will then be included in the remainder of this volume.",
            "Abstract entirety": 1,
            "Author pub id": "qUBdmWgAAAAJ:WA5NYHcadZ8C",
            "Publisher": "Springer, Cham"
        },
        {
            "Title": "Matrix profile goes MAD: variable-length motif and discord discovery in data series",
            "Publication year": 2020,
            "Publication url": "https://link.springer.com/article/10.1007/s10618-020-00685-w",
            "Abstract": "In the last 15 years, data series motif and discord discovery have emerged as two useful and well-used primitives for data series mining, with applications to many domains, including robotics, entomology, seismology, medicine, and climatology. Nevertheless, the state-of-the-art motif and discord discovery tools still require the user to provide the relative length. Yet, in several cases, the choice of length is critical and unforgiving. Unfortunately, the obvious brute-force solution, which tests all lengths within a given range, is computationally untenable. In this work, we introduce a new framework, which provides an exact and scalable motif and discord discovery algorithm that efficiently finds all motifs and discords in a given range of lengths. We evaluate our approach with five diverse real datasets, and demonstrate that it is up to 20 times faster than the state-of-the-art. Our results also show that removing the unrealistic \u2026",
            "Abstract entirety": 0,
            "Author pub id": "qUBdmWgAAAAJ:BzfGm06jWhQC",
            "Publisher": "Springer US"
        }
    ]
}]