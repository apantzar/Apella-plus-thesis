[{
    "name": " John Tsotsos",
    "romanize name": " John Tsotsos",
    "School-Department": "Electrical Engineering and Computer Science",
    "University": "York University",
    "Rank": "\u039a\u03b1\u03b8\u03b7\u03b3\u03b7\u03c4\u03ae\u03c2",
    "Apella_id": 9059,
    "Scholar name": "John K. Tsotsos",
    "Scholar id": "Ic6ZXhUAAAAJ",
    "Affiliation": "York University, Canada",
    "Citedby": 17187,
    "Interests": [
        "vision",
        "attention",
        "computer vision",
        "robotics",
        "computational neuroscience"
    ],
    "Scholar url": "https://scholar.google.com/citations?user=Ic6ZXhUAAAAJ&hl=en",
    "Publications": [
        {
            "Title": "Flipped on its Head: Deep Learning-Based Saliency Finds Asymmetry in the Opposite Direction Expected for Singleton Search of Flipped and Canonical Targets",
            "Publication year": 2019,
            "Publication url": "https://jov.arvojournals.org/article.aspx?articleid=2751224",
            "Abstract": "A search asymmetry occurs when it is faster for an observer to find some search target A amongst a set of distractors B than when searching for a target B amongst a set of A distractors. A number of search asymmetries are well-established in humans, but the phenomenon is less well studied by research into computational saliency models. Nevertheless, if these algorithsm are truly representing a component of early human visual attention, they should also be able to account for aspects of human attention beyond simply testing prediction performance on free-viewing fixation datasets (Bruce et al., 2015). Leveraging the recently developed Saliency Model Implementation Library for Experimental Research (SMILER), we devise a set of visual search arrays and test whether learned models of saliency exhibit an asymmetry of performance for targets with a novel flipped orientation over canonically oriented targets. Our \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Ic6ZXhUAAAAJ:LqIPBQt8_ycC",
            "Publisher": "The Association for Research in Vision and Ophthalmology"
        },
        {
            "Title": "Comparing neuronal and behavioral thresholds for spiral motion discrimination",
            "Publication year": 2009,
            "Publication url": "https://journals.lww.com/neuroreport/Fulltext/2009/12090/Comparing_neuronal_and_behavioral_thresholds_for.00009.aspx",
            "Abstract": "As we move, the projection of moving objects on our retinas generates an array of velocity vectors known as optic flow. One class of optic flow is spiral motion, defined by the angle between a local vector direction and the direction of the steepest increase in local speed. By discriminating among such angles, an organism could discern between different flow patterns and effectively interact with the environment. In primates, spiral-selective neurons in medial superior temporal area are thought to provide the substrate for this ability. We found that these cells show higher discrimination thresholds than found behaviorally in humans, suggesting that when discriminating spiral motions the brain integrates information across many of these neurons to achieve its high perceptual performance.",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:tzM49s52ZIMC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Detecting, representing and attending to visual shape",
            "Publication year": 2013,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-1-4471-5195-1_29",
            "Abstract": "The importance of shape detection, representation and recognition is not disputed by any relevant discipline and is an integral part of visual perception by both animals and machines. However, to date, there is no comprehensive theoretical framework of how to deal with visual shape. Here, we present the beginnings of such a framework and attempt to integrate the means to detect, represent and recognize shapes, specifically two-dimensional silhouettes. Of note is the inclusion of an attentional scheme primarily because there is growing evidence that human perception involves such a capacity yet how this might occur is virtually unexamined. Secondarily, the ability to attend to shape and shape elements is central to our ability to not only recognize shapes and objects, but also to reason about shape, solve problems involving shape, manipulate shapes and perform spatial reasoning.",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:k_7cPK9k7w8C",
            "Publisher": "Springer, London"
        },
        {
            "Title": "The Selective Tuning Model of Attention",
            "Publication year": 2005,
            "Publication url": "Unknown",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:CPlVwKnI7G4C",
            "Publisher": "Elsevier"
        },
        {
            "Title": "Optimization of 3-D Active Appearance Models Using the Inverse Compositional Approach: Applications to Cardiac MRI Segmentation",
            "Publication year": 2004,
            "Publication url": "https://www.researchgate.net/profile/John-Tsotsos/publication/265931908_Optimization_of_3-D_Active_Appearance_Models_Using_the_Inverse_Compositional_Approach_Applications_to_Cardiac_MRI_Segmentation/links/54b920a20cf28faced626f81/Optimization-of-3-D-Active-Appearance-Models-Using-the-Inverse-Compositional-Approach-Applications-to-Cardiac-MRI-Segmentation.pdf",
            "Abstract": "We present an efficient algorithm for the fitting of three dimensional (3-D) Active Appearance Models (AAMs) on short axis cardiac MRI, using an extension of the inverse compositional image alignment algorithm that was recently introduced by Matthews and Baker/8/. We demonstrate its applicability for the segmentation of the left ventricle in short axis cardiac MR images. We perform experiments to evaluate the speed and segmentation accuracy of our algorithm on a total of 477 MR images, acquired from/l patients. We observe a 60 fold increase in fitting speed compared to a brute force Gauss-Newton optimization and a segmentation accuracy which agrees well with an independent standard. We conclude that this is an efficient and robust algorithm for left ventricle segmentation using 3-D Active Appearance Models.",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:VaXvl8Fpj5cC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Feature-based attention causes a ring-like modulation of motion direction tuning curves in areas MT and MST of macaques",
            "Publication year": 2018,
            "Publication url": "https://jov.arvojournals.org/article.aspx?articleid=2699957",
            "Abstract": "We previously demonstrated that attention to a motion direction inhibits nearby directions using behavioural measures (Yoo et al., VSS 2017), suggesting feature-based surround suppression (Tsotsos, 2011). In the present study, we extended this finding by recording responses of direction selective neurons in area MT and MST of macaques while they viewed different configurations of two random dot kinematograms (RDKs) presented within a RF. One RDK always moved in the neurons preferred direction (preferred pattern); the other could moved in one of 12 different directions (tuning pattern, 30 step). The animals were cued to attend to the preferred (attend-preferred condition) or tuning pattern (attend-tuning condition) and detected a direction change in the attended pattern while ignoring changes in the unattended pattern. In a third condition (fixation), the animals attended to the fixation point and detected \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Ic6ZXhUAAAAJ:YFIp4goXIpYC",
            "Publisher": "The Association for Research in Vision and Ophthalmology"
        },
        {
            "Title": "Localization of Attended Multi-feature Stimuli: Tracing Back Feed-Forward Activation",
            "Publication year": 2006,
            "Publication url": "Unknown",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:_5tno0g5mFcC",
            "Publisher": "Berlin: Springer-Verlag, 1973-"
        },
        {
            "Title": "Towards social autonomous vehicles: Understanding pedestrian-driver interactions",
            "Publication year": 2018,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/8569324/",
            "Abstract": "Cooperative interaction in traffic is vital for resolving a wide range of ambiguities arising from road users' actions. Autonomous vehicles are no exception and require the ability to understand the intention of road users and communicate with them in order to ensure their safety and maintain traffic flow. In this paper, we address the problem of traffic interaction by analyzing a large sample of pedestrians communicating with drivers. We highlight the ways pedestrians communicate and use a logistic regression model to identify what factors influence communication patterns of pedestrians and how. We also discuss practical challenges regarding the recognizing and understanding of pedestrians' intention and how our theoretical findings can help to solve them. Our analysis suggests that pedestrians predominantly rely on implicit communication cues such as stepping onto the road to transmit their intention of crossing. In \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Ic6ZXhUAAAAJ:QhyW1pcpMSYC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Putting Saliency in its Place",
            "Publication year": 2015,
            "Publication url": "https://docs.lib.purdue.edu/modvis/2015/session04/5/",
            "Abstract": "The role of attention and the place within the visual processing stream where the concept of saliency has been situated is critically examined by considering the experimental evidence and performing tests that link experiment to computation.",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:H_jBuBxbQIAC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Motion Estimation Using a General Purpose Neural Network Simulator for Visual Attention",
            "Publication year": 2007,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/4118748/",
            "Abstract": "Motion detection and estimation is a first step in the much larger framework of attending to visual motion based on Selective Tuning Model of Visual Attention (Tsotsos, et al., 2002). In order to be able to detect and estimate complex motion in a hierarchical system it is necessary to use robust and efficient methods which encapsulate as much information as possible about the motion together with a measure of reliability of that information. One such method is the orientation tensor formalism which incorporates a confidence measure that propagates into subsequent processing steps. The tensor method is implemented in a neural network simulator which allows distributed processing and visualization of results. As output we obtain information about the moving objects from the scene",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:_axFR9aDTf0C",
            "Publisher": "IEEE"
        },
        {
            "Title": "Saliency, attention, and visual search: An information theoretic approach",
            "Publication year": 2009,
            "Publication url": "https://jov.arvojournals.org/article.aspx?articleid=2193531",
            "Abstract": "A proposal for saliency computation within the visual cortex is put forth based on the premise that localized saliency computation serves to maximize information sampled from one's environment. The model is built entirely on computational constraints but nevertheless results in an architecture with cells and connectivity reminiscent of that appearing in the visual cortex. It is demonstrated that a variety of visual search behaviors appear as emergent properties of the model and therefore basic principles of coding and information transmission. Experimental results demonstrate greater efficacy in predicting fixation patterns across two different data sets as compared with competing models.",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:9yKSN-GCB0IC",
            "Publisher": "The Association for Research in Vision and Ophthalmology"
        },
        {
            "Title": "Visual search for an object in a 3D environment using a mobile robot",
            "Publication year": 2010,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S1077314210000378",
            "Abstract": "Consider the problem of visually finding an object in a mostly unknown space with a mobile robot. It is clear that all possible views and images cannot be examined in a practical system. Visual attention is a complex phenomenon; we view it as a mechanism that optimizes the search processes inherent in vision (Tsotsos, 2001; Tsotsos et al., 2008) [1], [2]. Here, we describe a particular example of a practical robotic vision system that employs some of these attentive processes. We cast this as an optimization problem, i.e., optimizing the probability of finding the target given a fixed cost limit in terms of total number of robotic actions required to find the visual target. Due to the inherent intractability of this problem, we present an approximate solution and investigate its performance and properties. We conclude that our approach is sufficient to solve this problem and has additional desirable empirical characteristics.",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:NaGl4SEjCO4C",
            "Publisher": "Academic Press"
        },
        {
            "Title": "AND SPATIAL-FREQUENCY",
            "Publication year": 2012,
            "Publication url": "https://books.google.com/books?hl=en&lr=&id=90PuBwAAQBAJ&oi=fnd&pg=PA305&dq=info:mqLMCrO8wb4J:scholar.google.com&ots=6xlnFbVtHr&sig=7jS6ivcum5jsG32caSh8tnCYKVk",
            "Abstract": "Rather than build a stereopsis model based upon determining correspondences between sophisticated monocular features such as zero-crossings or peaks in band-pass versions of the monocular input, we propose that disparity detectors should be constructed that act directly upon band-pass versions of the monocular inputs. Building upon the results of these disparity detectors, we show that a simple surface model based on object cohesiveness and local planarity across a range of spatial-frequency tuned channels can be used to reduce false matches. The resulting local planar surface support could be used to segment the image into planar regions in depth. Due to the independent nature of both the disparity detection and local planar support mechanism, this method is capable of dealing with both opaque and transparent stimuli.",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:4xIGDXbuNMYC",
            "Publisher": "Springer Science & Business Media"
        },
        {
            "Title": "attention and performance in computer vision",
            "Publication year": 2005,
            "Publication url": "https://dl.acm.org/doi/abs/10.5555/1120076.1120077",
            "Abstract": "Special issue: attention and performance in computer vision: Computer Vision and Image \nUnderstanding: Vol 100, No 1-2 ACM Digital Library home ACM home Google, Inc. (search) \nAdvanced Search Browse About Sign in Register Advanced Search Journals Magazines \nProceedings Books SIGs Conferences People More Search ACM Digital Library SearchSearch \nAdvanced Search Computer Vision and Image Understanding Periodical Home Latest Issue \nArchive Authors Affiliations Award Winners More HomeBrowse by TitlePeriodicalsComputer \nVision and Image UnderstandingVol. , No. -2Special issue: attention and performance in \ncomputer vision article Special issue: attention and performance in computer vision Share on \nAuthors: Lucas Paletta profile image Lucas Paletta Graz, Austria Graz, Austria View Profile , John \nKonstantine Tsotsos profile image John K. Tsotsos Toronto, Canada Toronto, Canada View , -\u2026",
            "Abstract entirety": 0,
            "Author pub id": "Ic6ZXhUAAAAJ:4hFrxpcac9AC",
            "Publisher": "Elsevier Science Inc."
        },
        {
            "Title": "Benchmark for evaluating pedestrian action prediction",
            "Publication year": 2021,
            "Publication url": "https://openaccess.thecvf.com/content/WACV2021/html/Kotseruba_Benchmark_for_Evaluating_Pedestrian_Action_Prediction_WACV_2021_paper.html",
            "Abstract": "Pedestrian action prediction has been a topic of active research in recent years resulting in many new algorithmic solutions. However, measuring the overall progress towards solving this problem is difficult due to the lack of publicly available benchmarks and common training and evaluation procedures. To this end, we introduce a benchmark based on two public datasets for pedestrian behavior understanding. Using the proposed evaluation procedures, we rank a number of baseline and state-of-the-art models and analyze their performance with respect to various properties of the data. Based on these findings we propose a new model for pedestrian crossing action prediction that uses attention mechanisms to effectively combine implicit and explicit features and demonstrate new state-of-the-art results. The code for models and evaluation is available at https://github. com/ykotseruba/PedestrianActionBenchmark.",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:WEZ36b6n6v0C",
            "Publisher": "Unknown"
        },
        {
            "Title": "What Does it Mean to Better Attend?",
            "Publication year": 2014,
            "Publication url": "https://jov.arvojournals.org/article.aspx?articleid=2144392",
            "Abstract": "We present a proposal to answer: how could an agent learn to better attend to the relevant and ignore the irrelevant in the context of performing visual tasks? To answer this, attention is defined as in Tsotsos (2011): Attention is the set of mechanisms that tune and control the search processes inherent in perception and cognition, dynamically adapting a general purpose processor to the input and task of the moment. To improve one's attention means that tuning and search control become more effective, eg, task performance shows improvements in speed and accuracy. The link between this definition of attention and such improvements lies in the computational foundations underlying the Selective Tuning (ST) attentional theory, namely computational complexity (Tsotsos et al. 1995; Tsotsos 1990, 2011). Suppose one compares two algorithms, both effective for the same problem. The one with lower time complexity \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Ic6ZXhUAAAAJ:qE4H1tSSYIIC",
            "Publisher": "The Association for Research in Vision and Ophthalmology"
        },
        {
            "Title": "Do Saliency Models Detect Odd-One-Out Targets? New Datasets and Evaluations",
            "Publication year": 2019,
            "Publication url": "https://arxiv.org/abs/2005.06583",
            "Abstract": "Recent advances in the field of saliency have concentrated on fixation prediction, with benchmarks reaching saturation. However, there is an extensive body of works in psychology and neuroscience that describe aspects of human visual attention that might not be adequately captured by current approaches. Here, we investigate singleton detection, which can be thought of as a canonical example of salience. We introduce two novel datasets, one with psychophysical patterns and one with natural odd-one-out stimuli. Using these datasets we demonstrate through extensive experimentation that nearly all saliency algorithms do not adequately respond to singleton targets in synthetic and natural images. Furthermore, we investigate the effect of training state-of-the-art CNN-based saliency models on these types of stimuli and conclude that the additional training data does not lead to a significant improvement of their ability to find odd-one-out targets. Datasets are available at http://data.nvision2.eecs.yorku.ca/P3O3/.",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:AY-FHVasAVwC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Tracking Active Observers in 3D Visuo-Cognitive Tasks",
            "Publication year": 2021,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/3450341.3458496",
            "Abstract": "Most past and present research in computer vision involves passively observed data. Humans, however, are active observers in real life; they explore, search, select what and how to look. In this work, we present a psychophysical experimental setup for active, visual observation in a 3D world dubbed PESAO. The goal was to design PESAO for various active perception tasks with human subjects (active observers) capable of tracking the head and gaze.",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:_lZPlZTPtRIC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Active vision for door localization and door opening using playbot: A computer controlled wheelchair for people with mobility impairments",
            "Publication year": 2008,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/4562088/",
            "Abstract": "Playbot is a long-term, large-scale research project, whose goal is to provide a vision-based computer controlled wheelchair that enables children and adults with mobility impairments to become more independent. Within this context, we show how Playbot can actively search an indoor environment to localize a door, approach the door, use a mounted robotic arm to open the door, and go through the door, using exclusively vision-based sensors and without using a map of the environment. We demonstrate the effectiveness of active vision for localizing objects that are too large to fall within a single camerapsilas field of view and show that well-calibrated vision-based sensors are sufficient to safely pass through a door frame that is narrow enough to tolerate a wheelchair localization error of at most a few centimetres. We provide experimental results demonstrating near perfect performance in an indoor environment.",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:u_35RYKgDlwC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Activation of area MT/V5 and the right inferior parietal cortex during the discrimination of transient direction changes in translational motion",
            "Publication year": 2007,
            "Publication url": "https://academic.oup.com/cercor/article-abstract/17/7/1733/412589",
            "Abstract": "The perception of changes in the direction of objects that translate in space is an important function of our visual system. Here we investigate the brain electrical phenomena underlying such a function by using a combination of magnetoencephalography (MEG) and magnetic resonance imaging. We recorded MEG-evoked responses in 9 healthy human subjects while they discriminated the direction of a transient change in a translationally moving random dot pattern presented either to the right or to the left of a central fixation point. We found that responses reached their maximum in 2 main regions corresponding to motion processing area middle temporal (MT)/V5 contralateral to the stimulated visual field, and to the right inferior parietal lobe (rIPL). The activation latencies were very similar in both regions (\u223c135 ms) following the direction change onset. Our findings suggest that area MT/V5 provides the \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Ic6ZXhUAAAAJ:R3hNpaxXUhUC",
            "Publisher": "Oxford University Press"
        },
        {
            "Title": "Selective Segmentation Networks Using Top-Down Attention",
            "Publication year": 2020,
            "Publication url": "https://arxiv.org/abs/2002.01125",
            "Abstract": "Convolutional neural networks model the transformation of the input sensory data at the bottom of a network hierarchy to the semantic information at the top of the visual hierarchy. Feedforward processing is sufficient for some object recognition tasks. Top-Down selection is potentially required in addition to the Bottom-Up feedforward pass. It can, in part, address the shortcoming of the loss of location information imposed by the hierarchical feature pyramids. We propose a unified 2-pass framework for object segmentation that augments Bottom-Up \\convnets with a Top-Down selection network. We utilize the top-down selection gating activities to modulate the bottom-up hidden activities for segmentation predictions. We develop an end-to-end multi-task framework with loss terms satisfying task requirements at the two ends of the network. We evaluate the proposed network on benchmark datasets for semantic segmentation, and show that networks with the Top-Down selection capability outperform the baseline model. Additionally, we shed light on the superior aspects of the new segmentation paradigm and qualitatively and quantitatively support the efficiency of the novel framework over the baseline model that relies purely on parametric skip connections.",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:trmuqZugEg0C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Integrating Stereo Vision with a CNN Tracker for a Person-Following Robot",
            "Publication year": 2017,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-319-68345-4_27",
            "Abstract": "In this paper, we introduce a stereo vision based CNN tracker for a person following robot. The tracker is able to track a person in real-time using an online convolutional neural network. Our approach enables the robot to follow a target under challenging situations such as occlusions, appearance changes, pose changes, crouching, illumination changes or people wearing the same clothes in different environments. The robot follows the target around corners even when it is momentarily unseen by estimating and replicating the local path of the target. We build an extensive dataset for person following robots under challenging situations. We evaluate the proposed system quantitatively by comparing our tracking approach with existing real-time tracking algorithms.",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:caH3YpRUWsIC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Attentional blink as a product of attentional control signals: A computational investigation",
            "Publication year": 2017,
            "Publication url": "https://jov.arvojournals.org/article.aspx?articleid=2652064",
            "Abstract": "Although there are several different hypotheses regarding the origin of attentional blink, including interference, inhibition, and attentional capacity based explanations, largely, there have been few attempts to cohesively understand attentional blink from a single unified visual-attentive processing model. In the current work we have chosen Cognitive Programs model of visual processing (Tsotsos et al, 2014) in order to illustrate how attentional blink arises from executive control signals of visual-attentive module and visual working memory module. We have computationally simulated the rapid serial visual presentation (RSVP) tasks detailed in Raymond et al.(1992) using letters and oriented bars in order to capture important features of attentional blink. The novel aspect of our work is that in our work attentional blink arises as a by-product of visual processing and attentive control other than less parsimonious accounts \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Ic6ZXhUAAAAJ:AYaE08C4-t8C",
            "Publisher": "The Association for Research in Vision and Ophthalmology"
        },
        {
            "Title": "Action-Oriented Models of Cognitive Processing: A Little Less Cogitation, a Little More Action Please",
            "Publication year": 2016,
            "Publication url": "Unknown",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:lEqHes_HPG0C",
            "Publisher": "MIT Press"
        },
        {
            "Title": "From foundational principles to a hierarchical selection circuit for attention",
            "Publication year": 2001,
            "Publication url": "https://books.google.com/books?hl=en&lr=&id=pdYdyQwlnt0C&oi=fnd&pg=PA285&dq=info:YVrtb4GBNM4J:scholar.google.com&ots=iMPdcvQldj&sig=CdcgsY_cMrEi1v-2upKfBwhhmbM",
            "Abstract": "The work described in this chapter spans theoretical considerations, a computer model of cortical circuits applied to real-world scenes, and human psychophysics used to test model predictions. The theoretical work initially addressed the question \u201cIs there a computational justification for attentive selection?\u201d The obvious answer that has been given many times since at least Broadbent\u2014that the brain is not large enough to process all the incoming stimuli\u2014is hardly satisfactory. This answer is not quantitative, and provides no constraints on what processing system might be sufficient. Tsotsos (1989) employed methods from computational complexity theory to formally prove for the first time that purely data-directed visual search in its most general form is an intractable problem in any realization. He claimed that search is ubiquitous in vision, and thus purely data-directed visual pro-cessing is also intractable in general. His analyses provided important constraints on visual processing mechanisms and led to a specific (not necessarily unique or optimal) solution for visual perception. The constraints arose because vision was cast as a search problem, and because the combinatorics of search is too large at each stage of analysis. Attentive selection turns out to be a powerful heuristic to limit search and make the overall problem tractable.Attention is an important mechanism at any level of processing where one finds a many-to-one convergence of neural inputs, and thus potential stimulus interference, a conclusion reached by Tsotsos (1990). This was disputed at first (Desimone, 1990); however, more recent experimental work would appear to be \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Ic6ZXhUAAAAJ:M3NEmzRMIkIC",
            "Publisher": "MIT Press"
        },
        {
            "Title": "Multiplicative modulations in hue-selective cells enhance unique hue representation",
            "Publication year": 2019,
            "Publication url": "https://arxiv.org/abs/1907.02116",
            "Abstract": "There is still much to understand about the color processing mechanisms in the brain and the transformation from cone-opponent representations to perceptual hues. Moreover, it is unclear which areas(s) in the brain represent unique hues. We propose a hierarchical model inspired by the neuronal mechanisms in the brain for local hue representation, which reveals the contributions of each visual cortical area in hue representation. Local hue encoding is achieved through incrementally increasing processing nonlinearities beginning with cone input. Besides employing nonlinear rectifications, we propose multiplicative modulations as a form of nonlinearity. Our simulation results indicate that multiplicative modulations have significant contributions in encoding of hues along intermediate directions in the MacLeod-Boynton diagram and that model V4 neurons have the capacity to encode unique hues. Additionally, responses of our model neurons resemble those of biological color cells, suggesting that our model provides a novel formulation of the brain's color processing pathway.",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:kSfMFMOdMMkC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Fifth international cognitive vision workshop (ICVW 2009) categorization, attention and embodiment",
            "Publication year": 2009,
            "Publication url": "https://dl.acm.org/doi/abs/10.5555/1733343.1733349",
            "Abstract": "Fifth international cognitive vision workshop (ICVW 2009) categorization, attention and \nembodiment | Proceedings of the 2009 IEEE/RSJ international conference on Intelligent robots \nand systems ACM Digital Library home ACM home Google, Inc. (search) Advanced Search \nBrowse About Sign in Register Advanced Search Journals Magazines Proceedings Books \nSIGs Conferences People More Search ACM Digital Library SearchSearch Advanced Search \nBrowse Browse Digital Library Collections More HomeBrowse by TitleProceedingsIROS'09Fifth \ninternational cognitive vision workshop (ICVW 2009) categorization, attention and embodiment \nARTICLE Fifth international cognitive vision workshop (ICVW 2009) categorization, attention \nand embodiment Share on Authors: Barbara Caputo profile image Barbara Caputo View \nProfile , John Konstantine Tsotsos profile image John Tsotsos View Profile , Giorgio Metta Info \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Ic6ZXhUAAAAJ:OzeSX8-yOCQC",
            "Publisher": "Unknown"
        },
        {
            "Title": "A novel algorithm for fitting 3-D active appearance models: Applications to cardiac MRI segmentation",
            "Publication year": 2005,
            "Publication url": "https://link.springer.com/chapter/10.1007/11499145_74",
            "Abstract": "We present an efficient algorithm for fitting three dimensional (3-D) Active Appearance Models (AAMs). We do so, by introducing a 3-D extension of a recently proposed method that is based on the inverse compositional image alignment algorithm. We demonstrate its applicability for the segmentation of the left ventricle in short axis cardiac MRI. We perform experiments to evaluate the speed and segmentation accuracy of our algorithm on a total of 1473 cardiac MR images acquired from 11 patients. The fitting is around 60 times faster than standard Gauss-Newton optimization, with a segmentation accuracy that is as good as, and often better than Gauss-Newton.",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:CHSYGLWDkRkC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "A human cortical specialization for the processing of velocity gradients in moving stimuli",
            "Publication year": 2004,
            "Publication url": "https://jov.arvojournals.org/article.aspx?articleid=2131525",
            "Abstract": "It is known that the primate visual system possesses neurons specialized in motion processing. Many of these neurons are selective for the direction of translational motion (ie in areas V1, MT) or for the specific arrangement of different motion directions (ie, in areas MST and 7a) in moving random dot patterns (RDP). Some studies have reported that a subset of neurons in monkey area MT is selective for the orientation of velocity gradients (VG) in such patterns. Currently it is unclear whether humans possess a similar specialization. Here, we use event-related fMRI to investigate this issue. In experimental trials, two RDPs moving in the same direction were presented on a computer screen at both sides of a fixation cross during 500ms. Human observers (n= 5) indicated which pattern moved faster. In 1/3th of the trials the RDPs contained a velocity gradient (VG-trials, ie, dots accelerating), in other 1/3th of the trials dots \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Ic6ZXhUAAAAJ:anf4URPfarAC",
            "Publisher": "The Association for Research in Vision and Ophthalmology"
        },
        {
            "Title": "Boundary effects across filter spatial scales",
            "Publication year": 2014,
            "Publication url": "https://link.springer.com/article/10.1186/1471-2202-15-S1-P19",
            "Abstract": "Most saliency algorithms rely on a filter processing stage in which an image is analyzed using a bank of convolution kernels. When applying a convolution to an image, however, a region of pixels with thickness equal to one-half the kernel width at the image border is left undefined due to insufficient input (this undefined region is hereafter referred to as the boundary region). While the percentage of the output image falling within the boundary region is often kept small, this limits the spatial scale of filter which can be applied to the image. There is clear psychophysical evidence from visual search tasks that spatial scale can be used as a component of visual search, with differences in feature size, spatial frequency, and sub-component grouping [1]. Thus, handling filters with dimensions that are significant with respect to the image size is worthwhile if the spatial scale component of visual search is to be effectively \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Ic6ZXhUAAAAJ:isU91gLudPYC",
            "Publisher": "BioMed Central"
        },
        {
            "Title": "Video action recognition for lane-change classification and prediction of surrounding vehicles",
            "Publication year": 2021,
            "Publication url": "https://arxiv.org/abs/2101.05043",
            "Abstract": "In highway scenarios, an alert human driver will typically anticipate early cut-in/cut-out maneuvers of surrounding vehicles using visual cues mainly. Autonomous vehicles must anticipate these situations at an early stage too, to increase their safety and efficiency. In this work, lane-change recognition and prediction tasks are posed as video action recognition problems. Up to four different two-stream-based approaches, that have been successfully applied to address human action recognition, are adapted here by stacking visual cues from forward-looking video cameras to recognize and anticipate lane-changes of target vehicles. We study the influence of context and observation horizons on performance, and different prediction horizons are analyzed. The different models are trained and evaluated using the PREVENTION dataset. The obtained results clearly demonstrate the potential of these methodologies to serve as robust predictors of future lane-changes of surrounding vehicles proving an accuracy higher than 90% in time horizons of between 1-2 seconds.",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:kHL0TBcpPBcC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Totally-Looks-Like: A Dataset and Benchmark of Semantic Image Similarity",
            "Publication year": 2018,
            "Publication url": "https://jov.arvojournals.org/article.aspx?articleid=2699130",
            "Abstract": "Human perception of images goes far beyond objects, shapes, textures and contours. Viewing a scene often elicits recollection of other scenes whose global properties or relations resemble the currently observed one. This relies on a rich representation in image space in the brain, entailing scene structure and semantics, as well as a mechanism to use the representation of an observed scene to recollect similar ones from the profusion of those stored in memory. The recent explosion in the performance and applicability of deep-learning models in all fields of computer vision, including image retrieval and comparison, can tempt one to conclude that the representational power of such methods approaches that of humans. We aim to explore this by testing how deep neural networks fare on the challenge of similarity judgement between pairs of images from a new dataset, dubbed\" Totally-Looks-Like\". It is based on \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Ic6ZXhUAAAAJ:AYV8G9fXOwEC",
            "Publisher": "The Association for Research in Vision and Ophthalmology"
        },
        {
            "Title": "Improved Edge Representation via Early Recurrent Inhibition",
            "Publication year": 2012,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/6233121/",
            "Abstract": "This paper describes a biologically motivated computational model, termed as early recurrent inhibition, to improve edge representation. The computation borrows the idea from the primate visual system that visual features are calculated in the two main visual pathways with different speeds and thus one can positively affect the other via early recurrent mechanisms. Based on the collected results, we conclude such a recurrent processing from area MT to the ventral layers of the primary visual area (V1) may be at play, and hypothesize that one effect of this recurrent mechanism is that V1 responses to high-spatial frequency edges are suppressed by signals sent from MT, leading to a cleaner edge representation. The operation is modeled as a weighted multiplicative inhibition process. Depending on the weighting methods, two types of inhibition are investigated, namely isotropic and anisotropic inhibition. To \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Ic6ZXhUAAAAJ:3NQIlFlcGxIC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Scene Classification in Indoor Environments for  Robots using Context Based Word Embeddings",
            "Publication year": 2018,
            "Publication url": "https://arxiv.org/abs/1908.06422",
            "Abstract": "Scene Classification has been addressed with numerous techniques in computer vision literature. However, with the increasing number of scene classes in datasets in the field, it has become difficult to achieve high accuracy in the context of robotics. In this paper, we implement an approach which combines traditional deep learning techniques with natural language processing methods to generate a word embedding based Scene Classification algorithm. We use the key idea that context (objects in the scene) of an image should be representative of the scene label meaning a group of objects could assist to predict the scene class. Objects present in the scene are represented by vectors and the images are re-classified based on the objects present in the scene to refine the initial classification by a Convolutional Neural Network (CNN). In our approach we address indoor Scene Classification task using a model trained with a reduced pre-processed version of the Places365 dataset and an empirical analysis is done on a real-world dataset that we built by capturing image sequences using a GoPro camera. We also report results obtained on a subset of the Places365 dataset using our approach and additionally show a deployment of our approach on a robot operating in a real-world environment.",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:iwrO-dAzKaMC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Integrating attentional modulation with attentional selection",
            "Publication year": 2013,
            "Publication url": "https://www.eecs.yorku.ca/research/techreports/2013/CSE-2013-07.pdf",
            "Abstract": "Various models of the neural mechanisms of attentional modulation in the visual cortex have been proposed. In general, these models assume that an'attention'parameter is provided separately. Its value as well as the selection of neuron (s) to which it applies are assumed, but its source and the selection mechanism are unspecified. Here we show how the Selective Tuning model of visual attention can account for the modulation of the firing rate at the single neuron level, and for the temporal pattern of attentional modulations in the visual cortex, in a self-contained formulation that simultaneously determines the stimulus elements to be attended while modulating the relevant neural processes.",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:sA9dB-pw3HoC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Selective attention integrates sparse and population codes",
            "Publication year": 2007,
            "Publication url": "Unknown",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:6ZxmRoH8BuwC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Active 3D object localization using a humanoid robot",
            "Publication year": 2010,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/5664805/",
            "Abstract": "We study the problem of actively searching for an object in a three-dimensional (3-D) environment under the constraint of a maximum search time using a visually guided humanoid robot with 26 degrees of freedom. The inherent intractability of the problem is discussed, and a greedy strategy for selecting the best next viewpoint is employed. We describe a target probability updating scheme approximating the optimal solution to the problem, providing an efficient solution to the selection of the best next viewpoint. We employ a hierarchical recognition architecture, inspired by human vision, that uses contextual cues for attending to the view-tuned units at the proper intrinsic scales and for active control of the robotic platform sensor's coordinate frame, which also gives us control of the extrinsic image scale and achieves the proper sequence of pathognomonic views of the scene. The recognition model makes no \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Ic6ZXhUAAAAJ:BrmTIyaxlBUC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Feed-forward visual processing suffices for coarse localization but fine-grained localization in an attention-demanding context needs feedback processing",
            "Publication year": 2019,
            "Publication url": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0223166",
            "Abstract": "It is well known that simple visual tasks, such as object detection or categorization, can be performed within a short period of time, suggesting the sufficiency of feed-forward visual processing. However, more complex visual tasks, such as fine-grained localization may require high-resolution information available at the early processing levels in the visual hierarchy. To access this information using a top-down approach, feedback processing would need to traverse several stages in the visual hierarchy and each step in this traversal takes processing time. In the present study, we compared the processing time required to complete object categorization and localization by varying presentation duration and complexity of natural scene stimuli. We hypothesized that performance would be asymptotic at shorter presentation durations when feed-forward processing suffices for visual tasks, whereas performance would gradually improve as images are presented longer if the tasks rely on feedback processing. In Experiment 1, where simple images were presented, both object categorization and localization performance sharply improved until 100 ms of presentation then it leveled off. These results are a replication of previously reported rapid categorization effects but they do not support the role of feedback processing in localization tasks, indicating that feed-forward processing enables coarse localization in relatively simple visual scenes. In Experiment 2, the same tasks were performed but more attention-demanding and ecologically valid images were used as stimuli. Unlike in Experiment 1, both object categorization performance and localization \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Ic6ZXhUAAAAJ:2K5qSjdd3awC",
            "Publisher": "Public Library of Science"
        },
        {
            "Title": "Saliency based on information maximization",
            "Publication year": 2005,
            "Publication url": "http://cs.umanitoba.ca/~bruce/NIPS2005_0081.pdf",
            "Abstract": "A model of bottom-up overt attention is proposed based on the principle of maximizing information sampled from a scene. The proposed operation is based on Shannon\u2019s self-information measure and is achieved in a neural circuit, which is demonstrated as having close ties with the circuitry existent in the primate visual cortex. It is further shown that the proposed saliency measure may be extended to address issues that currently elude explanation in the domain of saliency based models. Results on natural images are compared with experimental eye tracking data revealing the ef\ufb01cacy of the model in predicting the deployment of overt attention as compared with existing efforts.",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:d1gkVwhDpl0C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Spatiotemporal saliency: Towards a hierarchical representation of visual saliency",
            "Publication year": 2008,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-642-00582-4_8",
            "Abstract": "In prior work, we put forth a model of visual saliency motivated by information theoretic considerations [1]. In this effort we consider how this proposal extends to explain saliency in the spatiotemporal domain and further, propose a distributed representation for visual saliency comprised of localized hierarchical saliency computation. Evidence for the efficacy of the proposal in capturing aspects of human behavior is achieved via comparison with eye tracking data and a discussion of the role of neural coding in the determination of saliency suggests avenues for future research.",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:8AbLer7MMksC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "Probing the Effect of Selection Bias on NN Generalization with a Thought Experiment",
            "Publication year": 2021,
            "Publication url": "https://arxiv.org/abs/2105.09934",
            "Abstract": "Learned networks in the domain of visual recognition and cognition impress in part because even though they are trained with datasets many orders of magnitude smaller than the full population of possible images, they exhibit sufficient generalization to be applicable to new and previously unseen data. Although many have examined issues regarding generalization from several perspectives, we wondered If a network is trained with a biased dataset that misses particular samples corresponding to some defining domain attribute, can it generalize to the full domain from which that training dataset was extracted? It is certainly true that in vision, no current training set fully captures all visual information and this may lead to Selection Bias. Here, we try a novel approach in the tradition of the Thought Experiment. We run this thought experiment on a real domain of visual objects that we can fully characterize and look at specific gaps in training data and their impact on performance requirements. Our thought experiment points to three conclusions: first, that generalization behavior is dependent on how sufficiently the particular dimensions of the domain are represented during training; second, that the utility of any generalization is completely dependent on the acceptable system error; and third, that specific visual features of objects, such as pose orientations out of the imaging plane or colours, may not be recoverable if not represented sufficiently in a training set. Any currently observed generalization in modern deep learning networks may be more the result of coincidental alignments and whose utility needs to be confirmed with respect to a system's \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Ic6ZXhUAAAAJ:1werCE7_32MC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Size of attentional suppressive surround",
            "Publication year": 2015,
            "Publication url": "http://jtl.lassonde.yorku.ca/wp-content/uploads/2015/05/2015VSS_SY.pdf",
            "Abstract": "Size of attentional suppressive surround Orientation < 3D objects (Greebles) Page 1 Size of \nattentional suppressive surround Sang-Ah Yoo 1, 4 , John K. Tsotsos 2, 4 , & Mazyar Fallah 3, \n4, 5 1. Department of Psychology, York University, Toronto, ON, Canada 2. Department of \nEngineering and Computer Science, York University, Toronto, ON, Canada 3. School of \nKinesiology and Health Science, York University, Toronto, ON, Canada 4. Centre for Vision \nResearch, York University, Toronto, ON, Canada 5. Canadian Action and Perception Network, \nYork University, Toronto, ON, Canada # 56.4094 Prediction: \u201cThe SIZE of the (suppressive) \nsurround is determined by the attended neuron. \u2026 The SIZE of that RF is what sets the extent of \nthe surround.\u201d (Tsotsos, 2011) Q. Does the size of attentional suppressive surround change \ndepending on the level of the attended feature in the processing hierarchy? Size of attentional < \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Ic6ZXhUAAAAJ:YB4bud6kWLwC",
            "Publisher": "The Association for Research in Vision and Ophthalmology"
        },
        {
            "Title": "Automatic detection of abnormal gait",
            "Publication year": 2009,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S026288560600357X",
            "Abstract": "Analysing human gait has found considerable interest in recent computer vision research. So far, however, contributions to this topic exclusively dealt with the tasks of person identification or activity recognition. In this paper, we consider a different application for gait analysis and examine its use as a means of deducing the physical well-being of people. Understanding the detection of unusual movement patterns as a two-class problem suggests using support vector machines for classification. We present a homeomorphisms between 2D lattices and binary shapes that provides a robust vector space embedding of segmented body silhouettes. Experimental results demonstrate that feature vectors obtained from this scheme are well suited to detect abnormal gait. Wavering, faltering, and falling can be detected reliably across individuals without tracking or recognising limbs or body parts.",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:xtRiw3GOFMkC",
            "Publisher": "Elsevier"
        },
        {
            "Title": "An Empirical Method to Quantify the Peripheral Performance Degradation in Deep Networks",
            "Publication year": 2020,
            "Publication url": "https://arxiv.org/abs/2012.02749",
            "Abstract": "When applying a convolutional kernel to an image, if the output is to remain the same size as the input then some form of padding is required around the image boundary, meaning that for each layer of convolution in a convolutional neural network (CNN), a strip of pixels equal to the half-width of the kernel size is produced with a non-veridical representation. Although most CNN kernels are small to reduce the parameter load of a network, this non-veridical area compounds with each convolutional layer. The tendency toward deeper and deeper networks combined with stride-based down-sampling means that the propagation of this region can end up covering a non-negligable portion of the image. Although this issue with convolutions has been well acknowledged over the years, the impact of this degraded peripheral representation on modern network behavior has not been fully quantified. What are the limits of translation invariance? Does image padding successfully mitigate the issue, or is performance affected as an object moves between the image border and center? Using Mask R-CNN as an experimental model, we design a dataset and methodology to quantify the spatial dependency of network performance. Our dataset is constructed by inserting objects into high resolution backgrounds, thereby allowing us to crop sub-images which place target objects at specific locations relative to the image border. By probing the behaviour of Mask R-CNN across a selection of target locations, we see clear patterns of performance degredation near the image boundary, and in particular in the image corners. Quantifying both the extent and magnitude \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Ic6ZXhUAAAAJ:LVc8VEQ2EB0C",
            "Publisher": "Unknown"
        },
        {
            "Title": "A Research Roadmap of Cognitive Vision",
            "Publication year": 2005,
            "Publication url": "https://www.academia.edu/download/39927484/A_Research_Roadmap_of_Cognitive_Vision20151112-12865-i6kp3r.pdf",
            "Abstract": "On the 1st March 2002, a European research network for cognitive computer vision systems\u2014ECVision\u2014was inaugurated. This network is funded for three years by the European Commission under the Information Society Technologies (IST) programme as project IST-2001-35454.The goal of ECVision is to promote research, education, and application systems engineering in cognitive computer vision in Europe. It pursues this goal by a variety of means, most of which are based on facilitating peer-to-peer interaction amongst the foremost researchers in the area. The network targets four main activities: research planning, education & training, information dissemination, and industrial liaison. In the research planning area, one of the main goals is to maximize the effectiveness of future research by creating a detailed research agenda: a research roadmap. Research roadmaps are often conceived as a statement of the state-of-the-art in a given discipline accompanied by a prioritized list of problematic issues and a strategy for their investigation. The state-of-the-art survey constitutes a point of departure on the roadmap, the problematic issues constitute the destination, and the strategy the path by which one should proceed to the destination. However, there isn\u2019t clear consensus on the right approach to take in addressing the problems posed by cognitive vision. Consequently, the approach adopted here is one of inclusiveness: we don\u2019t assume that there is a single point of departure, a single destination, and a clearly-mapped path leading from one to the other. Instead, we allow that there are several different destinations (ie types of cognitive vision \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Ic6ZXhUAAAAJ:wkmAz21iQ3gC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Person Following Robot Using Selected Online Ada-Boosting with Stereo Camera",
            "Publication year": 2017,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/8287674/",
            "Abstract": "Person following behavior is an important task for social robots. To enable robots to follow a person, we have to track the target in real-time without critical failures. There are many situations where the robot will potentially loose tracking in a dynamic environment, e.g., occlusion, illumination, pose-changes, etc. Often, people use a complex tracking algorithm to improve robustness. However, the trade-off is that their approaches may not able to run in real-time on mobile robots. In this paper, we present Selected Online Ada-Boosting (SOAB) technique, a modified Online Ada-Boosting (OAB) tracking algorithm with integrated scene depth information obtained from a stereo camera which runs in real-time on a mobile robot. We build and share our results on the performance of our technique on a new stereo dataset for the task of person following. The dataset covers different challenging situations like squatting, partial \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Ic6ZXhUAAAAJ:rlkjS_mI7T0C",
            "Publisher": "IEEE"
        },
        {
            "Title": "An information theoretic model of saliency and visual search",
            "Publication year": 2007,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-540-77343-6_11",
            "Abstract": "In this paper, a proposal which quantifies visual saliency based on an information theoretic definition is evaluated with respect to visual psychophysics paradigms. Analysis reveals that the proposal explains a broad range of results from classic visual search tasks, including many for which only specialized models have had success. As a whole, the results provide strong behavioral support for a model of visual saliency based on information, supplementing earlier work revealing the efficacy of the approach in predicting primate fixation data.",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:geHnlv5EZngC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "Color-opponent mechanisms for local hue encoding in a hierarchical framework",
            "Publication year": 2017,
            "Publication url": "https://arxiv.org/abs/1706.10266",
            "Abstract": "A biologically plausible computational model for color representation is introduced. We present a mechanistic hierarchical model of neurons that not only successfully encodes local hue, but also explicitly reveals how the contributions of each visual cortical layer participating in the process can lead to a hue representation. Our proposed model benefits from studies on the visual cortex and builds a network of single-opponent and hue-selective neurons. Local hue encoding is achieved through gradually increasing nonlinearity in terms of cone inputs to single-opponent cells. We demonstrate that our model's single-opponent neurons have wide tuning curves, while the hue-selective neurons in our model V4 layer exhibit narrower tunings, resembling those in V4 of the primate visual system. Our simulation experiments suggest that neurons in V4 or later layers have the capacity of encoding unique hues. Moreover, with a few examples, we present the possibility of spanning the infinite space of physical hues by combining the hue-selective neurons in our model.",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:3RprE1g1McgC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Agents-supported adaptive group awareness: smart distance and WWWaware",
            "Publication year": 2001,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/952712/",
            "Abstract": "We study how agents can facilitate and mediate interaction, communication, and cooperation among people. We propose the concepts of a smart distance and an awareness network in a distributed collaborative environment. We illustrate the architecture of an agent-mediated collaborative system - the agent-buddy system that can create a sense of group presence and, at the same time, preserve the privacy of each user. Virtual springs systems are used to model the awareness degrees among team members. Each agent makes decisions by considering multiple factors. The goal of the multi-agent team is to minimize the global awareness frustrations with respect to different kinds of tasks. Empirical studies were conducted to analyze the influence of individual behavior on global performance for various kinds of tasks.",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:r0BpntZqJG4C",
            "Publisher": "IEEE"
        },
        {
            "Title": "Sensor planning for 3d visual search with task constraints",
            "Publication year": 2016,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/7801501/",
            "Abstract": "Visual search is a fundamental problem in autonomous robotics. Traditionally, visual search is formulated as an optimization problem in which the sequence of actions ischosen based on immediate efficiency. In this paper we examine the effects of the task constraint in the form of maximum allowable cost on action selection in search. We propose three algorithms, namely Greedy Search with Constraint (GSC),Extended Greedy Search (EGS) and Dynamic Look Ahead Search (DLAS), to investigate which algorithm, whether locally or globally, has the most efficient performance under various conditions with a predefined task constraint. We examine our methods in environments of various sizes and configurations with three cost constraints including time, energy consumption and the distance travelled by the robot. Through extensive experiments on a mobile robot, we show that the environment characteristics as well \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Ic6ZXhUAAAAJ:l8DKPopc-98C",
            "Publisher": "IEEE"
        },
        {
            "Title": "On the Control of Attentional Processes in Vision",
            "Publication year": 2021,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S0010945221000150",
            "Abstract": "The study of attentional processing in vision has a long and deep history. Recently, several papers have presented insightful perspectives into how the coordination of multiple attentional functions in the brain might occur. These begin with experimental observations and the authors propose structures, processes, and computations that might explain those observations. Here, we consider a perspective that past works have not, as a complementary approach to the experimentally-grounded ones. We approach the same problem as past authors but from the other end of the computational spectrum, from the problem nature, as Marr's Computational Level would prescribe. What problem must the brain solve when orchestrating attentional processes in order to successfully complete one of the myriad possible visuospatial tasks at which we as humans excel? The hope, of course, is for the approaches to eventually meet \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Ic6ZXhUAAAAJ:0U2LDkvwOo4C",
            "Publisher": "Elsevier Press"
        },
        {
            "Title": "Attention is more important for visual cognition and reasoning than you think",
            "Publication year": 2018,
            "Publication url": "https://scholar.google.com/scholar?cluster=6973115565650390990&hl=en&oi=scholarr",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:YI35Bd-2PncC",
            "Publisher": "SPRINGER HEIDELBERG"
        },
        {
            "Title": "Attending to a feature results in neighboring within-feature suppression",
            "Publication year": 2009,
            "Publication url": "https://jov.arvojournals.org/article.aspx?articleid=2135586",
            "Abstract": "According to the Selective-Tuning model (Tsotsos, 1990), convergence of neural input and selection of a attended feature will result in surround suppression within that feature domain: the nearby feature values in the same feature dimension will be inhibited, but not the feature values farther away in the dimension. We present three experiments that support this hypothesis. The first experiment used a feature-cue paradigm. The subjects' attention was first attracted to an orientation cue, and then subjects made a perceptual judgment about a stimulus with same or different orientation as the cue. We found that orientation attention actively suppressed the nearby orientations (5\u223c 10 degree from the cue), but did not influence far away orientations (20\u223c 90 degree from the cue), replicating the results of Tombu & Tsotsos (2008). In the second experiment we used the same paradigm but added a distractor to the cue, and \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Ic6ZXhUAAAAJ:ClCfbGk0d_YC",
            "Publisher": "The Association for Research in Vision and Ophthalmology"
        },
        {
            "Title": "Impact of Neuroscience on Data Science for Perception",
            "Publication year": 2019,
            "Publication url": "Unknown",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:e0V1A8vmkmEC",
            "Publisher": "Unknown"
        },
        {
            "Title": "The roles of endstopped and curvature tuned computations in a hierarchical representation of 2D shape",
            "Publication year": 2012,
            "Publication url": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0042058",
            "Abstract": "That shape is important for perception has been known for almost a thousand years (thanks to Alhazen in 1083) and has been a subject of study ever since by scientists and phylosophers (such as Descartes, Helmholtz or the Gestalt psychologists). Shapes are important object descriptors. If there was any remote doubt regarding the importance of shape, recent experiments have shown that intermediate areas of primate visual cortex such as V2, V4 and TEO are involved in analyzing shape features such as corners and curvatures. The primate brain appears to perform a wide variety of complex tasks by means of simple operations. These operations are applied across several layers of neurons, representing increasingly complex, abstract intermediate processing stages. Recently, new models have attempted to emulate the human visual system. However, the role of intermediate representations in the visual cortex and their importance have not been adequately studied in computational modeling. This paper proposes a model of shape-selective neurons whose shape-selectivity is achieved through intermediate layers of visual representation not previously fully explored. We hypothesize that hypercomplex - also known as endstopped - neurons play a critical role to achieve shape selectivity and show how shape-selective neurons may be modeled by integrating endstopping and curvature computations. This model - a representational and computational system for the detection of 2-dimensional object silhouettes that we term 2DSIL - provides a highly accurate fit with neural data and replicates responses from neurons in area V4 with an average of \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Ic6ZXhUAAAAJ:Ade32sEp0pkC",
            "Publisher": "Public Library of Science"
        },
        {
            "Title": "Direct neurophysiological evidence for spatial suppression surrounding the focus of attention in vision",
            "Publication year": 2006,
            "Publication url": "https://www.pnas.org/content/103/4/1053.short",
            "Abstract": "The spatial focus of attention has traditionally been envisioned as a simple spatial gradient of enhanced activity that falls off monotonically with increasing distance. Here, we show with high-density magnetoencephalographic recordings in human observers that the focus of attention is not a simple monotonic gradient but instead contains an excitatory peak surrounded by a narrow inhibitory region. To demonstrate this center-surround profile, we asked subjects to focus attention onto a color pop-out target and then presented probe stimuli at various distances from the target. We observed that the electromagnetic response to the probe was enhanced when the probe was presented at the location of the target, but the probe response was suppressed in a narrow zone surrounding the target and then recovered at more distant locations. Withdrawing attention from the pop-out target by engaging observers in a \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Ic6ZXhUAAAAJ:WF5omc3nYNoC",
            "Publisher": "National Academy of Sciences"
        },
        {
            "Title": "MEG study of temporal parameters and localization of brain responses during the detection of transient changes in the direction of moving stimuli",
            "Publication year": 2004,
            "Publication url": "https://www.researchgate.net/profile/John-Tsotsos/publication/242397458_MEG_Study_of_Temporal_Parameters_and_Localization_of_Brain_Responses_During_the_Detection_of_Transient_Changes_in_the_Direction_of_Moving_Stimuli/links/0046353a1adc9edd7e000000/MEG-Study-of-Temporal-Parameters-and-Localization-of-Brain-Responses-During-the-Detection-of-Transient-Changes-in-the-Direction-of-Moving-Stimuli.pdf",
            "Abstract": "CONCLUSIONSOur results suggest that the MT/V5+ complex in humans contains neurons sensitive to abrupt changes in the direction of moving stimuli. We also identified an area in the right IPL activated by such changes. The latter finding could have at least two different explanations. First, that the right area IPL is specifically involved in detecting changes in the direction of moving stimuli. Second, that the right area IPL is involved in the detection of transient events independently of the type of sensory signal causing the event. This last explanation agrees with previous reports of area IPL involved in bottom-up (exogenous) attention.",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:YohjEiUPhakC",
            "Publisher": "The Association for Research in Vision and Ophthalmology"
        },
        {
            "Title": "Visual attention in dynamic environments",
            "Publication year": 2014,
            "Publication url": "Unknown",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:QB0F--xbfh4C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Development of spatial suppression surrounding the focus of visual attention",
            "Publication year": 2019,
            "Publication url": "https://jov.arvojournals.org/article.aspx?articleid=2738235",
            "Abstract": "In adulthood, research has demonstrated that surrounding the spatial location of attentional focus is a suppressive field, resulting from top-down attention promoting the processing of relevant stimuli and inhibiting surrounding distractors (eg, Hopf et al., 2006). It is not fully known, however, how this phenomenon manifests during development. This is an important question since attention processes are likely even more critical in development because of their potential impact on learning and day-to-day activities. The current study examined whether spatial suppression surrounding the focus of visual attention, a predicted by-product of top-down attentional modulation, is observed in development. A wide age range separated in six incremental age levels was included, allowing for a detailed examination of potential differences in the effect of attention on visual processing across development. Participants between 12 and 27 years of age exhibited spatial suppression surrounding their focus of visual attention. Their accuracy increased as a function of the separation distance between a spatially cued (and attended) target and a second target, suggesting that a ring of suppression surrounded the attended target. Attentional surround suppression was not observed in 8-to 11-years-olds, even with a longer spatial cue presentation time, demonstrating that the lack of the effect at these ages is not due to slowed attentional feedback processes. Our findings demonstrate that top-down attentional processes exhibit functional maturity beginning around 12 years of age with continuing maturation of their expression until 17, which likely impacts education and \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Ic6ZXhUAAAAJ:41KyI4NE9qkC",
            "Publisher": "The Association for Research in Vision and Ophthalmology"
        },
        {
            "Title": "A Research Roadmap of Cognitive Vision",
            "Publication year": 2005,
            "Publication url": "http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.106.4212&rep=rep1&type=pdf",
            "Abstract": "On the 1st March 2002, a European research network for cognitive computer vision systems\u2014ECVision\u2014was inaugurated. This network is funded for three years by the European Commission under the Information Society Technologies (IST) programme as project IST-2001-35454.The goal of ECVision is to promote research, education, and application systems engineering in cognitive computer vision in Europe. It pursues this goal by a variety of means, most of which are based on facilitating peer-to-peer interaction amongst the foremost researchers in the area. The network targets four main activities: research planning, education & training, information dissemination, and industrial liaison. In the research planning area, one of the main goals is to maximize the effectiveness of future research by creating a detailed research agenda: a research roadmap. Research roadmaps are often conceived as a statement of the state-of-the-art in a given discipline accompanied by a prioritized list of problematic issues and a strategy for their investigation. The state-of-the-art survey constitutes a point of departure on the roadmap, the problematic issues constitute the destination, and the strategy the path by which one should proceed to the destination. However, there isn\u2019t clear consensus on the right approach to take in addressing the problems posed by cognitive vision. Consequently, the approach adopted here is one of inclusiveness: we don\u2019t assume that there is a single point of departure, a single destination, and a clearly-mapped path leading from one to the other. Instead, we allow that there are several different destinations (ie types of cognitive vision \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Ic6ZXhUAAAAJ:BJrgspguQaEC",
            "Publisher": "www.ecvision.org"
        },
        {
            "Title": "Visual Attention: Computational Problems, Strategies, and Mechanism",
            "Publication year": 2012,
            "Publication url": "Unknown",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:4X0JR2_MtJMC",
            "Publisher": "Oxford University press"
        },
        {
            "Title": "Indoor localization in dynamic human environments using visual odometry and global pose refinement",
            "Publication year": 2018,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/8575775/",
            "Abstract": "Indoor Localization is a primary task for social robots. We are particularly interested in how to solve this problem for a mobile robot using primarily vision sensors. This work examines a critical issue related to generalizing approaches for static environments to dynamic ones: (i) it considers how to deal with dynamic users in the environment that obscure landmarks that are key to safe navigation, and (ii) it considers how standard localization approaches for static environments can be augmented to deal with dynamic agents (e.g., humans). We propose an approach which integrates wheel odometry with stereo visual odometry and perform a global pose refinement to overcome previously accumulated errors due to visual and wheel odometry. We evaluate our approach through a series of controlled experiments to see how localization performance varies with increasing number of dynamic agents present in the scene.",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:d1QmopYJ1igC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Feature-based attention induces non-linearities in neuronal tuning and behavior during visual motion perception",
            "Publication year": 2021,
            "Publication url": "https://www.biorxiv.org/content/10.1101/2021.02.17.431646v2.full.pdf",
            "Abstract": "Background: Feature-based attention prioritizes the processing of the attended feature while strongly suppressing the processing of nearby ones. This creates a non-linearity or \u201cattentional suppressive surround\u201d predicted by the Selective Tuning model of visual attention. However, previously reported effects of feature-based attention on neuronal responses are linear, eg, feature-similarity gain. Here, we investigated this apparent contradiction by neurophysiological and psychophysical approaches.Results: Responses of motion direction-selective neurons in area MT/MST of monkeys were recorded during a motion task. When attention was allocated to a stimulus moving in the neurons\u2019 preferred direction response tuning curves showed its minimum for directions 60-90 degrees away from the preferred direction, an attentional suppressive surround. This effect was modeled via the interaction of two Gaussian fields representing excitatory narrowly-tuned and inhibitory widely-tuned inputs into a neuron, with feature-based attention predominantly increasing the gain of inhibitory inputs. We further showed using a motion repulsion paradigm in humans that feature-based attention produces a similar non-linearity on motion discrimination performance.Conclusions: Our results link the gain modulation of neuronal inputs and tuning curves examined through the feature-similarity gain lens to the attentional impact on neural population responses predicted by the Selective Tuning model, providing a unified framework for the documented effects of feature-based attention on neuronal responses and behavior.",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:-U72JhJFxmcC",
            "Publisher": "Cold Spring Harbor Laboratory"
        },
        {
            "Title": "Contextual Interference Reduction by Selective Fine-Tuning of Neural Networks",
            "Publication year": 2020,
            "Publication url": "https://arxiv.org/abs/2011.10857",
            "Abstract": "Feature disentanglement of the foreground target objects and the background surrounding context has not been yet fully accomplished. The lack of network interpretability prevents advancing for feature disentanglement and better generalization robustness. We study the role of the context on interfering with a disentangled foreground target object representation in this work. We hypothesize that the representation of the surrounding context is heavily tied with the foreground object due to the dense hierarchical parametrization of convolutional networks with under-constrained learning algorithms. Working on a framework that benefits from the bottom-up and top-down processing paradigms, we investigate a systematic approach to shift learned representations in feedforward networks from the emphasis on the irrelevant context to the foreground objects. The top-down processing provides importance maps as the means of the network internal self-interpretation that will guide the learning algorithm to focus on the relevant foreground regions towards achieving a more robust representations. We define an experimental evaluation setup with the role of context emphasized using the MNIST dataset. The experimental results reveal not only that the label prediction accuracy is improved but also a higher degree of robustness to the background perturbation using various noise generation methods is obtained.",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:_6MJE67MA8AC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Computational foundations for attentive processes",
            "Publication year": 2008,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/B9780123757319500057",
            "Abstract": "Notions such as capacity limits pervade the attention literature. This presentation attempts to make these concrete and to discover constraints on plausible solutions to vision. Through the proofs, approximations, and optimizations to find architectures that plausibly do not violate biological constraints, important problems such as information routing and signal interference can be addressed. Perhaps the most important conclusion is that the brain is not solving the generic vision problem. Rather, the generic problem is reshaped through approximations so that it becomes solvable by the amount of processing power available for vision. Selective attention in feature, image, and object space plays a necessary role.",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:aIdbFUkbNIkC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Neurobiology of attention",
            "Publication year": 2005,
            "Publication url": "https://books.google.com/books?hl=en&lr=&id=8nLPgE-n8bgC&oi=fnd&pg=PR13&dq=info:UmZqfxSa1XEJ:scholar.google.com&ots=G_f1PzuK92&sig=lfuRsNQsLdBe5gGrdEPHTj2YGTA",
            "Abstract": "A key property of neural processing in higher mammals is the ability to focus resources by selectively directing attention to relevant perceptions, thoughts or actions. Research into attention has grown rapidly over the past two decades, as new techniques have become available to study higher brain function in humans, non-human primates, and other mammals. Neurobiology of Attention is the first encyclopedic volume to summarize the latest developments in attention research. An authoritative collection of over 100 chapters organized into thematic sections provides both broad coverage and access to focused, up-to-date research findings. This book presents a state-of-the-art multidisciplinary perspective on psychological, physiological and computational approaches to understanding the neurobiology of attention. Ideal for students, as a reference handbook or for rapid browsing, the book has a wide appeal to anybody interested in attention research.* Contains numerous quick-reference articles covering the breadth of investigation into the subject of attention* Provides extensive introductory commentary to orient and guide the reader* Includes the most recent research results in this field of study",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:hqOjcs7Dif8C",
            "Publisher": "Academic Press"
        },
        {
            "Title": "The spatial profile of the focus of attention in visual search: insights from MEG recordings",
            "Publication year": 2010,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S0042698910000283",
            "Abstract": "The spatial focus of attention has been suggested to resemble a spotlight, a zoom-lens, a simple gradient, or even a more complex center\u2013surround profile. Here we review evidence from neuromagnetic recordings indicating that the spatial profile is not fixed but depends on the particular perceptual demands of the attention task. We show that visual search requiring spatial scrutiny for target discrimination produces a zone of neural attenuation in the target\u2019s immediate surround, whereas search permitting target discrimination without spatial scrutiny is associated with a simple gradient. We provide new evidence indicating that increasing the demands on target discrimination without changing the spatial scale of discrimination does not influence surround attenuation, and that surround attenuation is also not influenced by the type of features involved in forward processing, that is whether the target location is defined \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Ic6ZXhUAAAAJ:1sJd4Hv_s6UC",
            "Publisher": "Pergamon"
        },
        {
            "Title": "The Pragmatic Turn: Toward Action-Oriented Views in Cognitive Science",
            "Publication year": 2016,
            "Publication url": "https://scholar.google.com/scholar?cluster=8306556340888649293&hl=en&oi=scholarr",
            "Abstract": "Experts from a range of disciplines assess the foundations and implications of a novel action-oriented view of cognition. Cognitive science is experiencing a pragmatic turn away from the traditional representation-centered framework toward a view that focuses on understanding cognition as \u201cenactive.\u201d This enactive view holds that cognition does not produce models of the world but rather subserves action as it is grounded in sensorimotor skills. In this volume, experts from cognitive science, neuroscience, psychology, robotics, and philosophy of mind assess the foundations and implications of a novel action-oriented view of cognition. Their contributions and supporting experimental evidence show that an enactive approach to cognitive science enables strong conceptual advances, and the chapters explore key concepts for this new model of cognition. The contributors discuss the implications of an enactive approach for cognitive development; action-oriented models of cognitive processing; action-oriented understandings of consciousness and experience; and the accompanying paradigm shifts in the fields of philosophy, brain science, robotics, and psychology. Contributors Moshe Bar, Lawrence W. Barsalov, Olaf Blanke, Jeannette Bohg, Martin V. Butz, Peter F. Dominey, Andreas K. Engel, Judith M. Ford, Karl J. Friston, Chris D. Frith, Shaun Gallagher, Antonia Hamilton, Tobias Heed, Cecilia Heyes, Elisabeth Hill, Matej Hoffmann, Jakob Hohwy, Bernhard Hommel, Atsushi Iriki, Pierre Jacob, Henrik J\u00f6rntell, J\u00fcrgen Jost, James Kilner, G\u00fcnther Knoblich, Peter K\u00f6nig, Danica Kragic, Miriam Kyselo, Alexander Maye, Marek McGann, Richard Menary \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Ic6ZXhUAAAAJ:Ol96Buz8XVoC",
            "Publisher": "MIT Press"
        },
        {
            "Title": "Place Recognition System for Localization of Mobile Robots",
            "Publication year": 2015,
            "Publication url": "http://www.raghavendersahdev.com/uploads/3/9/6/2/39623741/thesis_raghavender.pdf",
            "Abstract": "Autonomous Mobile Robots have been studied by a large number of researchers. One of the most important capabilities is Robot Localization. Robot Localization refers to answering the question for the robot \u201cWhere am I?\u201d Localization in general has 2 aspects qualitative and quantitative. The qualitative aspect of Localization refers to knowing where the robot is qualitatively. For example-In a building the robot should know that it is on a particular floor in room number 12 (which may be a seminar room, lab, kitchen, etc.) The Quantitative aspect of Localization allows the robot to have the knowledge about its coordinates in the particular room with reference to a standard point.In this report our focus is to deal with the qualitative aspect of Localization. We focus on Topological Place Recognition and Topological Place Categorization. Topological Place Recognition gives the robot the ability to recognize previously seen places/environments and classify them into their respective class whereas Topological Place Categorization allows the robot to learn from a specified set of places and recognize previously unseen environments and places. We here used vision as a tool to solve this task. We have implemented a HOUP descriptor [1] in this report and use it as a tool to generate descriptors required to perform the recognition and categorization tasks. For a given image sub block, a HOUP descriptor is produced by passing the sub block through a Gabor filter oriented in different orientations. The output of the Gabor filter is then used to generate Local Binary Patterns similar to those used in ones proposed by Ojala [2]. These patterns reflect the textural \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Ic6ZXhUAAAAJ:s9ia6_kGH2AC",
            "Publisher": "Unknown"
        },
        {
            "Title": "The center-surround profile of the focus of attention arises from recurrent processing in visual cortex",
            "Publication year": 2009,
            "Publication url": "https://academic.oup.com/cercor/article-abstract/19/4/982/283444",
            "Abstract": "We recently demonstrated with magnetoencephalographic recordings in human observers that the focus of attention in visual search has a spatial profile consisting of a center enhancement surrounded by a narrow zone of sensory attenuation. Here, we report new data from 2 experiments providing insights into the cortical processes that cause the surround attenuation. We show that surround suppression appears in search tasks that require spatial scrutiny, that is the precise binding of search-relevant features at the target's location but not in tasks that permit target discrimination without precise localization. Furthermore, we demonstrate that surround attenuation is linked with a stronger recurrent activity modulation in early visual cortex. Finally, we show that surround suppression appears with a delay (more than 175 ms) that is beyond the time course of the initial feedforward sweep of processing in the visual \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Ic6ZXhUAAAAJ:RYcK_YlVTxYC",
            "Publisher": "Oxford University Press"
        },
        {
            "Title": "Resampling 4D images using adaptive filtering",
            "Publication year": 2005,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/1443106/",
            "Abstract": "We present an adaptive filtering based methodology for resampling 3D time series images using an extension of the method presented by simultaneously reducing the artifacts due to image noise and resample the data on a finer grid along the time dimension. This provides a methodology for obtaining high quality image resampling without the disadvantages of staircase artifacts created by more common interpolation methods such as linear interpolation. We present qualitative results of the algorithm on a data set of 4D cardiac MRI. This is a useful approach for any situation where we have a data set of 4D images needing to be resampled.",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:yB1At4FlUx8C",
            "Publisher": "IEEE"
        },
        {
            "Title": "Behavioral Research and Practical Models of Drivers' Attention",
            "Publication year": 2021,
            "Publication url": "https://arxiv.org/abs/2104.05677",
            "Abstract": "Driving is a routine activity for many, but it is far from simple. Drivers deal with multiple concurrent tasks, such as keeping the vehicle in the lane, observing and anticipating the actions of other road users, reacting to hazards, and dealing with distractions inside and outside the vehicle. Failure to notice and respond to the surrounding objects and events can cause accidents. The ongoing improvements of the road infrastructure and vehicle mechanical design have made driving safer overall. Nevertheless, the problem of driver inattention has remained one of the primary causes of accidents. Therefore, understanding where the drivers look and why they do so can help eliminate sources of distractions and identify unsafe attention patterns. Research on driver attention has implications for many practical applications such as policy-making, improving driver education, enhancing road infrastructure and in-vehicle infotainment systems, as well as designing systems for driver monitoring, driver assistance, and automated driving. This report covers the literature on changes in drivers' visual attention distribution due to factors, internal and external to the driver. Aspects of attention during driving have been explored across multiple disciplines, including psychology, human factors, human-computer interaction, intelligent transportation, and computer vision, each offering different perspectives, goals, and explanations for the observed phenomena. We link cross-disciplinary theoretical and behavioral research on driver's attention to practical solutions. Furthermore, limitations and directions for future research are discussed. This report is based on over 175 \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Ic6ZXhUAAAAJ:m5pSp7c2PXAC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Feature-based surround suppression in the motion domain",
            "Publication year": 2017,
            "Publication url": "https://jov.arvojournals.org/article.aspx?articleid=2650930",
            "Abstract": "When we attend to a certain visual feature, such as a specific orientation (Tombu & Tsotsos, 2008) or specific colour (St\u00f6rmer & Alvarez, 2014), processing of features nearby in that space are suppressed (ie, feature-based surround suppression). In the present study, we investigated feature-based surround suppression in a new feature domain, motion direction, using motion repulsion as a measurement. Chen and colleagues (2005) suggested that attention to one motion direction reduces motion repulsion by inhibiting the other direction. Based on this finding, we conducted a similar direction judgment task having na\u00efve participants. They reported perceived directions of two superimposed motions after viewing the motions for 2 sec. The directional differences between two motions systematically varied (10~ 70 deg) and the surfaces were separated by different colours (green or red). In the unattended condition \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Ic6ZXhUAAAAJ:LA-8tw-JpD0C",
            "Publisher": "The Association for Research in Vision and Ophthalmology"
        },
        {
            "Title": "Is the Selective Tuning Model of Visual Attention Still Relevant?",
            "Publication year": 2019,
            "Publication url": "https://docs.lib.purdue.edu/cgi/viewcontent.cgi?article=1141&context=modvis",
            "Abstract": "The Selective Tuning (ST) model of visual attention is a theory-based model, derived from first principles with little or no appeal to data-directed derivation. It seems a natural question to ask whether the model might still have relevance in the present research milieu. This presentation examines this.To begin, ST and its theoretical roots will be briefly described. Its relevance will then be addressed on the basis of ST's ability to engender new knowledge of human visual processes and ST's contribution in terms of the quantitative performance of systems which embody its elements. To the former point, a number of recent human behavioral and neurophysiology results are offered that add to the growing body of similar past results: a. Feature-Based Attention-Attending to a particular feature value causes local suppression in that feature dimension. New human experimental work demonstrates this for color and for motion \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Ic6ZXhUAAAAJ:rI7N8NGxj9wC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Attention and visual search",
            "Publication year": 2007,
            "Publication url": "https://www.worldscientific.com/doi/abs/10.1142/s0129065707001135",
            "Abstract": "Selective Tuning (ST) presents a framework for modeling attention and in this work we show how it performs in covert visual search tasks by comparing its performance to human performance. Two implementations of ST have been developed. The Object Recognition Model recognizes and attends to simple objects formed by the conjunction of various features and the Motion Model recognizes and attends to motion patterns. The validity of the Object Recognition Model was first tested by successfully duplicating the results of Nagy and Sanchez. A second experiment was aimed at an evaluation of the model's performance against the observed continuum of search slopes for feature-conjunction searches of varying difficulty. The Motion Model was tested against two experiments dealing with searches in the visual motion domain. A simple odd-man-out search for counter-clockwise rotating octagons among identical \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Ic6ZXhUAAAAJ:yD5IFk8b50cC",
            "Publisher": "World Scientific Publishing Company"
        },
        {
            "Title": "Insights from computer vision to improve student data visualization",
            "Publication year": 2018,
            "Publication url": "Unknown",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:jmj0Wi0nzAgC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Attention to color sharpens neural population tuning via feedback processing in the human visual cortex hierarchy",
            "Publication year": 2017,
            "Publication url": "https://www.jneurosci.org/content/37/43/10346.abstract",
            "Abstract": "Attention can facilitate the selection of elementary object features such as color, orientation, or motion. This is referred to as feature-based attention and it is commonly attributed to a modulation of the gain and tuning of feature-selective units in visual cortex. Although gain mechanisms are well characterized, little is known about the cortical processes underlying the sharpening of feature selectivity. Here, we show with high-resolution magnetoencephalography in human observers (men and women) that sharpened selectivity for a particular color arises from feedback processing in the human visual cortex hierarchy. To assess color selectivity, we analyze the response to a color probe that varies in color distance from an attended color target. We find that attention causes an initial gain enhancement in anterior ventral extrastriate cortex that is coarsely selective for the target color and transitions within \u223c100 ms into a \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Ic6ZXhUAAAAJ:j2GxDk2JBlYC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Eyes and ears: Attentive teleconferencing utilizing audio and video cues",
            "Publication year": 2001,
            "Publication url": "https://asa.scitation.org/doi/abs/10.1121/1.4744878",
            "Abstract": "The multiple speaker teleconferencing systems currently available typically focus on a single speaker and provide limited, if any, automatic speaker tracking technologies. However, in a multiple\u2010speaker setting, speakers must be localized and tracked in both the video and audio domains. Although many fast and portable video trackers capable of locating and tracking humans exist, they employ conventional cameras thereby providing a narrow field of view. In addition, audio localization systems are expensive, nonportable, and computationally intensive. Furthermore, there have been very few attempts to combine both audio and visual systems. This work investigates the development of a simple, economical, and compact teleconferencing system utilizing both audio and video cues. An omni\u2010directional video sensor is used to provide a view of the entire visual hemisphere thereby providing multiple dynamic views \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Ic6ZXhUAAAAJ:WJVC3Jt7v1AC",
            "Publisher": "Acoustical Society of America"
        },
        {
            "Title": "The selective tuning model of attention: psychophysical evidence for a suppressive annulus around an attended item",
            "Publication year": 2003,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S0042698902004911",
            "Abstract": "The selective tuning model [Artif. Intell. 78 (1995) 507] is a neurobiologically plausible neural network model of visual attention. One of its key predictions is that to simultaneously solve the problems of convergence of neural input and selection of attended items, the portions of the visual neural network that process an attended stimulus must be surrounded by inhibition. To test this hypothesis, we mapped the attentional field around an attended location in a matching task where the subject\u2019s attention was directed to a cued target while the distance of a probe item to the target was varied systematically. The main result was that accuracy increased with inter-target separation. The observed pattern of variation of accuracy with distance provided strong evidence in favor of the critical prediction of the model that attention is actively inhibited in the immediate vicinity of an attended location.",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:YsMSGLbcyi4C",
            "Publisher": "Pergamon"
        },
        {
            "Title": "Adaptive step size window matching for detection",
            "Publication year": 2006,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/1699196/",
            "Abstract": "An often overlooked problem in matching lies in selecting an appropriate step size. The selection of the step size for real-time applications is critical both from the point of view of computational efficiency and detection performance. Current systems set the step size in an ad hoc manner. This paper describes an algorithm for selecting the step size based on a theoretical worst case analysis. We have implemented this adaptive step size method in an object detection algorithm. Experimental evaluation demonstrates the effectiveness of our proposed algorithm",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:qUcmZB5y_30C",
            "Publisher": "IEEE"
        },
        {
            "Title": "What does it mean to attend better?",
            "Publication year": 2014,
            "Publication url": "Unknown",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:X3EXpuCuTEcC",
            "Publisher": "Unknown"
        },
        {
            "Title": "People tracking using robust motion detection and estimation",
            "Publication year": 2005,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/1443140/",
            "Abstract": "Real world computer vision systems highly depend on reliable, robust retrieval of motion cues to make accurate decisions about their surroundings. In this paper, we present a simple, yet high performance low-level filter for motion tracking in digitized video signals. The algorithm is based on constant characteristics of a common, 2-frame interlaced video signal, yet results presented in this paper show its applicability to highly compressed, noisy image sequences as well. In general, our approach uses a computationally low-cost solution to define the area of interest for tracking of multiple, moving objects. Despite its simplicity, it compares very well to existing approaches due to its robustness towards environmental changes. To demonstrate this, we present results of processing a sequence of JPEG-compressed monocular images of a parking lot in order to track pedestrians, cars and bicycles. Despite a high level of \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Ic6ZXhUAAAAJ:tS2w5q8j5-wC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Histogram of oriented uniform patterns for robust place recognition and categorization",
            "Publication year": 2012,
            "Publication url": "https://journals.sagepub.com/doi/abs/10.1177/0278364911434936",
            "Abstract": "This paper presents a novel context-based scene recognition method that enables mobile robots to recognize previously observed topological places in known environments or categorize previously unseen places in new environments. We achieve this by introducing the Histogram of Oriented Uniform Patterns (HOUP), which provides strong discriminative power for place recognition, while offering a significant level of generalization for place categorization. HOUP descriptors are used for image representation within a subdivision framework, where the size and location of sub-regions are determined using an informative feature selection method based on kernel alignment. Further improvement is achieved by developing a similarity measure that accounts for perceptual aliasing to eliminate the effect of indistinctive but visually similar regions that are frequently present in outdoor and indoor scenes. An extensive set \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Ic6ZXhUAAAAJ:jgBuDB5drN8C",
            "Publisher": "SAGE Publications"
        },
        {
            "Title": "High-level perceptual similarity is enabled by learning diverse tasks",
            "Publication year": 2019,
            "Publication url": "https://arxiv.org/abs/1903.10920",
            "Abstract": "Predicting human perceptual similarity is a challenging subject of ongoing research. The visual process underlying this aspect of human vision is thought to employ multiple different levels of visual analysis (shapes, objects, texture, layout, color, etc). In this paper, we postulate that the perception of image similarity is not an explicitly learned capability, but rather one that is a byproduct of learning others. This claim is supported by leveraging representations learned from a diverse set of visual tasks and using them jointly to predict perceptual similarity. This is done via simple feature concatenation, without any further learning. Nevertheless, experiments performed on the challenging Totally-Looks-Like (TLL) benchmark significantly surpass recent baselines, closing much of the reported gap towards prediction of human perceptual similarity. We provide an analysis of these results and discuss them in a broader context of emergent visual capabilities and their implications on the course of machine-vision research.",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:KEmvaKc6tCQC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Natural Scene Segmentation of Static Images",
            "Publication year": 2009,
            "Publication url": "Unknown",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:-nhnvRiOwuoC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Smiler: Saliency model implementation library for experimental research",
            "Publication year": 2018,
            "Publication url": "https://arxiv.org/abs/1812.08848",
            "Abstract": "The Saliency Model Implementation Library for Experimental Research (SMILER) is a new software package which provides an open, standardized, and extensible framework for maintaining and executing computational saliency models. This work drastically reduces the human effort required to apply saliency algorithms to new tasks and datasets, while also ensuring consistency and procedural correctness for results and conclusions produced by different parties. At its launch SMILER already includes twenty three saliency models (fourteen models based in MATLAB and nine supported through containerization), and the open design of SMILER encourages this number to grow with future contributions from the community. The project may be downloaded and contributed to through its GitHub page: https://github.com/tsotsoslab/smiler",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:BBcCmHsDWsAC",
            "Publisher": "Unknown"
        },
        {
            "Title": "John K. Tsotsos",
            "Publication year": 2015,
            "Publication url": "https://core.ac.uk/download/pdf/81971575.pdf",
            "Abstract": "mentioned Einstein\u2019s influence, but I must admit, this was well before I had any real understanding of science or even what I was talking about. Still, I do feel this pointed me in the right direction. I also have already mentioned my math teacher who introduced me to computers. But once I was in university, among many strong influences, the one person who wound up having the greatest influence on me, by far, was John Mylopoulos. I met John when he taught me a computing theory course and then invited me to join his research group as an undergraduate. I remained a member of his group for six years. He was also primary supervisor for my PhD along with two others. John taught me how to formalize my conceptual solutions, how to organize and nurture a research group, how to adapt supervision to the needs of individual students, and how to lead by example. Generally, John introduced me to Artificial Intelligence and especially to its subareas of knowledge representation, knowledge-based systems, problem solving and reasoning. Noting that I wanted to do computer vision, a topic not within his main expertise, John sent me to a NATO Advanced Study Institute in 1978, and this was a turning point for me. I heard lectures and tutorials over two weeks and had inspiring conversations with many of the pioneering and leading figures in computer vision. Among those was Steven W. Zucker. Steve, then at McGill University, agreed to help me with my thesis work and has been my vision guidepost ever since. Steve taught me about human and computer vision and how to take the conceptual formulations I developed into the world of mathematics with \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Ic6ZXhUAAAAJ:A8cqit5AE6sC",
            "Publisher": "Elsevier"
        },
        {
            "Title": "A computational perspective on visual attention",
            "Publication year": 2011,
            "Publication url": "https://books.google.com/books?hl=en&lr=&id=eT7dTizZfrYC&oi=fnd&pg=PP1&dq=info:4IDxmNGKUHcJ:scholar.google.com&ots=LFiizGBJE0&sig=ez5nCrNitSGP8VdVGqi1kCjpc3o",
            "Abstract": "The derivation, exposition, and justification of the Selective Tuning model of vision and attention. Although William James declared in 1890,\" Everyone knows what attention is,\" today there are many different and sometimes opposing views on the subject. This fragmented theoretical landscape may be because most of the theories and models of attention offer explanations in natural language or in a pictorial manner rather than providing a quantitative and unambiguous statement of the theory. They focus on the manifestations of attention instead of its rationale. In this book, John Tsotsos develops a formal model of visual attention with the goal of providing a theoretical explanation for why humans (and animals) must have the capacity to attend. He takes a unique approach to the theory, using the full breadth of the language of computation--rather than simply the language of mathematics--as the formal means of description. The result, the Selective Tuning model of vision and attention, explains attentive behavior in humans and provides a foundation for building computer systems that see with human-like characteristics. The overarching conclusion is that human vision is based on a general purpose processor that can be dynamically tuned to the task and the scene viewed on a moment-by-moment basis. Tsotsos offers a comprehensive, up-to-date overview of attention theories and models and a full description of the Selective Tuning model, confining the formal elements to two chapters and two appendixes. The text is accompanied by more than 100 illustrations in black and white and color; additional color illustrations and movies are available on \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Ic6ZXhUAAAAJ:uWQEDVKXjbEC",
            "Publisher": "MIT Press"
        },
        {
            "Title": "Pedestrian action anticipation using contextual feature fusion in stacked rnns",
            "Publication year": 2020,
            "Publication url": "https://arxiv.org/abs/2005.06582",
            "Abstract": "One of the major challenges for autonomous vehicles in urban environments is to understand and predict other road users' actions, in particular, pedestrians at the point of crossing. The common approach to solving this problem is to use the motion history of the agents to predict their future trajectories. However, pedestrians exhibit highly variable actions most of which cannot be understood without visual observation of the pedestrians themselves and their surroundings. To this end, we propose a solution for the problem of pedestrian action anticipation at the point of crossing. Our approach uses a novel stacked RNN architecture in which information collected from various sources, both scene dynamics and visual features, is gradually fused into the network at different levels of processing. We show, via extensive empirical evaluations, that the proposed algorithm achieves a higher prediction accuracy compared to alternative recurrent network architectures. We conduct experiments to investigate the impact of the length of observation, time to event and types of features on the performance of the proposed method. Finally, we demonstrate how different data fusion strategies impact prediction accuracy.",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:xmdbLjM3F_sC",
            "Publisher": "Unknown"
        },
        {
            "Title": "What roles can attention play in recognition?",
            "Publication year": 2008,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/4640805/",
            "Abstract": "Does attention have relevance for visual recognition and if so, under what circumstances? Is there a particular role (or roles) for attentive processes? These are not so simple to answer. Attention, if used at all in computer vision, has traditionally played one or both of the following roles: where to look next (or selection of region of interest), or top-down task influence on visual computation. In this paper, I argue that these are only two of the possible roles. Attention is also closely linked to binding and it is the triad of attention, binding and recognition that go hand in hand for non-trivial visual recognition tasks. This paper describes a set of four novel binding processes that employ a variety of attentive mechanisms to achieve recognition beyond the first feed-forward pass. The description is at a conceptual level with many pointers to papers where details may be found.",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:wbdj-CoPYUoC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Blocks World Revisited: The Effect of Self-Occlusion on Classification by Convolutional Neural Networks",
            "Publication year": 2021,
            "Publication url": "https://arxiv.org/abs/2102.12911",
            "Abstract": "Despite the recent successes in computer vision, there remain new avenues to explore. In this work, we propose a new dataset to investigate the effect of self-occlusion on deep neural networks. With TEOS (The Effect of Self-Occlusion), we propose a 3D blocks world dataset that focuses on the geometric shape of 3D objects and their omnipresent challenge of self-occlusion. We designed TEOS to investigate the role of self-occlusion in the context of object classification. Even though remarkable progress has been seen in object classification, self-occlusion is a challenge. In the real-world, self-occlusion of 3D objects still presents significant challenges for deep learning approaches. However, humans deal with this by deploying complex strategies, for instance, by changing the viewpoint or manipulating the scene to gather necessary information. With TEOS, we present a dataset of two difficulty levels (L1 and L2 ), containing 36 and 12 objects, respectively. We provide 738 uniformly sampled views of each object, their mask, object and camera position, orientation, amount of self-occlusion, as well as the CAD model of each object. We present baseline evaluations with five well-known classification deep neural networks and show that TEOS poses a significant challenge for all of them. The dataset, as well as the pre-trained models, are made publicly available for the scientific community under https://nvision2.data.eecs.yorku.ca/TEOS.",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:KH-Iy8IzxhYC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Energy minimization via graph cuts for semantic place labeling",
            "Publication year": 2010,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/5649952/",
            "Abstract": "This paper presents a novel framework for semantic place labeling by formulating the problem in terms of energy minimization. A method based on graph cuts is used to minimize energy for a function of data cost and smoothness cost. While the data term aims at assigning visual observations to a set of pre-specified place categories, using appearance-based hierarchical classifiers, the smoothness term incorporates contextual evidence from neighbors to ensure that the labels vary smoothly almost everywhere while preserving discontinuities at the borders between adjacent places in the environment. Our proposed method achieved a performance of 91.85%, labeling 2,146 images from the challenging COLD database with place semantics. Correct labeling of 14.5% of images was the result of incorporating contextual information.",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:35r97b3x0nAC",
            "Publisher": "IEEE"
        },
        {
            "Title": "40 Years of Cognitive Architectures: Focus on Vision, Attention, Learning and Applications Supplemental material",
            "Publication year": 2016,
            "Publication url": "Unknown",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:VXkaQG_c9EQC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Models of bottom-up attention and saliency",
            "Publication year": 2005,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/B9780123757319500987",
            "Abstract": "Visually conspicuous, or so-called salient, stimuli often have the capability of attracting focal visual attention toward their locations. Several computational architectures subserving this bottom-up, stimulus-driven, spatiotemporal deployment of attention are reviewed in this chapter. The resulting computational models have applications not only to the prediction of visual search psychophysics, but also, in the domain of machine vision, to the rapid selection of regions of interest in complex, cluttered visual environments. We describe an unusal such application, to the objective evaluation of advertising designs.",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:YTuZlYwrTOUC",
            "Publisher": "Academic Press"
        },
        {
            "Title": "May I have your Attention Please?",
            "Publication year": 2018,
            "Publication url": "Unknown",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:66OACaKPDuEC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Active Observers in a 3D World: The 3D Same-Different Task",
            "Publication year": 2020,
            "Publication url": "https://jov.arvojournals.org/article.aspx?articleid=2771453",
            "Abstract": "Most past and present research in computer vision involves passively observed data. Humans, however, are active observers outside the lab; they explore, search, select what and how to look. Here, we are investigating active, visual observation in a 3D world. To focus, we ask subjects to decide if two 3D objects are the same or different, with no constraints on how they view those objects. Such 3D unconstrained, active observation seems under-studied. While many studies explore human performance, usually, they use line drawings portrayed in 2D, and no active observer is involved. The ability to compare two objects seems a core visual capability, one we use many times a day. It would also be essential for any robotic vision system whose role it is to be a real assistant at home, manufacturing or medical setting. To explore the 3D'same-different task', we designed a novel experimental environment and created a \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Ic6ZXhUAAAAJ:z1mV0M3xdQ0C",
            "Publisher": "The Association for Research in Vision and Ophthalmology"
        },
        {
            "Title": "Complexity, vision and attention",
            "Publication year": 2001,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-0-387-21591-4_6",
            "Abstract": "What does it mean for a problem to be complex? One dimension of complexity is computational complexity. This chapter focuses on how this type of complexity affects the design of perceptual systems. Many natural problems have optimal solutions that are believed to be computationally intractable in any implementation, machine or neural. Thus, the computational complexity of a particular solution greatly affects its realizability, and thus its plausibility. The focus here will be on problems in vision.",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:HoB7MX3m0LUC",
            "Publisher": "Springer-Verlag"
        },
        {
            "Title": "Laterality in Visual Attention",
            "Publication year": 2005,
            "Publication url": "https://scholar.google.com/scholar?cluster=5393920536158823203&hl=en&oi=scholarr",
            "Abstract": "2.1 The Eyes.................................. 2.2 Lateral Ceniculate Nucleus........................ 2.3 Primary Visual Cortex.......................... 2.4 Higher Visual Areas........................... 2.5 Computation Requiring Two Eyes.................... 2.5. 1 Physiology of Disparity Detection................ 2.6 Overview and Connectivity........................",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:qwy9JoKyICEC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Detecting motion patterns via direction maps with application to surveillance",
            "Publication year": 2009,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S1077314208001768",
            "Abstract": "Detection of motion patterns in video data can be significantly simplified by abstracting away from pixel intensity values towards representations that explicitly and compactly capture movement across space and time. A novel representation that captures the spatiotemporal distributions of motion across regions of interest, called the \u201cDirection Map,\u201d abstracts video data by assigning a two-dimensional vector, representative of local direction of motion, to quantized regions in space-time. Methods are presented for recovering direction maps from video, constructing direction map templates (defining target motion patterns of interest) and comparing templates to newly acquired video (for pattern detection and localization). These methods have been successfully implemented and tested (with real-time considerations) on over 6300 frames across seven surveillance/traffic videos, detecting potential targets of interest as \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Ic6ZXhUAAAAJ:PkDzUJVvfTUC",
            "Publisher": "Academic Press"
        },
        {
            "Title": "Mission-Directed Behaviour-Based Robots For Planetary Exploration",
            "Publication year": 2003,
            "Publication url": "http://www.cs.yorku.ca/~tsotsos/Homepage%20of%20John%20K_files/Rotenstein03iSairas.pdf",
            "Abstract": "This paper argues that the S* robot control architecture of Tsotsos [1997] is well suited to intelligent control of planetary rovers. Behaviour-based systems 0perate well in unknown environments, but cannot support deliberative functionality. Hybrid systems resolve this issue, but introduce the potential for other problems. S* is a non-hybrid approach that supports deliberation but also attentive vision. As well, S* includes a missionspecification language that permits behaviour reconfiguration on the fly.",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:PELIpwtuRlgC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Parameterless Isomap with adaptive neighborhood selection",
            "Publication year": 2006,
            "Publication url": "https://link.springer.com/chapter/10.1007/11861898_37",
            "Abstract": "Isomap is a highly popular manifold learning and dimensionality reduction technique that effectively performs multidimensional scaling on estimates of geodesic distances. However, the resulting output is extremely sensitive to parameters that control the selection of neighbors at each point. To date, no principled way of setting these parameters has been proposed, and in practice they are often tuned ad hoc, sometimes empirically based on prior knowledge of the desired output. In this paper we propose a parameterless technique that adaptively defines the neighborhood at each input point based on intrinsic dimensionality and local tangent orientation. In addition to eliminating the guesswork associated with parameter configuration, the adaptive nature of this technique enables it to select optimal neighborhoods locally at each point, resulting in superior performance.",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:HDshCWvjkbEC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "A review of 40 years of cognitive architecture research: Focus on perception, attention, learning and applications",
            "Publication year": 2016,
            "Publication url": "https://www.researchgate.net/profile/John-Tsotsos/publication/309483878_A_Review_of_40_Years_of_Cognitive_Architecture_Research_Focus_on_Perception_Attention_Learning_and_Applications/links/58148e1c08aedc7d8963b93b/A-Review-of-40-Years-of-Cognitive-Architecture-Research-Focus-on-Perception-Attention-Learning-and-Applications.pdf",
            "Abstract": "In this paper we present a broad overview of the last 40 years of research on cognitive architectures. Although the number of existing architectures is nearing several hundred, most of the existing surveys do not reflect this growth and focus on a handful of well-established architectures. While their contributions are undeniable, they represent only a part of the research in the field. Thus, in this survey we wanted to shift the focus towards a more inclusive and high-level overview of the research in cognitive architectures. Our final set of 86 architectures includes 55 that are still actively developed, and borrow from a diverse set of disciplines, spanning areas from psychoanalysis to neuroscience. To keep the length of this paper within reasonable limits we discuss only the core cognitive abilities, such as perception, attention mechanisms, learning and memory structure. To assess the breadth of practical applications of cognitive architectures we gathered information on over 700 practical projects implemented using the cognitive architectures in our list.We use various visualization techniques to highlight overall trends in the development of the field. For instance, our data confirms that the hybrid approach to cognitive modeling already dominates the field and will likely continue to do so in the future. Our analysis of practical applications shows that most architectures are very narrowly focused on a particular application domain. Furthermore, there is an apparent gap between general research in robotics and computer vision and research in these areas within the cognitive architectures field. It is very clear that biologically inspired models do not have the \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Ic6ZXhUAAAAJ:DFCteqpGOQ8C",
            "Publisher": "Unknown"
        },
        {
            "Title": "40 years of cognitive architectures: core cognitive abilities and practical applications",
            "Publication year": 2018,
            "Publication url": "https://link.springer.com/article/10.1007/s10462-018-9646-y",
            "Abstract": "In this paper we present a broad overview of the last 40 years of research on cognitive architectures. To date, the number of existing architectures has reached several hundred, but most of the existing surveys do not reflect this growth and instead focus on a handful of well-established architectures. In this survey we aim to provide a more inclusive and high-level overview of the research on cognitive architectures. Our final set of 84 architectures includes 49 that are still actively developed, and borrow from a diverse set of disciplines, spanning areas from psychoanalysis to neuroscience. To keep the length of this paper within reasonable limits we discuss only the core cognitive abilities, such as perception, attention mechanisms, action selection, memory, learning, reasoning and metareasoning. In order to assess the breadth of practical applications of cognitive architectures we present information on over \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Ic6ZXhUAAAAJ:Ioyf5y7uRMMC",
            "Publisher": "Springer Netherlands"
        },
        {
            "Title": "Probabilistic Representation and Inference in Natural Scene Segmentation",
            "Publication year": 2009,
            "Publication url": "Unknown",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:EkHepimYqZsC",
            "Publisher": "Unknown"
        },
        {
            "Title": "ASP. NET MVC 4 in Action: Revised edition of ASP. NET MVC 2 in Action",
            "Publication year": 2012,
            "Publication url": "https://books.google.com/books?hl=en&lr=&id=YTozEAAAQBAJ&oi=fnd&pg=PT19&dq=info:L-ZLnDORB1AJ:scholar.google.com&ots=YRecDWmaWk&sig=Aq1vzbUd6U8pMy_ttJ9tl7zpR90",
            "Abstract": "Summary ASP. NET MVC 4 in Action is a fast-paced tutorial designed to introduce ASP. NET MVC to. NET developers and show how to apply it effectively. All examples in this revised edition are based on ASP. NET MVC 4, so you'll get full coverage of features such as the Razor view engine, Web Matrix helpers, and improved extensibility. You'll see how your ASP. NET applications can benefit from changes in the. NET Framework. About the Technology ASP. NET MVC provides the architecture needed to separate an application's logic and its UI. Because each component's role is well defined, MVC applications are easy to test, maintain, and extend. The latest version, ASP. NET MVC 4, takes advantage of. NET 4 and includes powerful features like the Razor view engine, Web Matrix helpers, and enhanced extensibility. About the Book ASP. NET MVC 4 in Action is a hands-on guide that shows you howto apply ASP. NET MVC effectively. After a high-speed ramp up, this thoroughly revised new edition explores each key topic witha self-contained example so you can jump right to the parts youneed. Based on thousands of hours of real-world experience, theauthors show you valuable high-end techniques you won't findanywhere else. Written for developers, the book arms you withthe next-level skills and practical guidance to create compellingweb applications. You need some knowledge of ASP. NET and C#, but no priorASP. NET MVC experience is assumed. Purchase of the print book comes with an offer of a free PDF, ePub, and Kindle eBook from Manning. Also available is all code from the book. What's Inside Complete coverage of ASP. NET \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Ic6ZXhUAAAAJ:kuK5TVdYjLIC",
            "Publisher": "Simon and Schuster"
        },
        {
            "Title": "The Effect of Color Space Selection on Detectability and Discriminability of Colored Objects",
            "Publication year": 2017,
            "Publication url": "https://arxiv.org/abs/1702.05421",
            "Abstract": "In this paper, we investigate the effect of color space selection on detectability and discriminability of colored objects under various conditions. 20 color spaces from the literature are evaluated on a large dataset of simulated and real images. We measure the suitability of color spaces from two different perspectives: detectability and discriminability of various color groups. Through experimental evaluation, we found that there is no single optimal color space suitable for all color groups. The color spaces have different levels of sensitivity to different color groups and they are useful depending on the color of the sought object. Overall, the best results were achieved in both simulated and real images using color spaces C1C2C3, UVW and XYZ. In addition, using a simulated environment, we show a practical application of color space selection in the context of top-down control in active visual search. The results indicate that on average color space C1C2C3 followed by HSI and XYZ achieve the best time in searching for objects of various colors. Here, the right choice of color space can improve time of search on average by 20%. As part of our contribution, we also introduce a large dataset of simulated 3D objects",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:OiA2aNrLN7MC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Divided attention in the normal and the split brain: chronometry and imaging",
            "Publication year": 2005,
            "Publication url": "https://scholar.google.com/scholar?cluster=15259036407449413588&hl=en&oi=scholarr",
            "Abstract": "Divided attention is the ability to integrate in parallel multiple stimuli. A relevant experimental effect that has been studied for almost a century is the redundant target effect. When multiple copies of the same stimulus are presented to subjects, in choice, go no-go, and even a simple reaction time task, reaction times (RT) tend to be faster, compared to RT to a single copy of the stimulus. Paradoxically, this effect is larger in split-brain patients when two stimuli are presented in the two opposite hemifields. Recent RT and imaging studies reviewed here suggest that cortico-subcortical interactions between the superior colliculus and the extrastriate cortex, which are modulated by the corpus callosum, are reflected in different levels of activation in dorsal premotor cortex during divided attention tasks and can account for the paradoxical facilitation observed in split-brain patients.",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:tfFR5hCbSrAC",
            "Publisher": "Elsevier"
        },
        {
            "Title": "Robust face recognition through local graph matching",
            "Publication year": 2007,
            "Publication url": "http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.83.2301&rep=rep1&type=pdf",
            "Abstract": "A novel face recognition method is proposed, in which face images are represented by a set of local labeled graphs, each containing information about the appearance and geometry of a 3-tuple of face feature points, extracted using Local Feature Analysis (LFA) technique. Our method automatically learns a model set and builds a graph space for each individual. A two-stage method for optimal matching between the graphs extracted from a probe image and the trained model graphs is proposed. The recognition of each probe face image is performed by assigning it to the trained individual with the maximum number of references. Our approach achieves perfect result on the ORL face set and an accuracy rate of 98.4% on the FERET face set, which shows the superiority of our method over all considered state-of-the-art methods.",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:SeFeTyx0c_EC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Salience across spatial scales",
            "Publication year": 2014,
            "Publication url": "https://www.researchgate.net/profile/John-Tsotsos/publication/266156854_Salience_Across_Spatial_Scales/links/54b920a20cf28faced626f80/Salience-Across-Spatial-Scales.pdf",
            "Abstract": "Saliency maps are frequently used to determine the regions of an image which are in some way conspicuous. Applications of saliency range from image compression and mobile robotics to computational modeling of psychophysical data. Typically, a winner-take-all (WTA) approach is used to select the highest overall saliency value. Such methods are vulnerable to spike noise, however, and thus most algorithms include an additional post-processing smoothing step in order to increase the signal-to-noise ratio (SNR). The characteristics of this smoothing kernel can have a large impact on algorithmic performance, however, with the spatial extent of the kernel being the most prominent parameter affecting performance. We show that even when an optimal smoothing kernel is determined for a given dataset there remains significant performance variability between individual images. We propose a potential avenue of \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Ic6ZXhUAAAAJ:XZvG1uL-wj0C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Visual attention and its intimate links to spatial cognition",
            "Publication year": 2018,
            "Publication url": "https://link.springer.com/article/10.1007/s10339-018-0881-6",
            "Abstract": "It is almost universal to regard attention as the facility that permits an agent, human or machine, to give priority processing resources to relevant stimuli while ignoring the irrelevant. The reality of how this might manifest itself throughout all the forms of perceptual and cognitive processes possessed by humans, however, is not as clear. Here, we examine this reality with a broad perspective in order to highlight the myriad ways that attentional processes impact both perception and cognition. The paper concludes by showing two real-world problems that exhibit sufficient complexity to illustrate the ways in which attention and cognition connect. These then point to new avenues of research that might illuminate the overall cognitive architecture of spatial cognition.",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:yd8rdvfCKnwC",
            "Publisher": "Springer Berlin Heidelberg"
        },
        {
            "Title": "Computational models of visual attention",
            "Publication year": 2011,
            "Publication url": "http://www.scholarpedia.org/article/Computational_models_of_attention",
            "Abstract": "Figure 1: A Venn diagram of Computational Models organized by the hypotheses that influence them. The outer large circle represents all possible models while the inner four ovals represent the four major hypotheses discussed in the paper.A Model of Visual Attention addresses the observed and/or predicted behavior of human and non-human primate visual attention. Models can be descriptive, mathematical, algorithmic or computational and attempt to mimic, explain and/or predict some or all of visual attentive behavior. A Computational Model of Visual Attention not only includes a process description for how attention is computed, but also can be tested by providing image inputs, similar to those an experimenter might present a subject, and then seeing how the model performs by comparison.",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:DUooU5lO8OsC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Indoor Place Recognition for Localization of Social Robots",
            "Publication year": 2016,
            "Publication url": "Unknown",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:bVPaY08nMUAC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Modeling task influences for saccade sequence and visual relevance prediction",
            "Publication year": 2019,
            "Publication url": "https://jov.arvojournals.org/article.aspx?articleid=2750325",
            "Abstract": "Previous work from Wloka et al.(2017) presented the Selective Tuning Attentive Reference model Fixation Controller (STAR-FC), an active vision model for saccade prediction. Although the model is able to efficiently predict saccades during free-viewing, it is well known that stimulus and task instructions can strongly affect eye movement patterns (Yarbus, 1967). These factors are considered in previous Selective Tuning architectures (Tsotsos and Kruijne, 2014)(Tsotsos, Kotseruba and Wloka, 2016)(Rosenfeld, Biparva & Tsotsos 2017), proposing a way to combine bottom-up and top-down contributions to fixation and saccade programming. In particular, task priming has been shown to be crucial to the deployment of eye movements, involving interactions between brain areas related to goal-directed behavior, working and long-term memory in combination with stimulus-driven eye movement neuronal correlates \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Ic6ZXhUAAAAJ:ms1Q_PLG2XUC",
            "Publisher": "The Association for Research in Vision and Ophthalmology"
        },
        {
            "Title": "Visual feature binding within the selective tuning attention framework",
            "Publication year": 2008,
            "Publication url": "https://www.worldscientific.com/doi/abs/10.1142/S0218001408006648",
            "Abstract": "We present a biologically plausible computational model for solving the visual feature binding problem, based on recent results regarding the time course and processing sequence in the primate visual system. The feature binding problem appears due to the distributed nature of visual processing in the primate brain, and the gradual loss of spatial information along the processing hierarchy. This paper puts forward the proposal that by using multiple passes of the visual processing hierarchy, both bottom-up and top-down, and using task information to tune the processing prior to each pass, we can explain the different recognition behaviors that primate vision exhibits. To accomplish this, four different kinds of binding processes are introduced and are tied directly to specific recognition tasks and their time course. The model relies on the reentrant connections so ubiquitous in the primate brain to recover spatial \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Ic6ZXhUAAAAJ:NhqRSupF_l8C",
            "Publisher": "World Scientific Publishing Company"
        },
        {
            "Title": "Cognitive programs: Software for attention's executive",
            "Publication year": 2014,
            "Publication url": "https://www.frontiersin.org/articles/10.3389/fpsyg.2014.01260/full",
            "Abstract": "What are the computational tasks that an executive controller for visual attention must solve? This question is posed in the context of the Selective Tuning model of attention. The range of required computations go beyond top-down bias signals or region-of-interest determinations, and must deal with overt and covert fixations, process timing and synchronization, information routing, memory, matching control to task, spatial localization, priming, and coordination of bottom-up with top-down information. During task execution, results must be monitored to ensure the expected results. This description includes the kinds of elements that are common in the control of any kind of complex machine or system. We seek a mechanistic integration of the above, in other words, algorithms that accomplish control. Such algorithms operate on representations, transforming a representation of one kind into another, which then forms the input to yet another algorithm. Cognitive Programs (CPs) are hypothesized to capture exactly such representational transformations via stepwise sequences of operations. CPs, an updated and modernized offspring of Ullman's Visual Routines, impose an algorithmic structure to the set of attentional functions and play a role in the overall shaping of attentional modulation of the visual system so that it provides its best performance. This requires that we consider the visual system as a dynamic, yet general-purpose processor tuned to the task and input of the moment. This differs dramatically from the almost universal cognitive and computational views, which regard vision as a passively observing module to which simple questions \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Ic6ZXhUAAAAJ:T_ojBgVMvoEC",
            "Publisher": "Frontiers"
        },
        {
            "Title": "Attention-based active visual search for mobile robots",
            "Publication year": 2020,
            "Publication url": "https://link.springer.com/article/10.1007/s10514-019-09882-z?wt_mc=Internal.Event.1.SEM.ArticleAuthorOnlineFirst&utm_source=ArticleAuthorOnlineFirst&utm_medium=email&utm_content=AA_en_06082018&ArticleAuthorOnlineFirst_20190806&error=cookies_not_supported&error=cookies_not_supported&code=d4cd130c-a234-4500-b184-800d558a7e0e&code=3e3844fc-4ea9-41f6-baa4-f51addca431e",
            "Abstract": "We present an active visual search model for finding objects in unknown environments. The proposed algorithm guides the robot towards the sought object using the relevant stimuli provided by the visual sensors. Existing search strategies are either purely reactive or use simplified sensor models that do not exploit all the visual information available. In this paper, we propose a new model that actively extracts visual information via visual attention techniques and, in conjunction with a non-myopic decision-making algorithm, leads the robot to search more relevant areas of the environment. The attention module couples both top-down and bottom-up attention models enabling the robot to search regions with higher importance first. The proposed algorithm is evaluated on a mobile robot platform in a 3D simulated environment. The results indicate that the use of visual attention significantly improves search, but the \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Ic6ZXhUAAAAJ:r0ARIG2f-gUC",
            "Publisher": "Springer US"
        },
        {
            "Title": "Region classification for robust floor detection in indoor environments",
            "Publication year": 2009,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-642-02611-9_71",
            "Abstract": "A novel framework based on stereo homography is proposed for robust floor/obstacle detection, capable of producing dense results. Floor surfaces and floor anomalies are identified at the pixel level using the symmetric transfer distance from the ground homography. Pixel-wise results are used as seed measurements for higher lever classification, where image regions with similar visual properties are processed and classified together. Without requiring any prior training, the method incrementally learns appearance models for the floor surfaces and obstacles in the environment, and uses the models to disambiguate regions where the homography-based classifier cannot provide a confident response. Several experiments on an indoor database of stereo images with ground truth data validate the robustness of our proposed technique.",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:738O_yMBCRsC",
            "Publisher": "Springer Berlin/Heidelberg"
        },
        {
            "Title": "Feature-based attention induces surround suppression during the perception of visual motion",
            "Publication year": 2021,
            "Publication url": "https://www.biorxiv.org/content/10.1101/2021.02.17.431646v1.abstract",
            "Abstract": "Attention to a stimulus feature prioritizes its processing while strongly suppressing the processing of similar features, a non-linear phenomenon called surround suppression. Here we investigated this phenomenon using neurophysiology and psychophysics. We recorded responses of motion direction-selective neurons in area MT/MST of monkeys in different conditions. When attention was allocated to a stimulus moving in the neurons9 preferred direction responses to a distractor were strongly suppressed for directions nearby the preferred direction. These effects were modeled as the interaction between two Gaussian fields representing narrowly-tuned excitatory and widely-tuned inhibitory inputs into a neuron, with attention more strongly modulating the gain of the inhibitory inputs. We additionally demonstrated a corresponding behavioral effect in humans: Feature-based attention strongly reduced motion repulsion in the vicinity of the attended motion direction. Our results demonstrate that feature-based attention can induce non-linear changes in neuronal tuning curves via unbalanced gain changes to excitatory and inhibitory inputs into neurons ultimately translating into similar effects during behavior.",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:Eqg1ddRpejoC",
            "Publisher": "Cold Spring Harbor Laboratory"
        },
        {
            "Title": "Knowledge Granularity Spectrum, Action Pyramid and the Scaling Problem",
            "Publication year": 2001,
            "Publication url": "https://www.worldscientific.com/doi/abs/10.1142/S0218001401000952",
            "Abstract": "In this paper we introduce the concept of knowledge granularity and study the relationship between different knowledge representation schemes and the scaling problem. By scale to a task, we mean that an agent's planning system and knowledge representation scheme are able to generate the range of behaviors required by the task in a timely fashion. Action selection is critical to an agent performing a task in a dynamic, unpredictable environment. Knowledge representation is central to the agent's action selection process. It is important to study how an agent should adapt its methods of representation such that its performance can scale to different task requirements. Here we study the following issues. One is the knowledge granularity problem: to what detail should an agent represent a certain kind of knowledge if a single granularity of representation is to be used. Another is the representation scheme problem \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Ic6ZXhUAAAAJ:BzfGm06jWhQC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Examining The Feasibility Of Face Gesture Detection For Monitoring Of Users Of Autonomous Wheelchairs",
            "Publication year": 2010,
            "Publication url": "Unknown",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:nVrZBo8bIpAC",
            "Publisher": "Unknown"
        },
        {
            "Title": "A statistical basis for visual field anisotropies",
            "Publication year": 2006,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S0925231205004236",
            "Abstract": "There exist numerous psychophysical paradigms for which performance varies with location of stimulus presentation within the visual field. The following considers potential bases for visual anisotropies, considering the possibility of a statistical basis for such effects in cases where basic sensory asymmetries are present. In particular, the relationship between scene statistics and both upper\u2013lower and lateral visual field asymmetries is considered. Finally, an argument is put forth concerning the apparent radial organization of the visual field, with the suggestion that geometric perspective may give rise to the statistical bias responsible for this effect.",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:1qzjygNMrQYC",
            "Publisher": "Elsevier"
        },
        {
            "Title": "A Tour of This Volume",
            "Publication year": 2005,
            "Publication url": "https://philpapers.org/rec/TOMATO-2",
            "Abstract": "Cyrille Michon, avec la Coll. De Olivier Boulnois, nathana\u00ebl Dupr\u00e9 la tour (\u00e9ds), Thomas d'aquin et la controverse sur l'\u00e9ternit\u00e9 du monde, traductions, pr\u00e9sentations et notes parc. Michon, avec laColl. D'o. Boulnois et de N. Dupr\u00e9 la tour, Paris, gf flammarion, 2004, 415p.[REVIEW] Kristell Trego-2005-Revue de Th\u00e9ologie Et de Philosophie 137: 57.",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:QYdC8u9Cj1oC",
            "Publisher": "Academic Press"
        },
        {
            "Title": "Short and Long-Term Attentional Firing Rates Can Be Explained by ST-Neuron Dynamics",
            "Publication year": 2018,
            "Publication url": "https://www.frontiersin.org/articles/10.3389/fnins.2018.00123/full",
            "Abstract": "Attention modulates neural selectivity and optimizes the allocation of cortical resources during visual tasks. A large number or experimental studies in primates and humans provide ample evidence. As an underlying principle of visual attention, some theoretical models suggested the existence of a gain element that enhances contrast of the attended stimuli. In contrast, the Selective Tuning model of attention (ST) proposes an attentional mechanism based on suppression of irrelevant signals. In this paper, we present an updated characterization of the ST-neuron proposed by the Selective Tuning model, and suggest that the inclusion of adaptation currents (Ih) to ST-neurons may explain the temporal profiles of the firing rates recorded in single V4 cells during attentional tasks. Furthermore, using the model we show that the interaction between stimulus-selectivity of a neuron and attention shapes the profile of the firing rate, and is enough to explain its fast modulation and other discontinuities observed, when the neuron responds to a sudden switch of stimulus, or when one stimulus is added to another during a visual task.",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:grZTYWtF7b0C",
            "Publisher": "Frontiers"
        },
        {
            "Title": "Joint attention in autonomous driving (JAAD)",
            "Publication year": 2016,
            "Publication url": "https://arxiv.org/abs/1609.04741",
            "Abstract": "In this paper we present a novel dataset for a critical aspect of autonomous driving, the joint attention that must occur between drivers and of pedestrians, cyclists or other drivers. This dataset is produced with the intention of demonstrating the behavioral variability of traffic participants. We also show how visual complexity of the behaviors and scene understanding is affected by various factors such as different weather conditions, geographical locations, traffic and demographics of the people involved. The ground truth data conveys information regarding the location of participants (bounding boxes), the physical conditions (e.g. lighting and speed) and the behavior of the parties involved.",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:6AKj_8xLoccC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Compact Neural Representation Using Attentive Network Pruning",
            "Publication year": 2020,
            "Publication url": "https://arxiv.org/abs/2005.04559",
            "Abstract": "Deep neural networks have evolved to become power demanding and consequently difficult to apply to small-size mobile platforms. Network parameter reduction methods have been introduced to systematically deal with the computational and memory complexity of deep networks. We propose to examine the ability of attentive connection pruning to deal with redundancy reduction in neural networks as a contribution to the reduction of computational demand. In this work, we describe a Top-Down attention mechanism that is added to a Bottom-Up feedforward network to select important connections and subsequently prune redundant ones at all parametric layers. Our method not only introduces a novel hierarchical selection mechanism as the basis of pruning but also remains competitive with previous baseline methods in the experimental evaluation. We conduct experiments using different network architectures on popular benchmark datasets to show high compression ratio is achievable with negligible loss of accuracy.",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:0J7bdoE8TH0C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Neurobiological Models of Visual Attention",
            "Publication year": 2003,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-1-4615-0111-4_21",
            "Abstract": "The number of models that address the neurobiology of visual attention in a non-trivial manner is small. The number that have real computational tests on actual images is even smaller. However, the history of important ideas that contribute to our understanding requires one to scan not only the neurobiological literature but also the psychological and computational literature. A selected historical perspective on these ideas is presented in this paper.",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:FiytvqdAVhgC",
            "Publisher": "Kluwer Academic/Plenum Publ."
        },
        {
            "Title": "Attending to visual motion",
            "Publication year": 2005,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S1077314205000779",
            "Abstract": "Visual motion analysis has focused on decomposing image sequences into their component features. There has been little success at re-combining those features into moving objects. Here, a novel model of attentive visual motion processing is presented that addresses both decomposition of the signal into constituent features as well as the re-combination, or binding, of those features into wholes. A new feed-forward motion-processing pyramid is presented motivated by the neurobiology of primate motion processes. On this structure the Selective Tuning (ST) model for visual attention is demonstrated. There are three main contributions: (1) a new feed-forward motion processing hierarchy, the first to include a multi-level decomposition with local spatial derivatives of velocity; (2) examples of how ST operates on this hierarchy to attend to motion and to localize and label motion patterns; and (3) a new solution to the \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Ic6ZXhUAAAAJ:uVUOdF_882EC",
            "Publisher": "Elsevier"
        },
        {
            "Title": "A framework for door localization and door opening using a robotic wheelchair for people living with mobility impairments",
            "Publication year": 2007,
            "Publication url": "https://scholar.google.com/scholar?cluster=4761108662172857521&hl=en&oi=scholarr",
            "Abstract": "We present a framework for localizing and opening doors that fall within our current field of view, using Playbot, a computer controlled wheelchair that is equipped with vision sensors and a 6+ 2 degrees of freedom robotic arm. Contributions of the paper include:(i) Reliable detection of a specular door handle from close distances, where intense specularities tend to make many object detection algorithms unreliable (ii) Reliable stereo vision depth extraction of a specular door handle and subsequent opening of the door using a 6+ 2 degrees of freedom robotic arm. We present results demonstrating the validity of the approach and we discuss promising directions for future research.",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:HeT0ZceujKMC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Attention in Cognitive Systems",
            "Publication year": 2009,
            "Publication url": "https://philpapers.org/rec/BRUAIC",
            "Abstract": "N. Bruce & J. Tsotsos, Attention in Cognitive Systems - PhilPapers Sign in | Create an account \nPhilPapers PhilPeople PhilArchive PhilEvents PhilJobs PhilPapers home Syntax Advanced \nSearch Syntax Advanced Search Syntax Advanced Search Attention in Cognitive Systems N. \nBruce & J. Tsotsos (2009) Abstract This article has no associated abstract. (fix it) Keywords \nNo keywords specified (fix it) Categories Attention and Consciousness in Psychology in \nPhilosophy of Cognitive Science (categorize this paper) Buy this book Find it on Amazon.com \nOptions Edit this record Mark as duplicate Export citation Find it on Scholar Request removal \nfrom index Translate to english Revision history Download options PhilArchive copy Upload \na copy of this paper Check publisher's policy Papers currently archived: 59,864 External links \nThis entry has no external links. Add one. Setup an account with your affiliations in order to (if .\u2026",
            "Abstract entirety": 0,
            "Author pub id": "Ic6ZXhUAAAAJ:UmS_249rOGwC",
            "Publisher": "Unknown"
        },
        {
            "Title": "The elephant in the room",
            "Publication year": 2018,
            "Publication url": "https://arxiv.org/abs/1808.03305",
            "Abstract": "We showcase a family of common failures of state-of-the art object detectors. These are obtained by replacing image sub-regions by another sub-image that contains a trained object. We call this \"object transplanting\". Modifying an image in this manner is shown to have a non-local impact on object detection. Slight changes in object position can affect its identity according to an object detector as well as that of other objects in the image. We provide some analysis and suggest possible reasons for the reported phenomena.",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:nlk6zB4cO3MC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Hierarchical classifiers for robust topological robot localization",
            "Publication year": 2012,
            "Publication url": "https://link.springer.com/article/10.1007/s10846-012-9671-z",
            "Abstract": "This paper presents a novel appearance-based technique for topological robot localization and place recognition. A vocabulary of visual words is formed automatically, representing local features that frequently occur in the set of training images. Using the vocabulary, a spatial pyramid representation is built for each image by repeatedly subdividing it and computing histograms of visual words at increasingly fine resolutions. An information maximization technique is then applied to build a hierarchical classifier for each class by learning informative features. While top-level features in the hierarchy are selected from the coarsest resolution of the representation, capturing the holistic statistical properties of the images, child features are selected from finer resolutions, encoding more local characteristics, redundant with the information coded by their parents. Exploiting the redundancy in the data enables the \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Ic6ZXhUAAAAJ:XUvXOeBm_78C",
            "Publisher": "Springer Netherlands"
        },
        {
            "Title": "Tractability and Attention: Key Roles in Robotic Visual Search",
            "Publication year": 2014,
            "Publication url": "https://smartech.gatech.edu/handle/1853/51324",
            "Abstract": "Visual search for objects, locations, or events of interest is a central capability for a robot with real-world utility. This capability cannot be limited to yes-no detection; it must include an ability to measure, describe, and compare within the context of a task. We have been investigating this problem since the late 1980s and regardless of the prevailing trends in machine vision, learning, or robotics, have not found reason to ignore the roles of attention, nor a deep understanding of the computational nature of the problem. This presentation will briefly trace our journey. Along the way, we emphasize a number of major points, including the roots of our approach in issues of tractability, the design and evaluation of our subsumptive search algorithm, the development of the AIM saliency model, the confounding nature of sensor bias, the integration of saliency within the object search algorithm, and the need for an overarching framework for attentive behavior, which we have named \u201cCognitive Programs.\u201d",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:zdjWy_NXXwUC",
            "Publisher": "Georgia Institute of Technology"
        },
        {
            "Title": "Neural mechanisms of surround attenuation and distractor competition in visual search",
            "Publication year": 2011,
            "Publication url": "https://www.jneurosci.org/content/31/14/5213?utm_source=TrendMD&utm_medium=cpc&utm_campaign=JNeurosci_TrendMD_0",
            "Abstract": "Visual attention biases relevant processing in the visual system by amplifying relevant or attenuating irrelevant sensory input. A potential signature of the latter operation, referred to as surround attenuation, has recently been identified in the electromagnetic brain response of human observers performing visual search. It was found that a zone of attenuated cortical excitability surrounds the target when the search required increased spatial resolution for item discrimination. Here we address the obvious hypothesis that surround attenuation serves distractor suppression in the vicinity of the target where interference from irrelevant search items is maximal. To test this hypothesis, surround attenuation was assessed under conditions when the target was presented in isolation versus when it was surrounded by distractors. Surprisingly, substantial and indistinguishable surround attenuation was seen under both \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Ic6ZXhUAAAAJ:_Ybze24A_UAC",
            "Publisher": "Society for Neuroscience"
        },
        {
            "Title": "A possible reason for why data-driven beats theory-driven computer vision",
            "Publication year": 2019,
            "Publication url": "https://arxiv.org/abs/1908.10933",
            "Abstract": "Why do some continue to wonder about the success and dominance of deep learning methods in computer vision and AI? Is it not enough that these methods provide practical solutions to many problems? Well no, it is not enough, at least for those who feel there should be a science that underpins all of this and that we should have a clear understanding of how this success was achieved. Here, this paper proposes that the dominance we are witnessing would not have been possible by the methods of deep learning alone: the tacit change has been the evolution of empirical practice in computer vision and AI over the past decades. We demonstrate this by examining the distribution of sensor settings in vision datasets and performance of both classic and deep learning algorithms under various camera settings. This reveals a strong mismatch between optimal performance ranges of classical theory-driven algorithms and sensor setting distributions in the common vision datasets, while data-driven models were trained for those datasets. The head-to-head comparisons between data-driven and theory-driven models were therefore unknowingly biased against the theory-driven models.",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:kWRwubw1DjEC",
            "Publisher": "Unknown"
        },
        {
            "Title": "STNet: selective tuning of convolutional networks for object localization",
            "Publication year": 2017,
            "Publication url": "http://openaccess.thecvf.com/content_ICCV_2017_workshops/w40/html/Biparva_STNet_Selective_Tuning_ICCV_2017_paper.html",
            "Abstract": "Visual attention modeling has recently gained momentum in developing visual hierarchies provided by Convolutional Neural Networks. Despite recent successes of feedforward processing on the abstraction of concepts form raw images, the inherent nature of feedback processing has remained computationally controversial. Inspired by the computational models of covert visual attention, we propose the Selective Tuning of Convolutional Networks (STNet). It is composed of both streams of Bottom-Up and Top-Down information processing to selectively tune the visual representation of convolutional networks. We experimentally evaluate the performance of STNet for the weakly-supervised localization task on the ImageNet benchmark dataset. We demonstrate that STNet not only successfully surpasses the state-of-the-art results but also generates attention-driven class hypothesis maps.",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:E5exOps3BD0C",
            "Publisher": "Unknown"
        },
        {
            "Title": "The attentional suppressive surround: Eccentricity, location-based and feature-based effects and interactions",
            "Publication year": 2018,
            "Publication url": "https://www.frontiersin.org/articles/10.3389/fnins.2018.00710/full",
            "Abstract": "The Selective Tuning model of visual attention (Tsotsos, 1990) has proposed that the focus of attention is surrounded by an inhibitory zone, eliciting a center-surround attentional distribution. This attentional suppressive surround inhibits irrelevant information which is located close to attended information in physical space (e.g., Cutzu and Tsotsos, 2003; Hopf et al., 2010) or in feature space (e.g., Bartsch et al., 2017; St\u00f6rmer and Alvarez, 2014; Tombu and Tsotsos, 2008). In Experiment 1, we investigate the interaction between location-based and feature-based surround suppression and hypothesize that the attentional surround suppression would be maximized when spatially adjacent stimuli are also represented closely within a feature map. Our results demonstrate that perceptual discrimination is worst when two similar orientations are presented in proximity to each other, suggesting the interplay of the two surround suppression mechanisms. The Selective Tuning model also predicts that the size of the attentional suppressive surround is determined by the receptive field size of the neuron which optimally processes the attended information. The receptive field size of the processing neurons is tightly associated with stimulus size and eccentricity. Therefore, Experiment 2 tested the hypothesis that the size of the attentional suppressive surround would become larger as stimulus size and eccentricity increase, corresponding to an increase in the neuron\u2019s receptive field size. We show that stimulus eccentricity but not stimulus size modulates the size of the attentional suppressive surround. These results are consistent for both low- and high-level \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Ic6ZXhUAAAAJ:cOP-uZQ6k_YC",
            "Publisher": "Frontiers"
        },
        {
            "Title": "Separable linear classifiers for online learning in appearance based object detection",
            "Publication year": 2005,
            "Publication url": "https://link.springer.com/chapter/10.1007/11556121_43",
            "Abstract": "Online learning for object detection is an important requirement for many computer vision applications. In this paper, we present an iterative optimization algorithm that learns separable linear classifiers from a sample of positive and negative example images. We demonstrate that separability not only leads to rapid runtime behavior but enables very fast training. Experimental results underline that the approach even allows for real time online learning for tracking of articulated objects in real world environments.",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:JoZmwDi-zQgC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "Two-Stream Networks for Lane-Change Prediction of Surrounding Vehicles",
            "Publication year": 2020,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/9294326/",
            "Abstract": "In highway scenarios, an alert human driver will typically anticipate early cut-in and cut-out maneuvers of surrounding vehicles using only visual cues. An automated system must anticipate these situations at an early stage too, to increase the safety and the efficiency of its performance. To deal with lane-change recognition and prediction of surrounding vehicles, we pose the problem as an action recognition/prediction problem by stacking visual cues from video cameras. Two video action recognition approaches are analyzed: two-stream convolutional networks and spatiotemporal multiplier networks. Different sizes of the regions around the vehicles are analyzed, evaluating the importance of the interaction between vehicles and the context information in the performance. In addition, different prediction horizons are evaluated. The obtained results demonstrate the potential of these methodologies to serve as robust \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Ic6ZXhUAAAAJ:5s5aUJDWGkQC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Sensor Planning for Optimal 3D Visual Search with Task Constraints",
            "Publication year": 2016,
            "Publication url": "Unknown",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:5WkdyjDMKEYC",
            "Publisher": "Unknown"
        },
        {
            "Title": "A large-scale touch sensitive display",
            "Publication year": 2008,
            "Publication url": "https://www.researchgate.net/profile/John-Tsotsos/publication/268346094_A_large-scale_touch_sensitive_display/links/54b9209f0cf28faced626f7d/A-large-scale-touch-sensitive-display.pdf",
            "Abstract": "Large scale displays present a number of challenges in terms of physical construction and software control. This paper describes a software and hardware infrastructure that supports extremely large interactive display surfaces. The resulting device is capable of supporting multiple users interacting with the display surface simultaneously and the display of complex interactive graphics over expansive high resolution displays. A specific implementation 36\u201d\u00d7 54\u201d with a pixel resolution of 5040\u00d7 3150 pixels is presented.",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:Fu2w8maKXqMC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Hierarchical appearance-based classifiers for qualitative spatial localization",
            "Publication year": 2009,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/5354577/",
            "Abstract": "This paper presents a novel appearance-based technique for qualitative spatial localization. A vocabulary of visual words is built automatically, representing local features that repeatedly occur in the set of training images. An information maximization technique is then applied to build a hierarchical classifier for each environment by learning informative visual words. Child nodes in this hierarchy encode information redundant with information coded by their parents. In localization, hierarchical classifiers are used in a top-down manner, where top-level visual words are examined first, and for each top-level visual word which does not respond as expected, its lower-level visual words are examined. This allows inference to recover from missing features encoded by higher-level visual words. Several experiments on a challenging localization database demonstrate the advantages of our hierarchical framework and \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Ic6ZXhUAAAAJ:hkOj_22Ku90C",
            "Publisher": "IEEE"
        },
        {
            "Title": "Re-Visiting Visual Routines: A White Paper",
            "Publication year": 2010,
            "Publication url": "https://www.eecs.yorku.ca/research/techreports/2010/CSE-2010-11.pdf",
            "Abstract": "This White Paper lays out a set of new research objectives and the skeleton of a plan on how to achieve these. The objectives were motivated by the desire to take the successful Selective Tuning model of visual attention (ST) and move it to the next stage of its natural development. A key missing element of ST is an executive controller, a component that uses the attentional processes that Selective Tuning provides in solving real problems associated with visual perception, visual cognition and reasoning, including the use of vision for the guidance of action. To this end, the conceptualization of Ullman's Visual Routines seems to provide the best starting point. This extremely brief White Paper presents a proposal for how Ullman's work may be re-examined in the light of an up-todate understanding of visual attention and visual processing more generally. Conceptually, Ullman's contribution was significant but he left most of the details unspecified. This proposal suggests ways to update Ullman's visual routines concept given modern views on vision and attention, and moves to subsequently revise, extend and flesh-out the ideas in order to provide the functionality required to develop an executive controller for ST.",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:foquWX3nUaYC",
            "Publisher": "York University, Technical Report CSE-2010-11, October 1"
        },
        {
            "Title": "Attentional modulation and selection\u2013an integrated approach",
            "Publication year": 2014,
            "Publication url": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0099681",
            "Abstract": "Various models of the neural mechanisms of attentional modulation in the visual cortex have been proposed. In general, these models assume that an \u2018attention\u2019 parameter is provided separately. Its value as well as the selection of neuron(s) to which it applies are assumed, but its source and the selection mechanism are unspecified. Here we show how the Selective Tuning model of visual attention can account for the modulation of the firing rate at the single neuron level, and for the temporal pattern of attentional modulations in the visual cortex, in a self-contained formulation that simultaneously determines the stimulus elements to be attended while modulating the relevant neural processes.",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:RJOyoaXV5v8C",
            "Publisher": "Public Library of Science"
        },
        {
            "Title": "Next-Best-View Estimation based on Deep Reinforcement Learning for Active Object Classification",
            "Publication year": 2021,
            "Publication url": "https://arxiv.org/abs/2110.06766",
            "Abstract": "The presentation and analysis of image data from a single viewpoint are often not sufficient to solve a task. Several viewpoints are necessary to obtain more information. The $\\textit{next-best-view}$ problem attempts to find the optimal viewpoint with the greatest information gain for the underlying task. In this work, a robot arm holds an object in its end-effector and searches for a sequence of next-best-view to explicitly identify the object. We use Soft Actor-Critic (SAC), a method of deep reinforcement learning, to learn these next-best-views for a specific set of objects. The evaluation shows that an agent can learn to determine an object pose to which the robot arm should move an object. This leads to a viewpoint that provides a more accurate prediction to distinguish such an object from other objects better. We make the code publicly available for the scientific community and for reproducibility under $\\href{https://github.com/ckorbach/nbv_rl}{\\text{this https link}}$.",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:-gKCQx66J1MC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Visual correlates of fixation selection: a look at the spatial frequency domain",
            "Publication year": 2007,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/4379303/",
            "Abstract": "A representation for observing local image content is proposed for the purpose of considering the distinguishing characteristics of visual content that tends to draw a human observers gaze. Within this representation, the spectral profile distinguishing fixated from non-fixated locations is considered. Finally, the possibility of designing saliency operators based on the proposed local magnitude spectrum representation is explored, revealing a promising domain for predicting human gaze patterns.",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:tOudhMTPpwUC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Efficient and generalizable statistical models of shape and appearance for analysis of cardiac MRI",
            "Publication year": 2008,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S1361841508000029",
            "Abstract": "We present a framework for the analysis of short axis cardiac MRI, using statistical models of shape and appearance. The framework integrates temporal and structural constraints and avoids common optimization problems inherent in such high dimensional models. The first contribution is the introduction of an algorithm for fitting 3D active appearance models (AAMs) on short axis cardiac MRI. We observe a 44-fold increase in fitting speed and a segmentation accuracy that is on par with Gauss\u2013Newton optimization, one of the most widely used optimization algorithms for such problems. The second contribution involves an investigation on hierarchical 2D + time active shape models (ASMs), that integrate temporal constraints and simultaneously improve the 3D AAM based segmentation. We obtain encouraging results (endocardial/epicardial error 1.43 \u00b1 0.49 mm/1.51 \u00b1 0.48 mm) on 7980 short axis cardiac MR \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Ic6ZXhUAAAAJ:ULOm3_A8WrAC",
            "Publisher": "Elsevier"
        },
        {
            "Title": "Biologically motivated local contextual modulation improves low-level visual feature representations",
            "Publication year": 2012,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-642-31295-3_10",
            "Abstract": "This paper describes a biologically motivated local context operator to improve low-level visual feature representations. The computation borrows the idea from the primate visual system that different visual features are computed with different speeds in the visual system and thus they can positively affect each other via early recurrent modulations. The modulation improves visual representation by suppressing responses with respect to background pixels, cluttered scene parts and image noise. The proposed local contextual computation is fundamentally different from exiting approaches that involve \u201cwhole scene\u201d perspectives. Context-modulated visual feature representations are tested in a variety of existing saliency algorithms. Using real images and videos, we quantitatively compare output saliency representations between modulated and non-modulated architectures with respect to human \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Ic6ZXhUAAAAJ:1yWc8FF-_SYC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "May I have your Attention Please?",
            "Publication year": 2018,
            "Publication url": "Unknown",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:boxvjr4fIrYC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Active Vision",
            "Publication year": 2020,
            "Publication url": "Unknown",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:zebm8Pw5eyMC",
            "Publisher": "Springer, Berlin, Heidelberg,"
        },
        {
            "Title": "A robust motion detection and estimation filter for video signals",
            "Publication year": 2001,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/959033/",
            "Abstract": "The problem of detecting areas of motion in video sequences and estimating parameters such as speed, direction and dynamics is addressed in many applications of image processing such as video surveillance, object tracking, image stream compression or autonomous navigation systems. Real world computer vision highly depends on reliable, robust systems for recognition of motion cues to make accurate high-level decisions about its surroundings. In this paper, we present a simple, yet high performance low-level filter for motion detection and estimation in digitized video signals. The algorithm is based on constant characteristics of a common, 2-frame interlaced video signal, yet its applicability to generically acquired image sequences is shown as well. In general, our approach presents a computationally low-cost solution to motion estimation application and compares very well to existing approaches due to \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Ic6ZXhUAAAAJ:eJXPG6dFmWUC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Poster Presentations 1-Image Analysis, Computer Vision, Machine Vision, and Applications-A Novel Algorithm for Fitting 3-D Active Appearance Models: Applications to Cardiac MRI Segmentation",
            "Publication year": 2005,
            "Publication url": "https://scholar.google.com/scholar?cluster=514247806422960978&hl=en&oi=scholarr",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:z_wVstp3MssC",
            "Publisher": "Berlin: Springer-Verlag, 1973-"
        },
        {
            "Title": "Robot navigation via spatial and temporal coherent semantic maps",
            "Publication year": 2016,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S0952197615002596",
            "Abstract": "The ability of mobile robots to sense, interpret and map their environments in human terms is decisive for their applicability to everyday activities hereafter. Bearing this view in mind, we present here, for the first time, an integrated framework that aims: (i) to introduce a semantic mapping method and (ii) to use this semantic map, as a means to provide a hierarchical navigation solution. The semantic map is formed in a bottom-up fashion, along the robot\u05f3s course, relying on the conceptual space quantization, the time proximity and the spatial coherence integrated into the labeled sparse topological map. A novel time-evolving augmented navigation graph determines the semantic topology of the explored environment and the connectivity among the recognized places expressed by the inter-place transition probability. The robot navigation part is addressed through an interface that facilitates human robot interaction \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Ic6ZXhUAAAAJ:BmWJbWwHJAwC",
            "Publisher": "Pergamon"
        },
        {
            "Title": "The Complexity of Search Tasks",
            "Publication year": 2003,
            "Publication url": "Unknown",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:IaI1MmNe2tcC",
            "Publisher": "Kluwer Academic/Plenum Publ."
        },
        {
            "Title": "STAR-RT: Visual attention for real-time video game playing",
            "Publication year": 2017,
            "Publication url": "https://arxiv.org/abs/1711.09464",
            "Abstract": "In this paper we present STAR-RT - the first working prototype of Selective Tuning Attention Reference (STAR) model and Cognitive Programs (CPs). The Selective Tuning (ST) model received substantial support through psychological and neurophysiological experiments. The STAR framework expands ST and applies it to practical visual tasks. In order to do so, similarly to many cognitive architectures, STAR combines the visual hierarchy (based on ST) with the executive controller, working and short-term memory components and fixation controller. CPs in turn enable the communication among all these elements for visual task execution. To test the relevance of the system in a realistic context, we implemented the necessary components of STAR and designed CPs for playing two closed-source video games - Canabaltand Robot Unicorn Attack. Since both games run in a browser window, our algorithm has the same amount of information and the same amount of time to react to the events on the screen as a human player would. STAR-RT plays both games in real time using only visual input and achieves scores comparable to human expert players. It thus provides an existence proof for the utility of the particular CP structure and primitives used and the potential for continued experimentation and verification of their utility in broader scenarios.",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:EMrlLOzmm-AC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Bridging cognitive programs and machine learning",
            "Publication year": 2018,
            "Publication url": "https://arxiv.org/abs/1802.06091",
            "Abstract": "While great advances are made in pattern recognition and machine learning, the successes of such fields remain restricted to narrow applications and seem to break down when training data is scarce, a shift in domain occurs, or when intelligent reasoning is required for rapid adaptation to new environments. In this work, we list several of the shortcomings of modern machine-learning solutions, specifically in the contexts of computer vision and in reinforcement learning and suggest directions to explore in order to try to ameliorate these weaknesses.",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:xdWr7vBG5PQC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Incremental Learning Through Deep Adaptation",
            "Publication year": 2018,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/8554156/",
            "Abstract": "Given an existing trained neural network, it is often desirable to learn new capabilities without hindering performance of those already learned. Existing approaches either learn sub-optimal solutions, require joint training, or incur a substantial increment in the number of parameters for each added domain, typically as many as the original network. We propose a method called Deep Adaptation Modules (DAM) that constrains newly learned filters to be linear combinations of existing ones. DAMs precisely preserve performance on the original domain, require a fraction (typically 13 percent, dependent on network architecture) of the number of parameters compared to standard fine-tuning procedures and converge in less cycles of training to a comparable or better level of performance. When coupled with standard network quantization techniques, we further reduce the parameter cost to around 3 percent of the original \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Ic6ZXhUAAAAJ:vQNBHXYRXdUC",
            "Publisher": "IEEE"
        },
        {
            "Title": "An attentional framework for stereo vision",
            "Publication year": 2005,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/1443116/",
            "Abstract": "The necessity and utility of visual attention are discussed in the context of stereo vision in machines and primates. Specific problems that arise in this domain including binocular rivalry, and the deployment of attention in three-dimensional space are considered. Necessary conditions are outlined for achieving appropriate attentional behaviour in both the aforementioned domains. In this light, we outline classes of existing computational models of attention and discuss their applicability for realizing binocular attention. Finally, a stereo attention framework is presented by considering the tenets of an existing attentional architecture that extends naturally to the binocular domain, in conjunction with the connectivity of units involved in achieving stereo vision.",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:dshw04ExmUIC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Separable linear discriminant classification",
            "Publication year": 2005,
            "Publication url": "https://link.springer.com/chapter/10.1007/11550518_40",
            "Abstract": "Linear discriminant analysis is a popular technique in computer vision, machine learning and data mining. It has been successfully applied to various problems, and there are numerous variations of the original approach. This paper introduces the idea of separable LDA. Towards the problem of binary classification for visual object recognition, we derive an algorithm for training separable discriminant classifiers. Our approach provides rapid training and runtime behavior and also tackles the small sample size problem. Experimental results show that the method performs robust and allows for online learning.",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:4fKUyHm3Qg0C",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "50 years of object recognition: Directions forward",
            "Publication year": 2013,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S107731421300091X",
            "Abstract": "Object recognition systems constitute a deeply entrenched and omnipresent component of modern intelligent systems. Research on object recognition algorithms has led to advances in factory and office automation through the creation of optical character recognition systems, assembly-line industrial inspection systems, as well as chip defect identification systems. It has also led to significant advances in medical imaging, defence and biometrics. In this paper we discuss the evolution of computer-based object recognition systems over the last fifty years, and overview the successes and failures of proposed solutions to the problem. We survey the breadth of approaches adopted over the years in attempting to solve the problem, and highlight the important role that active and attentive approaches must play in any solution that bridges the semantic gap in the proposed object representations, while simultaneously \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Ic6ZXhUAAAAJ:QUX0mv85b1cC",
            "Publisher": "Academic Press"
        },
        {
            "Title": "Focusing on Selection for Fixation",
            "Publication year": 2016,
            "Publication url": "https://docs.lib.purdue.edu/modvis/2016/session02/1/",
            "Abstract": "Building on our presentation at MODVIS 2015, we continue in our quest to discover a functional, computational, explanation of the relationship among visual attention, interpretation of visual stimuli, and eye movements, and how these produce visual behavior. Here, we focus on one component, how selection is accomplished for the next fixation. The popularity of saliency map models drives the inference that this is solved; we suggested otherwise at MODVIS 2015. Here, we provide additional empirical and theoretical arguments. We then develop arguments that a cluster of complementary, conspicuity representations drive selection, modulated by task goals and history, leading to a blended process that encompasses early, mid-level and late attentional selection and reflects the differences between central and peripheral processes. This design is also constrained by the architectural characteristics of the visual processing pathways, specifically, the boundary problem, as well as retinal photoreceptor distribution. These elements combine into a new strategy for computing fixation targets and a first simulation of its performance is presented.",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:1DhOeZtQFr0C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Focus: Attention Science: Attention: The Messy Reality",
            "Publication year": 2019,
            "Publication url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6430176/",
            "Abstract": "The human capability to attend has been both considered as easy and as impossible to understand by philosophers and scientists through the centuries. Much has been written by brain, cognitive, and philosophical scientists trying to explain attention as it applies to sensory and reasoning processes, let alone consciousness. It has been only in the last few decades that computational scientists have entered the picture adding a new language with which to express attentional behavior and function. This new perspective has produced some progress to the centuries-old goal, but there is still far to go. Although a central belief in many scientific disciplines has been to seek a unifying explanatory principle for natural observations, it may be that we need to put this aside as it applies to attention and accept the fact that attention is really an integrated set of mechanisms, too messy to cleanly and parsimoniously express \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Ic6ZXhUAAAAJ:RcYKfjg9Zh4C",
            "Publisher": "Yale Journal of Biology and Medicine"
        },
        {
            "Title": "On sensor bias in experimental methods for comparing interest-point, saliency, and recognition algorithms",
            "Publication year": 2011,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/5765998/",
            "Abstract": "Most current algorithm evaluation protocols use large image databases, but give little consideration to imaging characteristics used to create the data sets. This paper evaluates the effects of camera shutter speed and voltage gain under simultaneous changes in illumination and demonstrates significant differences in the sensitivities of popular vision algorithms under variable illumination, shutter speed, and gain. These results show that offline data sets used to evaluate vision algorithms typically suffer from a significant sensor specific bias which can make many of the experimental methodologies used to evaluate vision algorithms unable to provide results that generalize in less controlled environments. We show that for typical indoor scenes, the different saturation levels of the color filters are easily reached, leading to the occurrence of localized saturation which is not exclusively based on the scene radiance but \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Ic6ZXhUAAAAJ:BUYA1_V_uYcC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Fast learning for customizable head pose recognition in robotic wheelchair control",
            "Publication year": 2006,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/1613038/",
            "Abstract": "In the PLAYBOT project, we aim at assisting disabled children at play. To this end, we are developing a semi autonomous robotic wheelchair. It is equipped with several visual sensors and a robotic manipulator and thus conveniently enhances the innate capabilities of a disabled child. In addition to a touch screen, the child may control the wheelchair using simple head movements. As control based on head posture requires reliable face detection and head pose recognition, we are in need of a robust technique that may effortlessly be tailored to individual users. In this paper, we present a multilinear classification algorithm for fast and reliable face detection. It trains within seconds and thus can easily be customized to the home environment of a disabled child. Subsequent head pose recognition is done using support vector machines. Experimental results show that this two stage approach to head pose-based \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Ic6ZXhUAAAAJ:J-pR_7NvFogC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Local feature analysis for robust face recognition",
            "Publication year": 2009,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/5356524/",
            "Abstract": "In this paper a novel technique for face recognition is proposed. Using the statistical local feature analysis (LFA) technique, a set of feature points is extracted from each face image, at locations with highest deviations from the statistical expected face. Each feature point is described by a set of Gabor wavelet responses at different frequencies and orientations. A triangle-inequality-based pruning algorithm is developed for fast matching, which automatically chooses a set of key features from the database of model features and uses the pre-computed distances of the keys to the database, along with the triangle inequality, in order to speedily compute lower bounds on the distances from a query feature to the database, and eliminate the unnecessary direct comparisons. Our proposed technique achieves perfect results on the ORL face set and an accuracy rate of 99.1% on the FERET face set, which shows the \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Ic6ZXhUAAAAJ:ye4kPcJQO24C",
            "Publisher": "IEEE"
        },
        {
            "Title": "Computer vision systems",
            "Publication year": 2008,
            "Publication url": "https://repository.vnu.edu.vn/handle/VNU_123/27888",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:ZKH7YajmJZgC",
            "Publisher": "Springer"
        },
        {
            "Title": "Guest Editorial Representations and Architectures for Cognitive Systems",
            "Publication year": 2010,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/5645771/",
            "Abstract": "The seven papers in this special issue focus on the development of artificial cognitive systems.",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:GtLg2Ama23sC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Towards the dream of intelligent, visually-guided wheelchairs",
            "Publication year": 2007,
            "Publication url": "https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.590.8272&rep=rep1&type=pdf",
            "Abstract": "An important focus of research into smart wheelchairs aims to assist people living with physical disabilities and possibly without speech but with normal cognitive functioning, vision and audition. What is sought is a wheelchair that is intelligent, that can visually understand the world and will do precisely what its operator wants, without tedious and detailed user control. This dream has yet to be achieved [21].These potential wheelchair users have the ability to issue high-level, sentential commands resembling natural language. Commands may include references to objects present in the environment that can be observed visually by both the smart wheelchair and its user. Given this, a truly intelligent wheelchair robot should be able to interpret the commands accurately and execute them safely. Required capabilities include object recognition, knowledge of objects and locations, landmark-based navigation, visual search, planning and reasoning about tasks, executive control and failure recovery. Also",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:fPk4N6BV_jEC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Do they want to cross? understanding pedestrian intention for behavior prediction",
            "Publication year": 2020,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/9304591/",
            "Abstract": "Driving in urban traffic requires making quick and safe decisions while interacting with multiple pedestrians and other road users. Early anticipation of others' intentions is especially important for predicting their future behavior. In this work, we explore the human ability to estimate intentions of pedestrians in typical urban traffic conditions. Towards this goal, we analyze the results of our large-scale experiment that involved over 700 subjects to establish a human reference point for the task of pedestrian intention estimation. We determine what visual features correlate with human decisions and the relative difficulty of scenarios and validate our conclusions using a linear logistic model. Furthermore, we propose two models to demonstrate the benefits of using intention for pedestrian trajectory and future crossing action prediction. Our experiments show that an improvement of up to 5 % can be achieved on both tasks.",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:1l_TmcoA3R8C",
            "Publisher": "IEEE"
        },
        {
            "Title": "Fast pattern recognition using normalized grey-scale correlation in a pyramid image representation",
            "Publication year": 2008,
            "Publication url": "https://link.springer.com/article/10.1007/s00138-007-0089-8",
            "Abstract": "The ability to quickly locate one or more instances of a model in a grey scale image is of importance to industry. The recognition/localization must be fast and accurate. In this paper we present an algorithm which incorporates normalized correlation into a pyramid image representation structure to perform fast recognition and localization. The algorithm employs an estimate of the gradient of the correlation surface to perform a steepest descent search. Test results are given detailing search time by target size, effect of rotation and scale changes on performance, and accuracy of the subpixel localization algorithm used in the algorithm. Finally, results are given for searches on real images with perspective distortion and the addition of Gaussian noise.",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:3s1wT3WcHBgC",
            "Publisher": "Springer-Verlag"
        },
        {
            "Title": "Revisting Active Perception",
            "Publication year": 2017,
            "Publication url": "https://link.springer.com/article/10.1007/s10514-017-9615-3",
            "Abstract": "Despite the recent successes in robotics, artificial intelligence and computer vision, a complete artificial agent necessarily must include active perception. A multitude of ideas and methods for how to accomplish this have already appeared in the past, their broader utility perhaps impeded by insufficient computational power or costly hardware. The history of these ideas, perhaps selective due to our perspectives, is presented with the goal of organizing the past literature and highlighting the seminal contributions. We argue that those contributions are as relevant today as they were decades ago and, with the state of modern computational tools, are poised to find new life in the robotic perception systems of the next decade.",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:gD_FYv0mKhcC",
            "Publisher": "Springer"
        },
        {
            "Title": "Learning a model of shape selectivity in V4 cells reveals shape encoding mechanisms in the brain",
            "Publication year": 2021,
            "Publication url": "https://jov.arvojournals.org/article.aspx?articleid=2777042",
            "Abstract": "The mechanisms of local shape information transformation from V1 to more abstract representations in IT are unknown. Studying the selectivities in intermediate stages of transformation suggest plausible mechanisms. For example, Pasupathy and Conner [1] studied Macaque V4 responses to convexities and concavities. They found that these neurons are selective to boundary configurations at a specific position in the stimulus, for example, a convexity adjacent to a concavity. Although such investigations reveal intermediate shape representations in the brain, they often do not suffice in capturing complex and long-range interactions within the receptive field due to imposing priors on tunings, eg, fitting a single Gaussian to neuron responses. Here, we propose a learning-based approach that eliminates the need for such strong priors. Specifically, we investigate shape representation in Macaque V4 cells and \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Ic6ZXhUAAAAJ:dWFDXTerv58C",
            "Publisher": "The Association for Research in Vision and Ophthalmology"
        },
        {
            "Title": "Visual saliency improves autonomous visual search",
            "Publication year": 2014,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/6816832/",
            "Abstract": "Visual search for a specific object in an unknown environment by autonomous robots is a complex task. The key challenge is to locate the object of interest while minimizing the cost of search in terms of time or energy consumption. Given the impracticality of examining all possible views of the search environment, recent studies suggest the use of attentive processes to optimize visual search. In this paper, we describe a method of visual search that exploits the use of attention in the form of a saliency map. This map is used to update the probability distribution of which areas to examine next, increasing the utility of spatial volumes where objects consistent with the target's visual saliency are observed. We present experimental results on a mobile robot and conclude that our method improves the process of visual search in terms of reducing the time and number of actions to be performed to complete the process.",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:eGYfIraVYiQC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Computer Vision",
            "Publication year": 2003,
            "Publication url": "Unknown",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:artPoR2Yc-kC",
            "Publisher": "Nature Publishing Group"
        },
        {
            "Title": "Visual Place Categorization in Indoor Environments",
            "Publication year": 2012,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/6233175/",
            "Abstract": "This paper addresses the problem of visual place categorization, which aims at augmenting different locations of the environment visited by an autonomous robot with information that relates them to human-understandable concepts. We formulate the problem of visual place categorization in terms of energy minimization. To label visual observations with place categories we present a global image representation that is invariant to common changes in dynamic environments and robust against intra-class variations. To satisfy temporal consistency, a general solution is presented that incorporates statistical cues, without being restricted by constant and small neighbourhood radii, or being dependent on the actual path followed by the robot. A set of experiments on publicly available databases demonstrates the advantages of the presented system and show a significant improvement over available methods.",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:CdxZDUztZiMC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Joint attention in driver-pedestrian interaction: from theory to practice",
            "Publication year": 2018,
            "Publication url": "https://arxiv.org/abs/1802.02522",
            "Abstract": "Today, one of the major challenges that autonomous vehicles are facing is the ability to drive in urban environments. Such a task requires communication between autonomous vehicles and other road users in order to resolve various traffic ambiguities. The interaction between road users is a form of negotiation in which the parties involved have to share their attention regarding a common objective or a goal (e.g. crossing an intersection), and coordinate their actions in order to accomplish it. In this literature review we aim to address the interaction problem between pedestrians and drivers (or vehicles) from joint attention point of view. More specifically, we will discuss the theoretical background behind joint attention, its application to traffic interaction and practical approaches to implementing joint attention for autonomous vehicles.",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:BAB3QVgpZKkC",
            "Publisher": "Unknown"
        },
        {
            "Title": "System and method for face recognition",
            "Publication year": 2018,
            "Publication url": "https://patents.google.com/patent/US9940506B2/en",
            "Abstract": "A system and method for generating a descriptor for a face is provided. The descriptor is operable to generate information about a given region in a face image to enable face recognition. The descriptor provided herein is a low dimension relative to many existing descriptors providing similar face recognition accuracy. In another aspect, a system and method for face recognition is provided.",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:tHxcpc5o5bgC",
            "Publisher": "Unknown"
        },
        {
            "Title": "A brief and selective history of attention",
            "Publication year": 2005,
            "Publication url": "https://philpapers.org/rec/TSOABA",
            "Abstract": "John K. Tsotsos, Laurent Itti & Geraint Rees, A brief and selective history of attention - \nPhilPapers Sign in | Create an account PhilPapers PhilPeople PhilArchive PhilEvents \nPhilJobs PhilPapers home Syntax Advanced Search Syntax Advanced Search Syntax \nAdvanced Search A brief and selective history of attention John K. Tsotsos, Laurent Itti & \nGeraint Rees In Laurent Itti, Geraint Rees & John K. Tsotsos (eds.), Neurobiology of \nAttention. Academic Press (2005) Abstract This article has no associated abstract. (fix it) \nKeywords No keywords specified (fix it) Categories Attention and Consciousness in \nPsychology in Philosophy of Cognitive Science (categorize this paper) Options Edit this \nrecord Mark as duplicate Export citation Find it on Scholar Request removal from index \nRevision history Download options PhilArchive copy Upload a copy of this paper Check \npublisher's policy Papers currently archived: 53,719 links ..(\u2026",
            "Abstract entirety": 0,
            "Author pub id": "Ic6ZXhUAAAAJ:YFjsv_pBGBYC",
            "Publisher": "Elsevier, San Diego, CA"
        },
        {
            "Title": "Long-term memory and",
            "Publication year": 2020,
            "Publication url": "https://pdfs.semanticscholar.org/945a/8e66429419f095999eb947ad3327d6505649.pdf",
            "Abstract": "Journal of Vision (2020) 20 (5): 10, 1\u201314 Yoo et al. 2 search time and fixation duration decreased, and gaze was directed closer to the target region, than when they forgot targets. These effects were seen even after a one-month delay from their initial viewing, suggesting the effects are associated with long-term, explicit memory. Saccadic amplitude was not strongly modulated by scene repetition or explicit recall of targets. The amnesic person did not show explicit recall or implicit repetition effects, whereas his control group showed similar patterns to those seen in Experiment 1. The results reveal several aspects of gaze control that are influenced by long-term memory. The dependence of gaze effects on medial temporal lobe integrity support a role for this region in predictive gaze control.",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:fcpTrIVD8aEC",
            "Publisher": "Unknown"
        },
        {
            "Title": "A review of 40 years of cognitive architecture research: Core cognitive abilities and practical applications",
            "Publication year": 2016,
            "Publication url": "https://arxiv.org/abs/1610.08602",
            "Abstract": "In this paper we present a broad overview of the last 40 years of research on cognitive architectures. Although the number of existing architectures is nearing several hundred, most of the existing surveys do not reflect this growth and focus on a handful of well-established architectures. Thus, in this survey we wanted to shift the focus towards a more inclusive and high-level overview of the research on cognitive architectures. Our final set of 84 architectures includes 49 that are still actively developed, and borrow from a diverse set of disciplines, spanning areas from psychoanalysis to neuroscience. To keep the length of this paper within reasonable limits we discuss only the core cognitive abilities, such as perception, attention mechanisms, action selection, memory, learning and reasoning. In order to assess the breadth of practical applications of cognitive architectures we gathered information on over 900 practical projects implemented using the cognitive architectures in our list. We use various visualization techniques to highlight overall trends in the development of the field. In addition to summarizing the current state-of-the-art in the cognitive architecture research, this survey describes a variety of methods and ideas that have been tried and their relative success in modeling human cognitive abilities, as well as which aspects of cognitive behavior need more research with respect to their mechanistic counterparts and thus can further inform how cognitive science might progress.",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:BvbJ36a9xgsC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Fast Hand Gesture Recognition for Real-Time Teleconferencing Applications",
            "Publication year": 2001,
            "Publication url": "https://scholar.google.com/scholar?cluster=12697603744434125197&hl=en&oi=scholarr",
            "Abstract": "Work on real-time hand-gesture recognition for SAVI (Stereo Active Vision Interface) is presented. Based on the detection of frontal faces, image regions near the face are searched for the existence of skin-tone blobs. Each blob is evaluated to determine if it is a hand held in a standard pose. A verification algorithm based on the responses of elongated oriented filters is used to decide whether a hand is present or not.Once a hand is detected, gestures are given by varying the number of fingers visible. The hand is segmented using an algorithm which detects connected skin-tone blobs in the region of interest, and a medial axis transform (skele-tonization) is applied. Analysis of the resulting skeleton allows detection of the number of fingers visible, thus de-termining the gesture. The skeletonization is sensitive to strong shadows which may alter the detected morphology of the hand. Experimental results are given indicating good performance of the algorithm.",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:hc6fSYdAWgkC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Attention and Cognition: Principles to Guide Modeling",
            "Publication year": 2017,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-981-10-0213-7_12",
            "Abstract": "Interest in the modeling of visual attention and cognition is strong with the number of models growing quickly. It thus becomes important to try to consolidate what all this activity has demonstrated in terms of what principles may be abstracted from the collective experience that can guide future research. This is not a straightforward task; many have tried and have little to show for it. Here, a different view is presented, one that attempts to combine multiple perspectives on the problem. The novelty is that in contrast with the vast majority of past work, there is an explicit assertion that no single principle can capture the complexities of human attentional and cognitive behavior. There are several principles, each defined in a particular context, with interactions among them. Many previous authors have stated principles that in fact are more correctly considered as modeling philosophies or requirements and these will \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Ic6ZXhUAAAAJ:tWiuw1KVSQEC",
            "Publisher": "Springer"
        },
        {
            "Title": "Hand gesture recognition within a linguistics-based framework",
            "Publication year": 2004,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-540-24670-1_22",
            "Abstract": "An approach to recognizing hand gestures from a monocular temporal sequence of images is presented. Of particular concern is the representation and recognition of hand movements that are used in single handed American Sign Language (ASL). The approach exploits previous linguistic analysis of manual languages that decompose dynamic gestures into their static and dynamic components. The first level of decomposition is in terms of three sets of primitives, hand shape, location and movement. Further levels of decomposition involve the lexical and sentence levels and are part of our plan for future work. We propose and demonstrate that given a monocular gesture sequence, kinematic features can be recovered from the apparent motion that provide distinctive signatures for 14 primitive movements of ASL. The approach has been implemented in software and evaluated on a database of 592 gesture \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Ic6ZXhUAAAAJ:4TOpqqG69KYC",
            "Publisher": "Springer Berlin/Heidelberg"
        },
        {
            "Title": "Subspace manifold learning with sample weights",
            "Publication year": 2009,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S026288560600360X",
            "Abstract": "Subspace manifold learning represents a popular class of techniques in statistical image analysis and object recognition. Recent research in the field has focused on nonlinear representations; locally linear embedding (LLE) is one such technique that has recently gained popularity. We present and apply a generalization of LLE that introduces sample weights. We demonstrate the application of the technique to face recognition, where a model exists to describe each face\u2019s probability of occurrence. These probabilities are used as weights in the learning of the low-dimensional face manifold. Results of face recognition using this approach are compared against standard nonweighted LLE and PCA. A significant improvement in recognition rates is realized using weighted LLE on a data set where face occurrences follow the modeled distribution.",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:lmc2jWPfTJgC",
            "Publisher": "Elsevier"
        },
        {
            "Title": "Robot localization in rough terrains: Performance evaluation",
            "Publication year": 2010,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/5479178/",
            "Abstract": "The goal of this paper is to present an overview of two common processes involved in most visual robot localization techniques: data association and robust motion estimation. For each of them, we review some of the available solutions and compare their performance in the context of outdoor robot localization, where the robot is subject to 6-DOF motion. Our experiments with different combinations of data association and motion estimation techniques show the superiority of the Hessian-Affine feature detector and the SIFT feature descriptor for data association, and the Hough Transform for robust motion estimation.",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:fEOibwPWpKIC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Adaptive enhancement of cardiac magnetic resonance (CMR) images",
            "Publication year": 2005,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/1544927/",
            "Abstract": "This paper presents a wavelet-based framework for enhancing the coherent structures attributable to the target organ in cardiac magnetic resonance (MR) images. Previous approaches focus on the Rician nature of noise in magnitude MR images. Image noise is but only one of the confounding factors that obscure the anatomical structures of the target organ. This paper models the image noise in a magnitude MR image in terms of two noise classes which occur over different ranges of signal intensity. An adaptive enhancement scheme is developed to achieve simultaneous attenuation of the effects of these factors and improvement in image contrast",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:1yQoGdGgb4wC",
            "Publisher": "IEEE"
        },
        {
            "Title": "PESAO: Psychophysical Experimental Setup for Active Observers",
            "Publication year": 2020,
            "Publication url": "https://arxiv.org/abs/2009.09933",
            "Abstract": "Most past and present research in computer vision involves passively observed data. Humans, however, are active observers outside the lab; they explore, search, select what and how to look. Nonetheless, how exactly active observation occurs in humans so that it can inform the design of active computer vision systems is an open problem. PESAO is designed for investigating active, visual observation in a 3D world. The goal was to build an experimental setup for various active perception tasks with human subjects (active observers) in mind that is capable of tracking the head and gaze. While many studies explore human performances, usually, they use line drawings portrayed in 2D, and no active observer is involved. PESAO allows us to bring many studies to the three-dimensional world, even involving active observers. In our instantiation, it spans an area of 400cm x 300cm and can track active observers at a frequency of 120Hz. Furthermore, PESAO provides tracking and recording of 6D head motion, gaze, eye movement-type, first-person video, head-mounted IMU sensor, birds-eye video, and experimenter notes. All are synchronized at microsecond resolution.",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:vXJHGeUEVGkC",
            "Publisher": "Unknown"
        },
        {
            "Title": "On computational modeling of visual saliency: Examining what\u2019s right, and what\u2019s left",
            "Publication year": 2015,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S0042698915000267",
            "Abstract": "In the past decade, a large number of computational models of visual saliency have been proposed. Recently a number of comprehensive benchmark studies have been presented, with the goal of assessing the performance landscape of saliency models under varying conditions. This has been accomplished by considering fixation data, annotated image regions, and stimulus patterns inspired by psychophysics. In this paper, we present a high-level examination of challenges in computational modeling of visual saliency, with a heavy emphasis on human vision and neural computation. This includes careful assessment of different metrics for performance of visual saliency models, and identification of remaining difficulties in assessing model performance. We also consider the importance of a number of issues relevant to all saliency models including scale-space, the impact of border effects, and spatial or central \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Ic6ZXhUAAAAJ:NxmKEeNBbOMC",
            "Publisher": "Pergamon"
        },
        {
            "Title": "Computer Vision Systems: 6th International Conference on Computer Vision Systems, ICVS 2008 Santorini, Greece, May 12-15, 2008, Proceedings",
            "Publication year": 2008,
            "Publication url": "https://books.google.com/books?hl=en&lr=&id=mh1qCQAAQBAJ&oi=fnd&pg=PR4&dq=info:BAM4NNcRguEJ:scholar.google.com&ots=-znXArj5KU&sig=_KnqIkgnmRksoRrVM2wduYJrnvI",
            "Abstract": "In the past few years, with the advances in microelectronics and digital te-nology, cameras became a widespread media. This, along with the enduring increase in computing power boosted the development of computer vision s-tems. The International Conference on Computer Vision Systems (ICVS) covers the advances in this area. This is to say that ICVS is not and should not be yet another computer vision conference. The? eld of computer vision is fully covered by many well-established and famous conferences and ICVS di? ers from these by covering the systems point of view. ICVS 2008 was the 6th International Conference dedicated to advanced research on computer vision systems. The conference, continuing a series of successful events in Las Palmas, Vancouver, Graz, New York and Bielefeld, in 2008 was held on Santorini. In all, 128 papers entered the review process and each was reviewed by three independent reviewers using the double-blind review method. Of these, 53-pers were accepted (23 as oral and 30 as poster presentation). There were also two invited talks by P. Anandan and by Heinrich H. Bultho \u0308?. The presented papers cover all aspects of computer vision systems, namely: cognitive vision, monitor and surveillance, computer vision architectures, calibration and reg-tration, object recognition and tracking, learning, human\u2014machine interaction and cross-modal systems.",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:XD-gHx7UXLsC",
            "Publisher": "Springer"
        },
        {
            "Title": "Automatically determining the awareness settings among people in distributed working environment",
            "Publication year": 2006,
            "Publication url": "https://patents.google.com/patent/US7028074B2/en",
            "Abstract": "Communication channels among users in a collaborative computing system are automatically adjusted based on users' current states detected by various sensing devices. The collaboration system that includes an awareness system for evaluating, monitoring, and controlling, in real-time, the collaboration environment by having events and occurrences with properties. The awareness monitoring system includes (1) receiving and analyzing real time data from input sensors and (2) an elastic spring energy model for automatically adjusting a distance according to a level of privacy desired by individual users, the requirement of the organization, and a need of the collaborative project to have some shared information about individual user activities. When a spring energy model is difficult to obtain, a matrix looks up model is used to automatically adjust a distance according to a level of privacy desired by individual \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Ic6ZXhUAAAAJ:Y4TYaDvN-EgC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Information fusion for multi-camera and multi-body structure and motion",
            "Publication year": 2007,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-540-76386-4_36",
            "Abstract": "Information fusion algorithms have been successful in many vision tasks such as stereo, motion estimation, registration and robot localization. Stereo and motion image analysis are intimately connected and can provide complementary information to obtain robust estimates of scene structure and motion. We present an information fusion based approach for multi-camera and multi-body structure and motion that combines bottom-up and top-down knowledge on scene structure and motion. The only assumption we make is that all scene motion consists of rigid motion. We present experimental results on synthetic and non-synthetic data sets, demonstrating excellent performance compared to binocular based state-of-the-art approaches for structure and motion.",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:2KloaMYe4IUC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "Dynamic Label Propagation for Semi-supervised Multi-class Multi-label Classification",
            "Publication year": 2013,
            "Publication url": "http://openaccess.thecvf.com/content_iccv_2013/html/Wang_Dynamic_Label_Propagation_2013_ICCV_paper.html",
            "Abstract": "In graph-based semi-supervised learning approaches, the classification rate is highly dependent on the size of the availabel labeled data, as well as the accuracy of the similarity measures. Here, we propose a semi-supervised multi-class/multi-label classification scheme, dynamic label propagation (DLP), which performs transductive learning through propagation in a dynamic process. Existing semi-supervised classification methods often have difficulty in dealing with multi-class/multi-label problems due to the lack in consideration of label correlation; our algorithm instead emphasizes dynamic metric fusion with label information. Significant improvement over the state-of-the-art methods is observed on benchmark datasets for both multiclass and multi-label tasks.",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:kJDgFkosVoMC",
            "Publisher": "IEEE"
        },
        {
            "Title": "The different stages of visual recognition need different attentional binding strategies",
            "Publication year": 2008,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S0006899308011736",
            "Abstract": "Many think that visual attention needs an executive to allocate resources. Although the cortex exhibits substantial plasticity, dynamic allocation of neurons seems outside its capability. Suppose instead that the visual processing architecture is fixed, but can be \u2018tuned\u2019 dynamically to task requirements: the only remaining resource that can be allocated is time. How can this fixed, yet tunable, structure be used over periods of time longer than one feed-forward pass? With the goal of developing a computational theory and model of vision and attention that has both biological predictive power as well as utility for computer vision, this paper proposes that by using multiple passes of the visual processing hierarchy, both bottom-up and top-down, and using task information to tune the processing prior to each pass, we can explain the different recognition behaviors that human vision exhibits. By examining in detail the basic \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Ic6ZXhUAAAAJ:BqipwSGYUEgC",
            "Publisher": "Elsevier"
        },
        {
            "Title": "Fast Visual Object Tracking using Ellipse Fitting for Rotated Bounding Boxes",
            "Publication year": 2019,
            "Publication url": "http://openaccess.thecvf.com/content_ICCVW_2019/html/VOT/Chen_Fast_Visual_Object_Tracking_using_Ellipse_Fitting_for_Rotated_Bounding_ICCVW_2019_paper.html",
            "Abstract": "In this paper, we demonstrate a novel algorithm that uses ellipse fitting to estimate the bounding box rotation angle and size with the segmentation (mask) on the target for online and real-time visual object tracking. Our method, SiamMask_E, improves the bounding box fitting procedure of the state-of-the-art object tracking algorithm SiamMask and still retains a fast-tracking frame rate (80 fps) on a system equipped with GPU (GeForce GTX 1080 Ti or higher). We tested our approach on the visual object tracking datasets (VOT2016, VOT2018, and VOT2019) that were labeled with rotated bounding boxes. By comparing with the original SiamMask, we achieved an improved Accuracy of 64.5% and 30.3% EAO on VOT2019, which is 4.9% and 2% higher than the original SiamMask. The implementation is available on GitHub: https://github. com/baoxinchen/siammask_e.",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:w0szDhK_4XgC",
            "Publisher": "Unknown"
        },
        {
            "Title": "The importance of intermediate representations for the modeling of 2d shape detection: Endstopping and curvature tuned computations",
            "Publication year": 2011,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/5995671/",
            "Abstract": "Computational models of visual processes with biological inspiration - and even biological realism - are currently of great interest in the computer vision community. This paper provides a biologically plausible model of 2D shape which incorporates intermediate layers of visual representation that have not previously been fully explored. We propose that endstopping and curvature cells are of great importance for shape selectivity and show how their combination can lead to shape selective neurons. This shape representation model provides a highly accurate fit with neural data from and provides comparable results with real-world images to current computer vision systems. The conclusion is that such intermediate representations may no longer require a learning approach as a bridge between early representations based on Gabor or Difference of Gaussian filters (that are not learned since they are well-understood \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Ic6ZXhUAAAAJ:-ssuBh8vdzEC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Agreeing To Cross: How Drivers and Pedestrians Communicate",
            "Publication year": 2017,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/7995730/",
            "Abstract": "The contribution of this paper is twofold. The first is a novel dataset for studying behaviors of traffic participants while crossing. Our dataset contains more than 650 samples of pedestrian behaviors in various street configurations and weather conditions. These examples were selected from approx. 240 hours of driving in the city, suburban and rural roads. The second contribution is an analysis of our data from the point of view of joint attention. We identify what types of non-verbal communication cues road users use at the point of crossing, their responses, and under what circumstances the crossing event takes place. It was found that in more than 90% of the cases pedestrians gaze at the approaching cars prior to crossing in non-signalized crosswalks. The crossing action, however, depends on additional factors such as time to collision, explicit driver's reaction or structure of the crosswalk.",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:JO-RqYbuJvsC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Recurrent refinement for visual saliency estimation in surveillance scenarios",
            "Publication year": 2012,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/6233131/",
            "Abstract": "In recent years, many different proposals for visual saliency computation have been put forth, that generally frame the determination of visual saliency as a measure of local feature contrast. There is however, a paucity of approaches that take into account more global holistic elements of the scene. In this paper, we propose a novel mechanism that augments the visual representation used to compute saliency. Inspired by research into biological vision, this strategy is one based on the role of recurrent computation in a visual processing hierarchy. Unlike existing approaches, the proposed model provides a manner of refining local saliency based computation based on the more global composition of a scene that is independent of semantic labeling or viewpoint. The results presented demonstrate that a fast recurrent mechanism significantly augments the determination of salient regions of interest as compared with a \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Ic6ZXhUAAAAJ:LPtt_HFRSbwC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Autonomous vehicles that interact with pedestrians: A survey of theory and practice",
            "Publication year": 2019,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/8667866/",
            "Abstract": "One of the major challenges that autonomous cars are facing today is driving in urban environments. To make it a reality, autonomous vehicles require the ability to communicate with other road users and understand their intentions. Such interactions are essential between vehicles and pedestrians, the most vulnerable road users. Understanding pedestrian behavior, however, is not intuitive and depends on various factors, such as demographics of the pedestrians, traffic dynamics, environmental conditions, and so on. In this paper, we identify these factors by surveying pedestrian behavior studies, both the classical works on pedestrian-driver interaction and the modern ones that involve autonomous vehicles. To this end, we will discuss various methods of studying pedestrian behavior and analyze how the factors identified in the literature are interrelated. We will also review the practical applications aimed at \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Ic6ZXhUAAAAJ:rt76XxiL7BoC",
            "Publisher": "IEEE"
        },
        {
            "Title": "System and method for categorizing an image",
            "Publication year": 2014,
            "Publication url": "https://patents.google.com/patent/US20140172643A1/en",
            "Abstract": "A system and method for performing object or context-based categorization of an image is described. A descriptor for image regions, which is represented by a histogram of oriented uniform patterns, is described. The descriptor is compared to descriptors of other images to determine a similarity score that accounts for distinctiveness, reducing perceptual aliasing. Additionally, a kernel alignment process considers only the descriptors that are determined to be most informative.",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:Eu_4uSHeUgAC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Early recurrence enables figure border ownership",
            "Publication year": 2021,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S0042698921000857",
            "Abstract": "Rubin\u2019s face-vase illusion demonstrates how one can switch back and forth between two different interpretations depending on how the figure outlines are assigned. In the primate visual system, assigning ownership along figure borders is encoded by neurons called the border ownership (BO) cells. Studies show that the responses of these neurons not only depend on the local features within their receptive fields, but also on contextual information. Despite two decades of studies on BO neurons, the ownership assignment mechanism in the brain is still unknown. Here, we propose a hierarchical recurrent model grounded on the hypothesis that neurons in the dorsal stream provide the context required for ownership assignment. Our proposed model incorporates early recurrence from the dorsal pathway as well as lateral modulations within the ventral stream. While dorsal modulations initiate the response difference \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Ic6ZXhUAAAAJ:p11oD0Q27JMC",
            "Publisher": "Pergamon"
        },
        {
            "Title": "Face recognition with weighted locally linear embedding",
            "Publication year": 2005,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/1443143/",
            "Abstract": "We present an approach to recognizing faces with varying appearances which also considers the relative probability of occurrence for each appearance. We propose and demonstrate extending dimensionality reduction using locally linear embedding (LLE), to model the local shape of the manifold using neighboring nodes of the graph, where the probability associated with each node is also considered. The approach has been implemented in software and evaluated on the Yale database of face images (Belhumeur et al., 1997). Recognition rates are compared with non-weighted LLE and principal component analysis (PCA), and in our setting, weighted LLE achieves superior performance.",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:NMxIlDl6LWMC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Choosing Knowledge Granularity for Efficient Functioning of an Intelligent Agent",
            "Publication year": 2001,
            "Publication url": "https://books.google.com/books?hl=en&lr=&id=yAhRAAAAMAAJ&oi=fnd&pg=PA459&dq=info:vs780Xpx0LwJ:scholar.google.com&ots=3eRZIWc-lV&sig=3MfpZQzlqdcqR6LTHA5Wf5vGkoM",
            "Abstract": "In this paper we introduce the concept of knowledge granularity and study its influence on an agent's action selection process. The goal is to provide a guideline for an agent to select a reasonable knowledge granularity for a given task. Finally we present an idea of using an adaptive mesh method for uneven granularity representation.",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:FAceZFleit8C",
            "Publisher": "NATIONAL INSTIUTE OF STANDARDS & TECHNOLOGY"
        },
        {
            "Title": "Large-scale, touch-sensitive video display",
            "Publication year": 2002,
            "Publication url": "https://patents.google.com/patent/US6377228B1/en",
            "Abstract": "A video surface is constructed by adjoining a large number of flat screen display devices together. Each screen on this surface is controlled by its own computer processor and these processors are networked together. Superimposed over this surface is a tiling of transparent touch-sensitive screens which allow for user input. The resulting display is thin, has a very high resolution, appears to be a single large screen to the user, and is capable of supporting many different types of human-machine interaction.",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:NU53l0vQ3PcC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Indoor place recognition system for localization of mobile robots",
            "Publication year": 2016,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/7801503/",
            "Abstract": "In this paper we present a method for robots to do visual place recognition and categorization. The robot learns from experience and then recognizes previously observed places in known environments and categorizes previously unseen places in new environments. This system has been practically tested with a novel dataset developed by us to validate the theoretical results of the proposed system. A Histogram of Oriented Uniform Patters (HOUP) descriptor has been used to represent an image and then appropriate classifiers have been used to perform the classification tasks. It is shown that our method not only performs well on our dataset but also on existing datasets. A major contribution of this work is that this is the first real time implementation of a HOUP descriptor on two mobile robot platforms. Finally we built a novel dataset of seventeen indoor places for doing place recognition and validated our method \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Ic6ZXhUAAAAJ:L7JqRCIhofwC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Random Polyhedral Scenes: An Image Generator for Active Vision System Experiments",
            "Publication year": 2018,
            "Publication url": "https://arxiv.org/abs/1803.10100",
            "Abstract": "We present a Polyhedral Scene Generator system which creates a random scene based on a few user parameters, renders the scene from random view points and creates a dataset containing the renderings and corresponding annotation files. We hope that this generator will enable research on how a program could parse a scene if it had multiple viewpoints to consider. For ambiguous scenes, typically people move their head or change their position to see the scene from different angles as well as seeing how it changes while they move; this research field is called active perception. The random scene generator presented is designed to support research in this field by generating images of scenes with known complexity characteristics and with verifiable properties with respect to the distribution of features across a population. Thus, it is well-suited for research in active perception without the requirement of a live 3D environment and mobile sensing agent, including comparative performance evaluations. The system is publicly available at https://polyhedral.eecs.yorku.ca.",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:KgQn5aR88cEC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Priming and intrusion errors in RSVP streams with two response dimensions",
            "Publication year": 2008,
            "Publication url": "https://link.springer.com/article/10.1007/s00426-007-0116-4",
            "Abstract": "Loach and Mar\u00ed-Beffa (Vis Cogn, 10:513\u2013526, 2003) observed that a distractor stimulus, presented immediately after a behaviorally relevant target stimulus, negatively primed a related probe stimulus indicating that the distractor had been inhibited. They argued that \u201cpost-target inhibition\u201d may be a mechanism for preventing interference from temporally proximal stimuli; interference that could potentially result in a binding/intrusion error. In order to test this hypothesis, the authors carried out two rapid serial visual presentation (RSVP) experiments in which participants had to report either the identity (Experiment 1) or color (Experiment 2) of a target letter surrounded by distractor letters. In Experiment 1, a close relationship between priming and errors was observed. When a distractor stimulus showed evidence of being inhibited the participant was less likely to commit a binding error. The opposite was true \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Ic6ZXhUAAAAJ:_FM0Bhl9EiAC",
            "Publisher": "Springer Berlin/Heidelberg"
        },
        {
            "Title": "Applying ensembles of multilinear classifiers in the frequency domain",
            "Publication year": 2006,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/1640746/",
            "Abstract": "Ensemble methods such as bootstrap, bagging or boosting have had a considerable impact on recent developments in machine learning, pattern recognition and computer vision. Theoretical and practical results alike have established that, in terms of accuracy, ensembles of weak classifiers generally outperform monolithic solutions. However, this comes at the cost of an extensive training process. The work presented in this paper results from projects on advanced human machine interaction. In scenarios like ours, online learning is a major requirement, and lengthy training is prohibitive. We therefore propose a different approach to ensemble learning. Instead of a set of weak classifiers, we combine strong, separable, multilinear discriminant functions. These are especially suited for computer vision: they train very quickly and allow for rapid classification of image content. Training different classifiers for different \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Ic6ZXhUAAAAJ:B3FOqHPlNUQC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Active fixation control to predict saccade sequences",
            "Publication year": 2018,
            "Publication url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Wloka_Active_Fixation_Control_CVPR_2018_paper.html",
            "Abstract": "Visual attention is a field with a considerable history, with eye movement control and prediction forming an important subfield. Fixation modeling in the past decades has been largely dominated computationally by a number of highly influential bottom-up saliency models, such as the Itti-Koch-Niebur model. The accuracy of such models has dramatically increased recently due to deep learning. However, on static images the emphasis of these models has largely been based on non-ordered prediction of fixations through a saliency map. Very few implemented models can generate temporally ordered human-like sequences of saccades beyond an initial fixation point. Towards addressing these shortcomings we present STAR-FC, a novel multi-saccade generator based on the integration of central high-level and object-based saliency and peripheral lower-level feature-based saliency. We have evaluated our model using the CAT2000 database, successfully predicting human patterns of fixation with equivalent accuracy and quality compared to what can be achieved by using one human sequence to predict another.",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:dGK5M7Mi7LgC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Attending to visual motion: Localizing and classifying affine motion patterns",
            "Publication year": 2004,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/1301484/",
            "Abstract": "The Selective Tuning Model is a proposal for modelling visual attention in primates and humans. This paper describes ongoing research to include attention to motion stimuli within the model. The effort is unique because it seems that no past model presents a motion hierarchy plus attention to motion. We propose a biologically realistic model of the primate visual motion system attempting to explain how a hierarchical feedforward network consisting of layers representing cortical areas V1, MT, MST, and 7a detects and classifies different kinds of motion patterns. The STM model is then integrated into this hierarchy demonstrating that successfully attending to motion patterns results in localization (segmentation) and labeling of those patterns.",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:kRWSkSYxWN8C",
            "Publisher": "IEEE"
        },
        {
            "Title": "Robot middleware must support task-directed perception",
            "Publication year": 2007,
            "Publication url": "https://www.researchgate.net/profile/John-Tsotsos/publication/228809504_%27Robot_middleware_must_support_task-directed_perception/links/0fcfd5093cba911b9e000000/Robot-middleware-must-support-task-directed-perception.pdf",
            "Abstract": "While current robot middleware projects address functional concerns of robot control, middleware should also support the needs of task-directed perceptual processing. S* is an approach to intelligent control that addresses this concern in particular. It prescribes constructing intelligent controllers as behaviour-based systems augmented with shared representations, which supports task-directed perception and also enables the development of extensible controllers. The focus of this paper is on a software framework, developed to support the development of intelligent robot control systems by teams of designers.",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:Y5dfb0dijaUC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Active Recognition, in Computer Vision, ed. by K. Ikeuchi",
            "Publication year": 2020,
            "Publication url": "Unknown",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:nf2iy15GSkQC",
            "Publisher": "Springer"
        },
        {
            "Title": "Complexity Level Analysis Revisited: What Can 30 Years of Hindsight Tell Us about How the Brain Might Represent Visual Information?",
            "Publication year": 2017,
            "Publication url": "https://www.frontiersin.org/articles/10.3389/fpsyg.2017.01216/full",
            "Abstract": "In a series of papers spanning 1987-2012, we examined the inherent computational difficulty of visual information processing using theoretical and empirical methods. The main goal of this activity had three components: to understand the deep nature of the computational problem of visual information processing; to discover how well the computational difficulty of vision matches to the fixed resources of biological seeing systems; and, to abstract from the matching exercise the key principles that lead to the observed characteristics of biological visual performance. The problem is clearly of interest to each of the communities studying vision, namely machine vision, neuroscience, psychology, cognitive science, artificial intelligence and robotics. This paper revisits those principles with the advantage that decades of hindsight can provide. It is clear, for example, that the current leading computational approaches to machine vision that employ deep learning have achieved their success in part due to conforming to the results of that analysis. It is also apparent that the problem of signal interference within a hierarchical network is significant and requires deeper examination. In order to deal with complexity issues and signal interference, we assert that the generality that human vision - and likely intelligence in general - exhibits is enabled by dynamic tuning of the brain's neural machinery based on task, environment and moment-by-moment requirements, and this is what attention accomplishes. And in order for this to occur, the underlying representations must be of a particular form: hierarchical, space and time limited, pyramidal, bidirectional, and \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Ic6ZXhUAAAAJ:MhMRrlfrL94C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Attentive Surround Suppression in the Feature Dimension.",
            "Publication year": 2010,
            "Publication url": "https://www.eecs.yorku.ca/research/techreports/2010/CSE-2010-01.pdf",
            "Abstract": "According to the selective-tuning model (Tsotsos, 1990), attending to an feature value results in an surround-suppression on close feature values, but not for feature values farther away from the attended one. To validate this prediction, subjects were first required to attend to an orientation (or color) value, and then their perception of other orientation (or color) values, which could be at, near, or far from the attended feature value, was probed. In line with this prediction, the results revealed that in both orientation and color domain, attending to a point in the orientation (or color) domain results in a surround-suppression for close orientations (or colors).",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:G0G8x1Xwn_oC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Examining the feasibility of face gesture detection using a wheelchair mounted camera.",
            "Publication year": 2009,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/1631097.1631103",
            "Abstract": "he user interface of existing autonomous wheelchairs concentrates on direct control of the wheelchair by the user using mechanical devices or various hand, head or face gestures. However, it is important to monitor the user to ensure safety an comfort of the user, who operates the autonomous wheelchair. In addition, such monitoring of a user greatly improves usablity of an autonomous wheelchair due to the improved communication between the user and the wheelchair. This paper proposes a user monitoring system for an autonomous wheelchair. The feedback of the user and the information about the actions of the user, obtained by such a system, will be used by the autonomous wheelchair for planning of its future actions. As a first step towards creation of the monitoring system, this work proposes and examines the feasibility of a system that is capable of recognizing static facial gestures of the user using a \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Ic6ZXhUAAAAJ:B06RkWtwG_wC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Image Space I3 and Eigen Curvature for Illumination Insensitive Face Detection",
            "Publication year": 2005,
            "Publication url": "https://link.springer.com/chapter/10.1007/11559573_57",
            "Abstract": "Generally, the performance of present day computer vision systems is still very much affected by varying brightness and light source conditions. Recently, Koenderink suggested that this weakness is due to methodical flaws in low level image processing. As a remedy, he develops a new theory of image modeling. This paper reports on applying his ideas to the problem of illumination insensitive face detection. Experimental results will underline that even a simple and conventional method like principal component analysis can accomplish robust and reliable face detection in the presence of illumination variation if applied to curvature features computed in Koenderink\u2019s image space.",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:kzcrU_BdoSEC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "Fast, Recurrent Attentional Modulation Improves Saliency Representation and Scene Recognition",
            "Publication year": 2011,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/5981745/",
            "Abstract": "The human brain uses visual attention to facilitate object recognition. Traditional theories and models envision this attentional mechanism either in a pure feedforward fashion for selection of regions of interest or in a top-down task-priming fashion. To these well-known attentional mechanisms, we add here an additional novel one. The approach is inspired by studies of biological vision pertaining to the asynchronous timing of feedforward signals among different early visual areas and the role of recurrent connections from short latency areas to facilitate object recognition. It is suggested that recurrence elicited from these short latency dorsal areas improves the slower feedforward processing in the early ventral areas. We therefore propose a computational model that simulates this process. To test this model, we add such fast recurrent processes to a well-known model of feedforward saliency, AIM and show that \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Ic6ZXhUAAAAJ:gVv57TyPmFsC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Towards the quantitative evaluation of visual attention models",
            "Publication year": 2015,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S0042698915001522",
            "Abstract": "Scores of visual attention models have been developed over the past several decades of research. Differences in implementation, assumptions, and evaluations have made comparison of these models very difficult. Taxonomies have been constructed in an attempt at the organization and classification of models, but are not sufficient at quantifying which classes of models are most capable of explaining available data. At the same time, a multitude of physiological and behavioral findings have been published, measuring various aspects of human and non-human primate visual attention. All of these elements highlight the need to integrate the computational models with the data by (1) operationalizing the definitions of visual attention tasks and (2) designing benchmark datasets to measure success on specific tasks, under these definitions. In this paper, we provide some examples of operationalizing and \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Ic6ZXhUAAAAJ:4aZ_i-5WJEQC",
            "Publisher": "Pergamon"
        },
        {
            "Title": "It\u2019s all about the constraints",
            "Publication year": 2014,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S0960982214008604",
            "Abstract": "Our ever-growing knowledge about the human brain and human behavior is opening doors to increasingly impressive technological achievements. This neurobiological inspiration has a significant history and involves almost equal parts neuroscience, computation and art. With a focus on the sense of vision, this essay presents a selective and highly condensed snapshot of the history of how neurobiology has inspired technological developments, pointing the way to where new inspirations may lead.",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:D_tqNUsBuKoC",
            "Publisher": "Cell Press"
        },
        {
            "Title": "Are they going to cross? A benchmark dataset and baseline for pedestrian crosswalk behavior",
            "Publication year": 2017,
            "Publication url": "http://openaccess.thecvf.com/content_ICCV_2017_workshops/w3/html/Rasouli_Are_They_Going_ICCV_2017_paper.html",
            "Abstract": "Designing autonomous vehicles suitable for urban environments remains an unresolved problem. One of the major dilemmas faced by autonomous cars is how to understand the intention of other road users and communicate with them. The existing datasets do not provide the necessary means for such higher level analysis of traffic scenes. With this in mind, we introduce a novel dataset which in addition to providing the bounding box information for pedestrian detection, also includes the behavioral and contextual annotations for the scenes. This allows combining visual and semantic information for better understanding of pedestrians' intentions in various traffic scenarios. We establish baseline approaches for analyzing the data and show that combining visual and contextual information can improve prediction of pedestrian intention at the point of crossing by at least 20%.",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:-VEz7GmFoMgC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Why Does Data-Driven Beat Theory-Driven Computer Vision?",
            "Publication year": 2019,
            "Publication url": "http://openaccess.thecvf.com/content_ICCVW_2019/html/NeurArch/Tsotsos_Why_Does_Data-Driven_Beat_Theory-Driven_Computer_Vision_ICCVW_2019_paper.html",
            "Abstract": "This paper proposes that despite the success of deep learning methods in computer vision, the dominance we see would not have been possible by the methods of deep learning alone: the tacit change has been the evolution of empirical practice in computer vision. We demonstrate this by examining the distribution of sensor settings in vision datasets, only one potential dataset bias, and performance of both classic and deep learning algorithms under various camera settings. This reveals a strong mismatch between optimal performance ranges of theory-driven algorithms and sensor setting distributions in common vision datasets.",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:A-tbffQ4IL8C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Attention links sensing to recognition",
            "Publication year": 2008,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S0262885606000680",
            "Abstract": "This paper presents arguments that explicit strategies for visual attentional selection are important for cognitive vision systems, and shows that a number of proposals currently exist for exactly how parts of this goal may be accomplished. A comprehensive survey of approaches to computational attention is given. A key characteristic of virtually all the models surveyed here is that they receive significant inspiration from the neurobiology and psychophysics of human and primate vision. This, although not necessarily a key component of mainstream computer vision, seems very appropriate for cognitive vision systems given a definition of the topic that always includes the goal of human-like visual performance. A particular model, the Selective Tuning model, is overviewed in some detail. The growing neurobiological and psychophysical evidence for its biological plausibility is cited highlighting the fact that it has more \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Ic6ZXhUAAAAJ:Wp0gIr-vW9MC",
            "Publisher": "Elsevier"
        },
        {
            "Title": "A computational learning theory of active object recognition under uncertainty",
            "Publication year": 2013,
            "Publication url": "https://link.springer.com/article/10.1007/s11263-012-0551-6",
            "Abstract": "We present some theoretical results related to the problem of actively searching a 3D scene to determine the positions of one or more pre-specified objects. We investigate the effects that input noise, occlusion, and the VC-dimensions of the related representation classes have in terms of localizing all objects present in the search region, under finite computational resources and a search cost constraint. We present a number of bounds relating the noise-rate of low level feature detection to the VC-dimension of an object representable by an architecture satisfying the given computational constraints. We prove that under certain conditions, the corresponding classes of object localization and recognition problems are efficiently learnable in the presence of noise and under a purposive learning strategy, as there exists a polynomial upper bound on the minimum number of examples necessary to correctly \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Ic6ZXhUAAAAJ:WC9gN4BGCRcC",
            "Publisher": "Springer US"
        },
        {
            "Title": "The seventh visual object tracking vot2019 challenge results",
            "Publication year": 2019,
            "Publication url": "http://openaccess.thecvf.com/content_ICCVW_2019/html/VOT/Kristan_The_Seventh_Visual_Object_Tracking_VOT2019_Challenge_Results_ICCVW_2019_paper.html",
            "Abstract": "The Visual Object Tracking challenge VOT2019 is the seventh annual tracker benchmarking activity organized by the VOT initiative. Results of 81 trackers are presented; many are state-of-the-art trackers published at major computer vision conferences or in journals in the recent years. The evaluation included the standard VOT and other popular methodologies for short-term tracking analysis as well as the standard VOT methodology for long-term tracking analysis. The VOT2019 challenge was composed of five challenges focusing on different tracking domains:(i) VOTST2019 challenge focused on short-term tracking in RGB,(ii) VOT-RT2019 challenge focused on\" real-time\" shortterm tracking in RGB,(iii) VOT-LT2019 focused on longterm tracking namely coping with target disappearance and reappearance. Two new challenges have been introduced:(iv) VOT-RGBT2019 challenge focused on short-term tracking in RGB and thermal imagery and (v) VOT-RGBD2019 challenge focused on long-term tracking in RGB and depth imagery. The VOT-ST2019, VOT-RT2019 and VOT-LT2019 datasets were refreshed while new datasets were introduced for VOT-RGBT2019 and VOT-RGBD2019. The VOT toolkit has been updated to support both standard shortterm, long-term tracking and tracking with multi-channel imagery. Performance of the tested trackers typically by far exceeds standard baselines. The source code for most of the trackers is publicly available from the VOT page. The dataset, the evaluation kit and the results are publicly available at the challenge website.",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:OShvA0zO5LQC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Peer to Peer Adaptive Awareness",
            "Publication year": 2001,
            "Publication url": "Unknown",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:gsN89kCJA0AC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Background subtraction via early recurrence in dynamic scenes",
            "Publication year": 2012,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/6460838/",
            "Abstract": "A biologically motivated model of background subtraction is proposed. The two-step computation borrows the idea from the low-level inhibitive processing of the two-pathway primate visual system. A spatiotemporal representation consistent with the dorsal pathway is computed and refined via center-surround inhibition. This representation catches perceptually salient foreground regions, and is further used to inhibit fine-scale visual features that are confined to the ventral pathway, leading to a high-spatially-accurate representation containing mostly foreground pixels. Output of our work is attached to a state-of-the-art visual saliency model. Results using real dynamic scenes are compared with ground truth, which confirmed that our early recurrent processing can effectively remove background.",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:ziOE8S1-AIUC",
            "Publisher": "IEEE"
        },
        {
            "Title": "slab: smart labeling of family photos through an interactive interface",
            "Publication year": 2008,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/1378889.1378949",
            "Abstract": "A novel technique for semi-automatic photo annotation is proposed and evaluated. The technique, sLab, uses face processing algorithms and a simplified user interface for labeling family photos. A user study compared our system with two others. One was Adobe Photoshop Element. The other was an in-house implementation of a face clustering interface recently proposed in the research community. Nine participants performed an annotation task with each system on faces extracted from a set of 150 images from their own family photo albums. As the faces were all well known to participants, accuracy was near perfect with all three systems. On annotation time, sLab was 25% faster than Photoshop Element and 16% faster than the face clustering interface.",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:tYavs44e6CUC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Challenging Images For Minds and Machines",
            "Publication year": 2018,
            "Publication url": "https://arxiv.org/abs/1802.04834",
            "Abstract": "There is no denying the tremendous leap in the performance of machine learning methods in the past half-decade. Some might even say that specific sub-fields in pattern recognition, such as machine-vision, are as good as solved, reaching human and super-human levels. Arguably, lack of training data and computation power are all that stand between us and solving the remaining ones. In this position paper we underline cases in vision which are challenging to machines and even to human observers. This is to show limitations of contemporary models that are hard to ameliorate by following the current trend to increase training data, network capacity or computational power. Moreover, we claim that attempting to do so is in principle a suboptimal approach. We provide a taster of such examples in hope to encourage and challenge the machine learning community to develop new directions to solve the said difficulties.",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:0a-0BRjGxG0C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Active Observer Visual Problem-Solving Methods are Dynamically Hypothesized, Deployed and Tested",
            "Publication year": 2021,
            "Publication url": "https://arxiv.org/abs/2108.08145",
            "Abstract": "The STAR architecture was designed to test the value of the full Selective Tuning model of visual attention for complex real-world visuospatial tasks and behaviors. However, knowledge of how humans solve such tasks in 3D as active observers is lean. We thus devised a novel experimental setup and examined such behavior. We discovered that humans exhibit a variety of problem-solving strategies whose breadth and complexity are surprising and not easily handled by current methodologies. It is apparent that solution methods are dynamically composed by hypothesizing sequences of actions, testing them, and if they fail, trying different ones. The importance of active observation is striking as is the lack of any learning effect. These results inform our Cognitive Program representation of STAR extending its relevance to real-world tasks.",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:Gt7F3adpS1AC",
            "Publisher": "Unknown"
        },
        {
            "Title": "The selective tuning model for visual attention",
            "Publication year": 2002,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-1-4615-0111-4_22",
            "Abstract": "Complexity analysis leads to the conclusion that if attention tunes the visual processing architecture task-directed processing is enabled and a solution to signal interference otherwise present in the converging feedforward pathways is provided. Selective tuning takes two forms: spatial selection is realized by inhibition of irrelevant connections; and feature selection is realized by inhibition of the units, which compute irrelevant features. Only a very brief summary is presented here (a more detailed account is in Tsotsos et al.1).",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:zA6iFVUQeVQC",
            "Publisher": "Springer, Boston, MA"
        },
        {
            "Title": "Selectivity for speed gradients in human area MT/V5",
            "Publication year": 2005,
            "Publication url": "https://journals.lww.com/neuroreport/Fulltext/2005/04040/Selectivity_for_speed_gradients_in_human_area.4.aspx",
            "Abstract": "Cortical area MT/V5 in the human occipito-temporal cortex is activated by visual motion. In this study, we use functional imaging to demonstrate that a subregion of MT/V5 is more strongly activated by unidirectional motion with speed gradients than by other motion patterns. Our results suggest that like the monkey homolog middle temporal area (MT), human MT/V5 contains neurons selective for the processing of speed gradients. Such neurons may constitute an intermediate stage of processing between neurons selective for the average speed of unidirectional motion and neurons selective for different combinations of speed gradient and different motion directions such as expanding optical flow patterns.",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:bEWYMUwI8FkC",
            "Publisher": "LWW"
        },
        {
            "Title": "Cognitive vision needs attention to link sensing with recognition",
            "Publication year": 2006,
            "Publication url": "https://link.springer.com/chapter/10.1007/11414353_3",
            "Abstract": "\u201cCognitive computer vision is concerned with integration and control of vision systems using explicit but not necessarily symbolic models of context, situation and goaldirected behaviour\u201d (Vernon 2003 [473]). This paper discusses one small but critical slice of a cognitive computer vision system, that of visual attention. The presentation begins with a brief discussion on a definition for attention followed by an enumeration of the different ways in which attention should play a role in computer vision and cognitive vision systems in particular. The Selective Tuning Model is then overviewed with an emphasis on its components that are most relevant for cognitive vision, namely the winner-take-all processing, the use of distributed saliency and feature binding as a link to recognition.",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:W5xh706n7nkC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "Towards a biologically plausible active visual search model",
            "Publication year": 2004,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-540-30572-9_10",
            "Abstract": "This paper proposes a neuronal-based solution to active visual search, that is, visual search for a given target in displays that are too large in spatial extent to be inspected covertly. Recent experimental data from behaving, fixating monkeys is used as a guide and this is the first model to incorporate such data. The strategy presented here includes novel components such as a representation of saccade history and of peripheral targets that is computed in an entirely separate stream from foveal attention. Although this presentation describes the prototype of this model and much work remains, preliminary results obtained from its implementation seem consistent with the behaviour exhibited in humans and macaque monkeys.",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:TQgYirikUcIC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "A Focus on Selection for Fixation",
            "Publication year": 2016,
            "Publication url": "https://bop.unibe.ch/JEMR/article/view/2710",
            "Abstract": "A computational explanation of how visual attention, interpretation of visual stimuli, and eye movements combine to produce visual behavior, seems elusive. Here, we focus on one component: how selection is accomplished for the next fixation. The popularity of saliency map models drives the inference that this is solved, but we argue otherwise. We provide arguments that a cluster of complementary, conspicuity representations drive selection, modulated by task goals and history, leading to a hybrid process that encompasses early and late attentional selection. This design is also constrained by the architectural characteristics of the visual processing pathways. These elements combine into a new strategy for computing fixation targets and a first simulation of its performance is presented. A sample video of this performance can be found by clicking on the\" Supplementary Files\" link under the\" Article Tools\" heading.",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:IBInekdKRWIC",
            "Publisher": "eyemovement.org"
        },
        {
            "Title": "Attention in cognitive systems",
            "Publication year": 2009,
            "Publication url": "https://repository.vnu.edu.vn/handle/VNU_123/28459",
            "Abstract": "This volume constitutes the thoroughly refereed post-workshop proceedings of the 5th International Workshop on Attention in Cognitive Systems, WAPCV 2008, held in Fira, Santorini, Greece in May 2008 as an associated event of the 6th International Conference on Computer Vision Systems (ICVS 2008). The 13 revised full papers presented together with with 9 posters, have been carefully selected from 34 submissions. The papers are organized in topical sections on attention in scene exploration, contextueal cueing and saliency, spatiotemporal saliency, attentional networks as well as attentional modelling.",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:VFeYHPVE0z4C",
            "Publisher": "Springer"
        },
        {
            "Title": "It's Not All About Size: On the Role of Data Properties in Pedestrian Detection",
            "Publication year": 2018,
            "Publication url": "https://openaccess.thecvf.com/content_eccv_2018_workshops/w2/html/Rasouli_Its_Not_All_About_Size_On_the_Role_of_Data_ECCVW_2018_paper.html",
            "Abstract": "Pedestrian detection is central in applications such as autonomous driving. The performance of algorithms tailored to solve this problem has been extensively evaluated on benchmark datasets, such as Caltech, which do not adequately represent the diversity of traffic scenes. Consequently, the true performance of algorithms and their limitations in practice remain understudied. To this end, we conduct an empirical study using 7 classical and state-ofthe-art algorithms on the recently proposed JAAD dataset augmented with 16 additional labels for pedestrian attributes. Using this data we show that the relative performance of the algorithms varies depending on the properties of the training data. We analyze the contribution of weather conditions and pedestrian attributes to performance changes and examine the major sources of detection errors. Finally, we show that the diversity of the training data leads to better generalizability of the algorithms across different datasets even with a smaller number of samples.",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:TaF7eNGHiZkC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Multiplicative modulations enhance diversity of hue-selective cells",
            "Publication year": 2020,
            "Publication url": "https://www.nature.com/articles/s41598-020-64969-3",
            "Abstract": "There is still much to understand about the brain\u2019s colour processing mechanisms and the transformation from cone-opponent representations to perceptual hues. Moreover, it is unclear which area (s) in the brain represent unique hues. We propose a hierarchical model inspired by the neuronal mechanisms in the brain for local hue representation, which reveals the contributions of each visual cortical area in hue representation. Hue encoding is achieved through incrementally increasing processing nonlinearities beginning with cone input. Besides employing nonlinear rectifications, we propose multiplicative modulations as a form of nonlinearity. Our simulation results indicate that multiplicative modulations have significant contributions in encoding of hues along intermediate directions in the MacLeod-Boynton diagram and that our model V2 neurons have the capacity to encode unique hues. Additionally \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Ic6ZXhUAAAAJ:yj0jDpv2chsC",
            "Publisher": "Nature Publishing Group"
        },
        {
            "Title": "Saccade sequence prediction: Beyond static saliency maps",
            "Publication year": 2017,
            "Publication url": "https://arxiv.org/abs/1711.10959",
            "Abstract": "Visual attention is a field with a considerable history, with eye movement control and prediction forming an important subfield. Fixation modeling in the past decades has been largely dominated computationally by a number of highly influential bottom-up saliency models, such as the Itti-Koch-Niebur model. The accuracy of such models has dramatically increased recently due to deep learning. However, on static images the emphasis of these models has largely been based on non-ordered prediction of fixations through a saliency map. Very few implemented models can generate temporally ordered human-like sequences of saccades beyond an initial fixation point. Towards addressing these shortcomings we present STAR-FC, a novel multi-saccade generator based on a central/peripheral integration of deep learning-based saliency and lower-level feature-based saliency. We have evaluated our model using the CAT2000 database, successfully predicting human patterns of fixation with equivalent accuracy and quality compared to what can be achieved by using one human sequence to predict another. This is a significant improvement over fixation sequences predicted by state-of-the-art saliency algorithms.",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:Ko-bl4t9PAIC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Edge Motion Technology To Detect Abnormalities of Gait and Balance",
            "Publication year": 2010,
            "Publication url": "https://scholar.google.com/scholar?cluster=18022836029791194320&hl=en&oi=scholarr",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:mWEH9CqjF64C",
            "Publisher": "LIPPINCOTT WILLIAMS & WILKINS"
        },
        {
            "Title": "A connectionist perspective on laterality in visual attention",
            "Publication year": 2005,
            "Publication url": "http://www.cs.umanitoba.ca/~bruce/qualNB_tech.pdf",
            "Abstract": "This paper contains a comprehensive review of attention with a significant emphasis on lateralization of function. Connectivity and computation associated with the human visual system is described in detail, and the existing body of psychophysical, neurophysiological and computational studies relating to attention is summarized. This provides the foundation for the later chapters which describe the nature of communication between hemispheres, and the relative efficiency with which each hemisphere handles different attentive and visuospatial tasks. Finally, we outline some possible directions for future research on these matters.",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:PR6Y55bgFSsC",
            "Publisher": "Technical Report CS-2005-08, York University"
        },
        {
            "Title": "The effects of image padding in saliency algorithms",
            "Publication year": 2014,
            "Publication url": "https://scholar.google.com/scholar?cluster=992846673014138484&hl=en&oi=scholarr",
            "Abstract": "Gaussian Smoothing is a popular post-processing step applied to saliency algorithms to improve salient region identification. Frequently, the best performance is achieved with very large smoothing kernels (often with standard deviation on the order of a hundred pixels). When performing any image convolution one must implement some rule to handle the edge pixels for when part of the kernel extends beyond the boundary of the image. This issue is most commonly addressed through some form of image padding: extending the number of pixels in an image such that all the required input pixels for the kernel are defined. With such large smoothing kernels being used to improve saliency algorithm performance, the type of padding which is implemented can have a significant effect on performance. Despite this potential impact, smoothing parameters and methodology beyond magnitude of the Gaussian standard \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Ic6ZXhUAAAAJ:L_l9e5I586QC",
            "Publisher": "Pion Ltd"
        },
        {
            "Title": "Hierarchical learning of dominant constellations for object class recognition",
            "Publication year": 2007,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-540-76386-4_46",
            "Abstract": "The importance of spatial configuration information for object class recognition is widely recognized. Single isolated local appearance codes are often ambiguous. On the other hand, object classes are often characterized by groups of local features appearing in a specific spatial structure. Learning these structures can provide additional discriminant cues and boost recognition performance. However, the problem of learning such features automatically from raw images remains largely uninvestigated. In contrast to previous approaches which require accurate localization and segmentation of objects to learn spatial information, we propose learning by hierarchical voting to identify frequently occurring spatial relationships among local features directly from raw images. The method is resistant to common geometric perturbations in both the training and test data. We describe a novel representation developed \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Ic6ZXhUAAAAJ:zLWjf1WUPmwC",
            "Publisher": "Springer Berlin/Heidelberg"
        },
        {
            "Title": "Correction: Rapid visual categorization is not guided by early salience-based selection",
            "Publication year": 2019,
            "Publication url": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0226429",
            "Abstract": "Fig 4. Sensitivity analysis of performance thresholds. The plots show how percentage of points of interest P within the ground truth masks and parafovea gradually decreases depending on how much of the GTM (by area) is inside the parafovea. On each plot the point (0, 0) corresponds to measure B (ie P is within the GTM and parafovea regardless of the amount of GTM within the parafovea). Dashed vertical lines show what amount of overlap corresponds to human performance in Potter and Thorpe experiments. https://doi. org/10.1371/journal. pone. 0226429. g001",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:qkdS9U4CG6gC",
            "Publisher": "Public Library of Science"
        },
        {
            "Title": "Computational models of visual attention.",
            "Publication year": 2015,
            "Publication url": "https://europepmc.org/article/med/26420739",
            "Abstract": "Computational models of visual attention. - Abstract - Europe PMC Sign in or create an \naccount https://orcid.org Europe PMC Menu About About Europe PMC Preprints in Europe \nPMC Funders Joining Europe PMC Governance Roadmap Outreach Tools Tools overview \nORCID article claiming Journal list Grant finder External links service RSS feeds \nAnnotations Annotations submission service Developers Developer resources Articles \nRESTful API Grants RESTful API API use cases SOAP web service Annotations API OAI \nservice Bulk downloads Developers Forum Help Help using Europe PMC Search syntax \nreference Contact us Contact us Helpdesk Feedback Twitter Blog Tech blog Developer \nForum Europe PMC plus Search worldwide, life-sciences literature Search Advanced \nSearch Recent history Saved searches Abstract Full text References Citations & impact \nFunding Computational models of visual attention. \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Ic6ZXhUAAAAJ:SxCCDk4iOpsC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Pie: A large-scale dataset and models for pedestrian intention estimation and trajectory prediction",
            "Publication year": 2019,
            "Publication url": "http://openaccess.thecvf.com/content_ICCV_2019/html/Rasouli_PIE_A_Large-Scale_Dataset_and_Models_for_Pedestrian_Intention_Estimation_ICCV_2019_paper.html",
            "Abstract": "Pedestrian behavior anticipation is a key challenge in the design of assistive and autonomous driving systems suitable for urban environments. An intelligent system should be able to understand the intentions or underlying motives of pedestrians and to predict their forthcoming actions. To date, only a few public datasets were proposed for the purpose of studying pedestrian behavior prediction in the context of intelligent driving. To this end, we propose a novel large-scale dataset designed for pedestrian intention estimation (PIE). We conducted a large-scale human experiment to establish human reference data for pedestrian intention in traffic scenes. We propose models for estimating pedestrian crossing intention and predicting their future trajectory. Our intention estimation model achieves 79% accuracy and our trajectory prediction algorithm outperforms state-of-the-art by 26% on the proposed dataset. We further show that combining pedestrian intention with observed motion improves trajectory prediction. The dataset and models are available at http://data. nvision2. eecs. yorku. ca/PIE_dataset/.",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:pcZehKZDzkAC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Understanding pedestrian behavior in complex traffic scenes",
            "Publication year": 2017,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/8241847/",
            "Abstract": "Designing autonomous vehicles for urban environments remains an unresolved problem. One major dilemma faced by autonomous cars is understanding the intention of other road users and communicating with them. To investigate one aspect of this, specifically pedestrian crossing behavior, we have collected a large dataset of pedestrian samples at crosswalks under various conditions (e.g., weather) and in different types of roads. Using the data, we analyzed pedestrian behavior from two different perspectives: the way they communicate with drivers prior to crossing and the factors that influence their behavior. Our study shows that changes in head orientation in the form of looking or glancing at the traffic is a strong indicator of crossing intention. We also found that context in the form of the properties of a crosswalk (e.g., its width), traffic dynamics (e.g., speed of the vehicles) as well as pedestrian demographics \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Ic6ZXhUAAAAJ:K0avj1FDtHUC",
            "Publisher": "IEEE"
        },
        {
            "Title": "An attentional mechanism for selecting appropriate actions afforded by graspable objects",
            "Publication year": 2008,
            "Publication url": "https://journals.sagepub.com/doi/abs/10.1111/j.1467-9280.2008.02234.x",
            "Abstract": "An object may afford a number of different actions. In this article, we show that an attentional mechanism inhibits competing motor programs that could elicit erroneous actions. Participants made a speeded key press to categorize the second of two successively presented door handles that were rotated at varying orientations relative to one another. Their responding hand was compatible or incompatible with the graspable part of the door handles (rightward or leftward facing). Compatible responses were faster than incompatible responses if the two handles shared an identical orientation, but they were slower if the two handles were aligned at slightly dissimilar orientations. Such suppressive surround effects are hallmarks of attentional processing in the visual domain, but they have never been observed behaviorally in the motor domain. This finding delineates a common mechanism involved in two of the most \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Ic6ZXhUAAAAJ:g5m5HwL7SMYC",
            "Publisher": "SAGE Publications"
        },
        {
            "Title": "Visual representation determines search difficulty: explaining visual search asymmetries",
            "Publication year": 2011,
            "Publication url": "https://www.frontiersin.org/articles/10.3389/fncom.2011.00033/full",
            "Abstract": "In visual search experiments there exist a variety of experimental paradigms in which a symmetric set of experimental conditions yields asymmetric corresponding task performance. There are a variety of examples of this that currently lack a satisfactory explanation. In this paper, we demonstrate that distinct classes of asymmetries may be explained by virtue of a few simple conditions that are consistent with current thinking surrounding computational modeling of visual search and coding in the primate brain. This includes a detailed look at the role that stimulus familiarity plays in the determination of search performance. Overall, we demonstrate that all of these asymmetries have a common origin, namely, they are a consequence of the encoding that appears in the visual cortex. The analysis associated with these cases yields insight into the problem of visual search in general and predictions of novel search asymmetries.",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:HbR8gkJAVGIC",
            "Publisher": "Frontiers"
        },
        {
            "Title": "Overt fixations reflect a natural central bias",
            "Publication year": 2013,
            "Publication url": "https://www.researchgate.net/profile/John-Tsotsos/publication/266158154_Overt_Fixations_Reflect_a_Natural_Central_Bias/links/54b920a00cf28faced626f7e/Overt-Fixations-Reflect-a-Natural-Central-Bias.pdf",
            "Abstract": "Judd et al. provide a large (1003 images) and useful psychophysical eye-tracking data set from which human fixation statistics may be examined [4]. Judd et al. took their recorded subject fixations and turned them into saliency maps by convolving the fixation point maps with a Gaussian kernel; the average of these maps produces a strongly centralized blob of high salience as shown in Figure 3.",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:LXmCCkuhhTsC",
            "Publisher": "The Association for Research in Vision and Ophthalmology"
        },
        {
            "Title": "A performance evaluation of robot localization methods in outdoor terrains",
            "Publication year": 2012,
            "Publication url": "https://www.worldscientific.com/doi/abs/10.1142/9789814343008_0023",
            "Abstract": "This chapter presents an overview of two common processes involved in most visual robot localization techniques, namely data association and robust motion estimation, and compares the performance of the available state-of-the-art solutions for each of them, in the context of outdoor robot localization, where the robot is subject to 6-DOF motions. For data association, where the task is to match different sets of observations over time, we compare the performance of different image feature detectors and descriptors to determine which is the most appropriate to use in the context of 6-DOF outdoor localization. For motion estimation, where the goal is to compute the transformation that would bring each observation into the best alignment with its match, we perform a comparative study on common fitting methods to find out which is best for approximating the robot pose that is consistent with as many matched \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Ic6ZXhUAAAAJ:hsZV8lGYWTMC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Attention based on information maximization",
            "Publication year": 2007,
            "Publication url": "https://jov.arvojournals.org/article.aspx?articleid=2134997",
            "Abstract": "Formal arguments exist establishing that the complexity of visual search prohibits extensive analysis of all visual content in parallel. It follows that the task of selecting important content out of the enormous pool of incoming sensory input may be regarded as a critical component of animal vision; theoretically as well as practically this remains an open, unsolved problem.",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:D03iK_w7-QYC",
            "Publisher": "The Association for Research in Vision and Ophthalmology"
        },
        {
            "Title": "Spatially Binned ROC: A Comprehensive Saliency Metric",
            "Publication year": 2016,
            "Publication url": "http://openaccess.thecvf.com/content_cvpr_2016/html/Wloka_Spatially_Binned_ROC_CVPR_2016_paper.html",
            "Abstract": "A recent trend in saliency algorithm development is large-scale benchmarking and algorithm ranking with ground truth provided by datasets of human fixations. In order to accommodate the strong bias humans have toward central fixations, it is common to replace traditional ROC metrics with a shuffled ROC metric which uses randomly sampled fixations from other images in the database as the negative set. However, the shuffled ROC introduces a number of problematic elements, including a fundamental assumption that it is possible to separate visual salience and image spatial arrangement. We argue that it is more informative to directly measure the effect of spatial bias on algorithm performance rather than try to correct for it. To capture and quantify these known sources of bias, we propose a novel metric for measuring saliency algorithm performance: the spatially binned ROC (spROC). This metric provides direct insight into the spatial biases of a saliency algorithm without sacrificing the intuitive raw performance evaluation of traditional ROC measurements. By quantitatively measuring the bias in saliency algorithms, researchers will be better equipped to select and optimize the most appropriate algorithm for a given task. We use a baseline measure of inherent algorithm bias to show that Adaptive Whitening Saliency (AWS)[14], Attention by Information Maximization (AIM)[8], and Dynamic Visual Attention (DVA)[20] provide the least spatially biased results, suiting them for tasks in which there is no information about the underlying spatial bias of the stimuli, whereas algorithms such as Graph Based Visual Saliency (GBVS)[18] and Context \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Ic6ZXhUAAAAJ:yXZqsUWzai8C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Large-scale, touch-sensitive video display",
            "Publication year": 2000,
            "Publication url": "https://patents.google.com/patent/US6118433A/en",
            "Abstract": "A video surface is constructed by adjoining a large number of flat screen display devices together. Each screen on this surface is controlled by its own computer processor and these processors are networked together. Superimposed over this surface is a tiling of transparent touch-sensitive screens which allow for user input. The resulting display is thin, has a very high resolution, appears to be a single large screen to the user, and is capable of supporting many different types of human-machine interaction.",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:pzedKLaGEyUC",
            "Publisher": "Unknown"
        },
        {
            "Title": "TarzaNN: A general purpose neural network simulator for visual attention modeling",
            "Publication year": 2004,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-540-30572-9_12",
            "Abstract": "A number of computational models of visual attention exist, but making comparisons is difficult due to the incompatible implementations and levels at which the simulations are conducted. To address this issue, we have developed a general-purpose neural network simulator that allows all of these models to be implemented in a unified framework. The simulator allows for the distributed execution of models, in a heterogeneous environment. Graphical tools are provided for the development of models by non-programmers and a common model description format facilitates the exchange of models. In this paper we will present the design of the simulator and results that demonstrate its generality.",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:UxriW0iASnsC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "Attention in Cognitive Systems",
            "Publication year": 2009,
            "Publication url": "https://ui.adsabs.harvard.edu/abs/2009LNCS.5395.....P/abstract",
            "Abstract": "Attention in Cognitive Systems - NASA/ADS Now on home page ads icon ads Enable full ADS \nview NASA/ADS Attention in Cognitive Systems Paletta, Lucas ; Tsotsos, John K. Abstract \nPublication: Lecture Notes in Computer Science Pub Date: 2009 DOI: 10.1007/978-3-642-00582-4 \nBibcode: 2009LNCS......P Keywords: Computer Science; Artificial Intelligence (incl. Robotics); \nImage Processing and Computer Vision; Pattern Recognition; Computer Imaging; Vision; \nPattern Recognition and Graphics; Neurosciences; Biometrics full text sources Publisher | \u00a9 The \nSAO/NASA Astrophysics Data System adshelp[at]cfa.harvard.edu The ADS is operated by the \nSmithsonian Astrophysical Observatory under NASA Cooperative Agreement NNX16AC86A \nNASA logo Smithsonian logo Resources About ADS ADS Help What's New Careers@ADS \nSocial @adsabs ADS Blog Project Switch to full ADS Is ADS down? (or is it just me..\u2026",
            "Abstract entirety": 0,
            "Author pub id": "Ic6ZXhUAAAAJ:iiZUkH1jxVAC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Rapid Visual Categorization is not Guided by Early Salience-Based Selection",
            "Publication year": 2020,
            "Publication url": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0224306",
            "Abstract": "The current dominant visual processing paradigm in both human and machine research is the feedforward, layered hierarchy of neural-like processing elements. Within this paradigm, visual saliency is seen by many to have a specific role, namely that of early selection. Early selection is thought to enable very fast visual performance by limiting processing to only the most salient candidate portions of an image. This strategy has led to a plethora of saliency algorithms that have indeed improved processing time efficiency in machine algorithms, which in turn have strengthened the suggestion that human vision also employs a similar early selection strategy. However, at least one set of critical tests of this idea has never been performed with respect to the role of early selection in human vision. How would the best of the current saliency models perform on the stimuli used by experimentalists who first provided evidence for this visual processing paradigm? Would the algorithms really provide correct candidate sub-images to enable fast categorization on those same images? Do humans really need this early selection for their impressive performance? Here, we report on a new series of tests of these questions whose results suggest that it is quite unlikely that such an early selection process has any role in human rapid visual categorization.",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:PcID3NGdOhUC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Industry and Academic Research in Computer Vision",
            "Publication year": 2021,
            "Publication url": "https://arxiv.org/abs/2107.04902",
            "Abstract": "This work aims to study the dynamic between research in the industry and academia in computer vision. The results are demonstrated on a set of top-5 vision conferences that are representative of the field. Since data for such analysis was not readily available, significant effort was spent on gathering and processing meta-data from the original publications. First, this study quantifies the share of industry-sponsored research. Specifically, it shows that the proportion of papers published by industry-affiliated researchers is increasing and that more academics join companies or collaborate with them. Next, the possible impact of industry presence is further explored, namely in the distribution of research topics and citation patterns. The results indicate that the distribution of the research topics is similar in industry and academic papers. However, there is a strong preference towards citing industry papers. Finally, possible reasons for citation bias, such as code availability and influence, are investigated.",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:qfe1Ex3B87sC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Border Ownership Assignment based on Dorsal and Horizontal Modulations",
            "Publication year": 2018,
            "Publication url": "https://jov.arvojournals.org/article.aspx?articleid=2699790",
            "Abstract": "The face-vase illusion introduced by Rubin (Rubin, 1915) demonstrates how one can switch back and forth between two different interpretations by assigning borders to either side of contours in an image. Border ownership assignment is an important step in perception of forms. Zhou et al.(Zhou, Friedman, & von der Heydt, 2000) suggested that certain neurons in the visual cortex encode border ownership. They showed that the responses of these neurons not only depend on the local features present in their classical receptive fields, but also on the contextual information. Various models (Layton, Mingolla, & Yazdanbakhsh, 2012; Tschechne & Neumann, 2014) proposed employing feedback modulations for border ownership neurons as the neurons higher in the ventral stream have larger receptive fields and hence, can provide the required contextual information. Zhaoping (Zhaoping, 2005), however, suggested \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Ic6ZXhUAAAAJ:oe-dhlAyNXgC",
            "Publisher": "The Association for Research in Vision and Ophthalmology"
        },
        {
            "Title": "Task and timing in visual processing",
            "Publication year": 2007,
            "Publication url": "https://link.springer.com/article/10.1186/1471-2202-8-S2-P148",
            "Abstract": "The study of visual perception abounds with examples of surprising results, and perhaps none of these has generated more controversy than the speed of object recognition. Some complex objects can be recognized with amazing speed even while attention is engaged on a different task. Some simple objects need lengthy attentional scrutiny, and performance breaks down in dual-task experiments [1]. These results are fundamental to our understanding of the visual cortex, as they clearly show the interplay of the representation of information in the brain, attentional mechanisms, binding and consciousness.We argue that the lack of a common terminology is a significant contributor to this controversy, and define several different levels of tasks as: Detection\u2013is a particular item present in the stimulus, yes or no?; Localization\u2013detection plus accurate location; Recognition\u2013localization plus detailed description of \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Ic6ZXhUAAAAJ:LI9QrySNdTsC",
            "Publisher": "BioMed Central"
        },
        {
            "Title": "Fast hand gesture recognition for real-time teleconferencing applications",
            "Publication year": 2001,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/938922/",
            "Abstract": "Work on real-time hand-gesture recognition for SAVI (stereo active vision interface) is presented. Based on the detection of frontal faces, image regions near the face are searched for the existence of skin-tone blobs. Each blob is evaluated to determine if it it is a hand held in a standard pose. A verification algorithm based on the responses of elongated oriented filters is used to decide whether a hand is present or not. Once a hand is detected, gestures are given by varying the number of fingers visible. The hand is segmented using an algorithm which detects connected skin-tone blobs in the region of interest, and a medial axis transform (skeletonization) is applied. Analysis of the resulting skeleton allows detection of the number of fingers visible, thus determining the gesture. The skeletonization is sensitive to strong shadows which may alter the detected morphology of the hand. Experimental results are given \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Ic6ZXhUAAAAJ:dhFuZR0502QC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Totally looks like-how humans compare, compared to machines",
            "Publication year": 2018,
            "Publication url": "https://openaccess.thecvf.com/content_cvpr_2018_workshops/w39/html/Rosenfeld_Totally_Looks_Like_CVPR_2018_paper.html",
            "Abstract": "Perceptual judgment of image similarity by humans relies on rich internal representations ranging from low-level features to high-level concepts, scene properties and even cultural associations. Existing methods and datasets attempting to explain perceived similarity use stimuli which arguably do not cover the full breadth of factors that affect human similarity judgments, even those geared toward this goal. We introduce a new dataset dubbed Totally-Looks-Like (TLL) after a popular entertainment website, which contains images paired by humans as being visually similar. The dataset contains 6016 image-pairs from the wild, shedding light upon a rich and diverse set of criteria employed by human beings. We conduct experiments to try to reproduce the pairings via features extracted from state-of-the-art deep convolutional neural networks, as well as additional human experiments to verify the consistency of the collected data. Though we create conditions to artificially make the matching task increasingly easier, we show that machine-extracted representations perform very poorly in terms of reproducing the matching selected by humans. The results suggest future directions for improvement of learned image representations.",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:okqt0LpTEZoC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Second-Order (Non-Fourier) Attention-Based Face Detection",
            "Publication year": 2006,
            "Publication url": "https://link.springer.com/chapter/10.1007/11840930_54",
            "Abstract": "We present an attention-based face detection and localization system. The system is biologically motivated, combining face detection based on second-order circular patterns with the localization capabilities of the Selective Tuning (ST) model of visual attention [1]. One of the characteristics of this system is that the face detectors are relatively insensitive to the scale and location of the face, and thus additional processing needs to be performed to localize the face for recognition. We extend ST\u2019s ability to recover spatial information to this object recognition system, and show how this can be used to precisely localize faces in images. The system presented in this paper exhibits temporal characteristics that are qualitatively similar to those of the primate visual system in that detection and categorization is performed early in the processing cycle, while detailed information needed for recognition is only available \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Ic6ZXhUAAAAJ:Ri6SYOTghG4C",
            "Publisher": "Berlin: Springer-Verlag, 1973-"
        },
        {
            "Title": "SMILER: Consistent and Usable Saliency Model Implementations",
            "Publication year": 2019,
            "Publication url": "https://docs.lib.purdue.edu/modvis/2019/session03/3/",
            "Abstract": "The Saliency Model Implementation Library for Experimental Research (SMILER) is a new software package which provides an open, standardized, and extensible framework for maintaining and executing computational saliency models. This work drastically reduces the human effort required to apply saliency algorithms to new tasks and datasets, while also ensuring consistency and procedural correctness for results and conclusions produced by different parties. At its launch SMILER already includes twenty three saliency models (fourteen models based in MATLAB and nine supported through containerization), and the open design of SMILER encourages this number to grow with future contributions from the community. The project may be downloaded and contributed to through its GitHub page: https://github. com/tsotsoslab/smiler",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:0ZEOuji6PikC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Interactions between spatial and temporal attention: an attentional blink study",
            "Publication year": 2005,
            "Publication url": "https://jov.arvojournals.org/article.aspx?articleid=2131827",
            "Abstract": "This experiment investigated interactions between spatial and temporal attention using an attentional blink (AB) procedure. The target letter, defined by color, was presented amongst distractor letters in a rapid serial visual presentation (RSVP) stream. The probe was a light dot that could occur in various positions in relation to the RSVP stream ie close or further away. The probe could occur at various stimulus onset asynchronies before and after the target. The effect of the probe's spatial and temporal distance from the target was compared in single-(respond only to the probe) and dual-task (respond to the target and probe) conditions. Results are considered in relation to the spotlight, gradient and selective tuning models of visual attention.",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:b1wdh0AR-JQC",
            "Publisher": "The Association for Research in Vision and Ophthalmology"
        },
        {
            "Title": "Intriguing properties of randomly weighted networks: Generalizing while learning next to nothing",
            "Publication year": 2019,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/8781620/",
            "Abstract": "Training deep neural networks results in strong learned representations that show good generalization capabilities. In most cases, training involves iterative modification of all weights in the network via back-propagation. In Extreme Learning Machines, it has been suggested to set the first layer of a network to fixed random values instead of learning it. In this paper, we propose to take this approach a step further and fix almost all layers of a deep convolutional neural network, allowing only a small portion of the weights to be learned. As our experiments show, fixing even the majority of the parameters of the network often results in performance which is on par with the performance of learning all of them. The implications of this intriguing property of deep neural networks are discussed and we suggest practical ways to harness it to create more robust and compact representations.",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:yor2SLS1ZLQC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Bounding box splitting for robust shape classification",
            "Publication year": 2005,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/1530096/",
            "Abstract": "This paper presents a fast method to compute homeomorphisms between 2D lattices and shapes found in binary images. Unlike many other methods, this mapping is not restricted to simply connected shapes but applies to arbitrary topologies. Moreover, it provides an avenue to the embedding of shapes in vectorspaces over R and C and thus enables robust shape recognition.",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:sTSjfTwc8rsC",
            "Publisher": "Unknown"
        },
        {
            "Title": "SYSTEMS GUEST EDITORIAL SPECIAL ISSUE ON REPRESENTATIONS AND ARCHITECTURES FOR COGNITIVE Representations and Architectures for Cognitive Systems",
            "Publication year": 2010,
            "Publication url": "https://scholar.google.com/scholar?cluster=4960656324940307383&hl=en&oi=scholarr",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:z-xpeKpFZ3wC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Active Control of Camera Parameters for Object Detection Algorithms",
            "Publication year": 2017,
            "Publication url": "https://arxiv.org/abs/1705.05685",
            "Abstract": "Camera parameters not only play an important role in determining the visual quality of perceived images, but also affect the performance of vision algorithms, for a vision-guided robot. By quantitatively evaluating four object detection algorithms, with respect to varying ambient illumination, shutter speed and voltage gain, it is observed that the performance of the algorithms is highly dependent on these variables. From this observation, a novel active control of camera parameters method is proposed, to make robot vision more robust under different light conditions. Experimental results demonstrate the effectiveness of our proposed approach, which improves the performance of object detection algorithms, compared with the conventional auto-exposure algorithm.",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:aEPHIGigqugC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Attention in Autonomous Robotic Visual Search",
            "Publication year": 2014,
            "Publication url": "http://ncfrn.mcgill.ca/members/pubs/Tsotsos_Rasouli2.pdf",
            "Abstract": "One important element of autonomy for mobile robots, both terrestrial and planetary, is the ability to search for and find targets of interest whether they be important for navigation, for science missions, for localization or for manipulation. In this paper, we introduce a novel method of autonomous visual search that exploits the use of attention in the form of a saliency map that is used to enhance the probability distribution of which areas to look next, increasing the utility of spatial volumes, where objects consistent with the target\u2019s visual saliency are observed. Experimental results on a practical mobile robot are presented, which show that our proposed model improves the process of visual search in terms of reducing the time and number of actions to be performed to complete the process.",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:-6RzNnnwWf8C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Integrating Three Mechanisms of Visual Attention for Active Visual Search",
            "Publication year": 2015,
            "Publication url": "https://arxiv.org/abs/1702.04292",
            "Abstract": "Algorithms for robotic visual search can benefit from the use of visual attention methods in order to reduce computational costs. Here, we describe how three distinct mechanisms of visual attention can be integrated and productively used to improve search performance. The first is viewpoint selection as has been proposed earlier using a greedy search over a probabilistic occupancy grid representation. The second is top-down object-based attention using a histogram backprojection method, also previously described. The third is visual saliency. This is novel in the sense that it is not used as a region-of-interest method for the current image but rather as a noncombinatorial form of look-ahead in search for future viewpoint selection. Additionally, the integration of these three attentional schemes within a single framework is unique and not previously studied. We examine our proposed method in scenarios where little or no information regarding the environment is available. Through extensive experiments on a mobile robot, we show that our method improves visual search performance by reducing the time and number of actions required.",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:qmtmRrLr0tkC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Vision-based fallen person detection for the elderly",
            "Publication year": 2017,
            "Publication url": "http://openaccess.thecvf.com/content_ICCV_2017_workshops/w22/html/Solbach_Vision-Based_Fallen_Person_ICCV_2017_paper.html",
            "Abstract": "Falls are serious and costly for elderly people. The Centers for Disease Control and Prevention of the US reports that millions of older people, 65 and older, fall each year at least once. Serious injuries such as; hip fractures, broken bones or head injury, are caused by 20% of the falls. The time it takes to respond and treat a fallen person is crucial. With this paper we present a new, non-invasive system for fallen people detection. Our approach uses only stereo camera data for passively sensing the environment. The key novelty is a human fall detector which uses a CNN based human pose estimator in combination with stereo data to reconstruct the human pose in 3D and estimate the ground plane in 3D. We have tested our approach in different scenarios covering most activities elderly people might encounter living at home. Based on our extensive evaluations, our systems shows high accuracy and almost no miss-classification. Our implementation is publicly available.",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:wmnBrZFLFP0C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Visual representation in the determination of saliency",
            "Publication year": 2011,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/5957567/",
            "Abstract": "In this paper, we consider the role that visual representation plays in determining the behavior of a generic model of visual salience. There are a variety of different representations that have been employed to form an early visual representation of image structure. The experiments presented demonstrate that the choice of representation has an appreciable effect on the system behavior. The reasons for these differences are discussed, and generalized to implications for vision systems in general. In instances where a design choice is arbitrary, we look to the properties of visual representation in early visual processing in humans for answers. The results as a whole demonstrate the importance of filter choice and highlight some desirable properties of log-Gabor filters.",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:LO7wyVUgiFcC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Attending to orientation results in an inhibitory surround in orientation space",
            "Publication year": 2008,
            "Publication url": "https://link.springer.com/article/10.3758/PP.70.1.30",
            "Abstract": "Subjects were required to attend to an orientation and make judgments about the stripes on briefly presented disks. Stripe orientation was varied so that they could be at, near, or far from the attended orientation. According to the selective-tuning model (Tsotsos, 1990; Tsotsos et al., 1995), attending to an orientation results in an inhibitory surround for nearby orientations, but not for orientations farther away. In line with this prediction, the results revealed an inhibitory surround. As in the spatial domain, attending to a point in orientation space results in an inhibitory surround for nearby orientations.",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:f2IySw72cVMC",
            "Publisher": "Springer-Verlag"
        },
        {
            "Title": "Visual tasks lead to unique sequences of cyclic attentional signals",
            "Publication year": 2016,
            "Publication url": "https://jov.arvojournals.org/article.aspx?articleid=2550599",
            "Abstract": "The enormous breadth of human visual tasks highlights the question of how the visual cortex achieves this incredible generality. Recently, models of vision and visual attention (eg, Tsotsos 2011, Beuth & Hamker 2015) have incorporated specific solutions toward such generality resulting in the insight that different visual tasks require unique patterns of neural activations to occur with specific timings in order to provide unified response. For example, sub-tasks such as task-set specific priming of visual features, disengaging from a previous attentional focus, selection of a next focus, matching focus to task, eye movements, storing extracted information into working memory, recognition of task completion (or failure), and resetting for the next task need to be set up, initiated, monitored and terminated with precise timing and coordination. Each computation takes time, each transfer of information between representations \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Ic6ZXhUAAAAJ:aMQnNzTHVu4C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Attention and visual search: Active robotic vision systems that search",
            "Publication year": 2007,
            "Publication url": "https://biecoll2.ub.uni-bielefeld.de/index.php/icvs/article/view/191",
            "Abstract": "Visual attention is a multi-faceted phenomenon, playing different roles in different situations and for different processing mechanisms. Regardless, attention is a mechanism that optimizes the search processes inherent in vision. This perspective leads to sound theoretical foundation for studies of attention in both machine and in the brain. The development of this foundation and the many ways in which attentional processes manifest themselves will be overviewed. One particular example of a practical robotic vision system that employs some of these attentional processes will be described. A difficult problem for robotic vision systems is visual search for a given target in an arbitrary 3D space. A solution to this problem will be described that optimizes the probability of finding the target given a fixed cost limit in terms of total number of robotic actions the robot requires to find its visual target. A robotic realization will be shown.",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:YynyIpEqGK0C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Tracking a person with pre-recorded image database and a pan, tilt, and zoom camera",
            "Publication year": 2000,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/646015/",
            "Abstract": "This paper proposes a novel tracking strategy that can robustly track a person or other object, within a fixed environment using a pan, tilt, and zoom camera with the help of a pre-recorded image database. We define a set called the minimum camera parameter settings (MCPS) which contains just enough camera states as required to survey the environment for the target. This set of states is used to facilitate tracking and segmentation. The idea is to store a background image of the environment for every camera state in MCPS, thus creating an image database. During tracking camera movements are restricted to states in MCPS (or a version of this set that is augmented to improve smoothness of tracking). Scanning for the target and segmentation of the target from the background are simplified as each current image can be compared with the corresponding pre-recorded background image.",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:70eg2SAEIzsC",
            "Publisher": "Springer-Verlag"
        },
        {
            "Title": "Overt fixations reflect a natural central bias",
            "Publication year": 2013,
            "Publication url": "https://www.researchgate.net/profile/John-Tsotsos/publication/266158154_Overt_Fixations_Reflect_a_Natural_Central_Bias/links/54b920a00cf28faced626f7e/Overt-Fixations-Reflect-a-Natural-Central-Bias.pdf",
            "Abstract": "Judd et al. provide a large (1003 images) and useful psychophysical eye-tracking data set from which human fixation statistics may be examined [4]. Judd et al. took their recorded subject fixations and turned them into saliency maps by convolving the fixation point maps with a Gaussian kernel; the average of these maps produces a strongly centralized blob of high salience as shown in Figure 3.",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:9djSGow2EaoC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Chandra'present a compelling argument for the relevance of complexity. The most",
            "Publication year": 2012,
            "Publication url": "https://books.google.com/books?hl=en&lr=&id=YBIDCAAAQBAJ&oi=fnd&pg=PA185&dq=info:sj7NErjJ_NsJ:scholar.google.com&ots=x1U1Sw_1hi&sig=e9ljNIc_stI_XnQTZ6KnwGobOYk",
            "Abstract": "powerful computer that could conceivably be built could not be larger than the known universe (less than 100 billion light-years in diameter), could not consist of hardware smaller than the proton (10-13 cm in diameter), and could not transmit information faster than the speed of light (3 x 108 m/s). Given these limitations, such a computer could consist of at most 10126 pieces of hardware. It can be proved that, regardless of the ingenuity of its design and the Sophistication of its program, this ideal computer would take at least 20 billion years to solve certain mathematical problems that are known to be solvable in principle. Since the universe is probably less than 20 billion years old, it seems safe to say that such problems defy computer analysis. There do exist real problems for which this argument applies (see Garey & Johnson\u2019for a catalog).",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:IZKZNMMMWs0C",
            "Publisher": "Springer Science & Business Media"
        },
        {
            "Title": "Velocity gradient information influences optical flow processing in human observers",
            "Publication year": 2004,
            "Publication url": "http://www.cse.yorku.ca/~tsotsos/Homepage%20of%20John%20K_files/posters/VSS2004final.pdf",
            "Abstract": "Methods Stimuli: were moving random dot patterns (RDPs)(100% coherence) accelerating or decelerating following straight paths. A trial consisted of the presentation of an adapting pattern lasting 20 sec. followed by a test pattern lasting 0.5 sec. Subjects decided whether the test pattern was accelerating or decelerating. Four different conditions consisting of 33 trials each were run by eight subjects. The staircase method was used.20 sec adaptation500 msec test 500 msec response or+",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:NJ774b8OgUMC",
            "Publisher": "The Association for Research in Vision and Ophthalmology"
        },
        {
            "Title": "Feature conjunctions in visual search",
            "Publication year": 2006,
            "Publication url": "https://link.springer.com/chapter/10.1007/11840930_52",
            "Abstract": "Selective Tuning (ST) [1] presents a framework for modeling attention and in this paper we show how it performs in visual search tasks. Two types of tasks are presented, a motion search task and an object search task. Both tasks are successfully tested with different feature and conjunction visual searches.",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:UHK10RUVsp4C",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "Long-term memory and hippocampal function support predictive gaze control during goal-directed search",
            "Publication year": 2020,
            "Publication url": "https://arvojournals.org/article.aspx?articleid=2766246",
            "Abstract": "Eye movements during visual search change with prior experience for search stimuli. Previous studies measured these gaze effects shortly after initial viewing, typically during free viewing; it remains open whether the effects are preserved across long delays and for goal-directed search, and which memory system guides gaze. In Experiment 1, we analyzed eye movements of healthy adults viewing novel and repeated scenes while searching for a scene-embedded target. The task was performed across different time points to examine the repetition effects in long-term memory, and memory types were grouped based on explicit recall of targets. In Experiment 2, an amnesic person with bilateral extended hippocampal damage and the age-matched control group performed the same task with shorter intervals to determine whether or not the repetition effects depend on hippocampal function. When healthy adults explicitly remembered repeated target-scene pairs, search time and fixation duration decreased, and gaze was directed closer to the target region, than when they forgot targets. These effects were seen even after a one-month delay from their initial viewing, suggesting the effects are associated with long-term, explicit memory. Saccadic amplitude was not strongly modulated by scene repetition or explicit recall of targets. The amnesic person did not show explicit recall or implicit repetition effects, whereas his control group showed similar patterns to those seen in Experiment 1. The results reveal several aspects of gaze control that are influenced by long-term memory. The dependence of gaze effects on medial temporal lobe integrity support \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Ic6ZXhUAAAAJ:0XvJNYv_SW4C",
            "Publisher": "The Association for Research in Vision and Ophthalmology"
        },
        {
            "Title": "Computational Foundations for Attentive Processes",
            "Publication year": 2005,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/B9780123757319500057",
            "Abstract": "Notions such as capacity limits pervade the attention literature. This presentation attempts to make these concrete and to discover constraints on plausible solutions to vision. Through the proofs, approximations, and optimizations to find architectures that plausibly do not violate biological constraints, important problems such as information routing and signal interference can be addressed. Perhaps the most important conclusion is that the brain is not solving the generic vision problem. Rather, the generic problem is reshaped through approximations so that it becomes solvable by the amount of processing power available for vision. Selective attention in feature, image, and object space plays a necessary role.",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:yjYM2qeFg4IC",
            "Publisher": "Elsevier"
        },
        {
            "Title": "Precise localization in conflicting context requires feedback processing",
            "Publication year": 2019,
            "Publication url": "https://jov.arvojournals.org/article.aspx?articleid=2750326",
            "Abstract": "People can rapidly perform simple visual tasks, such as object detection or categorization, suggesting the sufficiency of feed-forward visual processing for these tasks. However, more complex tasks, such as precise localization may require high-resolution information available at early areas in the visual hierarchy. Top-down feedback processing that traverses several stages in the visual hierarchy allows access to this information, but additional processing time is needed for this traversal (Tsotsos et al., 2008). Motivated by this, we hypothesized that a localization task which requires precise location information represented in early visual areas would need longer processing time than a simple categorization task. Each participant performed both categorization (animal detection) and feature localization tasks. We constrained stimulus presentation durations and compared processing time needed to perform each task \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Ic6ZXhUAAAAJ:OeO3PiPA3c0C",
            "Publisher": "The Association for Research in Vision and Ophthalmology"
        },
        {
            "Title": "A Complexity\u2010Level Analysis of the Sensor Planning Task for Object Search",
            "Publication year": 2001,
            "Publication url": "https://onlinelibrary.wiley.com/doi/abs/10.1111/0824-7935.00166",
            "Abstract": "Object search is the task of searching for a given 3D object in a given 3D environment by a controllable camera. Sensor planning for object search refers to the task of how to select the sensing parameters of the camera so as to bring the target into the field of view of the camera and to make the image of the target to be easily recognized by the available recognition algorithms. In this paper, we study the task of sensor planning for object search from the theoretical point of view. We formulate the task and point out many of its important properties. We then analyze this task from the complexity level and prove that this task is NP\u2010Complete.",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:pqnbT2bcN3wC",
            "Publisher": "Blackwell Publishers Inc"
        },
        {
            "Title": "Priming neural networks",
            "Publication year": 2018,
            "Publication url": "http://openaccess.thecvf.com/content_cvpr_2018_workshops/w39/html/Rosenfeld_Priming_Neural_Networks_CVPR_2018_paper.html",
            "Abstract": "Visual priming is known to affect the human visual system to allow detection of scene elements, even those that may have been near unnoticeable before, such as the presence of camouflaged animals. This process has been shown to be an effect of top-down signaling in the visual system triggered by the said cue. In this paper, we propose a mechanism to mimic the process of priming in the context of object detection and segmentation. We view priming as having a modulatory, cue dependent effect on layers of features within a network. Our results show how such a process can be complementary to, and at times more effective than simple post-processing applied to the output of the network, notably so in cases where the object is hard to detect such as in severe noise, small size or atypical appearance. Moreover, we find the effects of priming are sometimes stronger when early visual layers are affected. Overall, our experiments confirm that top-down signals can go a long way in improving object detection and segmentation.",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:lPNvfOEJVFUC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Visual Search with selective tuning",
            "Publication year": 2007,
            "Publication url": "https://jov.arvojournals.org/article.aspx?articleid=2134998",
            "Abstract": "Visual attention involves much more than simply the selection of next fixation for the eyes or for a camera system. Selective Tuning (ST)(Tsotsos et al. 1995; 2005) presents a framework for modeling this broader view of attention and in this work we show how it performs in covert visual search tasks by comparing its performance to the same input visual displays that human subjects have seen and qualitatively comparing the model's performance to human performance. Two implementations of ST have been developed. The Motion Model (MM) recognizes and attends to motion patterns and the Object Recognition Model (ORM) recognizes and attends to simple objects formed by the conjunction of various features. Two experiments were carried out in the motion domain. A simple odd-man-out search for CCW rotating octagon among identical CW rotating octagons produced linear increase in search time with the \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Ic6ZXhUAAAAJ:k8Z6L05lTy4C",
            "Publisher": "The Association for Research in Vision and Ophthalmology"
        },
        {
            "Title": "Attention and Performance in Computational Vision: Second International Workshop, WAPCV 2004",
            "Publication year": 2005,
            "Publication url": "Unknown",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:AYInfyleIOsC",
            "Publisher": "Springer-Verlag Heidelberg"
        },
        {
            "Title": "40 Years of Cognitive Architectures Core Cognitive Abilities and Practical Applications",
            "Publication year": 2017,
            "Publication url": "https://scholar.google.com/scholar?cluster=9962003745001879829&hl=en&oi=scholarr",
            "Abstract": "In this paper we present a broad overview of the last 40 years of research on cognitive architectures. Although the number of existing architectures is nearing several hundred, most of the existing surveys do not reflect this growth and focus on a handful of well-established architectures. Thus, in this survey we wanted to shift the focus towards a more inclusive and high-level overview of the research on cognitive architectures. Our final set of 85 architectures includes 49 that are still actively developed, and borrow from a diverse set of disciplines, spanning areas from psychoanalysis to neuroscience. To keep the length of this paper within reasonable limits we discuss only the core cognitive abilities, such as perception, attention mechanisms, action selection, memory, learning and reasoning. In order to assess the breadth of practical applications of cognitive architectures we gathered information on over 900 practical projects implemented using the cognitive architectures in our list.We use various visualization techniques to highlight overall trends in the development of the field. In addition to summarizing the current state-of-the-art in the cognitive architecture research, this survey describes a variety of methods and ideas that have been tried and their relative success in modeling human cognitive abilities, as well as which aspects of cognitive behavior need more research with respect to their mechanistic counterparts and thus can further inform how cognitive science might progress.",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:N8UqZ3HJrRYC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Fast visual object tracking with rotated bounding boxes",
            "Publication year": 2019,
            "Publication url": "https://arxiv.org/abs/1907.03892",
            "Abstract": "In this paper, we demonstrate a novel algorithm that uses ellipse fitting to estimate the bounding box rotation angle and size with the segmentation(mask) on the target for online and real-time visual object tracking. Our method, SiamMask_E, improves the bounding box fitting procedure of the state-of-the-art object tracking algorithm SiamMask and still retains a fast-tracking frame rate (80 fps) on a system equipped with GPU (GeForce GTX 1080 Ti or higher). We tested our approach on the visual object tracking datasets (VOT2016, VOT2018, and VOT2019) that were labeled with rotated bounding boxes. By comparing with the original SiamMask, we achieved an improved Accuracy of 0.652 and 0.309 EAO on VOT2019, which is 0.056 and 0.026 higher than the original SiamMask. The implementation is available on GitHub: https://github.com/baoxinchen/siammask_e.",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:PGOTqER0XmoC",
            "Publisher": "Unknown"
        },
        {
            "Title": "059 EDGE MOTION TECHNOLOGY TO DETECT ABNORMALITIES OF GAIT AND BALANCE",
            "Publication year": 2010,
            "Publication url": "https://www.infona.pl/resource/bwmeta1.element.elsevier-53cde489-1f4a-3247-8836-080ecb2366e4",
            "Abstract": "059 EDGE MOTION TECHNOLOGY TO DETECT ABNORMALITIES OF GAIT AND BALANCE \u00d7 \nClose The Infona portal uses cookies, ie strings of text saved by a browser on the user's \ndevice. The portal can access those files and use them to remember the user's data, such as \ntheir chosen settings (screen view, interface language, etc.), or their login data. By using the \nInfona portal the user accepts automatic saving and using this information for portal operation \npurposes. More information on the subject can be found in the Privacy Policy and Terms of \nService. By closing this window the user confirms that they have read the information on cookie \nusage, and they accept the privacy policy and the way cookies are used by the portal. You can \nchange the cookie settings in your browser. I accept Polski English Login or register account \nremember me Password recovery INFONA - science communication portal INFONA \u00d7 of -\u2026",
            "Abstract entirety": 0,
            "Author pub id": "Ic6ZXhUAAAAJ:vbGhcppDl1QC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Computational abstraction towards a theory of the brain",
            "Publication year": 2015,
            "Publication url": "https://core.ac.uk/download/pdf/81112759.pdf",
            "Abstract": "R698 Current Biology 25, R693\u2013R710, August 17, 2015\u00a9 2015 Elsevier Ltd All rights reserved components of Ballard\u2019s research enterprise, and it is not unexpected to find a whole chapter, very well presented, on the topic. I particularly like the summary section 5.7, where a list of constraints that must be satisfied by programs in the brain is given.Whereas Parts I and II focused on basic concepts and details of components, Part III puts these all together to see how they lead to behavior. The first two chapters deal with the concept of routines\u2014specialized programs that encode the sequence of actions, sensory or motor, that are required to carry out behaviors. This is a critical idea, without which the many specialized abilities we know are present in the brain have no means of combining to support complex human behavior. The concept is not simply a useful theoretical construct, as Ballard presents strong evidence for such routines in the brain. To me, research into such routines\u2014their characteristics, their locus in the brain, their function, their computational embodiment\u2014is among the most interesting future directions, and Ballard motivates a very useful foundation for this. The third chapter of Part III presents the last level of the hierarchy, the component that actually makes behavior happen\u2014the operating system. Here is where all the routines finally come together and where critical functionality is added, without which normal behavior would be impossible. The overall brain must have some element that is able to monitor the execution of routines, to determine if that execution is going as expected, to determine when a task had been successfully \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Ic6ZXhUAAAAJ:RtRctb2lSbAC",
            "Publisher": "Elsevier"
        },
        {
            "Title": "The Role of Attention in Shaping Visual Perceptual Processes",
            "Publication year": 2011,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-1-4419-1452-1_1",
            "Abstract": "It has been known now for over 20 years that an optimal solution to a basic vision problem such as visual search, which is robust enough to apply to any possible image or target, is unattainable because the problem of visual search is provably intractable (\u201cTsotsos, The complexity of perceptual search tasks, Proceedings of the International Joint Conference on Artificial Intelligence, 1989,\u201d \u201cRensink, A new proof of the NP-completeness of visual match, Technical Report 89\u201322, University of British Columbia, 1989\u201d). That the brain seems to solve it in an apparently effortless manner then poses a mystery. Either the brain is performing in a manner that cannot be captured computationally, or it is not solving that same generic visual search problem. The first option has been shown to not be the case (\u201cTsotsos and Bruce, Scholarpedia, 3(12), 6545, 2008\u201d). As a result, this chapter will focus on the second possibility \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Ic6ZXhUAAAAJ:-FonjvnnhkoC",
            "Publisher": "Springer, New York, NY"
        },
        {
            "Title": "Early Recurrence Improves Edge Detection.",
            "Publication year": 2013,
            "Publication url": "http://www.bmva.org/bmvc/2013/Papers/paper0022/paper0022.pdf",
            "Abstract": "A biologically motivated computational model of early recurrence is proposed for edge detection. Studies of the primate vision suggested that visual features are transmitted in the two visual pathways with different speeds (with the dorsal pathway processing faster than that of the ventral pathway) and the presences of extensive recurrent connections across the two pathways. It is thus likely that the dorsal perception facilitates the ventral perception via early recurrent mechanism. Following these neural principles, we hypothesize that early recurrence enables responses to high-spatial frequency features (fine edges) to be suppressed by low-spatial frequency features (coarse edges) in a multiplicative manner. Using real images, we quantitatively compared contours calculated by our work with another well-known biologically motivated model. To further explore early recurrence in solving machine vision problems, the representation is used to boost different popular edge algorithms. Results from both experiments lead to the conclusion that early recurrence has a positive and consistent influence on edge detection.",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:2v_ZtQDX9iAC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Psychophysical evaluation of saliency algorithms",
            "Publication year": 2016,
            "Publication url": "https://jov.arvojournals.org/article.aspx?articleid=2551269",
            "Abstract": "Significant effort has been spent evaluating the performance of saliency algorithms at predicting human fixations in natural images. However, many other aspects of human visual attention have received relatively little focus in the saliency literature but have been richly characterized by psychophysical investigations. In order to make use of this data, Bruce et al.(2015) have recommended the development of an axiomatic set of model constraints grounded in this body of psychophysical knowledge. We aim to provide a step towards this goal by linking human visual search response time to saliency algorithm output. Duncan and Humphreys (1989) theorized that subject response time in visual search tasks is correlated with similarity between search items (with search time increasing as targets become more similar to distractors). This result fits well with the widely held notion that saliency is largely driven by stimulus \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Ic6ZXhUAAAAJ:judUAtIFz0MC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Selection of Marr Prize Winners and Runners Up at ICCV 99",
            "Publication year": 2000,
            "Publication url": "https://scholar.google.com/scholar?cluster=12816593799291752766&hl=en&oi=scholarr",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:rmuvC79q63oC",
            "Publisher": "KLUWER ACADEMIC PUBLISHERS GROUP"
        },
        {
            "Title": "Computational Models Of Primate Visual Attention",
            "Publication year": 2004,
            "Publication url": "https://www.researchgate.net/profile/John-Tsotsos/publication/220579823_Computational_models_of_visual_attention/links/0fcfd50bf6f936c1a5000000/Computational-models-of-visual-attention.pdf",
            "Abstract": "This paper presents a comprehensive survey of approaches to the computational modeling of visual attention. A key characteristic of virtually all the models surveyed is that they receive significant inspiration from the neurobiology and psychophysics of human and primate vision. This, although not necessarily a key component of mainstream computer vision, seems very appropriate for cognitive vision systems given a definition of the topic that always includes the goal of human-like visual performance. The review is placed in the context of related computer vision and neuroscience research. Major theories of primate visual attention are presented in an original classification.",
            "Abstract entirety": 1,
            "Author pub id": "Ic6ZXhUAAAAJ:PoWvk5oyLR8C",
            "Publisher": "Unknown"
        },
        {
            "Title": "The interaction of target-distractor similarity and visual search efficiency for basic features",
            "Publication year": 2017,
            "Publication url": "https://jov.arvojournals.org/article.aspx?articleid=2652000",
            "Abstract": "Visual search efficiency is commonly measured by the relationship between subject response time (RT) and display set size. Basic features are visual features for which a singleton target can be found efficiently (RT independent of set size), a situation commonly referred to as pop-out. However, the seminal work of Duncan and Humphreys (1989) demonstrated that visual search RT is also correlated with the degree of target-distractor similarity. As similarity of the target with its surrounding distractors increases (and thus the target becomes more difficult to distinguish) RT can dramatically increase. Wolfe (1998a) identified this category as hard feature search, but left both an in-depth analysis of the transition from standard feature search to a hard search as well as the efficiency of hard search largely unexplored beyond a small number of orientation trials. As far as we are aware, the interaction of these two \u2026",
            "Abstract entirety": 0,
            "Author pub id": "Ic6ZXhUAAAAJ:FqkprvusZAMC",
            "Publisher": "The Association for Research in Vision and Ophthalmology"
        }
    ]
}]