[{
    "name": "\u0394\u03b9\u03bf\u03bd\u03cd\u03c3\u03b9\u03bf\u03c2 \u03a0\u03bd\u03b5\u03c5\u03bc\u03b1\u03c4\u03b9\u03ba\u03ac\u03c4\u03bf\u03c2 ",
    "romanize name": "Dionysios Pnevmatikatos ",
    "School-Department": "\u0397\u03bb\u03b5\u03ba\u03c4\u03c1\u03bf\u03bb\u03cc\u03b3\u03c9\u03bd \u039c\u03b7\u03c7\u03b1\u03bd\u03b9\u03ba\u03ce\u03bd \u03ba\u03b1\u03b9 \u039c\u03b7\u03c7\u03b1\u03bd\u03b9\u03ba\u03ce\u03bd \u03a5\u03c0\u03bf\u03bb\u03bf\u03b3\u03b9\u03c3\u03c4\u03ce\u03bd",
    "University": "ntua",
    "Rank": "\u039a\u03b1\u03b8\u03b7\u03b3\u03b7\u03c4\u03ae\u03c2",
    "Apella_id": 18599,
    "Scholar name": "Dionisios Pnevmatikatos",
    "Scholar id": "TKtxe-UAAAAJ",
    "Affiliation": "Professor of ECE,  National Technical University of Athens",
    "Citedby": 3460,
    "Interests": [
        "Computer Architecture",
        "Reconfigurable Computing",
        "Networking hardware"
    ],
    "Scholar url": "https://scholar.google.com/citations?user=TKtxe-UAAAAJ&hl=en",
    "Publications": [
        {
            "Title": "Code generation for packet header intrusion analysis on the ixp1200 network processor",
            "Publication year": 2003,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-540-39920-9_16",
            "Abstract": "We present a software architecture that enables the use of the IXP1200 network processor in packet header analysis for network intrusion detection. The proposed work consists of a simple and efficient run-time infrastructure for managing network processor resources, along with the S2I compiler, a tool that generates efficient C code from high-level, human readable, intrusion signatures. This approach facilitates the employment of the IXP1200 in network intrusion detection systems while our experimental results demonstrate that provides performance comparable to hand-crafted code.",
            "Abstract entirety": 1,
            "Author pub id": "TKtxe-UAAAAJ:0EnyYjriUFMC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "UNILOGIC: A novel architecture for highly parallel reconfigurable systems",
            "Publication year": 2020,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/3409115",
            "Abstract": "One of the main characteristics of High-performance Computing (HPC) applications is that they become increasingly performance and power demanding, pushing HPC systems to their limits. Existing HPC systems have not yet reached exascale performance mainly due to power limitations. Extrapolating from today\u2019s top HPC systems, about 100\u2013200 MWatts would be required to sustain an exaflop-level of performance. A promising solution for tackling power limitations is the deployment of energy-efficient reconfigurable resources (in the form of Field-programmable Gate Arrays (FPGAs)) tightly integrated with conventional CPUs. However, current FPGA tools and programming environments are optimized for accelerating a single application or even task on a single FPGA device. In this work, we present UNILOGIC (Unified Logic), a novel HPC-tailored parallel architecture that efficiently incorporates FPGAs \u2026",
            "Abstract entirety": 0,
            "Author pub id": "TKtxe-UAAAAJ:BUYA1_V_uYcC",
            "Publisher": "ACM"
        },
        {
            "Title": "On the importance of header classification in hw/sw network intrusion detection systems",
            "Publication year": 2005,
            "Publication url": "https://link.springer.com/chapter/10.1007/11573036_63",
            "Abstract": "In this paper we examine the impact of various levels of (partial) hardware acceleration levels on a software based Network Intrusion Detection System. While complete hardware solutions are possible and have been studied extensively, they are costly and may suffer from scalability and flexibility limitations. The flexibility of software is attractive to address these concerns. We show in this paper that (unexpectedly) a modest amount of hardware acceleration such as simple header classification can achieve respectable and cost-effective system throughput. We also find that further acceleration in the form of approximate filtering offers very small incremental improvement.",
            "Abstract entirety": 1,
            "Author pub id": "TKtxe-UAAAAJ:3fE2CSJIrl8C",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "Variable-length hashing for exact pattern matching",
            "Publication year": 2006,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/4101006/",
            "Abstract": "HashMem is a memory based, exact pattern matching architecture for Snort-like intrusion detection. It uses CRC- style functions to determine a unique location for a possible match and then matches the input against the pattern stored in the specified memory location. This approach achieves is a very low logic and a reasonable memory cost. In this paper we extend the HashMem architecture to allow storing of variable-length patterns in a single memory structure, reducing the number of required memory structures and comparators. In this way, we improve the density of the memories and reduce the necessary logic for CRC functions and comparators. These improvements allow V-HashMem to accommodate the newest Snort rule-set with modest memory and very low logic cost of about 0.06 logic cells per search pattern character. This logic cost is almost an order of magnitude smaller compared to other research \u2026",
            "Abstract entirety": 0,
            "Author pub id": "TKtxe-UAAAAJ:MXK_kJrjxJIC",
            "Publisher": "IEEE"
        },
        {
            "Title": "A memory-efficient reconfigurable Aho-Corasick FSM implementation for intrusion detection systems",
            "Publication year": 2007,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/4285750/",
            "Abstract": "The Aho-Corasick (AC) algorithm is a very flexible and efficient but memory-hungry pattern matching algorithm that can scan the existence of a query string among multiple test strings looking at each character exactly once, making it one of the main options for software-base intrusion detection systems such as SNORT. We present the Split-AC algorithm, which is a reconfigurable variation of the AC algorithm that exploits domain-specific characteristics of intrusion detection to reduce considerably the FSM memory requirements. SplitAC achieves an overall reduction between 28-75% compared to the best proposed implementation.",
            "Abstract entirety": 1,
            "Author pub id": "TKtxe-UAAAAJ:8k81kl-MbHgC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Enabling Virtual Memory Research on RISC-V with a Configurable TLB Hierarchy for the Rocket Chip Generator",
            "Publication year": 2020,
            "Publication url": "https://ui.adsabs.harvard.edu/abs/2020arXiv200907723C/abstract",
            "Abstract": "The Rocket Chip Generator uses a collection of parameterized processor components to produce RISC-V-based SoCs. It is a powerful tool that can produce a wide variety of processor designs ranging from tiny embedded processors to complex multi-core systems. In this paper we extend the features of the Memory Management Unit of the Rocket Chip Generator and specifically the TLB hierarchy. TLBs are essential in terms of performance because they mitigate the overhead of frequent Page Table Walks, but may harm the critical path of the processor due to their size and/or associativity. In the original Rocket Chip implementation the L1 Instruction/Data TLB is fully-associative and the shared L2 TLB is direct-mapped. We lift these restrictions and design and implement configurable, set-associative L1 and L2 TLB templates that can create any organization from direct-mapped to fully-associative to achieve the \u2026",
            "Abstract entirety": 0,
            "Author pub id": "TKtxe-UAAAAJ:4MWp96NkSFoC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Modeling multi-board communication in the axiom cyber-physical system",
            "Publication year": 2016,
            "Publication url": "http://www.ada-europe.org/archive/auj/auj-37-4.pdf#page=48",
            "Abstract": "The main goal of the AXIOM project is to design a small board that could be used as a LEGOTM-style module to build systems with more performance while keeping the programming task simple by using a familiar sharedmemory programming model. The interconnection plays a crucial role both for the need of providing fast and reliable communication (including lossless control flow as, eg, Infiniband, but with a simplified scope and cost). In this paper, we outline some of our initial choices and explore the performance of RDMA based mechanisms and interfaces, including the remote memory management behind the programming model. Our initial results show a potential for scaling the system as we use DF-Threads, good bandwidth for RDMA transfers, promising to scale once we use the OmpSs, programming model.",
            "Abstract entirety": 1,
            "Author pub id": "TKtxe-UAAAAJ:olpn-zPbct0C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Design and implementation of a database filter for BLAST acceleration",
            "Publication year": 2009,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/5090652/",
            "Abstract": "BLAST is a very popular computational biology algorithm. Since it is computationally expensive it is a natural target for acceleration research, and many reconfigurable architectures have been proposed offering significant improvements. In this paper we approach the same problem with a different approach: we propose a BLAST algorithm preprocessor that efficiently identifies the portions of the database that must be processed by the full algorithm in order to find the complete set of desired results. We show that this preprocessing is feasible and quick, and requires minimal FPGA resources, while achieving a significant reduction in the size of the database that needs to be processed by BLAST. We also determine the parameters under which prefiltering is guaranteed to identify the same set of solutions as the original NCBI software. We model our preprocessor in VHDL and implement it in reconfigurable \u2026",
            "Abstract entirety": 0,
            "Author pub id": "TKtxe-UAAAAJ:ZeXyd9-uunAC",
            "Publisher": "IEEE"
        },
        {
            "Title": "EXTRA: An open platform for reconfigurable architectures",
            "Publication year": 2018,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/3229631.3236092",
            "Abstract": "Reconfigurable hardware is becoming increasingly mainstream, evolving to a valid alternative to Graphics Processing Units-based hardware accelerators. However, several major challenges remain for migrating existing software to heterogeneous reconfigurable architectures. The EXTRA project aims to develop an integrated environment for developing and programming reconfigurable architectures. The EXTRA platform enables the joint optimization of architecture, tools, and reconfiguration technology, and targets the future High Performance Computing hardware nodes. In this paper, we present four innovative EXTRA technologies:(1) a hardware-software co-design framework;(2) a parallel memory system;(3) a decoupled access execute framework for reconfigurable technology; and (4) transparent access and virtualization of reconfigurable hardware accelerators. Moreover, we describe how the EXTRA \u2026",
            "Abstract entirety": 0,
            "Author pub id": "TKtxe-UAAAAJ:fEOibwPWpKIC",
            "Publisher": "Unknown"
        },
        {
            "Title": "RAiSD-X: A Fast and Accurate FPGA System for the Detection of Positive Selection in Thousands of Genomes",
            "Publication year": 2019,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/3364225",
            "Abstract": "Detecting traces of positive selection in genomes carries theoretical significance and has practical applications from shedding light on the forces that drive adaptive evolution to the design of more effective drug treatments. The size of genomic datasets currently grows at an unprecedented pace, fueled by continuous advances in DNA sequencing technologies, leading to ever-increasing compute and memory requirements for meaningful genomic analyses. The majority of existing methods for positive selection detection either are not designed to handle whole genomes or scale poorly with the sample size; they inevitably resort to a runtime versus accuracy tradeoff, raising an alarming concern for the feasibility of future large-scale scans. To this end, we present RAiSD-X, a high-performance system that relies on a decoupled access-execute processing paradigm for efficient FPGA acceleration and couples a novel, to \u2026",
            "Abstract entirety": 0,
            "Author pub id": "TKtxe-UAAAAJ:EkHepimYqZsC",
            "Publisher": "ACM"
        },
        {
            "Title": "The AXIOM project (agile, extensible, fast i/o module)",
            "Publication year": 2015,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/7363684/",
            "Abstract": "The AXIOM project (Agile, eXtensible, fast I/O Module) aims at researching new software/hardware architectures for the future Cyber-Physical Systems (CPSs). These systems are expected to react in real-time, provide enough computational power for the assigned tasks, consume the least possible energy for such task (energy efficiency), scale up through modularity, allow for an easy programmability across performance scaling, and exploit at best existing standards at minimal costs.",
            "Abstract entirety": 1,
            "Author pub id": "TKtxe-UAAAAJ:l7t_Zn2s7bgC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Cproc: An efficient Cryptographic Coprocessor",
            "Publication year": 2008,
            "Publication url": "http://ce-publications.et.tudelft.nl/publications/549_ccproc_an_efficient_cryptographic_coprocessor.pdf",
            "Abstract": "In this paper we introduce CCproc, a symmetric-key cryptographic (co) processor with a custom instruction set optimized for cryptographic applications. We study ten popular crypto algorithms, and provide custom solutions for them, while we also offer general support for future encryption algorithms. We design a custom but simple datapath able to execute the proposed instruction set and analyze its performance, proving to be competitive with other general purpose (but not custom) approaches, while having very small implementation cost.",
            "Abstract entirety": 1,
            "Author pub id": "TKtxe-UAAAAJ:mVmsd5A6BfQC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Processing and scheduling components in an innovative network processor architecture",
            "Publication year": 2003,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/1183136/",
            "Abstract": "In this paper, we describe the architecture of an innovative network processor aiming at the acceleration of packet processing in high speed network interfaces and at the tight coupling of low and high level protocols. The proposed design uses programmable hard-wired components with line rate throughput and is capable of executing protocols and handling efficiently high and low level streaming operations. We discuss the details of the main innovation of the proposed design, which incorporates a three stage RISC-based pipelined module and a composite scheduling unit for internal resource management and outgoing traffic shaping. When both components are integrated on the same platform then maximum and fair utilization of the available resources is achieved. Quantitative performance results are given, both by means of microcode profiling and simulation for indicative applications of the protocol processor.",
            "Abstract entirety": 1,
            "Author pub id": "TKtxe-UAAAAJ:UebtZRa9Y70C",
            "Publisher": "IEEE"
        },
        {
            "Title": "Storage-class memory hierarchies for scale-out servers",
            "Publication year": 2018,
            "Publication url": "https://scholar.google.com/scholar?cluster=17229852683208433812&hl=en&oi=scholarr",
            "Abstract": "With emerging storage-class memory (SCM) nearing commercialization, there is evidence that it will deliver the muchanticipated high density and access latencies within only a few factors of DRAM. Nevertheless, the latency-sensitive nature of in-memory services makes seamless integration of SCM in servers questionable. In this paper, we ask the question of how best to introduce SCM for such servers to help improve overall performance per cost over existing DRAM-only architectures. We first show that even with the best latency projections for SCM, the higher memory access latency results in prohibitive performance degradation. However, we find that deploying a modestly sized high-bandwidth stacked DRAM cache makes SCM-based memory competitive. The high degree of spatial locality in-memory services exhibit not only simplifies the DRAM cache\u2019s design as page-based, but also enables the amortization of increased SCM access latencies and mitigation of SCM\u2019s read/write latency disparity. We finally perform a case study with PCM, and show that a 2 bits/cell technology hits the performance/cost sweet spot, reducing the memory subsystem cost by 40% while keeping performance within 5% of the best performing DRAM-only system, whereas single-level and triple-level cell organizations are impractical for use as memory replacements.",
            "Abstract entirety": 1,
            "Author pub id": "TKtxe-UAAAAJ:dQ2og3OwTAUC",
            "Publisher": "Unknown"
        },
        {
            "Title": "MC-DeF: Creating Customized CGRAs for Dataflow Applications",
            "Publication year": 2021,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/3447970",
            "Abstract": "Executing complex scientific applications on Coarse-Grain Reconfigurable Arrays (CGRAs) promises improvements in execution time and/or energy consumption compared to optimized software implementations or even fully customized hardware solutions. Typical CGRA architectures contain of multiple instances of the same compute module that consist of simple and general hardware units such as ALUs, simple processors. However, generality in the cell contents, while convenient for serving a wide variety of applications, penalizes performance and energy efficiency. To that end, a few proposed CGRAs use custom logic tailored to a particular application\u2019s specific characteristics in the compute module. This approach, while much more efficient, restricts the versatility of the array. To date, versatility at hardware speeds is only supported with Field programmable gate arrays (FPGAs), that are reconfigurable at a \u2026",
            "Abstract entirety": 0,
            "Author pub id": "TKtxe-UAAAAJ:hMsQuOkrut0C",
            "Publisher": "ACM"
        },
        {
            "Title": "The Mondrian Data Engine",
            "Publication year": 2017,
            "Publication url": "https://www.research.ed.ac.uk/files/36213811/ISCA17_Mario_Drumond_1.pdf",
            "Abstract": "The increasing demand for extracting value out of ever-growing data poses an ongoing challenge to system designers, a task only made trickier by the end of Dennard scaling. As the performance density of traditional CPU-centric architectures stagnates, advancing compute capabilities necessitates novel architectural approaches. Near-memory processing (NMP) architectures are reemerging as promising candidates to improve computing efficiency through tight coupling of logic and memory. NMP architectures are especially fitting for data analytics, as they provide immense bandwidth to memory-resident data and dramatically reduce data movement, the main source of energy consumption. Modern data analytics operators are optimized for CPU execution and hence rely on large caches and employ random memory accesses. In the context of NMP, such random accesses result in wasteful DRAM row buffer activations that account for a significant fraction of the total memory access energy. In addition, utilizing NMP\u2019s ample bandwidth with fine-grained random accesses requires complex hardware that cannot be accommodated under NMP\u2019s tight area and power constraints. Our thesis is that efficient NMP calls for an algorithm-hardware co-design that favors algorithms with sequential accesses to enable simple hardware that accesses memory in streams. We introduce an instance of such a co-designed NMP architecture for data analytics, the Mondrian Data Engine. Compared to a CPU-centric and a baseline NMP system, the Mondrian Data Engine improves the performance of basic data analytics operators by up to 49\u00d7 and 5\u00d7, and efficiency \u2026",
            "Abstract entirety": 0,
            "Author pub id": "TKtxe-UAAAAJ:NJ774b8OgUMC",
            "Publisher": "Unknown"
        },
        {
            "Title": "A CGRA definition framework for dataflow applications",
            "Publication year": 2020,
            "Publication url": "https://scholar.google.com/scholar?cluster=6525591165373482884&hl=en&oi=scholarr",
            "Abstract": " Executing complex scientific applications on Coarse Grain Reconfigurable Arrays (CGRAs) promises execution time and/or energy consumption reduction compared to software execution or even customized hardware solutions. The compute core of CGRA architectures is a cell that typically consists of simple and generic hardware units, such as ALUs, simple processors, or even custom logic tailored to an application\u2019s specific characteristics. However generality in the cell contents, while convenient for serving multiple applications, comes at the cost of execution acceleration and energy consumption.This work proposes a novel Mixed-CGRA Definition Framework (MC-DeF) targeting a Mixed-CGRA architecture that leverages the advantages of CGRAs by utilizing a customized cell-array, and FPGAs by utilizing a separate LUT array used for adaptability. Our framework employs a custom cell structure and \u2026",
            "Abstract entirety": 0,
            "Author pub id": "TKtxe-UAAAAJ:uWiczbcajpAC",
            "Publisher": "Springer, Cham"
        },
        {
            "Title": "The DeSyRe runtime support for fault-tolerant embedded MPSoCs",
            "Publication year": 2014,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/6924447/",
            "Abstract": "Semiconductor technology scaling makes chips more sensitive to faults. This paper describes the DeSyRe design approach and its runtime management for future reliable embedded Multiprocessor Systems-on-Chip (MPSoCs). A light weight runtime system is described for shared-memory MPSoCs to support fault-tolerant execution upon detection of transient and permanent faults. The DeSyRe runtime system offers re-execution of tasks that suffer from transient faults and task-migration in cases where a worker processor is permanently faulty. In addition, a faulty worker can potentially remain usable, increasing systems fault-tolerance. This is achieved using alternative task implementations, which avoid the faulty circuit and are indicated in the application-code via pragma annotations, as well as by repairing a faulty core via hardware reconfiguration. Thereby, the system can be dynamically adapted using one or \u2026",
            "Abstract entirety": 0,
            "Author pub id": "TKtxe-UAAAAJ:uWQEDVKXjbEC",
            "Publisher": "IEEE"
        },
        {
            "Title": "The AXIOM platform for next-generation cyber physical systems",
            "Publication year": 2017,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S0141933116304434",
            "Abstract": "Cyber-Physical Systems (CPSs) are widely used in many applications that require interactions between humans and their physical environment. These systems usually integrate a set of hardware-software components for optimal application execution in terms of performance and energy consumption. The AXIOM project (Agile, eXtensible, fast I/O Module), presented in this paper, proposes a hardware-software platform for CPS coupled with an easy parallel programming model and sufficient connectivity so that the performance can scale-up by adding multiple boards. AXIOM supports a task-based programming model based on OmpSs and leverages a high-speed, inexpensive communication interface called AXIOM-Link. The board also tightly couples the CPU with reconfigurable resources to accelerate portions of the applications. As case studies, AXIOM uses smart video surveillance, and smart home living \u2026",
            "Abstract entirety": 0,
            "Author pub id": "TKtxe-UAAAAJ:eMMeJKvmdy0C",
            "Publisher": "Elsevier"
        },
        {
            "Title": "Versatile deployment of FPGA accelerators in disaggregated data centers: A bioinformatics case study",
            "Publication year": 2017,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/8056812/",
            "Abstract": "Important design considerations for the cost-effective employment of hardware accelerators in next-generation data centers involve a) the type of candidate applications that a proposed solution can accelerate (generality), and b) the required development effort to successfully deploy the available accelerators for a given application (adoption overhead). To address the problem of generality, we present a versatile and dynamically reconfigurable hardware architecture that exhibits several accelerator slots and programmable interconnect to create application-specific accelerator datapaths. The proposed architecture fits in the model of disaggregated data centers, where compute, memory, and accelerators are broadly regarded as large pools of resources, and subsets of these resource pools are dynamically allocated on an as-needed basis to cooperatively boost performance of a broad range of applications. Initial \u2026",
            "Abstract entirety": 0,
            "Author pub id": "TKtxe-UAAAAJ:VL0QpB8kHFEC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Embedded systems design with FPGAS",
            "Publication year": 2012,
            "Publication url": "https://books.google.com/books?hl=en&lr=&id=x_-Zsra5IAEC&oi=fnd&pg=PR5&dq=info:cXPpTE856XMJ:scholar.google.com&ots=gYwjAyBz4j&sig=xhQ7BV9yTE1p0_TAEOn8950dDBI",
            "Abstract": "This book presents the methodologies and for embedded systems design, using field programmable gate array (FPGA) devices, for the most modern applications. Coverage includes state-of-the-art research from academia and industry on a wide range of topics, including applications, advanced electronic design automation (EDA), novel system architectures, embedded processors, arithmetic, and dynamic reconfiguration.",
            "Abstract entirety": 1,
            "Author pub id": "TKtxe-UAAAAJ:ldfaerwXgEUC",
            "Publisher": "Springer Science & Business Media"
        },
        {
            "Title": "Slice-processors: an implementation of operation-based prediction",
            "Publication year": 2001,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/377792.377856",
            "Abstract": "We describe the Slice Processor micro-architecture that implements a generalized operation-based prefetching mechanism. Operation-based prefetchers predict the series of operations, or the computation slice that can be used to calculate forthcoming memory references. This is in contrast to outcome-based predictors that exploit regularities in the (address) outcome stream. Slice processors are a generalization of existing operation-based prefetching mechanisms such as stream buffers where the operation itself is fixed in the design (eg, address+ stride). A slice processor dynamically identifies frequently missing loads and extracts on-the-fly the relevant address computation slices. Such slices are then executed in-parallel with the main sequential thread prefetching memory data. We describe the various support structures and emphasize the design of the slice detection mechanism. We demonstrate that a \u2026",
            "Abstract entirety": 0,
            "Author pub id": "TKtxe-UAAAAJ:2osOgNQ5qMEC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Fast, large-scale string match for a 10 gbps fpga-based nids",
            "Publication year": 2005,
            "Publication url": "https://link.springer.com/chapter/10.1007/1-4020-3128-9_16",
            "Abstract": "Intrusion Detection Systems such as Snort scan incoming packets for evidence of security threats. The computation-intensive part of these systems is a text search of packet data against hundreds of patterns, and must be performed at wire-speed. FPGAs are particularly well suited for this task and several such systems have been proposed. In this paper we expand on previous work, in order to achieve and exceed OC192 processing bandwidth (10 Gbps).We employ a scalable architecture, and use extensive fine-grained pipelining to tackle the fan-out, match, and encode bottlenecks and achieve operating frequencies in excess of 340 MHz for fast Virtex devices. To increase throughput, we use multiple comparators and allow for parallel matching of multiple search strings. We evaluate the area and latency cost of our approach and find that the match cost per search pattern character is between 4 and 5 logic \u2026",
            "Abstract entirety": 0,
            "Author pub id": "TKtxe-UAAAAJ:d1gkVwhDpl0C",
            "Publisher": "Springer, Boston, MA"
        },
        {
            "Title": "The DeSyRe project: On-demand system reliability",
            "Publication year": 2012,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/6386909/",
            "Abstract": "The DeSyRe project builds on-demand adaptive and reliable Systems-on-Chips (SoCs). As fabrication technology scales down, chips are becoming less reliable, thereby incurring increased power and performance costs for fault tolerance. To make matters worse, power density is becoming a significant limiting factor in SoC design, in general. In the face of such changes in the technological landscape, current solutions for fault tolerance are expected to introduce excessive overheads in future systems. Moreover, attempting to design and manufacture a totally defect-/fault-free system, would impact heavily, even prohibitively, the design, manufacturing, and testing costs, as well as the system performance and power consumption. In this context, DeSyRe will deliver a new generation of systems that are reliable by design at well-balanced power, performance, and design costs.",
            "Abstract entirety": 1,
            "Author pub id": "TKtxe-UAAAAJ:pqnbT2bcN3wC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Efficient runtime support for embedded MPSoCs",
            "Publication year": 2013,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/6621119/",
            "Abstract": "Recently, many software runtime systems have been proposed that allow developers to efficiently map applications to contemporary consumer electronic devices and high-performance academic processing platforms. Most of these runtime systems employ advanced scheduling techniques for automatic task assignment to all available processing elements. However, they focus on a particular environment and architecture, and it is not easy to port them to reconfigurable embedded MPSoCs. As a consequence, in the embedded community, researchers implement hardwired application-specific task schedulers, which can not be used by other embedded MPSoCs. To address this problem, in this paper we propose a lightweight runtime software framework for reconfigurable shared-memory MPSoCs, that integrate a master embedded processor connected to slave cores. Similarly to many of the aforementioned \u2026",
            "Abstract entirety": 0,
            "Author pub id": "TKtxe-UAAAAJ:bFI3QPDXJZMC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Effective reconfigurable design: The FASTER approach",
            "Publication year": 2014,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-319-05960-0_35",
            "Abstract": "While fine-grain, reconfigurable devices have been available for years, they are mostly used in a fixed functionality, \u201casic-replacement\u201d manner. To exploit opportunities for flexible and adaptable run-time exploitation of fine grain reconfigurable resources (as implemented currently in dynamic, partial reconfiguration), better tool support is needed. The FASTER project aims to provide a methodology and a tool-chain that will enable designers to efficiently implement a reconfigurable system on a platform combining software and reconfigurable resources. Starting from a high-level application description and a target platform, our tools analyse the application, evaluate reconfiguration options, and implement the designer choices on underlying vendor tools. In addition, FASTER addresses micro-reconfiguration, verification, and the run-time management of system resources. We use industrial applications to \u2026",
            "Abstract entirety": 0,
            "Author pub id": "TKtxe-UAAAAJ:P5F9QuxV20EC",
            "Publisher": "Springer, Cham"
        },
        {
            "Title": "Embedded Computer Systems: Architectures, Modeling, and Simulation: 19th International Conference, SAMOS 2019, Samos, Greece, July 7\u201311, 2019, Proceedings",
            "Publication year": 2019,
            "Publication url": "https://books.google.com/books?hl=en&lr=&id=tkuoDwAAQBAJ&oi=fnd&pg=PR6&dq=info:RAi2gX6xiA4J:scholar.google.com&ots=twnxuCGB7X&sig=lJOLVQmg42TUtK6XpD7TH24E-Mg",
            "Abstract": "This book constitutes the refereed proceedings of the 19th International Conference on Embedded Computer Systems: Architectures, Modeling, and Simulation, SAMOS 2019, held in Pythagorion, Samos, Greece, in July 2019. The 21 regular papers presented were carefully reviewed and selected from 55 submissions. The papers are organized in topical sections on system design space exploration; deep learning optimization; system security; multi/many-core scheduling; system energy and heat management; many-core communication; and electronic system-level design and verification. In addition there are 13 papers from three special sessions which were organized on topics of current interest: insights from negative results; machine learning implementations; and European projects.",
            "Abstract entirety": 1,
            "Author pub id": "TKtxe-UAAAAJ:yB1At4FlUx8C",
            "Publisher": "Springer"
        },
        {
            "Title": "Hardware-assisted dynamic power and thermal management in multi-core SoCs",
            "Publication year": 2011,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/1973009.1973033",
            "Abstract": "The use of efficient and dynamic power dissipation management mechanisms is crucial in upcoming, complex and dynamic multi-core Systems-on-Chip. In such systems, static approaches are inadequate to capture the dynamic system behavior, while at the same time, their complexity makes the use of extensive, accurate simulation-based power estimation computationally difficult or prohibitive. This paper proposes dynamically programmable hardware monitors with insignificant cost in silicon area, easily integrated with multi-core Systems-on-Chip, which act non-intrusively in support of real-time identification of tasks' behavior and adaptive management of varying workload. We extract instruction and data activity metrics in order to estimate applications power phase in less than 10 clock cycles. Using\" binary\" on/off accelerators in conjuction with a distributed algorithm for workload throttling fast and efficient power \u2026",
            "Abstract entirety": 0,
            "Author pub id": "TKtxe-UAAAAJ:mB3voiENLucC",
            "Publisher": "Unknown"
        },
        {
            "Title": "A run-time Configurable Cache/Scratchpad Memory with Virtualized User-Level RDMA Capability",
            "Publication year": 2008,
            "Publication url": "https://139.91.152.92/carv/ipc/cache_scrpd_rdma_forth_hipeacIW08_sld_v0812.pdf",
            "Abstract": "A Run-time Configurable Cache/Scratchpad Memory with Virtualized User-Level RDMA Capability \nPage 1 A Run-time Configurable Cache/Scratchpad Memory with Virtualized User-Level RDMA \nCapability G. Nikiforos, G. Kalokerinos, V. Papaefstathiou, S. Kavadias, D. Pnevmatikatos and \nM. Katevenis FORTH-ICS - SARC project 6th HiPEAC Industrial Workshop November 26, \n2008 Paris FORTH Page 2 6th HiPEAC Industrial Workshop - Nov.08 - FORTH 2 Memory \nHierarchies and Locality Management \u2022 Multilevel Coherent Caches: + easy programming: \n\u201clet the data adaptively find their way\u201d \u2013 poor scalability to large number of cores \u2013 difficult to \noptimize or achieve deterministic performance, in the cases where application has knowledge \nabout locality \u2022 Scratchpads with DMA capabilities: + allow optimizations and predictable \nperformance \u21e8 scalable \u2013 hard to program \u2022 Merged: get the best of both worlds \u2026 Page - \u2026",
            "Abstract entirety": 0,
            "Author pub id": "TKtxe-UAAAAJ:ZHo1McVdvXMC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Towards supporting Fault-Tolerance in FPGAs",
            "Publication year": 2010,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/5572836/",
            "Abstract": "This paper proposes a novel methodology for improving reliability of FPGAs without requiring special purpose hardware. In contrast to related approaches that are applied uniformly over the target architecture, the proposed one insert redundancy only the critical for failure resources. Such an approach leads to reasonable performance improvement.",
            "Abstract entirety": 1,
            "Author pub id": "TKtxe-UAAAAJ:_Qo2XoVZTnwC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Design and implementation of a multigigabit nic and a scalable buffered crossbar switch",
            "Publication year": 2006,
            "Publication url": "http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.207.8459",
            "Abstract": "High speed interconnection networks are a fundamental component of next-generation, scalable compute and storage systems. Although already a popular area of research, new application requirements and technology constraints impose new restrictions and present new opportunities for the design and implementation of interconnection networks. These include the need to exceed 10 GBit/s speeds, to further reduce host-related overheads, to support applications in a transparent manner, and to allow system scalability to large numbers of nodes. This work presents the design and implementation of a multi-gigabit NIC and a scalable buffered crossbar switch that are currently used for research work in the area. The purpose of this work is to provide a detailed description of the architecture and its current implementation. We first provide an overview of the design, then we examine the prototyping infrastructure used, and finally we present the detailed NIC and switch implementation. Finally, we present the tests used for validating our implementation and we provide early performance results.",
            "Abstract entirety": 1,
            "Author pub id": "TKtxe-UAAAAJ:4TOpqqG69KYC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Hardware implementation of 2-opt local search algorithm for the traveling salesman problem",
            "Publication year": 2007,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/4228483/",
            "Abstract": "In this paper we discuss how one of the most famous local optimization algorithms for the Traveling Salesman Problem, the 2-Opt, can be efficiently implemented in hardware for Euclidean TSP instances up to a few hundred cities. We introduce the notion of \"symmetrical 2-Opt moves\" which allows us to uncover fine-grain parallelism when executing the specified algorithm. We propose a novel architecture that exploits this parallelism. A subset of the TSPLIB benchmark is used to evaluate the proposed architecture and its ASIC implementation, which exhibits better final results and an average speedup of 20 when compared with the state-of-the-art software implementation. Our approach produces, to the best of our knowledge, the fastest to date TSP 2-Opt solver for small-scale Euclidean TSP instances.",
            "Abstract entirety": 1,
            "Author pub id": "TKtxe-UAAAAJ:Zph67rFs4hoC",
            "Publisher": "IEEE"
        },
        {
            "Title": "An FPGA-based high-throughput stream join architecture",
            "Publication year": 2016,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/7577354/",
            "Abstract": "Stream join is a fundamental operation that combines information from different high-speed and high-volume data streams. This paper presents an FPGA-based architecture that maps the most performance-efficient stream join algorithm, i.e. ScaleJoin, to reconfigurable logic. The system was fully implemented on a Convey HC-2ex hybrid computer and the experimental performance evaluation shows that the proposed system outperforms by up to one order of magnitude the corresponding fully optimized parallel software-based solution running on a high-end 48-core multiprocessor platform. The proposed architecture can be used as a generic template for mapping stream processing algorithms to reconfigurable logic, taking into consideration real-world challenges.",
            "Abstract entirety": 1,
            "Author pub id": "TKtxe-UAAAAJ:V3AGJWp-ZtQC",
            "Publisher": "IEEE"
        },
        {
            "Title": "ReFiRe: efficient deployment of Remote Fine-grained Reconfigurable accelerators",
            "Publication year": 2018,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/8742297/",
            "Abstract": "The need for specialized hardware acceleration in today's computing platforms is well established, due to power and efficiency reasons. Broadening an accelerator's scope of application is highly desirable, but requires a finer-grained architecture with basic primitives, which inevitably exhibits increased communication and synchronization requirements. In disaggregated-computing environ-ments, where data transfers between remote nodes are realized via datacenter-wide packet exchanges, reducing communication and synchronization is a prerequisite for the effective employment of remote acceleration. To this end, we present ReFiRe (Remote Fine-grained Reconfigurable acceleration), a generic deployment framework with native support for partial reconfiguration that allows to considerably reduce communication needs between a processor and remote accelerators. This is achieved by shifting control flow \u2026",
            "Abstract entirety": 0,
            "Author pub id": "TKtxe-UAAAAJ:9Nmd_mFXekcC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Faster: facilitating analysis and synthesis technologies for effective reconfiguration",
            "Publication year": 2015,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S0141933114001409",
            "Abstract": "The FASTER (Facilitating Analysis and Synthesis Technologies for Effective Reconfiguration) EU FP7 project, aims to ease the design and implementation of dynamically changing hardware systems. Our motivation stems from the promise reconfigurable systems hold for achieving high performance and extending product functionality and lifetime via the addition of new features that operate at hardware speed. However, designing a changing hardware system is both challenging and time-consuming.FASTER facilitates the use of reconfigurable technology by providing a complete methodology enabling designers to easily specify, analyze, implement and verify applications on platforms with general-purpose processors and acceleration modules implemented in the latest reconfigurable technology. Our tool-chain supports both coarse- and fine-grain FPGA reconfiguration, while during execution a flexible run-time \u2026",
            "Abstract entirety": 0,
            "Author pub id": "TKtxe-UAAAAJ:HoB7MX3m0LUC",
            "Publisher": "Elsevier"
        },
        {
            "Title": "Design space exploration of reconfigurable systems for calculating flying object's optimal noise reduction paths",
            "Publication year": 2009,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/5272288/",
            "Abstract": "Despite improved aerodynamic designs that decrease sound emission, the noise produced by flying objects is a problem because it propagates in large distances in the atmosphere. However, it is possible to describe sound propagation effectively with a parabolic differential equation and determine a path that minimizes noise emissions taking into consideration atmospheric and geographic data. This approach calculates noise propagation progressively in the propagation direction and gives accurate results even for large distances. This paper presents a reconfigurable system that solves the tridiagonal problem that results from the Crank-Nicolson function of the 2 nd  order parabolic equation. Generally tridiagonal algorithms do not allow parallelism in every level, and complicate parallel and/or reconfigurable hardware implementations. We show that reconfigurable hardware technology allows the fast and \u2026",
            "Abstract entirety": 0,
            "Author pub id": "TKtxe-UAAAAJ:r0BpntZqJG4C",
            "Publisher": "IEEE"
        },
        {
            "Title": "The AXIOM project: IoT on heterogeneous embedded platforms",
            "Publication year": 2019,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/8894849/",
            "Abstract": "The AXIOM project aims at providing an environment for Cyber-Physical Systems. Smart Video Surveillance targets public environments, involving real-time face detection in crowds. Smart Home Living targets home environments and access control. These applications are used as experimental usecases for the AXIOM platform, currently based on the Xilinx Zynq-7000 SoCs. We have integrated the Xilinx Vivado HLS tool for the FPGA support within the OmpSs programming model, to enable OpenMP-like programming in the FPGA. This paper presents the programming environment, and the evaluation of the most computationally expensive parts of the target applications.",
            "Abstract entirety": 1,
            "Author pub id": "TKtxe-UAAAAJ:ipzZ9siozwsC",
            "Publisher": "IEEE"
        },
        {
            "Title": "REMAP: Remote mEmory Manager for disAggregated Platforms",
            "Publication year": 2018,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/8445095/",
            "Abstract": "Disaggregated computing is a new approach that promises to alleviate the problem of fixed resource proportionality in datacenter deployments. Two critical factors that affect the overall performance of disaggregated platforms are remote memory access latency and throughput. Previous works primarily expose remote data processing at the applcation level that (a) require code annotations and/or the use of custom user-level libraries, and (b) may hinder the overall system protection and functionality. In this paper, we are taking a different approach: we propose the Remote mEmory Manager for dis-Aggregated Platforms (REMAP), a hardware architecture that enables the hotplug of remote memory resources to processing nodes, as normal paged memory at the OS-level, without requiring application-level code modifications. REMAP tightly couples processing nodes with remote memory controllers. Our architecture \u2026",
            "Abstract entirety": 0,
            "Author pub id": "TKtxe-UAAAAJ:_Re3VWB3Y0AC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Rack-scale disaggregated cloud data centers: The dReDBox project vision",
            "Publication year": 2016,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/7459397/",
            "Abstract": "For quite some time now, computing systems servers, whether low-power or high-end ones designs are created around a common design principle: the main-board and its hardware components form a baseline, monolithic building block that the rest of the hardware/software stack design builds upon. This proportionality of compute/memory/network/storage resources is fixed during design time and remains static throughout machine lifetime, with known ramifications in terms of low system resource utilization, costly upgrade cycles and degraded energy proportionality. dReDBox takes on the challenge of revolutionizing the low-power computing market by breaking server boundaries through materialization of the concept of disaggregation. Besides proposing a highly modular software-defined architecture for the next generation datacentre, dRedBox will specify, design and prototype a novel hardware architecture \u2026",
            "Abstract entirety": 0,
            "Author pub id": "TKtxe-UAAAAJ:LPZeul_q3PIC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Formic: Cost-efficient and scalable prototyping of manycore architectures",
            "Publication year": 2012,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/6239792/",
            "Abstract": "Modeling emerging multicore architectures is challenging and imposes a tradeoff between simulation speed and accuracy. An effective practice that balances both targets well is to map the target architecture on FPGA platforms. We find that accurate prototyping of hundreds of cores on existing FPGA boards faces at least one of the following problems: (i) limited fast memory resources (SRAM) to model caches, (ii) insufficient inter-board connectivity for scaling the design or (iii) the board is too expensive. We address these shortcomings by designing a new FPGA board for multicore architecture prototyping, which explicitly targets scalability and cost-efficiency. Formic has a 35% bigger FPGA, three times more SRAM, four times more links and costs at most half as much when compared to the popular Xilinx XUPV5 prototyping platform. We build and test a 64-board system by developing a 512-core, Micro Blaze-based \u2026",
            "Abstract entirety": 0,
            "Author pub id": "TKtxe-UAAAAJ:RGFaLdJalmkC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Run-time management of systems with partially reconfigurable FPGAs",
            "Publication year": 2017,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S0167926016301560",
            "Abstract": "Partial reconfiguration (PR) of FPGAs can be used to dynamically extend and adapt the functionality of computing systems by swapping in and out HW tasks. To coordinate the on-demand task execution, we propose and implement a Run-Time System Manager (RTSM) for scheduling software (SW) tasks on available processor(s) and hardware (HW) tasks on any number of reconfigurable regions (RRs) of a partially reconfigurable FPGA. Fed with the initial partitioning of the application into tasks, the corresponding task graph, and the available task mappings, the RTSM controls system operation considering the status of each task and region (e.g. busy, idle, scheduled for reconfiguration/execution, etc). Our RTSM supports task reuse and configuration prefetching to minimize reconfigurations, task movement among regions to efficiently manage the FPGA area, and region reservation for future reconfiguration and \u2026",
            "Abstract entirety": 0,
            "Author pub id": "TKtxe-UAAAAJ:J-pR_7NvFogC",
            "Publisher": "Elsevier"
        },
        {
            "Title": "Architecture and application of plato, a reconfigurable active network platform",
            "Publication year": 2001,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/1420906/",
            "Abstract": "A new, configurable architecture has been designed and built in order to serve as a platform for experimentation with active networks. This architecture, named PLATO, provides 4 physical bi-directional connections for ATM networks, large reconfigurable resources, 256 Mbytes SDRAM for buffer space, a PCI port, and auxiliary expansion ports. Several applications are presented for this platform, one of which has been prototyped on the PCI Pamette and on PLATO. Detailed simulations and experimental results show that, for some applications, a significant improvement can be obtained using this approach as compared to using conventional network architectures.",
            "Abstract entirety": 1,
            "Author pub id": "TKtxe-UAAAAJ:ufrVoPGSRksC",
            "Publisher": "IEEE"
        },
        {
            "Title": "An Evaluation of FPGA-based IDS Pattern Matching Techniques",
            "Publication year": 2005,
            "Publication url": "https://www.researchgate.net/profile/Dionisios-Pnevmatikatos/publication/228786496_An_Evaluation_of_FPGA-based_IDS_Pattern_Matching_Techniques/links/00b7d52b35c325da05000000/An-Evaluation-of-FPGA-based-IDS-Pattern-Matching-Techniques.pdf",
            "Abstract": "Pattern matching is one of the most computationally intensive tasks in network security systems. Numerous pattern matching approaches have been proposed in the past. The most common ones use: regular expressions, discrete comparators or CAM, Pre-decoding, and Hashing to match patterns. The researchers\u2019 first concern was to achieve high operating throughput in order to process incoming packets in wire rates. Since the set of matching patterns increases rapidly, though, pattern matching designers started considering also the area cost of their designs. In this paper, we attempt an evaluation of FPGA-based pattern matching techniques for network security systems. We measure the efficiency of pattern matching modules in terms of obtained performance per area cost.",
            "Abstract entirety": 1,
            "Author pub id": "TKtxe-UAAAAJ:9ZlFYXVOiuMC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Efficient Field Processing Cores in an Innovative Protocol Processo System-on-Chip",
            "Publication year": 2003,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/1186665/",
            "Abstract": "We present an innovative protocol processor component that combines wire-speed processing for low-level, and best effort processing for higher-level protocols. The component is a System-on-Chip that integrates variable size packet buffering, specialised cores for header and field processing, generic RISC cores and scheduling blocks. We focus on the main innovation, the reprogrammable pipeline module, and discuss its internal architecture, optimised to perform field processing on byte streams, as well as protocol processing on complex data structures. Furthermore, we present how modern and new tools were used in system dimensioning, design, and verification phases. The chip is able to handle up to 512K flows organised in individual queues. It embeds 5 custom cores optimised for field processing, 3 typical RISC cores for packet processing and 11 generic and application specific hardware blocks. It's \u2026",
            "Abstract entirety": 0,
            "Author pub id": "TKtxe-UAAAAJ:qxL8FJ1GzNcC",
            "Publisher": "IEEE Computer Society"
        },
        {
            "Title": "DeSyRe: On-demand adaptive and reconfigurable fault-tolerant SoCs",
            "Publication year": 2014,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-319-05960-0_34",
            "Abstract": "The DeSyRe project builds on-demand adaptive, reliable Systems-on-Chips. In response to the current semiconductor technology trends thatmake chips becoming less reliable, DeSyRe describes a newgeneration of by design reliable systems, at a reduced power and performance cost. This is achieved through the following main contributions. DeSyRe defines a fault-tolerant system architecture built out of unreliable components, rather than aiming at totally fault-free and hence more costly chips. In addition, DeSyRe systems are on-demand adaptive to various types and densities of faults, as well as to other system constraints and application requirements. For leveraging on-demand adaptation/customization and reliability at reduced cost, a new dynamically reconfigurable substrate is designed and combined with runtime system software support. The above define a generic and repeatable design \u2026",
            "Abstract entirety": 0,
            "Author pub id": "TKtxe-UAAAAJ:1sJd4Hv_s6UC",
            "Publisher": "Springer, Cham"
        },
        {
            "Title": "FASTER run-time reconfiguration management",
            "Publication year": 2013,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/2464996.2467283",
            "Abstract": "The FASTER project Run-Time System Manager offloads programmers from low-level operations by performing task placement, scheduling, and dynamic FPGA reconfiguration. It also manages device fragmentation, configuration caching, pre-fetching and reuse, bitstream compression, and optimizes the system thermal and power footprints. We propose a micro-reconfiguration aware, configuration content agnostic ISA interface and a technology independent Task Configuration Microcode format targeting Maxeler Data Flow computers and Xilinx XUPV5 platforms. We achieve improved resource utilization with negligible performance overhead. Up to 4Gbps for DMA transfers, and up to 3Gbps for FPGA reconfiguration on Xilinx Virtex-5/6 devices is achieved.",
            "Abstract entirety": 1,
            "Author pub id": "TKtxe-UAAAAJ:cFHS6HbyZ2cC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Near-memory Acceleration for Scalable Phylogenetic Inference",
            "Publication year": 2020,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/3373087.3375364",
            "Abstract": "Phylogenetics study the evolutionary history of a collection of organisms based on observed heritable molecular traits, finding practical application in a wide range of domains, from conservation biology and epidemiology, to forensics and drug development. A fundamental computational kernel to evaluate evolutionary histories, also referred to as phylogenies, is the Phylogenetic Likelihood Function (PLF), which dominates the total execution time (by up to 95%) of widely used maximum-likelihood phylogenetic methods. Numerous efforts to boost PLF performance over the years mostly focused on accelerating computation; since the PLF is a data-intensive, memory-bound operation, performance remains limited by data movement. In this work, we employ near-memory computation units (NMUs) within a FPGA-based computing environment with disaggregated memory to alleviate the data movement problem and \u2026",
            "Abstract entirety": 0,
            "Author pub id": "TKtxe-UAAAAJ:vDijr-p_gm4C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Performance landscape of resource-constrained platforms targeting DNNs",
            "Publication year": 2021,
            "Publication url": "https://arxiv.org/abs/2107.10047",
            "Abstract": "Over the recent years, a significant number of complex, deep neural networks have been developed for a variety of applications including speech and face recognition, computer vision in the areas of health-care, automatic translation, image classification, etc. Moreover, there is an increasing demand in deploying these networks in resource-constrained edge devices. As the computational demands of these models keep increasing, pushing to their limits the targeted devices, the constant development of new hardware systems tailored to those workloads has been observed. Since programmability of these diverse and complex platforms -- compounded by the rapid development of new DNN models -- is a major challenge, platform vendors have developed Machine Learning tailored SDKs to maximize the platform's performance. This work investigates the performance achieved on a number of modern commodity embedded platforms coupled with the vendors' provided software support when state-of-the-art DNN models from image classification, object detection and image segmentation are targeted. The work quantifies the relative latency gains of the particular embedded platforms and provides insights on the relationship between the required minimum batch size for achieving maximum throughput, concluding that modern embedded systems reach their maximum performance even for modest batch sizes when a modern state of the art DNN model is targeted. Overall, the presented results provide a guide for the expected performance for a number of state-of-the-art DNNs on popular embedded platforms across the image classification, detection \u2026",
            "Abstract entirety": 0,
            "Author pub id": "TKtxe-UAAAAJ:KUbvn5osdkgC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Novel design methods and a tool flow for unleashing dynamic reconfiguration",
            "Publication year": 2012,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/6417320/",
            "Abstract": "During the last few years, there is an increasing interest in mixing software and hardware to serve efficiently different applications. This is due to the heterogeneity characterizing the tasks of an application which require the presence of resources from both worlds, software and hardware. Controlling effectively these resources through an integrated tool flow is a challenging problem and towards this direction only a few efforts exist. In fact, a framework that seamlessly exploits both resources of a platform for executing efficiently an application has not yet come into existence. Moreover, reconfigurable computing often incorporated in such platforms due to its high flexibility and customization, has not yet taken off due to the lack of exploiting its full capabilities. Thus, the capability of reconfigurable devices such as Field Programmable Gate Arrays (FPGAs) to be dynamically reconfigured, i.e. reprogramming part of the chip \u2026",
            "Abstract entirety": 0,
            "Author pub id": "TKtxe-UAAAAJ:SeFeTyx0c_EC",
            "Publisher": "IEEE"
        },
        {
            "Title": "On interconnecting and orchestrating components in disaggregated data centers: The dReDBox project vision",
            "Publication year": 2016,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/7561039/",
            "Abstract": "Computing systems servers -low- or high-end ones have been traditionally designed and built using a main-board and its hardware components as a \u201chard\u201d monolithic building block; this formed the base unit on which the system hardware and software stack design build upon. This hard deployment and management border on compute, memory, network and storage resources is either fixed or quite limited in expandability during design time and in practice remains so throughout machine lifetime as subsystem upgrades are seldomely employed. The impact of this rigidity has well known ramifications in terms of lower system resource utilization, costly upgrade cycles and degraded energy proportionality. In the dReDBox project we take on the challenge of breaking the server boundaries through materialization of the concept of disaggregation. The basic idea of the dReDBox architecture is to use a core of high \u2026",
            "Abstract entirety": 0,
            "Author pub id": "TKtxe-UAAAAJ:q3oQSFYPqjQC",
            "Publisher": "IEEE"
        },
        {
            "Title": "D7. 1: Project Handbook",
            "Publication year": 2011,
            "Publication url": "https://scholar.google.com/scholar?cluster=704790337609256715&hl=en&oi=scholarr",
            "Abstract": "This document describes the general management procedures of the FASTER project, including quality assurance and risk analysis. It includes information about all workpackages, responsibilities and consortium agreement information, risks and contingency plans.",
            "Abstract entirety": 1,
            "Author pub id": "TKtxe-UAAAAJ:XiSMed-E-HIC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Hardware Support for Explicit Communication in Scalable CMP\u2019s",
            "Publication year": 2008,
            "Publication url": "https://www.academia.edu/download/55865411/LMnDMAvsCnPP_2008jul.pdf",
            "Abstract": "Programming models with explicit communication between parallel tasks allow the runtime system to schedule task execution and data transfers ahead of time. Explicit communication is not limited to message passing and streaming applications: recent proposals in parallel programming allow such explicit communication in other task-based scenarios too. Scheduling of data transfers allows the overlap of computation and communication, and latency hiding, and locality optimization, using programmable data transfer engines, such as prefetchers or DMA controllers.In this paper, we present a qualitative analysis by comparing explicit communication scenarios in two different shared memory CMP architectures. The baseline architecture uses caches, a directory-based coherence protocol, and programmable prefetchers for scheduled data transfers. The target architecture uses on-chip local memories that are globally accessible with regular load/store instructions, and programmable DMA controllers for scheduled data transfers. The local memories architecture scales better, because it does not require a coherence protocol. Our analysis shows that the use of on-chip local memories, and remoteread/remote-write operations reduces access latency to critical data, network traffic, and energy consumption.",
            "Abstract entirety": 1,
            "Author pub id": "TKtxe-UAAAAJ:hC7cP41nSMkC",
            "Publisher": "Unknown"
        },
        {
            "Title": "dReDBox: Materializing a full-stack rack-scale system prototype of a next-generation disaggregated datacenter",
            "Publication year": 2018,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/8342174/",
            "Abstract": "Current datacenters are based on server machines, whose mainboard and hardware components form the baseline, monolithic building block that the rest of the system software, middleware and application stack are built upon. This leads to the following limitations: (a) resource proportionality of a multi-tray system is bounded by the basic building block (mainboard), (b) resource allocation to processes or virtual machines (VMs) is bounded by the available resources within the boundary of the mainboard, leading to spare resource fragmentation and inefficiencies, and (c) upgrades must be applied to each and every server even when only a specific component needs to be upgraded. The dRedBox project (Disaggregated Recursive Datacentre-in-a-Box) addresses the above limitations, and proposes the next generation, low-power, across form-factor datacenters, departing from the paradigm of the mainboard-as-a \u2026",
            "Abstract entirety": 0,
            "Author pub id": "TKtxe-UAAAAJ:Fu2w8maKXqMC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Less is more: Increasing the scope of hardware debugging with compression",
            "Publication year": 2017,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/8259958/",
            "Abstract": "In this work we consider the slow and tedious phase of hardware debugging in FPGAs. The process of hardware debugging is normally done via Internal Logic Analyzer (ILA) circuits, which add user observability in internal FPGA signals. The user first defines the target for debugging signal and a triggering condition. Then the ILA stores traces of it in trace buffers, these traces are finally transferred to a host PC for the user to observe. The user also has to consider the limited FPGA memory resources, which result in small-sized trace buffers, an important restriction of hardware debugging. In this paper, we attempt to increase the scope of hardware tracing, i.e. the number of samples written on the trace buffers, with the use of compression. We use the LZW algorithm and find that we can increase the debugging signals number of recorded samples by 90%, i.e. have double the amount of useful data with the same \u2026",
            "Abstract entirety": 0,
            "Author pub id": "TKtxe-UAAAAJ:UHK10RUVsp4C",
            "Publisher": "IEEE"
        },
        {
            "Title": "Design and performance evaluation of a Programmable Packet Processing Engine (PPE) suitable for high-speed network processors units",
            "Publication year": 2007,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S0141933106001293",
            "Abstract": "In this paper, we present a Programmable Packet Processing Engine suitable for deep header processing in high-speed networking systems. The engine, which has been \u2013 fabricated as part of a complete network processor, consists of a typical RISC-CPU, whose register file has been modified in order to support efficient context switching, and two simple special-purpose processing units. The engine can be used in a number of network processing units (NPUs), as an alternative to the typical design practice of employing a large number of simple general purpose processors, or in any other embedded system designed to process mainly network protocols. To assess the performance of the engine, we have profiled typical networking applications and a series of experiments were carried out. Further, we have compared the performance of our processing engine to that of two widely used NPUs and show that our \u2026",
            "Abstract entirety": 0,
            "Author pub id": "TKtxe-UAAAAJ:KlAtU1dfN6UC",
            "Publisher": "Elsevier"
        },
        {
            "Title": "Fault-Free: A Framework for Supporting Fault Tolerance in FPGAs",
            "Publication year": 2010,
            "Publication url": "http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.298.7259&rep=rep1&type=pdf#page=25",
            "Abstract": "In this paper we propose a novel methodology for supporting application mapping onto FPGAs with fault tolerance even if this feature is not supported by the target platform. For the purposes of this paper we incorporate three techniques for error correction. The introduced fault tolerance can be implemented either as a hardware modification, or through annotating the application\u2019s HDL. Also, we show that the existing approaches for fault tolerance result to hardware wastage, since there is no demand for applied them uniformly over the whole FPGA. Experimental results show the efficiency of the proposed framework in terms of error correction, with acceptable penalties in device area and Energy\u00d7 Delay Product (EDP) due to the redundant hardware resources.",
            "Abstract entirety": 1,
            "Author pub id": "TKtxe-UAAAAJ:hMod-77fHWUC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Demonstration of NFV for Mobile Edge Computing on an Optically Disaggregated Datacentre in a Box",
            "Publication year": 2018,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/8385960/",
            "Abstract": "This demonstrator showcases the hardware and software integration achieved by the dReDBox project [1] towards realization of a novel architecture using dynamically-reconfigurable optical interconnects to create a flexible, scalable and efficient disaggregated datacentre infrastructure.",
            "Abstract entirety": 1,
            "Author pub id": "TKtxe-UAAAAJ:uLbwQdceFCQC",
            "Publisher": "IEEE"
        },
        {
            "Title": "MCF-SMF Hybrid Low-Latency Circuit-Switched Optical Network for Disaggregated Data Centers",
            "Publication year": 2019,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/8727973/",
            "Abstract": "This paper proposes and experimentally evaluates a fully developed novel architecture with purpose built low latency communication protocols for next generation disaggregated data centers (DDCs). In order to accommodate for capacity and latency needs of disaggregated IT elements (i.e., CPU, memory), this architecture makes use of a low latency and high-capacity circuit-switched optical network for interconnecting various end points that are equipped with multi-channel silicon photonic based integrated transceivers. In a move to further decrease the perceived latency between various disaggregated IT elements, this paper proposes a novel network topology that cuts down the latency over the optical network by 34% while enhancing system scalability and channel bonding over multi-core fiber (MCF) switched links to reduce head to tail latency and in turn increase sustained memory bandwidth for \u2026",
            "Abstract entirety": 0,
            "Author pub id": "TKtxe-UAAAAJ:XD-gHx7UXLsC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Development of a Network Processor in Reconfigurable Logic (FPGA)",
            "Publication year": 2009,
            "Publication url": "http://artemis.library.tuc.gr/DT2009-0259/DT2009-0259.pdf",
            "Abstract": "Network Processors play a major role in computer network infrastructure and especially in the Internet, since they are embedded in many kinds of devices critical to the correct operation of these networks, such as routers, switches, firewalls etc. By being implemented in such devices, they are responsible for much of the workload these devices have to deal with. The purpose of this diploma thesis was to develop and implement a Network Processor in Reconfigurable Logic, supporting a specific instruction set, capable of handling some of the tasks Network Processors deal with under normal circumstances. It is capable of operating in 10, 100 and 1000 Mbit/s Ethernet speeds. The design was implemented in an advanced FPGA board.",
            "Abstract entirety": 1,
            "Author pub id": "TKtxe-UAAAAJ:CHSYGLWDkRkC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Accelerated inference of positive selection on whole genomes",
            "Publication year": 2018,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/8533493/",
            "Abstract": "Positive selection is the tendency of beneficial traits to increase in prevalence in a population. Its detection carries theoretical significance and has practical applications, from shedding light on the forces that drive adaptive evolution to identifying drug-resistant mutations in pathogens. With next-generation sequencing producing a plethora of genomic data for population genetic analyses, the increased computational complexity of existing methods and/or inefficient memory management hinders the efficient analysis of large-scale datasets. To this end, we devise a system-level solution that couples a generic out-of-core algorithm for parsing genomic data with a decoupled access/execute accelerator architecture, thereby providing a method-independent infrastructure for the rapid and scalable inference of positive selection. We employ a novel detection mechanism that mostly relies on integer arithmetic operations \u2026",
            "Abstract entirety": 0,
            "Author pub id": "TKtxe-UAAAAJ:2KloaMYe4IUC",
            "Publisher": "IEEE"
        },
        {
            "Title": "A survey and taxonomy of on-chip monitoring of multicore systems-on-chip",
            "Publication year": 2013,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/2442087.2442088",
            "Abstract": "Billion transistor systems-on-chip increasingly require dynamic management of their hardware components and careful coordination of the tasks that they carry out. Diverse real-time monitoring functions assist towards this objective through the collection of important system metrics, such as throughput of processing elements, communication latency, or resource utilization for each application. The online evaluation of these metrics can result in localized or global decisions that attempt to improve aspects of system behavior, system performance, quality-of-service, power and thermal effects under nominal conditions. This work provides a comprehensive categorization of monitoring approaches used in multiprocessor SoCs. As adaptive systems are encountered in many disciplines, it is imperative to present the prominent research efforts in developing online monitoring methods. To this end we offer a taxonomy that \u2026",
            "Abstract entirety": 0,
            "Author pub id": "TKtxe-UAAAAJ:dfsIfKJdRG4C",
            "Publisher": "ACM"
        },
        {
            "Title": "FPGA prototyping of emerging manycore architectures for parallel programming research using Formic boards",
            "Publication year": 2014,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S138376211400054X",
            "Abstract": "Performance evaluation of parallel software and architectural exploration of innovative hardware support face a common challenge with emerging manycore platforms: they are limited by the slow running time and the low accuracy of software simulators. Manycore FPGA prototypes are difficult to build, but they offer great rewards. Software running on such prototypes runs orders of magnitude faster than current simulators. Moreover, researchers gain significant architectural insight during the modeling process. We use the Formic FPGA prototyping board [1], which specifically targets scalable and cost-efficient multi-board prototyping, to build and test a 64-board model of a 512-core, MicroBlaze-based, non-coherent hardware prototype with a full network-on-chip in a 3D-mesh topology. We expand the hardware architecture to include the ARM Versatile Express platforms and build a 520-core heterogeneous prototype \u2026",
            "Abstract entirety": 0,
            "Author pub id": "TKtxe-UAAAAJ:nb7KW1ujOQ8C",
            "Publisher": "North-Holland"
        },
        {
            "Title": "An fpga-based prototyping platform for research in high-speed interprocessor communication",
            "Publication year": 2006,
            "Publication url": "https://www.researchgate.net/profile/Stamatis-Kavvadias/publication/228581075_An_FPGA-based_Prototyping_Platform_for_Research_in_High-Speed_Interprocessor_Communication/links/02e7e51dcc5c01f09a000000/An-FPGA-based-Prototyping-Platform-for-Research-in-High-Speed-Interprocessor-Communication.pdf",
            "Abstract": "Parallel and multinode computing systems are becoming widespread and grow in sophistication. Besides simulation, rapid prototyping becomes important in designing and evaluating their architecture. We present an FPGA-based system that we developed and use for prototyping and measuring high speed processor-network interfaces and interconnects; it is an experimental tool for research projects in architecture. We configure FPGA boards as network interfaces (NI) and as switches. NI\u2019s plug into the PCI-X bus of commercial PC\u2019s, and use 4 links of 2.5 Gb/s/link as network connections; we can bundle these links together, at the byte or packet level, offering 10 Gb/s of network throughput. NI\u2019s implement DMA on the PCI-X side, and remote DMA and remote notification (interrupt or flag-setting) on the network side. We configured the switch boards as buffered crossbars operating directly on variable-size packets and featuring credit-based flow control for lossless communication. Multiple, parallel switches can serve the NI links using multipath routing; NI\u2019s resequence the out-of-order packet arrivals. All boards provide extensive support for monitoring, debugging, and measurement. Colleagues adapted the Linux OS for this platform, and used it for remote disk I/O experiments [1]. We report here on the platform architecture, its design cost and complexity, latency and throughput parameters, and buffered crossbar performance. We now work on remote queues and synchronization mechanisms.",
            "Abstract entirety": 1,
            "Author pub id": "TKtxe-UAAAAJ:IWHjjKOFINEC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Smart technologies for effective reconfiguration: The faster approach",
            "Publication year": 2012,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/6322881/",
            "Abstract": "Current and future computing systems increasingly require that their functionality stays flexible after the system is operational, in order to cope with changing user requirements and improvements in system features, i.e. changing protocols and data-coding standards, evolving demands for support of different user applications, and newly emerging applications in communication, computing and consumer electronics. Therefore, extending the functionality and the lifetime of products requires the addition of new functionality to track and satisfy the customers needs and market and technology trends. Many contemporary products along with the software part incorporate hardware accelerators for reasons of performance and power efficiency. While adaptivity of software is straightforward, adaptation of the hardware to changing requirements constitutes a challenging problem requiring delicate solutions. The FASTER \u2026",
            "Abstract entirety": 0,
            "Author pub id": "TKtxe-UAAAAJ:70eg2SAEIzsC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Accelerating Binarized Convolutional Neural Networks with Dynamic Partial Reconfiguration on Disaggregated FPGAs",
            "Publication year": 2020,
            "Publication url": "https://ebooks.iospress.nl/volumearticle/53978",
            "Abstract": "Convolutional Neural Networks (CNNs) currently dominate the fields of artificial intelligence and machine learning due to their high accuracy. However, their computational and memory needs intensify with the complexity of the problems they are deployed to address, frequently requiring highly parallel and/or accelerated solutions. Recent advances in machine learning showcased the potential of CNNs with reduced precision, by relying on binarized weights and activations, thereby leading to Binarized Neural Networks (BNNs). Due to the embarassingly parallel and discrete arithmetic nature of the required operations, BNNs fit well to FPGA technology, thus allowing to considerably scale up problem complexity. However, the fixed amount of resources per chip introduces an upper bound on the dimensions of the problems that FPGA-accelerated BNNs can solve. To this end, we explore the potential of remote \u2026",
            "Abstract entirety": 0,
            "Author pub id": "TKtxe-UAAAAJ:BwyfMAYsbu0C",
            "Publisher": "IOS Press"
        },
        {
            "Title": "Rapid prototyping of a reusable 4/spl times/4 active ATM switch core with the PCI Pamette",
            "Publication year": 2001,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/933833/",
            "Abstract": "PLATO, a new reconfigurable platform for experimentation with active networks, is under development. Due to the large number of factors affecting the final validation of the prototype, we have used the PCI Pamette as a rapid prototyping platform. A 4/spl times/4 active ATM switch has been prototyped, together with all the circuits that disassemble, route and re-assemble ATM cells. Several experiments have been conducted with this prototype, substantially speeding up the design process, leading to working subsystems before the final platform is fully debugged and providing significant insight into the operation of the final system. The design itself was moved from the Pamette to its final operating platform (called PLATO) in two days.",
            "Abstract entirety": 1,
            "Author pub id": "TKtxe-UAAAAJ:ULOm3_A8WrAC",
            "Publisher": "IEEE"
        },
        {
            "Title": "An efficient, low-cost I/O subsystem for network processors",
            "Publication year": 2003,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/1214353/",
            "Abstract": "An efficient I/O subsystem enables cost-effective network processing. To improve high-speed data transfer, the I/O subsystem sends data directly into the processing core's register file. An implementation of this subsystem in a single-chip network processor , the Pro/sup 3/, can sustain advanced inspection firewall processing of 2.5-Gbps TCP traffic.",
            "Abstract entirety": 1,
            "Author pub id": "TKtxe-UAAAAJ:abG-DnoFyZgC",
            "Publisher": "IEEE"
        },
        {
            "Title": "The AXIOM software layers",
            "Publication year": 2016,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S0141933116300850",
            "Abstract": "People and objects will soon share the same digital network for information exchange in a world named as the age of the cyber-physical systems. The general expectation is that people and systems will interact in real-time. This poses pressure onto systems design to support increasing demands on computational power, while keeping a low power envelop. Additionally, modular scaling and easy programmability are also important to ensure these systems to become widespread. The whole set of expectations impose scientific and technological challenges that need to be properly addressed.The AXIOM project (Agile, eXtensible, fast I/O Module) will research new hardware/software architectures for cyber-physical systems to meet such expectations. The technical approach aims at solving fundamental problems to enable easy programmability of heterogeneous multi-core multi-board systems. AXIOM proposes the \u2026",
            "Abstract entirety": 0,
            "Author pub id": "TKtxe-UAAAAJ:tOudhMTPpwUC",
            "Publisher": "Elsevier"
        },
        {
            "Title": "A systematic evaluation of emerging mesh-like CMP NoCs",
            "Publication year": 2015,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/7110129/",
            "Abstract": "This paper studies alternative Network-on-Chip architectures for emerging many-core chip multiprocessors, by exploring the following design options on mesh-based networks: Multiple physical networks (P), cores concentration (C), express channels (X), it widths (W), and virtual channels (V). We exhaustively evaluate all combinations of the afore-mentioned parameters (P, C, X, W, V), using the energy-throughput ratio (ETR) as a metric to classify network congurations. Our experimental results show that, on one hand, with an appropriate selection of parameters (V,W), an optimized baseline 2D mesh offers the best possible ETR for NoCs with up to a few tens of cores (64-core NoC). More complicated networks, using concentration and express channels, can reduce the zero-load latency, but do not necessarily help to improve ETR. On the other hand, for larger CMPs, a 2D mesh with multiple physical networks is a \u2026",
            "Abstract entirety": 0,
            "Author pub id": "TKtxe-UAAAAJ:K3LRdlH-MEoC",
            "Publisher": "IEEE"
        },
        {
            "Title": "A 128 x 128 x 24Gb/s crossbar interconnecting 128 tiles in a single hop and occupying 6% of their area",
            "Publication year": 2010,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/5507559/",
            "Abstract": "We describe the implementation of a 128\u00d7128 crossbar switch in 90 nm CMOS standard-cell ASIC technology. The crossbar operates at 750 MHz and is 32-bits for a port capacity above 20Gb/s, while fitting in a silicon area as small as 6.6 mm 2  by filling it at the 90% level (control not included). Next, we arrange 128 1 mm 2  \"user tiles\" around the crossbar, forming a 150 mm 2  die, and we connect all tiles to the crossbar via global links that run on top of SRAM blocks that we assume to occupy three fourths of each user tile. Including the overhead of repeaters and pipeline registers on the global links, the area cost of the crossbar is 6% of the total tile area. Thus, we prove that crossbars are dense enough and can be connected \"for free\" for valencies exceeding by far the few tens of ports, that were believed to be the practical limit up to now, and reaching above one hundred ports. Applications include Combined Input \u2026",
            "Abstract entirety": 0,
            "Author pub id": "TKtxe-UAAAAJ:rO6llkc54NcC",
            "Publisher": "IEEE"
        },
        {
            "Title": "The FASTER vision for designing dynamically reconfigurable systems",
            "Publication year": 2013,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/6563290/",
            "Abstract": "Extending product functionality and lifetime requires constant addition of new features to satisfy the growing customer needs and the evolving market and technology trends. software component adaptivity is straightforward but not enough: recent products include hardware accelerators for reasons of performance and power efficiency that also need to adapt to new requirements. Reconfigurable logic allows the definition of new functions to be implemented in dynamically instantiated hardware units, combining adaptivity with hardware speed and efficiency. For the Intrusion Detection System example, new rules can be hardcoded into the reconfigurable logic, achieving high performance, while providing the necessary adaptivity to new threats. The FASTER (Facilitating Analysis and Synthesis Technologies for Effective Reconfiguration) project aims at introducing a complete methodology to allow designers to easily \u2026",
            "Abstract entirety": 0,
            "Author pub id": "TKtxe-UAAAAJ:pyW8ca7W8N0C",
            "Publisher": "IEEE"
        },
        {
            "Title": "A generic high throughput architecture for stream processing",
            "Publication year": 2017,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/8056796/",
            "Abstract": "Stream join is a fundamental and computationally expensive data mining operation for relating information from different data streams. This paper presents two FPGA-based architectures that accelerate stream join processing. The proposed hardware-based systems were implemented on a multi-FPGA hybrid system with high memory bandwidth. The experimental evaluation shows that our proposed systems can outperform a software-based solution that runs on a high-end, 48-core multiprocessor platform by at least one order of magnitude. In addition, the proposed solutions outperform any other previously proposed hardware-based or software-based solutions for stream join processing. Finally, our proposed hardware-based architectures can be used as generic templates to map stream processing algorithms on reconfigurable logic, taking into consideration real-world challenges and restrictions.",
            "Abstract entirety": 1,
            "Author pub id": "TKtxe-UAAAAJ:N5tVd3kTz84C",
            "Publisher": "IEEE"
        },
        {
            "Title": "EDRA: A Hardware-assisted Decoupled Access/Execute Framework on the Digital Market",
            "Publication year": 2021,
            "Publication url": "https://research.utwente.nl/en/publications/edra-a-hardware-assisted-decoupled-accessexecute-framework-on-the",
            "Abstract": "EDRA was an Horizon 2020 FET Launchpad project that focused on the commercialization of the Decoupled Access Execution Reconfigurable (DAER) framework-developed within the FET-HPC EXTRA project-on Amazon's Elastic Cloud (EC2) Compute FPGA-based infrastructure. The delivered framework encapsulates DAER into a EC2 virtual machine (VM), and uses a simple, directive-based, high-level application programming interface (API) to facilitate application mapping to the underlying hardware architecture. EDRA's Minimum",
            "Abstract entirety": 1,
            "Author pub id": "TKtxe-UAAAAJ:gsN89kCJA0AC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Pre-decoded CAMs for efficient and high-speed NIDS pattern matching",
            "Publication year": 2004,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/1364636/",
            "Abstract": "In this paper we advocate the use of pre-decoding for CAM-based pattern matching. We implement an FPGA based sub-system for NIDS (Snort) pattern matching using a combination of techniques. First, we reduce the area cost of character matching using (i) character pre-decoding before they are compared in the CAM line, and (ii) efficient shift register implementation using the SRL16 Xilinx cell. Then we achieve high operating frequencies by (iii) using ne grain pipelining for faster circuits and (iv) decoupling the data distribution network from the processing components. Our results show that for matching more than 18,000 characters (the entire SNORT rule set) our implementation requires an area cost of less than 1.1 logic cells per matched character, achieving an operating frequency of about 375 MHz (3 Gbps) on a Virtex2 device. When using quad parallelism to increase the matching throughput, the area cost \u2026",
            "Abstract entirety": 0,
            "Author pub id": "TKtxe-UAAAAJ:u-x6o8ySG0sC",
            "Publisher": "IEEE"
        },
        {
            "Title": "RACOS: Transparent access and virtualization of reconfigurable hardware accelerators",
            "Publication year": 2017,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/8344606/",
            "Abstract": "Crafting accelerators using reconfigurable hardware is a promising way to achieve improved performance and power/energy efficiency. However, deploying reconfigurable accelerators is still cumbersome as it involves overall system integration issues and and runtime reconfigurable resource management. We describe the design and implementation of RACOS, a Reconfigurable ACcelerator OS, that provides a simple and intuitive software interface to load/unload reconfigurable hardware accelerators and perform data I/Os transparently to the user. Multiple partially reconfigurable regions are supported, and each region can host either single- or dual-threaded accelerators, effectively virtualizing the reconfigurable resources. RACOS allows multiple applications to use one or more accelerators each, and schedules accelerators for execution according to four policies: simple and inorder that respect the order of \u2026",
            "Abstract entirety": 0,
            "Author pub id": "TKtxe-UAAAAJ:_Ybze24A_UAC",
            "Publisher": "IEEE"
        },
        {
            "Title": "D4. 3: Configuration Scheduler Requirements and Basic Functionality",
            "Publication year": 2012,
            "Publication url": "https://www.academia.edu/download/30794254/FASTER_D4_3_FOR_FF-20120910.pdf",
            "Abstract": "The run-time system manager (RTSM) is responsible for the on-line scheduling of partially reconfigurable tasks and the device management. In this document we discuss the requirements of the runtime configuration scheduler along with its basic functionality. We also identify the inputs that are necessary at compile time and during runtime needed in order to take decisions at runtime, and finally the type of operations controlled by the RTSM.",
            "Abstract entirety": 1,
            "Author pub id": "TKtxe-UAAAAJ:2P1L_qKh6hAC",
            "Publisher": "Unknown"
        },
        {
            "Title": "A fast FPGA-based 2-opt solver for small-scale euclidean traveling salesman problem",
            "Publication year": 2007,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/4297239/",
            "Abstract": "In this paper we discuss and analyze the FPGA-based implementation of an algorithm for the traveling salesman problem (TSP), and in particular of 2-Opt, one of the most famous local optimization algorithms, for Euclidean TSP instances up to a few hundred cities. We introduce the notion of \"symmetrical 2-Opt moves\" which allows us to uncover fine-grain parallelism when executing the specified algorithm. We propose a novel architecture that exploits this parallelism, and demonstrate its implementation in reconfigurable hardware. We evaluate our proposed architecture and its implementation on a state-of-the-art FPGA using a subset of the TSPLIB benchmark, and find that our approach exhibits better quality of final results and an average speedup of 600% when compared with the state-of-the-art software implementation. Our approach produces, to the best of our knowledge, the fastest to date TSP 2-Opt solver \u2026",
            "Abstract entirety": 0,
            "Author pub id": "TKtxe-UAAAAJ:L8Ckcad2t8MC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Design guidelines for high-performance SCM hierarchies",
            "Publication year": 2018,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/3240302.3240310",
            "Abstract": "With emerging storage-class memory (SCM) nearing commercialization, there is evidence that it will deliver the much-anticipated high density and access latencies within only a few factors of DRAM. Nevertheless, the latency-sensitive nature of memory-resident services makes seamless integration of SCM in servers questionable. In this paper, we ask the question of how best to introduce SCM for such servers to improve overall performance/cost over existing DRAM-only architectures. We first show that even with the most optimistic latency projections for SCM, the higher memory access latency results in prohibitive performance degradation. However, we find that deployment of a modestly sized high-bandwidth 3D stacked DRAM cache makes the performance of an SCM-mostly memory system competitive. The high degree of spatial locality that memory-resident services exhibit not only simplifies the DRAM cache \u2026",
            "Abstract entirety": 0,
            "Author pub id": "TKtxe-UAAAAJ:35r97b3x0nAC",
            "Publisher": "Unknown"
        },
        {
            "Title": "The mondrian data engine",
            "Publication year": 2017,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/3140659.3080233",
            "Abstract": "The increasing demand for extracting value out of ever-growing data poses an ongoing challenge to system designers, a task only made trickier by the end of Dennard scaling. As the performance density of traditional CPU-centric architectures stagnates, advancing compute capabilities necessitates novel architectural approaches. Near-memory processing (NMP) architectures are reemerging as promising candidates to improve computing efficiency through tight coupling of logic and memory. NMP architectures are especially fitting for data analytics, as they provide immense bandwidth to memory-resident data and dramatically reduce data movement, the main source of energy consumption.Modern data analytics operators are optimized for CPU execution and hence rely on large caches and employ random memory accesses. In the context of NMP, such random accesses result in wasteful DRAM row buffer \u2026",
            "Abstract entirety": 0,
            "Author pub id": "TKtxe-UAAAAJ:Y5dfb0dijaUC",
            "Publisher": "ACM"
        },
        {
            "Title": "Embedded systems\u2014new challenges and future directions",
            "Publication year": 2008,
            "Publication url": "https://dl.acm.org/doi/pdf/10.1145/1376804.1376805",
            "Abstract": "Embedded systems applications are present in several products in modern life ranging from consumer electronics to industrial systems like cell phones, digital televisions and video game consoles. The amount of functionality incorporated in an embedded system is continuously increasing. These applications are migrating from single processor-based systems to heterogeneous multiprocessing in a single chip (MPSoCs) with complex communication infra-structures. Designing embedded systems requires concurrent design of complex embedded software and a sophisticated hardware platform. This platform can contain several different types of processors with a complex interconnection network, the memory system can be heterogeneously distributed around the machine. The lack of early coordination between different teams belonging to different cultures ultimately causes delays and cost overheads that are no \u2026",
            "Abstract entirety": 0,
            "Author pub id": "TKtxe-UAAAAJ:TQgYirikUcIC",
            "Publisher": "ACM"
        },
        {
            "Title": "mCluster: a software framework for portable device-based volunteer computing",
            "Publication year": 2016,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/7515707/",
            "Abstract": "Recent market forecasts predict that the portable computing trend will vastly spread, as by 2020 there will bemore than 3 billion LTE device users worldwide. Motivated by this fact, many companies and research institutes have already launched research projects that utilize portable devices, voluntarily provided by users, to perform the required computations. Many such projects employ Berkeley's BOINC middleware, since it can support a large variety of stationary and mobile devices. However, currently available BOINC high-level APIs, either do not support portable devices or lack advanced processing capabilities (such as inter-node task dependencies) and/or easiness of use. To resolve these issues, we propose the mCluster software framework for application execution powered by the BOINC middleware on portable devices. mCluster adopts a task-based programming model that requires simple, pragma \u2026",
            "Abstract entirety": 0,
            "Author pub id": "TKtxe-UAAAAJ:eflP2zaiRacC",
            "Publisher": "IEEE"
        },
        {
            "Title": "A novel SRAM-based FPGA architecture for efficient TMR fault tolerance support",
            "Publication year": 2009,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/5272319/",
            "Abstract": "This paper proposes a novel SRAM based FPGA architecture that is suitable for mapping designs when fault tolerance is desirable. TMR has been successfully applied in FPGAs to mitigate transient faults, which are likely to occur in harsh environments such as in space applications. In addition, fault tolerance techniques gain importance as feature sizes shrink and make circuits less reliable. However, TMR comes at high area penalty, which increases as the TMR grain becomes finer. We propose a slight modification to existing SRAM based FPGA architectures to support fine grain redundancy at an area cost even less than 3times (1.76times in average for our benchmark circuits). Our approach also provides accurate fault location and allows smaller and more infrequent reconfigurations saving both reconfiguration time and power.",
            "Abstract entirety": 1,
            "Author pub id": "TKtxe-UAAAAJ:5nxA0vEk-isC",
            "Publisher": "IEEE"
        },
        {
            "Title": "DARSA: a dataflow analysis tool for reconfigurable platforms",
            "Publication year": 2018,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/3229631.3229644",
            "Abstract": "This paper presents DARSA, a Dataflow Application Resource and Sub-graph Analysis tool. DARSA can be used for early and accurate results for design space exploration of dataflow applications. Additionally DARSA can be used to extrapolate Coarse-Grain Reconfigurable Arrays to improve performance by analysing target applications.",
            "Abstract entirety": 1,
            "Author pub id": "TKtxe-UAAAAJ:j8SEvjWlNXcC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Prefetching and cache management using task lifetimes",
            "Publication year": 2013,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/2464996.2465443",
            "Abstract": "Task-based dataflow programming models and runtimes emerge as promising candidates for programming multicore and manycore architectures. These programming models analyze dynamically task dependencies at runtime and schedule independent tasks concurrently to the processing elements. In such models, cache locality, which is critical for performance, becomes more challenging in the presence of fine-grain tasks, and in architectures with many simple cores.",
            "Abstract entirety": 1,
            "Author pub id": "TKtxe-UAAAAJ:yD5IFk8b50cC",
            "Publisher": "Unknown"
        },
        {
            "Title": "A Configurable TLB Hierarchy for the RISC-V Architecture",
            "Publication year": 2020,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/9221630/",
            "Abstract": "The Rocket Chip Generator uses a collection of parameterized processor components to produce RISC-V-based SoCs. It is a powerful tool that can produce a wide variety of processor designs ranging from tiny embedded processors to complex multi-core systems. In this paper we extend the features of the Memory Management Unit of the Rocket Chip Generator and specifically the TLB Hierarchy. TLBs are essential in terms of performance because they mitigate the overhead of frequent Page Table Walks, but may harm the critical path of the processor due to their size and/or associativity. In the original Rocket Chip implementation the L1 Data/Instruction TLB is fully-associative and the shared L2 TLB is direct-mapped. We lift these restrictions and design and implement configurable, set-associative L1 and L2 TLB templates that can create any organization from direct-mapped to fully-associative to achieve the \u2026",
            "Abstract entirety": 0,
            "Author pub id": "TKtxe-UAAAAJ:ML0RJ9NH7IQC",
            "Publisher": "IEEE"
        },
        {
            "Title": "A Memory Efficient Intrusion Detection Architecture Using the Split-AC Pattern Matching Algorithm",
            "Publication year": 2006,
            "Publication url": "https://www.researchgate.net/profile/Dionisios-Pnevmatikatos/publication/266231111_A_Memory_Efficient_Intrusion_Detection_Architecture_Using_the_Split-AC_Pattern_Matching_Algorithm/links/55684d7908aeccd77737bfe7/A-Memory-Efficient-Intrusion-Detection-Architecture-Using-the-Split-AC-Pattern-Matching-Algorithm.pdf",
            "Abstract": "This chapter is dedicated to the algorithm we developed for reducing the memory requirements of the Aho-Corasick pattern matching algorithm. We call this algorithm \u201cSplit-AC\u201d, which is short for Split-Aho-Corasick. In the first part of this chapter we present the reasons for selecting the Aho-Corasick as the basis for our work as well. In the second part we present the ideas that led to the development of the Split-AC algorithm as well as a general description. The third and final part presents the original Split-AC algorithm in detail, as well as the two subsequent revisions that were made.",
            "Abstract entirety": 1,
            "Author pub id": "TKtxe-UAAAAJ:uc_IGeMz5qoC",
            "Publisher": "Unknown"
        },
        {
            "Title": "An evaluation of vivado HLS for efficient system design",
            "Publication year": 2016,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/7731785/",
            "Abstract": "High-Level Synthesis (HLS) tools are hailed as one of the most promising ways to bridge the design productivity gap, especially for reconfigurable systems. These tools increase designer productivity at a possible performance and/or silicon cost, although the designer can play a significant role in the minimisation of both. Currently, one of the key challenges for the designer is to efficiently use the vendor-defined methodology and the design guidelines of the HLS tool. Hence, this work aims at assisting designers in taking full advantage and making optimal use of the official HLS methodology when implementing three fundamental algorithms used in a variety of video and image processing applications. One is a sorting algorithm while the other two are algorithms used in traversing tree/graph data structures. The work presented here concerns a highly popular HLS tool, namely Vivado HLS, and the experiences and \u2026",
            "Abstract entirety": 0,
            "Author pub id": "TKtxe-UAAAAJ:1qzjygNMrQYC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Extra: Towards an efficient open platform for reconfigurable high performance computing",
            "Publication year": 2015,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/7371394/",
            "Abstract": "To handle the stringent performance requirements of future exascale-class applications, High Performance Computing (HPC) systems need ultra-efficient heterogeneous compute nodes. To reduce power and increase performance, such compute nodes will require hardware accelerators with a high degree of specialization. Ideally, dynamic reconfiguration will be an intrinsic feature, so that specific HPC application features can be optimally accelerated, even if they regularly change over time. In the EXTRA project, we create a new and flexible exploration platform for developing reconfigurable architectures, design tools and HPC applications with run-time reconfiguration built-in as a core fundamental feature instead of an add-on. EXTRA covers the entire stack from architecture up to the application, focusing on the fundamental building blocks for run-time reconfigurable exascale HPC systems: new chip \u2026",
            "Abstract entirety": 0,
            "Author pub id": "TKtxe-UAAAAJ:vRqMK49ujn8C",
            "Publisher": "IEEE"
        },
        {
            "Title": "Web-conscious storage management for web proxies",
            "Publication year": 2002,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/1134299/",
            "Abstract": "Many proxy servers are limited by their file I/O needs. Even when a proxy is configured with sufficient I/O hardware, the file system software often fails to provide the available bandwidth to the proxy processes. Although specialized file systems may offer a significant improvement and overcome these limitations, we believe that user-level disk management on top of industry-standard file systems can offer similar performance advantages. We study the overheads associated with file I/O in Web proxies, we investigate their underlying causes, and we propose Web-conscious storage management, a set of techniques that exploit the unique reference characteristics of Web-page accesses in order to allow Web proxies to overcome file I/O limitations. Using realistic trace-driven simulations, we show that these techniques can improve the proxy's secondary storage I/O throughput by a factor of 15 over traditional open-source \u2026",
            "Abstract entirety": 0,
            "Author pub id": "TKtxe-UAAAAJ:_FxGoFyzp5QC",
            "Publisher": "IEEE"
        },
        {
            "Title": "TOPIC CHAIRS",
            "Publication year": 2009,
            "Publication url": "https://past.date-conference.com/proceedings-archive/2009/DATE09/PDFFILES/TOPIC_CHAIRS.PDF",
            "Abstract": "TOPIC CHAIRS Page 1 www.date-conference.com 20-24 April 2009 A cropolis Nice, Fran ce D \nA TE09 TOPIC CHAIRS System Specification and Modeling Eugenio Villar Universidad de \nCantabria, ES Grant Martin Tensilica, US MPSoC and System Design Methods Luciano Lavagno \nCadence, US Wido Kruijtzer NXP Semiconductors, NL System Synthesis and Optimization Peter \nMarwedel U of Dortmund, DE Paul Pop TU of Denmark, DK Simulation and Validation Franco \nFummi U of Verona, IT Ian Harris U of California Irvine, US Design of Low Power Systems Miguel \nMiranda IMEC, BE Alberto Macii Politecnico di Torino, IT Power Estimation and Optimization \nJoerg Henkel U of Karlsruhe, DE Kaushik Roy Purdue U, US Emerging Technologies, \nSystems and Applications Sandeep Shukla Virginia Tech, US Yuan Xie Penn State U, \nUS Formal Methods and Verification Jason Baumgartner IBM Corporation, Austin, TX, -, -\u2026",
            "Abstract entirety": 0,
            "Author pub id": "TKtxe-UAAAAJ:JoZmwDi-zQgC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Real-time monitoring of multicore SoCs through specialized hardware agents on NoC network interfaces",
            "Publication year": 2012,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/6270646/",
            "Abstract": "Network-on-chip based multicore systems need efficient management of a multitude of processing resources, hence avoiding hardware and system software from making inefficient time- and power-decisions at runtime. Hardware event management is a necessary path to assist in high-speed management of captured events and enable efficient reaction mechanisms. This paper proposes different micro architecture alternatives and describes an infrastructure for real-time monitoring and management of network-on-chip based systems. High-speed and energy efficient circuit techniques are deployed for monitoring agents that reside at the network interfaces in order to be configured dynamically and communicate computed statistics to centralized hardware monitor managers of different functionality and complexity. An implementation of a pipelined centralized monitor manager is shown, with the capacity to maintain \u2026",
            "Abstract entirety": 0,
            "Author pub id": "TKtxe-UAAAAJ:J_g5lzvAfSwC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Towards on-demand system reliability: software implemented fault tolerance and testing",
            "Publication year": 2013,
            "Publication url": "https://eprints.soton.ac.uk/353386/",
            "Abstract": "Towards on-demand system reliability: software implemented fault tolerance and testing - \nePrints Soton The University of Southampton Courses University life Research Business Global \nAbout Visit Alumni Departments News Events Contact \u00d7 Search the Site Search Filter your \nsearch: All Courses Projects Staff University of Southampton Institutional Repository Search \nAdvanced Search Policies & Help Latest Download Statistics Browse by Year Browse by \nDivisions LeftRight Towards on-demand system reliability: software implemented fault tolerance \nand testing (2013) Towards on-demand system reliability: software implemented fault tolerance \nand testing. European Test Symposium (ETS), France. 27 - 31 May 2013. in-press . Record \ntype: Conference or Workshop Item (Other) Full text not available from this repository. More \ninformation Published date: 2013 Venue - Dates: European Test Symposium (ETS), France, -\u2026",
            "Abstract entirety": 0,
            "Author pub id": "TKtxe-UAAAAJ:a0OBvERweLwC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Explicit communication and synchronization in SARC",
            "Publication year": 2010,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/5567092/",
            "Abstract": "A new network interface optimized for SARC supports synchronization and explicit communication and provides a robust mechanism for event responses. Full-system simulation of the authors' design achieved a 10- to 40-percent speed increase over traditional cache architectures on 64 cores, a two- to four-fold decrease in on-chip network traffic, and a three- to five-fold decrease in lock and barrier latency.",
            "Abstract entirety": 1,
            "Author pub id": "TKtxe-UAAAAJ:YOwf2qJgpHMC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Prototyping a configurable cache/scratchpad memory with virtualized user-level RDMA capability",
            "Publication year": 2019,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-662-58834-5_6",
            "Abstract": "We present the hardware design and implementation of a local memory system for individual processors inside future chip multiprocessors (CMP). Our memory system supports both implicit communication via caches, and explicit communication via directly accessible local (\u201cscratchpad\u201d) memories and remote DMA (RDMA). We provide run-time configurability of the SRAM blocks that lie near each processor, so that portions of them operate as 2nd level (local) cache, while the rest operate as scratchpad. We also strive to merge the communication subsystems required by the cache and scratchpad into one integrated Network Interface (NI) and Cache Controller (CC), in order to economize on circuits. The processor interacts with the NI at user-level through virtualized command areas in scratchpad; the NI uses a similar access mechanism to provide efficient support for two hardware synchronization primitives \u2026",
            "Abstract entirety": 0,
            "Author pub id": "TKtxe-UAAAAJ:dhFuZR0502QC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "PR03: a hybrid NPU architecture",
            "Publication year": 2004,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/1353200/",
            "Abstract": "As the telecommunications industry recovers from the severe downturn of recent years, data traffic continues to exhibit a rate of increase that outpaces advances in VLSI technology. Therefore, lowering overall system cost at network processing nodes and maximizing network utilization - hence revenues - remain extremely important objectives. To address these issues, new semiconductor devices called network processing units (NPUs) have emerged. They are optimized to provide programmable processing of protocol data units (PDUs) in networks with diverse requirements while efficiently supporting current and emerging protocols and services. NPUs promise to deliver an ASICs speed with a CPU's programmability, thus augmenting the capacity and features of network nodes that forward and manipulate data traffic. The Programmable Protocol Processor (PRO3) system reduces the overhead incurred by \u2026",
            "Abstract entirety": 0,
            "Author pub id": "TKtxe-UAAAAJ:kNdYIx-mwKoC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Experimental Testing of PLATO, a Reconfigurable Active ATM Network Node",
            "Publication year": 2001,
            "Publication url": "https://www.researchgate.net/profile/Stamatis-Kavvadias/publication/228949594_Experimental_Testing_of_PLATO_a_Reconfigurable_Active_ATM_Network_Node/links/02e7e51dcc5bfc15f6000000/Experimental-Testing-of-PLATO-a-Reconfigurable-Active-ATM-Network-Node.pdf",
            "Abstract": "An active, reconfigurable network node, named PLATO, has been designed and implemented. Version V. X1. 0 was developed with a Xilinx Virtex XCV-1000 FPGA as a PCI board, with the capability of 256MBytes of SDRAM, 512KBytes of SRAM, and a UTOPIA level 2 based interface to 4 bidirectional 155 Mbps ATM links. This paper presents the implementation and testing of the PLATO system, as well as a priority enforcement scheme for transmission of TCP/IP packets over ATM networks.",
            "Abstract entirety": 1,
            "Author pub id": "TKtxe-UAAAAJ:NMxIlDl6LWMC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Design space exploration for fair resource-allocated noc architectures",
            "Publication year": 2014,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/6893205/",
            "Abstract": "Networks-on-chip are integral parts of modern chips and designers explore the architectural design space to optimize both performance and energy-efficiency. Architectural choices for modern NoCs include: (i) partitioning using multiple sub-networks (P), (ii) concentration (C), and (iii) express physical links (X). Previous efforts do not adequately cover the design space while the range of assumptions vary significantly, rendering direct comparisons between different configurations impossible. This work expands the NoC design space and overcomes previous shortcomings by exploring the impact of architectural choices (P, C, X) separately and combinatorially on a 2D mesh. We generate all possible NoC configurations for large systems (64 and 256 nodes) and compare performance, energy, and area when the configurations utilize equal resources. First, we equalize the bisection wire count and analyze the impact \u2026",
            "Abstract entirety": 0,
            "Author pub id": "TKtxe-UAAAAJ:UxriW0iASnsC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Creating Customized CGRAs for Scientific Applications",
            "Publication year": 2021,
            "Publication url": "https://www.mdpi.com/994930",
            "Abstract": "Executing complex scientific applications on Coarse Grain Reconfigurable Arrays (CGRAs) offers improvements in the execution time and/or energy consumption when compared to optimized software implementations or even fully customized hardware solutions. In this work, we explore the potential of application analysis methods in such customized hardware solutions. We offer analysis metrics from various scientific applications and tailor the results that are to be used by MC-Def, a novel Mixed-CGRA Definition Framework targeting a Mixed-CGRA architecture that leverages the advantages of CGRAs and those of FPGAs by utilizing a customized cell-array along, with a separate LUT array being used for adaptability. Additionally, we present the implementation results regarding the VHDL-created hardware implementations of our CGRA cell concerning various scientific applications.",
            "Abstract entirety": 1,
            "Author pub id": "TKtxe-UAAAAJ:EYYDruWGBe4C",
            "Publisher": "Multidisciplinary Digital Publishing Institute"
        },
        {
            "Title": "Approaching ideal NoC latency with pre-configured routes",
            "Publication year": 2007,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/4209004/",
            "Abstract": "In multi-core ASICs, processors and other compute engines need to communicate with memory blocks and other cores with latency as close as possible to the ideal of a direct buffered wire. However, current state of the art networks-on-chip (NoCs) suffer, at best, latency of one clock cycle per hop. We investigate the design of a NoC that offers close to the ideal latency in some preferred, run-time configurable paths. Processors and other compute engines may perform network reconfiguration to guarantee low latency over different sets of paths as needed. Flits in non-preferred paths are given lower priority than flits in preferred ones, and suffer a delay of one clock cycle per hop when there is no contention. To achieve our goal, we use the \"mad-postman\" technique: every incoming flit is eagerly (i.e. speculatively) forwarded to the input's preferred output, if any. This is accomplished with the mere delay of a single pre \u2026",
            "Abstract entirety": 0,
            "Author pub id": "TKtxe-UAAAAJ:eQOLeE2rZwMC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Prototyping efficient interprocessor communication mechanisms",
            "Publication year": 2007,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/4285730/",
            "Abstract": "Parallel computing systems are becoming widespread and grow in sophistication. Besides simulation, rapid system prototyping becomes important in designing and evaluating their architecture. We present an efficient FPGA-based platform that we developed and use for research and experimentation on high speed interprocessor communication, network interfaces and interconnects. Our platform supports advanced communication capabilities such as remote DMA, remote queues, zero-copy data delivery and flexible notification mechanisms, as well as link bundling for increased performance. We report on the platform architecture, its design cost, complexity and performance (latency and throughput). We also report our experiences from implementing benchmarking kernels and a user-level benchmark application, and show how software can take advantage of the provided features, but also expose the \u2026",
            "Abstract entirety": 0,
            "Author pub id": "TKtxe-UAAAAJ:7PzlFSSx8tAC",
            "Publisher": "IEEE"
        },
        {
            "Title": "FPGA implementation of a configurable cache/scratchpad memory with virtualized user-level RDMA capability",
            "Publication year": 2009,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/5289226/",
            "Abstract": "We report on the hardware implementation of a local memory system for individual processors inside future chip multiprocessors (CMP). It intends to support both implicit communication, via caches, and explicit communication, via directly accessible local (ldquoscratchpadrdquo) memories and remote DMA (RDMA). We provide run-time configurability of the SRAM blocks near each processor, so that part of them operates as 2nd level (local) cache, while the rest operates as scratchpad. We also strive to merge the communication subsystems required by the cache and scratchpad into one integrated Network Interface (NI) and Cache Controller (CC), in order to economize on circuits. The processor communicates with the NI in user-level, through virtualized command areas in scratchpad; through a similar mechanism, the NI also provides efficient support for synchronization, using two hardware primitives: counters \u2026",
            "Abstract entirety": 0,
            "Author pub id": "TKtxe-UAAAAJ:Se3iqnhoufwC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Disaggregated compute, memory and network systems: A new era for optical data centre architectures",
            "Publication year": 2017,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/7937418/",
            "Abstract": "The disaggregated dRedBox Data Centre architecture is proposed that enables dynamic allocation of pooled compute and memory resources. An orchestration platform is described and algorithms are simulated that demonstrate the efficient utilization of IT infrastructure.",
            "Abstract entirety": 1,
            "Author pub id": "TKtxe-UAAAAJ:HE397vMXCloC",
            "Publisher": "IEEE"
        },
        {
            "Title": "A Run-Time System for Partially Reconfigurable FPGAs: The case of STMicroelectronics SPEAr board",
            "Publication year": 2016,
            "Publication url": "https://ebooks.iospress.nl/doi/10.3233/978-1-61499-621-7-553",
            "Abstract": "During recent years much research focused on making Partial Reconfiguration (PR) more widespread. The FASTER project aimed at realizing an integrated toolchain that assists the designer in the steps of the design flow that are necessary to port a given application onto an FPGA device. The novelty of the framework lies in the use of partial dynamic reconfiguration seen as a first class citizen throughout the entire design flow in order to exploit FPGA device potential.",
            "Abstract entirety": 1,
            "Author pub id": "TKtxe-UAAAAJ:08ZZubdj9fEC",
            "Publisher": "IOS Press"
        },
        {
            "Title": "A reconfigurable perfect-hashing scheme for packet inspection",
            "Publication year": 2005,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/1515804/",
            "Abstract": "In this paper, we consider scanning and analyzing packets in order to detect hazardous contents using pattern matching. We introduce a hardware perfect-hashing technique to access the memory that contains the matching patterns. A subsequent simple comparison between incoming data and memory output determines the match. We implement our scheme in reconfigurable hardware and show that we can achieve a throughput between 1.7 and 5.7 Gbps requiring only a few tens of FPGA memory blocks and 0.30 to 0.57 logic cells per matching character. We also show that our designs achieve at least 30% better efficiency compared to previous work, measured in throughput per area required per matching character.",
            "Abstract entirety": 1,
            "Author pub id": "TKtxe-UAAAAJ:IjCSPb-OGe4C",
            "Publisher": "IEEE"
        },
        {
            "Title": "DeSyRe: On-demand system reliability",
            "Publication year": 2013,
            "Publication url": "https://www.sciencedirect.com/science/article/pii/S0141933113001208",
            "Abstract": "The DeSyRe project builds on-demand adaptive and reliable Systems-on-Chips (SoCs). As fabrication technology scales down, chips are becoming less reliable, thereby incurring increased power and performance costs for fault tolerance. To make matters worse, power density is becoming a significant limiting factor in SoC design, in general. In the face of such changes in the technological landscape, current solutions for fault tolerance are expected to introduce excessive overheads in future systems. Moreover, attempting to design and manufacture a totally defect-/fault-free system, would impact heavily, even prohibitively, the design, manufacturing, and testing costs, as well as the system performance and power consumption. In this context, DeSyRe delivers a new generation of systems that are reliable by design at well-balanced power, performance, and design costs. In our attempt to reduce the overheads of \u2026",
            "Abstract entirety": 0,
            "Author pub id": "TKtxe-UAAAAJ:f2IySw72cVMC",
            "Publisher": "Elsevier"
        },
        {
            "Title": "Enabling Virtual Memory Research on RISC-V with a Configurable TLB Hierarchy for the Rocket Chip Generator",
            "Publication year": 2020,
            "Publication url": "https://arxiv.org/abs/2009.07723",
            "Abstract": "The Rocket Chip Generator uses a collection of parameterized processor components to produce RISC-V-based SoCs. It is a powerful tool that can produce a wide variety of processor designs ranging from tiny embedded processors to complex multi-core systems. In this paper we extend the features of the Memory Management Unit of the Rocket Chip Generator and specifically the TLB hierarchy. TLBs are essential in terms of performance because they mitigate the overhead of frequent Page Table Walks, but may harm the critical path of the processor due to their size and/or associativity. In the original Rocket Chip implementation the L1 Instruction/Data TLB is fully-associative and the shared L2 TLB is direct-mapped. We lift these restrictions and design and implement configurable, set-associative L1 and L2 TLB templates that can create any organization from direct-mapped to fully-associative to achieve the desired ratio of performance and resource utilization, especially for larger TLBs. We evaluate different TLB configurations and present performance, area, and frequency results of our design using benchmarks from the SPEC2006 suite on the Xilinx ZCU102 FPGA.",
            "Abstract entirety": 1,
            "Author pub id": "TKtxe-UAAAAJ:Z5m8FVwuT1cC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Topic 11: Multicore and Manycore Programming",
            "Publication year": 2012,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-642-32820-6_58",
            "Abstract": "Modern multicore and manycore systems enjoy the benefits of technology scaling and promise impressive performance. However, harvesting this potential is not straightforward. While multicore and manycore processors alleviate several problems that are related to single-core processors \u2013 known as memory-, power-, or instruction-level parallelism-wall \u2013 they raise the issue of the programmability and programming effort. This topic focuses on novel solutions for multicore and manycore programmability and efficient programming in the context of generalpurpose systems.",
            "Abstract entirety": 1,
            "Author pub id": "TKtxe-UAAAAJ:lSLTfruPkqcC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "AXIOM: a hardware-software platform for cyber physical systems",
            "Publication year": 2016,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/7723597/",
            "Abstract": "Cyber-Physical Systems (CPSs) are widely necessary for many applications that require interactions with the humans and the physical environment. A CPS integrates a set of hardware-software components to distribute, execute and manage its operations. The AXIOM project (Agile, eXtensible, fast I/O Module) aims at developing a hardware-software platform for CPS such that i) it can use an easy parallel programming model and ii) it can easily scale-up the performance by adding multiple boards (e.g., 1 to 10 boards can run in parallel). AXIOM supports task-based programming model based on OmpSs and leverage a high-speed, inexpensive communication interface called AXIOM-Link. Another key aspect is that the board provides programmable logic (FPGA) to accelerate portions of an application. We are using smart video surveillance, and smart home living applications to drive our design.",
            "Abstract entirety": 1,
            "Author pub id": "TKtxe-UAAAAJ:kRWSkSYxWN8C",
            "Publisher": "IEEE"
        },
        {
            "Title": "Enabling Storage Class Memory as a DRAM Replacement for Datacenter Services",
            "Publication year": 2018,
            "Publication url": "https://scholar.google.com/scholar?cluster=9457017812232801906&hl=en&oi=scholarr",
            "Abstract": "Unknown",
            "Abstract entirety": 1,
            "Author pub id": "TKtxe-UAAAAJ:VLnqNzywnoUC",
            "Publisher": "Unknown"
        },
        {
            "Title": "The NEBULA RPC-optimized architecture",
            "Publication year": 2020,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/9138953/",
            "Abstract": "Large-scale online services are commonly structured as a network of software tiers, which communicate over the datacenter network using RPCs. Ongoing trends towards software decomposition have led to the prevalence of tiers receiving and generating RPCs with runtimes of only a few microseconds. With such small software runtimes, even the smallest latency overheads in RPC handling have a significant relative performance impact. In particular, we find that growing network bandwidth introduces queuing effects within a server\u2019s memory hierarchy, considerably hurting the response latency of fine-grained RPCs. In this work we introduce NEBULA, an architecture optimized to accelerate the most challenging microsecond-scale RPCs, by leveraging two novel mechanisms to drastically improve server throughput under strict tail latency goals. First, NEBULA reduces detrimental queuing at the memory controllers \u2026",
            "Abstract entirety": 0,
            "Author pub id": "TKtxe-UAAAAJ:URolC5Kub84C",
            "Publisher": "IEEE"
        },
        {
            "Title": "FPGA-based evaluation platform for disaggregated computing",
            "Publication year": 2017,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/8344620/",
            "Abstract": "Disaggregated computing aims at overcoming the problem of fixed resource proportionality in existing infrastructures while advancing resource allocation to virtual machines, which is currently restricted by the physical boundaries of a server tray. Organizing resources into large homogeneous pools (e.g., compute, memory, accelerators, etc) enables the demand-driven, fine-grained allocation of resources, effectively leading to improved resource utilization and significant power savings. However, the success of this approach relies on how efficiently the underlying resources are utilized by the software application. To facilitate software development in disaggregated computing environments, we introduce a versatile multi-FPGA evaluation platform that can serve as an early exploration tool for the involved trade-offs and execution alternatives given the application at hand. To increase functionality of the proposed \u2026",
            "Abstract entirety": 0,
            "Author pub id": "TKtxe-UAAAAJ:ZuybSZzF8UAC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Dynamic power and thermal management of noc-based heterogeneous mpsocs",
            "Publication year": 2014,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/2567658",
            "Abstract": "Advances in silicon process technology have made it possible to include multiple processor cores on a single die. Billion transistor architectures usually in the form of networks-on-chip present a wide range of challenges in design, microarchitecture, and algorithmic levels with significant impact to system performance and power consumption. In this article, we propose efficient methods and mechanisms that exploit a heterogeneous network-on-chip (NoC) to achieve a power- and thermal-aware coherent system. To this end, we utilize different management techniques which employ dynamic frequency scaling circuitry and power and temperature sensors per node to achieve real-time workload prediction and allocation at node and system level by low-cost threads. The developed heterogeneous multicoprocessing infrastructure is utilized to evaluate diverse policies for power-aware computing in terms of \u2026",
            "Abstract entirety": 0,
            "Author pub id": "TKtxe-UAAAAJ:xtRiw3GOFMkC",
            "Publisher": "ACM"
        },
        {
            "Title": "Multi-FPGA evaluation platform for disaggregated computing",
            "Publication year": 2017,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/7966678/",
            "Abstract": "We present a versatile FPGA-based evaluation platform for exploring alternative execution strategies on disaggregated environments for applications, considering different processing block types: compute cores, memory, and accelerators. Developers can interconnect different blocks types in order to create optimal configurations. A user-level software library allows quick mapping of applications on real hardware. We have implemented a fully working prototype using three ZC706 FPGA boards, and evaluated different software / hardware configurations of a matrix multiplication benchmark.",
            "Abstract entirety": 1,
            "Author pub id": "TKtxe-UAAAAJ:ye4kPcJQO24C",
            "Publisher": "IEEE"
        },
        {
            "Title": "A framework for enabling fault tolerance in reconfigurable architectures",
            "Publication year": 2010,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-642-12133-3_24",
            "Abstract": "Fault tolerance is a pre-request not only for safety critical systems, but almost for the majority of applications. However, the additional hardware elements impose performance degradation. In this paper we propose a software-supported methodology for protecting reconfigurable architectures against Single Event Upsets (SEUs), even if the target device is not aware about this feature. This methodology initially predicts areas of the target architecture where faults are most possible to occur and then inserts selectively redundancy only there. Based on experimental results, we show that our proposed selectively fault-tolerance results to a better tradeoff between desired level of reliability and area, delay, power overhead.",
            "Abstract entirety": 1,
            "Author pub id": "TKtxe-UAAAAJ:aqlVkmm33-oC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "Scalable multigigabit pattern matching for packet inspection",
            "Publication year": 2008,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/4408588/",
            "Abstract": "In this paper, we consider hardware-based scanning and analyzing packets payload in order to detect hazardous contents. We present two pattern matching techniques to compare incoming packets against intrusion detection search patterns. The first approach, decoded partial CAM (DpCAM), predecodes incoming characters, aligns the decoded data, and performs logical and on them to produce the match signal for each pattern. The second approach, perfect hashing memory (PHmem), uses perfect hashing to determine a unique memory location that contains the search pattern and a comparison between incoming data and memory output to determine the match. Both techniques are well suited for reconfigurable logic and match about 2200 intrusion detection patterns using a single Virtex2 field-programmable gate-array device. We show that DpCAM achieves a throughput between 2 and 8 Gb/s requiring 0.58 \u2026",
            "Abstract entirety": 0,
            "Author pub id": "TKtxe-UAAAAJ:Tyk-4Ss8FVUC",
            "Publisher": "IEEE"
        },
        {
            "Title": "An efficient and low-cost input/output subsystem for network processors",
            "Publication year": 2002,
            "Publication url": "https://www.academia.edu/download/30794237/10.1.1.60.2374.pdf",
            "Abstract": "We present the architecture and implementation of an input/output subsystem for a cost-effective network processor. We believe that adding processing power to a networking chip is relatively straightforward. However, transferring data to and from the processor (s) is insufficient for high wire speeds. To address this limitation we use a hardwired input/output subsystem transferring data directly into the processing core\u2019s register file. Using a simple scalar RISC core at 200MHz, we are able to sustain state-full inspection firewall processing at 2.5 Gbps TCP traffic.",
            "Abstract entirety": 1,
            "Author pub id": "TKtxe-UAAAAJ:QIV2ME_5wuYC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Crossbar NoCs are scalable beyond 100 nodes",
            "Publication year": 2012,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/6171053/",
            "Abstract": "We describe the design and layout of a radix-128 crossbar in 90 nm CMOS. The data path is 32 bits wide and runs at 750 MHz using a three-stage pipeline, while fitting in a silicon area as small as 6.6 mm 2  by filling it at the 90% level. The control path occupies 7 mm 2  next to the data path by filling it at 35% level, and reconfigures the data path once every three clock cycles. Next, we arrange 128 1 mm 2  \u201cuser tiles\u201d around the crossbar, forming a 150 mm 2  die, and we connect all tiles to the crossbar via global links running on top of the tiles. Including the overhead of repeaters and flip flops on global links, the area cost of the crossbar is 11% of the die. Thus, we prove that crossbar networks-on-chips (NoCs) are small enough for radices exceeding by far the few tens of ports, that were believed to be the practical limit up to now, and reaching above 100 ports. We also attempt a first-order comparison between our \u2026",
            "Abstract entirety": 0,
            "Author pub id": "TKtxe-UAAAAJ:ns9cj8rnVeAC",
            "Publisher": "IEEE"
        },
        {
            "Title": "High-performance embedded architecture and compilation roadmap",
            "Publication year": 2007,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-540-71528-3_2",
            "Abstract": "One of the key deliverables of the EU HiPEAC FP6 Network of Excellence is a roadmap on high-performance embedded architecture and compilation \u2013 the HiPEAC Roadmap for short. This paper is the result of the roadmapping process that took place within the HiPEAC community and beyond. It concisely describes the key research challenges ahead of us and it will be used to steer the HiPEAC research efforts.The roadmap details several of the key challenges that need to be tackled in the coming decade, in order to achieve scalable performance in multi-core systems, and in order to make them a practical mainstream technology for high-performance embedded systems.The HiPEAC roadmap is organized around 10 central themes: (i) single core architecture, (ii) multi-core architecture, (iii) interconnection networks, (iv) programming models and tools, (v) compilation, (vi) run-time \u2026",
            "Abstract entirety": 0,
            "Author pub id": "TKtxe-UAAAAJ:zYLM7Y9cAGgC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "A decoupled access-execute architecture for reconfigurable accelerators",
            "Publication year": 2018,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/3203217.3203267",
            "Abstract": "Mapping computational intensive applications on reconfigurable technology for acceleration requires two main implementation parts:(a) the data plane, ie, efficient interconnected units that accelerate processing, and (b) the access-plane, ie, efficient ways to access data and transfer them to/from the accelerator. Data plane construction is well understood and mature tools-such as High Level Synthesis (HLS)-that produce efficient reconfigurable architectures exist. The access plane, however, is more challenging: data fetching for big-data and high-performance computing applications is even more complex and time consuming than processing.",
            "Abstract entirety": 1,
            "Author pub id": "TKtxe-UAAAAJ:7T2F9Uy0os0C",
            "Publisher": "Unknown"
        },
        {
            "Title": "Acceleration of computationally-intensive kernels in the reconfigurable era",
            "Publication year": 2012,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/6322874/",
            "Abstract": "One of the major topics that attracts constantly the interest of research community is the acceleration of computationally-intensive applications. Towards this direction, different technologies are competing each other and are all characterized by a common tendency; they evolve continuously towards improving their products so as to serve better their customers and attract new ones. Each company stresses the stronger advantages of its technology to convince people from academia and industry, and either individuals to use it. However, none of the existing technologies monopolizes all domains yet. This is because each one has its own benefits and drawbacks and cannot serve well all application domains. Another reason is that different people prefer to acquire skills in a specific technology and avoid switching between different technologies, even though this could benefit the application under development. Hence \u2026",
            "Abstract entirety": 0,
            "Author pub id": "TKtxe-UAAAAJ:35N4QoGY0k4C",
            "Publisher": "IEEE"
        },
        {
            "Title": "Data stream statistics over sliding windows: How to summarize 150 Million updates per second on a single node",
            "Publication year": 2019,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/8892241/",
            "Abstract": "Traditional data management systems map information using centralized and static data structures. Modern applications need to process in real time datasets much larger than system memory. To achieve this, they use dynamic entities that are updated with streaming input data over a sliding window. For efficient and high performance processing, approximate sketch synopses of input streams have been proposed as effective means for the summarization of streaming data over large sliding windows with probabilistic accuracy guarantees. This work presents a system-level solution to accelerate the Exponential Count-Min (ECM) sketch algorithm on reconfigurable technology. Different reconfigurable architectures for the sketch structure that correspond to different cost and performance tradeoffs are presented. We map the proposed system-level ECM sketch architectures to a high-end modern HPC platform to \u2026",
            "Abstract entirety": 0,
            "Author pub id": "TKtxe-UAAAAJ:0KyAp5RtaNEC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Enabling dynamically reconfigurable technologies in mid range computers through PCI express",
            "Publication year": 2014,
            "Publication url": "https://users.isc.tuc.gr/~kpapadimitriou/publications/2014wrc-EnabDynRecMidRangeCompPCIe.pdf",
            "Abstract": "Efficient I/O access is crucial in reconfigurable hardware platforms for implementing high-performance systems. Such platforms can outperform CPUs and GPGPUs in executing applications characterized by inherent parallelism. However, the system-level performance depends heavily on sustaining high transfer rates for feeding data into the reconfigurable hardware and getting the results back to the end-user. In the present work we propose and implement a hybrid system comprising a host computer and an FPGA platform. The latter acts as coprocessor into which hardware accelerators are loaded and executed in a transparent way, ie user is not involved in FPGA programming neither controlling its execution. Depending on the user request, the FPGA can be reconfigured either partially or entirely. Initially, we discuss the current state-of-the-art on I/O interfaces attached to FPGAs focusing primarily on the PCI Express (PCIe). Then, we present our system on which we implemented a design for measuring end-to-end throughput. We have developed a simple yet functional interface for serving the communication between software and hardware over PCIe v1. 0 bus. At system-level, we achieved a throughput of 544 MBytes/s and 618 MBytes/s for DMA writes and reads respectively, over a PCIe four-lane (x4) connection. This includes all overhead such as communication delays and systems calls for requesting services from the operating system. Our work can be used as the basis for programming and executing hardware accelerators under the control of a run-time system.",
            "Abstract entirety": 1,
            "Author pub id": "TKtxe-UAAAAJ:bnK-pcrLprsC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Fast, large-scale string match for a 10Gbps FPGA-based network intrusion detection system",
            "Publication year": 2003,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-540-45234-8_85",
            "Abstract": "Intrusion Detection Systems such as Snort scan incoming packets for evidence of security threats. The most computation-intensive part of these systems is a text search against hundreds of patterns, and must be performed at wire-speed. FPGAs are particularly well suited for this task and several such systems have been proposed. In this paper we expand on previous work, in order to achieve and exceed a processing bandwidth of 11Gbps. We employ a scalable, low-latency architecture, and use extensive fine-grain pipelining to tackle the fan-out, match, and encode bottlenecks and achieve operating frequencies in excess of 340MHz for fast Virtex devices. To increase throughput, we use multiple comparators and allow for parallel matching of multiple search strings. We evaluate the area and latency cost of our approach and find that the match cost per search pattern character is between 4 and 5 logic cells.",
            "Abstract entirety": 1,
            "Author pub id": "TKtxe-UAAAAJ:4OULZ7Gr8RgC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "Fast, FPGA-based Rainbow Table creation for attacking encrypted mobile communications",
            "Publication year": 2013,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/6645525/",
            "Abstract": "Encryption algorithms utilized in mobile communication systems have been under attack since their introduction, and many of these attacks have been successful in practical settings. One such example, A5/1 used in GSM, was attacked using \u201cRainbow Tables\u201d, i.e. pre-computed tables that trade long offline computation and large storage for runtime efficiency when cracking the code. Traditionally, Rainbow Tables were used to reverse password hashes. Their application against A5/1 opened up a new domain of exploitation. In this paper, we present an FPGA-based architecture for the efficient creation of Rainbow Tables for the A5/3 block cipher that is used in 2 nd  and 3 rd  generation mobile communication systems. The overall goal is to extract the encryption key, provided we have a ciphertext block under a known plaintext attack. The presented architecture exploits the parallelism in the Rainbow Table creation \u2026",
            "Abstract entirety": 0,
            "Author pub id": "TKtxe-UAAAAJ:_xSYboBqXhAC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Packet pre-filtering for network intrusion detection",
            "Publication year": 2006,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/4579536/",
            "Abstract": "As intrusion detection systems (IDS) utilize more complex syntax to efficiently describe complex attacks, their processing requirements increase rapidly. Hardware and, even more, software platforms face difficulties in keeping up with the computationally intensive IDS tasks, and face overheads that can substantially diminish performance. In this paper we introduce a packet pre-filtering approach as a means to resolve, or at least alleviate, the increasing needs of current and future intrusion detection systems. We observe that it is very rare for a single incoming packet to fully or partially match more than a few tens of IDS rules. We capitalize on this observation selecting a small portion from each IDS rule to be matched in the pre-filtering step. The result of this partial match is a small subset of rules that are candidates for a full match. Given this pruned set of rules that can apply to a packet, a second-stage, full-match \u2026",
            "Abstract entirety": 0,
            "Author pub id": "TKtxe-UAAAAJ:W7OEmFMy1HYC",
            "Publisher": "IEEE"
        },
        {
            "Title": "EXTRA: Towards the exploitation of eXascale technology for reconfigurable architectures",
            "Publication year": 2016,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/7533896/",
            "Abstract": "To handle the stringent performance requirements of future exascale-class applications, High Performance Computing (HPC) systems need ultra-efficient heterogeneous compute nodes. To reduce power and increase performance, such compute nodes will require hardware accelerators with a high degree of specialization. Ideally, dynamic reconfiguration will be an intrinsic feature, so that specific HPC application features can be optimally accelerated, even if they regularly change over time. In the EXTRA project, we create a new and flexible exploration platform for developing reconfigurable architectures, design tools and HPC applications with run-time reconfiguration built-in as a core fundamental feature instead of an add-on. EXTRA covers the entire stack from architecture up to the application, focusing on the fundamental building blocks for run-time reconfigurable exascale HPC systems: new chip \u2026",
            "Abstract entirety": 0,
            "Author pub id": "TKtxe-UAAAAJ:BrmTIyaxlBUC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Hardware task scheduling for partially reconfigurable FPGAs",
            "Publication year": 2015,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-319-16214-0_45",
            "Abstract": "Partial reconfiguration (PR) of FPGAs can be used to dynamically extend and adapt the functionality of computing systems, swapping in and out HW tasks. To coordinate the on-demand task execution, we propose and implement a run time system manager for scheduling software (SW) tasks on available processor(s) and hardware (HW) tasks on any number of reconfigurable regions of a partially reconfigurable FPGA. Fed with the initial partitioning of the application into tasks, the corresponding task graph, and the available task mappings, the RTSM considers the runtime status of each task and region, e.g. busy, idle, scheduled for reconfiguration/execution, etc., to execute tasks. Our RTSM supports task reuse and configuration prefetching to minimize reconfigurations, task movement among regions to efficiently manage the FPGA area, and RR reservation for future reconfiguration and execution. We \u2026",
            "Abstract entirety": 0,
            "Author pub id": "TKtxe-UAAAAJ:738O_yMBCRsC",
            "Publisher": "Springer, Cham"
        },
        {
            "Title": "A software-defined architecture and prototype for disaggregated memory rack scale systems",
            "Publication year": 2017,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/8344644/",
            "Abstract": "Disaggregation and rack-scale systems have the potential of drastically increasing TCO and utilization of cloud datacenters, while maintaining performance. In this paper, we present a novel rack-scale system architecture featuring software-defined remote memory disaggregation. Our hardware design and operating system extensions enable unmodified applications to dynamically attach to memory segments residing on physically remote memory pools and use such remote segments in a byte-addressable manner, as if they were local to the application. Our system features also a control plane that automates software-defined dynamic matching of compute to memory resources, as driven by datacenter workload needs. We prototyped our system on the commercially available Zynq Ultrascale+ MPSoC platform. To our knowledge, this is the first time a software-defined disaggregated system has been prototyped on \u2026",
            "Abstract entirety": 0,
            "Author pub id": "TKtxe-UAAAAJ:1yQoGdGgb4wC",
            "Publisher": "IEEE"
        },
        {
            "Title": "An Implementation of Operation-Based Prediction",
            "Publication year": 2001,
            "Publication url": "https://scholar.google.com/scholar?cluster=10354265734063855401&hl=en&oi=scholarr",
            "Abstract": "ory data. Prefetching guesses what memory data the program We describe the Slice Processor micro-architecture that imple-will need and attempts to read them in advance of the actual proments a generalized operation-based prefetching mechanism. gram references. If successful, prefetching reduces the negativeOperation-based prefetchers predict the series of operations, or impact of long memory latencies. While existing prefetching the computation slice that can be used to calculate forthcoming methods have been effective, there is a continuous need for memory references. This is in contrast to outcome-based predic-improvements main because memory latencies do not improve tors that exploit regularities in the address) outcome stream. as fast as processor clock speeds.",
            "Abstract entirety": 1,
            "Author pub id": "TKtxe-UAAAAJ:p__nRnzSRKYC",
            "Publisher": "ACM Press"
        },
        {
            "Title": "Hashing+ memory= low cost, exact pattern matching",
            "Publication year": 2005,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/1515696/",
            "Abstract": "In this paper we propose the combination of hashing and use of memory to achieve low cost, exact matching of SNORT-like intrusion signatures. The basic idea is to use hashing to generate a distinct address for each candidate pattern, which is stored in memory. Our implementation, hash-mem, uses simple CRC-style polynomials implemented with XOR gates, to achieve low cost hashing of the input patterns. We reduce the sparseness of the memory using an indirection memory that allows a compact storing of the search patterns and use a simple comparator to verify the match. Our implementation uses in the order of 0.15 logic cells per search pattern character, and a few tens of memory blocks, fitting comfortably in small or medium FPGA devices.",
            "Abstract entirety": 1,
            "Author pub id": "TKtxe-UAAAAJ:UeHWp8X0CEIC",
            "Publisher": "IEEE"
        },
        {
            "Title": "CCproc: A custom VLIW cryptography co-processor for symmetric-key ciphers",
            "Publication year": 2009,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-642-00641-8_35",
            "Abstract": "In this paper, we present CCProc, a flexible cryptography co-processor for symmetric-key algorithms. Based on an extensive analysis of many symmetric-key ciphers, including the five AES finalists, we designed an Instruction Set Architecture tailored to symmetric-key ciphers and built a hardware processor prototype by using the VHDL language. The design was mapped on FPGAs and ASIC. Results show a small-area design, while also supporting many ciphers. Besides flexibility, a 4-core FPGA design can achieve up to 615 Mbits/sec at 95 MHz for Rijndael.",
            "Abstract entirety": 1,
            "Author pub id": "TKtxe-UAAAAJ:WbkHhVStYXYC",
            "Publisher": "Springer, Berlin, Heidelberg"
        },
        {
            "Title": "dreddbox: Demonstrating disaggregated memory in an optical data centre",
            "Publication year": 2018,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/8386007/",
            "Abstract": "This paper showcases the first experimental demonstration of disaggregated memory using the dRedDbox optical Data Centre architecture. Experimental results demonstrate the 4-tier network scalability and performance of the system at the physical and application layer.",
            "Abstract entirety": 1,
            "Author pub id": "TKtxe-UAAAAJ:JQOojiI6XY0C",
            "Publisher": "IEEE"
        },
        {
            "Title": "Breaking the GSM A5/1 cryptography algorithm with rainbow tables and high-end FPGAS",
            "Publication year": 2012,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/6339146/",
            "Abstract": "A5 is the basic cryptographic algorithm used in GSM cell-phones to ensure that the user communication is protected against illicit acts. The A5/1 version was developed in 1987 and has since been under attack. The most recent attack on A5/1 is the \u201cA51 security project\u201d, led by Karsten Nohl that consists of the creation of rainbow tables that map the internal state of the algorithm with the keystream. Rainbow tables are efficient structures that allow the tradeoff between run-time (computations performed to crack a conversation) and space (memory to hold pre-computed information). In this paper we describe a very effective parallel architecture for the creation of the A5/1 rainbow tables in reconfigurable hardware. Rainbow table creation is the most expensive portion of cracking a particular encrypted information exchange. Our approach achieves almost 3000\u00d7 speedup over a single processor, and 2.5\u00d7 speedup \u2026",
            "Abstract entirety": 0,
            "Author pub id": "TKtxe-UAAAAJ:M05iB0D1s5AC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Developing RFID-based systems for security in marine transportations",
            "Publication year": 2012,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/6377366/",
            "Abstract": "In marine transportations it is important to control effectively the boarding and debarkation of passengers and vehicles, as well as to effectively monitor the cargo. These procedures are usually handled using conventional ways such as barcode-based tickets and scanners. This technology, although used widely, has significant drawbacks and is outdated. In the present project we propose the use of Radio Frequency Identification Technology (RFID) technology to control these procedures. This paper describes the initial concept, the possible ways to fit the RFID technology in marine sector and the initial considerations on system architecture. We discuss the benefits of RFID over the barcode-based system in the context of the specific domain, the problems that may arise with its use and possible ways to tackle them. The research is carried out within the framework of the ongoing project \"MERIT\" 1 .",
            "Abstract entirety": 1,
            "Author pub id": "TKtxe-UAAAAJ:g5m5HwL7SMYC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Design trade-offs in energy efficient NoC architectures",
            "Publication year": 2014,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/7008786/",
            "Abstract": "This paper studies design trade-offs in energy efficient Networks-on-Chip by evaluating every network architecture that derives when we apply all possible variations of design-configuration parameters on a baseline 2D mesh. Network separation (P), concentration (C), express channels (X), flit widths (W), and virtual channels (V). Our comperative analysis selects the network architecture configuration that gives the best energy delay product (EDP) while allowing a maximum area margin of 15% over the most energy efficient configuration of the baseline.",
            "Abstract entirety": 1,
            "Author pub id": "TKtxe-UAAAAJ:Tiz5es2fbqcC",
            "Publisher": "IEEE"
        },
        {
            "Title": "dReDBox: A Disaggregated Architectural Perspective for Data Centers",
            "Publication year": 2019,
            "Publication url": "https://link.springer.com/chapter/10.1007/978-3-319-92792-3_3",
            "Abstract": "Data centers are currently constructed with fixed blocks (blades); the hard boundaries of this approach lead to suboptimal utilization of resources and increased energy requirements. The dReDBox (disaggregated Recursive Datacenter in a Box) project addresses the problem of fixed resource proportionality in next-generation, low-power data centers by proposing a paradigm shift toward finer resource allocation granularity, where the unit is the function block rather than the mainboard tray. This introduces various challenges at the system design level, requiring elastic hardware architectures, efficient software support and management, and programmable interconnect. Memory and hardware accelerators can be dynamically assigned to processing units to boost application performance, while high-speed, low-latency electrical and optical interconnect is a prerequisite for realizing the concept of data center \u2026",
            "Abstract entirety": 0,
            "Author pub id": "TKtxe-UAAAAJ:ZfRJV9d4-WMC",
            "Publisher": "Springer, Cham"
        },
        {
            "Title": "FPGA-based design using the FASTER toolchain: the case of STM Spear development board",
            "Publication year": 2014,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/6924439/",
            "Abstract": "Even though FPGAs are becoming more and more popular as they are used in many different scenarios like communications and HPC, the steep learning curve needed to work with this technology is still the major limiting factor to their full success. Many works proposed to mitigate this problem by creating a companion of tools to support the designer during the development phase for this technology. The EU FASTER Project aims at realizing an integrated toolchain that assists the designer in the steps of the design flow that are necessary to port a given application onto an FPGA device. The novelty of the framework relies in the fact that the partial dynamic reconfiguration, which FPGA devices can exploit, is seen as a first class citizen throughout the whole design flow. This work reports a case study in which the FASTER toolchain has been used to port a raytracer application onto the STM Spear prototyping \u2026",
            "Abstract entirety": 0,
            "Author pub id": "TKtxe-UAAAAJ:OU6Ihb5iCvQC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Network Interface Design for Explicit Communication in Chip Multiprocessors",
            "Publication year": 2010,
            "Publication url": "https://www.taylorfrancis.com/chapters/edit/10.1201/b10477-23/network-interface-design-explicit-communication-chip-multiprocessors-stamatis-kavadias-manolis-katevenis-dionisios-pnevmatikatos?context=ubx",
            "Abstract": "Scalable on-chip networks define a new environment for network interfaces (NI) and communication of the interconnected devices. On-chip communicating nodes are usually involved in a computation framework, whose efficiency critically depends on the organization of resources as well as on the performance of the communication architecture. The principle of device networking was inspired by off-chip network architectures, such as those in the Local Area Network (LAN)/ Wide Area Network (WAN) or personal computer (PC) cluster domains, which however evolved in a different direction inEralight of their distinctive features, with complex protocols, robustness in the face of varying traffic patterns and latency not being a primary concern.",
            "Abstract entirety": 1,
            "Author pub id": "TKtxe-UAAAAJ:g3aElNc5_aQC",
            "Publisher": "Chapman and Hall/CRC"
        },
        {
            "Title": "ON OPTIMIZING ATLAS I, A 10GBPS ATM SWITCH",
            "Publication year": 2000,
            "Publication url": "https://www.worldscientific.com/doi/abs/10.1142/9789812793928_0014",
            "Abstract": "We present ATLAS II, an optimized version of the ATLAS I single chip switch. In ATLAS I we concentrated on correctness, while in ATLAS II we concentrate on optimizing the area and the performance of the switch. Our metrics for this optimization is the chip area, an indirect metric of the cost of the switch, and the cut-through latency, which is of paramount importance for the construction of computer networks, either in the form of parallel computers, or in the form of Clusters of Workstations. To achieve these goals we utilize improved design techniques and circuitry, and we eliminate functionalities of marginal benefit. We show that we can achieve significant latency and cost reduction, requiring only a small increment in manpower. We also evaluate scaling of the switch considering three important parameters: the cell buffer size, the rate of the serial links and the number of the links.",
            "Abstract entirety": 1,
            "Author pub id": "TKtxe-UAAAAJ:GnPB-g6toBAC",
            "Publisher": "Unknown"
        },
        {
            "Title": "A rate-based prefiltering approach to BLAST acceleration",
            "Publication year": 2008,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/4630026/",
            "Abstract": "DNA sequence comparison and database search have evolved in the last years as a field of strong competition between several reconfigurable hardware computing groups. In this paper we present a BLAST preprocessor that efficiently marks the parts of the database that may produce matches. Our prefiltering approach offers significant reduction in the size of the database that needs to be fully processed by BLAST, with a corresponding reduction in the run-time of the algorithm. We have implemented our architecture, evaluated its effectiveness for a variety of databases and queries, and compared its accuracy against the original NCBI Blast implementation. We have found that prefiltering offers at least a factor of 5 and up to 3 orders of magnitude reduction in the database space that needs to be fully searched. Due to its prefiltering nature, our approach can be combined with all major reconfigurable acceleration \u2026",
            "Abstract entirety": 0,
            "Author pub id": "TKtxe-UAAAAJ:_kc_bZDykSQC",
            "Publisher": "IEEE"
        },
        {
            "Title": "The combined input-output queued crossbar architecture for high-radix on-chip switches",
            "Publication year": 2014,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/6840829/",
            "Abstract": "High-radix, single-chip routers have emerged as efficient building blocks for interconnection networks. Researchers believe that hierarchical switch architectures are needed at high radices as crossbars scale with the square of the router radix. This article proposes a novel microarchitecture that allows flat crossbar switches to scale to 128 ports, supporting 32 Gbits per second per port (Gbps/port) while occupying 4.9 mm^2 and consuming 4.2 W, or supporting 64 Gbps/port at 7.5 mm^2 and 7.5 W, in 45-nm CMOS. Key features include deep crossbar pipelining to cope with wire delay, a novel cross-scheduler architecture to reduce wiring complexity, and catalytic custom gate placement within standard electronic design automation (EDA) flows. Furthermore, on a chip, crossbar speedup and combined I/O queuing (CIOQ) is better than hierarchical queueing, providing top performance with orders of magnitude lower \u2026",
            "Abstract entirety": 0,
            "Author pub id": "TKtxe-UAAAAJ:dshw04ExmUIC",
            "Publisher": "IEEE"
        },
        {
            "Title": "An architecture for the acceleration of a hybrid leaky integrate and fire SNN on the convey HC-2ex FPGA-based processor",
            "Publication year": 2017,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/7966649/",
            "Abstract": "Neuromorphic computing is expanding by leaps and bounds through custom integrated circuits (digital and analog), and large scale platforms developed by industry or government-funded projects (e.g. TrueNorth and BrainScaleS, respectively). Whereas the trend is for massive parallelism and neuromorphic computation in order to solve problems, such as those that may appear in machine learning and deep learning algorithms, there is substantial work on brain-like highly accurate neuromorphic computing in order to model the human brain. In such a form of computing, spiking neural networks (SNN) such as the Hodgkin and Huxley model are mapped to various technologies, including FPGAs. In this work, we present a highly efficient FPGA-based architecture for the detailed hybrid Leaky Integrate and Fire SNN that can simulate generic characteristics of neurons of the cerebral cortex. This architecture supports \u2026",
            "Abstract entirety": 0,
            "Author pub id": "TKtxe-UAAAAJ:LjlpjdlvIbIC",
            "Publisher": "IEEE"
        },
        {
            "Title": "Algorithm/architecture co-design for near-memory processing",
            "Publication year": 2018,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/3273982.3273992",
            "Abstract": "With mainstream technologies to couple logic tightly with memory on the horizon, near-memory processing has re-emerged as a promising approach to improving performance and energy for data-centric computing. DRAM, however, is primarily designed for density and low cost, with a rigid internal organization that favors coarse-grain streaming rather than byte-level random access. This paper makes the case that treating DRAM as a block-oriented streaming device yields significant efficiency and performance benefits, which motivate for algorithm/architecture co-design to favor streaming access patterns, even at the price of a higher order algorithmic complexity. We present the Mondrian Data Engine that drastically improves the runtime and energy efficiency of basic in-memory analytic operators, despite doing more work as compared to traditional CPU-optimized algorithms, which heavily rely on random \u2026",
            "Abstract entirety": 0,
            "Author pub id": "TKtxe-UAAAAJ:tzM49s52ZIMC",
            "Publisher": "ACM"
        },
        {
            "Title": "D7. 2.1: Project Management Plan",
            "Publication year": 2012,
            "Publication url": "https://scholar.google.com/scholar?cluster=712726602894785157&hl=en&oi=scholarr",
            "Abstract": "This document describes the general management procedures of the FASTER project. It compiles pertinent information from the official Technical Annex, and the project handbook, with a focus on the methods and techniques used during the project. Along with the more straightforward structural information that is largely expected to remain fixed during the execution of the project (partners, roles, etc), we include information about schedule and its management, financial and resource tracking, quality assurance, and risk analysis. Dissemination and exploitation management is kept short, since there are planned independent deliverables for this topic.",
            "Abstract entirety": 1,
            "Author pub id": "TKtxe-UAAAAJ:u9iWguZQMMsC",
            "Publisher": "Unknown"
        },
        {
            "Title": "ReSim, a trace-driven, reconfigurable ILP processor simulator",
            "Publication year": 2009,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/5090722/",
            "Abstract": "Modern processors are becoming more complex and as features and application size increase, their evaluation is becoming more time-consuming. To date, design space exploration relies on extensive use of software simulation that when highly accurate is slow. In this paper we propose ReSim, a parameterizable ILP processor simulation acceleration engine based on reconfigurable hardware. We describe ReSim's trace-driven microarchitecture that allows us to simulate the operation of a complex ILP processor in a cycle serial fashion, aiming to simplify implementation complexity and to boost operating frequency. Being trace driven, ReSim can simulate timing in an almost ISA independent fashion, and supports all SimpleScalar ISAs, i.e. PISA, Alpha, etc. We implemented ReSim for the latest Xilinx devices. In our experiments with a 4-way superscalar processor ReSim achieves a simulation throughput of up to \u2026",
            "Abstract entirety": 0,
            "Author pub id": "TKtxe-UAAAAJ:M3ejUd6NZC8C",
            "Publisher": "IEEE"
        },
        {
            "Title": "An open reconfigurable research platform as stepping stone to exascale high-performance computing",
            "Publication year": 2017,
            "Publication url": "https://ieeexplore.ieee.org/abstract/document/7927026/",
            "Abstract": "To handle the stringent performance and power requirements of future exascale-class applications, High Performance Computing (HPC) systems need ultra-efficient heterogeneous compute nodes and hardware accelerators with a high degree of specialization. Ideally, dynamic reconfiguration will be an intrinsic feature, so that specific HPC application features can be optimally accelerated, even if they regularly change over time. We create a new and flexible exploration platform for developing reconfigurable architectures, design tools and HPC applications with run-time reconfiguration built-in as a core fundamental feature instead of an add-on. Our project proposes an open research platform that covers the entire stack from architecture up to the application, focusing on the fundamental building blocks for run-time reconfigurable exascale HPC systems: new chip architectures with very low reconfiguration \u2026",
            "Abstract entirety": 0,
            "Author pub id": "TKtxe-UAAAAJ:Mojj43d5GZwC",
            "Publisher": "IEEE"
        },
        {
            "Title": "The mondrian data engine",
            "Publication year": 2017,
            "Publication url": "https://infoscience.epfl.ch/record/227947",
            "Abstract": "The increasing demand for extracting value out of ever-growing data poses an ongoing challenge to system designers, a task only made trickier by the end of Dennard scaling. As the performance density of traditional CPU-centric architectures stagnates, advancing compute capabilities necessitates novel architectural approaches. Near-memory processing (NMP) architectures are reemerging as promising candidates to improve computing efficiency through tight coupling of logic and memory. NMP architectures are especially fitting for data analytics, as they provide immense bandwidth to memory-resident data and dramatically reduce data movement, the main source of energy consumption. Modern data analytics operators are optimized for CPU execution and hence rely on large caches and employ random memory accesses. In the context of NMP, such random accesses result in wasteful DRAM row buffer activations that account for a significant fraction of the total memory access energy. In addition, utilizing NMP\u2019s ample bandwidth with fine-grained random accesses requires complex hardware that cannot be accommodated under NMP\u2019s tight area and power constraints. Our thesis is that efficient NMP calls for an algorithm-hardware co-design that favors algorithms with sequential accesses to enable simple hardware that accesses memory in streams. We introduce an instance of such a co-designed NMP architecture for data analytics, the Mondrian Data Engine. Compared to a CPU-centric and a baseline NMP system, the Mondrian Data Engine improves the performance of basic data analytics operators by up to 49\u00d7 and 5\u00d7, and efficiency \u2026",
            "Abstract entirety": 0,
            "Author pub id": "TKtxe-UAAAAJ:hkOj_22Ku90C",
            "Publisher": "Unknown"
        },
        {
            "Title": "VLSI micro-architectures for high-radix crossbar schedulers",
            "Publication year": 2011,
            "Publication url": "https://dl.acm.org/doi/abs/10.1145/1999946.1999981",
            "Abstract": "We study the scaling of parallel-matching crossbar schedulers to radices above 100. First, we examine a traditional microarchitecture that implements the matching decision of each input and each output of the crossbar in a separate arbiter block and communicates the matching decisions between the input and the output arbiters through global point-to-point links. Using simple models and experimentation with 90nm CMOS layouts, we show that this architecture is expensive because the global point-to-point links take up O (N 4) area, where N the radix of the crossbar. Next, by observing that the wiring of an arbiter fits in a minimal O (NlogN) area, we propose a novel microarchitecture that inverts the locality of wires by orthogonally interleaving the input with the output arbiters, thus lowering the wiring area of the scheduler down to O (N 2 log 2 N). Using this architecture, the scheduler for a radix-128 FIFO, VOQ, or 2 \u2026",
            "Abstract entirety": 0,
            "Author pub id": "TKtxe-UAAAAJ:RHpTSmoSYBkC",
            "Publisher": "Unknown"
        },
        {
            "Title": "Session details: A cache memory management for performance and reliability",
            "Publication year": 2017,
            "Publication url": "https://dl.acm.org/doi/abs/10.5555/3130379.3252803",
            "Abstract": "Session details: A cache memory management for performance and reliability | \nProceedings of the Conference on Design, Automation & Test in Europe ACM Digital \nLibrary home ACM home Google, Inc. (search) Advanced Search Browse About Sign in \nRegister Advanced Search Journals Magazines Proceedings Books SIGs Conferences \nPeople More Search ACM Digital Library SearchSearch Advanced Search Browse Browse \nDigital Library Collections More HomeBrowse by TitleProceedingsDATE '17Session details: \nA cache memory management for performance and reliability section Session details: A \ncache memory management for performance and reliability Share on Editors: Dionisios N \nPnevmatikatos profile image Dionisios Pnevmatikatos Technical University of Crete, GR \nTechnical University of Crete, GR View Profile , Cristina Silvano profile image Cristina \nSilvano Politecnico di Milano, IT Politecnico di , : '\u2026",
            "Abstract entirety": 0,
            "Author pub id": "TKtxe-UAAAAJ:tKAzc9rXhukC",
            "Publisher": "Unknown"
        }
    ]
}]