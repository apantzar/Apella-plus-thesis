Title,Publication Year,Publication url,Abstract,Abstract entirety
Web Service Composition Using a Deductive XML Rule,0,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.97.3203&rep=rep1&type=pdf,"This paper describes a knowledge-based Web Service composition system, called SWIM, which is based on the Service Domain model. Service Domains are communities of related Web Services that are mediated by a single Web Service, called the Mediator Service, which functions as a proxy for them. When a requestor sends a message to the Mediator Service one or more of the related Web Services are selected to dispatch the message and the results returned are aggregated to a single answer to the requestor. Mediator Services can be further composed to more complex Mediator Services that combine several selection and aggregation algorithms among many heterogeneous web services. The system utilizes the X-DEVICE deductive XML rule language for defining complex algorithms for selecting registered web services, combining the results, and synchronizing the workflow of information among the combined web services in a declarative way. In the paper, we demonstrate the flexibility and expressibility of our approach for composing Web Services using several e-business examples, covering most of the workflow patterns found in a comprehensive workflow management system [2].",1
Useful Links,0,https://scholar.google.com/scholar?cluster=7745661753836984991&hl=en&oi=scholarr,"Machine Learning is a subfield of Artificial Intelligence that is concerned with algorithms and techniques that allow computer systems to “learn from experience” to successfully solve artificial intelligence problems. Experience is usually provided in the form of problem-specific “examples”(organized in “datasets”) that allow the learning system to discover new knowledge and improve its performance on a particular task. If the training examples are not available at the beginning of the learning process, but they are collected during training we have the case of “on-line” or incremental learning. If the system is already provided some knowledge about the domain and/or the task, we have the case of knowledge refinement or analytical learning.Machine Learning problems are generally distinguished into three main categories depending on the nature of the datasets: In supervised learning, we are given a set of labeled …",0
MIREX AUDIO TAG CLASSIFICATION,0,https://www.music-ir.org/mirex/abstracts/2008/auth.pdf,"This extended abstract details a submission to the Music Information Retrieval Evaluation eXchange in the audio tag classification task, a new task introduced this year. We model the problem as a multilabel classification task and employ suitable learning algorithms from the Mulan toolkit 1.",1
InterBase-KB: Integrating a knowledge base system with a multidatabase system for data warehousing,2003,https://ieeexplore.ieee.org/abstract/document/1232272/,"This paper describes the integration of a multidatabase system and a knowledge-base system to support the data-integration component of a data warehouse. The multidatabase system integrates various component databases with a common query language; however, it does not provide capability for schema integration and other utilities necessary for data warehousing. In addition, the knowledge base system offers a declarative logic language with second-order syntax but first-order semantics for integrating the schemes of the data sources into the warehouse and for defining complex, recursively defined materialized views. Furthermore, deductive rules are also used for cleaning, checking the integrity and summarizing the data imported into the data warehouse. The knowledge base system features an efficient incremental view maintenance mechanism that is used for refreshing the data warehouse, without …",0
Modelling constraints with exceptions in object-oriented databases,1994,https://link.springer.com/chapter/10.1007/3-540-58786-1_80,"This paper deals with modelling constraints in object-oriented databases, with emphasis given on exceptions. Constraints are restrictions on properties and relations of database objects that ensure the integrity of data. Therefore, they should be obeyed by every object, but as in real-life, there are some exceptions to this rule. Object-oriented databases provide rich semantic constructs, adequate to model real-world relations. Inheritance of constraints in object-oriented databases has been treated in a completely mandatory way, providing no room for exceptions. In this paper, an object-oriented constraint representation scheme is presented, along with a methodology for modelling constraint exceptions. Finally, an algorithm is described that ensures correct runtime resolution of constraint applicability. Since business is not in abstract, but in real-world, business database modelling would be greatly benefited …",0
Combinatorial Optimization,1976,https://scholar.google.com/scholar?cluster=4173281276403659515&hl=en&oi=scholarr,Unknown,1
Socialsensor: Finding diverse images at mediaeval 2014,2014,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.664.8925&rep=rep1&type=pdf,"This paper describes the participation of the SosialSensor team in the Retrieving Diverse Social Images Task of MediaEval 2014. All our entries are produced by a different instantiation (set of features, parameter configuration) of the same diversification algorithm that optimizes a joint relevance-diversity criterion. All our runs are automated and use only resources given by the task organizers. Our best results in terms of the official ranking metric (F1@ 20≈ 0.59) came by the runs that combine visual and textual information, followed by the visual-only run.",1
StackTIS: A stacked generalization approach for effective prediction of translation initiation sites,2012,https://www.sciencedirect.com/science/article/pii/S0010482511002058,"The prediction of the translation initiation site in an mRNA or cDNA sequence is an essential step in gene prediction and an open research problem in bioinformatics. Although recent approaches perform well, more effective and reliable methodologies are solicited. We developed an adaptable data mining method, called StackTIS, which is modular and consists of three prediction components that are combined into a meta-classification system, using stacked generalization, in a highly effective framework. We performed extensive experiments on sequences of two diverse eukaryotic organisms (Homo sapiens and Oryza sativa), indicating that StackTIS achieves statistically significant improvement in performance.",1
Exploiting State Constraints in Heuristic State-Space Planning.,2000,https://www.aaai.org/Papers/AIPS/2000/AIPS00-040.pdf,"In the last years, some very promising domain independent heuristic state-space planners for STRIPS worlds, like ASP/HSP, HSPr and GRT, have been presented. These planners achieve remarkable performance in some domains, like the blocks world, the logistics and the gripper, but they are not effective in other domains, like the grid and the mystery. In this paper we propose the use of state constraints in heuristic state space planning. We claim that one of the causes for the pre-mentioned failures is the absence of domain specific knowledge about properties that characterize every valid and complete state. We propose the inclusion of state constraints in the domain definition and we present how they can be exploited by heuristic planners in order to decompose a problem into subproblems that are easily solvable. We give performance results that exhibit significant speedup in the problem solving process …",0
ISLE: an intelligent system for land evaluation,1999,https://www.researchgate.net/profile/Grigorios-Tsoumakas/publication/2593759_ISLE_An_Intelligent_System_for_Land_Evaluation/links/0f317531a4d5563d5c000000/ISLE-An-Intelligent-System-for-Land-Evaluation.pdf,"Land evaluation is a process that requires the information of a GIS (Geographical Information System) and the expertise of a specialised soil scientist to analyse and interpret this information. Visualising the whole process is a subject of great importance, especially when vast land areas are regarded. This paper presents ISLE, an intelligent system for land evaluation that automates the process of evaluation and graphically illustrates the results on digital maps. Its main features are the support of GIS capabilities on the digital map of an area, and the support of expert analysis of regions of this area, through one sophisticated user interface. ISLE’s knowledge base, models the evaluation of land in accordance with the FAO-SYS model for Land Evaluation. The system has as input a digital map of an area and its geographical database, displays this map, evaluates the land units selected by the user and finally visualises the results colouring properly the analysed land units.",1
Large-scale semantic indexing and question answering in biomedicine,2016,https://www.aclweb.org/anthology/W16-3107.pdf,"In this paper we present the methods and approaches employed in terms of our participation in the 2016 version of the BioASQ challenge. For the semantic indexing task, we extended our successful ensemble approach of last year with additional models. The official results obtained so-far demonstrate a continuing consistent advantage of our approaches against the National Library of Medicine (NLM) baselines. For the question answering task, we extended our approach on factoid questions, while we also developed approaches for the document, concept and snippet retrieval sub-tasks.",1
Mining frequent patterns and association rules from biological data,2014,http://www.gtzanis.gr/files/pubs/Kavakiotis_BKDH14.pdf,"During the last years biology and computer science have been characterized by major advances that have attracted a lot of interest. Nowadays the collaboration between biologists and computer scientists is deemed a vital necessity for the further progress of biological research. Bioinformatics is a novel research area that has emerged as a solution to the aforementioned need for collaboration. Two relative subfields of computer science, data mining and machine learning, have provided biologists, as well as experts from other areas, a powerful set of tools to analyze new data types in order to extract various types of knowledge efficiently and effectively. These tools combine powerful techniques of artificial intelligence, statistics, mathematics, and database technology. This fusion of technologies aims to overcome the obstacles and constraints posed by the traditional statistical methods.Association rules mining has attracted the attention of the data mining research community since the early 90s, as a means of unsupervised, exploratory data analysis. Association rules were first introduced by Agrawal et al.(1993) as a market basket analysis tool, however since then, they have been effectively applied to many other application domains, including biology and bioinformatics. An association rule implies the co-existence of a number of items in a portion of a transaction database. The goal of this exploratory data analysis is to provide the decision maker with valuable knowledge about a certain domain modeled by a transaction database. The frequent existence of two or more items in the same transaction implies a relationship among them. For example …",0
Semantic awareness in automated web service composition through planning,2010,https://link.springer.com/chapter/10.1007/978-3-642-12842-4_16,"PORSCE II is a framework that performs automatic web service composition by transforming the composition problem into AI planning terms and utilizing external planners to obtain solutions. A distinctive feature of the system is that throughout the entire process, it achieves semantic awareness by exploiting semantic information extracted from the OWL-S descriptions of the available atomic web services and the corresponding ontologies. This information is then used in order to enhance the planning domain and problem. Semantic awareness facilitates approximations when searching for suitable atomic services, as well as modification of the produced composite service. The alternatives for modification include the replacement of a certain atomic service that takes part in the composite service by an equivalent or a semantically relevant service, the replacement of an atomic service through planning, or the …",0
Combining progression and regression in state-space heuristic planning,2001,Unknown,Unknown,1
On determining and completing incomplete states in STRIPS Domains,1999,https://ieeexplore.ieee.org/abstract/document/810279/,"GRT is an effective domain-independent heuristic for STRIPS worlds, based on greedy regression tables. The heuristic is able to provide quite accurate estimates for the distances between the intermediate states and the goals, guiding in this way the search of any state-space planner. This estimation is performed by repeatedly applying 'inverted' actions to the goals, trying to achieve the facts of the domain. The problem with this approach is that in many problem instances the goals do not constitute a complete state, so it is impossible to apply actions to them, since the preconditions of no one action are included within the goals. The solution adopted initially was to manually enriching the goals with more facts, that are not in contradiction with the existing ones. In this paper we present some approaches to automatically detect and complete incomplete (goal) states and test the impact of these algorithms to the GRT …",0
Applying adaptive prediction to sea-water quality measurements,2009,https://www.sciencedirect.com/science/article/pii/S0957417408005551,"This study explores the possibility of using adaptive filters to predict sea-water quality indicators such as water temperature, pH and dissolved oxygen based on measurements produced by an under-water measurement set-up. Two alternative adaptive approaches are tested, namely a projection algorithm and a least squares algorithm. These algorithms were chosen for comparison because they are widely used prediction algorithms. The results indicate that if the measurements remain reasonably stationary, it is possible to make one-day ahead predictions, which perform better than the prediction that the value of a certain quality variable tomorrow is going to be equal to the value today.",1
A synergy of planning and ontology concept ranking for semantic web service composition,2008,https://link.springer.com/chapter/10.1007/978-3-540-88309-8_5,"This paper presents a prototype system that exploits planning and an ontology concept ranking algorithm for composing semantic Web services (PORSCE). The system exploits the inferencing capabilities of a Description Logics Reasoner in order to compute the subsumption hierarchy of the ontologies whose concepts are used in the OWL-S Profile descriptions as input and output concepts. The concept ranking algorithm is applied over this hierarchy in order to determine similar concepts based on different degrees of semantic matching relaxation, such as subclass or sibling hierarchical relationships. The domain independent planning system’s role is to semantically search the space of possible compositions of Web services, generating plans according to the desirable level of relaxation.",1
An interoperable and scalable Web-based system for classifier sharing and fusion,2007,https://www.sciencedirect.com/science/article/pii/S0957417406001965,"This paper describes CSF/DC, a Web-based system for classifier sharing and fusion. CSF/DC enables the sharing of classification models, by allowing the upload and download of such models expressed in the industry standard PMML language on the system’s online classifier repository. CSF/DC also leverages the individual knowledge shared by such (potentially heterogeneous) classification models and offers quality decision support to any user with an Internet connection through a guided procedure. However, some organizations or individuals might want to share the predictive capabilities of their classification models without compromising their internal structure. This is accommodated by CSF/DC through the use of Web services. Specifically, CSF/DC allows the participation of classifier Web services in the decision fusion process, by offering the necessary online mechanisms for the registration and …",0
A novel approach for incremental uncertainty rule generation from databases with missing values handling: Application to dynamic medical databases,2005,https://www.tandfonline.com/doi/abs/10.1080/14639230500209336,"Current approaches for mining association rules usually assume that the mining is performed in a static database, where the problem of missing attribute values does not practically exist. However, these assumptions are not preserved in some medical databases, like in a home care system. In this paper, a novel uncertainty rule algorithm is illustrated, namely URG-2 (Uncertainty Rule Generator), which addresses the problem of mining dynamic databases containing missing values. This algorithm requires only one pass from the initial dataset in order to generate the item set, while new metrics corresponding to the notion of Support and Confidence are used. URG-2 was evaluated over two medical databases, introducing randomly multiple missing values for each record's attribute (rate: 5 – 20% by 5% increments) in the initial dataset. Compared with the classical approach (records with missing values are ignored …",0
A heuristic for planning based on action evaluation,2002,https://link.springer.com/chapter/10.1007/3-540-46148-5_7,"This paper proposes a domain independent heuristic for regression planners, which is based on action evaluation. The heuristic obtains estimates for the cost of applying each action of the domain by performing a forward search in a relaxed version of the initial problem. The estimates for the actions are then utilized in a backward search on the original problem. The heuristic, which has been further refined by a fact ordering and several domain-analysis techniques, has been implemented in AcE (Action Evaluation), a regression, heuristic planner. AcE has been thoroughly tested on a variety of planning problems, from the AIPS competitions with quite promising results.",1
An open learning environment for thermal phenomena,2001,http://gnosis.library.ucy.ac.cy/handle/7/64399,"In this work we present an open learning environment, suitable for teaching Heat and Thermodynamics. The software consists of two independent visual laboratories (one for Heat and the other for Thermodynamics) and a series of relevant multimedia themes on technology and everyday life. The package has an open and dynamic structure, that allows the teacher to compose virtual experiments and re-organise the available multimedia themes, according to the needs of his class. And a pilot evaluation based on the attitudes of experiences physics teachers is also presented.",1
An empirical study of multi-label learning methods for video annotation,2009,https://ieeexplore.ieee.org/abstract/document/5137810/,This paper presents an experimental comparison of different approaches to learning from multi-labeled video data. We compare state-of-the-art multi-label learning methods on the Media mill Challenge dataset. We employ MPEG-7 and SIFT-based global image descriptors independently and in conjunction using variations of the stacking approach for their fusion. We evaluate the results comparing the different classifiers using both MPEG-7 and SIFT-based descriptors and their fusion. A variety of multi-label evaluation measures is used to explore advantages and disadvantages of the examined classifiers. Results give rise to interesting conclusions.,1
DR-DEVICE: A defeasible logic system for the Semantic Web,2004,https://link.springer.com/chapter/10.1007/978-3-540-30122-6_10,"This paper presents DR-DEVICE, a system for defeasible reasoning on the Web. Defeasible reasoning is a rule-based approach for efficient reasoning with incomplete and inconsistent information. Such reasoning is, among others, useful for ontology integration, where conflicting information arises naturally; and for the modeling of business rules and policies, where rules with exceptions are often used. In this paper we describe these scenarios in more detail along with the implementation of the DR-DEVICE system, which is capable of reasoning about RDF data over multiple Web sources using defeasible logic rules. The system is implemented on top of CLIPS production rule system and builds upon R-DEVICE, an earlier deductive rule system over RDF data that also supports derived attribute and aggregate attribute rules. Rules can be expressed either in a native CLIPS-like language, or in an extension of …",0
An ensemble of classifiers for coping with recurring contexts in data streams,2008,https://ebooks.iospress.nl/volumearticle/4488,"This paper proposes a general framework for classifying data streams by exploiting incremental clustering in order to dynamically build and update an ensemble of incremental classifiers. To achieve this, a transformation function that maps batches of examples into a new conceptual feature space is proposed. The clustering algorithm is then applied in order to group different concepts and identify recurring contexts. The ensemble is produced by maintaining an classifier for every concept discovered in the stream",1
The GRT planning system: Backward heuristic construction in forward state-space planning,2001,https://www.jair.org/index.php/jair/article/view/10281,"This paper presents GRT, a domain-independent heuristic planning system for STRIPS worlds. GRT solves problems in two phases. In the pre-processing phase, it estimates the distance between each fact and the goals of the problem, in a backward direction. Then, in the search phase, these estimates are used in order to further estimate the distance between each intermediate state and the goals, guiding so the search process in a forward direction and on a best-first basis. The paper presents the benefits from the adoption of opposite directions between the preprocessing and the search phases, discusses some difficulties that arise in the pre-processing phase and introduces techniques to cope with them. Moreover, it presents several methods of improving the efficiency of the heuristic, by enriching the representation and by reducing the size of the problem. Finally, a method of overcoming local optimal states, based on domain axioms, is proposed. According to it, difficult problems are decomposed into easier sub-problems that have to be solved sequentially. The performance results from various domains, including those of the recent planning competitions, show that GRT is among the fastest planners.",1
ESSE: an expert system for software evaluation,1999,https://www.sciencedirect.com/science/article/pii/S0950705199000313,"Solving software evaluation problems is a particularly difficult software engineering process and many different—often contradictory—criteria must be considered in order to reach a decision. This paper presents ESSE, a prototype expert system for software evaluation that embodies various aspects of the Multiple-Criteria Decision Aid (MCDA) methodology. Its main features are the flexibility in problem modeling and the built-in knowledge about software problem solving and software attribute assessment. Evaluation problems are modeled around top-level software attributes, such as quality and cost. Expert assistants guide the evaluator in feeding values to the decision model. ESSE covers all important dimensions of software evaluation through the integration of different technologies.",1
Multi-label classification methods for multi-target regression,2012,https://www.academia.edu/download/34394145/1211.6581v4.pdf,"Real world prediction problems often involve the simultaneous prediction of multiple target variables using the same set of predictive variables. When the target variables are binary, the prediction task is called multi-label classification while when the target variables are realvalued the task is called multi-target regression. Although multi-target regression attracted the attention of the research community prior to multi-label classification, the recent advances in this field motivate a study of whether newer state-of-the-art algorithms developed for multilabel classification are applicable and equally successful in the domain of multi-target regression. In this paper we introduce two new multitarget regression algorithms: multi-target stacking (MTS) and ensemble of regressor chains (ERC), inspired by two popular multi-label classification approaches that are based on a single-target decomposition of the multi-target problem and the idea of treating the other prediction targets as additional input variables that augment the input space. Furthermore, we detect an important shortcoming on both methods related to the methodology used to create the additional input variables and develop modified versions of the algorithms (MTSC and ERCC) to tackle it. All methods are empirically evaluated on 12 real-world multi-target regression datasets, 8 of which are first introduced in this paper and are made publicly available for future benchmarks. The experimental results show that ERCC performs significantly better than both a strong baseline that learns a single model for each target using bagging of regression trees and the state-of-the-art multi-objective random …",0
Multi-target regression via random linear target combinations,2014,https://link.springer.com/chapter/10.1007/978-3-662-44845-8_15,"Multi-target regression is concerned with the simultaneous prediction of multiple continuous target variables based on the same set of input variables. It arises in several interesting industrial and environmental application domains, such as ecological modelling and energy forecasting. This paper presents an ensemble method for multi-target regression that constructs new target variables via random linear combinations of existing targets. We discuss the connection of our approach with multi-label classification algorithms, in particular RAkEL, which originally inspired this work, and a family of recent multi-label classification algorithms that involve output coding. Experimental results on 12 multi-target datasets show that it performs significantly better than a strong baseline that learns a single model for each target using gradient boosting and compares favourably to multi-objective random forest approach …",0
Multiobjective heuristic state-space planning,2003,https://www.sciencedirect.com/science/article/pii/S0004370202003715,"Modern domain-independent heuristic planners evaluate their plans on the single basis of their length. However, in real-world problems, there are other criteria that also play an important role, eg, resource consumption, profit, safety, etc. This paper enhances the GRT planner, an efficient domain-independent heuristic state-space planner, with the ability to consider multiple criteria. The GRT heuristic is based on the estimation of the distances between each fact of a problem and the goals. The new planner, called MO-GRT, uses a weighted A∗ strategy and a multiobjective heuristic function, computed over a weighted hierarchy of user-defined criteria. Its computation is based on sets of non-dominated cost-vectors assigned to the problem facts, which estimate the total cost of achieving the facts from the goals, using alternative paths. Experiments show that a change in the criteria weights or scales affects both the …",0
Regression via Classification applied on software defect estimation,2008,https://www.sciencedirect.com/science/article/pii/S0957417407000875,"In this paper we apply Regression via Classification (RvC) to the problem of estimating the number of software defects. This approach apart from a certain number of faults, it also outputs an associated interval of values, within which this estimate lies with a certain confidence. RvC also allows the production of comprehensible models of software defects exploiting symbolic learning algorithms. To evaluate this approach we perform an extensive comparative experimental study of the effectiveness of several machine learning algorithms in two software data sets. RvC manages to get better regression error than the standard regression approaches on both datasets.",1
Greedy regression ensemble selection: Theory and an application to water quality prediction,2008,https://www.sciencedirect.com/science/article/pii/S0020025508001576,"This paper studies the greedy ensemble selection family of algorithms for ensembles of regression models. These algorithms search for the globally best subset of regressors by making local greedy decisions for changing the current subset. We abstract the key points of the greedy ensemble selection algorithms and present a general framework, which is applied to an application domain with important social and commercial value: water quality prediction.",1
Knowledge based evaluation of software systems: a case study,2000,https://www.sciencedirect.com/science/article/pii/S0950584999000932,"Solving software evaluation problems is a particularly difficult software engineering process and many contradictory criteria must be considered to reach a decision. Nowadays, the way that decision support techniques are applied suffers from a number of severe problems, such as naive interpretation of sophisticated methods and generation of counter-intuitive, and therefore most probably erroneous, results. In this paper we identify some common flaws in decision support for software evaluations. Subsequently, we discuss an integrated solution through which significant improvement may be achieved, based on the Multiple Criteria Decision Aid methodology and the exploitation of packaged software evaluation expertise in the form of an intelligent system. Both common mistakes and the way they are overcome are explained through a real world example.",1
GRT: a domain independent heuristic for STRIPS worlds based on greedy regression tables,1999,https://link.springer.com/chapter/10.1007/10720246_27,"This paper presents Greedy Regression Tables (GRT), a new domain independent heuristic for STRIPS worlds. The heuristic can be used to guide the search process of any state-space planner, estimating the distance between each intermediate state and the goals. At the beginning of the problem solving process a table is created, the records of which contain the ground facts of the domain, among with estimates for their distances from the goals. Additionally, the records contain information about interactions that occur while trying to achieve different ground facts simultaneously. During the search process, the heuristic, using this table, extracts quite accurate estimates for the distances between intermediate states and the goals. A simple best-first search planner that uses this heuristic has been implemented in C++ and has been tested on several “classical” problem instances taken from the bibliography …",0
Transfer learning in multi-agent reinforcement learning domains,2011,https://link.springer.com/chapter/10.1007/978-3-642-29946-9_25,"In the context of reinforcement learning, transfer learning refers to the concept of reusing knowledge acquired in past tasks to speed up the learning procedure in new tasks. Transfer learning methods have been succesfully applied in single-agent reinforcement learning algorithms, but no prior work has focused on applying them in a multi-agent environment. We propose a novel method for transfer learning in multi-agent reinforcement learning domains. We proceed to test the proposed approach in a multi-agent domain under various configurations. The results demonstrate that the method can reduce the learning time and increase the asymptotic performance of the learning algorithm.",1
A survey of service composition in ambient intelligence environments,2013,https://link.springer.com/article/10.1007/s10462-011-9283-1,"This article presents a comparative review of systems performing service composition in Ambient Intelligence Environments. Such environments should comply to ubiquitous or pervasive computing guidelines by sensing the user needs or wishes and offering intuitive human-computer interaction and a comfortable non-intrusive experience. To achieve this goal service orientation is widely used and tightly linked with AmI systems. Some of these employ the Web Service technology, which involves well-defined web technologies and standards that facilitate interoperable machine to machine interaction. Other systems regard services of different technologies (e.g. UPnP, OSGi etc) or generally as abstractions of various actions. Service operations are sometimes implemented as software based functions or actions over hardware equipment (e.g. UPnP players). However, a single service satisfies an atomic only …",0
A review of multi-label classification methods,2006,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.474.6415&rep=rep1&type=pdf,"Nowadays, multi-label classification methods are increasingly required by modern applications, such as protein function classification, music categorization and semantic scene classification. This paper introduces the task of multi-label classification, organizes the sparse related literature into a structured presentation and performs comparative experimental results of certain multi-label classification methods. It also contributes the presentation of an undocumented method and the definition of a concept for the quantification of the multi-label nature of a data set.",1
An empirical study on sea water quality prediction,2008,https://www.sciencedirect.com/science/article/pii/S0950705108000506,"This paper studies the problem of predicting future values for a number of water quality variables, based on measurements from under-water sensors. It performs both exploratory and automatic analysis of the collected data with a variety of linear and nonlinear modeling methods. The paper investigates issues, such as the ability to predict future values for a varying number of days ahead and the effect of including values from a varying number of past days. Experimental results provide interesting insights on the predictability of the target variables and the performance of the different learning algorithms.",1
Ensemble pruning using reinforcement learning,2006,https://link.springer.com/chapter/10.1007/11752912_31,"Multiple Classifier systems have been developed in order to improve classification accuracy using methodologies for effective classifier combination. Classical approaches use heuristics, statistical tests, or a meta-learning level in order to find out the optimal combination function. We study this problem from a Reinforcement Learning perspective. In our modeling, an agent tries to learn the best policy for selecting classifiers by exploring a state space and considering a future cumulative reward from the environment. We evaluate our approach by comparing with state-of-the-art combination methods and obtain very promising results.",1
Clustering classifiers for knowledge discovery from physically distributed databases,2004,https://www.sciencedirect.com/science/article/pii/S0169023X03001538,"Most distributed classification approaches view data distribution as a technical issue and combine local models aiming at a single global model. This however, is unsuitable for inherently distributed databases, which are often described by more than one classification models that might differ conceptually. In this paper we present an approach for clustering distributed classifiers in order to discover groups of similar classifiers and thus similar databases with respect to a specific classification task. We also show that clustering distributed classifiers as a pre-processing step for classifier combination enhances the achieved predictive performance of the ensemble.",1
The PORSCE II framework: Using AI planning for automated semantic web service composition,2013,https://www.cambridge.org/core/journals/knowledge-engineering-review/article/porsce-ii-framework-using-ai-planning-for-automated-semantic-web-service-composition/5A80CDF3D9710EF6DDF6B5D3796AE784,"This paper presents PORSCE II, an integrated system that performs automatic Semantic Web service composition exploiting artificial intelligence (AI) techniques, specifically planning. Essential steps in achieving Web service composition include the translation of the Web service composition problem into a solver-ready planning domain and problem, followed by the acquisition of solutions, and the translation of the solutions back to Web service terms. The solutions to the problem, that is, the descriptions of the desired composite service, are obtained by means of external domain-independent planning systems, they are visualized and finally evaluated. Throughout the entire process, the system exploits semantic information extracted from the semantic descriptions of the available Web services and the corresponding ontologies, in order to perform composition under semantic awareness and relaxation.",1
Distributed data mining,2009,https://www.igi-global.com/chapter/distributed-data-mining/7907,"The continuous developments in information and communication technology have recently led to the appearance of distributed computing environments, which comprise several, and different sources of large volumes of data and several computing units. The most prominent example of a distributed environment is the Internet, where increasingly more databases and data streams appear that deal with several areas, such as meteorology, oceanography, economy and others. In addition the Internet constitutes the communication medium for geographicallydistributed information systems, as for example the earth observing system of NASA (eos. gsfc. nasa. gov). Other examples of distributed environments that have been developed in the last few years are sensor networks for process monitoring and grids where a large number of computing and storage units are interconnected over a highspeed network.",1
aWESoME: A web service middleware for ambient intelligence,2013,https://www.sciencedirect.com/science/article/pii/S0957417413000936,"This work presents a Web Service Middleware infrastructure for Ambient Intelligence environments, named aWESoME. aWESoME is a vital part of the Smart IHU project, a large-scale Smart University deployment. The purpose of the proposed middleware within the project is twofold: for one, to ensure universal, homogeneous access to the system’s functions and secondly, to fulfill functional and non-functional requirements of the system. Namely, the infrastructure itself should consume significantly low power (as it is meant for energy savings in addition to automations), without compromising reliability and fast response time. The infrastructure should enable fast and direct discovery, invocation and execution of services. Finally, on hardware level, the wireless sensor and actuator network should be optimally configured for speed and reliability as well. The proposed solution employs widely used web open standards …",0
On the discovery of weak periodicities in large time series,2002,https://link.springer.com/chapter/10.1007/3-540-45681-3_5,"The search for weak periodic signals in time series data is an active topic of research. Given the fact that rarely a real world dataset is perfectly periodic, this paper approaches this problem in terms of data mining, trying to discover weak periodic signals in time series databases, when no period length is known in advance. In existing time series mining algorithms, the period length is user-specified. We propose an algorithm for finding approximate periodicities in large time series data, utilizing autocorrelation function and FFT. This algorithm is an extension to the partial periodicity detection algorithm presented in a previous paper of ours. We provide some mathematical background as well as experimental results.",1
E-DEVICE: An extensible active knowledge base system with multiple rule type support,2000,https://ieeexplore.ieee.org/abstract/document/877511/,"This paper describes E-DEVICE, an extensible active knowledge base system (KBS) that supports the processing of event-driven, production, and deductive rules into the same active OODB system. E-DEVICE provides the infrastructure for the smooth integration of various declarative rule types, such as production and deductive rules, into an active OODB system that supports low-level event-driven rules only by: (1) mapping each declarative rule into one event-driven rule, offering centralized rule selection control for correct run-time behavior and conflict resolution, and (2) using complex events to map the conditions of declarative rules and monitor the database to incrementally match those conditions. E-DEVICE provides the infrastructure for easily extending the system by adding: (1) new rule types as subtypes of existing ones, and (2) transparent optimizations to the rule matching network. The resulting system is …",0
Learning to teach reinforcement learning agents,2019,https://www.mdpi.com/243736,"In this article, we study the transfer learning model of action advice under a budget. We focus on reinforcement learning teachers providing action advice to heterogeneous students playing the game of Pac-Man under a limited advice budget. First, we examine several critical factors affecting advice quality in this setting, such as the average performance of the teacher, its variance and the importance of reward discounting in advising. The experiments show that the best performers are not always the best teachers and reveal the non-trivial importance of the coefficient of variation (CV) as a statistic for choosing policies that generate advice. The CV statistic relates variance to the corresponding mean. Second, the article studies policy learning for distributing advice under a budget. Whereas most methods in the relevant literature rely on heuristics for advice distribution, we formulate the problem as a learning one and propose a novel reinforcement learning algorithm capable of learning when to advise or not. The proposed algorithm is able to advise even when it does not have knowledge of the student’s intended action and needs significantly less training time compared to previous learning approaches. Finally, in this article, we argue that learning to advise under a budget is an instance of a more generic learning problem: Constrained Exploitation Reinforcement Learning. View Full-Text",1
Rule-based approaches for energy savings in an ambient intelligence environment,2015,https://www.sciencedirect.com/science/article/pii/S1574119214000777,"This paper presents a novel real-world application for energy savings in a Smart Building environment. The proposed system unifies heterogeneous wireless sensor networks under a Semantic Web Service middleware. Two complementary and mutually exclusive rule-based approaches for enforcing energy-saving policies are proposed: a reactive agent based on production rules and a deliberative agent based on defeasible logic. The system was deployed at a Greek University, showing promising experimental results (at least 4% daily savings). Although the percentage of energy savings may seem low, the greatest merit of the method is ensuring that no energy is wasted by constantly enforcing the policies.",1
PersoNews: a personalized news reader enhanced by machine learning and semantic filtering,2006,https://link.springer.com/chapter/10.1007/11914853_62,"In this paper, we present a web-based, machine-learning enhanced news reader (PersoNews). The main advantages of PersoNews are the aggregation of many different news sources, machine learning filtering offering personalization not only per user but also for every feed a user is subscribed to, and finally the ability for every user to watch a more abstracted topic of interest by employing a simple form of semantic filtering through a taxonomy of topics.",1
Distributed data mining of large classifier ensembles,2002,http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.18.3906,"Nowadays, classifier ensembles are often used for distributed data mining in order to discover knowledge from inherently distributed information sources and scale up learning to very large databases. One of the most successful methods used for combining multiple classifiers is Stacking. However, this method suffers from very high computational cost in the case of large number of distributed nodes. This paper presents a new classifier combination strategy that scales up efficiently and achieves both high predictive accuracy and tractability of problems with high complexity. It induces a global model by learning from the averages of the local classifiers' output. This way, fast and effective combination of large number of classifiers is achieved.",1
Obtaining bipartitions from score vectors for multi-label classification,2010,https://ieeexplore.ieee.org/abstract/document/5670068/,"Multi-label classification is a popular learning task. However, some of the algorithms that learn from multi-label data, can only output a score for each label, so they cannot be readily used in applications that require bipartitions. In addition, several of the recent state-of-the-art multi-label classification algorithms, actually output a score vector primarily and employ one (sometimes simple) thresholding method in order to be able to output bipartitions. Furthermore, some approaches can naturally output both a score vector and a bipartition, but whether a better bipartition can be obtained through thresholding has not been investigated. This paper contributes a theoretical and empirical comparative study of existing thresholding methods, highlighting their importance for obtaining bipartitions of high quality.",1
Effective stacking of distributed classifiers,2002,https://books.google.com/books?hl=en&lr=&id=5ZuuF0ogxU4C&oi=fnd&pg=PA340&dq=info:MxbZXDZ6s8sJ:scholar.google.com&ots=e1jo7nR2EL&sig=RcuJTpc4HikaoBGH9YEDhvgwrKQ,"One of the most promising lines of research towards discovering global predictive models from physically distributed data sets is local learning and model integration. Local learning avoids moving raw data around the distributed nodes and minimizes com-munication, coordination and synchronization cost. However, the in-tegration of local models is not a straightforward process. Majority Voting is a simple solution that works well in some domains, but it does not always offer the best predictive performance. Stacking on the other hand, offers flexibility in modelling, but brings along the problem of how to train on sufficient and at the same time in-dependent data without the cost of moving raw data around the distributed nodes. In addition, the scalability of Stacking with respect to the number of distributed nodes is another important issue that has not yet been substantially investigated. This paper presents a framework for constructing a global predictive model from local classifiers that does not require moving raw data around, achieves high predictive accuracy and scales up efficiently with respect to large numbers of distributed data sets. of distributed nodes is another important issue that has not yet been substantially investigated. This paper presents a framework for combining distributed classi-fiers without moving raw data around that achieves high predictive accuracy and scales up efficiently with respect to large numbers of distributed data sets. The main contribution of this work is: i) a new methodology for training-based approaches to distributed data min-ing that avoids the problem of gathering parts of the raw data for training purposes and ii …",0
System architecture for a smart university building,2010,https://link.springer.com/chapter/10.1007/978-3-642-15825-4_64,"This paper presents a system architecture that provides smart building monitoring and management. The proposed solution integrates heterogeneous geographically disparate sensor networks and devices, and enables optimal operations of the building while reducing its energy footprint. The platform is based on Semantic Web Services composition using AI Planning, that integrates and manages WiFi, RFiD and ZigBee networks providing connectivity to the devices. The goal is to develop a model that follows the latest guidelines in the area of Information Communication Technologies (ICT) for sustainable growth, energy efficiency and better quality of life.",1
Improving diversity in image search via supervised relevance scoring,2015,https://dl.acm.org/doi/abs/10.1145/2671188.2749334,"Results returned by commercial image search engines should include relevant and diversified depictions of queries in order to ensure good coverage of users' information needs. While relevance has drastically improved in recent years, diversity is still an open problem. In this paper we propose a reranking method that could be implemented on top of such engines in order to provide a better balance between relevance and diversity. Our method formulates the reranking problem as an optimization of a utility function that jointly considers relevance and diversity. Our main contribution is the replacement of the unsupervised definition of relevance that is commonly used in this formulation with a supervised classification model that strives to capture a query and application-specific notion of relevance. This model provides more accurate relevance scores that lead to significantly improved diversification performance …",0
A defeasible logic reasoner for the semantic web,2004,https://link.springer.com/chapter/10.1007/978-3-540-30504-0_5,"Defeasible reasoning is a rule-based approach for efficient reasoning with incomplete and inconsistent information. Such reasoning is, among others, useful for ontology integration, where conflicting information arises naturally; and for the modeling of business rules and policies, where rules with exceptions are often used. This paper describes these scenarios in more detail, and reports on the implementation of a system for defeasible reasoning on the Web. The system is called DR-DEVICE and is capable of reasoning about RDF metadata over multiple Web sources using defeasible logic rules. The system is implemented on top of CLIPS production rule system and builds upon R-DEVICE, an earlier deductive rule system over RDF metadata that also supports derived attribute and aggregate attribute rules. Rules can be expressed either in a native CLIPS-like language, or in an extension of the OO …",0
Monitoring water quality through a telematic sensor network and a fuzzy expert system,2007,https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1468-0394.2007.00426.x," In this paper we present an expert system that monitors seawater quality and pollution in northern Greece through a sensor network called Andromeda. The expert system monitors sensor data collected by local monitoring stations and reasons about the current level of water suitability for various aquatic uses, such as swimming and piscicultures. The aim of the expert system is to help the authorities in the decision‐making process in the battle against pollution of the aquatic environment, which is vital for public health and the economy of northern Greece. The expert system determines, using fuzzy logic, when certain environmental parameters exceed certain pollution limits, which are specified either by the authorities or by environmental scientists, and flags up appropriate alerts.",1
R-DEVICE: an object-oriented knowledge base for RDF metadata,2006,https://www.igi-global.com/article/device-object-oriented-knowledge-base/2819,"In this paper we present R-DEVICE, a deductive object-oriented knowledge base system for reasoning over RDF metadata. R-DEVICE imports RDF documents into the CLIPS production rule system by transforming RDF triples into COOL objects and uses a deductive rule language for reasoning about them. R-DEVICE is based on an OO RDF data model, different than the established triple-based model, which maps resources to objects and encapsulates properties inside resource objects, as traditional OO attributes. In this way, fewer joins are required to access the properties of a single resource resulting in better inferencing/querying performance, as it is experimentally shown in the paper. Furthermore, RDF can interoperate seamlessly with other Web data models and languages. The descriptive semantics of RDF may call for dynamic redefinitions of resource classes, which are handled by R-DEVICE effectively …",0
A semantic recommendation algorithm for the PaaSport platform-as-a-service marketplace,2017,https://www.sciencedirect.com/science/article/pii/S0957417416305164,"Platform as a service (PaaS) is one of the Cloud computing services that provide a computing platform in the Cloud, allowing customers to develop, run, and manage web applications without the complexity of building and maintaining the infrastructure. The primary disadvantage for an SME to enter the emerging PaaS market is the possibility of being locked into a certain platform, mostly provided by the market's giants. The PaaSport project focuses on facilitating SMEs to deploy business applications on the best-matching Cloud PaaS offering and to seamlessly migrate these applications on demand, via a thin, non-intrusive Cloud-broker, in the form of a Cloud PaaS Marketplace. PaaSport enables PaaS provider SMEs to roll out semantically interoperable PaaS offerings, by annotating them using a unified PaaS semantic model that has been defined as an OWL ontology. In this paper we focus on the …",0
An empirical study on the combination of SURF features with VLAD vectors for image search,2012,https://ieeexplore.ieee.org/abstract/document/6226771/,"The study of efficient image representations has attracted significant interest due to the computational needs of large-scale applications. In this paper we study the performance of the recently proposed VLAD method for aggregating local image descriptors when combined with SURF features, in the domain of image search. The experiments show that when SURF features are used as local image descriptors, VLAD attains better performance compared to using SIFT features. We also study how the average number of local image descriptors extracted per image affects the performance and show that by controlling this number we are able to adjust the trade off between feature extraction time and search accuracy. Finally, we examine the retrieval performance of the proposed scheme with varying levels of distractor images.",1
RENEWABLE ENERGY FORECASTING,0,http://ikee.lib.auth.gr/record/330225/files/GRI-2021-30378.pdf,"The energy industry has seen an increased research interest in recent years. Especially in the renewable energy field there is a plethora of study cases since the start of the twenty first century. The great rise of the renewable energy usage, together with their unpredictability due to their dependence on weather conditions, has given birth to the much-needed renewable energy forecasting. Recent studies have shown that machine learning techniques can provide more accurate forecasting results. The objective of this thesis is the forecasting of renewable energy using machine learning and deep learning algorithms.More specifically, this particular case study makes use of two datasets, one for solar energy and one for wind energy, for the purpose of forecasting. The methodologies used are separated into three main categories: the short-term prediction of the generation of the next hour and the prediction of a predetermined forecast horizon in a multi-output approach and a recursive one. The different features that can be used in each approach are also examined, to best represent the determining factors of the renewable energy generation forecasting.",1
Pascal and Francis Bibliographic Databases,0,https://pascal-francis.inist.fr/vibad/index.php?action=getRecordDetail&idt=66345,"Sauf mention contraire ci-dessus, le contenu de cette notice bibliographique peut être utilisé dans le cadre d’une licence CC BY 4.0 Inist-CNRS/Unless otherwise stated above, the content of this bibliographic record may be used under a CC BY 4.0 licence by Inist-CNRS/A menos que se haya señalado antes, el contenido de este registro bibliográfico puede ser utilizado al amparo de una licencia CC BY 4.0 Inist-CNRS",1
E-DEVICE: An Extensible Knowledge Base System with Multiple Rule SupportV,0,https://scholar.google.com/scholar?cluster=16101248084592266448&hl=en&oi=scholarr,"This paper describes E-DEVICE, an extensible active knowledge base system (KBS) that supports the processing of event-driven, production, and deductive rules into the same active OODB system. E-DEVICE provides the infrastructure for the smooth integration of various declarative rule types into an active OODB system that supports low-level event-driven rules only by a) mapping each declarative rule into one event-driven rule, offering centralized rule selection control for correct run-time behavior and conflict resolution, and b) using complex events to map the conditions of production rules and monitor the database to incrementally match those conditions. E-DEVICE provides the infrastructure for easily extending the system by adding a) new rule types as subtypes of existing ones and b) transparent optimizations to the rule matching network. The resulting system is a flexible, yet efficient, KBS that gives the user …",0
The Tomaco Hybrid Matching Framework for SAWSDL Semantic Web Services,0,https://scholar.google.com/scholar?cluster=10995878620407084366&hl=en&oi=scholarr,"This work aims to advance Web Service retrieval, also known as Matching, in two directions. First, it introduces a matching algorithm for SAWSDL, which adapts and extends known concepts with novel strategies. Effective logic-based and syntactic strategies are introduced and combined in a novel hybrid strategy, targeting an envisioned well-defined, real-world scenario for matching. The algorithm is evaluated in a universal environment for matching algorithms, SME2, in an objective, reproducible manner. Evaluation ranks Tomaco high amongst state of the art, especially for early recall levels (first in macro-averaging precision, up to 0.7 recall). Secondly, this work introduces the Tomaco web application, which aims to promote wide-spread adoption of Semantic Web Services while targeting the lack of user-friendly applications in this field, by integrating a variety of configurable matching algorithms proposed in this …",0
AUTH-Atypon at BioASQ 3; Large-Scale Semantic Indexing and Question Answering in Bio-medicine,0,https://www.academia.edu/download/55539830/auth-atypon-bioasq.pdf,"In this paper we present the methods and the approaches employed in terms of our participation to the BioASQ Challenge 2015. The challenge comprises of two separate tasks; semantic annotation of scientific abstracts (task 3a) and question answering of biomedical natural language questions (task 3b). Based on the successful approaches of the previous years, with respect to task 3a, we considered a variety of ensembles, incorporated journal-specific semantic information and developed an approach to handle the concept drift within the BioASQ corpus. The official task 3a results demonstrate a consistent advantage of our approaches against the baselines. Specifically, the systems proposed by our team ranked among the top tier ones along the competition, obtaining the second place in 10 out of 15 weeks. Concerning task 3b, we further extended our previous work...",1
An Integrated Approach to Automated Semantic Web Service Composition through Planning,0,https://scholar.google.com/scholar?cluster=302871932684379364&hl=en&oi=scholarr,"The paper presents an integrated approach for automated semantic web service composition using AI planning techniques. An important advantage of this approach is that the composition process, as well as the discovery of the atomic services that take part in the composition, are significantly facilitated by the incorporation of semantic information. OWL-S web service descriptions are transformed into a planning problem described in a standardized fashion using PDDL, while semantic information is used for the enhancement of the composition process as well as for approximating the optimal composite service when exact solutions are not found. Solving, visualization, manipulation, and evaluation of the produced composite services are accomplished, while, unlike other systems, independence from specific planners is maintained. Implementation was performed through the development and integration of two …",0
Pascal and Francis Bibliographic Databases,0,https://pascal-francis.inist.fr/vibad/index.php?action=getRecordDetail&idt=150558,"Isolement d'une communauté microbienne dégradant l'acide 2, 4-dichlorophénoxyacétique à partir d'un sol de Dijon. Caractérisations cinétique et génétique des souches impliquées. 1992, 2 vol., 180 p, ref: 267 ref",1
The GRT Planner in the AIPS-00 Competition,0,https://scholar.google.com/scholar?cluster=15691314715949704928&hl=en&oi=scholarr,"This paper presents the GRT planner, a forward heuristic planner based on the Greedy Regression Tables approach, and comments on the results obtained from the AIPS-00 planning competition. GRT planner works in two phases. In the pre-processing phase, it estimates the distances between the domain's facts and the goals of the problem. During the search phase the estimates are utilized in order to guide a forward directed search. GRT participated in the STRIPS track of the competition and succeeded very promising results. Although it has not gained any prize, it gave us good prospects for the future.",1
The Organon and the logic perspective of computation,0,https://www.researchgate.net/profile/Panagiotis-Katsaros/publication/303407444_The_Organon_and_the_logic_perspective_of_computation/links/5742236a08ae9f741b3756ec/The-Organon-and-the-logic-perspective-of-computation.pdf,"At a moment of culmination of the philosophical thought, ancient Greek philosophers were focused on a rational explanation of the world based exclusively on evidence and reasoning. In this era, Aristotle saw the need for a separate discipline to study and develop the act of pure reason, irrespective of what it is about. He wrote five treatises, known collectively as the Organon, that are still the object of study and of inspiration for scholars around the world, towards the quest of new logical insights [1-12].Having seen the Organon as a tool used by all the sciences, Aristotle introduced a theory of deductive inferences, which are known as syllogisms. The syllogism is defined as “a logos (speech) in which, certain things having been supposed, something different from the things supposed results of necessity because of their being so”. However, logical inference is not a matter of the contents of the supposed things. Schemes with dummy letters (variables) are used to stand for the terms (subjects and predicates) in the premises, like eg that “All A are B” or that “No B is C”. A scheme cannot be a syllogism, if there are terms to substitute for the letters that make the premises true and the conclusion false. This characterization of an argument’s validity based on its logical form was first achieved by Aristotle, who is therefore considered as the father of formal logic. The syllogisms were the dominant form of logical reasoning with no major breakthroughs until the 19th century advances in mathematical logic, where the focus of interest is the logical reasoning in artificial languages.",1
A Sensor Network Deployment for Energy Efficiency Monitoring in Local Data centers,0,https://www.researchgate.net/profile/I-Vlahavas/publication/264856481_A_Sensor_Network_Deployment_for_Energy_Efficiency_Monitoring_in_Local_Data_centers/links/541ac0e60cf2218008bfddfc/A-Sensor-Network-Deployment-for-Energy-Efficiency-Monitoring-in-Local-Data-centers.pdf,"This paper presents a sensor network architecture to monitor in real time the energy efficiency of local data centers. Energy consumption and important parameters are measured at the most critical parts of the data center. Already published metrics and modified versions are proposed that are capable to provide a detailed representation on the variation of the energy efficiency of the data center with time. The paper also investigates challenges for achieving energy efficiency and measurement results drive to important conclusions. The proposed sensor network architecture can be easily deployed with low cost commodity sensors on any local data center, ie data centers operating in educational institutions.",1
The Smart IHU Project Architecture for Energy and Ambient Intelligence Applications,0,https://intelligence.csd.auth.gr/wp-content/uploads/2019/03/thanosSmart1TR.pdf,"This paper presents a complete architecture for a Smart University Building. The real-world deployment is based on a wide range of wireless sensor and actuator networks, integrated by a middleware based on the Service-Oriented Architecture of Web Services. The middleware provides the necessary basis for various energy monitoring, management and savings applications as well as Intelligent Agents in the context of Ambient Intelligence.",1
Theories and Applications,0,https://link.springer.com/content/pdf/10.1007/978-3-642-30448-4.pdf,"It is our pleasure to welcome you to the proceedings of the 7th Hellenic Conference on Artificial Intelligence (SETN 2012) held during May 28–31, 2012, in Lamia, Greece. SETN 2012 was organized by the Hellenic AI Society (EETN), in collaboration with the Department of Computer Science and Biomedical Informatics of the University of Central Greece. Previous conferences were held at the University of Piraeus (1996), at the Aristotle University of Thessaloniki (2002), at the University of the Aegean (Samos, 2004, and Syros, 2008), jointly at the Foundation for Research and Technology Hellas (FORTH) and the University of Crete (2006), and at NCSR “Demokritos”(2010).",1
UTH and IHU (CI)-WP4 Energy Efficiency Monitoring in Data Centers: Case Study at International Hellenic University,0,https://scholar.google.com/scholar?cluster=16283475750806969198&hl=en&oi=scholarr,The assessment window must be defined in such a way to allow the capture of data center’s variation over time (not too big not too small). The DCeP factor gives an estimate of the performance of the data center and is not as accurate as DCiE or PUE due to its relativity!!,1
A common framework for expert systems and hypertext,0,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.49.8470&rep=rep1&type=pdf,"Intelligent hypertext is a promising approach to information systems, because it combines the power of inference of expert systems and the intuitive power of hypertext. In this paper we propose the"" COMFRESH"", a common framework for expert systems and hypertext. It is based on a Prolog interpreter and uses the conceptual graph knowledge representation formalism for browsing and reasoning. COMFRESH can be used as a knowledge based hypertext (intelligent hypertext) or as an expert system with hypertext capabilities.",1
Animating Formal Models in a Communicating Sequential Process Platform,0,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.719.4071&rep=rep1&type=pdf,"The X-machine formal method forms the basis for a specification/modeling language with a substantial potential value to software engineers. An X-machine is a more expressive and flexible state machine, capable of modeling both the dynamic and the static aspect of a system. Communicating X-machines provide a methodology for building communicating systems out of existing stand-alone X-machines. However, for practically using the model in an real-world system development process, a tool for demonstrating and informally verifying the properties of the modeled system is required. An ideal platform for efficiently implementing such a tool, should support, process oriented programming, efficient communication primitives and declarativeness. Cspcons is a distributed CLP platform that supports program execution over multiple independent sequential CLP processes that synchronize though message and event passing. The present paper demonstrates the applicability of the Cspcons programming model to the implementation of a communicating X-machine animator tool that will act as the basis for an extended set of tools that will support the formal mathematical analysis of the specified X-machine models.",1
"Methods and applications of artificial intelligence(Thessaloniki, 11-12 April 2002)",0,https://scholar.google.com/scholar?cluster=14866560861221430887&hl=en&oi=scholarr,Unknown,1
DR-DEVICE: A Defeasible Logic Reasoner for the Semantic Web,0,http://lpis.csd.auth.gr/systems/dr-device/manual.pdf,"Defeasible reasoning is a rule-based approach for efficient reasoning with incomplete and inconsistent information. Such reasoning is, among others, useful for ontology integration, where conflicting information arises naturally; and for the modeling of business rules and policies, where rules with exceptions are often used. In this demonstration we pre-sent a prototype system for defeasible reasoning on the Web. The system is called DR-DEVICE ([1],[2],[3]) and is capable of reasoning about RDF metadata over multiple Web sources using defeasible logic rules. The system is implemented on top of CLIPS production rule system and builds upon RDEVICE ([4],[2]), an earlier deductive rule system over RDF metadata that also supports derived attribute and aggregate attribute rules. Rules can be expressed either in a native CLIPS-like language, or in an extension of the OO-RuleML2 syntax. The operational semantics of defeasible logic are implemented through compilation into the generic rule language of R-DEVICE. This demonstration includes a complete use case of a semantic web broker that reasons about apartment renting.1 http://iskp. csd. auth. gr/systems/dr-device. html2 http://www. ruleml. org/",1
Multiobjective Heuristic State-Space,0,https://scholar.google.com/scholar?cluster=9754367798803187552&hl=en&oi=scholarr,"Modern domain-independent heuristic planners evaluate their plans on the single basis of their length. However, in real-world problems, there are other criteria that also play an important role, eg resource consumption, profit, safety, etc. This paper enhances the GRT planner, an efficient domain-independent heuristic state-space planner, with the ability to consider multiple criteria. The GRT heuristic is based on the estimation of the distances between each fact of a problem and the goals. The new planner, called MO-GRT, uses a weighted A* strategy and a multiobjective heuristic function, computed over a weighted hierarchy of user-defined criteria. Its computation is based on sets of non-dominated cost-vectors assigned to the problem facts, which estimate the total cost of achieving the facts from the goals, using alternative paths. Experiments show that a change in the criteria weights or scales affects both the …",0
Polyadenylation site prediction using PolyA-iEP method,2014,https://link.springer.com/content/pdf/10.1007/978-1-62703-971-0_11.pdf,"This chapter presents a method called PolyA-iEP that has been developed for the prediction of polyadenylation sites. More precisely, PolyA-iEP is a method that recognizes mRNA 3′ends which contain polyadenylation sites. It is a modular system which consists of two main components. The first exploits the advantages of emerging patterns and the second is a distance-based scoring method. The outputs of the two components are finally combined by a classifier. The final results reach very high scores of sensitivity and specificity.",1
IRISPortal: a semantic portal for industrial risk cases management,2012,https://dl.acm.org/doi/abs/10.1145/2254129.2254164,"In this paper, we describe the architecture and functionality of IRISPortal, a semantic portal that allows the management of industrial risk cases by exploiting state-of-the-art semantic technologies, such as the OWL 2 language and the OWLIM semantic repository. The portal allows the web-based management of risk cases that are modeled in terms of a risk ontology, assisting the domain experts to perform administrative tasks, such as adding, deleting and updating risk cases. Furthermore, the portal provides the functionality to the end-users for searching and browsing the modeled risk cases and their corresponding characteristics, based on the semantic relationships that derive from the ontology model after the reasoning procedure.",1
"Artificial Intelligence Applications and Innovations: Proceedings of the 5th IFIP Conference on Artificial Intelligence Applications and Innovations (AIAI'2009), April 23-25, 2009, Thessaloniki, Greece",2009,https://books.google.com/books?hl=en&lr=&id=BrGxEVpiiRIC&oi=fnd&pg=PA1&dq=info:5CMCKC9k0awJ:scholar.google.com&ots=gU5I45643K&sig=iuW1mz2LpYbt9-pqHePv-qjnhQg,"The ever expanding abundance of information and computing power enables-searchers and users to tackle highly interesting issues, such as applications prov-ing personalized access and interactivity to multimodal information based on user preferences and semantic concepts or human-machine interface systems utilizing information on the affective state of the user. The general focus of the AIAI conf-ence is to provide insights on how AI can be implemented in real world applications. This volume contains papers selected for presentation at the 5th IFIP Conf-ence on Artificial Intelligence Applications & Innovations (AIAI 2009) being held from 23rd till 25th of April, in Thessaloniki, Greece. The IFIP AIAI 2009 conf-ence is co-organized by the Aristotle University of Thessaloniki, by the University of Macedonia Thessaloniki and by the Democritus University of Thrace. AIAI 2009 is the official conference of the WG12. 5"" Artificial Intelligence Appli-tions"" working group of IFIP TC12 the International Federation for Information Processing Technical Committee on Artificial Intelligence (AI). It is a conference growing and maintaining high standards of quality. The p-pose of the 5th IFIP AIAI Conference is to bring together researchers, engineers and practitioners interested in the technical advances and business/industrial-plications of intelligent systems. AIAI 2009 is not only focused in providing-sights on how AI can be implemented in real world applications, but it also covers innovative methods, tools and ideas of AI on architectural and algorithmic level.",1
Incremental clustering for the classification of concept-drifting data streams,2008,https://www.researchgate.net/profile/Grigorios-Tsoumakas/publication/228980443_Incremental_Clustering_for_the_Classification_of_Concept-Drifting_Data_Streams/links/57357df008ae9ace840962a9/Incremental-Clustering-for-the-Classification-of-Concept-Drifting-Data-Streams.pdf,"Concept drift is a common phenomenon in streaming data environments and constitutes an interesting challenge for researchers in the machine learning and data mining community. This paper proposes a probabilistic representation model for data stream classification and investigates the use of incremental clustering algorithms in order to identify and adapt to concept drift. An experimental study is performed using three real-world datasets from the text domain, a basic implementation of the proposed framework and three baseline methods for dealing with drifting concepts. Results are promising and encourage further investigation.",1
"Summarization of multiple, metadata rich, product reviews",2008,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.511.4651&rep=rep1&type=pdf,"Modern successful on-line shops and product comparison sites allow consumers to express their opinion on products and services they purchased. Although such information can be useful to other potential customers, reading and mentally processing quite a few dozens or even hundreds of reviews for a single product is tedious and time consuming.In this paper, we propose ReSum a novel summarization approach for multiple, metadata augmented, product reviews. We argue that the contribution of additional information (metadata) such as the user's expertise, the usefulness of the review to other users, etc., is significant and can result in improved summaries. The summarization algorithm we propose outperforms two commercial, general purpose summarizers that ignore such metadata.",1
Visual Representation of web service composition problems through VLEPpO,2007,http://ftp.informatik.rwth-aachen.de/Publications/CEUR-WS/Vol-302/paper6.pdf,"This paper discusses the problem of the automatic composition of Semantic Web Services. Web Services constitute a new computing paradigm, which provides a standardized framework that facilitates the interoperability among software systems and machines that are accessible through the Internet. Semantics can significantly improve software reuse and discovery and allow the automatic composition of Web Services in order to produce large scale applications. The use of VLEPpO for the automatic composition of Web Services is proposed. VLEPpO is a visual programming tool for designing planning problems using visual elements and simple mouse operations. In the tool the user simply defines the properties of the available Web Services and the global goals of the application. Then VLEPpO automatically forms the description as a planning problem, solves it by calling an appropriate planning system and exports the solution either to a Web Service execution monitoring system or to a UDDI registry.",1
Hybrid ace: Combining search directions for heuristic planning,2005,https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1467-8640.2005.00275.x,"One of the most promising trends in Domain‐Independent AI Planning, nowadays, is state‐space heuristic planning. The planners of this category construct general but efficient heuristic functions, which are used as a guide to traverse the state space either in a forward or in a backward direction. Although specific problems may favor one or the other direction, there is no clear evidence why any of them should be generally preferred. This paper presents Hybrid‐AcE, a domain‐independent planning system that combines search in both directions utilizing a complex criterion that monitors the progress of the search, to switch between them. Hybrid AcE embodies two powerful domain‐independent heuristic functions extending one of the AcE planning systems. Moreover, the system is equipped with a fact‐ordering technique and two methods for problem simplification that limit the search space and guide the algorithm …",0
Mining for weak periodic signals in time series databases,2005,https://content.iospress.com/articles/intelligent-data-analysis/ida00194,"Periodicity is a particularly interesting feature, which is often inherent in real world time series data sets. In this article we propose a data mining technique for detecting multiple partial and approximate periodicities. Our approach is exploratory and follows a filter/refine paradigm. In the filter phase we introduce an autocorrelation-based algorithm that produces a set of candidate partial periodicities. The algorithm is extended to capture approximate periodicities. In the refine phase we effectively prune invalid periodicities. We conducted a series of experiments with various real-world data sets to test the performance and verify the quality of the results.",1
Data Mining in Biological Data,2005,https://scholar.archive.org/work/afnkhng7tnflvi5xe3w2lknw3y/access/wayback/http://lpis.csd.auth.gr:80/publications/Biological_Data_Mining.pdf,"At the end of the 1980’sa new discipline, named data mining, emerged. The introduction of new technologies such as computers, satellites, new mass storage media and many others have lead to an exponential growth of collected data. Traditional data analysis techniques often fail to process large amounts of-often noisy-data efficiently, in an exploratory fashion. The scope of data mining is the knowledge extraction from large data amounts with the help of computers. It is an interdisciplinary area of research, that has its roots in databases, machine learning, and statistics and has contributions from many other areas such as information retrieval, pattern recognition, visualization, parallel and distributed computing. There are many applications of data mining in real world. Customer relationship management, fraud detection, market and industry characterization, stock management, medicine, pharmacology, and biology are some examples (Two Crows Corporation, 1999). Recently, the collection of biological data has been increasing at explosive rates due to improvements of existing technologies and the introduction of new ones such as the microarrays. These technological advances have assisted the conduct of large scale experiments and research programs. An important example is the Human Genome Project, that was founded in 1990 by the US Department of Energy and the US National Institutes of Health (NIH) and was completed in 2003 (US Department of Energy Office of Science, 2004). A representative example of the rapid biological data accumulation is the exponential growth of GenBank (Figure 1), the US NIH genetic sequence …",0
Modeling Information Extraction Wrappers with Conceptual Graphs,2004,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.1062.9019&rep=rep1&type=pdf,"In this paper, we propose the use of the Conceptual Graphs knowledge representation and reasoning formalism to model information extraction wrappers (CG-Wrappers). An information extraction wrapper is a mapping that populates a data repository with implicit objects that exist inside a given web page. Creating a wrapper, usually involves some training by which the wrapper learns to identify the desired information based, mainly, on the surrounding HTML elements. In the paper, we demonstrate how the generalization, specialization and projection operations of the Conceptual Graph theory, naturally support semi-automatic wrapper induction and wrapper evaluation. The proposed modeling approach is flexible enough to support wrapper reuse, enabling us in that way to create more complex wrappers.",1
Rule induction for automatic configuration of planning systems,2003,http://lpis.csd.auth.gr/publications/TR-LPIS-142-03.pdf,"This paper presents a methodology for building an adaptive planning system, which automatically fine-tunes its planning parameters according to the morphology of the problem in hand, through a combination of Planning, Machine Learning and Knowledge-Based techniques. The adaptation is guided by a rule-based system that sets planner configuration parameters based on measurable characteristics of the problem instance. The knowledge of the rule system has been acquired through a rule induction algorithm. Specifically, the approach of propositional rule learning was applied to a dataset produced by results from experiments on a large number of problems from various domains, including those used in the three International Planning Competitions. The validity of our methodology is assessed through thorough experimental results that demonstrate the boost in performance of the planning system in problems of both known and unknown domains.",1
Similarity based distributed classification,2002,https://www.academia.edu/download/46076415/Similarity_Based_Distributed_Classificat20160530-23643-inngf5.pdf,"Most distributed knowledge discovery approaches view data distribution as a technical issue and combine local models aiming at a single global model. This however, is unsuitable for inherently distributed databases, which often produce models that differ semantically. In this paper we present an approach for distributed classification that uses the pairwise similarity of local models in order to produce a better model for each of the distributed databases. This is achieved by averaging the decisions of all local models weighted by their similarity with the model induced from the origin of the unlabelled data.",1
FUNAGES: an expert system for fundus fluorescein angiography,2001,https://journals.sagepub.com/doi/abs/10.1177/146045820100700317,"FUNAGES is an expert system that deals with the interpretation of fundus fluorescein angiography. Fluorescein angiography is an extremely valuable clinical test that provides information about the circulatory system of the ocular fundus (the back of the eye) not attainable by routine examination. The different appearance of fluorescein, in place and time and the classification of the fundus diseases render angiography a dynamic, cinematographic and deductive diagnostic method. Therefore, ability to interpret fundus fluorescein angiograms allows an ophthalmologist specializing in ocular fundus diseases to follow a systematic, orderly and logical line of reasoning that leads to a proper diagnosis. FUNAGES was developed to simulate such logical reasoning, in order to train inexperienced ophthalmologists in the interpretation of angiograms. The system achieved its purpose via a graphical user interface and a …",0
Land Evaluation-An Artificial Intelligence Approach,2001,https://www.igi-global.com/chapter/land-evaluation-artificial-intelligence-approach/18533,"A major environmental concern of today’s scientists is the inefficient exploitation of natural resources. The land is the ultimate source of wealth and the foundation on which civilization is constructed. Inappropriate land use, leads to destruction of the land resource, poverty and other social problems, and even to the destruction of civilization. To avoid such phenomena, land evaluation is employed, for rational land use planning and appropriate and sustainable use of natural and human resources (Rossiter, 1994). The management of land use is an interdisciplinary activity that relies on large amounts of information from different sources. Land evaluators need to collect information from soil surveyors, climatologists and census takers on land resource. They also need the expert knowledge of soil scientists, agronomists and economists on land use. In addition, land evaluators must select and apply the most appropriate …",0
AI Planning for Transportation Logistics,2001,https://www.researchgate.net/profile/Nick-Bassiliades/publication/2402645_Ai_Planning_For_Transportation_Logistics/links/0912f50af8568f30af000000/Ai-Planning-For-Transportation-Logistics.pdf,"In the last decade the efficiency of the Artificial Intelligence Planning Systems has been increased significantly. New systems appeared that are able to cope with planning problems being orders of magnitude more complex than the ones solvable in early 90's. This vast improvement increase was made possible mainly by three new approaches in plan generation: planning graphs, satisfiability planning and heuristic state-space planning. The latter approach, which is the most powerful one, derives a heuristic function from the specification of a planning problem, independently of its domain, and uses it for guiding the search through the space of the states. During the last years appeared many heuristic state-space planners, such as ASP, HSP, GRT and FF, which were able to solve large transportation logistics problems, with numerous locations, trucks and objects that have to be transferred, very efficiently, as it has been shown in the recent international planning competitions.This paper briefly presents the current status in domain-independent heuristic state-space planning and concentrates on the GRT and MO-GRT planners, where the latter is a recent extension of GRT being able to consider multiple criteria in the plan generation and evaluation process. Finally, the paper outlines results of running MO-GRT in some transportation logistics problems and poses directions for future research.",1
CG-PerLS: Conceptual Graphs for Personalized Learning Systems,2001,https://www.researchgate.net/profile/Fotis-Kokkoras/publication/228679216_CG-PerLS_Conceptual_Graphs_for_Personalized_Learning_Systems/links/0912f5075bc62cb8cd000000/CG-PerLS-Conceptual-Graphs-for-Personalized-Learning-Systems.pdf,"Two of the most important standardization efforts for e-learning technologies are related to the definition of metadata describing educational resources and metadata describing the learner's profile. The internal details of systems that utilize these metadata is still an open issue since these efforts are primarily dealing with"" what"" and not"" how"". Under the light of these emerging efforts, we present CG-PerLS, a knowledge based approach for organizing and accessing educational resources. CG-PerLS is a model of a WWW portal for learning objects that encodes the learning technologies metadata in the Conceptual Graph knowledge representation formalism, and uses related inference techniques to provide advanced, personalized functionality. CG-PerLS allows learning resource creators to manifest their material, client-side learners to access these resources in a way tailored to their individual profile and educational needs, and dynamic course generation based on fine or coarse grained educational resources.",1
Active Knowledge-Based Systems: Techniques and Applications,2000,https://intelligence.csd.auth.gr/wp-content/uploads/2019/03/academic-chapter1.pdf,"This chapter focuses on Active Knowledge Base Systems and more specifically it presents various implementation techniques that are used by the numerous systems found in the literature and on applications made based on such systems. Systems are compared based on the different techniques and on their efficiency on various applications. Finally, the Active Object-Oriented Knowledge Base System DEVICE is thoroughly described giving emphasis on its advantages against similar systems. Furthermore, two applications based on the DEVICE system are described: Deductive Databases and Data Warehouses.",1
An operator distribution method for parallel planning,2000,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.589.5988&rep=rep1&type=pdf,"This paper presents the Operator Distribution Method for Parallel Planning (ODMP), a parallelization method especially suitable for heuristic planners. ODMP distributes the process of finding and applying the ground applicable actions to a given state, to the set of the available processors. The operator schemas of the domain are distributed to the available processors in a dynamic manner. In order to utilize a larger number of processors and to achieve better load balancing, the set of the domain’s operators is initially expanded by considering all the possible instantiations of their first argument. The proposed method, ODMP, is an effective parallelization method for heuristic planners, but it can also be applied to planners that embody other search strategies as well. We implemented ODMP in a best first planner that uses a domain specific heuristic for logistics problems and tested its efficiency on a variety of problems, adopted from the AIPS-98 planning competition.",1
Communicating sequential processes for distributed constraint satisfaction,2006,https://www.sciencedirect.com/science/article/pii/S0020025504003421,"CSPCONS is a programming language that supports program execution over multiple Prolog processes with constraints. The language is an extended version of Csp-ii, a version of Prolog that supports channel-based communicating processes and TCP/IP communication, that is based on the CSP model introduced by Hoare. Cspcons inherits all the advanced features of Csp-ii and extends it by introducing constraint solving capabilities to the processes. In Cspcons each Prolog process has one or more solvers attached and each solver is independent from the others, following the original Csp-ii model, thus resulting to a communicating sequential constraint logic programming system. Such a model can facilitate greatly the implementation of distributed CLP applications. This paper describes the original Csp-ii system along with details of the extensions that resulted to the Cspcons system and presents an example …",0
Predicting missing values in a home care database using an adaptive uncertainty rule method,2005,https://www.thieme-connect.com/products/ejournals/abstract/10.1055/s-0038-1634020,"  Objectives:  Contemporary literature illustrates an abundance of adaptive algorithms for mining association rules. However, most literature is unable to deal with the peculiarities, such as missing values and dynamic data creation, that are frequently encountered in fields like medicine. This paper proposes an uncertainty rule method that uses an adaptive threshold for filling missing values in newly added records. A new approach for mining uncertainty rules and filling missing values is proposed, which is in turn particularly suitable for dynamic databases, like the ones used in home care systems.  Methods:  In this study, a new data mining method named FiMV (Filling Missing Values) is illustrated based on the mined uncertainty rules. Uncertainty rules have quite a similar structure to association rules and are extracted by an algorithm proposed in previous work, namely AURG (Adaptive Uncertainty Rule …",0
HAP RC: an automatically configurable planning system,2005,https://content.iospress.com/articles/ai-communications/aic335,"This paper presents an adaptive planning system, called HAP RC, which automatically fine-tunes its planning parameters according to the morphology of the problem in hand, through a combination of Planning, Machine Learning and Knowledge-Based techniques. The adaptation is guided by a rule-based system that sets planner configuration parameters based on measurable characteristics of the problem instance. The knowledge of the rule system has been acquired through a rule induction algorithm. Specifically, the approach of propositional rule learning was applied to a dataset produced by results from experiments on a large number of problems from various domains, including those used in the three International Planning Competitions. The improvement of the adaptive system over the original planner is assessed through thorough experiments in problems of both known and unknown domains.",1
ViTAPlan: A Visual Tool for Adaptive Planning,2003,http://delab.csd.auth.gr/~bci1/Panhellenic/167vrakas.pdf,"This paper presents a friendly visual tool for HAP, a ruleconfigurable planning system, which automatically adapts to each problem, in order to achieve best performance. HAP analyzes the problem and uses a rule system in order to configure the planning parameters in a way that best suites the morphology of the problem. The visual tool enables the user to use the planning system, get advice from the built-in rule system and even interfere with it. ViTAPlan also contains a visual designer, based on the Planning Domain Definition Language, that enables the user to create new planning domains and problems in a graphical way and get visual representations of existing ones. Furthermore the tool contains a module that simulates the execution of the plan and illustrates the changes in the world, which follow the application of each action in the plan.",1
COMFRESH: a common framework for expert systems and hypertext,1995,https://www.sciencedirect.com/science/article/pii/030645739500004Z,"Intelligent hypertext is a promising approach to information systems, because it combines the power of inference of expert systems and the intuitive power of hypertext. In this paper we propose the “COMFRESH”, a common framework for expert systems and hypertext. It is based on a Prolog interpreter and uses the conceptual graph knowledge representation formalism for browsing and reasoning. COMFRESH can be used as a knowledge based hypertext (intelligent hypertext) or as an expert system with hypertext capabilities.",1
Predicting the average size of blasted rocks in aggregate quarries using artificial neural networks,2019,https://link.springer.com/article/10.1007/s10064-018-1270-1,"The prediction of the average size of fragments in blasted rock piles produced after blasting in aggregate quarries is essential for decresing the cost of crushing and secondary breaking. There are several conventional and advanced processes to estimate the size of blasted rocks. Among these, the empirical prediction of the expected fragmentation in most cases is carried out by Kuznetsov’s equation (Sov Min Sci 9:144–148, 1973), modified by Lilly (1986) and Cunningham (1987). The present research focuses on the effect of the engineering geological factors and blasting process on the blasted fragments using a more powerful, advanced computational tool, an artificial neural network. In particular, the blast database consists of the blastability index of limestone on the pit face, the quantities of the explosives and of the blasted rock pile, assessing the interaction of these parameters on the blasted rocks …",0
A novel bacteria-based broadcast system exploiting chemotaxis,2016,https://dl.acm.org/doi/abs/10.1145/2967446.2967482,"Bacterial and molecular-based communication has recently emerged as one of the paradigms for establishing communication environments in the nanoscale. This paper presents a novel bacteria-based communication system exploiting the phenomenon of chemotaxis. Such a system could provide solutions in applications with the requirement for biocompatibility or low power consumption. In order to demonstrate and investigate the properties of this system, a simulator was employed and experiments were performed, where bits were transmitted using bacteria release pulses and successfully received at a sensor node. The experiments highlight the value of the chemotaxis phenomenon for augmenting information transfer as well as the influence of the parameters of distance and number of bacteria per pulse on the received signal strength and achievable bit error rate.",1
Learning to play monopoly: A reinforcement learning approach,2014,http://lpis.csd.auth.gr/publications/AISB.pdf,"Reinforcement Learning is a rather popular machine learning paradigm which relies on an agent interacting with an environment and learning through trial and error to maximize the cummulative sum of rewards received by it. In this paper, we are proposing a novel representation of the famous board game Monopoly as a Markov Decision Process and a Reinforcement Learning agent capable of playing and learning winning strategies. The conclusions drawn from the experiments are particularly positive, since the proposed agent demonstrated intelligent behavior and high win rates against different types of agent-players.",1
Machine learning and data mining in bioinformatics,2009,https://www.igi-global.com/chapter/machine-learning-data-mining-bioinformatics/20747,"Machine learning is one of the oldest subfields of artificial intelligence and is concerned with the design and development of computational systems that can adapt themselves and learn. The most common machine learning algorithms can be either supervised or unsupervised. Supervised learning algorithms generate a function that maps inputs to desired outputs, based on a set of examples with known output (labeled examples). Unsupervised learning algorithms find patterns and relationships over a given set of inputs (unlabeled examples). Other categories of machine learning are semi-supervised learning, where an algorithm uses both labeled and unlabeled examples, and reinforcement learning, where an algorithm learns a policy of how to act given an observation of the world.",1
Induction as a search procedure,2008,https://www.igi-global.com/chapter/induction-search-procedure/5323,"This chapter introduces Inductive Logic Programming (ILP) from the perspective of search algorithms in Computer Science. It first briefly considers the Version Spaces approach to induction, and then focuses on Inductive Logic Programming: from its formal definition and main techniques and strategies, to priors used to restrict the search space and optimized sequential, parallel, and stochastic algorithms. The authors hope that this presentation of the theory and applications of Inductive Logic Programming will help the reader understand the theoretical underpinnings of ILP, and also provide a helpful overview of the State-of-the-Art in the domain.",1
A visual programming tool for designing planning problems for semantic web service composition,2008,https://www.igi-global.com/chapter/visual-languages-interactive-computing/31045,"This chapter is concerned with the issue of knowledge representation for AI Planning problems, especially those related to Semantic Web Service composition. It discusses current approaches in encoding planning problems using the PDDL formal language and it presents ViTAPlan, a user-friendly visual tool for planning. More than just being a user friendly environment for executing the underlying planner, the tool serves as a unified planning environment for encoding a new problem, solving it, visualizing the solution and monitoring its execution on a simulation of the problem’s world. The tool consists of various sub-systems, each one accompanied by a graphical interface, which collaborate with each other and assist the user, either a knowledge engineer, a domain expert, an academic or even an end-user in industry, to carry out complex planning tasks, such as composing complex Semantic Web Services from …",0
Accurate classification of SAGE data based on frequent patterns of gene expression,2007,https://ieeexplore.ieee.org/abstract/document/4410269/,"In this paper we present a method for classifying accurately SAGE (serial analysis of gene expression) data. The high dimensionality of the data, namely the large number of features, in combination with the small number of samples poses a great challenge and demands more accurate and robust algorithms for classification. The prediction accuracy of the up to now proposed approaches is moderate. In our approach we exploit the associations among the expressions of genes in order to construct more accurate classifiers. For validating the effectiveness of our approach we experimented with two real datasets using numerous feature selection and classification algorithms. The results have shown that our approach improves significantly the classification accuracy, which reaches 99%.",1
A visualization environment for planning,2005,https://www.worldscientific.com/doi/abs/10.1142/S0218213005002491,"This article presents ViTAPlan-2, a visual tool for adaptive  planning that is build on top of HAPRC, a rule-configurable  planning system, which automatically adapts to each problem,  in order to achieve best performance. Apart from HAPRC, ViTAPlan  can be interfaced with any other planning system that supports the  PDDL language. More than just being a user friendly environment  for executing the underlying planner, the tool serves as a  unified planning environment for encoding a new problem problem,  solving it, visualizing the solution and monitoring its execution on a simulation of the problem's word. The tool consists of various  sub-systems, each one accompanied by a graphical interface,  that collaborate with each other and assist the user, whether  he is a knowledge engineer, a domain expert, an academic or even  an end user in industry, to carry out complex planning tasks.",1
Applying neural networks with active neurons to sea-water quality measurements,2005,https://www.academia.edu/download/37730122/hatzikos_et_al_1.pdf,"This study examines the presence of either linear or nonlinear relationships between a number of popular sea-water quality indicators such as water temperature, pH, amount of dissolved oxygen and turbidity. The data are obtained from a set of sensors in an underwater measurement station. The neural networks with active neurons are applied to the prediction of each one of the above four indicators and their performance is compared against a benchmark prediction method known as the random walk model. The random walk model is the simpler prediction method, which accepts as the best prediction for a variable its current value. The neural network with active neurons is a black box method, which contrary to neural networks with passive neurons does not require a long set of training data. The results show that for daily predictions the neural network with active neurons is able to beat the random walk model with regard to directional accuracy, namely the direction (upward or downwards) of the modelling object in the next day.",1
Deep reinforcement learning: A state-of-the-art walkthrough,2020,http://www.jair.org/index.php/jair/article/view/12412,"Deep Reinforcement Learning is a topic that has gained a lot of attention recently, due to the unprecedented achievements and remarkable performance of such algorithms in various benchmark tests and environmental setups. The power of such methods comes from the combination of an already established and strong field of Deep Learning, with the unique nature of Reinforcement Learning methods. It is, however, deemed necessary to provide a compact, accurate and comparable view of these methods and their results for the means of gaining valuable technical and practical insights. In this work we gather the essential methods related to Deep Reinforcement Learning, extracting common property structures for three complementary core categories: a) Model-Free, b) Model-Based and c) Modular algorithms. For each category, we present, analyze and compare state-of-the-art Deep Reinforcement Learning algorithms that achieve high performance in various environments and tackle challenging problems in complex and demanding tasks. In order to give a compact and practical overview of their differences, we present comprehensive comparison figures and tables, produced by reported performances of the algorithms under two popular simulation platforms: the Atari Learning Environment and the MuJoCo physics simulation platform. We discuss the key differences of the various kinds of algorithms, indicate their potential and limitations, as well as provide insights to researchers regarding future directions of the field.",1
LionForests: Local interpretation of random forests,2019,https://arxiv.org/abs/1911.08780,"Towards a future where machine learning systems will integrate into every aspect of people's lives, researching methods to interpret such systems is necessary, instead of focusing exclusively on enhancing their performance. Enriching the trust between these systems and people will accelerate this integration process. Many medical and retail banking/finance applications use state-of-the-art machine learning techniques to predict certain aspects of new instances. Tree ensembles, like random forests, are widely acceptable solutions on these tasks, while at the same time they are avoided due to their black-box uninterpretable nature, creating an unreasonable paradox. In this paper, we provide a methodology for shedding light on the predictions of the misjudged family of tree ensemble algorithms. Using classic unsupervised learning techniques and an enhanced similarity metric, to wander among transparent trees inside a forest following breadcrumbs, the interpretable essence of tree ensembles arises. An interpretation provided by these systems using our approach, which we call ""LionForests"", can be a simple, comprehensive rule.",1
Real Time Location Based Sentiment Analysis on Twitter: The AirSent System,2018,https://dl.acm.org/doi/abs/10.1145/3200947.3201052,"The widespread use of Social Media creates great opportunities for businesses to take advantage of. By combining clever techniques, companies can develop powerful data analysis systems to understand their customers. This paper presents a real time sentiment analysis and location inference system, showcased via AirSent, an R-based application designed to assist airline carriers in measuring their passengers' satisfaction. AirSent can download, classify and locate tweets within seconds, presenting the results in interactive maps.",1
Drawing parallels between multi-label classification and multi-target regression,2014,http://users.auth.gr/users/0/9/022090/public_html/publications/slides/spyromitrosECMLPKDD14MTPW.pdf,"Drawing parallels between multi-label classification and multi-target regression Page 1 
International Workshop on Multi-Target Prediction Nancy, France, September 15th, 2014 
Drawing Parallels between Multi-label Classification and Multi-target Regression Grigorios 
Tsoumakas, Eleftherios Spyromitros-Xioufis, and Ioannis Vlahavas Drawing Parallels between 
Multi-label Classification and Multi-target Regression Grigorios Tsoumakas, Eleftherios 
Spyromitros-Xioufis, and Ioannis Vlahavas Machine Learning and Knowledge Discovery (MLKD) 
group Department of Informatics, Aristotle University of Thessaloniki, Greece Page 2 International 
Workshop on Multi-Target Prediction Nancy, France, September 15th, 2014 Drawing Parallels 
between Multi-label Classification and Multi-target Regression Grigorios Tsoumakas, Eleftherios 
Spyromitros-Xioufis, and Ioannis Vlahavas • Two instances of multi-target prediction -& --…",0
A smart university platform for building energy monitoring and savings,2016,https://content.iospress.com/articles/journal-of-ambient-intelligence-and-smart-environments/ais375,"This paper presents a novel, integrated platform for energy monitoring, management and savings in the context of a Smart University Building. Namely, the proposed Smart International Hellenic University (IHU) platform integrates an intelligent, rule-based agent that enforces savings, while a variety of applications offers user interaction with the system and the means for monitoring and management. The application layer is built over a common Web Service middleware, incorporating semantic interoperability. Monitoring applications visualize raw and aggregated sensor readings, such as building energy disaggregation, environmental measurements and data center efficiency. Extensive monitoring capabilities allow users to take immediate action and devise policies towards energy-savings. Such policies are, then, autonomously enforced by the intelligent, hybrid agent, which is capable of both deliberative (long …",0
Reinforcement learning with classifier selection for focused crawling,2008,https://ebooks.iospress.nl/volumearticle/4486,"Focused crawlers are programs that wander in the Web, using its graph structure, and gather pages that belong to a specific topic. The most critical task in Focused Crawling is the scoring of the URLs as it designates the path that the crawler will follow, and thus its effectiveness. In this paper we propose a novel scheme for assigning scores to the URLs, based on the Reinforcement Learning (RL) framework. The proposed approach learns to select the best classifier for ordering the URLs. This formulation reduces the size of the search space for the RL method and makes the problem tractable. We evaluate the proposed approach on-line on a number of topics, which offers a realistic view of its performance, comparing it also with a RL method and a simple but effective classifier-based crawler. The results demonstrate the strength of the proposed approach.",1
Intelligent techniques for planning,2005,https://books.google.com/books?hl=en&lr=&id=-MdQtA2GfT0C&oi=fnd&pg=PR1&dq=info:M2Gw6c72YXwJ:scholar.google.com&ots=v8U0GiUkzh&sig=HGqDoHahpY-HdWegS_8tviBtZLM,"The Intelligent Techniques for Planning presents a number of modern approaches to the area of automated planning. These approaches combine methods from classical planning such as the construction of graphs and the use of domain-independent heuristics with techniques from other areas of artificial intelligence. This book discuses, in detail, a number of state-of-the-art planning systems that utilize constraint satisfaction techniques in order to deal with time and resources, machine learning in order to utilize experience drawn from past runs, methods from knowledge systems for more expressive representation of knowledge and ideas from other areas such as Intelligent Agents. Apart from the thorough analysis and implementation details, each chapter of the book also provides extensive background information about its subject and presents and comments on similar approaches done in the past.",1
Capturing RDF Descriptive Semantics in an Object Oriented Knowledge Base System.,2003,https://www.researchgate.net/profile/Nick-Bassiliades/publication/221024133_Capturing_RDF_Descriptive_Semantics_in_an_Object_Oriented_Knowledge_Base_System/links/0046352616e949e8b4000000/Capturing-RDF-Descriptive-Semantics-in-an-Object-Oriented-Knowledge-Base-System.pdf,"In this paper, we present a deductive object-oriented knowledge base system, called R-DEVICE, which imports RDF data into the CLIPS production rule system as objects and uses a deductive rule language for querying and reasoning about them. In our model properties of resources are not scattered across several triples as in most other RDF storage and querying systems, resulting in increased query per-formance due to less joins. R-DEVICE features a powerful deductive rule language which is able to express arbitrary queries both on the RDF schema and data, including generalized path expressions, strati-fied negation, aggregate, grouping, and sorting, functions, mainly due to the second-order syntax of the rule language which is efficiently translated into sets of first-order logic rules using metadata.",1
A multi-agent coordination framework for smart building energy management,2014,https://ieeexplore.ieee.org/abstract/document/6974838/,"This paper presents a novel energy management framework for multi-agent coordination in smart buildings. The framework builds on top of an existing Service-Oriented middleware for Ambient Intelligence, which offers sensor and actuator functions of wireless devices. The middleware also provides a semantics infrastructure that assists in authoring agent policies for reducing energy consumption and maximizing user comfort. Each agent within the framework is responsible for monitoring the environmental context and controlling the electrical appliances of a specific room. However, the collective behavior of the multi-agent system is controlled by a Coordinator Agent that approves or rejects the allocation of building resources in time, aiming at more ""long-term"" goals that are out of the reach and scope of the individual Room Agents. The agents' underlying logic is expressed via defeasible logics, a formalism …",0
Web Data Management Practices: Emerging Techniques and Technologies: Emerging Techniques and Technologies,2006,https://books.google.com/books?hl=en&lr=&id=1sneHjL-yGQC&oi=fnd&pg=PR1&dq=info:iArsSJN67xAJ:scholar.google.com&ots=tNRw3K_2VY&sig=aGtGOwsi02Qp6CkYpMQc7a--o0U,"New state-of-the-art techniques for analyzing and managing Web data have emerged due to the need for dealing with huge amounts of data which are circulated on the Web. Web Data Management Practices: Emerging Techniques and Technologies provides a thorough understanding of major issues, current practices, and the main ideas in the field of Web data management, helping readers to identify current and emerging issues, as well as future trends in this area. Web Data Management Practices: Emerging Techniques and Technologies presents a complete overview of important aspects related to Web data management practices, such as: Web mining, Web data clustering, and others. This book also covers an extensive range of topics, including related issues about Web mining, Web caching and replication, Web services, and the XML standard.",1
Parallel planning via the distribution of operators,2001,https://www.tandfonline.com/doi/abs/10.1080/09528130110063074,"This paper describes Operator Distribution Method for parallel Planning (ODMP), a parallelization method for efficient heuristic planning. The method innovates in that it parallelizes the application of the available operators to the current state and the evaluation of the successor states using the heuristic function. In order to achieve better load balancing and a lift in the scalability of the algorithm, the operator set is initially enlarged, by grounding the first argument of each operator. Additional load balancing is achieved through the reordering of the operator set, based on the expected amount of imposed work. ODMP is effective for heuristic planners, but it can be applied to planners that embody other search strategies as well. It has been applied to GRT, a domain-independent heuristic planner, and CL, a heuristic planner for simple logistics problems, and has been thoroughly tested on a set of logistics problems …",0
"Parallel, object-oriented, and active knowledge base systems",1998,https://books.google.com/books?hl=en&lr=&id=kNPLVc5rEbkC&oi=fnd&pg=PP13&dq=info:-jscwKyHbKgJ:scholar.google.com&ots=4UbDZKr62z&sig=MJMy6Ep-ijemJNO8nttrrNa3OLc,"Knowledge Base Systems are an integration of conventional database systems with Artificial Intelligence techniques. They provide inference capabilities to the database system by encapsulating the knowledge of the application domain within the database. Knowledge is the most valuable of all corporate resources that must be captured, stored, re-used and continuously improved, in much the same way as database systems were important in the previous decade. Flexible, extensible, and yet efficient Knowledge Base Systems are needed to capture the increasing demand for knowledge-based applications which will become a significant market in the next decade. Knowledge can be expressed in many static and dynamic forms; the most prominent being domain objects, their relationships, and their rules of evolution and transformation. It is important to express and seamlessly use all types of knowledge in a single Knowledge Base System. Parallel, Object-Oriented, and Active Knowledge Base Systems presents in detail features that a Knowledge Base System should have in order to fulfill the above requirements. Parallel, Object-Oriented, and Active Knowledge Base Systems covers in detail the following topics: Integration of deductive, production, and active rules in sequential database systems. Integration and inter-operation of multiple rule types into the same Knowledge Base System. Parallel rule matching and execution, for deductive, production, and active rules, in parallel Export, Knowledge Base, and Database Systems. In-depth description of a Parallel, Object-Oriented, and Active Knowledge Base System that integrates all rule …",0
Transfer learning with probabilistic mapping selection,2015,https://journals.sagepub.com/doi/abs/10.1177/1059712314559525,"When transferring knowledge between reinforcement learning agents with different state representations or actions, past knowledge must be efficiently mapped to novel tasks so that it aids learning. The majority of the existing approaches use pre-defined mappings provided by a domain expert. To overcome this limitation and enable autonomous transfer learning, this paper introduces a method for weighting and using multiple inter-task mappings based on a probabilistic framework. Experimental results show that the use of multiple inter-task mappings, accompanied with a probabilistic selection mechanism, can significantly boost the performance of transfer learning relative to 1) learning without transfer and 2) using a single hand-picked mapping. We especially introduce novel tasks for transfer learning in a realistic simulation of the iCub robot, demonstrating the ability of the method to select mappings in complex …",0
Transfer learning via multiple inter-task mappings,2011,https://link.springer.com/chapter/10.1007/978-3-642-29946-9_23,"In this paper we investigate using multiple mappings for transfer learning in reinforcement learning tasks. We propose two different transfer learning algorithms that are able to manipulate multiple inter-task mappings for both model-learning and model-free reinforcement learning algorithms. Both algorithms incorporate mechanisms to select the appropriate mappings, helping to avoid the phenomenon of negative transfer. The proposed algorithms are evaluated in the Mountain Car and Keepaway domains. Experimental results show that the use of multiple inter-task mappings can significantly boost the performance of transfer learning methodologies, relative to using a single mapping or learning without transfer.",1
Deploying a semantically-enabled content management system in a state university,2010,https://link.springer.com/chapter/10.1007/978-3-642-15172-9_24,"Public institutes often face the challenge of managing vast volumes of administrative documents, a need that is often met via Content Management Systems (CMSs). CMSs offer various advantages, like separation of data structure from presentation and variety in user roles, but also present certain disadvantages, like inefficient keyword-based search facilities. The new generation of content management solutions imports the notion of semantics and is based on Semantic Web technologies, such as metadata and ontologies. The benefits include semantic interoperability, competitive advantages and dramatic cost reduction. In this paper a leading Enterprise CMS is extended with semantic capabilities for automatically importing and exporting ontologies. This functionality enables reuse of repository content, semantically-enabled search and interoperability with third-party applications. The extended system is …",0
VLEPPO: A visual language for problem representation,2007,http://ktilinux.ms.mff.cuni.cz/~bartak/PLANSIG2007/downloads/Proceedings.pdf#page=66,"AI planning constitutes a field of interest as its techniques can be applied to many areas. Contemporary systems that are being developed deal with certain aspects of planning and focus mainly on dealing with advanced features such as resources, time and numerical expressions. This paper presents VLEPpO, a Visual Language for Enhanced Planning problem Orchestration. VLEPpO is a visual programming environment that allows the user to easily define planning domains and problems, acquire their PDDL representations, as well as receive solutions, utilizing web services infrastructure.",1
Large-scale online semantic indexing of biomedical articles via an ensemble of multi-label classification models,2017,https://link.springer.com/article/10.1186/s13326-017-0150-0,"In this paper we present the approach that we employed to deal with large scale multi-label semantic indexing of biomedical papers. This work was mainly implemented within the context of the BioASQ challenge (2013–2017), a challenge concerned with biomedical semantic indexing and question answering. Our main contribution is a MUlti-Label Ensemble method (MULE) that incorporates a McNemar statistical significance test in order to validate the combination of the constituent machine learning algorithms. Some secondary contributions include a study on the temporal aspects of the BioASQ corpus (observations apply also to the BioASQ’s super-set, the PubMed articles collection) and the proper parametrization of the algorithms used to deal with this challenging classification task. The ensemble method that we developed is compared to other approaches in experimental scenarios with subsets of the …",0
Large-scale semantic indexing of biomedical publications at bioasq,2013,https://www.researchgate.net/profile/Grigorios-Tsoumakas/publication/289393652_Large-scale_semantic_indexing_of_biomedical_publications_at_BioASQ/links/56b9a29808ae3b658a8931fc/Large-scale-semantic-indexing-of-biomedical-publications-at-BioASQ.pdf,"Automated annotation of scientific publications in real-world digital libraries requires dealing with challenges such as large number of concepts and training examples, multi-label training examples and hierarchical structure of concepts. BioASQ is a European project that contributes a large-scale biomedical publications corpus for working on these challenges. This paper documents the participation of our team to the large-scale biomedical semantic indexing task of BioASQ.",1
Lazy adaptive multicriteria planning,2004,http://lpis.csd.auth.gr/publications/tsoumakas-ecai04.pdf,"This paper describes a learning system for the automatic configuration of domain independent planning systems, based on measurable features of planning problems. The purpose of the Lazy Adaptive Multicriteria Planning (LAMP) system is to configure a planner in an optimal way, concerning two quality metrics (ie execution speed and plan quality), for a given problem according to user-specified preferences. The training data are produced by running the planner under consideration on a set of problems using all possible parameter configurations and recording the planning time and the plan length. When a new problem arises, LAMP extracts the values for a number of domain-expert specified problem features and uses them to identify the а nearest problems solved in the past. The system then performs a multicriteria combination of the performances of the retrieved problems according to user-specified weights that specify the relative importance of the quality metrics and selects the configuration with the best score. Experimental results show that LAMP improves the performance of the default configuration of two already well-performing planning systems in a variety of planning problems.",1
PREVENT: An algorithm for mining intertransactional patterns for the prediction of rare events,2004,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.580.7502&rep=rep1&type=pdf,"In this paper we propose a data mining technique for the efficient prediction of rare events, such as heat waves, network intrusions and engine failures, using inter transactional patterns. Data mining is a research area that attempts to assist the decision makers with a set of tools to treat a wide range of real world problems that the traditional statistical and mathematical approaches are not enough in terms of efficiency and computational performance. Transaction databases, such as the ones in this paper that contain sets of events, require special approaches in order to extract valuable temporal knowledge. We utilize the framework of inter-transaction association rules, which associate events across a window of transactions. We propose an approach that extends sequential analysis to predict rare events in transaction databases. We formulate the problem of rare events prediction and we propose PREVENT, an algorithm that produces inter-transactional patterns for the fast and accurate prediction of a user-specified rare event. Finally, we provide experimental results and suggest some ideas for future research.",1
Using logic for querying XML data,2003,https://www.igi-global.com/chapter/web-powered-databases/31422,"In this chapter, we propose the use of first-order logic, in the form of deductive database rules, as a query language for XML data, and we present X-Device, an extension of the deductive object-oriented database system Device, for storing and querying XML data. XML documents are stored into the OODB by automatically mapping the DTD to an object schema. XML elements are treated either as classes or attributes based on their complexity, without loosing the relative order of elements in the original document. Furthermore, this chapter describes the extension of the system’s deductive rule query language with second-order variables, general path and ordering expressions, for querying over the stored, tree-structured XML data and constructing XML documents as a result. The extensions were implemented by translating all the extended features into the basic, first-order deductive rule language of Device using …",0
Data mining and knowledge discovery handbook. Mining multi-label data,2009,https://scholar.google.com/scholar?cluster=187301861665405320&hl=en&oi=scholarr,Unknown,1
Exploiting and-or parallelism in Prolog: The OASys computational model and abstract architecture,1998,https://www.sciencedirect.com/science/article/pii/S0164121298100213,"Different forms of parallelism have been extensively investigated over the last few years in logic programs and a number of systems have been proposed. Or/And System (OASys) is an experimental parallel Prolog system that exploits and-or-parallelism and comprises a computational model, a compiler, an abstract machine and an emulator. OASys computational model combines the two types of parallelism considering each alternative path as a totally independent computation which consists of a conjunction of determinate subgoals. It is based on distributed scheduling and supports recomputation of paths as well as stack copying. The system features modular design, high distribution and minimal inter-processor communication. This paper presents briefly the computational model and describes the abstract machine discussing data representation, memory organization, instruction set, operation and …",0
InterBase (KB): A Knowledge-based Multidatabase System for Data Warehousing,1997,https://docs.lib.purdue.edu/cgi/viewcontent.cgi?article=2382&context=cstech,"This paper describes the extension of a mullidatnbase system with a knowledge-base module in order to support data warehousing. The multidatabase system integrates various component databases with a common query and transaction specification language, however, il does not provide capabilily for schema integration. The knowledge base module provides a declarative logic language with second-order syntax but first-order semantics for integrating the schemes of the data sources into the warehouse and for defining complex materialized views. Funhennore, the views are self-maintainable, ie they are incrementally maintained by an efficient mechanism that uses only the changes to the data sources.",1
THE AND OR PARALLEL PROLOG MACHINE APIM-EXECUTION MODEL AND ABSTRACT DESIGN,1993,https://scholar.google.com/scholar?cluster=2490812605703142183&hl=en&oi=scholarr,"Aristotle parallel inference machine (APIM) is a prototype implementation of the Prolog language. It supports full AND/OR parallelism while retaining the full Prolog semantics. This report complements and concludes previous work published on the APIM project. The parallel resolution principle on which the design of APIM is based is briefly described. The actual distributed multiprocessor system as well as the abstract machine for the AND/OR parallel execution of logic programs are then presented in detail. Finally the advantages of APIM, and the benefit in terms of speeding up the execution by analysing simulation results obtained from example Prolog programs, are then discussed.",1
ET: Entity-Transformers. Coreference augmented Neural Language Model for richer mention representations via Entity-Transformer blocks,2020,https://arxiv.org/abs/2011.05431,"In the last decade, the field of Neural Language Modelling has witnessed enormous changes, with the development of novel models through the use of Transformer architectures. However, even these models struggle to model long sequences due to memory constraints and increasing computational complexity. Coreference annotations over the training data can provide context far beyond the modelling limitations of such language models. In this paper we present an extension over the Transformer-block architecture used in neural language models, specifically in GPT2, in order to incorporate entity annotations during training. Our model, GPT2E, extends the Transformer layers architecture of GPT2 to Entity-Transformers, an architecture designed to handle coreference information when present. To that end, we achieve richer representations for entity mentions, with insignificant training cost. We show the comparative model performance between GPT2 and GPT2E in terms of Perplexity on the CoNLL 2012 and LAMBADA datasets as well as the key differences in the entity representations and their effects in downstream tasks such as Named Entity Recognition. Furthermore, our approach can be adopted by the majority of Transformer-based language models.",1
An Autonomous Transfer Learning Algorithm for TD-Learners,2014,https://link.springer.com/chapter/10.1007/978-3-319-07064-3_5,"The main objective of transfer learning is to use the knowledge acquired from a source task in order to boost the learning procedure in a target task. Transfer learning comprises a suitable solution for reinforcement learning algorithms, which often require a considerable amount of training time, especially when dealing with complex tasks. This work proposes an autonomous method for transfer learning in reinforcement learning agents. The proposed method is empirically evaluated in the keepaway and the mountain car domains. The results demonstrate that the proposed method can improve the learning procedure in the target task.",1
Pattern discovery for microsatellite genome analysis,2014,https://www.sciencedirect.com/science/article/pii/S0010482514000043,"Microsatellite loci comprise an important part of eukaryotic genomes. Their applications in biology as genetic markers are related to numerous fields ranging from paternity analyses to construction of genetic maps and linkage to human disease. Existing software solutions which offer pattern discovery algorithms for the correct identification and downstream analysis of microsatellites are scarce and are proving to be inefficient to analyze large, exponentially increasing, sequenced genomes. Moreover, such analyses can be very difficult for bioinformatically inexperienced biologists. In this paper we present Microsatellite Genome Analysis (MiGA) software for the detection of all microsatellite loci in genomic data through a user friendly interface. The algorithm searches exhaustively and rapidly for most microsatellites. Contrary to other applications, MiGA takes into consideration the following three most important aspects …",0
Transferring models in hybrid reinforcement learning agents,2011,https://link.springer.com/chapter/10.1007/978-3-642-23957-1_19,"The main objective of transfer learning is to reuse knowledge acquired in a previous learned task, in order to enhance the learning procedure in a new and more complex task. Transfer learning comprises a suitable solution for speeding up the learning procedure in Reinforcement Learning tasks. In this work, we propose a novel method for transferring models to a hybrid reinforcement learning agent. The models of the transition and reward functions of a source task, will be transferred to a relevant but different target task. The learning algorithm of the target task’s agent takes a hybrid approach, implementing both model-free and model-based learning, in order to fully exploit the presence of a model. The empirical evaluation, of the proposed approach, demonstrated significant results and performance improvements in the 3D Mountain Car task, by successfully using the models generated from the standard …",0
"Artificial Intelligence, (in Greek",2006,http://mlkd.csd.auth.gr/publication_details.asp?publicationID=212,"Τεχνητή Νοημοσύνη είναι ο τομέας της επιστήμης των υπολογιστών, που ασχολείται με τη σχεδίαση ευφυών υπολογιστικών συστημάτων, δηλαδή συστημάτων που επιδεικνύουν χαρακτηριστικά που σχετίζουμε με τη νοημοσύνη στην ανθρώπινη συμπεριφορά.",1
Distributed singleton consistency,2004,https://www.tandfonline.com/doi/abs/10.1080/09528130410001724968,"Distributed constraint satisfaction has drawn much attention in the past years, with a number of algorithms proposed to tackle the problem. Research in the area has followed two directions: distributed search techniques and distributed filtering techniques. This paper presents a new distributed filtering algorithm, named Distributed Singleton Arc Consistency (Dis-SAC), which is based on the singleton consistency algorithm. Dis-SAC is a parallel, coarse-grain filtering algorithm aimed at improving the performance of singleton consistency by distributing the work to be done to a number of agents. The current paper presents the basic idea behind the algorithm and two versions of it that employ different communication policies along with experimental results obtained on a set of random binary CSP problems.",1
A knowledge-based framework for building web service domains,2003,https://intelligence.csd.auth.gr/wp-content/uploads/2019/03/pci9-bassiliades.pdf,"This paper describes a knowledge-based framework, called SWIM, for building Web Service Domains, which are collections or communities of related Web Services that are mediated and/or aggregated by a single Web Service, called the Mediator Service that functions as a proxy for them. When a requestor sends a message to the Mediator Service our system will select one or more of the Web Services to dispatch the message and will fuse the results returned by the selected services. The selection of Web services and the algorithm for fusing the results is defined by the administrator of the Service Domain using a declarative rule language, called X-DEVICE. SWIM system offers services for registering new Web Services and Service Domains. The main advantage of the SWIM system, compared to similar proposed approaches is that it allows the easy definition of arbitrary service selection strategies using a logicbased language. Furthermore, it goes beyond the mere conditional re-routing of Web Service requests by allowing combination of results of multiple Web Services leading to a simple logic-based form for Web Service composition.",1
eLPA: an e-Learner's Personal Assistant,2002,http://lml.bas.bg/iccs2002/acs/kokkoras.pdf,"One of the most rapidly evolving e-services is e-Learning, that is, the creation of advanced educational resources that are accessible on-line and, potentially, offer numerous advantages over the traditional ones like intelligent access, interoperability between two or more educational resources and adaptation to the user ([1],[2]). The driving force behind the most advanced e-Learning services that are about to appear is the definition of the various standards about educational metadata, that is, data describing learning resources, the learner, assessment results, etc. The internal details of systems that utilize these metadata are still an open issue since these efforts are primarily dealing with"" what"" and not"" how"". In this position paper, and under the light of these emerging metadata standards, we outline eLPA, an intelligent agent that uses a conceptual graph (CG) binding of certain educational metadata together with CG rules, to serve primarily as a personal memory assistant.",1
A knowledge based approach on educational metadata use,2001,https://link.springer.com/chapter/10.1007/3-540-38076-0_14,"One of the most rapidly evolving e-services is e-Learning, that is, the creation of advanced educational resources that are accessible on-line and, potentially, offer numerous advantages over the traditional ones like intelligent access, interoperability between two or more educational resources and adaptation to the user. The driving force behind these approaches is the definition of the various standards about educational metadata, that is, data describing learning resources, the learner, assessment results, etc. The internal details of systems that utilize these metadata is an open issue since these efforts are primarily dealing with “what” and not “how”. Under the light of these emerging efforts, we present CG-PerLS, a knowledge based approach for organizing and accessing educational resources. CG-PerLS is a model of a web portal for learning objects that encodes the educational metadata in the …",0
Fuzzy meta-learning: preliminary results,2001,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.21.4912&rep=rep1&type=pdf,"Learning from distributed data is becoming in our times a necessity, but it is also a complex and challenging task. Approaches developed so far have not dealt with the uncertainty, imprecision and vagueness involved in distributed learning. Meta-Learning, a successful approach for distributed data mining, is in this paper extended to handle the imprecision and uncertainty of the local models and the vagueness that characterizes the meta-learning process. The proposed approach, Fuzzy Meta-Learning uses a fuzzy inductive algorithm to meta-learn a global model from the degrees of certainty of the output of local classifiers. This way more accurate models of collective knowledge can be acquired from data with application both to inherently distributed databases and parts of a very large database. Preliminary results are promising and encourage further research towards this direction.",1
The GRT planner: New results,2000,https://link.springer.com/chapter/10.1007/3-540-45612-0_8,"This paper presents recent extensions to the GRT planner, a domain-independent heuristic state-space planner for STRIPS worlds. The planner computes off-line, in a pre-processing phase, estimates for the distances between each problem’s fact and the goals. These estimates are utilized during a forward search phase, in order to obtain values for the distances between the intermediate states and the goals.The paper focuses on several problems that arise from the backward heuristic computation and presents ways to cope with them. Moreover, two methods, which concern automatic domain enrichment and automatic irrelevant objects elimination, are presented. Finally, the planner has been equipped with a hill-climbing strategy and a closed list of visited states for pruning purposes. Performance results show that GRT exhibits significant improvement over its AIPS-00 competition version.",1
Automating the evaluation of educational software,1999,https://www.academia.edu/download/46076208/Automating_the_Evaluation_of_Educational20160530-11884-cqli8h.pdf,"This paper proposes a framework for educational software evaluation based on the Multiple Criteria Decision Aid methodology, supported by ESSE, an Expert System for Software Evaluation. An evaluation example is presented that illustrates the overall evaluation process. Evaluating educational software products is a twofold process: both the technical and the educational aspect of the evaluated products have to be considered. As far as the product’s educational effectiveness is concerned, the flexibility of ESSE in problem modeling allows the development and the use of a set of criteria, which clearly describe the context, and the educational setting in which the software products are to be used. From the technical point of view, a software attribute set based on the ISO/IEC 9126 standard has been chosen together with the accompanying measurement guidelines.",1
OASys: An AND/OR parallel logic programming system,1999,https://www.sciencedirect.com/science/article/pii/S0167819198001082,"The OASys (Or/And SYStem) is a software implementation designed for AND/OR-parallel execution of logic programs. In order to combine these two types of parallelism, OASys considers each alternative path as a totally independent computation (leading to OR-parallelism) which consists of a conjunction of determinate subgoals (leading to AND-parallelism). This computation model is motivated by the need for the elimination of communication between processing elements (PEs). OASys aims towards a distributed memory architecture in which the PEs performing the OR-parallel computation possess their own address space while other simple processing units are assigned with AND-parallel computation and share the same address space. OASys execution is based on distributed scheduling which allows either recomputation of paths or environment copying. We discuss in detail the OASys execution scheme …",0
The basic OASys model: preliminary results,1997,http://eprints.lib.uom.gr/574/,"½¤ ¾¿ rÀ ÁiÂBÃeÀ ÄmÅ Æ Æ} Ç ÈBÉÊiËÌ ÍiÌsËÊiÎÏ Ê ÐÈ Í Ñ ÍiÉÉÆ} ÉËÒ Ó¦ ÌsÅ ÍiÌ ËÒ Î Í Ì ÔxÑPÍ ÉÉÕÖ Æ ÓA× yÆ ØxØBÆ ØÖ ËÎ¦ Ì Å Æ ØBÆ Ù} ÉÍ ÑPÍ ÌsËÚeÆ"" Ò Æ Ó"" ÍiÎ2ÌsËÙ Ò ÊuÐÉÊiÛiËÙ"" ÈxÑPÊ ÛeÑ ÍeÓ"" Ò Å ÍiÒ× yÆ Æ} ÎÖ Í'Ó"" ÍiÜXÊiÑ ËÒ ÒoÔ ÆÝ ÊuÐÌ ÅBÆ {É Ê ÛiË Ù"" ÈBÑPÊ ÛeÑ ÍiÓÝÓ ËÎxÛ@ Ù ÊeÓ"" Ó¥ ÔBÎBËÌXÕÖ ËÎÖ ÌsÅ Æ {È ÍiÒsÌ ØxÆ Ù ÍeØxÆeÞ ßhÍ Ñ ËÊ Ô Òi Ó"" Ê ØBÆ} ÉÒi Í Î ØH Í ÑPÙ ÅBËÌ Æ Ù} Ì ÔBÑ Æ Òi Å Í Ú2Æ× bÆ Æ} Î'ÈBÑ Ê ÈyÊeÒsÆ Ø'ËÎ@ Ê ÑPØBÆ} Ñm Ì Ê ÍeÙ ÅxË Æ} ÚeÆ¥ Ì Å Æ Íi× bÊTÚeÆ Ó"" Æ} Î2ÌsË Ê Î Æ Ø¦ Ì ÍiÒ àbÞm ÄmÅBËÒ È Í ÈyÆ} Ñ ØBÆ ÒsÙ} Ñ Ë× yÆ Òi ÌsÅ Æ¥× ÍeÒoËÙÝ á0â ã2ÕBÒ {ä âiÎ Ø6åiáæÑ¥ ã2ÕxÒsÌ Æ Ó (çrè Í¤ Ù ÊiÓ"" ÈBÔxÌPÍ Ì ËÊ Î ÍiÉ Ó"" Ê ØBÆ} É6 ØBÆ ÒsËÛiÎ Æ Ø (Ð Ê Ñ0 ÈBÍiÑ ÍiÉÉÆ} É Æ} ÇxÆ Ù} ÔBÌsËÊiÎ'ÊuÐ ÉÊ ÛeËÙ ÈBÑ ÊiÛiÑ ÍeÓ"" ÒTÞá0â ã2ÕBÒh ÈyÆ} ÑoÐ Ê Ñ ÓÝÒi áæé È Í ÑPÍ ÉÉÆ} ÉË ÒsÓ¢× 2Õ ÍiÒsÒsËÛeÎxËÎxÛ¤ Æ ÍiÙ Å¤ ËÎ ØBÆ} ÈyÆrÎ ØBÆ} Î2Ìæ áæé È Í ÌsÅ¤ ÌPÊ¥ ÍA ØxËêyÆ} ÑPÆ} ÎeÌ0 ÈxÑPÊ Ù Æ Ò ÒoËÎBÛ Æ} ÉÆ Ó"" Æ} Î2ÌTèB Í Î Ø¤ âië ì í ÈBÍiÑ ÍiÉÉÆ} ÉËÒ Ó× eÕ"" Æ} ÇBÆ Ù} ÔxÌ ËÎBÛA Ì Å Ææ Ù Ê ÎeÜ ÔBÎ Ù} ÌsËÚ2Ææ ØBÆ} Ì Æ} Ñ Ó"" ËÎ Í ÌPÆæ ÒoÔB× BÛeÊeÍ ÉÒm ÒsËÓAÔxÉÌ Í Î Æ ÊiÔBÒsÉÕ2Þm ÄmÅ Æi Ó"" Ê ØBÆ} É Ë ÒØBÆ ÒsËÛiÎ Æ Ø¤ ËÎ ÒoÔ Ù ÅA îmÍ Õ¥ Ì Å Í Ì Í ÉÉB Ù ÊiÓÝÓ¥ ÔBÎBËÙ Í Ì ËÊ ÎÝ× bÆ} ÌXîmÆ Æ} Î¥ ÌsÅ Æh ÈBÑPÊ Ù Æ Ò ÒoËÎBÛ ÔxÎBËÌPÒ ËÒ ÉËÓ ËÌPÆ Ø {Ì Êæ ÊiÎBÉÕ¥ ÌsÅ ÆÎ Æ Ù Æ} Ò ÒsÍiÑsÕ ÒsÙ Å Æ ØxÔxÉËÎBÛÖ Ê ÐF ØxËêyÆ} Ñ Æ} Î2Ì {Ì ÍiÒ à Ò ÌsÅ ÍiÌ Í ÑPÆ Û2Æ} Î ÆrÑPÍ ÌPÆ ØÖ Ø ÔBÑ ËÎBÛ@ Ì ÅBÆ {ÈBÑPÊ ÛeÑ ÍiÓ Æ} ÇBÆ Ù} ÔxÌ ËÊ Î Þ ÄmÅBËÒ È Í ÈyÆ} Ñ Í ÉÒ Ê¥ ÈBÑ Æ Ò Æ} Î2Ì ÒÈBÑ Æ} ÉËÓ"" ËÎ …",0
A contribution to the problem of avoiding congestion in multistage networks in the presence of unbalanced traffic,1994,https://www.sciencedirect.com/science/article/pii/0164121294900175,Multistage packet-switched interconnection networks (MINs) have been proposed for use in parallel processing systems and for implementation of fast packetswitch architecture designs. Performance of these networks has been known to severely degrade under unbalanced (nonuniform) traffic patterns. This article proposes various flow control procedures and corresponding logical implementations as possible solutions to the problem of performance degradation of such systems. Simulation results are presented to show the potential to improve MIN performance by introducing the proposed flow-control procedures.,1
Cooperative CG-wrappers for web content extraction,2007,https://link.springer.com/chapter/10.1007/978-3-540-73681-3_38,"We use Conceptual Graphs (CGs) to model web content extraction rules (CG-Wrappers). The approach presented incorporates all major existing extraction techniques and allows the definition of synergies of cooperative wrappers for handling complex extraction task, without requiring programming.",1
A graphical rule authoring tool for defeasible reasoning in the semantic web,2005,https://link.springer.com/chapter/10.1007/11573036_38,"Defeasible reasoning is a rule-based approach for efficient reasoning with incomplete and inconsistent information. Such reasoning is useful for many applications in the Semantic Web, such as policies and business rules, agent brokering and negotiation, ontology and knowledge merging, etc. However, the syntax of defeasible logic may appear too complex for many users. In this paper we present a graphical authoring tool for defeasible logic rules that acts as a shell for the DR-DEVICE defeasible reasoning system over RDF metadata. The tool helps users to develop a rule base using the OO-RuleML syntax of DR-DEVICE rules, by constraining the allowed vocabulary through analysis of the input RDF namespaces, so that the user does not have to type-in class and property names. Rule visualization follows the tree model of RuleML. The DR-DEVICE reasoning system is implemented on top of the CLIPS …",0
Machine learning for adaptive planning,2005,https://www.igi-global.com/chapter/intelligent-techniques-planning/24460,This chapter is concerned with the enhancement of planning systems using techniques from Machine Learning in order to automatically configure their planning parameters according to the morphology of the problem in hand. It presents two different adaptive systems that set the planning parameters of a highly adjustable planner based on measurable characteristics of the problem instance. The planners have acquired their knowledge from a large data set produced by results from experiments on many problems from various domains. The first planner is a rule-based system that employs propositional rule learning to induce knowledge that suggests effective configuration of planning parameters based on the problem’s characteristics. The second planner employs instance-based learning in order to find problems with similar structure and adopt the planner configuration that has proved in the past to be effective …,0
Metadata Aware Peer-to-Peer Agents for the e-Learner,2003,https://www.academia.edu/download/37730202/extension_of_rdfs_based_on_the_cgs_formalisms.pdf,"Metadata, being the first building block of the emerging semantic web, will enable computers to understand what the accessed information is all about, allowing in that way the building of advanced web services. The e-Learning domain is one of the first that is benefited by the definition, among others, of the Learning Object Metadata (LOM). From another perspective, the distributed nature of the web suggests that agent technologies will play a key role towards the use of these metadata. In this paper, we detail a Conceptual Graph (CG) binding of LOM (CG/LOM) and present the eLPA, a knowledge based, client side, metadata aware, peer-to-peer agent, that relies solely on the CG knowledge representation formalism. eLPA serves primarily as a personal memory agent for the e-learner.",1
An educational metadata management system using a deductive object-oriented database approach,2002,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.127.7696&rep=rep1&type=pdf,"Internet-based education and training offer many potential benefits specific to adult learners with emphasis given to learner-centered and self-directed instruction models empowered by web-based educational resources. Indeed, the recent growth of the World Wide Web (WWW) has greatly increased the amount of information and educational resources available to the education community.The full exploitation of this mass body of knowledge resources available on the Web, can be, however, compromised, by the difficulty in describing, classifying and maintaining those resources in such a way that they can be retrieved in an “educationally efficient and effective way”. Today, the web community has embraced the collection and use of metadata to characterise and index educational resources, which lead to semantically more accurate retrieval of information than search engines. In general sense, metadata is information about data. In the context of resource discovery, descriptive metadata is a characterisation that aims to represent the intellectual content of the resource. The most popular technology for representing metadata is XML (eXtensible Markup Language).",1
Bi-Directional Heuristic Planning in State-Spaces,2001,https://www.researchgate.net/profile/I-Vlahavas/publication/255600796_BiDirectional_Heuristic_Planning_in_State-Spaces/links/541ac0e70cf2218008bfddfd/BiDirectional-Heuristic-Planning-in-State-Spaces.pdf,"One of the most promising trends in Domain Independent AI Planning, nowadays, is state–space heuristic planning. The planners of this category construct general but efficient heuristic functions, which are used as a guide to traverse the state space either in a forward or a backward direction. Although specific problems may favor one or the other direction, there is no clear evidence why any of them should be generally preferred. This paper proposes a hybrid search strategy that combines search in both directions. The search begins from the Initial State in a forward direction and proceeds with a weighted A* search until no further improving states can be found. At that point, the algorithm changes direction and starts regressing the Goals trying to reach the best state found at the previous step. The direction of the search may change several times before a solution can be found. Two domain-independent heuristic functions based on ASP/HSP planners enhanced with a Goal Ordering technique have been implemented. The whole bi-directional planning system, named BP, was tested on a variety of problems adopted from the recent AIPS-00 planning competition with quite promising results.",1
A Heuristic Based Approach to Planning in Strips Domains,2000,https://www.worldscientific.com/doi/abs/10.1142/9789812793928_0027,"This paper presents a new domain independent heuristic for STRIPS worlds, which estimates the distance between each intermediate state and the goal state of a planning problem, guiding in this way the search process of any state-space planner. At the beginning of the problem solving process a table is created, the records of which contain the ground facts of the domain, among with estimations for their distances from the goal state. Additionally, the records contain information about interactions that occur while trying to achieve different ground facts simultaneously. During the search process, quite accurate estimations for the distances between intermediate states and the goal state can be extracted by this table. In order to have a notion of the efficiency of the proposed heuristic, a simple planner consisting of a best-first search algorithm that uses the proposed heuristic has been implemented in PROLOG. The …",0
On the Parallelization of Greedy Regression Tables,1999,http://lpis.csd.auth.gr/publications/pgrt.pdf,"This paper presents PGRT, a parallel version of a best first planner based on the Greedy Regression Tables approach. The parallelization method of PGRT distributes the task of extracting applicable actions to a given state among the available processors. Although the number of operators limits the scalability of PGRT, it has proven to be quite efficient for low scale parallelization. A modified Operator Reordering method has been used in order to achieve further increase in the efficiency of the parallel algorithm. We illustrate the speedup of PGRT on a variety of hard logistics problems, adopted from the AIPS-98 planning competition.",1
Controlling performance degradation of multistage interconnection networks with non-uniform traffic,1999,https://www.tandfonline.com/doi/abs/10.1080/02286203.1999.11760424,"Multistage Interconnection Networks (MINs) have been proposed as an efficient interconnection medium for parallel computers. In addition, many ATM switch architectures have been proposed in the literature and most of them adopt a multistage arrangement of simple switching elements with self-routing capabilities. In MINs the performance estimates obtained under uniform traffic tend to be optimistic since the presence of unbalanced traffic loads could result in increased congestion. In this paper, a non-uniform model that captures non-uniform traffic in the presence of hotspot is described. Also, we present a solution to the problem of performance degradation of MINs, with non-uniform traffic, which includes a feedback based flow control scheme, a switching strategy that implements priority policies at the packet level, and a switch model. Finally, we demonstrate the effectiveness of the proposed approach by …",0
A deductive object-oriented database system based on active rules,1997,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.28.7893&rep=rep1&type=pdf,"This paper describes a Deductive Object-Oriented Database (DOOD) system that is built on top of an active Object-Oriented Database (OODB) system. The system, named DEVICE, uses the primitives of the latter, like active rules, simple and complex events, to integrate deductive and production rules. The integration is based on the emulation of deductive rules by special purpose if-then-else production rules that have been smoothly integrated into an active OODB. The DEVICE system supports thus multiple rule systems, like active (event-driven), production (data-driven) and deductive (goal-driven) rules into the same OODB system. The core of this multiple rule integration is: a) the mapping of each high-level rule into one event-driven rule, offering centralised rule selection control for correct run-time behaviour and conflict resolution, and b) the use of complex events to map the conditions of high-level rules and monitor the database to incrementally match those conditions. DEVICE is extensible because a) it reuses the primitives of the host active OODB system to build the integration scheme, without introducing low-level data structures that do not blend well with the OO model and are not easily extensible, and b) the rule managers support general-purpose rule scheduling functions. In conclusion, DEVICE is a flexible Knowledge Base System (KBS) that gives the user the ability to express knowledge in a variety of high-level forms for advanced problem solving in data intensive applications.",1
Multiple OR-parallel resolution: Meta-level control of parallel logic programs,1996,https://link.springer.com/chapter/10.1007/3-540-61626-8_91,"Multiple OR-parallel Resolution (MORE) Prolog is a combination of a pure logic language and control directives expressed as a meta-program. The meta-program affects the default resolution strategy by suspending execution of particular predicates, ordering the suspended processes and selectively reactivating them, thus achieving the desired kind of resolution. In this paper, we formally define the computation process of MORE-Prolog and illustrate how a set of primitive directives could be combined, leading in effect to application of different parallel search algorithms over the same state space. Finally, the effectiveness of MORE-Prolog is demonstrated by presenting different meta-programs which result in different performance if applied on the same logic program.",1
Parallel management of large deductive databases in a multi-processor environment,1994,https://ieeexplore.ieee.org/abstract/document/380912/,"This paper describes a parallel deductive database system, built on top of Prolog. The system is based on the TOP-DOWN evaluation of logic programs. Parallelism is provided at the rule level, by transforming the query AND/OR tree into Disjunctive Normal Form. The clauses of the transformed formula are executed independently in parallel, on a transputer multi-processor machine, using the processor-farm algorithm. Both main-memory consultation and direct disk access have been implemented and tested. The measurement of the system performance shows speed improvement over the sequential Prolog interpreter, for large rule bases, but also exhibits implementation-dependent drawbacks that cause under-linear speed-up.< >",1
A novel flow control and switching strategy for preventing hotspot congestion in multistage networks,1993,https://www.sciencedirect.com/science/article/pii/014193319390063D,Multistage packet switched interconnection networks have been proposed both for use in parallel processing systems and for communications switching. The performance of these networks has been known to degrade severely with non-uniformities in the traffic distribution. In this paper we present a combination of a flow control scheme with a novel switching strategy that reduces the performance degradation of such networks. We also present a switch model in order to support the proposed solution. Simulation results are presented to show that this method can successfully improve the overall network performance.,1
LBASE: A Logical Database Management System,1991,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.54.5341&rep=rep1&type=pdf,"Logic offers a uniform environment both for data description and program execution and provides a powerful programming language with the use of"" headed"" queries. Relational data model proved to be the best model of the"" conventional"" database theory This paper describes the advantages of connecting a relational database management system (RDBMS) with logic programming, building a logical DBMS (LDBMS) that extends the power of the relational data model. Relations are described both by facts (assertions) and rules (deductions), so data become more meaningful, and complex queries can be answered. Memory organisation also provides space saving and efficient indexing using b-trees instead of sequential searching.",1
REIN-2: Giving Birth to Prepared Reinforcement Learning Agents Using Reinforcement Learning Agents,2021,https://arxiv.org/abs/2110.05128,"Deep Reinforcement Learning (Deep RL) has been in the spotlight for the past few years, due to its remarkable abilities to solve problems which were considered to be practically unsolvable using traditional Machine Learning methods. However, even state-of-the-art Deep RL algorithms have various weaknesses that prevent them from being used extensively within industry applications, with one such major weakness being their sample-inefficiency. In an effort to patch these issues, we integrated a meta-learning technique in order to shift the objective of learning to solve a task into the objective of learning how to learn to solve a task (or a set of tasks), which we empirically show that improves overall stability and performance of Deep RL algorithms. Our model, named REIN-2, is a meta-learning scheme formulated within the RL framework, the goal of which is to develop a meta-RL agent (meta-learner) that learns how to produce other RL agents (inner-learners) that are capable of solving given environments. For this task, we convert the typical interaction of an RL agent with the environment into a new, single environment for the meta-learner to interact with. Compared to traditional state-of-the-art Deep RL algorithms, experimental results show remarkable performance of our model in popular OpenAI Gym environments in terms of scoring and sample efficiency, including the Mountain Car hard-exploration environment.",1
TP-DDI: Transformer-based pipeline for the extraction of Drug-Drug Interactions,2021,https://www.sciencedirect.com/science/article/pii/S0933365721001469,"Drug-Drug Interaction (DDI) extraction is the task of identifying drug entities and the potential interactions between drug pairs from biomedical literature. Computer-aided extraction of DDIs is vital for drug discovery, as this process remains extremely expensive and time consuming. Therefore, Machine Learning-based approaches can reduce the laborious task during the drug development cycle. Numerous traditional and Neural Network-based approaches for Drug Named Entity Recognition (DNER) and the classification of DDIs have been proposed over the years. However, despite the development of many effective methods, achieving good prediction accuracy is an area where significant improvement can be made. In this article, we present a novel end-to-end approach that tackles the overall DDI extraction task as a pipelined method via the Transformer model architecture and biomedical domain pre-trained …",0
Serious Game Development for the Diagnosis of Major Depressive Disorder Cases Using Machine Learning Methods,2020,http://ceur-ws.org/Vol-2844/games6.pdf,"Major Depressive Disorder (MDD) is a serious mental disorder that affects millions of adults, occasionally leading to life-threatening results. Current diagnostic tools for MDD mostly consist of questionnaires and/or long, specialized therapy sessions. In this work we present a serious game called"" The Delivery"", developed for diagnosing MDD in players. The video game has the players immerse into a realistic scenario, the development of which depends on their actions, that is, through conversations with in-game characters, completion of quests, and interactions with the environment. All in-game features and mechanics are designed to correspond to specific diagnostic criteria for MDD. We recorded gameplay data from labeled players (both MDD and non-MDD cases) in order to train Machine Learning models that can accurately distinguish gameplay behaviors MDD-positive and MDD-negative players.",1
Machine Learning Methods for Customer's Payment Acceptance Prediction in an Electricity Distribution Company,2017,https://dl.acm.org/doi/abs/10.1145/3139367.3139406,"In this short paper, we use machine learning methods to maximise the efficiency in the Hellenic Electricity Distribution Network Operator (HEDNO) SA's project management by predicting which upcoming projects are going to be paid by the customer, thus enabling the company to fetch all needed materials in time, and to avoid unwanted delays in the operations of the company.",1
The AIPS'00 Planning Competition-The GRT Planner,2001,https://scholar.google.com/scholar?cluster=14746688208599201602&hl=en&oi=scholarr,Unknown,1
PARCIS: a robust parallel VLSI circuit simulator,1999,https://www.sciencedirect.com/science/article/pii/S0928486998000202,"The accurate verification of VLSI circuits is essential for their successful and economic production but is an extremely time consuming process for the large circuits of today. This paper describes a robust parallel circuit simulator, PARCIS, designed for a message passing multiprocessing system. It uses a demand driven technique, based on the analysis of hierarchically partitioned circuits. The computation time is reduced by decoupling the circuit equations and distributing the computational load over many processors. On each processor, the circuit blocks, compacted in hierarchical levels, are analyzed asynchronously according to their temporal activity. Currently the PARCIS system is running on a network of transputers. To demonstrate the effectiveness of the proposed simulation program, results are presented for the simulation of typical digital circuits, showing that the execution time decreases in a constant rate …",0
OASys,1999,https://scholar.google.com/scholar?cluster=10410696797238284572&hl=en&oi=scholarr,"The OASys (Or/And SYStem) is a software implementation designed for AND/OR-parallel execution of logic programs. In order to combine these two types of parallelism, OASys considers each alternative path as a totally independent computation (leading to OR-parallelism) which consists of a conjunction of determinate subgoals (leading to AND-parallelism). This computation model is motivated by the need for the elimination of communication between processing elements (PEs). OASys aims towards a distributed memory architecture in which the PEs performing the OR-parallel computation possess their own address space while other simple processing units are assigned with AND-parallel computation and share the same address space. OASys execution is based on distributed scheduling which allows either recomputation of paths or environment copying. We discuss in detail the OASys execution scheme and we demonstrate OASys e ectiveness by presenting the results obtained by a prototype implementation, running on a network of workstations. The results show that speedup obtained by AND/OR-parallelism is greater than the speedups obtained by exploiting AND or OR-parallelism alone. In addition, comparative performance measurements show that copying has a minor advantage over recomputation",1
Integration of Multiple Rule Types,1998,https://link.springer.com/chapter/10.1007/978-1-4757-6134-4_3,"In the previous chapter we have presented the integration of various rule types in various database systems. All rule paradigms are useful for different tasks in the database system. Therefore, the integration of multiple rule types in the same system is important. This will provide a single, flexible, multi-purpose knowledge base management system.",1
Parallel Database Systems,1998,https://link.springer.com/chapter/10.1007/978-1-4757-6134-4_5,"In this chapter we overview some of the issues of parallel database systems, including object-oriented systems. This discussion is vital for understanding several issues related to concurrent processing of data in parallel systems. The material presented here will help understanding the parallel execution of rules in parallel knowledge base systems, in the next chapter.",1
A Parallel Object-Oriented Knowledge Base System,1998,https://link.springer.com/chapter/10.1007/978-1-4757-6134-4_7,"In this chapter, we present in detail a parallel object-oriented knowledge base system, called PRACTICKB. PRACTICKB implements the rule integration techniques of the DEVICE knowledge base system (presented in chapter 4) on top of a parallel object-oriented database system, named PRACTIC [14, 15]. The implementation of DEVICE in PRACTIC involves issues concerning the distribution and parallel execution of complex event detection and rule processing.",1
Parallel Knowledge Base Systems,1998,https://link.springer.com/chapter/10.1007/978-1-4757-6134-4_6,"In this chapter, we discuss the various theoretical and implementation issues and approaches to parallel knowledge base systems. The main problems concerning parallel execution of rules are: how to speed-up the matching of rule conditions by distrubuting them in a multiprocessor machine, and how to execute rules in parallel in such a way that the sequential semantics of rule programs are preserved. The discussion includes parallel production systems, parallel deductive, and parallel active databases.",1
Deductive and Active Databases,1998,https://link.springer.com/chapter/10.1007/978-1-4757-6134-4_2,"In this chapter we overview deductive and active databases which are the two different paths that have been followed towards the integration of rules in database systems. We do not extensively present every theoretical and/or implementation detail of these systems, but we mainly focus on the issues that will prove useful for the understanding of the unification of various rule systems that will be discussed in the next chapter.",1
Parallel Logic Programming,1998,https://link.springer.com/chapter/10.1007/978-1-4615-5119-5_3,"Although the sequential computing technology has been successfully applied since the dawn of the information technology era, researchers have realized that a feasible solution to the problem of achieving high performance computing systems, was the construction of multiprocessor machines for parallel execution of programs. The latter involves not only the development of parallel computer architectures but also the development of parallel programming languages, which proved to be the harder of the two tasks; the term parallel programming refers to the efficient execution of a single program on multiple processors.",1
Constraint Logic Programming,1998,https://link.springer.com/chapter/10.1007/978-1-4615-5119-5_4,"Constraint Logic Programming (CLP) is a fast evolving powerful framework of programming languages with significant applications. The insight which led to the design of the CLP framework is the observation that the algorithm of unification used in Logic Programming is a constraint solving algorithm and as such it could be combined with, or replaced by, various other constraint solving algorithms. In other words, Logic Programming (LP) offers the means to create a single and powerful framework for various cooperating constraint solving algorithms. In this sense, we can say that CLP merges two declarative paradigms: logic programming and constraint solving. The generalization of Logic Programming into Constraint Logic Programming offers important application areas. Solutions based on CLP have been used in a variety of applications like, for example, scheduling, resource allocation, timetabling …",0
Logic Programming,1998,https://link.springer.com/chapter/10.1007/978-1-4615-5119-5_2,"This part of the book is a brief description of logic programming; this was considered necessary, in order to smoothly introduce the reader to the notation and terms that will be used in the presentation of parallel and constraint logic programming. However, we should stress that what is presented here is just a small introduction, that could not possibly cover in depth the vast field of logic programming. In order to obtain a complete view of the field, the interested reader should refer to other books, some of which appear in the selected bibliography section of this chapter; this introduction has mainly been based on them.",1
IDIS-KS: an Intelligent Drug Information System as a Knowledge Server,1997,https://ebooks.iospress.nl/doi/10.3233/978-1-60750-887-8-368,"Expert System technology in combination with other technologies such as Networks and Data Base systems can prove to be a valuable tool for medical experts, providing decision support and information services, and therefore facilitating and improving their everyday tasks. IDIS-KS described in this paper, is an consultation and information system dedicated to deliver drug information and suggestions about possible treatments to medical practicioners in the National area of Greece.",1
Classification of Concept Drifting Data Streams–Bibliography,1996,https://www.academia.edu/download/42207527/conceptdrift_bibliography.pdf,"Classification of Concept Drifting Data Streams – Bibliography Page 1 Classification of Concept 
Drifting Data Streams – Bibliography Ioannis Katakis, Grigorios Tsoumakas and Ioannis 
Vlahavas Department of Informatics, Aristotle University of Thessaloniki 54124 Thessaloniki, 
Greece {katak, greg, vlahavas}@csd.auth.gr Last Update: May 5, 2008 [1] Domingos, P. and 
Hulten, G., Mining high-speed data streams. Knowledge discovery and data mining, 2000: p. 
71-80. [2] Fan, W. Systematic data selection to mine concept-drifting data streams. in Tenth 
ACM SIGKDD international conference on Knowledge Discovery and Data Mining. 2004. 
Seattle, WA, USA: ACM Press: p. 128-137. [3] Forman, G. Tackling Concept Drift by Temporal 
Inductive Transfer. in 29th International ACM SIGIR Conference on Research and Development 
in Information Retrieval. 2006. Washington, USA: ACM Press: p. 252-259. [4] Hulten, G., , L., -…",0
Flow control and switching strategy for preventing congestion in multistage networks,1994,https://link.springer.com/chapter/10.1007/978-1-4757-4536-8_5,"Multistage Interconnection Networks are used in parallel computer applications as well as in new, high performance packet switch architecture for communication systems. In these networks the presence of unbalanced traffic loads creates significant performance problems. The main goal of this paper is to propose: (a) a flow control scheme, which permits the characterization of the traffic distribution, and (b) switching strategies, at the packet level, for controlling this performance degradation. We also present a switch model, in order to support the suggested solutions. The proposed solutions can be implemented with minimal additional logic in the switch design. Simulation results are presented to test the effectiveness of the proposed approach.",1
An abstract prolog machine based on parallel resolution principle,1992,https://www.sciencedirect.com/science/article/pii/016560749290399R,"We describe an abstract machine, called SPUM, for the AND parallel execution of Prolog programs. We also present a resolution algorithm for logic programs, on which the SPUM architecture is based. The algorithm, called SPU, is based on parallel resolution principle and allows parallel execution of unificationsof a deterministic path of the proof tree, giving in effect dependent and-parallelism. We also present preliminary results which are indicative of the performance expected from SPUM.",1
PORSCE II: Using planning for semantic web service composition,0,https://www.academia.edu/download/42558797/ICKEPS2009_hatzi_p38-45.pdf,"This paper presents PORSCE II, an integrated system that performs automatic semantic web service composition through planning. In order to achieve that, an essential step is the translation of the web service composition problem into a planning problem. The planning problem is then solved using external domain-independent planning systems, and the solutions are visualized and evaluated. The system exploits semantic information to enhance the translation and planning processes.",1
An Empirical Study of Multi-label Learning Methods for Video,0,https://www.academia.edu/download/35531201/tsoumakas-cbmi09.pdf,This paper presents an experimental comparison of different approaches to learning from multi-labeled video data. We compare state-of-the-art multi-label learning methods on the Mediamill Challenge dataset. We employ MPEG-7 and SIFT-based global image descriptors independently and in conjunction using variations of the stacking approach for their fusion. We evaluate the results comparing the different classifiers using both MPEG-7 and SIFT-based descriptors and their fusion. A variety of multi-label evaluation measures is used to explore advantages and disadvantages of the examined classifiers. Results give rise to interesting conclusions.,1
Improving Diversity in Image Search via Supervised Relevance Scoring,0,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.735.2338&rep=rep1&type=pdf,"Results returned by commercial image search engines should include relevant and diversified depictions of queries in order to ensure good coverage of users’ information needs. While relevance has drastically improved in recent years, diversity is still an open problem. In this paper we propose a reranking method that could be implemented on top of such engines in order to provide a better balance between relevance and diversity. Our method formulates the reranking problem as an optimization of a utility function that jointly considers relevance and diversity. Our main contribution is the replacement of the unsupervised definition of relevance that is commonly used in this formulation with a supervised classification model that strives to capture a query and application-specific notion of relevance. This model provides more accurate relevance scores that lead to significantly improved diversification performance. Furthermore, we propose a stacking-type ensemble learning approach that allows combining multiple features in a principled way when computing the relevance of an image. An empirical evaluation carried out on the datasets of the MediaEval 2013 and 2014 “Retrieving Diverse Social Images”(RDSI) benchmarks confirms the superior performance of the proposed method compared to other participating systems as well as a stateof-the-art, unsupervised reranking method.",1
E-mail mining: Emerging techniques for e-mail management,2007,https://www.igi-global.com/chapter/web-data-management-practices/31103,"Email has met tremendous popularity over the past few years. People are sending and receiving many messages per day, communicating with partners and friends, or exchanging files and information. Unfortunately, the phenomenon of email overload has grown over the past years becoming a personal headache for users and a financial issue for companies. In this chapter, we will discuss how disciplines like Machine Learning and Data Mining can contribute to the solution of the problem by constructing intelligent techniques which automate email managing tasks and what advantages they hold over other conventional solutions. We will also discuss the particularity of email data and what special treatment it requires. Some interesting email mining applications like mail categorization, summarization, automatic answering and spam filtering will be also presented.",1
Heuristic planning with resources,2000,http://m.frontiersinai.com/ecai/ecai2000/pdf/p0521.pdf,"This paper presents GRT-R, an enhanced version of the GRT planner capable of explicitly handling resources. GRT is a domain independent heuristic STRIPS planner, which works in the space of the states. The heuristic computes off-line, in a preprocessing phase, estimates for the distances between the domain's facts and the goals. These estimates are utilized during the search process, in order to obtain values for the distances between the intermediate states and the goals. We propose an explicit representation of resources in a numerical way. There are two kinds of resources: the consumable and the allocable ones. In the pre-processing phase, GRT-R assigns to the domain's facts vectors of costs. The first cost is an estimate of the distance between a fact and the goals, while the remaining costs estimate the amount of consumable resources needed to achieve that fact. GRT-R assigns each fact with a set of such vectors, each one of them corresponding to a different way of achieving the fact. During the search process, GRT-R assigns similarly each intermediate state with such a vector, based on the vectors of the state's facts, with the intention to minimize the distance between the state and the goals, without exceeding the available resources. Allocable resources are taken into account only while searching, in order to preserve the validity of the states. Performance results show that GRT-R copes well in domains that embody resources.",1
ExperNet: an intelligent multiagent system for WAN management,2002,https://ieeexplore.ieee.org/abstract/document/988459/,"The authors describe ExperNet, an intelligent multiagent system developed to assist in managing large-scale data networks. The system assists network operators at various nodes of a WAN to detect and diagnose hardware failures and network traffic problems, suggesting the most feasible solution through a Web-based interface.",1
Smart VideoText: a video data model based on conceptual graphs,2002,https://link.springer.com/content/pdf/10.1007/s005300200054.pdf," An intelligent annotation-based video data model called Smart VideoText is introduced. It utilizes the conceptual graph knowledge representation formalism to capture the semantic associations among the concepts described in text annotations of video data. The aim is to achieve more effective query, retrieval, and browsing capabilities based on the semantic content of video data. Finally, a generic and modular video database architecture based on the Smart VideoText data model is described.",1
"Processing production rules in DEVICE, an active knowledge base system",1997,https://www.sciencedirect.com/science/article/pii/S0169023X97000062,"Production rules are useful for several tasks in active database systems, such as integrity constraint checking, derived data maintenance, database state monitoring, etc. Furthermore, production rules can express knowledge in a high-level form for problem solving in Knowledge Base Systems (KBS). Present active object-oriented database (OODB) systems traditionally provide event-driven rules which are triggered by events, i.e. database modifications. This paper describes DEVICE, a high-level rule integration scheme in an active OODB system, resulting in an active KBS. The paper emphasises the run-time processing of production rules, namely the incremental matching of rule conditions, as well as rule selection and firing. The matching of production rules requires special algorithms based on the flow of updated data through a discrimination network, like RETE, TREAT, etc. DEVICE offers a smooth integration …",0
PolyA-iEP: A data mining method for the effective prediction of polyadenylation sites,2011,https://www.sciencedirect.com/science/article/pii/S0957417411005355,"This paper presents a study on polyadenylation site prediction, which is a very important problem in bioinformatics and medicine, promising to give a lot of answers especially in cancer research. We describe a method, called PolyA-iEP, that we developed for predicting polyadenylation sites and we present a systematic study of the problem of recognizing mRNA 3′ ends which contain a polyadenylation site using the proposed method. PolyA-iEP is a modular system consisting of two main components that both contribute substantially to the descriptive and predictive potential of the system. In specific, PolyA-iEP exploits the advantages of emerging patterns, namely high understandability and discriminating power and the strength of a distance-based scoring method that we propose. The extracted emerging patterns may span across many elements around the polyadenylation site and can provide novel and …",0
Improving the accuracy of classifiers for the prediction of translation initiation sites in genomic sequences,2005,https://link.springer.com/chapter/10.1007/11573036_40,"The prediction of the Translation Initiation Site (TIS) in a genomic sequence is an important issue in biological research. Although several methods have been proposed to deal with this problem, there is a great potential for the improvement of the accuracy of these methods. Due to various reasons, including noise in the data as well as biological reasons, TIS prediction is still an open problem and definitely not a trivial task. In this paper we follow a three-step approach in order to increase TIS prediction accuracy. In the first step, we use a feature generation algorithm we developed. In the second step, all the candidate features, including some new ones generated by our algorithm, are ranked according to their impact to the accuracy of the prediction. Finally, in the third step, a classification model is built using a number of the top ranked features. We experiment with various feature sets, feature selection …",0
DEVICE: Compiling production rules into event-driven rules using complex events,1997,https://www.sciencedirect.com/science/article/pii/S095058499601155X,"This paper describes a technique for the smooth integration of production rules into an active Object-Oriented Database (OODB) system that provides Event-Condition-Action (ECA) rules only, called DEVICE. The emphasis is given on the compilation of rule conditions into a discrimination network for incremental matching at run-time. The network consists of primitive, logical and complex events that save information about partial condition element matching, as in RETE algorithm, and trigger one ECA rule that corresponds to the production rule. The DEVICE method re-uses the primitives of active OODB systems, without introducing low-level data structures and provides an infrastructure for the integration of all database rule paradigms into a single knowledge base system.",1
A study on greedy algorithms for ensemble pruning,2012,http://lpis.csd.auth.gr/publications/partalas-tr-2012.pdf,"Ensemble selection deals with the reduction of an ensemble of predictive models in order to improve its efficiency and predictive performance. A number of ensemble selection methods that are based on greedy search of the space of all possible ensemble subsets have recently been proposed. They use different directions for searching this space and different measures for evaluating the available actions at each state. Some use the training set for subset evaluation, while others a separate validation set. This paper abstracts the key points of these methods and offers a general framework of the greedy ensemble selection algorithm, discussing its important parameters and the different options for instantiating these parameters.",1
Learning Rules for Adaptive Planning.,2003,https://www.aaai.org/Papers/ICAPS/2003/ICAPS03-009.pdf,"This paper presents a novel idea, which combines Planning, Machine Learning and Knowledge-Based techniques. It is concerned with the development of an adaptive planning system that can fine-tune its planning parameters based on the values of specific measurable characteristics of the given planning problem. Adaptation is guided by a rule-based system, whose knowledge has been acquired through machine learning techniques. Specifically, the algorithm of classification based on association rules was applied to a large dataset produced by results from experiments on a large number of problems used in the three AIPS Planning competitions. The paper presents experimental results with the adaptive planner, which demonstrate the boost in performance of the planning system.",1
Dynamic ensemble pruning based on multi-label classification,2015,https://www.sciencedirect.com/science/article/pii/S0925231214012284,"Dynamic (also known as instance-based) ensemble pruning selects a (potentially) different subset of models from an ensemble during prediction based on the given unknown instance with the goal of maximizing prediction accuracy. This paper models dynamic ensemble pruning as a multi-label classification task, by considering the members of the ensemble as labels. Multi-label training examples are constructed by evaluating whether ensemble members are accurate or not on the original training set via cross-validation. We show that classification accuracy is maximized when learning algorithms that optimize example-based precision are used in the multi-label classification task. Results comparing the proposed framework against state-of-the-art dynamic ensemble pruning approaches in a variety of datasets using a heterogeneous ensemble of 200 classifiers show that it leads to significantly improved accuracy.",1
Transferring task models in reinforcement learning agents,2013,https://www.sciencedirect.com/science/article/pii/S0925231212007771,"The main objective of transfer learning is to reuse knowledge acquired in a previous learned task, in order to enhance the learning procedure in a new and more complex task. Transfer learning comprises a suitable solution for speeding up the learning procedure in Reinforcement Learning tasks. This work proposes a novel method for transferring models to Reinforcement Learning agents. The models of the transition and reward functions of a source task, will be transferred to a relevant but different target task. The learning algorithm of the target task's agent takes a hybrid approach, implementing both model-free and model-based learning, in order to fully exploit the presence of a source task model. Moreover, a novel method is proposed for transferring models of potential-based reward shaping functions. The empirical evaluation, of the proposed approaches, demonstrated significant results and performance …",0
Chronic lymphocytic leukemia with mutated IGHV4-34 receptors: shared and distinct immunogenetic features and clinical outcomes,2017,https://clincancerres.aacrjournals.org/content/23/17/5292.abstract,"Purpose: We sought to investigate whether B cell receptor immunoglobulin (BcR IG) stereotypy is associated with particular clinicobiological features among chronic lymphocytic leukemia (CLL) patients expressing mutated BcR IG (M-CLL) encoded by the IGHV4-34 gene, and also ascertain whether these associations could refine prognostication.Experimental Design: In a series of 19,907 CLL cases with available immunogenetic information, we identified 339 IGHV4-34–expressing cases assigned to one of the four largest stereotyped M-CLL subsets, namely subsets #4, #16, #29 and #201, and investigated in detail their clinicobiological characteristics and disease outcomes.Results: We identified shared and subset-specific patterns of somatic hypermutation (SHM) among patients assigned to these subsets. The greatest similarity was observed between subsets #4 and #16, both including IgG-switched cases (IgG …",0
"Immunoglobulin heavy variable (IGHV) genes and alleles: new entities, new names and implications for research and prognostication in chronic lymphocytic leukaemia",2015,https://link.springer.com/article/10.1007/s00251-014-0812-3,"Νext generation sequencing studies in Homo sapiens have identified novel immunoglobulin heavy variable (IGHV) genes and alleles necessitating changes in the international ImMunoGeneTics information system (IMGT) GENE-DB and reference directories of IMGT/V-QUEST. In chronic lymphocytic leukaemia (CLL), the somatic hypermutation (SHM) status of the clonotypic rearranged IGHV gene is strongly associated with patient outcome. Correct determination of this parameter strictly depends on the comparison of the nucleotide sequence of the clonotypic rearranged IGHV gene with that of the closest germline counterpart. Consequently, changes in the reference directories could, in principle, affect the correct interpretation of the IGHV mutational status in CLL. To this end, we analyzed 8066 productive IG heavy chain (IGH) rearrangement sequences from our consortium both before and after the latest …",0
Artificial intelligence for advanced problem solving techniques,2008,https://books.google.com/books?hl=en&lr=&id=ZnRYBPlrk9kC&oi=fnd&pg=PP1&dq=info:sBfGRFIyWl8J:scholar.google.com&ots=FvbeJTGmId&sig=PyB25anWh_C-CL-TUyEDMwsLbF8,"One of the most important functions of artificial intelligence, automated problem solving, consists mainly of the development of software systems designed to find solutions to problems. These systems utilize a search space and algorithms in order to reach a solution. Artificial Intelligence for Advanced Problem Solving Techniques offers scholars and practitioners cutting-edge research on algorithms and techniques such as search, domain independent heuristics, scheduling, constraint satisfaction, optimization, configuration, and planning, and highlights the relationship between the search categories and the various ways a specific application can be modeled and solved using advanced problem solving techniques.",1
Biological data mining,2008,https://www.igi-global.com/chapter/biological-data-mining/7725,"At the end of the 1980s, a new discipline named data mining emerged. The introduction of new technologies such as computers, satellites, new mass storage media, and many others have lead to an exponential growth of collected data. Traditional data analysis techniques often fail to process large amounts of, often noisy, data efficiently in an exploratory fashion. The scope of data mining is the knowledge extraction from large data amounts with the help of computers. It is an interdisciplinary area of research that has its roots in databases, machine learning, and statistics and has contributions from many other areas such as information retrieval, pattern recognition, visualization, parallel and distributed computing. There are many applications of data mining in the real world. Customer relationship management, fraud detection, market and industry characterization, stock management, medicine, pharmacology, and …",0
PASER: a curricula synthesis system based on automated problem solving,2007,https://www.inderscienceonline.com/doi/abs/10.1504/IJTCS.2007.014217,"This paper presents PASER, a system for automatically synthesising curricula using AI Planning and Machine Learning techniques based on an ontology of educational resources metadata. Given the initial state of the problem (learner's profile, preferences, needs and abilities), the available actions (study an educational resource, take an exam, join an e-learning course, etc.) and the goals (obtain a certificate, learn a subject, acquire a skill, etc.), the planning module of PASER constructs a complete educational curriculum that achieves the goals. The Machine Learning module of PASER matches textually described learning requests, objectives and prerequisites to concepts of the ontology.",1
The GRT planner,2001,https://ojs.aaai.org/index.php/aimagazine/article/view/1573,"This article presents the GRT planner, a forward heuristic state-space planner, and comments on the results obtained from the Fifth International Conference on Artificial Intelligence Planning and Scheduling (AIPS'00) planning competition. The grt planner works in two phases. In the preprocessing phase, it estimates the distances between the facts and the goals of the problem. During the search phase, the estimates are used to guide a forward-directed search. grt participated in the strips track of the competition and showed promising results. Although it did not gain any prize, it gave us good prospects for the future.",1
Combining inter-review learning-to-rank and intra-review incremental training for title and abstract screening in systematic reviews,2017,http://ikee.lib.auth.gr/record/299543?ln=en,"We describe the approach we employed for Task II of CLEF eHealth 2017, concerning title and abstract screening in diagnostic test accuracy reviews. Our approach combines a learning-to-rank model trained across multiple reviews with a model focused on the given review, incrementally trained based on relevance feedback. Our learning-to-rank model is built using extreme gradient boosting on features computed by considering the similarity of different fields of the documents (title, abstract), with different fields of the topics (title, query). Our incrementally trained model is a support vector machine trained on a TF-IDF representation of title and abstract of the documents. The results of our approach are promising, reaching 0.658 normalized cumulative gain in the top 10 ranked documents in the simple evaluation setting and 0.846 in the cost-effective evaluation setting, the latter assuming feedback can be obtained …",0
AUTH-Atypon at BioASQ 3: Large-Scale Semantic Indexing in Biomedicine.,2015,http://ceur-ws.org/Vol-1391/29-CR.pdf,"In this paper we present the methods and the approaches employed in terms of our participation to the BioASQ Challenge 2015 and more specifically in task 3a, concerning the automatic semantic annotation of scientific abstracts. Based on the successful approaches of the previous years we considered a variety of ensembles, incorporated journalspecific semantic information and developed an approach to handle the concept drift within the BioASQ corpus. The official results demonstrate a consistent advantage of our approaches against the BioASQ and the National Library of Medicine (NLM) baselines. Specifically, the systems proposed by our team ranked among the top tier ones along the competition, obtaining the second place in 10 out of 15 weeks.",1
A system for energy savings in an ambient intelligence environment,2011,https://link.springer.com/chapter/10.1007/978-3-642-23447-7_10,"This work presents an Ambient Intelligence system that targets energy consumption awareness and savings. The system was deployed at the School of Science and Technology of the International Hellenic University and follows a three-layer approach. The first layer hosts devices (currently smart plugs, sensor boards and smart clampers) suited for the purpose. The second layer, namely the aWESoME middleware (a WEb Service MiddlewarE), resolves interoperability issues on the first layer, by universally exposing all actuator functions and sensor data through Web Services. Finally, a prototype application, named iDEALISM, has been developed to reside on the topmost layer. iDEALISM presents and manages all heterogeneous devices in the same place, enabling users to make comparisons, and take informed decisions on saving energy.",1
PORSCE II: Using planning for semantic web service composition,2009,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.595.7740&rep=rep1&type=pdf,"This paper presents PORSCE II, an integrated system that performs automatic semantic web service composition through planning. In order to achieve that, an essential step is the translation of the web service composition problem into a planning problem. The planning problem is then solved using external domain-independent planning systems, and the solutions are visualized and evaluated. The system exploits semantic information to enhance the translation and planning processes.",1
Reinforcement learning and automated planning: A survey,2008,https://www.igi-global.com/chapter/reinforcement-learning-automated-planning/5322,"This article presents a detailed survey on Artificial Intelligent approaches, that combine Reinforcement Learning and Automated Planning. There is a close relationship between those two areas as they both deal with the process of guiding an agent, situated in a dynamic environment, in order to achieve a set of predefined goals. Therefore, it is straightforward to integrate learning and planning, in a single guiding mechanism and there have been many approaches in this direction during the past years. The approaches are organized and presented according to various characteristics, as the used planning mechanism or the reinforcement learning algorithm.",1
Negotiation of meaning and digital textbooks in the CLIL classroom,2007,https://scholar.google.com/scholar?cluster=1286768259277776884&hl=en&oi=scholarr,Unknown,1
A Knowledge-Based Web Information System for the Fusion of Distributed Classifers,2004,https://www.igi-global.com/chapter/web-information-systems/31128,"This chapter presents the design and development of WebDisC, a knowledge-based web information system for the fusion of classifiers induced at geographically distributed databases. The main features of our system are:(i) a declarative rule language for classifier selection that allows the combination of syntactically heterogeneous distributed classifiers;(ii) a variety of standard methods for fusing the output of distributed classifiers;(iii) a new approach for clustering classifiers in order to deal with the semantic heterogeneity of distributed classifiers, detect their interesting similarities and differences, and enhance their fusion; and (iv) an architecture based on the Web services paradigm that utilizes the open and scalable standards of XML and SOAP.",1
MACLP: multi agent constraint logic programming,2002,https://www.sciencedirect.com/science/article/pii/S0020025502001901,"Multi Agent Systems (MAS) have become the key technology for decomposing complex problems in order to solve them more efficiently, or for problems distributed in nature. However, many industrial applications besides their distributed nature, also involve a large number of parameters and constraints among them, i.e. they are combinatorial. Solving such particularly hard problems efficiently requires programming tools that combine MAS technology with a programming schema that facilitates the modeling and solution of constraints. This paper presents MACLP (Multi Agent Constraint Logic Programming), a logic-programming platform for building, in a declarative way, multi agent systems with constraint-solving capabilities. MACLP extends CSPCONS, a logic programming system that permits distributed program execution through communicating sequential Prolog processes with constraints, by providing all the …",0
Fuzzy stochastic automata for reactive learning and hybrid control,2002,https://link.springer.com/chapter/10.1007/3-540-46014-4_33,"Fuzzy Stochastic Automata (FSA) are suitable for the modelling of the reactive (memoryless) learning and for the control of hybrid systems. The concept of FSA is to switch between a fuzzy increase and a fuzzy decrease of the control action according to the sign of the product e e, where e = x-x d is the error of the system’s output and is its first derivative. The learning in FSA has stochastic features. The applications of FSA concern mainly autonomous systems and intelligent robots.",1
Cspcons: A Communicating Sequential Prolog with Constraints,2002,https://link.springer.com/chapter/10.1007/3-540-46014-4_8,"Cspcons is a programming language that supports program execution over multiple Prolog processes with constraints. The language is an extended version of Csp-ii, a version of Prolog that supports, among other features, channel-based communicating processes and TCP/IP communication and is based on the CSP model introduced by Hoare. Cspcons inherits all the advanced features of Csp-ii and extends it by introducing constraint solving capabilities to the processes. In Cspcons each Prolog process has one or more solvers attached and each solver is independent from the others, following the original Csp-ii model, thus resulting to a communicating sequential constraint logic programming system. Such a model can facilitate greatly the implementation of distributed CLP applications. Currently Cspcons offers a finite domain constraint solver, but the addition of new solvers is supported as they can be …",0
An adaptable framework for educational software evaluation,2000,https://link.springer.com/chapter/10.1007/978-1-4757-4919-9_23,"This paper proposes a framework for educational software evaluation based on the Multiple Criteria Decision Aid methodology. Evaluating educational software products is a twofold process: both the educational and the technical aspect of the evaluated products have to be considered. As far as the product educational effectiveness is concerned, we propose a set of attributes covering both the general educational features and the content of the product. From the technical point of view, a software attribute set based on the ISO/IEC 9126 standard has been chosen together with the accompanying measurement guidelines. Finally, an evaluation example involving three commercial educational software packages for mechanics is presented.",1
System architecture of a distributed expert system for the management of a national data network,1998,https://link.springer.com/chapter/10.1007/BFb0057465,"The management of large data networks, like a national WAN, is without any doubt a complex task. Taking into account the constantly increasing size and complexity of today's TCP/IP based networks, it becomes obvious that there is a demanding need for better than simple monitoring management tools. Expert system technology seems to be a very promising approach for the development of such tools. This paper describes the system architecture of ExperNet, a distributed expert system for the management of the National Computer Network of Ukraine, and the implementation of the tools used for its development. ExperNet is a multiagent system built in DEVICE, an active OODB enhanced with high level rules, that uses CS-Prolog II to implement the communication facilities required. The system employs HNMS+ and Big-Brother, two modified versions of existing network management tools, in order to …",0
Information theoretic multi-target feature selection via output space quantization,2019,https://www.mdpi.com/525600,"A key challenge in information theoretic feature selection is to estimate mutual information expressions that capture three desirable terms—the relevancy of a feature with the output, the redundancy and the complementarity between groups of features. The challenge becomes more pronounced in multi-target problems, where the output space is multi-dimensional. Our work presents an algorithm that captures these three desirable terms and is suitable for the well-known multi-target prediction settings of multi-label/dimensional classification and multivariate regression. We achieve this by combining two ideas—deriving low-order information theoretic approximations for the input space and using quantization algorithms for deriving low-dimensional approximations of the output space. Under the above framework we derive a novel criterion, G roup-JMI-Rand, which captures various high-order target interactions. In an extensive experimental study we showed that our suggested criterion achieves competing performance against various other information theoretic feature selection criteria suggested in the literature. View Full-Text",1
Agents teaching humans in reinforcement learning tasks,2014,https://irll.ca/files/publications/2014ala-zhan.pdf,"This paper extends our existing teacher-student framework to allow a knowledgeable agent to teach human students. An agent teacher instructs a human student by suggesting actions the student should take as it learns. This paper extends previous algorithms, used for agents teaching other agents, to develop several new algorithms for agents teaching humans. Our results in the Pac-Man domain show that our new approaches can indeed be effectively used to improve human learning. Moreover, some of these human-teaching approaches perform better than some of the original algorithms when one agent teaches another agent.",1
Planning and scheduling,2013,https://www.eetn.gr/index.php/about-eetn/eetn-publications/ai-research-in-greece/planning-and-scheduling,"Automated planning and scheduling is a branch of artificial intelligence that is concerned with the realization of strategies or action sequences, typically for execution by intelligent agents, autonomous robots and unmanned vehicles. Unlike classical control and classification problems, the solutions are complex and have to be discovered and optimized in multidimensional space.In static and deterministic environments that can be easily modeled, automated planning can be performed offline. Solutions can be found and evaluated prior to execution. However, in unknown, dynamic and non-deterministic environments, the strategy often needs to be revised online. Models and policies need to be adapted. Solutions usually resort to iterative trial and error processes commonly seen in artificial intelligence. These include dynamic programming, reinforcement learning and combinatorial optimization.",1
"Parallel and Constraint Logic Programming: An Introduction to Logic, Parallelism and Constraints",2012,https://books.google.com/books?hl=en&lr=&id=A9_vBwAAQBAJ&oi=fnd&pg=PA1&dq=info:5-5buMu8JawJ:scholar.google.com&ots=UehZ2VzfSz&sig=k-rQGq6Ua0_hYAGwxt4jGKeP6gY,"Constraint Logic Programming (CLP), an area of extreme research interest in recent years, extends the semantics of Prolog in such a way that the combinatorial explosion, a characteristic of most problems in the field of Artificial Intelligence, can be tackled efficiently. By employing solvers dedicated to each domain instead of the unification algorithm, CLP drastically reduces the search space of the problem, which leads to increased efficiency in the execution of logic programs. CLP offers the possibility of solving complex combinatorial problems in an efficient way, and at the same time maintains the advantages offered by the declarativeness of logic programming. The aim of this book is to present parallel and constraint logic programming, offering a basic understanding of the two fields to the reader new to the area. The first part of the book gives an introduction to the fundamental aspects of conventional logic programming which is necessary for understanding the parts that follow. The second part includes an introduction to parallel logic programming, architectures and implementations proposed in the area. Finally, the third part presents the principles of constraint logic programming. The last two parts also include descriptions of the supporting facilities for the two paradigms in two popular systems; ECLIPSe and SICStus. These platforms have been selected mainly because they offer both parallel and constraint features. Annotated and explained examples are also included in the relevant parts, offering a valuable guide and a first practical experience to the reader. Finally, applications of the covered paradigms are presented. The authors felt that a …",0
Multi-label learning approaches for music instrument recognition,2011,https://link.springer.com/chapter/10.1007/978-3-642-21916-0_77,"This paper presents the two winning approaches that we developed for the instrument recognition track of the ISMIS 2011 contest on Music Information. The solution that ranked first was based on the Binary Relevance approach and built a separate model for each instrument on a selected subset of the available training data. Moreover, a new ranking approach was utilized to produce an ordering of the instruments according to their degree of relevance to a given track. The solution that ranked second was based on the idea of constraining the number of pairs that were being predicted. It applied a transformation to the original dataset and utilized a variety of post-processing filters based on domain knowledge and exploratory analysis of the evaluation set. Both solutions were developed using the Mulan open-source software for multi-label learning.",1
Mining High Quality Clusters of SAGE Data,2007,http://lpis.csd.auth.gr/publications/tzanis_vdmb07.pdf,"Serial Analysis of Gene Expression (SAGE) is a method that allows the quantitative and simultaneous analysis of the whole gene function of a cell. One of the advantages of this method is that the experimenter does not have to select a priori the mRNA sequences that will be counted in a sample. This makes SAGE a powerful tool for analyzing gene expression and studying various diseases, such as cancer. An important concern in cancer studies is the discovery of the differences between healthy and cancerous samples and the accurate separation of these two groups of samples. However, the high dimensionality of the data, the multiple cell sources (ie bulk and cell line) and the multiple cancer subtypes make very difficult the effective clustering of SAGE libraries. Furthermore, the various sources of noise pose an extra challenge to data miners. For all these reasons we propose an approach that involves the discretization of the data, the selection of the most prominent gene tags and the use of a clustering algorithm in order to obtain more compact and reliable clusters that can assist cancer profiling. We experimented with two families of clustering algorithms, partitional and hierarchical, and we utilized various cluster validity criteria in order to evaluate the resulted clustering structures. The experimental results have shown that our approach provides more interesting clustering structures.",1
A parallel prolog resolution based on multiple unifications,1992,https://www.sciencedirect.com/science/article/pii/016781919290070N,"This paper presents two algorithms as extensions to the basic Resolution Principle of logic programs which exploit parallelism retaining the full semantics of Prolog. The first algorithm, called SPU, allows parallel execution of unifications belonging to deterministic paths of the proof tree, giving in effect AND-parallel execution. The second algorithm, called MPU, retains the benefits of SPU while exploiting OR-parallelism. We also present simulation results which are indicative of the performance of the proposed algorithms and finally we discuss implementation issues which give rise to the development of a parallel machine.",1
Flow control in packet-switched multistage interconnection networks,1992,https://www.computer.org/csdl/proceedings-article/cmpeur/1992/00218466/12OmNBcShRZ,"The authors present a threshold-based flow control procedure, based on feedback schemes for reducing the performance degradation of packet-switched multistage interconnection networks with binary routing, under a nonuniform hot spot traffic pattern. The use of the proposed feedback policies in such networks permits the discrimination between regular and hot packets, controls the tree saturation, and offers a significant network performance improvement.<>",1
Improved Biomedical Entity Recognition via Longer Context Modeling,2021,https://link.springer.com/chapter/10.1007/978-3-030-79150-6_4,"Biomedical Named Entity Recognition is a difficult task, aimed to identify all named entities in medical literature. The importance of the task becomes apparent as these entities are used to identify key features, enable better search results and can accelerate the process of reviewing related evidence to a medical case. This practice is known as Evidence-Based Medicine (EBM) and is globally used by medical practitioners who do not have the time to read all the latest developments in their respective fields. In this paper we propose a methodology which achieves state-of-the-art results in a plethora of Biomedical Named Entity Recognition datasets, with a lightweight approach that requires minimal training. Our model is end-to-end and capable of efficiently modeling significantly longer sequences than previous models, benefiting from inter-sentence dependencies.",1
TransforMED: End-to-Εnd Transformers for Evidence-Based Medicine and Argument Mining in medical literature,2021,https://www.sciencedirect.com/science/article/pii/S1532046421000964,"Argument Mining (AM) refers to the task of automatically identifying arguments in a text and finding their relations. In medical literature this is done by identifying Claims and Premises and classifying their relations as either Support or Attack. Evidence-Based Medicine (EBM) refers to the task of identifying all related evidence in medical literature to allow medical practitioners to make informed choices and form accurate treatment plans. This is achieved through the automatic identification of Population, Intervention, Comparator and Outcome entities (PICO) in the literature to limit the collection to only the most relevant documents. In this work, we combine EBM with AM in medical literature to increase the performance of the individual models and create high quality argument graphs, annotated with PICO entities. To that end, we introduce a state-of-the-art EBM model, used to predict the PICO entities and two novel …",0
Drug-Drug Interaction Classification Using Attention Based Neural Networks,2020,https://dl.acm.org/doi/abs/10.1145/3411408.3411461,"Drug-drug interaction (DDI) identification is the task of identifying potential interactions between drugs when administered simultaneously. The interactions can be synergetic or antagonistic as one drug can affect the other. Adverse drug reactions caused by antagonistic DDI can pose a serious threat to health and potentially lead to greater increase in health care expenditure. Multiple excellent resources for DDI already exist, although unable to keep up with the exponential increase in published biomedical literature. Most existing systems rely on handcrafted features to extract and classify the relationships between drugs. In this paper, we present a deep learning method of stacked bidirectional Long Short Term Memory (Bi-LSTM) and Convolutional neural (CNN) networks that utilize word embeddings, part-of-speech tags and distance embeddings respectively to perform the DDI extraction task and aid the drug …",0
Multi-target feature selection through output space clustering.,2019,https://intelligence.csd.auth.gr/wp-content/uploads/2021/01/Multi-target-feature-selection-through-output-ESANN-2019.pdf,"A key challenge in information theoretic feature selection is to estimate mutual information expressions that capture three desirable terms: the relevancy of a feature with the output, the redundancy and the complementarity between groups of features. The challenge becomes more pronounced in multi-target problems, where the output space is multidimensional. Our work presents a generic algorithm that captures these three desirable terms and is suitable for the well-known multi-target prediction settings of multi-label/dimensional classification and multivariate regression. We achieve this by combining two ideas: deriving low-order information theoretic approximations for the input space and using clustering for deriving low-dimensional approximations of the output space.",1
Adipose tissue as a biomarker in data mining predictive models of metabolic pathophysiologies,2017,https://link.springer.com/chapter/10.1007/978-981-10-7419-6_18,"It is well known that the metabolic syndrome emerges as one of the major public health issues worldwide. In diabetes and other metabolism related diseases, further complexity is added in diagnosis and prognosis due to the presence of metabolic syndrome, including obesity. Obesity, which is defined as an excess of body fat, can be described as an underlying risk factor of almost any of the aforementioned metabolic related pathologies. Moreover, a very likely potential link between such pathologies and obesity is the adipose tissue, which functions as an endocrine organ. Since obesity serves as general key to metabolism related disorders and complications, the adipose tissue can be a useful tool in predicting such pathologies. In the present mini review work, several representative studies are discussed with respect to the effectiveness of adipose tissue as a valuable biomarker along with other factors …",0
Message dissemination dynamics in biological communication systems: A reaction-diffusion approach,2017,https://ieeexplore.ieee.org/abstract/document/7998265/,"Biological systems ranging from simple ecology models to biochemical interactions in molecular biology, have profited profoundly by the advances and potentials of nanotechnology, especially those in lower dimensions. Molecular nanonetworks, the outcome of this adjacency, have been under great growth, the result of which was the establishment of molecular communication paradigm. Under this paradigm, we study the message dissemination dynamics in a biological communication system, by a model typical of electromagnetic networks. Applying a reaction-diffusion mathematical model of double diffusivity in a biological communication system, we compare the outcome with the simulation results. To this aim and based on a commercial tool, a set of efficient simulation scenarios, for the precise prediction of message dissemination dynamics were run, under the newly developed simulation framework. In …",0
Ensemble feature selection using rank aggregation methods for population genomic data,2016,https://dl.acm.org/doi/abs/10.1145/2903220.2903233,"Single Nucleotide Polymorphisms (SNPs) constitute important genetic markers with numerous medical and biological applications of high scientific and economic interest. SNP datasets are typically high dimensional, containing up to million features. Reasons originating from both biology and machine learning, dictate to perform feature selection which is mainly performed after feature evaluation. In this paper we present methods for SNP evaluation and eventually selection, based on combining results obtained from established genetic marker evaluation methods originating from the field of population genetics. To achieve this we have formulated the feature selection task as a ranking aggregation problem, which is a classical problem in social choice and voting theory.",1
Feature Evaluation Metrics for Population Genomic Data,2014,https://link.springer.com/chapter/10.1007/978-3-319-07064-3_36,"Single Nucleotide Polymorphisms (SNPs) are considered nowadays one of the most important class of genetic markers with a wide range of applications with both scientific and economic interests. Although the advance of biotechnology has made feasible the production of genome wide SNP datasets, the cost of the production is still high. The transformation of the initial dataset into a smaller one with the same genetic information is a crucial task and it is performed through feature selection. Biologists evaluate features using methods originating from the field of population genetics. Although several studies have been performed in order to compare the existing biological methods, there is a lack of comparison between methods originating from the biology field with others originating from the machine learning. In this study we present some early results which support that biological methods perform slightly …",0
An Applied Energy Management Approach in Intelligent Environments based on a Hybrid Agent Architecture,2014,https://www.researchgate.net/profile/Efstratios-Kontopoulos/publication/281616720_An_Applied_Energy_Management_Approach_in_Intelligent_Environments_based_on_a_Hybrid_Agent_Architecture/links/55eff4fc08aef559dc44f268/An-Applied-Energy-Management-Approach-in-Intelligent-Environments-based-on-a-Hybrid-Agent-Architecture.pdf,"This paper presents a framework for ambient sensing and managing a University building aimed at energy savings and user comfort. The system builds upon previous work, using a Semantic Web Service middleware for unifying the various heterogeneous sensor and actuator networks. Two applications are introduced in the framework, the Manager App and the Rule App. The latter incorporates a hybrid intelligent agent that enables both reactive and deliberate manipulation of the environment, based on user-configurable policies expressed in defeasible logic. The Manager App provides users with advanced control and renders the system sustainable. Specifically, it allows bypassing the policies and manually administrating the infrastructure, eg during exceptional or emergency cases. The framework is deployed and evaluated at a University course office, guaranteeing 20% daily energy savings on controlled devices, aggregated to 17% total per room savings.",1
A Holistic Virtual Laboratory on Wireless Communications and Sensor Networks.,2013,http://users.ics.forth.gr/~cliaskos/files/jrn/IJIM.pdf,"Virtual laboratories have evolved into an ade-quately mature educational tool for multiple fields of study. Their use is especially beneficial to modern topics such as modern wireless communications. Related solutions in this field explored various approaches and architectures in designing such a virtual environment. The presented software package combines these fragmentary conclusions to a holistic and extensible laboratory architecture. Classic and modern topics, such as propagation, green networking, indoor communications and sensor networks are discussed through interactive 2D/3D environments. The student is also introduced to field measurement procedures and ray tracing principles. Statistical assessment in the context of a postgraduate course in wireless communications demonstrates the educational benefits of the approach.",1
Autonomous Selection of Inter-Task Mappings in Transfer Learning,2013,https://www.aaai.org/ocs/index.php/SSS/SSS13/paper/viewPaper/5751,"When transferring knowledge between reinforcement learning agents with different state representations or actions, past knowledge must be efficiently mapped so that it assists learning. The majority of the existing approaches use pre-defined mappings given by a domain expert. To overcome this limitations and allow autonomous transfer learning, this paper introduces a method for weighting and using multiple inter-task mappings, named COMBREL. Experimental results show that the use of multiple inter-task mappings, accompanied with a selection mechanism, can significantly boost the performance of transfer learning, relative to learning without transfer and relative to using a single hand-picked mapping.",1
"Virtual laboratories on wireless communications: A contemporary, extensible approach",2012,https://ieeexplore.ieee.org/abstract/document/6201078/,"The present work demonstrates a novel, free and open-source educational software package on wireless communications. Targeting graduate and post-graduate studies, the package covers issues of antennas and propagation, wireless channel modeling (fading, shadowing, path loss, Doppler effect), static and adaptive modulation, client mobility and network planning applied to DVB/T and indoor networks (WiFi, femtocell) settings. The corresponding packages are fully interactive and parametric, offering 3D GUIs, ray traced maps and connection to field measurements. Being extensible via the addition of simple text files, the presented package constitutes a concrete approach that was missing from the related approaches that follow the virtual laboratories paradigm.",1
Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics): Preface,2012,https://ir.lib.uth.gr/xmlui/handle/11615/30497,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence 
and Lecture Notes in Bioinformatics): Preface Toggle navigation English Ελληνικά Deutsch 
français italiano español Ελληνικά English Ελληνικά Deutsch français italiano español Σύνδεση 
Toggle navigation Προβολή τεκμηρίου Ιδρυματικό Αποθετήριο Πανεπιστημίου Θεσσαλίας 
Επιστημονικές Δημοσιεύσεις Μελών ΠΘ (ΕΔΠΘ) Δημοσιεύσεις σε περιοδικά, συνέδρια, κεφάλαια 
βιβλίων κλπ. Προβολή τεκμηρίου Ιδρυματικό Αποθετήριο Πανεπιστημίου Θεσσαλίας 
Επιστημονικές Δημοσιεύσεις Μελών ΠΘ (ΕΔΠΘ) Δημοσιεύσεις σε περιοδικά, συνέδρια, κεφάλαια 
βιβλίων κλπ. Προβολή τεκμηρίου Όλο το DSpace Κοινότητες & Συλλογές Ανά ημερομηνία 
δημοσίευσης Συγγραφείς Τίτλοι Λέξεις κλειδιά Lecture Notes in Computer Science (including 
subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics): Preface , I.…",0
Mining for mutually exclusive gene expressions,2010,https://link.springer.com/chapter/10.1007/978-3-642-12842-4_29,"Association rules mining is a popular task that involves the discovery of co-occurences of items in transaction databases. Several extensions of the traditional association rules mining model have been proposed so far, however, the problem of mining for mutually exclusive items has not been investigated. Such information could be useful in various cases in many application domains like bioinformatics (e.g. when the expression of a gene excludes the expression of another) In this paper, we address the problem of mining pairs and triples of genes, such that the presence of one excludes the presence of the other. First, we provide a concise review of the literature, then we define this problem, we propose a probability-based evaluation metric, and finally a mining algorithm that we apply on gene expression data gaining new biological insights.",1
Transferring experience in reinforcement learning through task decomposition.,2009,https://www.academia.edu/download/39820865/Transferring_experience_in_reinforcement20151109-10836-105lda4.pdf,"Transfer learning refers to the process of conveying experience from a simple task to another more complex (and related) task in order to reduce the amount of time that is required to learn the latter task. Typically, in a transfer learning procedure the agent learns a behavior in a source task, and it uses the gained knowledge in order to speed up the learning process in a target task. Reinforcement Learning algorithms are time expensive when they learn from scratch, especially in complex domains, and transfer learning comprises a suitable solution to speed up the training process. In this work we propose a method that decomposes the target task in several instances of the source task and uses them to extract an adviced action for the target task. We evaluate the efficacy of the proposed approach in the robotic soccer Keepaway domain. The results demonstrate that the proposed method helps to reduce the training time of the target task.",1
Multi-label classification bibliography,2008,http://mlkd.csd.auth.gr/multilabel/multilabel_bib.pdf,"Multi-Label Classification Bibliography Page 1 Multi-Label Classification Bibliography 
Grigorios Tsoumakas, Ioannis Katakis and Ioannis Vlahavas Department of Informatics, 
Aristotle University of Thessaloniki 54124 Thessaloniki, Greece {greg,katak,vlahavas}@csd.auth.gr 
August 31, 2008 1 Multi-Label Classification Bibliography [1], [2], [3], [5], [4], [6], [7], [8], [9], [10], 
[11], [12], [13], [14], [15], [16], [17], [18], [19], [20], [21], [22], [23], [24], [25], [26], [28], [27], [29], [30], 
[31], [32], [33], [34], [35], [36], [37], [38], [39], [40], [41], [42], [43], [44], [45], [46], [47], [48], [49], [50], 
[51], [52], [53], [54], [55], [56], [57], [58], [59], [60], [61], [62], [63], [64], [65]. References [1] Zafer 
Barutcuoglu, Robert E. Schapire, and Olga G. Troyanskaya. Hierarchical multi-label prediction 
of gene function. Bioinformatics, 22(7):830– 836, 2006. [2] H. Blockeel, L. Schietgat, J. 
Struyf, S. Dz?eroski, and A. Clare. Decision trees for hierarchical multilabel classification: . …",0
Active knowledge-based systems,2000,https://www.sciencedirect.com/science/article/pii/B9780124438750500021,"Knowledge is the information about a specific domain needed by a computer program to enable it to exhibit intelligent behavior with regard to a specific problem. Knowledge includes information about both real-world entities and the relationships between them. Knowledge can also take the form of procedures for combining and operating on information. Computer programs that encapsulate such knowledge are called “knowledge-based systems.” This chapter discusses some existing approaches to building a knowledge base management system (KBMS) by integrating one or more rule types into a database management systems (DBMS), giving emphasis to solutions based on the reactive behavior of active knowledge-based systems. The implementation techniques found in various published systems are presented and compared in the chapter according to their functionality and efficiency …",0
A neural entity coreference resolution review,2021,https://www.sciencedirect.com/science/article/pii/S0957417420311143,"Entity Coreference Resolution is the task of resolving all mentions in a document that refer to the same real world entity and is considered as one of the most difficult tasks in natural language understanding. It is of great importance for downstream natural language processing tasks such as entity linking, machine translation, summarization, chatbots, etc. This work aims to give a detailed review of current progress on solving Coreference Resolution using neural-based approaches. It also provides a detailed appraisal of the datasets and evaluation metrics in the field, as well as the subtask of Pronoun Resolution that has seen various improvements in the recent years. We highlight the advantages and disadvantages of the approaches, the challenges of the task, the lack of agreed-upon standards in the task and propose a way to further expand the boundaries of the field.",1
FIFS: A data mining method for informative marker selection in high dimensional population genomic data,2017,https://www.sciencedirect.com/science/article/pii/S0010482517303189,"Single Nucleotide Polymorphism (SNPs) are, nowadays, becoming the marker of choice for biological analyses involving a wide range of applications with great medical, biological, economic and environmental interest. Classification tasks i.e. the assignment of individuals to groups of origin based on their (multi-locus) genotypes, are performed in many fields such as forensic investigations, discrimination between wild and/or farmed populations and others. Τhese tasks, should be performed with a small number of loci, for computational as well as biological reasons. Thus, feature selection should precede classification tasks, especially for Single Nucleotide Polymorphism (SNP) datasets, where the number of features can amount to hundreds of thousands or millions.In this paper, we present a novel data mining approach, called FIFS – Frequent Item Feature Selection, based on …",0
Semantically aware web service composition through AI planning,2015,https://www.worldscientific.com/doi/abs/10.1142/S0218213014500158,"Web service composition is a significant problem as the number of available web services increases; however, manual composition is not an efficient option. Automated web service composition can be performed using AI Planning techniques, utilizing descriptions of available atomic web services, enhanced with semantic awareness and relaxation. This paper discusses a unified, semantically aware approach, handling both semantic (OWL-S & SAWSDL) and non-semantic (WSDL) web service descriptions. In the first case, ontology analysis is adopted to semantically enhance the planning domains and problems, in order to deal with cases where exact syntactic input-to-output matching is not feasible. In the non-semantic descriptions case, semantic information is acquired utilizing alternative sources such as lexical thesauri. Concept similarity measures are applied and utilized to achieve the desired degree of …",0
Iridescent: A tool for rapid semantic annotation of web service descriptions,2013,https://dl.acm.org/doi/abs/10.1145/2479787.2479797,"Although the Semantic Web and Web Service technologies have already formed a synergy towards Semantic Web Services, their use remains limited. Potential adopters are usually discouraged by the number of different methodologies and the lack of tools, which both force them to acquire expert knowledge and commit to exhausting manual labor. This work proposes a novel functional and user-friendly graphical tool, named Iridescent, intended for both expert and non-expert users, to create and edit Semantic Web Service descriptions, following the SAWSDL recommendation. The tool's aim is twofold: to enable users manually create descriptions in a visual manner, providing a complete alternative to coding, and to semi-automate the process by matching elements and concepts and suggesting annotations. A state-of-the-art survey has been carried out to reveal critical points and requirements. The tool's …",0
Mopis: a multiple opinion summarizer,2008,https://link.springer.com/chapter/10.1007/978-3-540-87881-0_11,"Product reviews written by on-line shoppers is a valuable source of information for potential new customers who desire to make an informed purchase decision. Manually processing quite a few dozens, or even hundreds, of reviews for a single product is tedious and time consuming. Although there exist mature and generic text summarization techniques, they are focused primarily on article type content and do not perform well on short and usually repetitive snippets of text found at on-line shops. In this paper, we propose MOpiS, a multiple opinion summarization algorithm that generates improved summaries of product reviews by taking into consideration metadata information that usually accompanies the on-line review text. We demonstrate the effectiveness of our approach with experimental results.",1
Detection and prediction of rare events in transaction databases,2007,https://www.worldscientific.com/doi/abs/10.1142/S0218213007003564,"Rare events analysis is an area that includes methods for the detection and prediction of events, e.g. a network intrusion or an engine failure, that occur infrequently and have some impact to the system. There are various methods from the areas of statistics and data mining for that purpose. In this article we propose PREVENT, an algorithm which uses inter-transactional patterns for the prediction of rare events in transaction databases. PREVENT is a general purpose inter-transaction association rules mining algorithm that optimally fits the demands of rare event prediction. It requires only 1 scan on the original database and 2 over the transformed, which is considerably smaller and it is complete as it does not miss any patterns. We provide the mathematical formulation of the problem and experimental results that show PREVENT's efficiency in terms of run time and effectiveness in terms of sensitivity and specificity.",1
Ensemble selection for water quality prediction,2007,http://ftp.informatik.rwth-aachen.de/Publications/CEUR-WS/Vol-284/page429.pdf,"This paper studies the greedy ensemble selection algorithm for ensembles of regression models. We explore two interesting parameters of this algorithm: a) the direction of search (forward, backward), and b) the performance evaluation dataset (training set, validation set) on a large ensemble (200 models) of neural networks and support vector machines. Experimental comparison of the different parameters are performed on an application domain with important social and commercial value: water quality monitoring. In specific we experiment on real data collected from an underwater sensor system.",1
Web service composition using a deductive XML rule language,2005,https://link.springer.com/article/10.1007/s10619-004-0087-z,"This paper describes a knowledge-based Web Service composition system, called SWIM, which is based on the Service Domain model. Service Domains are communities of related Web Services that are mediated by a single Web Service, called the Mediator Service, which functions as a proxy for them. When a requestor sends a message to the Mediator Service one or more of the related Web Services are selected to dispatch the message and the results returned are aggregated to a single answer to the requestor. Mediator Services can be further composed to more complex Mediator Services that combine several selection and aggregation algorithms among many heterogeneous web services. The system utilizes the X-DEVICE deductive XML rule language for defining complex algorithms for selecting registered web services, combining the results, and synchronizing the workflow of information among …",0
Using the k-nearest problems for adaptive multicriteria planning,2004,https://link.springer.com/chapter/10.1007/978-3-540-24674-9_15,"This paper concerns the design and development of an adaptive planner that is able to adjust its parameters to the characteristics of a given problem and to the priorities set by the user concerning plan length and planning time. This is accomplished through the implementation of the k nearest neighbor machine learning algorithm on top of a highly adjustable planner, called HAP. Learning data are produced by running HAP offline on several problems from multiple domains using all value combinations of its parameters. When the adaptive planner HAP is faced with a new problem, it locates the k nearest problems, using a set of measurable problem characteristics, retrieves the performance data for all parameter configurations on these problems and performs a multicriteria combination, with user-specified weights for plan length and planning time. Based on this combination, the configuration with the best …",0
The MO-GRT system: Heuristic planning with multiple criteria,2002,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.19.4407&rep=rep1&type=pdf#page=54,"This paper enhances the GRT planner, an efficient domainindependent heuristic state-space planner, with the ability to consider multiple criteria. The GRT heuristic is based on the estimation of the distances between each fact of a problem and the goals. The new planner, called MO-GRT, uses a weighted A* strategy and a multiobjective heuristic function, computed over a weighted hierarchy of userdefined criteria. Its computation is based on sets of nondominated cost-vectors assigned to the problem facts, which estimate the total cost of achieving the facts from the goals, using alternative paths. Experiments show that a change in the criteria weights or scales affects both the quality of the resulting plan and the planning time.",1
A Non-Uniform Data Fragmentation Strategy for Parallel Main-Menory Database Systems,1995,https://www.researchgate.net/profile/Nick-Bassiliades/publication/2353453_A_Non-Uniform_Data_Fragmentation_Strategy_for_Parallel_Main-Memory_Database_Systems/links/0912f50af856a9a012000000/A-Non-Uniform-Data-Fragmentation-Strategy-for-Parallel-Main-Memory-Database-Systems.pdf,"In multi-processor database systems there are processor initialization and inter-communication overheads that diverge real systems from the ideal linear behaviour as the number of processors increases. Main-memory database systems suffer more since the database processing cost is small compared to disk-based database systems and thus comparable to the processor initialization cost. The usual uniform data fragmentation strategy divides a relation into equal data partitions, leading to idleness of single processors after local query execution termination and before global termination. In this paper, we propose a new, non-uniform data fragmentation strategy that results in concurrent termination of query processing among all the processors. The proposed fragmentation strategy is analytically modeled, simulated and compared to the uniform strategy. It is proven that the non-uniform fragmentation strategy offers inherently better performance for a parallel database system than the uniform strategy. Furthermore, the non-uniform strategy scales-up perfectly till an upper limit, after which a system re-configuration is needed.",1
A prediction model of passenger demand using AVL and APC data from a bus fleet,2015,https://dl.acm.org/doi/abs/10.1145/2801948.2801984,"In this paper we present the passenger demand prediction model of BusGrid. BusGrid is a novel information system for the improvement of productivity and customer service in public transport bus services. BusGrid receives and processes real time data from the automated vehicle location (AVL) and the automated passenger counting (APC) sensors installed on a bus fleet and assists their operator on the improvement of bus schedules and the design of new bus routes and stops based on the expected demand. For the prediction of passenger demand in any bus stop, the raw sensor data were pre-processed and several different feature sets were extracted and tested as predictors of passenger demand. The pre-processed data were used for the supervised learning of a regression model that predicts people demand for any given bus stop and route. Experimental results show that the proposed approach achieved …",0
Model-based reinforcement learning for humanoids: A study on forming rewards with the iCub platform,2013,https://ieeexplore.ieee.org/abstract/document/6609170/,"Technological advancements in robotics and cognitive science are contributing to the development of the field of cognitive robotics. Modern robotic platforms are able to exhibit the ability to learn and reason about complex tasks and to follow behavioural goals in complex environments. Nevertheless, many challenges still exist. One of these great challenges is to equip these robots with cognitive systems that allow them to deal with less constrained situations, beyond constrained scenarios as in industrial robotics. In this work we explore the application of the Reinforcement Learning (RL) paradigm to study the autonomous development of robot controllers without a priori supervised learning. Such a model-based RL architecture is discussed for the cognitive implications of applying RL in humanoid robots. To this end we show a developmental framework for RL in robotics and its implementation and testing for the …",0
Transferring evolved reservoir features in reinforcement learning tasks,2011,https://link.springer.com/chapter/10.1007/978-3-642-29946-9_22,"The major goal of transfer learning is to transfer knowledge acquired on a source task in order to facilitate learning on another, different, but usually related, target task. In this paper, we are using neuroevolution to evolve echo state networks on the source task and transfer the best performing reservoirs to be used as initial population on the target task. The idea is that any non-linear, temporal features, represented by the neurons of the reservoir and evolved on the source task, along with reservoir properties, will be a good starting point for a stochastic search on the target task. In a step towards full autonomy and by taking advantage of the random and fully connected nature of echo state networks, we examine a transfer method that renders any inter-task mappings of states and actions unnecessary. We tested our approach and that of inter-task mappings in two RL testbeds: the mountain car and the server …",0
Polyadenylation site prediction using interesting emerging patterns,2008,https://ieeexplore.ieee.org/abstract/document/4696711/,"This paper presents a study on polyadenylation site prediction in mRNA sequences. We describe a method, called PolyA-EP, that we developed for predicting polyadenylation sites and we present a systematic study of the problem of recognizing mRNA 3' ends which contain a polyadenylation site using the proposed method. PolyA-EP exploits the advantages of emerging patterns, namely high understandability and discriminating power and can be used for both descriptive and predictive analysis. In particular, PolyA-EP is a parameterizable tool that can be used in order to extract interesting emerging patterns for describing or predicting polyadenylation sites. Moreover, the extracted emerging patterns can span across many elements around the polyadenylation site. We discuss the results of the experiments we conducted with Arabidopsis thaliana sequences drawing important conclusions and finally we propose a …",0
A framework for multi-criteria plan evaluation in heuristic state-space planning,2001,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.23.1528&rep=rep1&type=pdf,"This paper proposes a framework that enhances domain independent heuristic state-space planners with the ability to plan for multiple criteria simultaneously. A criteria hierarchy, together with preferences among them and boundaries over their values, is defined by the knowledge engineer. For the search process in the state-space, a weighted A* strategy is adopted. The heuristic function uses the criteria hierarchy, in order to measure the known accumulated value of the incomplete plan and to estimate the value of the remaining plan. The latter estimation is based on the assignment of multiple value-vectors to the facts of the problem, which estimate the value to achieve the facts from the current state, using alternative paths. A prototype system has been implemented and preliminary performance results have shown that the weights and the scales affect significantly both solution time and plan quality. The framework is general enough, so that it can be applied to all modern heuristic statespace planners.",1
Hierarchical query execution in a parallel object-oriented database system,1996,https://www.sciencedirect.com/science/article/pii/0167819196000312,"We present a hierarchical query execution strategy for a parallel object-oriented database (OODB) system. The system, named PRACTIC, is based on a concurrent active class management model and is mapped to an abstract hierarchical multiprocessor architecture. The proposed strategy is studied analytically and by simulation on a transputer-based machine, verifying the theoretical results. Although the analysis suits both main-memory and disk-based database systems, it becomes significant for main-memory systems where the multiprocessor initialization and communication overheads are comparable to the actual workload. The hierarchical query execution strategy is proved much better than the usual flat strategy of parallel database systems, except some clearly identified extreme cases, where flat processing is better. Furthermore, we propose a declustering scheme for space optimization to improve …",0
A hybrid approach for cold-start recommendations of videolectures,2011,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.369.3516&rep=rep1&type=pdf,This paper presents the solution which ranked 2nd in the “cold-start” recommendations task of the ECML/PKDD 2011 discovery challenge. The task was the recommendation of new videolectures to new users of the Videolectures. net Web site. The proposed solution is a hybrid recommendation approach which combines content-based and collaborative information. Structured and unstructured textual attributes which describe each lecture are synthesized to create a vector representation with tf/idf weights. Collaborative information is incorporated for query expansion with a novel method which identifies neighboring lectures in a co-viewing graph and uses them to supplement missing attributes. The cosine similarity measure is used to find similar lectures and final recommendations are made by also accounting the coexistence duration of lectures. The results of the competition show that the proposed approach is able to give accurate “cold-start” recommendations.,1
An intelligent system for monitoring and predicting water quality,2009,http://mlkd.csd.auth.gr/publication_details.asp?publicationID=305,"In this paper we present an intelligent system for monitoring and predicting water quality, whose main aim is to help the authorities in the"" decision-making"" process in the battle against the pollution of the aquatic environment, which is very vital for the public health and the economy of Northern Greece. Two sensor-telematic networks for collecting water quality measurements in real time (Andromeda, for sea waters, and Interrisk, for surface/fresh waters) were developed and deployed. Sensor readings (water temperature, pH, dissolved oxygen, conductance, turbidity, sea currents, and salinity) are transmitted to a main station for processing and storage. The intelligent system monitors sensor data, reasons, using fuzzy logic, about the current level of water suitability for various aquatic uses, such as swimming and piscicultures, and flags out appropriate alerts. Furthermore, the system employs Machine Learning and …",0
On the discovery of mutually exclusive items in a market basket database,2006,https://www.academia.edu/download/50835734/On_the_Discovery_of_Mutually_Exclusive_I20161211-8825-gc9372.pdf,"Mining a transaction database for association rules is a particularly popular data mining task, which involves the search for frequent co-occurrences among items. One of the problems often encountered is the large number of weak rules extracted. Item taxonomies, when available, can be used to reduce them to a more usable volume. In this paper we introduce a new data mining paradigm, which involves the discovery of pairs of mutually exclusive items. We call this new type of knowledge mutual exclusion, as opposed to association, and we propose its use to tackle the aforementioned problem. We formulate the problem of mining for mutually exclusive items, provide important background information, propose a novel mutual exclusion metric and finally, present a mining algorithm that we test on transaction data.",1
Towards automatic synthesis of educational resources through automated planning,2006,https://link.springer.com/chapter/10.1007/11752912_42,"This paper reports on the results of an ongoing project for the development of a platform for e-Learning, which automatically constructs curricula based on available educational resources and the learners needs and abilities. The system under development, called PASER (Planner for the Automatic Synthesis of Educational Resources), uses an automated planner, which given the initial state of the problem (learner’s profile, preferences, needs and abilities), the available actions (study an educational resource, take an exam, join an e-learning course, etc.) and the goals (obtain a certificate, learn a subject, acquire a skill, etc.) constructs a complete educational curriculum that achieves the goals. PASER is compliant with the evolving educational metadata standards that describe learning resources (LOM), content packaging (CP), educational objectives (RDCEO) and learner related information (LIP).",1
Mining for contiguous frequent itemsets in transaction databases,2005,https://ieeexplore.ieee.org/abstract/document/4062223/,"Mining a transaction database for association rules is a particularly popular data mining task, which involves the search for frequent co-occurrences among items. One of the problems often encountered is the large number of weak rules extracted. Item taxonomies, when available, can be used to reduce them to a more usable volume. In this paper we introduce a new data mining paradigm, which involves the discovery of contiguous frequent itemsets. We formulate the problem of mining contiguous frequent itemsets in a transaction database and we present a level-wise algorithm for finding these itemsets. Contiguous frequent itemsets may contain important knowledge about the dataset, that can not be exposed by the use of classic association rule mining approaches. This knowledge may well include serious hints for the generation of a taxonomy for all or part of the items.",1
Smart Video Text: An Intelligent Video Database System,1997,https://docs.lib.purdue.edu/cgi/viewcontent.cgi?article=2384&context=cstech,"In this paper, an intelligent annotation-based video data model called Smart VideoText is introduced. It utilizes the Conceptual Graph knowledge representation fonnalism to capture the semantic associations among the concepts described in le;.. 1 annotations of the video data. The aim is to achieve more effective query, rct. r: icval and browsing capabilities based on video data's semantic content. Finally, a generic and modular video database architecture based on Smart VideoText data model is described.",1
"Ebm+: advancing evidence-based medicine via two level automatic identification of populations, interventions, outcomes in medical literature",2020,https://www.sciencedirect.com/science/article/pii/S0933365720301986,"Evidence-Based Medicine (EBM) has been an important practice for medical practitioners. However, as the number of medical publications increases dramatically, it is becoming extremely difficult for medical experts to review all the contents available and make an informative treatment plan for their patients. A variety of frameworks, including the PICO framework which is named after its elements (Population, Intervention, Comparison, Outcome), have been developed to enable fine-grained searches, as the first step to faster decision making.In this work, we propose a novel entity recognition system that identifies PICO entities within medical publications and achieves state-of-the-art performance in the task. This is achieved by the combination of four 2D Convolutional Neural Networks (CNNs) for character feature extraction, and a Highway Residual connection to facilitate deep Neural Network architectures. We …",0
The anatomy of bacteria-inspired nanonetworks: molecular nanomachines in message dissemination,2019,https://www.sciencedirect.com/science/article/pii/S187877891830139X,"Nanotechnology is an emerging field devoted to providing new insight into a vast range of subjects interfacing sciences and engineering. As advances in nanotechnology emerge continuously, new areas of applications in nanoscale communication also emerge that involve biological systems. By definition, nanocommunication is the exchange of information at nanoscale level and constitutes the basis of any wireless interconnection of individual nanomachines comprising a nanonetwork. Such systems have unique properties that must be taken into account, when trying to delve into new communication paradigms based on micro-biological communication systems. In this context, development of bio-inspired nanonetworks is a fledgling yet fast growing area of scientific interest with a significant impact on future applications in multiple fields. A representative family of such systems includes bacterial nanonetworks …",0
Integrating multiple immunogenetic data sources for feature extraction and mining somatic hypermutation patterns: the case of “towards analysis” in chronic lymphocytic leukaemia,2016,https://link.springer.com/article/10.1186/s12859-016-1044-3,"Somatic Hypermutation (SHM) refers to the introduction of mutations within rearranged V(D)J genes, a process that increases the diversity of Immunoglobulins (IGs). The analysis of SHM has offered critical insight into the physiology and pathology of B cells, leading to strong prognostication markers for clinical outcome in chronic lymphocytic leukaemia (CLL), the most frequent adult B-cell malignancy. In this paper we present a methodology for integrating multiple immunogenetic and clinocobiological data sources in order to extract features and create high quality datasets for SHM analysis in IG receptors of CLL patients. This dataset is used as the basis for a higher level integration procedure, inspired form social choice theory. This is applied in the Towards Analysis, our attempt to investigate the potential ontogenetic transformation of genes belonging to specific stereotyped CLL subsets towards other genes or …",0
A hybrid multiagent reinforcement learning approach using strategies and fusion,2008,https://www.worldscientific.com/doi/abs/10.1142/S0218213008004230,"Reinforcement Learning comprises an attractive solution to the problem of coordinating a group of agents in a Multiagent System, due to its robustness for learning in uncertain and unknown environments. This paper proposes a multiagent Reinforcement Learning approach, that uses coordinated actions, which we call strategies and a fusing process to guide the agents. To evaluate the proposed approach, we conduct experiments in the Predator-Prey domain and compare it with other learning techniques. The results demonstrate the efficiency of the proposed approach.",1
Predicting missing parts in time series using uncertainty theory,2004,https://link.springer.com/chapter/10.1007/978-3-540-30547-7_32,"As extremely large time series data sets grow more prevalent in a wide variety of applications, including biomedical data analysis, diagnosis and monitoring systems and exploratory data analysis in scientific and business time series, the need of developing efficient analysis methods is high. However, essential preprocessing algorithms are required in order to obtain positive results. The goal of this paper is to propose a novel algorithm that is appropriate for filling missing parts of time series. This algorithm, named FiTS (Filling Time Series), was evaluated over 11 congestive heart failure patients’ ECGs (Electrocardiogram). Those patients using electronic microdevices with which were recording their ECGs and sending them via telephone to a home care monitoring system, over a period of 8 to 16 months. Randomly missing parts in each ECG were introduced in the initial ECG. As a result, FiTS had 100% of …",0
Web services for adaptive planning,2004,http://lpis.csd.auth.gr/publications/tsoumakas-ecai04workshop.pdf,"This paper presents the design and development of an adaptive planning system using the technology of Web services. The Web-based adaptive planning system consists of two modules that can work independently. The first one is called HAP-WS and is the Web service interface to the domain independent planner HAP (Highly Adjustable Planner) that can be customized through the adjustment of several parameters, either manually or automatically. In the manual mode, the user itself adjusts planner parameters giving explicitly the values. In the automatic mode, the second subsystem, called LAMP-WS, computes the values of the planning parameters of HAP. LAMP-WS is the Web service interface to the learning system LAMP (Lazy Adaptive Multicriteria Planning) that can automatically configure a planning system using instance-based learning on past performance data of that system. The two subsystems are implemented as independent Web services, which can be used stand-alone and reside in different servers in potentially different geographical locations.",1
A Graphical Interface for Adaptive Planning,2003,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.9.4274&rep=rep1&type=pdf,"This paper describes a friendly graphical interface for HAP, a rule-configurable planning system, which automatically adapts to each problem, in order to achieve best performance. HAP analyzes the problem and uses a rule system in order to make the most appropriate choices for planning. The graphical interface enables the user to use and even interfere in the process of fine tuning the planning system. Furthermore, the interface allows the user to manually configure and experiment with the system and also to define its own domains and problems through an easy-to-use visual tool.",1
Towards adaptive heuristic planning through machine learning,2002,https://www.academia.edu/download/42207533/hap.pdf,"In domain independent heuristic planning there is a number of planning systems with very good performance on some problems and very poor on others. Few attempts have been made in the past to explain this phenomenon. In this paper we use machine learning techniques to discover knowledge hidden in the dynamics of the planning process that would relate specific characteristics of a planning problem with specific properties of a planning system that lead to good or bad performance. By this, we aim at shedding light to some of the dark areas of heuristic planning and develop an adaptive planner that would be able to optimize its configuration according to the problem at hand.",1
Intelligent Querying of Web Documents Using a Deductive XML Repository,2002,https://link.springer.com/chapter/10.1007/3-540-46014-4_39,"In this paper, we present a deductive object-oriented database system, called X-DEVICE, which is used as a repository for XML documents. X-DEVICE employs a powerful rule-based query language for intelligently querying stored Web documents and data and publishing the results. XML documents are stored into the OODB by automatically mapping the DTD to an object schema. XML elements are treated either as objects or attributes based on their complexity, without loosing the relative order of elements in the original document. The rule-based language features second-order logic syntax, generalized path and ordering expressions, which greatly facilitate the querying of recursive, treestructured XML data and the construction of XML trees as query results. All the extended features of the rule language are translated through the use of object metadata into a set of first-order deductive rules that are …",0
SSPOP: A state-space partial-order planner,1999,https://scholar.google.com/scholar?cluster=9108792997214725338&hl=en&oi=scholarr,"This paper presents a new planner for STRIPS-style problems, named State-Space Partial-Order Planner (SSPOP). This planner is a hybrid one, since it combines state-space search, the reduced search-space feature of the partial-order planners and heuristic search guided by a domain-independent algorithm. Using local search techniques, SSPOP discovers groups of plans that are equivalent re-orderings of a set of actions and keeps one plan of each group for further exploration. Moreover, additional checks detect and eliminate plans with redundant actions. Finally, SSPOP has been enhanced with Greedy Regression Tables (GRT), a domain-independent heuristic algorithm that estimates distances between intermediate states and the goal. SSPOP has been implemented in PROLOG and has been tested in several domains, being quite competitive against other known planners, like SATPLAN, BLACKBOX and HSP, in terms of solution time and length.",1
Constraint checking in a parallel object-oriented database system,1995,https://www.tandfonline.com/doi/abs/10.1080/10637199508915480,"This paper deals with parallel checking of passive constraints in object-oriented databases. It presents a parallel algorithm for constraint checking based on a master-slave technique and discusses its implementation on a parallel object-oriented database system. The system is named PRACTIC and is based on class concurrency. Passive constraints, unlike active database rules, are independent and can be executed using AND-parallelism. Simulation shows that the proposed algorithm offers considerable speedup, which mainly depends on the number of constraints and the total constraint execution time, while it is only slightly affected from the distribution of constraints and the constraint scheduling policy. Finally, it is explained how the PRACTIC system enhances the algorithm's performance using features, like nested query parallelism and constraint overlapping.",1
Multi-target regression via output space quantization,2020,https://ieeexplore.ieee.org/abstract/document/9206984/,"Multi-target regression is concerned with the prediction of multiple continuous target variables using a shared set of predictors. Two key challenges in multi-target regression are: (a) modelling target dependencies and (b) scalability to large output spaces. In this paper, a new multi-target regression method is proposed that tries to jointly address these challenges via a novel problem transformation approach. The proposed method, called MRQ, is based on the idea of quantizing the output space in order to transform the multiple continuous targets into one or more discrete ones. Learning on the transformed output space naturally enables modeling of target dependencies while the quantization strategy can be flexibly parameterized to control the trade-off between prediction accuracy and computational efficiency. Experiments on a large collection of benchmark datasets show that MRQ is both highly scalable and also …",0
Ensemble Pruning Bibliography,2008,https://www.academia.edu/download/5748670/ensemblepruning_bib.pdf,"Ensemble Pruning Bibliography Page 1 Ensemble Pruning Bibliography Grigorios Tsoumakas, 
Ioannis Partalas and Ioannis Vlahavas Department of Informatics, Aristotle University of 
Thessaloniki 54124 Thessaloniki, Greece {greg,partalas,vlahavas}@csd.auth.gr January 28, 
2008 1 Ensemble Pruning Bibliography [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], 
[15], [16], [17], [18], [19], [20], [21], [22], [23], [24], [25], [26], [27], [28], [29], [30] References [1] Bart 
Bakker and Tom Heskes. Clustering ensembles of neural network models. Neural Networks, 
16(2):261–269, 2003. [2] RE Banfield, LO Hall, KW Bowyer, and PW Kegelmeyer. A new 
ensemble diversity measure applied to thinning ensembles. In Proceedings of the International 
Workshop on Multiple Classifier Systems, pages 306– 316, Surrey, UK, 2003. [3] Robert E. 
Banfield, Lawrence O. Hall, Kevin W. Bowyer, and W. Philip Kegelmeyer. Ensemble and (…",0
E-Mail. Mining: Emerging. Techniques. for.,2007,https://books.google.com/books?hl=en&lr=&id=1sneHjL-yGQC&oi=fnd&pg=PA219&dq=info:GkcDrECzQx4J:scholar.google.com&ots=tNRw3K_2UT&sig=feFrZyBDDir1pjy5eYty4yBdEmY,"E-mail has met tremendous popularity over the past few years. People are sending and receiving many messages per day, communicating with partners and friends or exchanging files and information. Unfortunately, the phenomenon of e-mail overload has grown over the past years, becoming a personal headache for users and a financial issue for companies. In this chapter, we will discuss how disciplines like machine learning and data mining can contribute to the solution of the problem by constructing intelligent techniques that automate e-mail managing tasks and what advantages they hold over other conventional solutions. We will also discuss the particularity of e-mail data and what special treatment they require. Some interesting e-mail mining applications like mail categorization, summarization, automatic answering, and spam filtering will also be presented.",1
Constraint Logic Programming on Multiple Processors,2006,https://books.google.com/books?hl=en&lr=&id=rYtuk_sm23UC&oi=fnd&pg=PA263&dq=info:yyzOIWCB0YsJ:scholar.google.com&ots=_cZLFsICnj&sig=HyYrWqrCrn4Ut2n-qmhb67LKFj4,"Logic programming (LP) is identiﬁed as one of the major programming paradigms, based on sound theoretical foundations. It has been an active area of research for the past three decades, especially from the mid-1970s until the late 1990s. This research effort has lead not only to a large number of theoretical results and proposed models, but also to industrial strength implementations of logic programming languages, as, for example, Prolog that is undoubtedly the main representative of this class of languages. The interest in logic programming, and especially in its main representative Prolog, stems from its signiﬁcant advantages in developing applications involving symbolic computation and reasoning. This comes as no surprise, since one of the funding works on logic programming was the effort of Colmeraurer and Russel in Marseille, to develop a language for natural language applications. Close interaction between the Marseille group and the research group of Edinburgh gave rise to the idea of using ﬁrst-order predicate logic as a programming language, an idea ﬁrst described in the seminal paper of Kowalski A major criticism of Prolog and its approach to programming is inefﬁciency. This criticism seems to carry on even today where the maturity of the ﬁeld both in implementation technology, as well as optimization techniques, has resulted in very efﬁcient LP platforms. However, rather early two orthogonal approaches to the solution of the above problem where identiﬁed: parallehzation and constraint solving. The former exploits parallelism that is naturally embedded in the declarative semantics of logic programs, in order to decrease the …",0
Using Classifier Selection,2006,https://scholar.google.com/scholar?cluster=17367574109041649065&hl=en&oi=scholarr,"The prediction of the translation initiation site (TIS) in a genomic se-quence is an important issue in biological research. Several methods have been proposed to deal with it. However, it is still an open problem. In this paper we follow an approach consisting of a number of steps in order to increase TIS prediction accuracy. First, all the sequences are scanned and the candidate TISS are detected. These sites are grouped according to the length of the sequence upstream and downstream them and a number of features is generated for each one. The features are evaluated among the instances of every group and a num-ber of the top ranked ones are selected for building a classifier. A new instance is assigned to a group and is classified by the corresponding classifier. We ex-periment with various feature sets and classification algorithms, compare with alternative methods and draw important conclusions.",1
"Ontologies, Databases and Applications of Semantics (ODBASE) 2006 International Conference-Agents-PersoNews: A Personalized News Reader Enhanced by Machine Learning and Semantic Filtering",2006,https://scholar.google.com/scholar?cluster=4298965210945281080&hl=en&oi=scholarr,Unknown,1
A Novel Approach for Incremental Uncertainty Rule Generation from Databases with Missing Values Handling,2005,http://ikee.lib.auth.gr/record/201979,"Current approaches for mining association rules usually assume that the mining is performed in a static database, where the problem of missing attribute values does not practically exist. However, these assumptions are not preserved in some medical databases, like in a home care system. In this paper, a novel uncertainty rule algorithm is illustrated, namely URG-2 (Uncertainty Rule Generator), which addresses the problem of mining dynamic databases containing missing values. This algorithm requires only one pass from the initial dataset in order to generate the item set, while new metrics corresponding to the notion of Support and Confidence are used. URG-2 was evaluated over two medical databases, introducing randomly multiple missing values for each record's attribute (rate: 5–20% by 5% increments) in the initial dataset. Compared with the classical approach (records with missing values are ignored …",0
Coordination in Multi-Agent Planning with an Application in Logistics,2005,https://www.igi-global.com/chapter/intelligent-techniques-planning/24463,"Multi-agent planning comprises planning in an environment with multiple autonomous actors. Techniques for multi-agent planning differ from conventional planning in that planning activities are distributed and the planning autonomy of the agents must be respected. We focus on approaches to coordinate the multi-agent planning process. While usually coordination is intertwined with the planning process, we distinguish a number of separate phases in the planning process to get a clear view on the different role (s) of coordination. In particular, we discuss the pre-planning coordination phase and post-planning coordination phase. In the pre-planning part, we view coordination as the process of managing (sub) task dependencies and we discuss a method that ensures complete planning autonomy by introducing additional (intra-agent) dependencies. In the post-planning part, we will show how agents can improve …",0
Aggregator: A Knowledge Based Comparison Chart Builder for eShopping,2005,https://link.springer.com/chapter/10.1007/978-1-4020-7829-3_6,"Most internet stores selling certain types of products, usually offer a limited set of brand names and for each brand name, a limited set of products. In addition, the design of such e-commerce sites is strongly influenced by retailers whose only goal is to sell as many products as possible to the users that visit their site. As a result, such sites follow a fixed representation for the products offered and put more emphasis on the price, less emphasis on the complete presentation of the features of the product, and unfortunately, they discourage side-by-side comparison shopping. Moreover, presenting various products, they put emphasis on just a few strong features and they don’t mention the weak ones. Although such e-shops are valuable for the final purchase transaction, they fail to service the non-informed customer, that is, the potential buyer that has no clear picture of what exactly to buy from the available …",0
for Adaptive Multicriteria Planning,2004,https://scholar.google.com/scholar?cluster=11825988580296414117&hl=en&oi=scholarr,"This paper concerns the design and development of an adap-tive planner that is able to adjust its parameters to the characteristics of a given problem and to the priorities set by the user concerning plan length and planning time. This is accomplished through the implementation of the k nearest neighbor machine learning algorithm on top of a highly adjustable planner, called HAP. Learning data are produced by running HAP offline on several problems from multiple domains using all value combinations of its parameters. When the adaptive planner HAPnn is faced with a new problem, it locates the k nearest problems, using a set of measurable problem characteristics, retrieves the performance data for all parameter configurations on these problems and performs a mul-ticriteria combination, with user-specified weights for plan length and planning time. Based on this combination, the configuration with the best performance is then used in order to solve the new problem. Comparative experiments with the statistically best static configurations of the planner show that HAPnn manages to adapt successfully to unseen problems, leading to an increased planning performance.",1
Simple Distributed Filtering on a CLP Platform,2004,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.719.2234&rep=rep1&type=pdf,"The area of distributed constraint satisfaction has drawn significant attention in the past decade. The approaches proposed in the area can be classified in two large categories: distributed search techniques and distributed filtering techniques. The work described in this paper concerns the CLP implementation of the Dis-SAC algorithm, a novel distributed filtering technique that is based on the singleton consistency algorithm. The advantages of the algorithm include a high pruning efficiency and a remarkable simplicity. The latter allows an unproblematic implementation of the algorithm in any constraint programming platform that supports network communication, without the need of tampering with the (low level) consistency algorithm employed. The present paper briefly describes Dis-SAC along with its implementation in the Cspcons distributed CLP platform and presents experimental results on a number of structured constraint problems. The motivation behind this work is twofold: to support our argument concerning the simple implementation of the algorithm and to further investigate the benefits of its application to constraint satisfaction problems.",1
"DR, DEVICE: A Defeasible Logic RDF Rule Language",2004,https://www.academia.edu/download/37730134/iswc04-demo.pdf,"Defeasible reasoning is a rule4based approach for efficient reasoning with incomplete and inconsistent information. Such reasoning is, among others, useful for ontology integration, where conflicting information arises naturally; and for the modeling of business rules and policies, where rules with exceptions are often used. In this demonstration we pre4 sent a prototype system for defeasible reasoning on the Web. The system is called DR4DEVICE [4] and is capable of reasoning about RDF metadata over multiple Web sources using defeasible logic [1] rules. The system is implemented on top of CLIPS production rule system and builds upon R4DEVICE [5], an earlier deductive rule system over RDF metadata that also supports derived attribute and aggregate attribute rules. Rules can be expressed either in a native CLIPS4like language, or in an extension of the OO4RuleML [9] syntax. The operational semantics of defeasible logic are implemented through compilation into the generic rule language of R4DEVICE. This demonstration includes a complete use case of a semantic web broker that reasons about apartment renting. The most important features of DR4DEVICE are the following:• Support for multiple rule types of defeasible logic, such as strict rules, defeasible rules, and defeaters.• Support for both classical (strong) negation and negation-as-failure.• Support for conflicting literals, ie derived objects that exclude each other.• Direct import from the Web of RDF ontologies and data as input facts to the defeasible logic program.• Direct import from the Web of defeasible logic programs in an XML compliant rule syntax (RuleML).• Direct export to …",0
"Preface| Information Sciences-Volume 155, Issues 3–4",2003,https://scholar.google.com/scholar?cluster=10009290449363818566&hl=en&oi=scholarr,"The interdisciplinary research area of Knowledge Discovery in Databases and Data Mining started forming in the late 80’s in order to deal with the problem of automating data analysis, gathering the interest of researchers and practitioners from areas such as statistics, databases, and machine learning. Since then, the technologies for data sensing and storing have progressed enormously. Soon we will be able to record everything: personal multimedia, textual and other data, scientific structured data, business structured and unstructured data. Dealing with this information avalanche is still a grand challenge for data mining.The ever-growing size of data being stored in today’s information systems, inevitably leads to distributed database architectures, as data cannot fit in a single machine. Moreover, the offices or departments of many organizations and companies are scattered across a country or across the world …",0
"Methods and Applications of Artificial Intelligence: Second Hellenic Conference on AI, SETN 2002 Thessaloniki, Greece, April 11–12, 2002 Proceedings",2003,https://books.google.com/books?hl=en&lr=&id=i6moCAAAQBAJ&oi=fnd&pg=PR1&dq=info:s3zw3DzBrJcJ:scholar.google.com&ots=5pizTSWg0X&sig=Q7yNAkPSCdyQskZ3WUJ-8PaA6lQ,"This book constitutes the refereed proceedings of the Second Hellenic Conference on Artificial Intelligence, SETN 2002, held in Thessaloniki, Greece, in April 2002. The 42 revised full papers presented together with two invited contributions were carefully reviewed and selected for inclusion in the book. The papers are organized in topical sections on knowledge representation and reasoning, logic programming and constraint satisfaction, planning and scheduling, natural language processing, human-computer interaction, machine learning, intelligent Internet and multiagent systems, and intelligent applications.",1
"Anderson, M. and R. McCartney Diagram processing: Computing with diagrams 181–226 Backer, E., see Veenman, CJ 227–243 Campbell, M., see Schetter, T. 147–180",2003,https://core.ac.uk/download/pdf/82149950.pdf,"Li, S. and M. Ying Region Connection Calculus: Its models and composition table 121–146 McCartney, R., see Anderson, M. 181–226 Narizzano, M., see Giunchiglia, E. 99–120 Refanidis, I. and I. Vlahavas Multiobjective heuristic state-space planning 1–32 Reinders, MJT, see Veenman, CJ 227–243 Sandholm, T. and S. Suri BOB: Improved winner determination in combinatorial auctions and generalizations 33–58",1
Applying a Distributed CLP Platform to a Workforce Management Problem,2003,http://lpis.csd.auth.gr/publications/sakellariou_cspwom_isap03.pdf,"The work presented in this paper concerns the ap-plication of CSPCONS, a distributed constraint logic programming platform to a workforce management problem, namely the BT-250-118 problem instance. The latter is a well-studied problem instance in which the requirement is to create sequences of job locations for the technicians to visit (tours), so as to serve as many jobs as possible, minimizing at the same time the travel duration. CSPCONS is a logic programming platform that supports program execution over multiple Prolog processes with constraints. It offers channel-based communicating processes and TCP/IP communication and is based on the CSP model introduced by Hoare. This paper demonstrates its applicability to such complex Distributed Constraint Satisfaction problems.",1
Educational Metadata Management System using a Deductive Object-Oriented Database Approach,2002,https://www.learntechlib.org/p/10218/,"The traditional use of large search engines for retrieving educational information on the Internet is rather inaccurate and provides irrelevant search results in most cases. Recently metadata are widely used to semantically describe educational resources and a number of educational metadata specifications have been proposed aiming at defining the set of elements that can better describe an educational resource. This paper proposes an architecture for an educational metadata management system, which facilitates both metadata storage and data retrieval, by using a deductive object-oriented database. The proposed system provides not only tools for creation, validation and modification of educational metadata documents, but also an efficient information retrieval mechanism based on user queries.",1
FUNAGES: an Educational Expert System for Fundus Fluorescein Angiography,2001,http://ikee.lib.auth.gr/record/201543,"FUNAGES is an expert system that deals with the interpretation of fundus fluorescein angiography. Fluorescein angiography is an extremely valuable clinical test that provides information about the circulatory system of the ocular fundus (the back of the eye) not attainable by routine examination. The different appearance of fluorescein, in place and time and the classification of the fundus diseases render angiography a dynamic, cinematographic and deductive diagnostic method. Therefore, ability to interpret fundus fluorescein angiograms allows an ophthalmologist specializing in ocular fundus diseases to follow a systematic, orderly and logical line of reasoning that leads to a proper diagnosis. FUNAGES was developed to simulate such logical reasoning, in order to train inexperienced ophthalmologists in the interpretation of angiograms. The system achieved its purpose via a graphical user interface and a …",0
The GRT Planning System,2001,http://ikee.lib.auth.gr/record/263353,"This paper presents GRT, a domain-independent heuristic planning system for STRIPS worlds. GRT solves problems in two phases. In the pre-processing phase, it estimates the distance between each fact and the goals of the problem, in a backward direction. Then, in the search phase, these estimates are used in order to further estimate the distance between each intermediate state and the goals, guiding so the search process in a forward direction and on a best-first basis. The paper presents the benefits from the adoption of opposite directions between the preprocessing and the search phases, discusses some difficulties that arise in the pre-processing phase and introduces techniques to cope with them. Moreover, it presents several methods of improving the efficiency of the heuristic, by enriching the representation and by reducing the size of the problem. Finally, a method of overcoming local optimal states …",0
A comprehensive study over VLAD and product quantization in large-scale image retrieval,2014,https://ieeexplore.ieee.org/abstract/document/6847226/,"This paper deals with content-based large-scale image retrieval using the state-of-the-art framework of VLAD and Product Quantization proposed by Jegou as a starting point. Demonstrating an excellent accuracy-efficiency trade-off, this framework has attracted increased attention from the community and numerous extensions have been proposed. In this work, we make an in-depth analysis of the framework that aims at increasing our understanding of its different processing steps and boosting its overall performance. Our analysis involves the evaluation of numerous extensions (both existing and novel) as well as the study of the effects of several unexplored parameters. We specifically focus on: a) employing more efficient and discriminative local features; b) improving the quality of the aggregated representation; and c) optimizing the indexing scheme. Our thorough experimental evaluation provides new insights …",0
An integrated approach to automated semantic web service composition through planning,2011,https://ieeexplore.ieee.org/abstract/document/5744077/,"The paper presents an integrated approach for automated semantic web service composition using AI planning techniques. An important advantage of this approach is that the composition process, as well as the discovery of the atomic services that take part in the composition, are significantly facilitated by the incorporation of semantic information. OWL-S web service descriptions are transformed into a planning problem described in a standardized fashion using PDDL, while semantic information is used for the enhancement of the composition process as well as for approximating the optimal composite service when exact solutions are not found. Solving, visualization, manipulation, and evaluation of the produced composite services are accomplished, while, unlike other systems, independence from specific planners is maintained. Implementation was performed through the development and integration of two …",0
An ensemble pruning primer,2009,https://link.springer.com/chapter/10.1007/978-3-642-03999-7_1,Ensemble pruning deals with the reduction of an ensemble of predictive models in order to improve its efficiency and predictive performance. The last 12 years a large number of ensemble pruning methods have been proposed. This work proposes a taxonomy for their organization and reviews important representative methods of each category. It abstracts their key components and discusses their main advantages and disadvantages. We hope that this work will serve as a good starting point and reference for researchers working on the development of new ensemble pruning methods.,1
A defeasible logic reasoner for the semantic web,2006,https://www.igi-global.com/article/defeasible-logic-reasonersemantic-web/2815,"Defeasible reasoning is a rule-based approach for efficient reasoning with incomplete and inconsistent information. Such reasoning is, among others, useful for ontology integration, where conflicting information arises naturally; and for the modeling of business rules and policies, where rules with exceptions are often used. This paper describes these scenarios and reports on the implementation of a system for defeasible reasoning on the Web. The system, DR-DEVICE, is capable of reasoning about RDF metadata over multiple Web sources using defeasible logic rules. It is implemented on top of CLIPS production rule system and builds upon R-DEVICE, an earlier deductive rule system over RDF metadata that also supports derived attribute and aggregate attribute rules. Rules can be expressed either in a native CLIPS-like language, or in an extension of the OO-RuleML syntax. The operational semantics of …",0
Selective fusion of heterogeneous classifiers,2005,https://content.iospress.com/articles/intelligent-data-analysis/ida00225,"There are two main paradigms in combining different classification algorithms: Classifier Selection and Classifier Fusion. The first one selects a single model for classifying a new instance, while the latter combines the decisions of all models. The work presented in this paper stands in between these two paradigms aiming to tackle the disadvantages and benefit from the advantages of both. In particular, this paper proposes the use of statistical procedures for the selection of the best subgroup among different classification algorithms and the subsequent fusion of the decision of the models in this subgroup with simple methods like Weighted Voting. Extensive experimental results show that the proposed approach, Selective Fusion, improves over simple selection and fusion methods, leading to performance comparable with the state-of-the-art heterogeneous classifier combination method of Stacking, without the …",0
An ontology-based planning system for e-course generation,2008,https://www.sciencedirect.com/science/article/pii/S0957417407002588,"Researchers in the area of educational software have always shown great interest in the automatic synthesis of learning curricula. During the recent years, with the extensive use of metadata and the emergence of the Semantic Web, this vision is gradually turning into a reality. A number of systems for curricula synthesis have been proposed. These systems are based on strong relations defined in the metadata of learning objects, which allow them to be combined with other learning objects, in order to form a complete educational program. This article presents PASER, a system for automatically synthesizing curricula using AI Planning and Semantic Web technologies. The use of classical planning techniques allows the system to dynamically construct learning paths even from disjoint learning objects, meeting the learner’s profile, preferences, needs and abilities.",1
An ensemble uncertainty aware measure for directed hill climbing ensemble pruning,2010,https://link.springer.com/article/10.1007/s10994-010-5172-0,"This paper proposes a new measure for ensemble pruning via directed hill climbing, dubbed Uncertainty Weighted Accuracy (UWA), which takes into account the uncertainty of the decision of the current ensemble. Empirical results on 30 data sets show that using the proposed measure to prune a heterogeneous ensemble leads to significantly better accuracy results compared to state-of-the-art measures and other baseline methods, while keeping only a small fraction of the original models. Besides the evaluation measure, the paper also studies two other parameters of directed hill climbing ensemble pruning methods, the search direction and the evaluation dataset, with interesting conclusions on appropriate values.",1
Dealing with concept drift and class imbalance in multi-label stream classification,2011,https://www.aaai.org/ocs/index.php/IJCAI/IJCAI11/paper/viewPaper/2928,"Data streams containing objects that are (or can be) associated with more than one label at the same time are ubiquitous. In spite of its important applications, classification of streaming multi-label data is largely unexplored. Existing approaches try to tackle the problem by transferring traditional single-label stream classification practices to the multi-label domain. Nevertheless, they fail to consider some of the unique properties of the problem such as within and between class imbalance and multiple concept drift. To deal with these challenges, this paper proposes a novel multi-label stream classification approach that employs two windows for each label, one for positive and one for negative examples. Instance-sharing is exploited for space efficiency, while a time-efficient instantiation based on the k-Nearest Neighbor algorithm is also proposed. Finally, a batch-incremental thresholding technique is proposed to further deal with the class imbalance problem. Results of an empirical comparison against two other methods on three real world datasets are in favor of the proposed approach.",1
Pruning an ensemble of classifiers via reinforcement learning,2009,https://www.sciencedirect.com/science/article/pii/S0925231208003184,"This paper studies the problem of pruning an ensemble of classifiers from a reinforcement learning perspective. It contributes a new pruning approach that uses the Q-learning algorithm in order to approximate an optimal policy of choosing whether to include or exclude each classifier from the ensemble. Extensive experimental comparisons of the proposed approach against state-of-the-art pruning and combination methods show very promising results. Additionally, we present an extension that allows the improvement of the solutions returned by the proposed approach over time, which is very useful in certain performance-critical domains.",1
Multiple and partial periodicity mining in time series databases,2002,https://core.ac.uk/download/pdf/21172789.pdf,"Periodicity search in time series is a problem that has been investigated by mathematicians in various areas, such as statistics, economics, and digital signal processing. For large databases of time series data, scalability becomes an issue that traditional techniques fail to address. In existing time series mining algorithms for detecting periodic patterns, the period length is userspecified. This is a drawback especially for datasets where no period length is known in advance. We propose an algorithm that extracts a set of candidate periods featured in a time series that satisfy a minimum confidence threshold, by utilizing the autocorrelation function and FFT as a filter. We provide some mathematical background as well as experimental results. 12",1
Focused Ensemble Selection: A Diversity-Based Method for Greedy Ensemble Selection.,2008,https://books.google.com/books?hl=en&lr=&id=3Wsn3SwEBScC&oi=fnd&pg=PA117&dq=info:matxk_HzgacJ:scholar.google.com&ots=a2qumL9ylQ&sig=UmtK50stg2hX8IG5ahDp1BjuWhE,"Ensemble selection deals with the reduction of an ensemble of predictive models in order to improve its efficiency and predictive performance. A number of ensemble selection methods that are based on greedy search of the space of all possible ensemble subsets have recently been proposed. This paper contributes a novel method, based on a new diversity measure that takes into account the strength of the decision of the current ensemble. Experimental comparison of the proposed method, dubbed Focused Ensemble Selection (FES), against state-of-the-art greedy ensemble selection methods shows that it leads to small ensembles with high predictive performance.",1
An adaptive personalized news dissemination system,2009,https://link.springer.com/content/pdf/10.1007/s10844-008-0053-8.pdf,"With the explosive growth of the Word Wide Web, information overload became a crucial concern. In a data-rich information-poor environment like the Web, the discrimination of useful or desirable information out of tons of mostly worthless data became a tedious task. The role of Machine Learning in tackling this problem is thoroughly discussed in the literature, but few systems are available for public use. In this work, we bridge theory to practice, by implementing a web-based news reader enhanced with a specifically designed machine learning framework for dynamic content personalization. This way, we get the chance to examine applicability and implementation issues and discuss the effectiveness of machine learning methods for the classification of real-world text streams. The main features of our system named PersoNews are: (a) the aggregation of many different news sources that offer an RSS …",0
Multi-label classification of music by emotion,2011,https://link.springer.com/article/10.1186/1687-4722-2011-426793,"This work studies the task of automatic emotion detection in music. Music may evoke more than one different emotion at the same time. Single-label classification and regression cannot model this multiplicity. Therefore, this work focuses on multi-label classification approaches, where a piece of music may simultaneously belong to more than one class. Seven algorithms are experimentally compared for this task. Furthermore, the predictive power of several audio features is evaluated using a new multi-label feature selection method. Experiments are conducted on a set of 593 songs with six clusters of emotions based on the Tellegen-Watson-Clark model of affect. Results show that multi-label modeling is successful and provide interesting insights into the predictive quality of the algorithms and features.",1
A taxonomy and short review of ensemble selection,2008,https://www.academia.edu/download/5748662/partalas08-suema.pdf,"Ensemble selection deals with the reduction of an ensemble of predictive models in order to improve its efficiency and predictive performance. The last 10 years a large number of very diverse ensemble selection methods have been proposed. In this paper we make a first approach to categorize them into a taxonomy. We also present a short review of some of these methods. We particularly focus on a category of methods that are based on greedy search of the space of all possible ensemble subsets. Such methods use different directions for searching this space and different measures for evaluating the available actions at each state. Some use the training set for subset evaluation, while others a separate validation set. This paper abstracts the key points of these methods and offers a general framework of the greedy ensemble selection algorithm, discussing its important parameters and the different options for instantiating these parameters.",1
The CLEF 2011 Photo Annotation and Concept-based Retrieval Tasks.,2011,http://ceur-ws.org/Vol-1177/CLEF2011wn-ImageCLEF-NowakEt2011.pdf,"The ImageCLEF 2011 Photo Annotation and Concept-based Retrieval Tasks pose the challenge of an automated annotation of Flickr images with 99 visual concepts and the retrieval of images based on query topics. The participants were provided with a training set of 8,000 images including annotations, EXIF data, and Flickr user tags. The annotation challenge was performed on 10,000 images, while the retrieval challenge considered 200,000 images. Both tasks differentiate among approaches that consider solely visual information, approaches that rely only on textual information in form of image metadata and user tags, and multi-modal approaches that combine both information sources. The relevance assessments were acquired with a crowdsourcing approach and the evaluation followed two evaluation paradigms: per concept and per example. In total, 18 research teams participated in the annotation challenge with 79 submissions. The concept-based retrieval task was tackled by 4 teams that submitted a total of 31 runs. Summarizing the results, the annotation task could be solved with a MiAP of 0.443 in the multimodal configuration, with a MiAP of 0.388 in the visual configuration, and with a MiAP of 0.346 in the textual configuration. The conceptbased retrieval task was solved best with a MAP of 0.164 using multimodal information and a manual intervention in the query formulation. The best completely automated approach achieved 0.085 MAP and uses solely textual information. Results indicate that while the annotation task shows promising results, the concept-based retrieval task is much harder to solve, especially for specific …",0
Effective voting of heterogeneous classifiers,2004,https://link.springer.com/chapter/10.1007/978-3-540-30115-8_43,"This paper deals with the combination of classification models that have been derived from running different (heterogeneous) learning algorithms on the same data set. We focus on the Classifier Evaluation and Selection (ES) method, that evaluates each of the models (typically using 10-fold cross-validation) and selects the best one. We examine the performance of this method in comparison with the Oracle selecting the best classifier for the test set and show that 10-fold cross-validation has problems in detecting the best classifier. We then extend ES by applying a statistical test to the 10-fold accuracies of the models and combining through voting the most significant ones. Experimental results show that the proposed method, Effective Voting, performs comparably with the state-of-the-art method of Stacking with Multi-Response Model Trees without the additional computational cost of meta-training.",1
Reinforcement learning agents providing advice in complex video games,2014,https://www.tandfonline.com/doi/abs/10.1080/09540091.2014.885279,"This article introduces a teacher–student framework for reinforcement learning, synthesising and extending material that appeared in conference proceedings [Torrey, L., & Taylor, M. E. (2013)]. Teaching on a budget: Agents advising agents in reinforcement learning. {Proceedings of the international conference on autonomous agents and multiagent systems}] and in a non-archival workshop paper [Carboni, N., &Taylor, M. E. (2013, May)]. Preliminary results for 1 vs. 1 tactics in StarCraft. {Proceedings of the adaptive and learning agents workshop (at AAMAS-13)}]. In this framework, a teacher agent instructs a student agent by suggesting actions the student should take as it learns. However, the teacher may only give such advice a limited number of times. We present several novel algorithms that teachers can use to budget their advice effectively, and we evaluate them in two complex video games: StarCraft and …",0
Software Defect Prediction Using Regression via Classification.,2006,https://www.academia.edu/download/39820881/Software_Defect_Prediction_Using_Regress20151109-10467-18qewqk.pdf,"In this paper we apply a machine learning approach to the problem of estimating the number of defects called Regression via Classification (RvC). RvC initially automatically discretizes the number of defects into a number of fault classes, then learns a model that predicts the fault class of a software system. Finally, RvC transforms the class output of the model back into a numeric prediction. This approach includes uncertainty in the models because apart from a certain number of faults, it also outputs an associated interval of values, within which this estimate lies, with a certain confidence. To evaluate this approach we perform a comparative experimental study of the effectiveness of several machine learning algorithms in a software dataset. The data was collected by Pekka Forselious and involves applications maintained by a bank of Finland.",1
A new hybrid neural-genetic methodology for improving learning,1997,https://ieeexplore.ieee.org/abstract/document/632233/,A new hybrid neural-generic methodology is presented that exploits the optimization advantages of genetic algorithms for the purpose of accelerating neural network training. The choice of fitness function is addressed and experimental findings are shown where neural network training is improved through the proposed approach. The results suggest that genetic algorithms can be a powerful tool for improving learning in neural networks.,1
TRES: identification of discriminatory and informative SNPs from population genomic data,2015,https://academic.oup.com/jhered/article-abstract/106/5/672/2960031,"The advent of high-throughput genomic technologies is enabling analyses on thousands or even millions of single-nucleotide polymorphisms (SNPs). At the same time, the selection of a minimum number of SNPs with the maximum information content is becoming increasingly problematic. Available locus ranking programs have been accused of providing upwardly biased results (concerning the predicted accuracy of the chosen set of markers for population assignment), cannot handle high-dimensional datasets, and some of them are computationally intensive. The toolbox for ranking and evaluation of SNPs (TRES) is a collection of algorithms built in a user-friendly and computationally efficient software that can manipulate and analyze datasets even in the order of millions of genotypes in a matter of seconds. It offers a variety of established methods for evaluating and ranking SNPs on user defined groups of …",0
Ensemble Approaches for Large-Scale Multi-Label Classification and Question Answering in Biomedicine.,2014,http://ceur-ws.org/Vol-1180/CLEF2014wn-QA-PapanikolaouEt2014.pdf,"This paper documents the systems that we developed for our participation in the BioASQ 2014 large-scale bio-medical semantic indexing and question answering challenge. For the large-scale semantic indexing task, we employed a novel multi-label ensemble method consisting of support vector machines, labeled Latent Dirichlet Allocation models and meta-models predicting the number of relevant labels. This method proved successful in our experiments as well as during the competition. For the question answering task we combined different techniques for scoring of candidate answers based on recent literature.",1
Instance-based ensemble pruning via multi-label classification,2010,https://ieeexplore.ieee.org/abstract/document/5670063/,"Ensemble pruning is concerned with the reduction of the size of an ensemble prior to its combination. Its purpose is to reduce the space and time complexity of the ensemble and/or to increase the ensemble's accuracy. This paper focuses on instance-based approaches to ensemble pruning, where a different subset of the ensemble may be used for each different unclassified instance. We propose modeling this task as a multi-label learning problem, in order to take advantage of the recent advances in this area for the construction of effective ensemble pruning approaches. Results comparing the proposed framework against a variety of other instance-based ensemble pruning approaches in a variety of datasets using a heterogeneous ensemble of 200 classifiers, show that it leads to improved accuracy.",1
MANTIS: a data mining methodology for effective translation initiation site prediction,2007,https://ieeexplore.ieee.org/abstract/document/4353806/,"The prediction of the translation initiation site in a genomic sequence with the highest possible accuracy is an important problem that still has to be investigated by the research community. Current approaches perform quite well, however there is still room for a more general framework for the researchers who want to follow an effective and reliable methodology. We developed a prediction methodology that combines ad hoc as well as discovered knowledge in order to significantly increase the achieved accuracy reliably. Our methodology is modular and consists of three major decision components: a consensus component, a coding region classification component and a novel ATG location-based component that allows for the utilization of the advantages of the popular ribosome scanning model while overcoming its limitations. All three of them are combined into a meta-classification system, using stacked …",0
Modern applications of machine learning,2006,https://intelligence.csd.auth.gr/wp-content/uploads/2019/03/tzanis_seerc06.pdf,"A cognitive system tries to understand the concepts of its environment by using a simplified interpretation of this environment called model. The procedure of constructing such a model is called inductive learning. Moreover, a cognitive system is able to organize its experience by constructing new structures called patterns. The construction of models and patterns by a cognitive system using a dataset is called machine learning. Machine learning tasks can be classified into the following two groups:",1
Inter-transaction association rules mining for rare events prediction,2004,https://intelligence.csd.auth.gr/wp-content/uploads/2019/03/076-Berberidis-Angelis-Vlahavas-SETN04.pdf,"Rare events prediction is a very interesting and critical issue that has been approached within various contexts by research areas, such as statistics and machine learning. Data mining has provided a set of tools to treat this problem when the size as well as the inherent features of the data, such as noise, randomness and special data types, become an issue for the traditional methods. Transaction databases that contain sets of events require special approaches in order to extract valuable temporal knowledge. Sequential analysis aims to discover patterns or rules describing the temporal structure of data. In this paper we propose an approach that extends sequential analysis to predict rare events in transaction databases. We utilize the framework of inter-transaction association rules, which associate events across a window of transactions. The proposed algorithm produces rules for the accurate and timely prediction of a userspecified rare event, such as a network intrusion or an engine failure.",1
PRACTIC: A concurrent object data model for a parallel object-oriented database system,1995,https://www.sciencedirect.com/science/article/pii/0020025595000924,"A concurrent object data model for a parallel object-oriented database system, named PRACTIC, and its abstract machine are presented. PRACTIC means PaRallel ACTIve Classes and is based on the vertical partitioning and concurrent management of the database schema classes and metaclasses, which are collectively called active objects. Active objects are permanent processes in memory that encapsulate their definitions, methods, and management procedures. Semiactive and passive objects exist to realize abstract classes and instances (the actual data), respectively. The object model gives rise to a query/method execution model that provides parallelism on all levels of the instantiation hierarchy. The abstract PRACTIC machine directly maps the model to a MIMD machine. The performance of one of the proposed parallel query/method execution schemes is measured by simulation on the abstract machine.",1
PaaSport semantic model: An ontology for a platform-as-a-service semantically interoperable marketplace,2018,https://www.sciencedirect.com/science/article/pii/S0169023X17300551,"PaaS is a Cloud computing service that provides a computing platform to develop, run, and manage applications without the complexity of infrastructure maintenance. SMEs are reluctant to enter the growing PaaS market due to the possibility of being locked in to a certain platform, mostly provided by the market's giants. The PaaSport Marketplace aims to avoid the provider lock-in problem by allowing Platform provider SMEs to roll out semantically interoperable PaaS offerings and Software SMEs to deploy or migrate their applications on the best-matching offering, through a thin, non-intrusive Cloud broker. In this paper, we present the PaaSport semantic model, namely an OWL ontology, extension of the DUL ontology. The ontology is used for semantically representing (a) PaaS offering capabilities and (b) requirements of applications to be deployed. The ontology has been designed to optimally support a semantic …",0
The tomaco hybrid matching framework for SAWSDL semantic web services,2015,https://ieeexplore.ieee.org/abstract/document/7104178/,"This work aims to advance Web Service retrieval, also known as Matching, in two directions. First, it introduces a matching algorithm for SAWSDL, which adapts and extends known concepts with novel strategies. Effective logic-based and syntactic strategies are introduced and combined in a novel hybrid strategy, targeting an envisioned well-defined, real-world scenario for matching. The algorithm is evaluated in a universal environment for matching algorithms, SME2, in an objective, reproducible manner. Evaluation ranks Tomaco high amongst state of the art, especially for early recall levels (first in macro-averaging precision, up to 0.7 recall). Secondly, this work introduces the Tomaco web application, which aims to promote wide-spread adoption of Semantic Web Services while targeting the lack of user-friendly applications in this field, by integrating a variety of configurable matching algorithms proposed in this …",0
A novel data mining approach for the accurate prediction of translation initiation sites,2006,https://link.springer.com/chapter/10.1007/11946465_9,"In an mRNA sequence, the prediction of the exact codon where the process of translation starts (Translation Initiation Site – TIS) is a particularly important problem. So far it has been tackled by several researchers that apply various statistical and machine learning techniques, achieving high accuracy levels, often over 90%. In this paper we propose a mahine learning approach that can further improve the prediction accuracy. First, we provide a concise review of the literature in this field. Then we propose a novel feature set. We perform extensive experiments on a publicly available, real world dataset for various vertebrate organisms using a variety of novel features and classification setups. We evaluate our results and compare them with a reference study and show that our approach that involves new features and a combination of the Ribosome Scanning Model with a meta-classifier shows higher …",0
Path planning in a 2-D known space using neural networks and skeletonization,1997,https://ieeexplore.ieee.org/abstract/document/635147/,"A neural network and a skeletonization based path planning in a 2D known space is presented. For the neural network path planning approach a Kohonen self-organizing net has been chosen, while for the skeletonization Kwok's method (1988) was used. The output of the network represents a reduced representation of the free space available for robotic movement in a 2D known environment.",1
A visual programming system for automated problem solving,2010,https://www.sciencedirect.com/science/article/pii/S0957417409010938,"Although new AI planning algorithms and techniques are being developed and improved rapidly, there is a lack of efficient and easy to use systems able to incorporate and utilize them. Furthermore, while visual representation facilitates design, maintenance and comprehension of planning domains and problems, very few systems incorporate it. This paper presents VLEPPO, an integrated system aiming at visually modeling planning domains and problems through a convenient graphical interface, while maintaining compatibility with the Planning Domain Definition Language (PDDL), with import and export features. Solutions to planning problems can be obtained by invoking different planners employing the web services technology. The demonstration of the system is performed through a case study involving web service composition viewed as a planning problem.",1
Semantic web service composition using planning and ontology concept relevance,2009,https://ieeexplore.ieee.org/abstract/document/5286036/,"This paper presents PORSCE II, a system that combines planning and ontology concept relevance for automatically composing semantic web services. The presented approach includes transformation of the web service composition problem into a planning problem, enhancement with semantic awareness and relaxation and solution through external planners. The produced plans are visualized and their accuracy is assessed.",1
Multi-agent reinforcement learning using strategies and voting,2007,https://ieeexplore.ieee.org/abstract/document/4410398/,"Multiagent learning attracts much attention in the past few years as it poses very challenging problems. Reinforcement Learning is an appealing solution to the problems that arise to Multi Agent Systems (MASs). This is due to the fact that Reinforcement Learning is a robust and well suited technique for learning in MASs. This paper proposes a multi-agent Reinforcement Learning approach, that uses coordinated actions, which we call strategies and a voting process that combines the decisions of the agents, in order to follow a strategy. We performed experiments to the predator-prey domain, comparing our approach with other multi-agent Reinforcement Learning techniques, getting promising results.",1
Prediction of translation initiation sites using classifier selection,2006,https://link.springer.com/chapter/10.1007/11752912_37,"The prediction of the translation initiation site (TIS) in a genomic sequence is an important issue in biological research. Several methods have been proposed to deal with it. However, it is still an open problem. In this paper we follow an approach consisting of a number of steps in order to increase TIS prediction accuracy. First, all the sequences are scanned and the candidate TISs are detected. These sites are grouped according to the length of the sequence upstream and downstream them and a number of features is generated for each one. The features are evaluated among the instances of every group and a number of the top ranked ones are selected for building a classifier. A new instance is assigned to a group and is classified by the corresponding classifier. We experiment with various feature sets and classification algorithms, compare with alternative methods and draw important conclusions.",1
R-device: A deductive rdf rule language,2004,https://link.springer.com/chapter/10.1007/978-3-540-30504-0_6,"In this paper we present R-DEVICE, a deductive rule language for reasoning about RDF metadata. R-DEVICE includes features such as normal and generalized path expressions, stratified negation, aggregate, grouping, and sorting, functions. The rule language supports a second-order syntax, where variables can range over classes and properties. Users can define views which are materialized and, optionally, incrementally maintained by translating deductive rules into CLIPS production rules. Users can choose between an OPS5/CLIPS-like or a RuleML-like syntax. R-DEVICE is based on a OO RDF data model, different than the established graph model, which maps resources to objects and encapsulates properties inside resource objects, as traditional OO attributes. In this way, less joins are required to access the properties of a single resource resulting in better inferencing/querying performance. The …",0
An intelligent educational metadata repository,2003,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.1033.5125&rep=rep1&type=pdf,"Recently, several standardization efforts for e-learning technologies gave rise to various specifications for educational metadata, that is, data describing all the"" entities"" involved in an educational procedure. The internal details of systems that utilize these metadata are still an open issue since these efforts are primarily dealing with"" what"" and not"" how"". In this chapter, under the light of these emerging standardization efforts, we present XDevice, an intelligent XML repository system for educational metadata. XDevice can be used as the intelligent back-end of a WWW portal on which"" learning objects"" are supplied by educational service providers and accessed by learners according to their individual profiles and educational needs. XDevice transforms the widely adopted XML binding for educational metadata into a flexible, object-oriented representation and uses intelligent second-order logic querying facilities to provide advanced, personalized functionality. Furthermore, a case study is presented, in which learning object metadata and learner's profile metadata are combined under certain XDevice rules in order to dynamically infer customized courses for the learner.",1
Mining multi-label data,2009,https://link.springer.com/chapter/10.1007/978-0-387-09823-4_34,"A large body of research in supervised learning deals with the analysis of single-label data, where training examples are associated with a single label λ from a set of disjoint labels L. However, training examples in several application domains are often associated with a set of labels Y ⊆ L. Such data are called multi-label.Textual data, such as documents and web pages, are frequently annotated with more than a single label. For example, a news article concerning the reactions of the Christian church to the release of the “Da Vinci Code” film can be labeled as both religion and movies. The categorization of textual data is perhaps the dominant multi-label application.",1
Random k-Labelsets: An Ensemble Method for Multilabel Classification,2007,https://link.springer.com/chapter/10.1007/978-3-540-74958-5_38,"This paper proposes an ensemble method for multilabel classification. The RAndom k-labELsets (RAKEL) algorithm constructs each member of the ensemble by considering a small random subset of labels and learning a single-label classifier for the prediction of each element in the powerset of this subset. In this way, the proposed algorithm aims to take into account label correlations using single-label classifiers that are applied on subtasks with manageable number of labels and adequate number of examples per label. Experimental results on common multilabel domains involving protein, document and scene classification show that better performance can be achieved compared to popular multilabel classification approaches.",1
Multi-label classification of music into emotions.,2008,https://books.google.com/books?hl=en&lr=&id=OHp3sRnZD-oC&oi=fnd&pg=PA325&dq=info:7dzC1REq6pwJ:scholar.google.com&ots=oGMPrKhxf8&sig=_8Yu_7tzOgckljM1aOvns5CtBzo,"In this paper, the automated detection of emotion in music is modeled as a multilabel classification task, where a piece of music may belong to more than one class. Four algorithms are evaluated and compared in this task. Furthermore, the predictive power of several audio features is evaluated using a new multilabel feature selection method. Experiments are conducted on a set of 593 songs with 6 clusters of music emotions based on the Tellegen-Watson-Clark model. Results provide interesting insights into the quality of the discussed algorithms and features.",1
Data mining,2005,https://scholar.google.com/scholar?cluster=10892743474699234220&hl=en&oi=scholarr,"Softcover. Condition: New. 3rd edition.. Brand NEW, Paperback International Edition. Black & White or color, Cover and ISBN may be different but similar contents as US editions. Standard delivery takes 5-9 business days by USPS/DHL with tracking number. Choose expedited shipping for superfast delivery 3-5 business days by UPS/DHL/FEDEX. We also ship to PO Box addresses but by Standard delivery and shipping charges will be extra. International Edition Textbooks may bear a label-Not for sale in the US or...",1
Random k-labelsets for multilabel classification,2010,https://ieeexplore.ieee.org/abstract/document/5567103/,"A simple yet effective multilabel learning method, called label powerset (LP), considers each distinct combination of labels that exist in the training set as a different class value of a single-label classification task. The computational efficiency and predictive performance of LP is challenged by application domains with large number of labels and training examples. In these cases, the number of classes may become very large and at the same time many classes are associated with very few training examples. To deal with these problems, this paper proposes breaking the initial set of labels into a number of small random subsets, called labelsets and employing LP to train a corresponding classifier. The labelsets can be either disjoint or overlapping depending on which of two strategies is used to construct them. The proposed method is called RAkEL (RAndom k labELsets), where k is a parameter that specifies the size …",0
Mulan: A java library for multi-label learning,2011,https://www.jmlr.org/papers/volume12/tsoumakas11a/tsoumakas11a.pdf,"MULAN is a Java library for learning from multi-label data. It offers a variety of classification, ranking, thresholding and dimensionality reduction algorithms, as well as algorithms for learning from hierarchically structured labels. In addition, it contains an evaluation framework that calculates a rich variety of performance measures.",1
Machine learning and data mining methods in diabetes research,2017,https://www.sciencedirect.com/science/article/pii/S2001037016300733,"The remarkable advances in biotechnology and health sciences have led to a significant production of data, such as high throughput genetic data and clinical information, generated from large Electronic Health Records (EHRs). To this end, application of machine learning and data mining methods in biosciences is presently, more than ever before, vital and indispensable in efforts to transform intelligently all available information into valuable knowledge. Diabetes mellitus (DM) is defined as a group of metabolic disorders exerting significant pressure on human health worldwide. Extensive research in all aspects of diabetes (diagnosis, etiopathophysiology, therapy, etc.) has led to the generation of huge amounts of data. The aim of the present study is to conduct a systematic review of the applications of machine learning, data mining techniques and tools in the field of diabetes research with respect to a) Prediction …",0
Effective and efficient multilabel classification in domains with large number of labels,2008,http://www.ecmlpkdd2008.org/files/pdf/workshops/mmd/4.pdf,"This paper contributes a novel algorithm for effective and computationally efficient multilabel classification in domains with large label sets L. The HOMER algorithm constructs a Hierarchy Of Multilabel classifiERs, each one dealing with a much smaller set of labels compared to L and a more balanced example distribution. This leads to improved predictive performance along with linear training and logarithmic testing complexities with respect to| L|. Label distribution from parent to children nodes is achieved via a new balanced clustering algorithm, called balanced k means.",1
“Cultures in negotiation”: teachers’ acceptance/resistance attitudes considering the infusion of technology into schools,2003,https://www.sciencedirect.com/science/article/pii/S0360131503000125,"A teachers’ training project, employing teacher-mentored in-school training approach, has been recently initiated in Greek secondary education for the introduction of Information and Communication Technology (ICT) into the classroom. Data resulting from this project indicate that although teachers express considerable interest in learning how to use technology they need consistent support and extensive training in order to consider themselves able for integrating it into their instructional practice. Teachers are interested in using ICT (1) to attain a better professional profile, and (2) to take advantage of any possible learning benefits offered by ICT but always in the context of the school culture. They are willing to explore open and communicative modes of ICT-based teaching whenever school objectives permit, otherwise they appear to cautiously adapt the use of ICT to the traditional teacher-centered mode of …",0
Multilabel text classification for automated tag suggestion,2008,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.183.2636&rep=rep1&type=pdf,"The increased popularity of tagging during the last few years can be mainly attributed to its embracing by most of the recently thriving user-centric content publishing and management Web 2.0 applications. However, tagging systems have some limitations that have led researchers to develop methods that assist users in the tagging process, by automatically suggesting an appropriate set of tags. We have tried to model the automated tag suggestion problem as a multilabel text classification task in order to participate in the ECML/PKDD 2008 Discovery Challenge.",1
An empirical study of lazy multilabel classification algorithms,2008,https://link.springer.com/chapter/10.1007/978-3-540-87881-0_40,"Multilabel classification is a rapidly developing field of machine learning. Despite its short life, various methods for solving the task of multilabel classification have been proposed. In this paper we focus on a subset of these methods that adopt a lazy learning approach and are based on the traditional k-nearest neighbor (kNN) algorithm. Two are our main contributions. Firstly, we implement BRkNN, an adaptation of the kNN algorithm for multilabel classification that is conceptually equivalent to using the popular Binary Relevance problem transformation method in conjunction with the kNN algorithm, but much faster. We also identify two useful extensions of BRkNN that improve its overall predictive performance. Secondly, we compare this method against two other lazy multilabel classification methods, in order to determine the overall best performer. Experiments on different real-world multilabel datasets …",0
Protein classification with multiple algorithms,2005,https://link.springer.com/chapter/10.1007/11573036_42,"Nowadays, the number of protein sequences being stored in central protein databases from labs all over the world is constantly increasing. From these proteins only a fraction has been experimentally analyzed in order to detect their structure and hence their function in the corresponding organism. The reason is that experimental determination of structure is labor-intensive and quite time-consuming. Therefore there is the need for automated tools that can classify new proteins to structural families. This paper presents a comparative evaluation of several algorithms that learn such classification models from data concerning patterns of proteins with known structure. In addition, several approaches that combine multiple learning algorithms to increase the accuracy of predictions are evaluated. The results of the experiments provide insights that can help biologists and computer scientists design high …",0
On the stratification of multi-label data,2011,https://link.springer.com/chapter/10.1007/978-3-642-23808-6_10,"Stratified sampling is a sampling method that takes into account the existence of disjoint groups within a population and produces samples where the proportion of these groups is maintained. In single-label classification tasks, groups are differentiated based on the value of the target variable. In multi-label learning tasks, however, where there are multiple target variables, it is not clear how stratified sampling could/should be performed. This paper investigates stratification in the multi-label data context. It considers two stratification methods for multi-label data and empirically compares them along with random sampling on a number of datasets and based on a number of evaluation criteria. The results reveal some interesting conclusions with respect to the utility of each method for particular types of multi-label datasets.",1
Tracking recurring contexts using ensemble classifiers: an application to email filtering,2010,https://link.springer.com/article/10.1007/s10115-009-0206-2,"Concept drift constitutes a challenging problem for the machine learning and data mining community that frequently appears in real world stream classification problems. It is usually defined as the unforeseeable concept change of the target variable in a prediction task. In this paper, we focus on the problem of recurring contexts, a special sub-type of concept drift, that has not yet met the proper attention from the research community. In the case of recurring contexts, concepts may re-appear in future and thus older classification models might be beneficial for future classifications. We propose a general framework for classifying data streams by exploiting stream clustering in order to dynamically build and update an ensemble of incremental classifiers. To achieve this, a transformation function that maps batches of examples into a new conceptual representation model is proposed. The clustering algorithm is …",0
Multi-target regression via input space expansion: treating targets as inputs,2016,https://link.springer.com/article/10.1007/s10994-016-5546-z,"In many practical applications of supervised learning the task involves the prediction of multiple target variables from a common set of input variables. When the prediction targets are binary the task is called multi-label classification, while when the targets are continuous the task is called multi-target regression. In both tasks, target variables often exhibit statistical dependencies and exploiting them in order to improve predictive accuracy is a core challenge. A family of multi-label classification methods address this challenge by building a separate model for each target on an expanded input space where other targets are treated as additional input variables. Despite the success of these methods in the multi-label classification domain, their applicability and effectiveness in multi-target regression has not been studied until now. In this paper, we introduce two new methods for multi-target regression, called …",0
Lecture notes in computer science (including subseries lecture notes in artificial intelligence and lecture notes in bioinformatics): Preface,2010,http://repository.bilkent.edu.tr/bitstream/handle/11693/37924/Recognizing-Patterns.pdf?sequence=1,"The 20th ICPR (International Conference on Pattern Recognition) Conference took place in Istanbul, Turkey, during August 23–26, 2010. For the first time in the ICPR history, several scientific contests (http://www. icpr2010. org/contests. php) were organized in parallel to the conference main tracks. The purpose of these contests was to provide a setting where participants would have the opportunity to evaluate their algorithms using publicly available datasets and standard performance assessment methodologies, disseminate their results, and discuss technical topics in an atmosphere that fosters active exchange of ideas. Members from all segments of the pattern recognition community were invited to submit contest proposals for review.",1
On the utility of incremental feature selection for the classification of textual data streams,2005,https://link.springer.com/chapter/10.1007/11573036_32,"In this paper we argue that incrementally updating the features that a text classification algorithm considers is very important for real-world textual data streams, because in most applications the distribution of data and the description of the classification concept changes over time. We propose the coupling of an incremental feature ranking method and an incremental learning algorithm that can consider different subsets of the feature vector during prediction (what we call a feature based classifier), in order to deal with the above problem. Experimental results with a longitudinal database of real spam and legitimate emails shows that our approach can adapt to the changing nature of streaming data and works much better than classical incremental learning algorithms.",1
Correlation-based pruning of stacked binary relevance models for multi-label learning,2009,https://www.academia.edu/download/30764166/learning-from-multi-label-data.pdf#page=102,"Binary relevance (BR) learns a single binary model for each different label of multi-label data. It has linear complexity with respect to the number of labels, but does not take into account label correlations and may fail to accurately predict label combinations and rank labels according to relevance with a new instance. Stacking the models of BR in order to learn a model that associates their output to the true value of each label is a way to alleviate this problem. In this paper we propose the pruning of the models participating in the stacking process, by explicitly measuring the degree of label correlation using the phi coefficient. Exploratory analysis of phi shows that the correlations detected are meaningful and useful. Empirical evaluation of the pruning approach shows that it leads to substantial reduction of the computational cost of stacking and occasional improvements in predictive performance.",1
Message dissemination dynamics in biological communication systems,2017,http://ikee.lib.auth.gr/record/299332,"Biological systems ranging from simple ecology models to biochemical interactions in molecular biology, have profited profoundly by the advances and potentials of nanotechnology, especially those in lower dimensions. Molecular nanonetworks, the outcome of this adjacency, have been under great growth, the result of which was the establishment of molecular communication paradigm. Under this paradigm, we study the message dissemination dynamics in a biological communication system, by a model typical of electromagnetic networks. Applying a reaction-diffusion mathematical model of double diffusivity in a biological communication system, we compare the outcome with the simulation results. To this aim and based on a commercial tool, a set of efficient simulation scenarios, for the precise prediction of message dissemination dynamics were run, under the newly developed simulation framework. In …",0
Segmento: An R-based Visualization-rich System for Customer Segmentation and Targeting,2016,https://dl.acm.org/doi/abs/10.1145/2903220.2903245,"Customer segmentation is one of the most efficient and promising tools in a marketer's toolbox. In this paper, we introduce Segmento, an R-based customer segmentation system that uses clustering techniques to discover customer segments and offers tools to design and evaluate marketing campaigns. We present the features and the functionality of the system, as well as some of its unique, state-of-the-art visualizations.",1
Segmento,2016,http://ikee.lib.auth.gr/record/300843,"Customer segmentation is one of the most ecient and promis-ing tools in a marketer's toolbox. In this paper, we introduce Segmento, an R-based customer segmentation system that uses clustering techniques to discover customer segments and oers tools to design and evaluate marketing campaigns. We present the features and the functionality of the system, as well as some of its unique, state-of-the-art visualizations.",1
"Proceedings of the 9th Hellenic Conference on Artificial Intelligence, SETN 2016, Thessaloniki, Greece, May 18-20, 2016",2016,https://scholar.google.com/scholar?cluster=2731853471107832757&hl=en&oi=scholarr,Unknown,1
Charting Unique Signatures of Somatic Hypermutation Amongst Chronic Lymphocytic Leukemia Patients Expressing IGHV4-34 Clonotypic B Cell Receptors,2014,https://ashpublications.org/blood/article-abstract/124/21/1969/90110,"The human IGHV4-34 gene encodes antibodies which are intrinsically autoreactive when the VH domain is unmutated. Therefore, B cells expressing IGHV4-34 B-cell receptor immunoglobulins (BcR IG) are normally under close scrutiny in order to avoid unwanted autoreactivity, especially against DNA. The IGHV4-34 gene is frequently utilized in chronic lymphocytic leukemia (CLL), where, typically, it shows a high load of somatic hypermutation (SHM). We have previously reported distinctive SHM patterns amongst IGHV4-34 CLL, especially for subsets with stereotyped BcR IG. However, although a large number of cases (~2000) was previously studied, since even the largest subsets account for only ~3% of CLL, meaningful conclusions could not be reached for smaller subsets. Here we revisit this issue in a series of 16,528 CLL cases and focus on IGHV4-34 expressing subsets: #4 (IGHV4-34/IGHD5-18 …",0
Special Issue on Selected Papers from the 24th Annual IEEE International Conference on Tools with Artificial Intelligence (ICTAI-2012),2014,https://scholar.google.com/scholar?cluster=15657381884320481789&hl=en&oi=scholarr,Unknown,1
"Immunoglobulin Heavy Chain Variable Genes and Alleles: New Entities, New Names and Implications for Research and Prognostication in CLL",2014,https://iris.unito.it/handle/2318/1533750,Il report seguente simula gli indicatori relativi alla produzione scientifica in relazione alle soglie ASN 2018-2020 del proprio SC/SSD. Si ricorda che il superamento dei valori soglia (almeno 2 su 3) è requisito necessario ma non sufficiente al conseguimento dell'abilitazione.La simulazione si basa sui dati IRIS e presenta gli indicatori calcolati alla data indicata sul report. Si ricorda che in sede di domanda ASN presso il MIUR gli indicatori saranno invece calcolati a partire dal 1 gennaio rispettivamente del quinto/decimo/quindicesimo anno precedente la scadenza del quadrimestre di presentazione della domanda (art 2 del DM 598/2018).,1
"Immunoglobulin Heavy Variable Genes and Alleles: New Entities, New Names and Implications for Research and Prognostication in CLL",2014,https://www.diva-portal.org/smash/record.jsf?pid=diva2:767630,Unknown,1
Machine Learning and Neural Networks,2013,https://www.eetn.gr/index.php/about-eetn/eetn-publications/ai-research-in-greece/machine-learning-and-neural-networks?showall=1,"Machine Learning is a subfield of Artificial Intelligence that is concerned with algorithms and techniques that allow computer systems to “learn from experience” to successfully solve artificial intelligence problems. Experience is usually provided in the form of problem-specific “examples”(organized in “datasets”) that allow the learning system to discover new knowledge and improve its performance on a particular task. If the training examples are not available at the beginning of the learning process, but they are collected during training we have the case of “on-line” or incremental learning. If the system is already provided some knowledge about the domain and/or the task, we have the case of knowledge refinement or analytical learning.Machine Learning problems are generally distinguished into three main categories depending on the nature of the datasets: In supervised learning, we are given a set of labeled examples and the aim is to discover the knowledge required for labeling new examples. Typical tasks that fall within the paradigm of supervised learning are classification where a class label is predicted for each input example and regression, where a numerical value is predicted for each input example. In unsupervised learning we are given a set of unlabeled examples and the aim is to identify the underlying structure of the data and extract it in the form of actionable knowledge. Typical unsupervised learning tasks are clustering, where the goal is to identify commonalities among the examples and form interesting clusters, and model estimation, where the knowledge model that generated the data is being sought, eg in the form of …",0
Large-Scale Semantic Indexing Large-Scale Semantic Indexing of Biomedical Publications at BioASQ,2013,http://ikee.lib.auth.gr/record/261421,"Automated annotation of scientic publications in real-world digital libraries requires dealing with challenges such as large number of concepts and training examples, multi-label training examples and hierarchical structure of concepts. BioASQ is a European project that contributes a large-scale biomedical publications corpus for working on these challenges. This paper documents the participation of our team to the large-scale biomedical semantic indexing task of BioASQ.",1
"Artificial Intelligence: Theories, Models and Applications: 7th Hellenic Conference on AI, SETN 2012, Lamia, Greece, May 28-31, 2012, Proceedings",2012,https://books.google.com/books?hl=en&lr=&id=QMm6BQAAQBAJ&oi=fnd&pg=PR2&dq=info:InOjbPsNWLMJ:scholar.google.com&ots=mGYOEcP9I3&sig=9oWWXkUkwP5awkKh2IneOY53Hrc,"This book constitutes the proceedings of the 7th Hellenic Conference on Artificial Intelligence, SETN 2012, held in Lamia, Greece, in May 2012. The 47 contributions included in this volume were carefully reviewed and selected from 81 submissions. They deal with emergent topics of artificial intelligence and come from the SETN main conference as well as from the following special sessions on advancing translational biological research through the incorporation of artificial intelligence methodologies; artificial intelligence in bioinformatics; intelligent annotation of digital content; intelligent, affective, and natural interfaces; and unified multimedia knowledge representation and processing.",1
Evaluation Metrics for Feature Selection in Population Genomic Data,2011,http://lpis.csd.auth.gr/publications/Kavakiotis_SETN14.pdf,"Single Nucleotide Polymorphisms (SNPs) are considered nowadays one of the most important class of genetic markers with a wide range of applications with both scientific and economic interests. Although the advance of biotechnology has made feasible the production of genome wide SNP datasets, the cost of the production is still high. The transformation of the initial dataset into a smaller one with the same genetic information is a crucial task and it is performed through feature selection. Biologists evaluate features using methods originating from the field of population genetics. Although several studies have been performed in order to compare the existing biological methods, there is a lack of comparison between methods originating from the biology field with others originating from the machine learning. In this study we present some early results which support that biological methods perform slightly better than machine learning methods.",1
Iridescent: a Tool for Rapid Semantic Web Service Descriptions,2011,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.248.6389&rep=rep1&type=pdf,"Although the Semantic Web and Web Service technologies have already formed a synergy towards Semantic Web Services, their use remains limited. Potential adopters are usually discouraged by the plurality of methodologies and the lack of tools which in turn force them to acquire expert knowledge and commit to exhausting manual labor. This work proposes a novel, functional and user-friendly tool, named Iridescent, intended for both expert and nonexpert users to rapidly create and edit Semantic Web Service descriptions, following the SAWSDL recommendation. The tool‟ s aim is twofold: to enable users manually create descriptions in a visual manner, providing a complete alternative to coding, and to semi-automate the process by matching elements and concepts and suggesting annotations. A state-of-the-art survey has been carried out to reveal critical requirements and compare Iridescent to existing tools. Usage scenarios demonstrate how Iridescent enhances the authoring process and in turn enables Intelligence eg in an Ambient Intelligence environment. Finally, the tool was methodically tested for usability and evaluated by a range of expert and non-expert users.",1
Obtaining Bipartitions from Score Vectors for Multi-Label Classification,2010,https://scholar.google.com/scholar?cluster=10046395636862074568&hl=en&oi=scholarr,"Multi-label classification is a popular learning task. However, some of the algorithms that learn from multi-label data, can only output a score for each label, so they cannot be readily used in applications that require bipartitions. In addition, several of the recent state-of-the-art multi-label classification algorithms, actually output a score vector primarily and employ one (sometimes simple) thresholding method in order to be able to output bipartitions. Furthermore, some approaches can naturally output both a score vector and a bipartition, but whether a better bipartition can be obtained through thresholding has not been investigated. This paper contributes a theoretical and empirical comparative study of existing thresholding methods, highlighting their importance for obtaining bipartitions of high quality.",1
Artificial Intelligence for Advanced Problem Solving Techniques,2010,https://scholar.google.com/scholar?cluster=14664458414925777268&hl=en&oi=scholarr,"As a graduate student in the early 1970s, Percy Brill devoted 2 years of his life (several thousand hours by his count) tediously deriving'fifty page'integral equations for stochastic models by hand. Naturally, he wondered if there was a better way. His experiences led to the observation that many of his derivations could be completed in a simpler manner. The fundamental structure of these alternate derivations became the basis for a body of methods known as level crossing methods.Level Crossing Methods in Stochastic Models is a book that describes how such methods can be used to analyse a variety of stochastic models including M/G/l queues (and variants), M/M/c queues, G/M/c queues, multi-dimensional models, inventory models, and many others. Level-crossing methods work using an intuitive ratebalancing property. The methods start by drawing a sample path of the system in time-for example, the virtual …",0
Special issue on Artificial Intelligence Techniques for Pervasive Computing: Preface”.,2010,http://mlkd.csd.auth.gr/publication_details.asp?publicationID=339,"This special issue focuses on how Artificial Intelligence techniques of various AI sub-areas, such as Knowledge Representation and Reasoning, Machine Learning, Machine Vision, Speech Recognition, Intelligent Human-Computer Interaction, Intelligent Agents, can contribute to the vision of pervasive computing to build electronic environments that are sensitive and responsive to the presence of people, by tackling highly interesting issues, such as applications providing personalized access and interactivity to multimodal information based on user preferences and semantic concepts or human-machine interface systems utilizing information on the affective state of the user.",1
Special Issue on Artificial Intelligence Techniques for Pervasive Computing,2010,https://scholar.google.com/scholar?cluster=15857720966381422866&hl=en&oi=scholarr,Unknown,1
Focused Crawling Bibliography,2008,https://www.researchgate.net/profile/I-Vlahavas/publication/228693774_Focused_Crawling_Bibliography/links/02e7e522789a28e471000000/Focused-Crawling-Bibliography.pdf,"Focused Crawling Bibliography Page 1 Focused Crawling Bibliography Ioannis Partalas, 
Ioannis Vlahavas {partalas,vlahavas}@csd.auth.gr February 28, 2008 Focused Crawling 
Bibliography [De Bra and Post, 1994], [Hersovici et al., 1998], [Cho et al., 1998], [Diligenti et 
al., 2000], [Grigoriadis and Paliouras, 2004], [Rennie and McCallum, 1999], [C.-C. Hsu, 2006], 
[Chakrabarti et al., 1999], [Page et al., 1998], [O’Meara and Patel, 2001], [Johnson et al., 
2003], [Pant and Menczer, 2002], [Chakrabarti et al., 2002], [Liu et al., 2004],[Srinivasan et al., 
2005], [Pant and Srinivasan, 2005], [Pant and Srinivasan, 2006], [Almpanidis et al., 2007], [Babaria 
et al., 2007]. References G. Almpanidis, C. Kotropoulos, and I. Pitas. Combining text and link 
analysis for focused crawling-an application for vertical search engines. Information Systems, 
32(6):886–908, 2007. Rashmin Babaria, J. Saketha Nath, Krishnan S, Sivaramakrishnan KR, .…",0
